[10:27:30.124] Namespace(base_lr=0.01, batch_size=24, consistency=0.1, consistency_rampup=200.0, consistency_type='mse', deterministic=1, ema_decay=0.99, exp='ACDC/EVILv1_kl0.5_tau0.25', labeled_bs=12, labeled_num=21, max_iterations=30000, model='unet', num_classes=4, patch_size=[256, 256], root_path='../data/ACDC', seed=1337)
[10:27:30.284] 33 iterations per epoch
[10:27:37.323] iteration 1 : model1 loss : 1.436182 model2 loss : 1.083758
[10:27:37.524] iteration 2 : model1 loss : 1.266022 model2 loss : 1.054896
[10:27:37.697] iteration 3 : model1 loss : 0.964829 model2 loss : 0.999288
[10:27:37.873] iteration 4 : model1 loss : 0.692714 model2 loss : 0.936500
[10:27:38.067] iteration 5 : model1 loss : 0.567568 model2 loss : 0.854536
[10:27:38.253] iteration 6 : model1 loss : 0.536227 model2 loss : 0.759726
[10:27:38.440] iteration 7 : model1 loss : 0.537968 model2 loss : 0.698059
[10:27:38.634] iteration 8 : model1 loss : 0.539410 model2 loss : 0.632874
[10:27:38.831] iteration 9 : model1 loss : 0.518869 model2 loss : 0.570825
[10:27:39.035] iteration 10 : model1 loss : 0.530586 model2 loss : 0.539725
[10:27:39.230] iteration 11 : model1 loss : 0.521366 model2 loss : 0.506097
[10:27:39.423] iteration 12 : model1 loss : 0.510027 model2 loss : 0.483849
[10:27:39.596] iteration 13 : model1 loss : 0.530027 model2 loss : 0.491483
[10:27:39.772] iteration 14 : model1 loss : 0.521741 model2 loss : 0.478092
[10:27:39.941] iteration 15 : model1 loss : 0.523917 model2 loss : 0.473143
[10:27:40.121] iteration 16 : model1 loss : 0.507093 model2 loss : 0.461903
[10:27:40.312] iteration 17 : model1 loss : 0.525218 model2 loss : 0.473319
[10:27:40.526] iteration 18 : model1 loss : 0.508428 model2 loss : 0.463298
[10:27:40.747] iteration 19 : model1 loss : 0.530662 model2 loss : 0.476304
[10:27:40.947] iteration 20 : model1 loss : 0.532728 model2 loss : 0.481827
[10:27:41.164] iteration 21 : model1 loss : 0.524698 model2 loss : 0.459129
[10:27:41.375] iteration 22 : model1 loss : 0.512141 model2 loss : 0.451738
[10:27:41.593] iteration 23 : model1 loss : 0.532891 model2 loss : 0.482720
[10:27:41.801] iteration 24 : model1 loss : 0.525868 model2 loss : 0.472506
[10:27:41.988] iteration 25 : model1 loss : 0.507521 model2 loss : 0.444223
[10:27:42.169] iteration 26 : model1 loss : 0.539401 model2 loss : 0.475172
[10:27:42.351] iteration 27 : model1 loss : 0.534284 model2 loss : 0.471401
[10:27:42.534] iteration 28 : model1 loss : 0.522526 model2 loss : 0.457542
[10:27:42.717] iteration 29 : model1 loss : 0.521776 model2 loss : 0.468591
[10:27:42.896] iteration 30 : model1 loss : 0.511104 model2 loss : 0.448488
[10:27:43.068] iteration 31 : model1 loss : 0.510173 model2 loss : 0.451752
[10:27:43.251] iteration 32 : model1 loss : 0.526412 model2 loss : 0.450756
[10:27:43.421] iteration 33 : model1 loss : 0.523728 model2 loss : 0.447227
[10:27:45.431] iteration 34 : model1 loss : 0.500806 model2 loss : 0.431170
[10:27:45.606] iteration 35 : model1 loss : 0.504433 model2 loss : 0.447811
[10:27:45.785] iteration 36 : model1 loss : 0.513670 model2 loss : 0.447804
[10:27:45.957] iteration 37 : model1 loss : 0.528198 model2 loss : 0.459171
[10:27:46.127] iteration 38 : model1 loss : 0.535611 model2 loss : 0.464450
[10:27:46.296] iteration 39 : model1 loss : 0.513192 model2 loss : 0.439548
[10:27:46.473] iteration 40 : model1 loss : 0.513601 model2 loss : 0.447081
[10:27:46.640] iteration 41 : model1 loss : 0.510354 model2 loss : 0.435692
[10:27:46.811] iteration 42 : model1 loss : 0.536581 model2 loss : 0.449695
[10:27:46.977] iteration 43 : model1 loss : 0.512256 model2 loss : 0.442448
[10:27:47.147] iteration 44 : model1 loss : 0.521481 model2 loss : 0.438026
[10:27:47.318] iteration 45 : model1 loss : 0.534566 model2 loss : 0.464347
[10:27:47.489] iteration 46 : model1 loss : 0.532642 model2 loss : 0.466023
[10:27:47.656] iteration 47 : model1 loss : 0.522662 model2 loss : 0.436645
[10:27:47.830] iteration 48 : model1 loss : 0.522795 model2 loss : 0.430770
[10:27:47.996] iteration 49 : model1 loss : 0.535362 model2 loss : 0.468859
[10:27:48.171] iteration 50 : model1 loss : 0.523965 model2 loss : 0.441662
[10:27:48.340] iteration 51 : model1 loss : 0.519540 model2 loss : 0.449037
[10:27:48.517] iteration 52 : model1 loss : 0.529725 model2 loss : 0.444017
[10:27:48.699] iteration 53 : model1 loss : 0.526694 model2 loss : 0.444968
[10:27:48.892] iteration 54 : model1 loss : 0.514953 model2 loss : 0.444695
[10:27:49.081] iteration 55 : model1 loss : 0.527994 model2 loss : 0.455330
[10:27:49.265] iteration 56 : model1 loss : 0.504107 model2 loss : 0.433556
[10:27:49.450] iteration 57 : model1 loss : 0.508286 model2 loss : 0.437966
[10:27:49.633] iteration 58 : model1 loss : 0.525272 model2 loss : 0.428199
[10:27:49.803] iteration 59 : model1 loss : 0.538155 model2 loss : 0.431871
[10:27:49.977] iteration 60 : model1 loss : 0.505168 model2 loss : 0.429560
[10:27:50.143] iteration 61 : model1 loss : 0.509641 model2 loss : 0.438739
[10:27:50.315] iteration 62 : model1 loss : 0.524790 model2 loss : 0.439003
[10:27:50.486] iteration 63 : model1 loss : 0.524799 model2 loss : 0.444865
[10:27:50.657] iteration 64 : model1 loss : 0.518637 model2 loss : 0.446105
[10:27:50.827] iteration 65 : model1 loss : 0.516906 model2 loss : 0.439783
[10:27:50.997] iteration 66 : model1 loss : 0.512339 model2 loss : 0.423209
[10:27:53.141] iteration 67 : model1 loss : 0.521510 model2 loss : 0.445790
[10:27:53.314] iteration 68 : model1 loss : 0.523442 model2 loss : 0.433974
[10:27:53.490] iteration 69 : model1 loss : 0.521687 model2 loss : 0.440827
[10:27:53.662] iteration 70 : model1 loss : 0.514869 model2 loss : 0.430537
[10:27:53.834] iteration 71 : model1 loss : 0.507638 model2 loss : 0.421818
[10:27:54.000] iteration 72 : model1 loss : 0.517050 model2 loss : 0.425754
[10:27:54.173] iteration 73 : model1 loss : 0.526766 model2 loss : 0.422019
[10:27:54.342] iteration 74 : model1 loss : 0.517746 model2 loss : 0.433782
[10:27:54.516] iteration 75 : model1 loss : 0.513042 model2 loss : 0.421637
[10:27:54.687] iteration 76 : model1 loss : 0.519067 model2 loss : 0.441580
[10:27:54.864] iteration 77 : model1 loss : 0.513082 model2 loss : 0.424655
[10:27:55.031] iteration 78 : model1 loss : 0.509448 model2 loss : 0.398086
[10:27:55.202] iteration 79 : model1 loss : 0.535333 model2 loss : 0.463656
[10:27:55.370] iteration 80 : model1 loss : 0.517746 model2 loss : 0.428152
[10:27:55.545] iteration 81 : model1 loss : 0.516800 model2 loss : 0.426740
[10:27:55.717] iteration 82 : model1 loss : 0.507911 model2 loss : 0.410535
[10:27:55.897] iteration 83 : model1 loss : 0.507059 model2 loss : 0.421072
[10:27:56.065] iteration 84 : model1 loss : 0.525874 model2 loss : 0.449439
[10:27:56.237] iteration 85 : model1 loss : 0.530924 model2 loss : 0.443323
[10:27:56.423] iteration 86 : model1 loss : 0.519618 model2 loss : 0.415206
[10:27:56.600] iteration 87 : model1 loss : 0.504812 model2 loss : 0.430320
[10:27:56.768] iteration 88 : model1 loss : 0.510065 model2 loss : 0.414400
[10:27:56.940] iteration 89 : model1 loss : 0.520978 model2 loss : 0.437953
[10:27:57.107] iteration 90 : model1 loss : 0.515023 model2 loss : 0.415097
[10:27:57.279] iteration 91 : model1 loss : 0.533434 model2 loss : 0.454627
[10:27:57.447] iteration 92 : model1 loss : 0.513142 model2 loss : 0.407266
[10:27:57.621] iteration 93 : model1 loss : 0.509628 model2 loss : 0.398554
[10:27:57.790] iteration 94 : model1 loss : 0.523449 model2 loss : 0.427030
[10:27:57.960] iteration 95 : model1 loss : 0.523675 model2 loss : 0.398039
[10:27:58.125] iteration 96 : model1 loss : 0.511550 model2 loss : 0.399830
[10:27:58.298] iteration 97 : model1 loss : 0.520733 model2 loss : 0.410256
[10:27:58.464] iteration 98 : model1 loss : 0.522702 model2 loss : 0.426814
[10:27:58.634] iteration 99 : model1 loss : 0.513259 model2 loss : 0.398180
[10:28:00.975] iteration 100 : model1 loss : 0.521456 model2 loss : 0.406310
[10:28:01.163] iteration 101 : model1 loss : 0.506805 model2 loss : 0.415880
[10:28:01.372] iteration 102 : model1 loss : 0.511035 model2 loss : 0.402969
[10:28:01.575] iteration 103 : model1 loss : 0.517009 model2 loss : 0.386721
[10:28:01.751] iteration 104 : model1 loss : 0.513792 model2 loss : 0.392186
[10:28:01.929] iteration 105 : model1 loss : 0.522111 model2 loss : 0.416724
[10:28:02.103] iteration 106 : model1 loss : 0.518324 model2 loss : 0.418177
[10:28:02.327] iteration 107 : model1 loss : 0.534814 model2 loss : 0.445001
[10:28:02.495] iteration 108 : model1 loss : 0.525686 model2 loss : 0.415204
[10:28:02.671] iteration 109 : model1 loss : 0.504886 model2 loss : 0.412906
[10:28:02.844] iteration 110 : model1 loss : 0.501378 model2 loss : 0.367028
[10:28:03.017] iteration 111 : model1 loss : 0.516357 model2 loss : 0.426781
[10:28:03.184] iteration 112 : model1 loss : 0.531398 model2 loss : 0.399621
[10:28:03.358] iteration 113 : model1 loss : 0.517852 model2 loss : 0.412679
[10:28:03.531] iteration 114 : model1 loss : 0.517924 model2 loss : 0.395639
[10:28:03.703] iteration 115 : model1 loss : 0.519225 model2 loss : 0.420246
[10:28:03.871] iteration 116 : model1 loss : 0.514861 model2 loss : 0.401033
[10:28:04.043] iteration 117 : model1 loss : 0.511568 model2 loss : 0.442285
[10:28:04.209] iteration 118 : model1 loss : 0.511241 model2 loss : 0.389182
[10:28:04.383] iteration 119 : model1 loss : 0.514232 model2 loss : 0.391138
[10:28:04.557] iteration 120 : model1 loss : 0.510262 model2 loss : 0.397556
[10:28:04.736] iteration 121 : model1 loss : 0.518946 model2 loss : 0.434069
[10:28:04.917] iteration 122 : model1 loss : 0.510691 model2 loss : 0.378425
[10:28:05.106] iteration 123 : model1 loss : 0.522062 model2 loss : 0.413216
[10:28:05.282] iteration 124 : model1 loss : 0.523239 model2 loss : 0.370029
[10:28:05.472] iteration 125 : model1 loss : 0.518454 model2 loss : 0.409503
[10:28:05.661] iteration 126 : model1 loss : 0.520272 model2 loss : 0.412904
[10:28:05.841] iteration 127 : model1 loss : 0.519892 model2 loss : 0.416766
[10:28:06.026] iteration 128 : model1 loss : 0.505241 model2 loss : 0.418949
[10:28:06.206] iteration 129 : model1 loss : 0.515018 model2 loss : 0.362488
[10:28:06.374] iteration 130 : model1 loss : 0.522199 model2 loss : 0.406181
[10:28:06.545] iteration 131 : model1 loss : 0.512930 model2 loss : 0.385489
[10:28:06.712] iteration 132 : model1 loss : 0.515796 model2 loss : 0.344426
[10:28:08.806] iteration 133 : model1 loss : 0.512129 model2 loss : 0.369342
[10:28:08.986] iteration 134 : model1 loss : 0.509420 model2 loss : 0.379143
[10:28:09.163] iteration 135 : model1 loss : 0.514878 model2 loss : 0.369884
[10:28:09.350] iteration 136 : model1 loss : 0.521291 model2 loss : 0.379216
[10:28:09.529] iteration 137 : model1 loss : 0.517329 model2 loss : 0.367330
[10:28:09.697] iteration 138 : model1 loss : 0.522536 model2 loss : 0.365673
[10:28:09.869] iteration 139 : model1 loss : 0.517496 model2 loss : 0.376509
[10:28:10.036] iteration 140 : model1 loss : 0.515657 model2 loss : 0.332029
[10:28:10.208] iteration 141 : model1 loss : 0.519457 model2 loss : 0.389869
[10:28:10.393] iteration 142 : model1 loss : 0.530372 model2 loss : 0.347191
[10:28:10.566] iteration 143 : model1 loss : 0.501166 model2 loss : 0.354457
[10:28:10.734] iteration 144 : model1 loss : 0.528169 model2 loss : 0.394812
[10:28:10.906] iteration 145 : model1 loss : 0.509852 model2 loss : 0.386913
[10:28:11.075] iteration 146 : model1 loss : 0.519048 model2 loss : 0.376445
[10:28:11.247] iteration 147 : model1 loss : 0.512266 model2 loss : 0.377227
[10:28:11.415] iteration 148 : model1 loss : 0.519007 model2 loss : 0.402594
[10:28:11.601] iteration 149 : model1 loss : 0.503940 model2 loss : 0.349666
[10:28:11.772] iteration 150 : model1 loss : 0.511975 model2 loss : 0.370525
[10:28:11.944] iteration 151 : model1 loss : 0.508547 model2 loss : 0.384129
[10:28:12.112] iteration 152 : model1 loss : 0.511456 model2 loss : 0.346019
[10:28:12.284] iteration 153 : model1 loss : 0.516521 model2 loss : 0.337998
[10:28:12.452] iteration 154 : model1 loss : 0.516717 model2 loss : 0.346716
[10:28:12.629] iteration 155 : model1 loss : 0.505111 model2 loss : 0.338669
[10:28:12.803] iteration 156 : model1 loss : 0.513410 model2 loss : 0.339093
[10:28:12.976] iteration 157 : model1 loss : 0.512248 model2 loss : 0.347849
[10:28:13.147] iteration 158 : model1 loss : 0.527343 model2 loss : 0.316466
[10:28:13.318] iteration 159 : model1 loss : 0.514189 model2 loss : 0.360452
[10:28:13.488] iteration 160 : model1 loss : 0.504257 model2 loss : 0.323798
[10:28:13.661] iteration 161 : model1 loss : 0.510703 model2 loss : 0.353637
[10:28:13.833] iteration 162 : model1 loss : 0.513807 model2 loss : 0.340284
[10:28:14.003] iteration 163 : model1 loss : 0.519248 model2 loss : 0.369209
[10:28:14.174] iteration 164 : model1 loss : 0.513371 model2 loss : 0.364454
[10:28:14.342] iteration 165 : model1 loss : 0.511969 model2 loss : 0.350655
[10:28:16.398] iteration 166 : model1 loss : 0.516210 model2 loss : 0.351699
[10:28:16.574] iteration 167 : model1 loss : 0.521445 model2 loss : 0.334588
[10:28:16.758] iteration 168 : model1 loss : 0.515485 model2 loss : 0.338185
[10:28:16.950] iteration 169 : model1 loss : 0.511088 model2 loss : 0.318647
[10:28:17.129] iteration 170 : model1 loss : 0.510237 model2 loss : 0.351853
[10:28:17.297] iteration 171 : model1 loss : 0.516681 model2 loss : 0.375104
[10:28:17.498] iteration 172 : model1 loss : 0.523038 model2 loss : 0.347920
[10:28:17.700] iteration 173 : model1 loss : 0.515459 model2 loss : 0.344265
[10:28:17.906] iteration 174 : model1 loss : 0.496788 model2 loss : 0.338493
[10:28:18.095] iteration 175 : model1 loss : 0.515994 model2 loss : 0.313288
[10:28:18.287] iteration 176 : model1 loss : 0.511928 model2 loss : 0.323171
[10:28:18.486] iteration 177 : model1 loss : 0.507799 model2 loss : 0.328587
[10:28:18.667] iteration 178 : model1 loss : 0.516881 model2 loss : 0.326231
[10:28:18.844] iteration 179 : model1 loss : 0.499906 model2 loss : 0.320969
[10:28:19.017] iteration 180 : model1 loss : 0.523151 model2 loss : 0.330523
[10:28:19.185] iteration 181 : model1 loss : 0.500968 model2 loss : 0.327712
[10:28:19.368] iteration 182 : model1 loss : 0.525388 model2 loss : 0.344185
[10:28:19.547] iteration 183 : model1 loss : 0.522078 model2 loss : 0.305675
[10:28:19.720] iteration 184 : model1 loss : 0.508766 model2 loss : 0.304964
[10:28:19.894] iteration 185 : model1 loss : 0.510428 model2 loss : 0.324562
[10:28:20.070] iteration 186 : model1 loss : 0.506294 model2 loss : 0.326754
[10:28:20.237] iteration 187 : model1 loss : 0.513324 model2 loss : 0.336068
[10:28:20.407] iteration 188 : model1 loss : 0.515009 model2 loss : 0.327030
[10:28:20.579] iteration 189 : model1 loss : 0.514957 model2 loss : 0.330747
[10:28:20.751] iteration 190 : model1 loss : 0.500260 model2 loss : 0.271108
[10:28:20.918] iteration 191 : model1 loss : 0.518174 model2 loss : 0.293420
[10:28:21.091] iteration 192 : model1 loss : 0.505045 model2 loss : 0.289192
[10:28:21.260] iteration 193 : model1 loss : 0.510301 model2 loss : 0.325679
[10:28:21.431] iteration 194 : model1 loss : 0.519045 model2 loss : 0.343235
[10:28:21.610] iteration 195 : model1 loss : 0.518950 model2 loss : 0.305822
[10:28:21.785] iteration 196 : model1 loss : 0.496260 model2 loss : 0.330240
[10:28:21.950] iteration 197 : model1 loss : 0.517105 model2 loss : 0.332328
[10:28:22.116] iteration 198 : model1 loss : 0.510909 model2 loss : 0.296178
[10:28:24.182] iteration 199 : model1 loss : 0.509152 model2 loss : 0.307803
[10:28:24.353] iteration 200 : model1 loss : 0.518941 model2 loss : 0.294109
[10:28:24.544] iteration 201 : model1 loss : 0.512685 model2 loss : 0.309100
[10:28:24.718] iteration 202 : model1 loss : 0.505367 model2 loss : 0.311514
[10:28:24.890] iteration 203 : model1 loss : 0.503082 model2 loss : 0.347042
[10:28:25.062] iteration 204 : model1 loss : 0.519645 model2 loss : 0.329071
[10:28:25.234] iteration 205 : model1 loss : 0.515773 model2 loss : 0.311933
[10:28:25.403] iteration 206 : model1 loss : 0.506724 model2 loss : 0.324855
[10:28:25.577] iteration 207 : model1 loss : 0.514798 model2 loss : 0.260012
[10:28:25.747] iteration 208 : model1 loss : 0.516721 model2 loss : 0.307191
[10:28:25.916] iteration 209 : model1 loss : 0.521275 model2 loss : 0.290347
[10:28:26.099] iteration 210 : model1 loss : 0.510235 model2 loss : 0.285805
[10:28:26.274] iteration 211 : model1 loss : 0.515756 model2 loss : 0.270156
[10:28:26.443] iteration 212 : model1 loss : 0.502470 model2 loss : 0.279632
[10:28:26.617] iteration 213 : model1 loss : 0.511992 model2 loss : 0.345710
[10:28:26.802] iteration 214 : model1 loss : 0.508218 model2 loss : 0.337566
[10:28:26.975] iteration 215 : model1 loss : 0.497190 model2 loss : 0.286775
[10:28:27.141] iteration 216 : model1 loss : 0.495460 model2 loss : 0.245410
[10:28:27.317] iteration 217 : model1 loss : 0.520137 model2 loss : 0.262097
[10:28:27.495] iteration 218 : model1 loss : 0.521464 model2 loss : 0.259299
[10:28:27.671] iteration 219 : model1 loss : 0.501243 model2 loss : 0.271494
[10:28:27.839] iteration 220 : model1 loss : 0.501331 model2 loss : 0.273054
[10:28:28.012] iteration 221 : model1 loss : 0.514785 model2 loss : 0.268789
[10:28:28.180] iteration 222 : model1 loss : 0.504901 model2 loss : 0.231878
[10:28:28.357] iteration 223 : model1 loss : 0.507342 model2 loss : 0.229290
[10:28:28.537] iteration 224 : model1 loss : 0.502028 model2 loss : 0.311551
[10:28:28.717] iteration 225 : model1 loss : 0.507558 model2 loss : 0.286950
[10:28:28.886] iteration 226 : model1 loss : 0.512032 model2 loss : 0.325579
[10:28:29.078] iteration 227 : model1 loss : 0.501958 model2 loss : 0.285283
[10:28:29.251] iteration 228 : model1 loss : 0.491362 model2 loss : 0.241812
[10:28:29.422] iteration 229 : model1 loss : 0.505877 model2 loss : 0.329865
[10:28:29.595] iteration 230 : model1 loss : 0.514627 model2 loss : 0.278063
[10:28:29.768] iteration 231 : model1 loss : 0.505116 model2 loss : 0.257993
[10:28:31.826] iteration 232 : model1 loss : 0.505352 model2 loss : 0.356302
[10:28:31.993] iteration 233 : model1 loss : 0.504518 model2 loss : 0.273964
[10:28:32.165] iteration 234 : model1 loss : 0.504194 model2 loss : 0.287205
[10:28:32.334] iteration 235 : model1 loss : 0.521638 model2 loss : 0.331464
[10:28:32.504] iteration 236 : model1 loss : 0.499184 model2 loss : 0.218591
[10:28:32.673] iteration 237 : model1 loss : 0.506623 model2 loss : 0.305757
[10:28:32.856] iteration 238 : model1 loss : 0.510305 model2 loss : 0.255263
[10:28:33.030] iteration 239 : model1 loss : 0.502402 model2 loss : 0.237045
[10:28:33.205] iteration 240 : model1 loss : 0.493160 model2 loss : 0.286357
[10:28:33.375] iteration 241 : model1 loss : 0.507002 model2 loss : 0.212699
[10:28:33.556] iteration 242 : model1 loss : 0.498291 model2 loss : 0.247806
[10:28:33.727] iteration 243 : model1 loss : 0.506252 model2 loss : 0.228485
[10:28:33.907] iteration 244 : model1 loss : 0.505216 model2 loss : 0.226826
[10:28:34.080] iteration 245 : model1 loss : 0.518771 model2 loss : 0.239592
[10:28:34.251] iteration 246 : model1 loss : 0.502367 model2 loss : 0.214668
[10:28:34.419] iteration 247 : model1 loss : 0.491289 model2 loss : 0.284536
[10:28:34.594] iteration 248 : model1 loss : 0.501041 model2 loss : 0.206950
[10:28:34.762] iteration 249 : model1 loss : 0.500590 model2 loss : 0.242670
[10:28:34.934] iteration 250 : model1 loss : 0.502257 model2 loss : 0.254987
[10:28:35.104] iteration 251 : model1 loss : 0.506047 model2 loss : 0.255365
[10:28:35.276] iteration 252 : model1 loss : 0.496441 model2 loss : 0.223657
[10:28:35.444] iteration 253 : model1 loss : 0.510780 model2 loss : 0.316451
[10:28:35.615] iteration 254 : model1 loss : 0.498224 model2 loss : 0.249437
[10:28:35.803] iteration 255 : model1 loss : 0.512452 model2 loss : 0.276533
[10:28:36.002] iteration 256 : model1 loss : 0.505648 model2 loss : 0.223723
[10:28:36.198] iteration 257 : model1 loss : 0.490811 model2 loss : 0.240166
[10:28:36.382] iteration 258 : model1 loss : 0.506248 model2 loss : 0.214881
[10:28:36.565] iteration 259 : model1 loss : 0.507589 model2 loss : 0.260031
[10:28:36.741] iteration 260 : model1 loss : 0.499416 model2 loss : 0.225506
[10:28:36.919] iteration 261 : model1 loss : 0.501294 model2 loss : 0.223428
[10:28:37.119] iteration 262 : model1 loss : 0.519727 model2 loss : 0.208311
[10:28:37.300] iteration 263 : model1 loss : 0.497744 model2 loss : 0.168758
[10:28:37.479] iteration 264 : model1 loss : 0.499792 model2 loss : 0.229968
[10:28:39.528] iteration 265 : model1 loss : 0.506001 model2 loss : 0.226748
[10:28:39.711] iteration 266 : model1 loss : 0.494918 model2 loss : 0.214693
[10:28:39.887] iteration 267 : model1 loss : 0.506196 model2 loss : 0.190600
[10:28:40.071] iteration 268 : model1 loss : 0.502585 model2 loss : 0.225386
[10:28:40.263] iteration 269 : model1 loss : 0.503128 model2 loss : 0.217311
[10:28:40.447] iteration 270 : model1 loss : 0.503818 model2 loss : 0.243318
[10:28:40.623] iteration 271 : model1 loss : 0.511357 model2 loss : 0.240936
[10:28:40.830] iteration 272 : model1 loss : 0.494416 model2 loss : 0.240937
[10:28:41.024] iteration 273 : model1 loss : 0.502775 model2 loss : 0.237628
[10:28:41.212] iteration 274 : model1 loss : 0.500536 model2 loss : 0.169418
[10:28:41.394] iteration 275 : model1 loss : 0.501190 model2 loss : 0.165481
[10:28:41.586] iteration 276 : model1 loss : 0.503866 model2 loss : 0.223221
[10:28:41.777] iteration 277 : model1 loss : 0.499114 model2 loss : 0.235576
[10:28:41.967] iteration 278 : model1 loss : 0.504105 model2 loss : 0.229358
[10:28:42.142] iteration 279 : model1 loss : 0.510301 model2 loss : 0.228037
[10:28:42.327] iteration 280 : model1 loss : 0.484496 model2 loss : 0.152295
[10:28:42.496] iteration 281 : model1 loss : 0.491596 model2 loss : 0.244297
[10:28:42.672] iteration 282 : model1 loss : 0.512707 model2 loss : 0.214901
[10:28:42.841] iteration 283 : model1 loss : 0.496367 model2 loss : 0.212015
[10:28:43.016] iteration 284 : model1 loss : 0.498070 model2 loss : 0.175001
[10:28:43.190] iteration 285 : model1 loss : 0.505067 model2 loss : 0.235073
[10:28:43.362] iteration 286 : model1 loss : 0.501027 model2 loss : 0.139974
[10:28:43.542] iteration 287 : model1 loss : 0.499758 model2 loss : 0.153121
[10:28:43.719] iteration 288 : model1 loss : 0.501366 model2 loss : 0.142715
[10:28:43.888] iteration 289 : model1 loss : 0.493023 model2 loss : 0.145150
[10:28:44.063] iteration 290 : model1 loss : 0.497434 model2 loss : 0.174507
[10:28:44.234] iteration 291 : model1 loss : 0.506898 model2 loss : 0.172062
[10:28:44.407] iteration 292 : model1 loss : 0.505474 model2 loss : 0.153731
[10:28:44.580] iteration 293 : model1 loss : 0.503562 model2 loss : 0.211968
[10:28:44.752] iteration 294 : model1 loss : 0.495418 model2 loss : 0.142350
[10:28:44.942] iteration 295 : model1 loss : 0.499441 model2 loss : 0.201287
[10:28:45.135] iteration 296 : model1 loss : 0.489098 model2 loss : 0.107711
[10:28:45.327] iteration 297 : model1 loss : 0.502542 model2 loss : 0.154989
[10:28:47.518] iteration 298 : model1 loss : 0.505336 model2 loss : 0.197328
[10:28:47.697] iteration 299 : model1 loss : 0.496407 model2 loss : 0.191857
[10:28:47.877] iteration 300 : model1 loss : 0.496775 model2 loss : 0.208816
[10:28:48.058] iteration 301 : model1 loss : 0.497721 model2 loss : 0.155038
[10:28:48.254] iteration 302 : model1 loss : 0.498295 model2 loss : 0.156021
[10:28:48.440] iteration 303 : model1 loss : 0.485386 model2 loss : 0.164922
[10:28:48.618] iteration 304 : model1 loss : 0.498428 model2 loss : 0.217252
[10:28:48.795] iteration 305 : model1 loss : 0.493160 model2 loss : 0.140157
[10:28:48.971] iteration 306 : model1 loss : 0.496665 model2 loss : 0.149522
[10:28:49.155] iteration 307 : model1 loss : 0.503959 model2 loss : 0.206758
[10:28:49.334] iteration 308 : model1 loss : 0.480535 model2 loss : 0.095350
[10:28:49.520] iteration 309 : model1 loss : 0.497834 model2 loss : 0.159313
[10:28:49.696] iteration 310 : model1 loss : 0.498010 model2 loss : 0.188092
[10:28:49.882] iteration 311 : model1 loss : 0.492464 model2 loss : 0.141237
[10:28:50.054] iteration 312 : model1 loss : 0.486065 model2 loss : 0.136725
[10:28:50.233] iteration 313 : model1 loss : 0.488830 model2 loss : 0.133213
[10:28:50.406] iteration 314 : model1 loss : 0.507675 model2 loss : 0.201805
[10:28:50.582] iteration 315 : model1 loss : 0.487414 model2 loss : 0.151534
[10:28:50.755] iteration 316 : model1 loss : 0.498254 model2 loss : 0.197369
[10:28:50.923] iteration 317 : model1 loss : 0.490694 model2 loss : 0.170676
[10:28:51.094] iteration 318 : model1 loss : 0.483147 model2 loss : 0.181819
[10:28:51.281] iteration 319 : model1 loss : 0.492616 model2 loss : 0.125305
[10:28:51.460] iteration 320 : model1 loss : 0.496302 model2 loss : 0.143129
[10:28:51.628] iteration 321 : model1 loss : 0.497135 model2 loss : 0.139138
[10:28:51.803] iteration 322 : model1 loss : 0.494330 model2 loss : 0.125661
[10:28:51.974] iteration 323 : model1 loss : 0.494509 model2 loss : 0.159409
[10:28:52.145] iteration 324 : model1 loss : 0.503923 model2 loss : 0.149735
[10:28:52.322] iteration 325 : model1 loss : 0.493214 model2 loss : 0.149313
[10:28:52.505] iteration 326 : model1 loss : 0.503575 model2 loss : 0.193334
[10:28:52.683] iteration 327 : model1 loss : 0.503026 model2 loss : 0.183975
[10:28:52.874] iteration 328 : model1 loss : 0.498298 model2 loss : 0.141709
[10:28:53.045] iteration 329 : model1 loss : 0.491426 model2 loss : 0.172995
[10:28:53.227] iteration 330 : model1 loss : 0.501439 model2 loss : 0.215018
[10:28:55.283] iteration 331 : model1 loss : 0.505147 model2 loss : 0.156416
[10:28:55.469] iteration 332 : model1 loss : 0.484291 model2 loss : 0.163279
[10:28:55.665] iteration 333 : model1 loss : 0.494781 model2 loss : 0.167886
[10:28:55.842] iteration 334 : model1 loss : 0.493650 model2 loss : 0.160135
[10:28:56.018] iteration 335 : model1 loss : 0.493438 model2 loss : 0.152441
[10:28:56.183] iteration 336 : model1 loss : 0.493796 model2 loss : 0.155499
[10:28:56.356] iteration 337 : model1 loss : 0.499234 model2 loss : 0.154931
[10:28:56.539] iteration 338 : model1 loss : 0.497786 model2 loss : 0.190938
[10:28:56.723] iteration 339 : model1 loss : 0.482552 model2 loss : 0.113622
[10:28:56.930] iteration 340 : model1 loss : 0.490957 model2 loss : 0.145089
[10:28:57.109] iteration 341 : model1 loss : 0.491141 model2 loss : 0.122917
[10:28:57.282] iteration 342 : model1 loss : 0.484192 model2 loss : 0.127452
[10:28:57.457] iteration 343 : model1 loss : 0.493733 model2 loss : 0.109130
[10:28:57.627] iteration 344 : model1 loss : 0.481044 model2 loss : 0.114485
[10:28:57.795] iteration 345 : model1 loss : 0.484180 model2 loss : 0.196197
[10:28:57.967] iteration 346 : model1 loss : 0.499252 model2 loss : 0.172295
[10:28:58.134] iteration 347 : model1 loss : 0.491309 model2 loss : 0.119202
[10:28:58.320] iteration 348 : model1 loss : 0.502283 model2 loss : 0.099683
[10:28:58.500] iteration 349 : model1 loss : 0.484070 model2 loss : 0.140814
[10:28:58.674] iteration 350 : model1 loss : 0.494213 model2 loss : 0.132503
[10:28:58.854] iteration 351 : model1 loss : 0.498563 model2 loss : 0.204939
[10:28:59.042] iteration 352 : model1 loss : 0.488593 model2 loss : 0.121057
[10:28:59.211] iteration 353 : model1 loss : 0.490340 model2 loss : 0.159359
[10:28:59.395] iteration 354 : model1 loss : 0.493273 model2 loss : 0.150849
[10:28:59.568] iteration 355 : model1 loss : 0.488227 model2 loss : 0.115103
[10:28:59.746] iteration 356 : model1 loss : 0.491622 model2 loss : 0.158389
[10:28:59.930] iteration 357 : model1 loss : 0.486422 model2 loss : 0.164815
[10:29:00.106] iteration 358 : model1 loss : 0.485247 model2 loss : 0.188544
[10:29:00.287] iteration 359 : model1 loss : 0.500391 model2 loss : 0.111047
[10:29:00.469] iteration 360 : model1 loss : 0.488041 model2 loss : 0.162058
[10:29:00.663] iteration 361 : model1 loss : 0.492009 model2 loss : 0.160501
[10:29:00.844] iteration 362 : model1 loss : 0.487940 model2 loss : 0.149830
[10:29:01.018] iteration 363 : model1 loss : 0.486096 model2 loss : 0.138871
[10:29:03.051] iteration 364 : model1 loss : 0.479220 model2 loss : 0.097044
[10:29:03.224] iteration 365 : model1 loss : 0.477490 model2 loss : 0.112928
[10:29:03.397] iteration 366 : model1 loss : 0.488282 model2 loss : 0.159228
[10:29:03.565] iteration 367 : model1 loss : 0.494170 model2 loss : 0.178948
[10:29:03.737] iteration 368 : model1 loss : 0.495636 model2 loss : 0.157219
[10:29:03.908] iteration 369 : model1 loss : 0.490018 model2 loss : 0.130662
[10:29:04.076] iteration 370 : model1 loss : 0.479019 model2 loss : 0.128997
[10:29:04.245] iteration 371 : model1 loss : 0.494322 model2 loss : 0.134472
[10:29:04.421] iteration 372 : model1 loss : 0.504417 model2 loss : 0.128990
[10:29:04.589] iteration 373 : model1 loss : 0.490100 model2 loss : 0.129847
[10:29:04.757] iteration 374 : model1 loss : 0.486194 model2 loss : 0.117067
[10:29:04.927] iteration 375 : model1 loss : 0.485680 model2 loss : 0.125855
[10:29:05.096] iteration 376 : model1 loss : 0.486973 model2 loss : 0.128903
[10:29:05.262] iteration 377 : model1 loss : 0.485790 model2 loss : 0.132933
[10:29:05.449] iteration 378 : model1 loss : 0.492627 model2 loss : 0.157568
[10:29:05.618] iteration 379 : model1 loss : 0.490696 model2 loss : 0.132305
[10:29:05.800] iteration 380 : model1 loss : 0.482258 model2 loss : 0.098479
[10:29:05.981] iteration 381 : model1 loss : 0.495141 model2 loss : 0.151968
[10:29:06.155] iteration 382 : model1 loss : 0.490122 model2 loss : 0.136207
[10:29:06.339] iteration 383 : model1 loss : 0.491612 model2 loss : 0.152949
[10:29:06.520] iteration 384 : model1 loss : 0.479845 model2 loss : 0.137485
[10:29:06.698] iteration 385 : model1 loss : 0.485285 model2 loss : 0.138680
[10:29:06.872] iteration 386 : model1 loss : 0.484793 model2 loss : 0.180461
[10:29:07.044] iteration 387 : model1 loss : 0.498474 model2 loss : 0.124107
[10:29:07.212] iteration 388 : model1 loss : 0.492882 model2 loss : 0.150324
[10:29:07.381] iteration 389 : model1 loss : 0.485947 model2 loss : 0.138898
[10:29:07.556] iteration 390 : model1 loss : 0.479542 model2 loss : 0.118093
[10:29:07.724] iteration 391 : model1 loss : 0.478840 model2 loss : 0.164754
[10:29:07.898] iteration 392 : model1 loss : 0.497320 model2 loss : 0.154837
[10:29:08.070] iteration 393 : model1 loss : 0.487637 model2 loss : 0.131745
[10:29:08.240] iteration 394 : model1 loss : 0.482859 model2 loss : 0.118754
[10:29:08.408] iteration 395 : model1 loss : 0.481421 model2 loss : 0.107547
[10:29:08.592] iteration 396 : model1 loss : 0.478673 model2 loss : 0.085835
[10:29:10.637] iteration 397 : model1 loss : 0.491398 model2 loss : 0.139101
[10:29:10.820] iteration 398 : model1 loss : 0.492989 model2 loss : 0.099911
[10:29:10.995] iteration 399 : model1 loss : 0.500518 model2 loss : 0.143173
[10:29:11.164] iteration 400 : model1 loss : 0.485623 model2 loss : 0.150230
[10:29:11.347] iteration 401 : model1 loss : 0.481097 model2 loss : 0.122077
[10:29:11.525] iteration 402 : model1 loss : 0.489010 model2 loss : 0.166245
[10:29:11.706] iteration 403 : model1 loss : 0.483643 model2 loss : 0.123130
[10:29:11.883] iteration 404 : model1 loss : 0.493636 model2 loss : 0.125556
[10:29:12.059] iteration 405 : model1 loss : 0.478395 model2 loss : 0.136721
[10:29:12.230] iteration 406 : model1 loss : 0.484958 model2 loss : 0.111806
[10:29:12.402] iteration 407 : model1 loss : 0.486536 model2 loss : 0.121882
[10:29:12.575] iteration 408 : model1 loss : 0.484478 model2 loss : 0.147164
[10:29:12.747] iteration 409 : model1 loss : 0.486205 model2 loss : 0.125222
[10:29:12.919] iteration 410 : model1 loss : 0.478052 model2 loss : 0.091440
[10:29:13.094] iteration 411 : model1 loss : 0.480296 model2 loss : 0.132675
[10:29:13.260] iteration 412 : model1 loss : 0.486124 model2 loss : 0.134214
[10:29:13.429] iteration 413 : model1 loss : 0.477299 model2 loss : 0.111858
[10:29:13.606] iteration 414 : model1 loss : 0.485226 model2 loss : 0.119892
[10:29:13.776] iteration 415 : model1 loss : 0.493402 model2 loss : 0.116463
[10:29:13.944] iteration 416 : model1 loss : 0.475882 model2 loss : 0.134359
[10:29:14.118] iteration 417 : model1 loss : 0.483747 model2 loss : 0.105370
[10:29:14.286] iteration 418 : model1 loss : 0.482106 model2 loss : 0.122921
[10:29:14.455] iteration 419 : model1 loss : 0.475847 model2 loss : 0.095945
[10:29:14.631] iteration 420 : model1 loss : 0.494958 model2 loss : 0.116144
[10:29:14.810] iteration 421 : model1 loss : 0.482350 model2 loss : 0.089870
[10:29:14.979] iteration 422 : model1 loss : 0.482600 model2 loss : 0.147905
[10:29:15.159] iteration 423 : model1 loss : 0.480071 model2 loss : 0.130595
[10:29:15.334] iteration 424 : model1 loss : 0.485897 model2 loss : 0.136648
[10:29:15.512] iteration 425 : model1 loss : 0.479335 model2 loss : 0.121246
[10:29:15.695] iteration 426 : model1 loss : 0.498503 model2 loss : 0.117848
[10:29:15.868] iteration 427 : model1 loss : 0.489284 model2 loss : 0.158937
[10:29:16.035] iteration 428 : model1 loss : 0.493263 model2 loss : 0.120974
[10:29:16.208] iteration 429 : model1 loss : 0.483707 model2 loss : 0.170777
[10:29:18.242] iteration 430 : model1 loss : 0.496730 model2 loss : 0.122235
[10:29:18.420] iteration 431 : model1 loss : 0.481355 model2 loss : 0.098578
[10:29:18.597] iteration 432 : model1 loss : 0.491019 model2 loss : 0.118187
[10:29:18.766] iteration 433 : model1 loss : 0.483196 model2 loss : 0.124432
[10:29:18.938] iteration 434 : model1 loss : 0.482814 model2 loss : 0.112152
[10:29:19.110] iteration 435 : model1 loss : 0.489171 model2 loss : 0.132241
[10:29:19.287] iteration 436 : model1 loss : 0.484623 model2 loss : 0.167643
[10:29:19.459] iteration 437 : model1 loss : 0.493892 model2 loss : 0.120705
[10:29:19.644] iteration 438 : model1 loss : 0.484273 model2 loss : 0.083003
[10:29:19.829] iteration 439 : model1 loss : 0.483288 model2 loss : 0.107986
[10:29:20.008] iteration 440 : model1 loss : 0.471033 model2 loss : 0.059810
[10:29:20.188] iteration 441 : model1 loss : 0.481282 model2 loss : 0.098499
[10:29:20.367] iteration 442 : model1 loss : 0.487749 model2 loss : 0.113898
[10:29:20.556] iteration 443 : model1 loss : 0.481009 model2 loss : 0.117847
[10:29:20.742] iteration 444 : model1 loss : 0.475868 model2 loss : 0.093868
[10:29:20.911] iteration 445 : model1 loss : 0.482908 model2 loss : 0.109179
[10:29:21.084] iteration 446 : model1 loss : 0.484123 model2 loss : 0.134016
[10:29:21.265] iteration 447 : model1 loss : 0.484019 model2 loss : 0.120347
[10:29:21.439] iteration 448 : model1 loss : 0.489309 model2 loss : 0.105557
[10:29:21.612] iteration 449 : model1 loss : 0.474551 model2 loss : 0.114389
[10:29:21.785] iteration 450 : model1 loss : 0.485961 model2 loss : 0.093863
[10:29:21.960] iteration 451 : model1 loss : 0.488297 model2 loss : 0.103153
[10:29:22.158] iteration 452 : model1 loss : 0.490933 model2 loss : 0.116600
[10:29:22.341] iteration 453 : model1 loss : 0.485592 model2 loss : 0.096873
[10:29:22.522] iteration 454 : model1 loss : 0.487609 model2 loss : 0.132923
[10:29:22.691] iteration 455 : model1 loss : 0.485491 model2 loss : 0.104933
[10:29:22.866] iteration 456 : model1 loss : 0.473406 model2 loss : 0.080370
[10:29:23.037] iteration 457 : model1 loss : 0.483507 model2 loss : 0.123688
[10:29:23.212] iteration 458 : model1 loss : 0.491772 model2 loss : 0.143612
[10:29:23.390] iteration 459 : model1 loss : 0.486815 model2 loss : 0.170157
[10:29:23.568] iteration 460 : model1 loss : 0.484612 model2 loss : 0.129666
[10:29:23.737] iteration 461 : model1 loss : 0.470816 model2 loss : 0.086190
[10:29:23.907] iteration 462 : model1 loss : 0.492643 model2 loss : 0.109741
[10:29:25.904] iteration 463 : model1 loss : 0.477437 model2 loss : 0.094001
[10:29:26.077] iteration 464 : model1 loss : 0.484939 model2 loss : 0.118237
[10:29:26.254] iteration 465 : model1 loss : 0.480502 model2 loss : 0.073342
[10:29:26.431] iteration 466 : model1 loss : 0.476840 model2 loss : 0.111795
[10:29:26.603] iteration 467 : model1 loss : 0.489952 model2 loss : 0.114713
[10:29:26.796] iteration 468 : model1 loss : 0.484793 model2 loss : 0.094946
[10:29:26.975] iteration 469 : model1 loss : 0.485454 model2 loss : 0.147917
[10:29:27.148] iteration 470 : model1 loss : 0.486247 model2 loss : 0.080637
[10:29:27.322] iteration 471 : model1 loss : 0.475377 model2 loss : 0.145391
[10:29:27.491] iteration 472 : model1 loss : 0.476579 model2 loss : 0.091542
[10:29:27.661] iteration 473 : model1 loss : 0.480749 model2 loss : 0.090065
[10:29:27.834] iteration 474 : model1 loss : 0.479057 model2 loss : 0.096463
[10:29:28.013] iteration 475 : model1 loss : 0.478441 model2 loss : 0.087391
[10:29:28.190] iteration 476 : model1 loss : 0.475308 model2 loss : 0.111774
[10:29:28.362] iteration 477 : model1 loss : 0.477547 model2 loss : 0.119892
[10:29:28.535] iteration 478 : model1 loss : 0.482776 model2 loss : 0.106204
[10:29:28.705] iteration 479 : model1 loss : 0.484414 model2 loss : 0.086785
[10:29:28.873] iteration 480 : model1 loss : 0.475337 model2 loss : 0.128551
[10:29:29.047] iteration 481 : model1 loss : 0.498591 model2 loss : 0.126880
[10:29:29.215] iteration 482 : model1 loss : 0.478584 model2 loss : 0.088740
[10:29:29.387] iteration 483 : model1 loss : 0.482481 model2 loss : 0.163226
[10:29:29.565] iteration 484 : model1 loss : 0.471795 model2 loss : 0.092036
[10:29:29.749] iteration 485 : model1 loss : 0.483545 model2 loss : 0.088961
[10:29:29.921] iteration 486 : model1 loss : 0.474853 model2 loss : 0.087661
[10:29:30.091] iteration 487 : model1 loss : 0.477725 model2 loss : 0.084835
[10:29:30.271] iteration 488 : model1 loss : 0.478081 model2 loss : 0.112147
[10:29:30.447] iteration 489 : model1 loss : 0.479076 model2 loss : 0.074449
[10:29:30.621] iteration 490 : model1 loss : 0.488524 model2 loss : 0.133536
[10:29:30.824] iteration 491 : model1 loss : 0.480970 model2 loss : 0.084370
[10:29:31.005] iteration 492 : model1 loss : 0.470188 model2 loss : 0.173270
[10:29:31.189] iteration 493 : model1 loss : 0.492850 model2 loss : 0.134084
[10:29:31.375] iteration 494 : model1 loss : 0.480207 model2 loss : 0.203684
[10:29:31.550] iteration 495 : model1 loss : 0.483077 model2 loss : 0.156213
[10:29:33.668] iteration 496 : model1 loss : 0.479442 model2 loss : 0.101999
[10:29:33.844] iteration 497 : model1 loss : 0.479970 model2 loss : 0.092767
[10:29:34.017] iteration 498 : model1 loss : 0.480468 model2 loss : 0.097026
[10:29:34.186] iteration 499 : model1 loss : 0.479376 model2 loss : 0.121532
[10:29:34.363] iteration 500 : model1 loss : 0.478392 model2 loss : 0.119661
[10:29:34.533] iteration 501 : model1 loss : 0.479980 model2 loss : 0.081507
[10:29:34.705] iteration 502 : model1 loss : 0.468121 model2 loss : 0.102713
[10:29:34.884] iteration 503 : model1 loss : 0.477613 model2 loss : 0.067262
[10:29:35.070] iteration 504 : model1 loss : 0.484719 model2 loss : 0.109685
[10:29:35.248] iteration 505 : model1 loss : 0.479070 model2 loss : 0.108739
[10:29:35.430] iteration 506 : model1 loss : 0.482937 model2 loss : 0.067632
[10:29:35.615] iteration 507 : model1 loss : 0.476676 model2 loss : 0.088407
[10:29:35.789] iteration 508 : model1 loss : 0.476960 model2 loss : 0.100670
[10:29:35.964] iteration 509 : model1 loss : 0.483236 model2 loss : 0.145740
[10:29:36.138] iteration 510 : model1 loss : 0.483344 model2 loss : 0.122203
[10:29:36.325] iteration 511 : model1 loss : 0.475815 model2 loss : 0.073542
[10:29:36.511] iteration 512 : model1 loss : 0.482405 model2 loss : 0.098918
[10:29:36.691] iteration 513 : model1 loss : 0.480871 model2 loss : 0.096555
[10:29:36.865] iteration 514 : model1 loss : 0.481795 model2 loss : 0.109917
[10:29:37.038] iteration 515 : model1 loss : 0.475814 model2 loss : 0.117428
[10:29:37.227] iteration 516 : model1 loss : 0.479651 model2 loss : 0.080744
[10:29:37.396] iteration 517 : model1 loss : 0.487884 model2 loss : 0.101663
[10:29:37.577] iteration 518 : model1 loss : 0.470381 model2 loss : 0.099374
[10:29:37.749] iteration 519 : model1 loss : 0.470646 model2 loss : 0.102058
[10:29:37.927] iteration 520 : model1 loss : 0.478713 model2 loss : 0.093165
[10:29:38.109] iteration 521 : model1 loss : 0.477338 model2 loss : 0.101751
[10:29:38.291] iteration 522 : model1 loss : 0.476485 model2 loss : 0.118828
[10:29:38.459] iteration 523 : model1 loss : 0.477216 model2 loss : 0.118187
[10:29:38.638] iteration 524 : model1 loss : 0.480785 model2 loss : 0.103858
[10:29:38.821] iteration 525 : model1 loss : 0.483944 model2 loss : 0.107939
[10:29:39.001] iteration 526 : model1 loss : 0.475288 model2 loss : 0.145207
[10:29:39.177] iteration 527 : model1 loss : 0.473415 model2 loss : 0.115681
[10:29:39.354] iteration 528 : model1 loss : 0.476912 model2 loss : 0.118888
[10:29:41.432] iteration 529 : model1 loss : 0.474274 model2 loss : 0.086550
[10:29:41.610] iteration 530 : model1 loss : 0.470134 model2 loss : 0.128918
[10:29:41.788] iteration 531 : model1 loss : 0.487168 model2 loss : 0.092877
[10:29:41.958] iteration 532 : model1 loss : 0.478699 model2 loss : 0.090974
[10:29:42.128] iteration 533 : model1 loss : 0.468195 model2 loss : 0.080969
[10:29:42.303] iteration 534 : model1 loss : 0.488730 model2 loss : 0.104154
[10:29:42.477] iteration 535 : model1 loss : 0.475266 model2 loss : 0.102160
[10:29:42.655] iteration 536 : model1 loss : 0.478218 model2 loss : 0.097141
[10:29:42.834] iteration 537 : model1 loss : 0.480865 model2 loss : 0.154889
[10:29:43.009] iteration 538 : model1 loss : 0.475099 model2 loss : 0.078513
[10:29:43.195] iteration 539 : model1 loss : 0.476973 model2 loss : 0.110522
[10:29:43.370] iteration 540 : model1 loss : 0.474532 model2 loss : 0.090155
[10:29:43.543] iteration 541 : model1 loss : 0.478664 model2 loss : 0.089095
[10:29:43.714] iteration 542 : model1 loss : 0.471859 model2 loss : 0.089819
[10:29:43.895] iteration 543 : model1 loss : 0.473012 model2 loss : 0.112675
[10:29:44.068] iteration 544 : model1 loss : 0.478119 model2 loss : 0.127571
[10:29:44.241] iteration 545 : model1 loss : 0.469560 model2 loss : 0.071898
[10:29:44.416] iteration 546 : model1 loss : 0.479008 model2 loss : 0.080409
[10:29:44.596] iteration 547 : model1 loss : 0.475442 model2 loss : 0.118940
[10:29:44.764] iteration 548 : model1 loss : 0.479918 model2 loss : 0.077836
[10:29:44.936] iteration 549 : model1 loss : 0.469493 model2 loss : 0.077476
[10:29:45.116] iteration 550 : model1 loss : 0.481493 model2 loss : 0.114639
[10:29:45.294] iteration 551 : model1 loss : 0.472389 model2 loss : 0.096688
[10:29:45.472] iteration 552 : model1 loss : 0.477673 model2 loss : 0.061375
[10:29:45.645] iteration 553 : model1 loss : 0.475010 model2 loss : 0.088826
[10:29:45.829] iteration 554 : model1 loss : 0.482307 model2 loss : 0.088480
[10:29:46.009] iteration 555 : model1 loss : 0.479453 model2 loss : 0.077803
[10:29:46.182] iteration 556 : model1 loss : 0.475273 model2 loss : 0.107334
[10:29:46.355] iteration 557 : model1 loss : 0.479453 model2 loss : 0.108590
[10:29:46.540] iteration 558 : model1 loss : 0.472031 model2 loss : 0.118190
[10:29:46.716] iteration 559 : model1 loss : 0.485896 model2 loss : 0.128367
[10:29:46.895] iteration 560 : model1 loss : 0.473008 model2 loss : 0.065417
[10:29:47.090] iteration 561 : model1 loss : 0.472783 model2 loss : 0.096738
[10:29:49.245] iteration 562 : model1 loss : 0.467821 model2 loss : 0.084770
[10:29:49.426] iteration 563 : model1 loss : 0.482688 model2 loss : 0.090100
[10:29:49.611] iteration 564 : model1 loss : 0.476310 model2 loss : 0.098819
[10:29:49.782] iteration 565 : model1 loss : 0.475192 model2 loss : 0.080865
[10:29:49.960] iteration 566 : model1 loss : 0.472636 model2 loss : 0.073688
[10:29:50.129] iteration 567 : model1 loss : 0.481856 model2 loss : 0.106765
[10:29:50.329] iteration 568 : model1 loss : 0.479184 model2 loss : 0.130735
[10:29:50.521] iteration 569 : model1 loss : 0.473177 model2 loss : 0.068900
[10:29:50.704] iteration 570 : model1 loss : 0.475324 model2 loss : 0.150034
[10:29:50.875] iteration 571 : model1 loss : 0.476351 model2 loss : 0.070160
[10:29:51.045] iteration 572 : model1 loss : 0.473671 model2 loss : 0.076653
[10:29:51.213] iteration 573 : model1 loss : 0.467749 model2 loss : 0.065341
[10:29:51.391] iteration 574 : model1 loss : 0.467532 model2 loss : 0.092122
[10:29:51.579] iteration 575 : model1 loss : 0.474152 model2 loss : 0.077443
[10:29:51.767] iteration 576 : model1 loss : 0.474628 model2 loss : 0.084211
[10:29:51.940] iteration 577 : model1 loss : 0.480890 model2 loss : 0.102864
[10:29:52.125] iteration 578 : model1 loss : 0.476131 model2 loss : 0.067525
[10:29:52.311] iteration 579 : model1 loss : 0.474207 model2 loss : 0.111587
[10:29:52.492] iteration 580 : model1 loss : 0.468283 model2 loss : 0.071079
[10:29:52.665] iteration 581 : model1 loss : 0.476160 model2 loss : 0.098708
[10:29:52.836] iteration 582 : model1 loss : 0.469293 model2 loss : 0.066919
[10:29:53.001] iteration 583 : model1 loss : 0.468757 model2 loss : 0.086688
[10:29:53.172] iteration 584 : model1 loss : 0.482763 model2 loss : 0.123095
[10:29:53.354] iteration 585 : model1 loss : 0.470547 model2 loss : 0.082302
[10:29:53.538] iteration 586 : model1 loss : 0.467417 model2 loss : 0.076054
[10:29:53.713] iteration 587 : model1 loss : 0.472441 model2 loss : 0.064654
[10:29:53.885] iteration 588 : model1 loss : 0.477164 model2 loss : 0.088089
[10:29:54.051] iteration 589 : model1 loss : 0.478697 model2 loss : 0.119726
[10:29:54.227] iteration 590 : model1 loss : 0.474974 model2 loss : 0.074648
[10:29:54.397] iteration 591 : model1 loss : 0.477540 model2 loss : 0.139194
[10:29:54.570] iteration 592 : model1 loss : 0.468708 model2 loss : 0.060766
[10:29:54.736] iteration 593 : model1 loss : 0.481798 model2 loss : 0.127898
[10:29:54.913] iteration 594 : model1 loss : 0.471569 model2 loss : 0.069391
[10:29:56.914] iteration 595 : model1 loss : 0.471453 model2 loss : 0.078949
[10:29:57.090] iteration 596 : model1 loss : 0.476328 model2 loss : 0.078383
[10:29:57.276] iteration 597 : model1 loss : 0.470363 model2 loss : 0.087795
[10:29:57.448] iteration 598 : model1 loss : 0.468601 model2 loss : 0.089829
[10:29:57.622] iteration 599 : model1 loss : 0.482002 model2 loss : 0.087611
[10:29:57.796] iteration 600 : model1 loss : 0.477891 model2 loss : 0.084665
[10:29:57.972] iteration 601 : model1 loss : 0.474911 model2 loss : 0.086389
[10:29:58.139] iteration 602 : model1 loss : 0.474693 model2 loss : 0.071164
[10:29:58.320] iteration 603 : model1 loss : 0.468513 model2 loss : 0.087876
[10:29:58.505] iteration 604 : model1 loss : 0.475326 model2 loss : 0.099938
[10:29:58.694] iteration 605 : model1 loss : 0.472709 model2 loss : 0.054081
[10:29:58.876] iteration 606 : model1 loss : 0.473094 model2 loss : 0.103837
[10:29:59.062] iteration 607 : model1 loss : 0.478475 model2 loss : 0.103879
[10:29:59.233] iteration 608 : model1 loss : 0.471801 model2 loss : 0.104493
[10:29:59.424] iteration 609 : model1 loss : 0.471881 model2 loss : 0.085849
[10:29:59.610] iteration 610 : model1 loss : 0.468204 model2 loss : 0.073142
[10:29:59.783] iteration 611 : model1 loss : 0.471375 model2 loss : 0.090200
[10:29:59.967] iteration 612 : model1 loss : 0.470072 model2 loss : 0.059653
[10:30:00.151] iteration 613 : model1 loss : 0.470464 model2 loss : 0.075432
[10:30:00.338] iteration 614 : model1 loss : 0.472139 model2 loss : 0.164779
[10:30:00.526] iteration 615 : model1 loss : 0.479533 model2 loss : 0.068844
[10:30:00.709] iteration 616 : model1 loss : 0.467228 model2 loss : 0.078507
[10:30:00.893] iteration 617 : model1 loss : 0.476364 model2 loss : 0.111539
[10:30:01.067] iteration 618 : model1 loss : 0.470652 model2 loss : 0.126179
[10:30:01.241] iteration 619 : model1 loss : 0.467741 model2 loss : 0.071466
[10:30:01.421] iteration 620 : model1 loss : 0.477392 model2 loss : 0.133247
[10:30:01.597] iteration 621 : model1 loss : 0.476007 model2 loss : 0.118572
[10:30:01.774] iteration 622 : model1 loss : 0.468072 model2 loss : 0.095063
[10:30:01.961] iteration 623 : model1 loss : 0.481089 model2 loss : 0.083793
[10:30:02.152] iteration 624 : model1 loss : 0.475889 model2 loss : 0.067028
[10:30:02.337] iteration 625 : model1 loss : 0.465239 model2 loss : 0.089471
[10:30:02.517] iteration 626 : model1 loss : 0.470836 model2 loss : 0.102636
[10:30:02.696] iteration 627 : model1 loss : 0.473578 model2 loss : 0.080630
[10:30:04.857] iteration 628 : model1 loss : 0.485849 model2 loss : 0.100482
[10:30:05.034] iteration 629 : model1 loss : 0.464727 model2 loss : 0.056261
[10:30:05.210] iteration 630 : model1 loss : 0.468857 model2 loss : 0.065490
[10:30:05.381] iteration 631 : model1 loss : 0.479216 model2 loss : 0.089577
[10:30:05.579] iteration 632 : model1 loss : 0.472484 model2 loss : 0.074076
[10:30:05.770] iteration 633 : model1 loss : 0.466818 model2 loss : 0.070923
[10:30:05.970] iteration 634 : model1 loss : 0.469183 model2 loss : 0.136338
[10:30:06.181] iteration 635 : model1 loss : 0.476917 model2 loss : 0.088643
[10:30:06.359] iteration 636 : model1 loss : 0.470165 model2 loss : 0.065782
[10:30:06.536] iteration 637 : model1 loss : 0.474159 model2 loss : 0.069067
[10:30:06.714] iteration 638 : model1 loss : 0.474904 model2 loss : 0.111633
[10:30:06.904] iteration 639 : model1 loss : 0.466537 model2 loss : 0.066639
[10:30:07.097] iteration 640 : model1 loss : 0.467821 model2 loss : 0.073501
[10:30:07.278] iteration 641 : model1 loss : 0.472988 model2 loss : 0.111069
[10:30:07.447] iteration 642 : model1 loss : 0.474900 model2 loss : 0.099438
[10:30:07.646] iteration 643 : model1 loss : 0.468776 model2 loss : 0.068813
[10:30:07.819] iteration 644 : model1 loss : 0.469807 model2 loss : 0.064988
[10:30:08.011] iteration 645 : model1 loss : 0.470567 model2 loss : 0.076741
[10:30:08.186] iteration 646 : model1 loss : 0.469763 model2 loss : 0.089403
[10:30:08.364] iteration 647 : model1 loss : 0.472110 model2 loss : 0.070461
[10:30:08.560] iteration 648 : model1 loss : 0.474474 model2 loss : 0.082794
[10:30:08.732] iteration 649 : model1 loss : 0.473190 model2 loss : 0.065972
[10:30:08.907] iteration 650 : model1 loss : 0.468413 model2 loss : 0.077554
[10:30:09.077] iteration 651 : model1 loss : 0.468707 model2 loss : 0.128082
[10:30:09.246] iteration 652 : model1 loss : 0.481577 model2 loss : 0.111694
[10:30:09.420] iteration 653 : model1 loss : 0.478253 model2 loss : 0.082105
[10:30:09.588] iteration 654 : model1 loss : 0.473398 model2 loss : 0.097146
[10:30:09.760] iteration 655 : model1 loss : 0.477984 model2 loss : 0.110433
[10:30:09.930] iteration 656 : model1 loss : 0.471558 model2 loss : 0.107276
[10:30:10.099] iteration 657 : model1 loss : 0.462167 model2 loss : 0.064628
[10:30:10.277] iteration 658 : model1 loss : 0.467831 model2 loss : 0.072038
[10:30:10.450] iteration 659 : model1 loss : 0.472269 model2 loss : 0.084941
[10:30:10.619] iteration 660 : model1 loss : 0.470434 model2 loss : 0.078326
[10:30:13.008] iteration 661 : model1 loss : 0.469819 model2 loss : 0.071057
[10:30:13.195] iteration 662 : model1 loss : 0.469687 model2 loss : 0.060881
[10:30:13.374] iteration 663 : model1 loss : 0.467352 model2 loss : 0.069039
[10:30:13.544] iteration 664 : model1 loss : 0.468487 model2 loss : 0.074071
[10:30:13.719] iteration 665 : model1 loss : 0.473492 model2 loss : 0.067056
[10:30:13.890] iteration 666 : model1 loss : 0.473262 model2 loss : 0.097705
[10:30:14.062] iteration 667 : model1 loss : 0.479096 model2 loss : 0.124410
[10:30:14.231] iteration 668 : model1 loss : 0.467048 model2 loss : 0.063036
[10:30:14.406] iteration 669 : model1 loss : 0.465959 model2 loss : 0.103699
[10:30:14.575] iteration 670 : model1 loss : 0.481324 model2 loss : 0.098447
[10:30:14.748] iteration 671 : model1 loss : 0.462791 model2 loss : 0.052319
[10:30:14.917] iteration 672 : model1 loss : 0.476222 model2 loss : 0.069751
[10:30:15.090] iteration 673 : model1 loss : 0.467925 model2 loss : 0.050946
[10:30:15.259] iteration 674 : model1 loss : 0.475876 model2 loss : 0.107481
[10:30:15.433] iteration 675 : model1 loss : 0.474068 model2 loss : 0.084417
[10:30:15.602] iteration 676 : model1 loss : 0.465194 model2 loss : 0.063024
[10:30:15.776] iteration 677 : model1 loss : 0.464490 model2 loss : 0.170860
[10:30:15.944] iteration 678 : model1 loss : 0.463749 model2 loss : 0.057590
[10:30:16.116] iteration 679 : model1 loss : 0.473419 model2 loss : 0.065363
[10:30:16.286] iteration 680 : model1 loss : 0.468829 model2 loss : 0.066755
[10:30:16.460] iteration 681 : model1 loss : 0.487189 model2 loss : 0.104665
[10:30:16.630] iteration 682 : model1 loss : 0.468647 model2 loss : 0.081735
[10:30:16.802] iteration 683 : model1 loss : 0.471021 model2 loss : 0.094733
[10:30:16.969] iteration 684 : model1 loss : 0.469588 model2 loss : 0.095795
[10:30:17.144] iteration 685 : model1 loss : 0.470294 model2 loss : 0.073988
[10:30:17.313] iteration 686 : model1 loss : 0.472762 model2 loss : 0.075057
[10:30:17.486] iteration 687 : model1 loss : 0.461561 model2 loss : 0.065707
[10:30:17.657] iteration 688 : model1 loss : 0.468479 model2 loss : 0.059208
[10:30:17.829] iteration 689 : model1 loss : 0.463760 model2 loss : 0.066966
[10:30:17.998] iteration 690 : model1 loss : 0.467600 model2 loss : 0.074268
[10:30:18.171] iteration 691 : model1 loss : 0.481510 model2 loss : 0.105748
[10:30:18.341] iteration 692 : model1 loss : 0.469555 model2 loss : 0.110182
[10:30:18.519] iteration 693 : model1 loss : 0.475078 model2 loss : 0.082728
[10:30:20.532] iteration 694 : model1 loss : 0.475245 model2 loss : 0.082967
[10:30:20.705] iteration 695 : model1 loss : 0.463311 model2 loss : 0.072689
[10:30:20.881] iteration 696 : model1 loss : 0.463005 model2 loss : 0.067431
[10:30:21.052] iteration 697 : model1 loss : 0.464819 model2 loss : 0.075381
[10:30:21.227] iteration 698 : model1 loss : 0.474134 model2 loss : 0.070273
[10:30:21.396] iteration 699 : model1 loss : 0.479204 model2 loss : 0.081434
[10:30:21.572] iteration 700 : model1 loss : 0.471033 model2 loss : 0.055912
[10:30:21.743] iteration 701 : model1 loss : 0.469474 model2 loss : 0.062699
[10:30:21.918] iteration 702 : model1 loss : 0.470276 model2 loss : 0.083936
[10:30:22.085] iteration 703 : model1 loss : 0.465440 model2 loss : 0.049646
[10:30:22.258] iteration 704 : model1 loss : 0.481224 model2 loss : 0.140365
[10:30:22.429] iteration 705 : model1 loss : 0.463235 model2 loss : 0.052068
[10:30:22.605] iteration 706 : model1 loss : 0.471615 model2 loss : 0.087119
[10:30:22.776] iteration 707 : model1 loss : 0.474000 model2 loss : 0.092405
[10:30:22.948] iteration 708 : model1 loss : 0.463191 model2 loss : 0.056106
[10:30:23.122] iteration 709 : model1 loss : 0.466573 model2 loss : 0.058005
[10:30:23.294] iteration 710 : model1 loss : 0.470891 model2 loss : 0.095203
[10:30:23.466] iteration 711 : model1 loss : 0.474226 model2 loss : 0.084099
[10:30:23.644] iteration 712 : model1 loss : 0.459705 model2 loss : 0.071458
[10:30:23.818] iteration 713 : model1 loss : 0.465931 model2 loss : 0.060421
[10:30:23.991] iteration 714 : model1 loss : 0.461639 model2 loss : 0.071541
[10:30:24.182] iteration 715 : model1 loss : 0.482603 model2 loss : 0.127658
[10:30:24.373] iteration 716 : model1 loss : 0.480189 model2 loss : 0.067915
[10:30:24.617] iteration 717 : model1 loss : 0.464444 model2 loss : 0.057799
[10:30:24.825] iteration 718 : model1 loss : 0.468165 model2 loss : 0.068297
[10:30:25.042] iteration 719 : model1 loss : 0.466462 model2 loss : 0.091269
[10:30:25.281] iteration 720 : model1 loss : 0.472705 model2 loss : 0.097092
[10:30:25.505] iteration 721 : model1 loss : 0.461361 model2 loss : 0.046651
[10:30:25.728] iteration 722 : model1 loss : 0.470551 model2 loss : 0.082272
[10:30:25.944] iteration 723 : model1 loss : 0.464226 model2 loss : 0.070047
[10:30:26.136] iteration 724 : model1 loss : 0.465034 model2 loss : 0.062537
[10:30:26.328] iteration 725 : model1 loss : 0.468746 model2 loss : 0.074220
[10:30:26.521] iteration 726 : model1 loss : 0.468196 model2 loss : 0.086735
[10:30:28.806] iteration 727 : model1 loss : 0.467865 model2 loss : 0.085577
[10:30:28.981] iteration 728 : model1 loss : 0.471449 model2 loss : 0.083342
[10:30:29.163] iteration 729 : model1 loss : 0.470362 model2 loss : 0.075199
[10:30:29.335] iteration 730 : model1 loss : 0.472925 model2 loss : 0.090469
[10:30:29.513] iteration 731 : model1 loss : 0.464676 model2 loss : 0.072507
[10:30:29.692] iteration 732 : model1 loss : 0.463457 model2 loss : 0.055583
[10:30:29.867] iteration 733 : model1 loss : 0.467072 model2 loss : 0.047369
[10:30:30.041] iteration 734 : model1 loss : 0.476818 model2 loss : 0.113563
[10:30:30.215] iteration 735 : model1 loss : 0.466067 model2 loss : 0.078029
[10:30:30.387] iteration 736 : model1 loss : 0.465888 model2 loss : 0.061298
[10:30:30.565] iteration 737 : model1 loss : 0.468755 model2 loss : 0.056830
[10:30:30.734] iteration 738 : model1 loss : 0.467666 model2 loss : 0.052114
[10:30:30.912] iteration 739 : model1 loss : 0.468528 model2 loss : 0.073370
[10:30:31.080] iteration 740 : model1 loss : 0.466974 model2 loss : 0.059789
[10:30:31.254] iteration 741 : model1 loss : 0.469661 model2 loss : 0.053622
[10:30:31.426] iteration 742 : model1 loss : 0.463010 model2 loss : 0.073552
[10:30:31.600] iteration 743 : model1 loss : 0.473892 model2 loss : 0.080291
[10:30:31.770] iteration 744 : model1 loss : 0.462976 model2 loss : 0.056395
[10:30:31.942] iteration 745 : model1 loss : 0.465234 model2 loss : 0.071131
[10:30:32.110] iteration 746 : model1 loss : 0.470626 model2 loss : 0.088633
[10:30:32.282] iteration 747 : model1 loss : 0.465841 model2 loss : 0.058367
[10:30:32.456] iteration 748 : model1 loss : 0.472259 model2 loss : 0.079354
[10:30:32.634] iteration 749 : model1 loss : 0.470682 model2 loss : 0.115394
[10:30:32.807] iteration 750 : model1 loss : 0.476337 model2 loss : 0.128464
[10:30:32.984] iteration 751 : model1 loss : 0.481777 model2 loss : 0.113012
[10:30:33.168] iteration 752 : model1 loss : 0.462423 model2 loss : 0.061145
[10:30:33.353] iteration 753 : model1 loss : 0.467385 model2 loss : 0.079561
[10:30:33.530] iteration 754 : model1 loss : 0.470618 model2 loss : 0.096738
[10:30:33.703] iteration 755 : model1 loss : 0.468779 model2 loss : 0.095650
[10:30:33.870] iteration 756 : model1 loss : 0.468735 model2 loss : 0.059802
[10:30:34.052] iteration 757 : model1 loss : 0.471120 model2 loss : 0.092898
[10:30:34.218] iteration 758 : model1 loss : 0.470001 model2 loss : 0.084216
[10:30:34.396] iteration 759 : model1 loss : 0.464626 model2 loss : 0.064749
[10:30:36.509] iteration 760 : model1 loss : 0.466264 model2 loss : 0.059373
[10:30:36.722] iteration 761 : model1 loss : 0.475381 model2 loss : 0.082098
[10:30:36.927] iteration 762 : model1 loss : 0.466536 model2 loss : 0.084208
[10:30:37.106] iteration 763 : model1 loss : 0.461320 model2 loss : 0.059131
[10:30:37.279] iteration 764 : model1 loss : 0.464967 model2 loss : 0.080672
[10:30:37.449] iteration 765 : model1 loss : 0.469149 model2 loss : 0.057449
[10:30:37.621] iteration 766 : model1 loss : 0.463376 model2 loss : 0.086038
[10:30:37.792] iteration 767 : model1 loss : 0.462020 model2 loss : 0.047094
[10:30:37.968] iteration 768 : model1 loss : 0.465953 model2 loss : 0.075174
[10:30:38.136] iteration 769 : model1 loss : 0.467272 model2 loss : 0.082668
[10:30:38.307] iteration 770 : model1 loss : 0.463542 model2 loss : 0.070376
[10:30:38.479] iteration 771 : model1 loss : 0.465002 model2 loss : 0.074294
[10:30:38.655] iteration 772 : model1 loss : 0.473363 model2 loss : 0.102671
[10:30:38.825] iteration 773 : model1 loss : 0.465236 model2 loss : 0.057482
[10:30:38.998] iteration 774 : model1 loss : 0.464192 model2 loss : 0.053861
[10:30:39.166] iteration 775 : model1 loss : 0.471031 model2 loss : 0.113306
[10:30:39.342] iteration 776 : model1 loss : 0.460125 model2 loss : 0.072175
[10:30:39.518] iteration 777 : model1 loss : 0.466028 model2 loss : 0.089763
[10:30:39.691] iteration 778 : model1 loss : 0.459456 model2 loss : 0.057328
[10:30:39.875] iteration 779 : model1 loss : 0.463863 model2 loss : 0.069773
[10:30:40.048] iteration 780 : model1 loss : 0.467062 model2 loss : 0.080644
[10:30:40.217] iteration 781 : model1 loss : 0.469809 model2 loss : 0.070092
[10:30:40.391] iteration 782 : model1 loss : 0.465162 model2 loss : 0.056106
[10:30:40.560] iteration 783 : model1 loss : 0.465326 model2 loss : 0.080998
[10:30:40.731] iteration 784 : model1 loss : 0.481042 model2 loss : 0.114516
[10:30:40.903] iteration 785 : model1 loss : 0.468903 model2 loss : 0.054824
[10:30:41.076] iteration 786 : model1 loss : 0.473791 model2 loss : 0.092892
[10:30:41.247] iteration 787 : model1 loss : 0.474628 model2 loss : 0.109963
[10:30:41.421] iteration 788 : model1 loss : 0.461071 model2 loss : 0.063539
[10:30:41.591] iteration 789 : model1 loss : 0.458933 model2 loss : 0.062804
[10:30:41.790] iteration 790 : model1 loss : 0.483906 model2 loss : 0.121075
[10:30:41.991] iteration 791 : model1 loss : 0.467115 model2 loss : 0.089268
[10:30:42.191] iteration 792 : model1 loss : 0.474797 model2 loss : 0.078775
[10:30:44.341] iteration 793 : model1 loss : 0.472283 model2 loss : 0.120414
[10:30:44.524] iteration 794 : model1 loss : 0.478617 model2 loss : 0.099504
[10:30:44.695] iteration 795 : model1 loss : 0.462447 model2 loss : 0.050674
[10:30:44.866] iteration 796 : model1 loss : 0.464536 model2 loss : 0.072847
[10:30:45.039] iteration 797 : model1 loss : 0.467998 model2 loss : 0.077312
[10:30:45.229] iteration 798 : model1 loss : 0.459841 model2 loss : 0.067518
[10:30:45.404] iteration 799 : model1 loss : 0.473971 model2 loss : 0.109755
[10:30:45.575] iteration 800 : model1 loss : 0.460489 model2 loss : 0.074377
[10:30:45.747] iteration 801 : model1 loss : 0.464742 model2 loss : 0.068965
[10:30:45.962] iteration 802 : model1 loss : 0.464412 model2 loss : 0.070226
[10:30:46.174] iteration 803 : model1 loss : 0.459750 model2 loss : 0.056279
[10:30:46.365] iteration 804 : model1 loss : 0.462541 model2 loss : 0.058622
[10:30:46.588] iteration 805 : model1 loss : 0.462374 model2 loss : 0.057076
[10:30:46.793] iteration 806 : model1 loss : 0.467382 model2 loss : 0.080989
[10:30:47.007] iteration 807 : model1 loss : 0.460881 model2 loss : 0.055945
[10:30:47.238] iteration 808 : model1 loss : 0.459379 model2 loss : 0.056171
[10:30:47.426] iteration 809 : model1 loss : 0.463825 model2 loss : 0.061163
[10:30:47.601] iteration 810 : model1 loss : 0.472103 model2 loss : 0.064506
[10:30:47.798] iteration 811 : model1 loss : 0.471953 model2 loss : 0.081605
[10:30:47.998] iteration 812 : model1 loss : 0.460895 model2 loss : 0.054120
[10:30:48.170] iteration 813 : model1 loss : 0.466984 model2 loss : 0.079752
[10:30:48.369] iteration 814 : model1 loss : 0.468764 model2 loss : 0.095476
[10:30:48.581] iteration 815 : model1 loss : 0.469198 model2 loss : 0.069915
[10:30:48.814] iteration 816 : model1 loss : 0.460171 model2 loss : 0.073401
[10:30:49.015] iteration 817 : model1 loss : 0.464633 model2 loss : 0.072958
[10:30:49.186] iteration 818 : model1 loss : 0.462772 model2 loss : 0.054361
[10:30:49.356] iteration 819 : model1 loss : 0.458896 model2 loss : 0.048097
[10:30:49.532] iteration 820 : model1 loss : 0.471241 model2 loss : 0.083945
[10:30:49.709] iteration 821 : model1 loss : 0.469269 model2 loss : 0.118040
[10:30:49.883] iteration 822 : model1 loss : 0.464554 model2 loss : 0.064033
[10:30:50.060] iteration 823 : model1 loss : 0.459434 model2 loss : 0.058569
[10:30:50.250] iteration 824 : model1 loss : 0.460099 model2 loss : 0.088773
[10:30:50.454] iteration 825 : model1 loss : 0.466755 model2 loss : 0.076647
[10:30:52.578] iteration 826 : model1 loss : 0.469353 model2 loss : 0.082198
[10:30:52.836] iteration 827 : model1 loss : 0.464051 model2 loss : 0.065418
[10:30:53.020] iteration 828 : model1 loss : 0.468035 model2 loss : 0.078782
[10:30:53.197] iteration 829 : model1 loss : 0.473023 model2 loss : 0.098094
[10:30:53.368] iteration 830 : model1 loss : 0.471934 model2 loss : 0.084982
[10:30:53.550] iteration 831 : model1 loss : 0.452881 model2 loss : 0.049418
[10:30:53.721] iteration 832 : model1 loss : 0.463179 model2 loss : 0.084149
[10:30:53.894] iteration 833 : model1 loss : 0.459347 model2 loss : 0.062232
[10:30:54.065] iteration 834 : model1 loss : 0.465660 model2 loss : 0.056727
[10:30:54.236] iteration 835 : model1 loss : 0.466666 model2 loss : 0.089579
[10:30:54.445] iteration 836 : model1 loss : 0.469900 model2 loss : 0.116615
[10:30:54.691] iteration 837 : model1 loss : 0.466277 model2 loss : 0.073232
[10:30:54.889] iteration 838 : model1 loss : 0.460781 model2 loss : 0.067475
[10:30:55.062] iteration 839 : model1 loss : 0.460305 model2 loss : 0.066162
[10:30:55.230] iteration 840 : model1 loss : 0.462501 model2 loss : 0.074397
[10:30:55.409] iteration 841 : model1 loss : 0.470301 model2 loss : 0.085378
[10:30:55.579] iteration 842 : model1 loss : 0.457447 model2 loss : 0.052728
[10:30:55.797] iteration 843 : model1 loss : 0.457442 model2 loss : 0.077299
[10:30:56.003] iteration 844 : model1 loss : 0.466086 model2 loss : 0.062774
[10:30:56.226] iteration 845 : model1 loss : 0.461339 model2 loss : 0.075450
[10:30:56.440] iteration 846 : model1 loss : 0.461303 model2 loss : 0.082898
[10:30:56.679] iteration 847 : model1 loss : 0.453724 model2 loss : 0.057644
[10:30:56.888] iteration 848 : model1 loss : 0.467630 model2 loss : 0.065188
[10:30:57.059] iteration 849 : model1 loss : 0.468581 model2 loss : 0.097391
[10:30:57.232] iteration 850 : model1 loss : 0.459211 model2 loss : 0.089557
[10:30:57.413] iteration 851 : model1 loss : 0.466909 model2 loss : 0.056142
[10:30:57.591] iteration 852 : model1 loss : 0.463823 model2 loss : 0.073896
[10:30:57.772] iteration 853 : model1 loss : 0.454965 model2 loss : 0.052545
[10:30:57.990] iteration 854 : model1 loss : 0.458350 model2 loss : 0.062205
[10:30:58.174] iteration 855 : model1 loss : 0.458118 model2 loss : 0.050447
[10:30:58.400] iteration 856 : model1 loss : 0.459412 model2 loss : 0.058882
[10:30:58.605] iteration 857 : model1 loss : 0.467751 model2 loss : 0.080103
[10:30:58.841] iteration 858 : model1 loss : 0.460940 model2 loss : 0.074410
[10:31:01.103] iteration 859 : model1 loss : 0.460631 model2 loss : 0.077507
[10:31:01.277] iteration 860 : model1 loss : 0.459181 model2 loss : 0.075427
[10:31:01.456] iteration 861 : model1 loss : 0.471521 model2 loss : 0.090984
[10:31:01.628] iteration 862 : model1 loss : 0.456084 model2 loss : 0.052797
[10:31:01.800] iteration 863 : model1 loss : 0.458927 model2 loss : 0.052417
[10:31:01.972] iteration 864 : model1 loss : 0.464758 model2 loss : 0.085216
[10:31:02.149] iteration 865 : model1 loss : 0.455540 model2 loss : 0.064291
[10:31:02.319] iteration 866 : model1 loss : 0.466880 model2 loss : 0.082500
[10:31:02.492] iteration 867 : model1 loss : 0.460319 model2 loss : 0.061389
[10:31:02.662] iteration 868 : model1 loss : 0.462379 model2 loss : 0.090519
[10:31:02.833] iteration 869 : model1 loss : 0.457640 model2 loss : 0.046445
[10:31:03.049] iteration 870 : model1 loss : 0.462247 model2 loss : 0.089794
[10:31:03.283] iteration 871 : model1 loss : 0.462130 model2 loss : 0.085564
[10:31:03.470] iteration 872 : model1 loss : 0.465574 model2 loss : 0.083821
[10:31:03.643] iteration 873 : model1 loss : 0.468313 model2 loss : 0.078088
[10:31:03.813] iteration 874 : model1 loss : 0.458523 model2 loss : 0.065050
[10:31:03.983] iteration 875 : model1 loss : 0.473117 model2 loss : 0.076887
[10:31:04.153] iteration 876 : model1 loss : 0.460736 model2 loss : 0.066343
[10:31:04.323] iteration 877 : model1 loss : 0.455013 model2 loss : 0.072846
[10:31:04.495] iteration 878 : model1 loss : 0.467536 model2 loss : 0.099461
[10:31:04.672] iteration 879 : model1 loss : 0.466065 model2 loss : 0.056838
[10:31:04.851] iteration 880 : model1 loss : 0.464422 model2 loss : 0.080471
[10:31:05.047] iteration 881 : model1 loss : 0.454318 model2 loss : 0.058279
[10:31:05.228] iteration 882 : model1 loss : 0.475092 model2 loss : 0.076428
[10:31:05.428] iteration 883 : model1 loss : 0.452458 model2 loss : 0.059431
[10:31:05.641] iteration 884 : model1 loss : 0.453529 model2 loss : 0.050301
[10:31:05.865] iteration 885 : model1 loss : 0.458603 model2 loss : 0.066896
[10:31:06.036] iteration 886 : model1 loss : 0.468723 model2 loss : 0.091232
[10:31:06.231] iteration 887 : model1 loss : 0.454305 model2 loss : 0.060045
[10:31:06.441] iteration 888 : model1 loss : 0.465607 model2 loss : 0.094547
[10:31:06.673] iteration 889 : model1 loss : 0.461986 model2 loss : 0.062264
[10:31:06.841] iteration 890 : model1 loss : 0.471769 model2 loss : 0.066828
[10:31:07.023] iteration 891 : model1 loss : 0.457134 model2 loss : 0.061173
[10:31:09.065] iteration 892 : model1 loss : 0.450775 model2 loss : 0.046864
[10:31:09.239] iteration 893 : model1 loss : 0.469222 model2 loss : 0.075122
[10:31:09.418] iteration 894 : model1 loss : 0.453341 model2 loss : 0.048548
[10:31:09.588] iteration 895 : model1 loss : 0.466001 model2 loss : 0.077364
[10:31:09.764] iteration 896 : model1 loss : 0.454071 model2 loss : 0.059457
[10:31:09.934] iteration 897 : model1 loss : 0.469763 model2 loss : 0.080227
[10:31:10.105] iteration 898 : model1 loss : 0.465831 model2 loss : 0.059391
[10:31:10.281] iteration 899 : model1 loss : 0.453913 model2 loss : 0.058374
[10:31:10.458] iteration 900 : model1 loss : 0.456991 model2 loss : 0.057909
[10:31:10.628] iteration 901 : model1 loss : 0.460554 model2 loss : 0.069689
[10:31:10.805] iteration 902 : model1 loss : 0.471651 model2 loss : 0.083175
[10:31:11.038] iteration 903 : model1 loss : 0.459107 model2 loss : 0.062700
[10:31:11.251] iteration 904 : model1 loss : 0.467887 model2 loss : 0.076957
[10:31:11.425] iteration 905 : model1 loss : 0.459916 model2 loss : 0.098752
[10:31:11.598] iteration 906 : model1 loss : 0.470976 model2 loss : 0.072291
[10:31:11.840] iteration 907 : model1 loss : 0.455942 model2 loss : 0.075412
[10:31:12.027] iteration 908 : model1 loss : 0.446852 model2 loss : 0.049631
[10:31:12.266] iteration 909 : model1 loss : 0.459962 model2 loss : 0.081526
[10:31:12.453] iteration 910 : model1 loss : 0.457915 model2 loss : 0.051736
[10:31:12.626] iteration 911 : model1 loss : 0.461359 model2 loss : 0.057316
[10:31:12.830] iteration 912 : model1 loss : 0.466471 model2 loss : 0.097136
[10:31:13.066] iteration 913 : model1 loss : 0.455894 model2 loss : 0.089721
[10:31:13.236] iteration 914 : model1 loss : 0.462152 model2 loss : 0.078440
[10:31:13.412] iteration 915 : model1 loss : 0.459539 model2 loss : 0.066175
[10:31:13.581] iteration 916 : model1 loss : 0.453576 model2 loss : 0.081615
[10:31:13.753] iteration 917 : model1 loss : 0.454983 model2 loss : 0.072215
[10:31:13.920] iteration 918 : model1 loss : 0.463255 model2 loss : 0.095706
[10:31:14.091] iteration 919 : model1 loss : 0.453817 model2 loss : 0.059880
[10:31:14.306] iteration 920 : model1 loss : 0.467277 model2 loss : 0.061648
[10:31:14.498] iteration 921 : model1 loss : 0.466323 model2 loss : 0.092172
[10:31:14.672] iteration 922 : model1 loss : 0.463506 model2 loss : 0.084125
[10:31:14.840] iteration 923 : model1 loss : 0.458022 model2 loss : 0.068549
[10:31:15.010] iteration 924 : model1 loss : 0.467895 model2 loss : 0.093342
[10:31:17.124] iteration 925 : model1 loss : 0.453770 model2 loss : 0.054079
[10:31:17.315] iteration 926 : model1 loss : 0.459248 model2 loss : 0.065536
[10:31:17.507] iteration 927 : model1 loss : 0.464618 model2 loss : 0.084920
[10:31:17.686] iteration 928 : model1 loss : 0.461118 model2 loss : 0.074199
[10:31:17.862] iteration 929 : model1 loss : 0.466964 model2 loss : 0.060311
[10:31:18.034] iteration 930 : model1 loss : 0.462899 model2 loss : 0.087535
[10:31:18.211] iteration 931 : model1 loss : 0.458373 model2 loss : 0.056854
[10:31:18.389] iteration 932 : model1 loss : 0.461409 model2 loss : 0.097924
[10:31:18.571] iteration 933 : model1 loss : 0.460527 model2 loss : 0.106432
[10:31:18.759] iteration 934 : model1 loss : 0.456507 model2 loss : 0.064123
[10:31:18.935] iteration 935 : model1 loss : 0.459806 model2 loss : 0.054690
[10:31:19.103] iteration 936 : model1 loss : 0.470962 model2 loss : 0.079765
[10:31:19.280] iteration 937 : model1 loss : 0.454027 model2 loss : 0.066732
[10:31:19.459] iteration 938 : model1 loss : 0.455434 model2 loss : 0.065222
[10:31:19.634] iteration 939 : model1 loss : 0.471200 model2 loss : 0.094460
[10:31:19.803] iteration 940 : model1 loss : 0.452748 model2 loss : 0.056057
[10:31:19.972] iteration 941 : model1 loss : 0.473650 model2 loss : 0.089827
[10:31:20.145] iteration 942 : model1 loss : 0.456355 model2 loss : 0.053670
[10:31:20.321] iteration 943 : model1 loss : 0.452048 model2 loss : 0.049615
[10:31:20.489] iteration 944 : model1 loss : 0.468863 model2 loss : 0.119437
[10:31:20.660] iteration 945 : model1 loss : 0.446913 model2 loss : 0.048756
[10:31:20.833] iteration 946 : model1 loss : 0.457494 model2 loss : 0.063045
[10:31:21.003] iteration 947 : model1 loss : 0.454952 model2 loss : 0.050813
[10:31:21.173] iteration 948 : model1 loss : 0.456660 model2 loss : 0.044825
[10:31:21.375] iteration 949 : model1 loss : 0.461819 model2 loss : 0.070613
[10:31:21.571] iteration 950 : model1 loss : 0.461047 model2 loss : 0.066847
[10:31:21.750] iteration 951 : model1 loss : 0.449753 model2 loss : 0.054444
[10:31:21.931] iteration 952 : model1 loss : 0.465623 model2 loss : 0.072547
[10:31:22.120] iteration 953 : model1 loss : 0.458439 model2 loss : 0.074848
[10:31:22.332] iteration 954 : model1 loss : 0.447592 model2 loss : 0.051759
[10:31:22.536] iteration 955 : model1 loss : 0.463202 model2 loss : 0.088475
[10:31:22.717] iteration 956 : model1 loss : 0.452765 model2 loss : 0.061899
[10:31:22.891] iteration 957 : model1 loss : 0.469342 model2 loss : 0.117724
[10:31:25.017] iteration 958 : model1 loss : 0.467544 model2 loss : 0.082722
[10:31:25.198] iteration 959 : model1 loss : 0.466159 model2 loss : 0.093820
[10:31:25.398] iteration 960 : model1 loss : 0.460778 model2 loss : 0.062874
[10:31:25.573] iteration 961 : model1 loss : 0.451023 model2 loss : 0.062548
[10:31:25.771] iteration 962 : model1 loss : 0.464280 model2 loss : 0.077677
[10:31:25.950] iteration 963 : model1 loss : 0.465685 model2 loss : 0.065086
[10:31:26.132] iteration 964 : model1 loss : 0.463500 model2 loss : 0.066237
[10:31:26.322] iteration 965 : model1 loss : 0.462585 model2 loss : 0.076777
[10:31:26.498] iteration 966 : model1 loss : 0.456181 model2 loss : 0.066469
[10:31:26.682] iteration 967 : model1 loss : 0.451609 model2 loss : 0.053720
[10:31:26.870] iteration 968 : model1 loss : 0.462396 model2 loss : 0.080763
[10:31:27.038] iteration 969 : model1 loss : 0.458010 model2 loss : 0.065820
[10:31:27.228] iteration 970 : model1 loss : 0.455104 model2 loss : 0.053182
[10:31:27.415] iteration 971 : model1 loss : 0.461005 model2 loss : 0.090511
[10:31:27.590] iteration 972 : model1 loss : 0.458969 model2 loss : 0.067550
[10:31:27.771] iteration 973 : model1 loss : 0.461332 model2 loss : 0.069124
[10:31:27.952] iteration 974 : model1 loss : 0.475132 model2 loss : 0.081744
[10:31:28.119] iteration 975 : model1 loss : 0.455121 model2 loss : 0.059308
[10:31:28.290] iteration 976 : model1 loss : 0.463492 model2 loss : 0.070720
[10:31:28.466] iteration 977 : model1 loss : 0.458437 model2 loss : 0.061771
[10:31:28.639] iteration 978 : model1 loss : 0.456316 model2 loss : 0.083621
[10:31:28.807] iteration 979 : model1 loss : 0.459939 model2 loss : 0.048255
[10:31:28.979] iteration 980 : model1 loss : 0.458200 model2 loss : 0.071433
[10:31:29.146] iteration 981 : model1 loss : 0.461111 model2 loss : 0.115027
[10:31:29.318] iteration 982 : model1 loss : 0.451918 model2 loss : 0.077921
[10:31:29.489] iteration 983 : model1 loss : 0.451853 model2 loss : 0.050628
[10:31:29.665] iteration 984 : model1 loss : 0.468941 model2 loss : 0.097066
[10:31:29.842] iteration 985 : model1 loss : 0.454582 model2 loss : 0.072425
[10:31:30.026] iteration 986 : model1 loss : 0.456940 model2 loss : 0.068861
[10:31:30.198] iteration 987 : model1 loss : 0.449686 model2 loss : 0.060157
[10:31:30.375] iteration 988 : model1 loss : 0.454746 model2 loss : 0.057363
[10:31:30.545] iteration 989 : model1 loss : 0.452708 model2 loss : 0.052982
[10:31:30.737] iteration 990 : model1 loss : 0.470705 model2 loss : 0.100114
[10:31:33.756] iteration 991 : model1 loss : 0.452485 model2 loss : 0.060714
[10:31:33.948] iteration 992 : model1 loss : 0.479476 model2 loss : 0.156801
[10:31:34.137] iteration 993 : model1 loss : 0.458195 model2 loss : 0.076255
[10:31:34.317] iteration 994 : model1 loss : 0.458781 model2 loss : 0.076350
[10:31:34.496] iteration 995 : model1 loss : 0.452629 model2 loss : 0.053038
[10:31:34.671] iteration 996 : model1 loss : 0.459020 model2 loss : 0.049891
[10:31:34.847] iteration 997 : model1 loss : 0.455050 model2 loss : 0.057088
[10:31:35.013] iteration 998 : model1 loss : 0.471794 model2 loss : 0.081058
[10:31:35.184] iteration 999 : model1 loss : 0.446064 model2 loss : 0.055124
[10:31:35.356] iteration 1000 : model1 loss : 0.458040 model2 loss : 0.069762
[10:31:44.727] iteration 1000 : model1_mean_dice : 0.442294 model1_mean_hd95 : 11.153364
[10:31:54.678] iteration 1000 : model2_mean_dice : 0.676971 model2_mean_hd95 : 4.602605
[10:31:54.865] iteration 1001 : model1 loss : 0.457131 model2 loss : 0.065949
[10:31:55.038] iteration 1002 : model1 loss : 0.455576 model2 loss : 0.059577
[10:31:55.205] iteration 1003 : model1 loss : 0.454286 model2 loss : 0.053197
[10:31:55.375] iteration 1004 : model1 loss : 0.464844 model2 loss : 0.087026
[10:31:55.545] iteration 1005 : model1 loss : 0.454032 model2 loss : 0.077136
[10:31:55.712] iteration 1006 : model1 loss : 0.454266 model2 loss : 0.068612
[10:31:55.881] iteration 1007 : model1 loss : 0.457188 model2 loss : 0.075171
[10:31:56.058] iteration 1008 : model1 loss : 0.452571 model2 loss : 0.048953
[10:31:56.272] iteration 1009 : model1 loss : 0.474921 model2 loss : 0.121183
[10:31:56.480] iteration 1010 : model1 loss : 0.461311 model2 loss : 0.086751
[10:31:56.691] iteration 1011 : model1 loss : 0.470930 model2 loss : 0.070015
[10:31:56.885] iteration 1012 : model1 loss : 0.449813 model2 loss : 0.042902
[10:31:57.063] iteration 1013 : model1 loss : 0.458846 model2 loss : 0.068425
[10:31:57.247] iteration 1014 : model1 loss : 0.448763 model2 loss : 0.055815
[10:31:57.422] iteration 1015 : model1 loss : 0.452266 model2 loss : 0.044516
[10:31:57.593] iteration 1016 : model1 loss : 0.463119 model2 loss : 0.073275
[10:31:57.765] iteration 1017 : model1 loss : 0.454914 model2 loss : 0.060771
[10:31:57.935] iteration 1018 : model1 loss : 0.457349 model2 loss : 0.055428
[10:31:58.103] iteration 1019 : model1 loss : 0.465581 model2 loss : 0.080771
[10:31:58.269] iteration 1020 : model1 loss : 0.461834 model2 loss : 0.064718
[10:31:58.438] iteration 1021 : model1 loss : 0.448823 model2 loss : 0.051502
[10:31:58.603] iteration 1022 : model1 loss : 0.455673 model2 loss : 0.060087
[10:31:58.781] iteration 1023 : model1 loss : 0.455202 model2 loss : 0.058897
[10:32:01.207] iteration 1024 : model1 loss : 0.454056 model2 loss : 0.056760
[10:32:01.379] iteration 1025 : model1 loss : 0.456231 model2 loss : 0.063069
[10:32:01.555] iteration 1026 : model1 loss : 0.454514 model2 loss : 0.066973
[10:32:01.720] iteration 1027 : model1 loss : 0.454260 model2 loss : 0.068021
[10:32:01.904] iteration 1028 : model1 loss : 0.457725 model2 loss : 0.067337
[10:32:02.070] iteration 1029 : model1 loss : 0.455480 model2 loss : 0.063640
[10:32:02.287] iteration 1030 : model1 loss : 0.462198 model2 loss : 0.052420
[10:32:02.503] iteration 1031 : model1 loss : 0.458404 model2 loss : 0.068892
[10:32:02.672] iteration 1032 : model1 loss : 0.452533 model2 loss : 0.055654
[10:32:02.857] iteration 1033 : model1 loss : 0.453445 model2 loss : 0.057796
[10:32:03.052] iteration 1034 : model1 loss : 0.456942 model2 loss : 0.073884
[10:32:03.245] iteration 1035 : model1 loss : 0.451032 model2 loss : 0.049409
[10:32:03.459] iteration 1036 : model1 loss : 0.463924 model2 loss : 0.074408
[10:32:03.644] iteration 1037 : model1 loss : 0.465101 model2 loss : 0.086835
[10:32:03.830] iteration 1038 : model1 loss : 0.455158 model2 loss : 0.045255
[10:32:03.999] iteration 1039 : model1 loss : 0.457345 model2 loss : 0.081096
[10:32:04.170] iteration 1040 : model1 loss : 0.459792 model2 loss : 0.079432
[10:32:04.340] iteration 1041 : model1 loss : 0.450084 model2 loss : 0.056953
[10:32:04.522] iteration 1042 : model1 loss : 0.451368 model2 loss : 0.067004
[10:32:04.688] iteration 1043 : model1 loss : 0.460009 model2 loss : 0.064637
[10:32:04.871] iteration 1044 : model1 loss : 0.450536 model2 loss : 0.057739
[10:32:05.039] iteration 1045 : model1 loss : 0.452795 model2 loss : 0.074426
[10:32:05.211] iteration 1046 : model1 loss : 0.449928 model2 loss : 0.048417
[10:32:05.381] iteration 1047 : model1 loss : 0.457588 model2 loss : 0.055828
[10:32:05.559] iteration 1048 : model1 loss : 0.450199 model2 loss : 0.044181
[10:32:05.728] iteration 1049 : model1 loss : 0.448585 model2 loss : 0.057992
[10:32:05.933] iteration 1050 : model1 loss : 0.458252 model2 loss : 0.058145
[10:32:06.114] iteration 1051 : model1 loss : 0.456221 model2 loss : 0.054296
[10:32:06.290] iteration 1052 : model1 loss : 0.456018 model2 loss : 0.072275
[10:32:06.460] iteration 1053 : model1 loss : 0.454435 model2 loss : 0.054144
[10:32:06.630] iteration 1054 : model1 loss : 0.471513 model2 loss : 0.089644
[10:32:06.816] iteration 1055 : model1 loss : 0.452785 model2 loss : 0.057415
[10:32:07.022] iteration 1056 : model1 loss : 0.448805 model2 loss : 0.061473
[10:32:09.171] iteration 1057 : model1 loss : 0.455625 model2 loss : 0.051811
[10:32:09.361] iteration 1058 : model1 loss : 0.457529 model2 loss : 0.057733
[10:32:09.536] iteration 1059 : model1 loss : 0.459027 model2 loss : 0.045796
[10:32:09.726] iteration 1060 : model1 loss : 0.464627 model2 loss : 0.064942
[10:32:09.935] iteration 1061 : model1 loss : 0.456695 model2 loss : 0.087287
[10:32:10.117] iteration 1062 : model1 loss : 0.448589 model2 loss : 0.054412
[10:32:10.366] iteration 1063 : model1 loss : 0.455716 model2 loss : 0.053795
[10:32:10.538] iteration 1064 : model1 loss : 0.453974 model2 loss : 0.056732
[10:32:10.729] iteration 1065 : model1 loss : 0.464319 model2 loss : 0.136838
[10:32:10.911] iteration 1066 : model1 loss : 0.460722 model2 loss : 0.062717
[10:32:11.082] iteration 1067 : model1 loss : 0.455802 model2 loss : 0.056303
[10:32:11.256] iteration 1068 : model1 loss : 0.459553 model2 loss : 0.094696
[10:32:11.428] iteration 1069 : model1 loss : 0.448006 model2 loss : 0.050362
[10:32:11.596] iteration 1070 : model1 loss : 0.464843 model2 loss : 0.092375
[10:32:11.764] iteration 1071 : model1 loss : 0.450146 model2 loss : 0.060844
[10:32:11.979] iteration 1072 : model1 loss : 0.464566 model2 loss : 0.052170
[10:32:12.204] iteration 1073 : model1 loss : 0.449088 model2 loss : 0.056914
[10:32:12.391] iteration 1074 : model1 loss : 0.447835 model2 loss : 0.047561
[10:32:12.561] iteration 1075 : model1 loss : 0.462769 model2 loss : 0.079415
[10:32:12.727] iteration 1076 : model1 loss : 0.449990 model2 loss : 0.046060
[10:32:12.901] iteration 1077 : model1 loss : 0.468167 model2 loss : 0.066619
[10:32:13.069] iteration 1078 : model1 loss : 0.449047 model2 loss : 0.065247
[10:32:13.239] iteration 1079 : model1 loss : 0.465505 model2 loss : 0.092682
[10:32:13.406] iteration 1080 : model1 loss : 0.455436 model2 loss : 0.088172
[10:32:13.576] iteration 1081 : model1 loss : 0.450528 model2 loss : 0.042933
[10:32:13.744] iteration 1082 : model1 loss : 0.451117 model2 loss : 0.056649
[10:32:13.915] iteration 1083 : model1 loss : 0.456189 model2 loss : 0.056938
[10:32:14.161] iteration 1084 : model1 loss : 0.451443 model2 loss : 0.052768
[10:32:14.337] iteration 1085 : model1 loss : 0.450583 model2 loss : 0.065003
[10:32:14.508] iteration 1086 : model1 loss : 0.450229 model2 loss : 0.047649
[10:32:14.674] iteration 1087 : model1 loss : 0.470288 model2 loss : 0.074095
[10:32:14.845] iteration 1088 : model1 loss : 0.463384 model2 loss : 0.052702
[10:32:15.069] iteration 1089 : model1 loss : 0.458886 model2 loss : 0.077157
[10:32:17.133] iteration 1090 : model1 loss : 0.449634 model2 loss : 0.062694
[10:32:17.302] iteration 1091 : model1 loss : 0.449195 model2 loss : 0.050098
[10:32:17.475] iteration 1092 : model1 loss : 0.453788 model2 loss : 0.073343
[10:32:17.644] iteration 1093 : model1 loss : 0.447614 model2 loss : 0.058608
[10:32:17.813] iteration 1094 : model1 loss : 0.456881 model2 loss : 0.067046
[10:32:17.991] iteration 1095 : model1 loss : 0.458671 model2 loss : 0.094511
[10:32:18.202] iteration 1096 : model1 loss : 0.451743 model2 loss : 0.047389
[10:32:18.418] iteration 1097 : model1 loss : 0.451754 model2 loss : 0.050342
[10:32:18.642] iteration 1098 : model1 loss : 0.461234 model2 loss : 0.061198
[10:32:18.905] iteration 1099 : model1 loss : 0.444506 model2 loss : 0.047020
[10:32:19.114] iteration 1100 : model1 loss : 0.468236 model2 loss : 0.115554
[10:32:19.286] iteration 1101 : model1 loss : 0.453702 model2 loss : 0.044218
[10:32:19.510] iteration 1102 : model1 loss : 0.455992 model2 loss : 0.057284
[10:32:19.741] iteration 1103 : model1 loss : 0.456910 model2 loss : 0.060777
[10:32:19.942] iteration 1104 : model1 loss : 0.455961 model2 loss : 0.076927
[10:32:20.140] iteration 1105 : model1 loss : 0.448306 model2 loss : 0.048376
[10:32:20.395] iteration 1106 : model1 loss : 0.451669 model2 loss : 0.061147
[10:32:20.623] iteration 1107 : model1 loss : 0.456680 model2 loss : 0.090538
[10:32:20.799] iteration 1108 : model1 loss : 0.453887 model2 loss : 0.095968
[10:32:21.006] iteration 1109 : model1 loss : 0.451399 model2 loss : 0.060404
[10:32:21.256] iteration 1110 : model1 loss : 0.471247 model2 loss : 0.083640
[10:32:21.469] iteration 1111 : model1 loss : 0.458362 model2 loss : 0.049390
[10:32:21.655] iteration 1112 : model1 loss : 0.455138 model2 loss : 0.053393
[10:32:21.845] iteration 1113 : model1 loss : 0.458766 model2 loss : 0.068093
[10:32:22.033] iteration 1114 : model1 loss : 0.443159 model2 loss : 0.058496
[10:32:22.228] iteration 1115 : model1 loss : 0.455081 model2 loss : 0.055003
[10:32:22.416] iteration 1116 : model1 loss : 0.449357 model2 loss : 0.046504
[10:32:22.607] iteration 1117 : model1 loss : 0.461330 model2 loss : 0.069380
[10:32:22.798] iteration 1118 : model1 loss : 0.455634 model2 loss : 0.044193
[10:32:22.992] iteration 1119 : model1 loss : 0.459725 model2 loss : 0.064666
[10:32:23.176] iteration 1120 : model1 loss : 0.456962 model2 loss : 0.068791
[10:32:23.368] iteration 1121 : model1 loss : 0.446305 model2 loss : 0.046446
[10:32:23.560] iteration 1122 : model1 loss : 0.458345 model2 loss : 0.066125
[10:32:25.639] iteration 1123 : model1 loss : 0.454252 model2 loss : 0.060429
[10:32:25.833] iteration 1124 : model1 loss : 0.456407 model2 loss : 0.061015
[10:32:26.021] iteration 1125 : model1 loss : 0.456955 model2 loss : 0.051837
[10:32:26.203] iteration 1126 : model1 loss : 0.456795 model2 loss : 0.055997
[10:32:26.396] iteration 1127 : model1 loss : 0.456100 model2 loss : 0.061068
[10:32:26.588] iteration 1128 : model1 loss : 0.449661 model2 loss : 0.053454
[10:32:26.777] iteration 1129 : model1 loss : 0.454393 model2 loss : 0.053460
[10:32:26.967] iteration 1130 : model1 loss : 0.459991 model2 loss : 0.052295
[10:32:27.159] iteration 1131 : model1 loss : 0.466416 model2 loss : 0.086076
[10:32:27.347] iteration 1132 : model1 loss : 0.452412 model2 loss : 0.060514
[10:32:27.541] iteration 1133 : model1 loss : 0.450707 model2 loss : 0.049015
[10:32:27.732] iteration 1134 : model1 loss : 0.454886 model2 loss : 0.057761
[10:32:27.934] iteration 1135 : model1 loss : 0.449477 model2 loss : 0.048611
[10:32:28.126] iteration 1136 : model1 loss : 0.458530 model2 loss : 0.059950
[10:32:28.317] iteration 1137 : model1 loss : 0.456027 model2 loss : 0.063599
[10:32:28.506] iteration 1138 : model1 loss : 0.452556 model2 loss : 0.047423
[10:32:28.698] iteration 1139 : model1 loss : 0.471383 model2 loss : 0.067169
[10:32:28.889] iteration 1140 : model1 loss : 0.451004 model2 loss : 0.052205
[10:32:29.089] iteration 1141 : model1 loss : 0.459474 model2 loss : 0.092585
[10:32:29.319] iteration 1142 : model1 loss : 0.454492 model2 loss : 0.050224
[10:32:29.510] iteration 1143 : model1 loss : 0.456896 model2 loss : 0.064686
[10:32:29.700] iteration 1144 : model1 loss : 0.451774 model2 loss : 0.053498
[10:32:29.894] iteration 1145 : model1 loss : 0.455385 model2 loss : 0.044526
[10:32:30.086] iteration 1146 : model1 loss : 0.452451 model2 loss : 0.050650
[10:32:30.274] iteration 1147 : model1 loss : 0.454623 model2 loss : 0.069492
[10:32:30.467] iteration 1148 : model1 loss : 0.449997 model2 loss : 0.050723
[10:32:30.653] iteration 1149 : model1 loss : 0.456111 model2 loss : 0.073542
[10:32:30.837] iteration 1150 : model1 loss : 0.447255 model2 loss : 0.040536
[10:32:31.026] iteration 1151 : model1 loss : 0.468968 model2 loss : 0.114298
[10:32:31.226] iteration 1152 : model1 loss : 0.454215 model2 loss : 0.068530
[10:32:31.407] iteration 1153 : model1 loss : 0.460186 model2 loss : 0.055289
[10:32:31.580] iteration 1154 : model1 loss : 0.454844 model2 loss : 0.049628
[10:32:31.763] iteration 1155 : model1 loss : 0.448503 model2 loss : 0.066025
[10:32:33.817] iteration 1156 : model1 loss : 0.446178 model2 loss : 0.057839
[10:32:33.987] iteration 1157 : model1 loss : 0.451136 model2 loss : 0.060023
[10:32:34.161] iteration 1158 : model1 loss : 0.446425 model2 loss : 0.047020
[10:32:34.334] iteration 1159 : model1 loss : 0.447627 model2 loss : 0.053934
[10:32:34.507] iteration 1160 : model1 loss : 0.455068 model2 loss : 0.050609
[10:32:34.684] iteration 1161 : model1 loss : 0.469927 model2 loss : 0.112733
[10:32:34.856] iteration 1162 : model1 loss : 0.447117 model2 loss : 0.039453
[10:32:35.030] iteration 1163 : model1 loss : 0.456870 model2 loss : 0.071514
[10:32:35.201] iteration 1164 : model1 loss : 0.453690 model2 loss : 0.069137
[10:32:35.378] iteration 1165 : model1 loss : 0.457267 model2 loss : 0.076881
[10:32:35.548] iteration 1166 : model1 loss : 0.449952 model2 loss : 0.071439
[10:32:35.716] iteration 1167 : model1 loss : 0.457587 model2 loss : 0.085192
[10:32:35.889] iteration 1168 : model1 loss : 0.457513 model2 loss : 0.063661
[10:32:36.063] iteration 1169 : model1 loss : 0.454230 model2 loss : 0.081080
[10:32:36.239] iteration 1170 : model1 loss : 0.461029 model2 loss : 0.063651
[10:32:36.412] iteration 1171 : model1 loss : 0.449086 model2 loss : 0.067801
[10:32:36.595] iteration 1172 : model1 loss : 0.452619 model2 loss : 0.060756
[10:32:36.766] iteration 1173 : model1 loss : 0.454157 model2 loss : 0.049296
[10:32:36.941] iteration 1174 : model1 loss : 0.452945 model2 loss : 0.059596
[10:32:37.126] iteration 1175 : model1 loss : 0.454799 model2 loss : 0.078729
[10:32:37.297] iteration 1176 : model1 loss : 0.458194 model2 loss : 0.054963
[10:32:37.481] iteration 1177 : model1 loss : 0.449581 model2 loss : 0.067335
[10:32:37.654] iteration 1178 : model1 loss : 0.446663 model2 loss : 0.064187
[10:32:37.825] iteration 1179 : model1 loss : 0.467313 model2 loss : 0.096016
[10:32:37.995] iteration 1180 : model1 loss : 0.447494 model2 loss : 0.045700
[10:32:38.167] iteration 1181 : model1 loss : 0.461794 model2 loss : 0.065921
[10:32:38.341] iteration 1182 : model1 loss : 0.459987 model2 loss : 0.062309
[10:32:38.510] iteration 1183 : model1 loss : 0.463814 model2 loss : 0.079628
[10:32:38.685] iteration 1184 : model1 loss : 0.447323 model2 loss : 0.042550
[10:32:38.862] iteration 1185 : model1 loss : 0.455334 model2 loss : 0.068249
[10:32:39.041] iteration 1186 : model1 loss : 0.448844 model2 loss : 0.049854
[10:32:39.208] iteration 1187 : model1 loss : 0.448928 model2 loss : 0.046478
[10:32:39.388] iteration 1188 : model1 loss : 0.446267 model2 loss : 0.047474
[10:32:41.469] iteration 1189 : model1 loss : 0.456554 model2 loss : 0.065230
[10:32:41.641] iteration 1190 : model1 loss : 0.453250 model2 loss : 0.053187
[10:32:41.818] iteration 1191 : model1 loss : 0.449915 model2 loss : 0.059732
[10:32:41.998] iteration 1192 : model1 loss : 0.442129 model2 loss : 0.040681
[10:32:42.175] iteration 1193 : model1 loss : 0.453493 model2 loss : 0.056506
[10:32:42.349] iteration 1194 : model1 loss : 0.450922 model2 loss : 0.054739
[10:32:42.542] iteration 1195 : model1 loss : 0.456600 model2 loss : 0.064475
[10:32:42.730] iteration 1196 : model1 loss : 0.445289 model2 loss : 0.040697
[10:32:42.912] iteration 1197 : model1 loss : 0.448612 model2 loss : 0.055664
[10:32:43.085] iteration 1198 : model1 loss : 0.448516 model2 loss : 0.043391
[10:32:43.263] iteration 1199 : model1 loss : 0.457446 model2 loss : 0.055217
[10:32:43.437] iteration 1200 : model1 loss : 0.445600 model2 loss : 0.052080
[10:32:43.610] iteration 1201 : model1 loss : 0.464834 model2 loss : 0.071039
[10:32:43.786] iteration 1202 : model1 loss : 0.456702 model2 loss : 0.055557
[10:32:43.963] iteration 1203 : model1 loss : 0.459489 model2 loss : 0.074395
[10:32:44.138] iteration 1204 : model1 loss : 0.457814 model2 loss : 0.066328
[10:32:44.317] iteration 1205 : model1 loss : 0.465438 model2 loss : 0.089743
[10:32:44.487] iteration 1206 : model1 loss : 0.453328 model2 loss : 0.041691
[10:32:44.655] iteration 1207 : model1 loss : 0.450090 model2 loss : 0.058229
[10:32:44.825] iteration 1208 : model1 loss : 0.463161 model2 loss : 0.081115
[10:32:45.003] iteration 1209 : model1 loss : 0.448296 model2 loss : 0.046704
[10:32:45.179] iteration 1210 : model1 loss : 0.446783 model2 loss : 0.050755
[10:32:45.355] iteration 1211 : model1 loss : 0.447851 model2 loss : 0.050792
[10:32:45.523] iteration 1212 : model1 loss : 0.456651 model2 loss : 0.084277
[10:32:45.726] iteration 1213 : model1 loss : 0.453006 model2 loss : 0.063785
[10:32:45.911] iteration 1214 : model1 loss : 0.459073 model2 loss : 0.063002
[10:32:46.086] iteration 1215 : model1 loss : 0.442776 model2 loss : 0.051944
[10:32:46.265] iteration 1216 : model1 loss : 0.455300 model2 loss : 0.050340
[10:32:46.452] iteration 1217 : model1 loss : 0.449234 model2 loss : 0.052462
[10:32:46.624] iteration 1218 : model1 loss : 0.459756 model2 loss : 0.065598
[10:32:46.794] iteration 1219 : model1 loss : 0.444227 model2 loss : 0.046637
[10:32:46.962] iteration 1220 : model1 loss : 0.449802 model2 loss : 0.063405
[10:32:47.134] iteration 1221 : model1 loss : 0.446211 model2 loss : 0.050796
[10:32:49.159] iteration 1222 : model1 loss : 0.442864 model2 loss : 0.043026
[10:32:49.348] iteration 1223 : model1 loss : 0.457543 model2 loss : 0.056477
[10:32:49.526] iteration 1224 : model1 loss : 0.467483 model2 loss : 0.075964
[10:32:49.701] iteration 1225 : model1 loss : 0.451394 model2 loss : 0.052185
[10:32:49.880] iteration 1226 : model1 loss : 0.454530 model2 loss : 0.045021
[10:32:50.053] iteration 1227 : model1 loss : 0.453319 model2 loss : 0.042042
[10:32:50.228] iteration 1228 : model1 loss : 0.451353 model2 loss : 0.056003
[10:32:50.400] iteration 1229 : model1 loss : 0.448883 model2 loss : 0.047622
[10:32:50.580] iteration 1230 : model1 loss : 0.455070 model2 loss : 0.070092
[10:32:50.769] iteration 1231 : model1 loss : 0.455374 model2 loss : 0.060985
[10:32:50.969] iteration 1232 : model1 loss : 0.457328 model2 loss : 0.070892
[10:32:51.144] iteration 1233 : model1 loss : 0.452590 model2 loss : 0.046784
[10:32:51.324] iteration 1234 : model1 loss : 0.451422 model2 loss : 0.069045
[10:32:51.499] iteration 1235 : model1 loss : 0.459940 model2 loss : 0.069374
[10:32:51.677] iteration 1236 : model1 loss : 0.459982 model2 loss : 0.058818
[10:32:51.861] iteration 1237 : model1 loss : 0.468380 model2 loss : 0.065208
[10:32:52.040] iteration 1238 : model1 loss : 0.448228 model2 loss : 0.048522
[10:32:52.215] iteration 1239 : model1 loss : 0.459538 model2 loss : 0.049543
[10:32:52.406] iteration 1240 : model1 loss : 0.449408 model2 loss : 0.045347
[10:32:52.584] iteration 1241 : model1 loss : 0.451573 model2 loss : 0.056071
[10:32:52.772] iteration 1242 : model1 loss : 0.450323 model2 loss : 0.050100
[10:32:52.945] iteration 1243 : model1 loss : 0.449338 model2 loss : 0.050454
[10:32:53.117] iteration 1244 : model1 loss : 0.450635 model2 loss : 0.051135
[10:32:53.291] iteration 1245 : model1 loss : 0.453914 model2 loss : 0.054641
[10:32:53.473] iteration 1246 : model1 loss : 0.451414 model2 loss : 0.050178
[10:32:53.649] iteration 1247 : model1 loss : 0.446876 model2 loss : 0.047306
[10:32:53.823] iteration 1248 : model1 loss : 0.445532 model2 loss : 0.047460
[10:32:53.991] iteration 1249 : model1 loss : 0.448092 model2 loss : 0.046979
[10:32:54.186] iteration 1250 : model1 loss : 0.452280 model2 loss : 0.051341
[10:32:54.371] iteration 1251 : model1 loss : 0.450109 model2 loss : 0.062903
[10:32:54.549] iteration 1252 : model1 loss : 0.449999 model2 loss : 0.039383
[10:32:54.720] iteration 1253 : model1 loss : 0.446504 model2 loss : 0.046714
[10:32:54.906] iteration 1254 : model1 loss : 0.459068 model2 loss : 0.058325
[10:32:57.072] iteration 1255 : model1 loss : 0.451121 model2 loss : 0.047481
[10:32:57.257] iteration 1256 : model1 loss : 0.443713 model2 loss : 0.047668
[10:32:57.433] iteration 1257 : model1 loss : 0.452489 model2 loss : 0.056088
[10:32:57.610] iteration 1258 : model1 loss : 0.457843 model2 loss : 0.045142
[10:32:57.783] iteration 1259 : model1 loss : 0.451341 model2 loss : 0.056982
[10:32:57.950] iteration 1260 : model1 loss : 0.456168 model2 loss : 0.052073
[10:32:58.129] iteration 1261 : model1 loss : 0.447378 model2 loss : 0.042292
[10:32:58.303] iteration 1262 : model1 loss : 0.453820 model2 loss : 0.049568
[10:32:58.488] iteration 1263 : model1 loss : 0.455925 model2 loss : 0.043889
[10:32:58.674] iteration 1264 : model1 loss : 0.446822 model2 loss : 0.047472
[10:32:58.855] iteration 1265 : model1 loss : 0.451754 model2 loss : 0.043991
[10:32:59.024] iteration 1266 : model1 loss : 0.454507 model2 loss : 0.053795
[10:32:59.197] iteration 1267 : model1 loss : 0.454850 model2 loss : 0.059031
[10:32:59.365] iteration 1268 : model1 loss : 0.457011 model2 loss : 0.046910
[10:32:59.538] iteration 1269 : model1 loss : 0.456012 model2 loss : 0.046105
[10:32:59.720] iteration 1270 : model1 loss : 0.458964 model2 loss : 0.059753
[10:32:59.898] iteration 1271 : model1 loss : 0.458351 model2 loss : 0.079268
[10:33:00.075] iteration 1272 : model1 loss : 0.446815 model2 loss : 0.049376
[10:33:00.254] iteration 1273 : model1 loss : 0.464808 model2 loss : 0.056367
[10:33:00.421] iteration 1274 : model1 loss : 0.468013 model2 loss : 0.065530
[10:33:00.595] iteration 1275 : model1 loss : 0.454772 model2 loss : 0.057891
[10:33:00.767] iteration 1276 : model1 loss : 0.461747 model2 loss : 0.049313
[10:33:00.949] iteration 1277 : model1 loss : 0.457482 model2 loss : 0.059709
[10:33:01.122] iteration 1278 : model1 loss : 0.445827 model2 loss : 0.039235
[10:33:01.301] iteration 1279 : model1 loss : 0.456098 model2 loss : 0.052030
[10:33:01.475] iteration 1280 : model1 loss : 0.455801 model2 loss : 0.058123
[10:33:01.650] iteration 1281 : model1 loss : 0.442706 model2 loss : 0.044513
[10:33:01.816] iteration 1282 : model1 loss : 0.469934 model2 loss : 0.065373
[10:33:01.989] iteration 1283 : model1 loss : 0.458103 model2 loss : 0.062572
[10:33:02.158] iteration 1284 : model1 loss : 0.459592 model2 loss : 0.065341
[10:33:02.327] iteration 1285 : model1 loss : 0.449026 model2 loss : 0.044046
[10:33:02.505] iteration 1286 : model1 loss : 0.459960 model2 loss : 0.062589
[10:33:02.674] iteration 1287 : model1 loss : 0.464510 model2 loss : 0.057119
[10:33:04.730] iteration 1288 : model1 loss : 0.451970 model2 loss : 0.053712
[10:33:04.900] iteration 1289 : model1 loss : 0.449528 model2 loss : 0.056001
[10:33:05.081] iteration 1290 : model1 loss : 0.463718 model2 loss : 0.061347
[10:33:05.254] iteration 1291 : model1 loss : 0.455073 model2 loss : 0.049643
[10:33:05.433] iteration 1292 : model1 loss : 0.445755 model2 loss : 0.042400
[10:33:05.608] iteration 1293 : model1 loss : 0.450073 model2 loss : 0.049153
[10:33:05.782] iteration 1294 : model1 loss : 0.450497 model2 loss : 0.045503
[10:33:05.949] iteration 1295 : model1 loss : 0.463212 model2 loss : 0.046797
[10:33:06.119] iteration 1296 : model1 loss : 0.450541 model2 loss : 0.042775
[10:33:06.288] iteration 1297 : model1 loss : 0.448372 model2 loss : 0.048827
[10:33:06.459] iteration 1298 : model1 loss : 0.450764 model2 loss : 0.041900
[10:33:06.638] iteration 1299 : model1 loss : 0.452634 model2 loss : 0.055798
[10:33:06.812] iteration 1300 : model1 loss : 0.447697 model2 loss : 0.049395
[10:33:06.983] iteration 1301 : model1 loss : 0.454967 model2 loss : 0.053431
[10:33:07.157] iteration 1302 : model1 loss : 0.452239 model2 loss : 0.041612
[10:33:07.331] iteration 1303 : model1 loss : 0.459688 model2 loss : 0.086767
[10:33:07.513] iteration 1304 : model1 loss : 0.451671 model2 loss : 0.056391
[10:33:07.687] iteration 1305 : model1 loss : 0.449504 model2 loss : 0.047968
[10:33:07.860] iteration 1306 : model1 loss : 0.457595 model2 loss : 0.056520
[10:33:08.031] iteration 1307 : model1 loss : 0.454274 model2 loss : 0.052628
[10:33:08.200] iteration 1308 : model1 loss : 0.453648 model2 loss : 0.051127
[10:33:08.370] iteration 1309 : model1 loss : 0.451806 model2 loss : 0.056966
[10:33:08.538] iteration 1310 : model1 loss : 0.456175 model2 loss : 0.045627
[10:33:08.707] iteration 1311 : model1 loss : 0.454065 model2 loss : 0.054964
[10:33:08.880] iteration 1312 : model1 loss : 0.459922 model2 loss : 0.063892
[10:33:09.064] iteration 1313 : model1 loss : 0.459121 model2 loss : 0.069949
[10:33:09.234] iteration 1314 : model1 loss : 0.454056 model2 loss : 0.056917
[10:33:09.404] iteration 1315 : model1 loss : 0.458140 model2 loss : 0.073085
[10:33:09.576] iteration 1316 : model1 loss : 0.449450 model2 loss : 0.050109
[10:33:09.744] iteration 1317 : model1 loss : 0.450105 model2 loss : 0.042015
[10:33:09.915] iteration 1318 : model1 loss : 0.444216 model2 loss : 0.046439
[10:33:10.087] iteration 1319 : model1 loss : 0.450922 model2 loss : 0.044681
[10:33:10.257] iteration 1320 : model1 loss : 0.450256 model2 loss : 0.049458
[10:33:12.281] iteration 1321 : model1 loss : 0.460966 model2 loss : 0.055133
[10:33:12.452] iteration 1322 : model1 loss : 0.454103 model2 loss : 0.054863
[10:33:12.626] iteration 1323 : model1 loss : 0.450679 model2 loss : 0.047578
[10:33:12.794] iteration 1324 : model1 loss : 0.457597 model2 loss : 0.048292
[10:33:12.964] iteration 1325 : model1 loss : 0.447467 model2 loss : 0.043315
[10:33:13.131] iteration 1326 : model1 loss : 0.449141 model2 loss : 0.055415
[10:33:13.305] iteration 1327 : model1 loss : 0.450039 model2 loss : 0.052126
[10:33:13.473] iteration 1328 : model1 loss : 0.450699 model2 loss : 0.041980
[10:33:13.643] iteration 1329 : model1 loss : 0.448506 model2 loss : 0.040260
[10:33:13.814] iteration 1330 : model1 loss : 0.459459 model2 loss : 0.048457
[10:33:13.986] iteration 1331 : model1 loss : 0.447503 model2 loss : 0.047822
[10:33:14.154] iteration 1332 : model1 loss : 0.461979 model2 loss : 0.054876
[10:33:14.324] iteration 1333 : model1 loss : 0.447376 model2 loss : 0.043772
[10:33:14.497] iteration 1334 : model1 loss : 0.467508 model2 loss : 0.065025
[10:33:14.668] iteration 1335 : model1 loss : 0.455537 model2 loss : 0.063718
[10:33:14.835] iteration 1336 : model1 loss : 0.457384 model2 loss : 0.053070
[10:33:15.006] iteration 1337 : model1 loss : 0.459732 model2 loss : 0.059586
[10:33:15.172] iteration 1338 : model1 loss : 0.453063 model2 loss : 0.042675
[10:33:15.344] iteration 1339 : model1 loss : 0.460269 model2 loss : 0.044677
[10:33:15.517] iteration 1340 : model1 loss : 0.459092 model2 loss : 0.053417
[10:33:15.686] iteration 1341 : model1 loss : 0.447355 model2 loss : 0.043808
[10:33:15.857] iteration 1342 : model1 loss : 0.457968 model2 loss : 0.050698
[10:33:16.029] iteration 1343 : model1 loss : 0.445845 model2 loss : 0.054555
[10:33:16.196] iteration 1344 : model1 loss : 0.462129 model2 loss : 0.062550
[10:33:16.365] iteration 1345 : model1 loss : 0.453090 model2 loss : 0.053330
[10:33:16.534] iteration 1346 : model1 loss : 0.457078 model2 loss : 0.064676
[10:33:16.708] iteration 1347 : model1 loss : 0.448588 model2 loss : 0.041253
[10:33:16.875] iteration 1348 : model1 loss : 0.446139 model2 loss : 0.042477
[10:33:17.046] iteration 1349 : model1 loss : 0.447401 model2 loss : 0.048615
[10:33:17.216] iteration 1350 : model1 loss : 0.452624 model2 loss : 0.050969
[10:33:17.388] iteration 1351 : model1 loss : 0.452873 model2 loss : 0.051585
[10:33:17.554] iteration 1352 : model1 loss : 0.452103 model2 loss : 0.064427
[10:33:17.726] iteration 1353 : model1 loss : 0.450468 model2 loss : 0.046818
[10:33:19.722] iteration 1354 : model1 loss : 0.456872 model2 loss : 0.054799
[10:33:19.896] iteration 1355 : model1 loss : 0.443806 model2 loss : 0.051225
[10:33:20.067] iteration 1356 : model1 loss : 0.447884 model2 loss : 0.045589
[10:33:20.232] iteration 1357 : model1 loss : 0.459733 model2 loss : 0.055977
[10:33:20.404] iteration 1358 : model1 loss : 0.463401 model2 loss : 0.086732
[10:33:20.576] iteration 1359 : model1 loss : 0.465965 model2 loss : 0.062875
[10:33:20.747] iteration 1360 : model1 loss : 0.451968 model2 loss : 0.050496
[10:33:20.916] iteration 1361 : model1 loss : 0.457177 model2 loss : 0.058962
[10:33:21.089] iteration 1362 : model1 loss : 0.452496 model2 loss : 0.043245
[10:33:21.256] iteration 1363 : model1 loss : 0.444763 model2 loss : 0.039307
[10:33:21.428] iteration 1364 : model1 loss : 0.451717 model2 loss : 0.045900
[10:33:21.598] iteration 1365 : model1 loss : 0.451309 model2 loss : 0.051820
[10:33:21.768] iteration 1366 : model1 loss : 0.449576 model2 loss : 0.049608
[10:33:21.937] iteration 1367 : model1 loss : 0.445122 model2 loss : 0.043057
[10:33:22.110] iteration 1368 : model1 loss : 0.445946 model2 loss : 0.044187
[10:33:22.279] iteration 1369 : model1 loss : 0.452857 model2 loss : 0.043439
[10:33:22.450] iteration 1370 : model1 loss : 0.445870 model2 loss : 0.034499
[10:33:22.618] iteration 1371 : model1 loss : 0.459321 model2 loss : 0.056343
[10:33:22.792] iteration 1372 : model1 loss : 0.450573 model2 loss : 0.061974
[10:33:22.959] iteration 1373 : model1 loss : 0.448777 model2 loss : 0.055169
[10:33:23.129] iteration 1374 : model1 loss : 0.458429 model2 loss : 0.060317
[10:33:23.300] iteration 1375 : model1 loss : 0.458735 model2 loss : 0.052239
[10:33:23.472] iteration 1376 : model1 loss : 0.455180 model2 loss : 0.064471
[10:33:23.638] iteration 1377 : model1 loss : 0.465716 model2 loss : 0.065394
[10:33:23.813] iteration 1378 : model1 loss : 0.443840 model2 loss : 0.043318
[10:33:23.980] iteration 1379 : model1 loss : 0.448399 model2 loss : 0.047188
[10:33:24.151] iteration 1380 : model1 loss : 0.445519 model2 loss : 0.040037
[10:33:24.321] iteration 1381 : model1 loss : 0.461009 model2 loss : 0.058340
[10:33:24.493] iteration 1382 : model1 loss : 0.453341 model2 loss : 0.052141
[10:33:24.660] iteration 1383 : model1 loss : 0.453016 model2 loss : 0.056817
[10:33:24.830] iteration 1384 : model1 loss : 0.447251 model2 loss : 0.051666
[10:33:25.000] iteration 1385 : model1 loss : 0.458332 model2 loss : 0.059488
[10:33:25.170] iteration 1386 : model1 loss : 0.457784 model2 loss : 0.067630
[10:33:27.195] iteration 1387 : model1 loss : 0.451101 model2 loss : 0.056739
[10:33:27.403] iteration 1388 : model1 loss : 0.450291 model2 loss : 0.052362
[10:33:27.618] iteration 1389 : model1 loss : 0.448018 model2 loss : 0.044607
[10:33:27.826] iteration 1390 : model1 loss : 0.449502 model2 loss : 0.050383
[10:33:28.001] iteration 1391 : model1 loss : 0.450779 model2 loss : 0.055085
[10:33:28.175] iteration 1392 : model1 loss : 0.449029 model2 loss : 0.042751
[10:33:28.346] iteration 1393 : model1 loss : 0.452422 model2 loss : 0.055842
[10:33:28.517] iteration 1394 : model1 loss : 0.449935 model2 loss : 0.052806
[10:33:28.685] iteration 1395 : model1 loss : 0.461857 model2 loss : 0.075112
[10:33:28.862] iteration 1396 : model1 loss : 0.445730 model2 loss : 0.041344
[10:33:29.049] iteration 1397 : model1 loss : 0.455730 model2 loss : 0.062981
[10:33:29.219] iteration 1398 : model1 loss : 0.448850 model2 loss : 0.048388
[10:33:29.399] iteration 1399 : model1 loss : 0.452124 model2 loss : 0.056012
[10:33:29.571] iteration 1400 : model1 loss : 0.449854 model2 loss : 0.051852
[10:33:29.739] iteration 1401 : model1 loss : 0.446245 model2 loss : 0.048118
[10:33:29.911] iteration 1402 : model1 loss : 0.447143 model2 loss : 0.044939
[10:33:30.080] iteration 1403 : model1 loss : 0.461353 model2 loss : 0.056510
[10:33:30.251] iteration 1404 : model1 loss : 0.450545 model2 loss : 0.064656
[10:33:30.421] iteration 1405 : model1 loss : 0.439353 model2 loss : 0.049559
[10:33:30.595] iteration 1406 : model1 loss : 0.452615 model2 loss : 0.053650
[10:33:30.763] iteration 1407 : model1 loss : 0.450917 model2 loss : 0.049267
[10:33:30.938] iteration 1408 : model1 loss : 0.449831 model2 loss : 0.052386
[10:33:31.107] iteration 1409 : model1 loss : 0.456130 model2 loss : 0.064689
[10:33:31.277] iteration 1410 : model1 loss : 0.450740 model2 loss : 0.057528
[10:33:31.445] iteration 1411 : model1 loss : 0.447125 model2 loss : 0.045477
[10:33:31.616] iteration 1412 : model1 loss : 0.444533 model2 loss : 0.042068
[10:33:31.785] iteration 1413 : model1 loss : 0.450092 model2 loss : 0.045151
[10:33:31.962] iteration 1414 : model1 loss : 0.444899 model2 loss : 0.057535
[10:33:32.129] iteration 1415 : model1 loss : 0.449374 model2 loss : 0.048145
[10:33:32.300] iteration 1416 : model1 loss : 0.448930 model2 loss : 0.052473
[10:33:32.468] iteration 1417 : model1 loss : 0.454935 model2 loss : 0.048372
[10:33:32.637] iteration 1418 : model1 loss : 0.440230 model2 loss : 0.042935
[10:33:32.804] iteration 1419 : model1 loss : 0.458270 model2 loss : 0.063715
[10:33:34.795] iteration 1420 : model1 loss : 0.445835 model2 loss : 0.039150
[10:33:34.967] iteration 1421 : model1 loss : 0.452986 model2 loss : 0.062809
[10:33:35.140] iteration 1422 : model1 loss : 0.445571 model2 loss : 0.045142
[10:33:35.306] iteration 1423 : model1 loss : 0.448329 model2 loss : 0.048986
[10:33:35.477] iteration 1424 : model1 loss : 0.451760 model2 loss : 0.073630
[10:33:35.646] iteration 1425 : model1 loss : 0.448817 model2 loss : 0.045974
[10:33:35.818] iteration 1426 : model1 loss : 0.449382 model2 loss : 0.067663
[10:33:35.987] iteration 1427 : model1 loss : 0.448344 model2 loss : 0.052140
[10:33:36.155] iteration 1428 : model1 loss : 0.454553 model2 loss : 0.054129
[10:33:36.323] iteration 1429 : model1 loss : 0.439168 model2 loss : 0.042344
[10:33:36.495] iteration 1430 : model1 loss : 0.453794 model2 loss : 0.051014
[10:33:36.662] iteration 1431 : model1 loss : 0.448259 model2 loss : 0.051338
[10:33:36.831] iteration 1432 : model1 loss : 0.450586 model2 loss : 0.054395
[10:33:36.997] iteration 1433 : model1 loss : 0.442640 model2 loss : 0.041494
[10:33:37.168] iteration 1434 : model1 loss : 0.445778 model2 loss : 0.051780
[10:33:37.337] iteration 1435 : model1 loss : 0.446506 model2 loss : 0.056747
[10:33:37.512] iteration 1436 : model1 loss : 0.446964 model2 loss : 0.046871
[10:33:37.679] iteration 1437 : model1 loss : 0.449279 model2 loss : 0.055194
[10:33:37.851] iteration 1438 : model1 loss : 0.453765 model2 loss : 0.055812
[10:33:38.018] iteration 1439 : model1 loss : 0.449196 model2 loss : 0.050701
[10:33:38.188] iteration 1440 : model1 loss : 0.454891 model2 loss : 0.056559
[10:33:38.358] iteration 1441 : model1 loss : 0.459687 model2 loss : 0.072125
[10:33:38.534] iteration 1442 : model1 loss : 0.444225 model2 loss : 0.048978
[10:33:38.702] iteration 1443 : model1 loss : 0.453805 model2 loss : 0.064974
[10:33:38.873] iteration 1444 : model1 loss : 0.456423 model2 loss : 0.049757
[10:33:39.041] iteration 1445 : model1 loss : 0.441958 model2 loss : 0.042538
[10:33:39.211] iteration 1446 : model1 loss : 0.452089 model2 loss : 0.042731
[10:33:39.380] iteration 1447 : model1 loss : 0.446646 model2 loss : 0.045627
[10:33:39.552] iteration 1448 : model1 loss : 0.451025 model2 loss : 0.053186
[10:33:39.719] iteration 1449 : model1 loss : 0.451812 model2 loss : 0.061998
[10:33:39.891] iteration 1450 : model1 loss : 0.450236 model2 loss : 0.041258
[10:33:40.057] iteration 1451 : model1 loss : 0.451297 model2 loss : 0.042510
[10:33:40.226] iteration 1452 : model1 loss : 0.451225 model2 loss : 0.047094
[10:33:42.215] iteration 1453 : model1 loss : 0.449259 model2 loss : 0.044868
[10:33:42.388] iteration 1454 : model1 loss : 0.448869 model2 loss : 0.051767
[10:33:42.568] iteration 1455 : model1 loss : 0.444801 model2 loss : 0.037431
[10:33:42.736] iteration 1456 : model1 loss : 0.451906 model2 loss : 0.042796
[10:33:42.925] iteration 1457 : model1 loss : 0.445013 model2 loss : 0.040842
[10:33:43.114] iteration 1458 : model1 loss : 0.450555 model2 loss : 0.036813
[10:33:43.305] iteration 1459 : model1 loss : 0.453361 model2 loss : 0.055909
[10:33:43.494] iteration 1460 : model1 loss : 0.449456 model2 loss : 0.050625
[10:33:43.684] iteration 1461 : model1 loss : 0.441647 model2 loss : 0.046251
[10:33:43.871] iteration 1462 : model1 loss : 0.454598 model2 loss : 0.045272
[10:33:44.060] iteration 1463 : model1 loss : 0.460088 model2 loss : 0.073784
[10:33:44.245] iteration 1464 : model1 loss : 0.448614 model2 loss : 0.051245
[10:33:44.437] iteration 1465 : model1 loss : 0.449432 model2 loss : 0.049977
[10:33:44.640] iteration 1466 : model1 loss : 0.442431 model2 loss : 0.038276
[10:33:44.858] iteration 1467 : model1 loss : 0.451739 model2 loss : 0.052550
[10:33:45.076] iteration 1468 : model1 loss : 0.450958 model2 loss : 0.042227
[10:33:45.271] iteration 1469 : model1 loss : 0.447726 model2 loss : 0.050850
[10:33:45.462] iteration 1470 : model1 loss : 0.447787 model2 loss : 0.044499
[10:33:45.651] iteration 1471 : model1 loss : 0.442256 model2 loss : 0.046375
[10:33:45.844] iteration 1472 : model1 loss : 0.457947 model2 loss : 0.061143
[10:33:46.031] iteration 1473 : model1 loss : 0.450191 model2 loss : 0.044143
[10:33:46.225] iteration 1474 : model1 loss : 0.449956 model2 loss : 0.055835
[10:33:46.413] iteration 1475 : model1 loss : 0.455313 model2 loss : 0.062019
[10:33:46.605] iteration 1476 : model1 loss : 0.446975 model2 loss : 0.046776
[10:33:46.794] iteration 1477 : model1 loss : 0.459489 model2 loss : 0.053071
[10:33:46.986] iteration 1478 : model1 loss : 0.447478 model2 loss : 0.040540
[10:33:47.176] iteration 1479 : model1 loss : 0.451221 model2 loss : 0.052849
[10:33:47.370] iteration 1480 : model1 loss : 0.449509 model2 loss : 0.051472
[10:33:47.579] iteration 1481 : model1 loss : 0.452491 model2 loss : 0.043736
[10:33:47.784] iteration 1482 : model1 loss : 0.444281 model2 loss : 0.049773
[10:33:47.977] iteration 1483 : model1 loss : 0.446811 model2 loss : 0.038621
[10:33:48.165] iteration 1484 : model1 loss : 0.450647 model2 loss : 0.047705
[10:33:48.361] iteration 1485 : model1 loss : 0.448882 model2 loss : 0.059929
[10:33:50.448] iteration 1486 : model1 loss : 0.444455 model2 loss : 0.052509
[10:33:50.634] iteration 1487 : model1 loss : 0.450831 model2 loss : 0.046506
[10:33:50.827] iteration 1488 : model1 loss : 0.447459 model2 loss : 0.052300
[10:33:51.011] iteration 1489 : model1 loss : 0.452780 model2 loss : 0.062238
[10:33:51.201] iteration 1490 : model1 loss : 0.445460 model2 loss : 0.043088
[10:33:51.391] iteration 1491 : model1 loss : 0.457556 model2 loss : 0.059349
[10:33:51.579] iteration 1492 : model1 loss : 0.451928 model2 loss : 0.046147
[10:33:51.767] iteration 1493 : model1 loss : 0.442503 model2 loss : 0.051189
[10:33:51.960] iteration 1494 : model1 loss : 0.447461 model2 loss : 0.050585
[10:33:52.147] iteration 1495 : model1 loss : 0.442644 model2 loss : 0.041163
[10:33:52.336] iteration 1496 : model1 loss : 0.443904 model2 loss : 0.043295
[10:33:52.510] iteration 1497 : model1 loss : 0.450086 model2 loss : 0.041118
[10:33:52.682] iteration 1498 : model1 loss : 0.460273 model2 loss : 0.069119
[10:33:52.848] iteration 1499 : model1 loss : 0.452936 model2 loss : 0.046652
[10:33:53.018] iteration 1500 : model1 loss : 0.450460 model2 loss : 0.040829
[10:33:53.190] iteration 1501 : model1 loss : 0.449280 model2 loss : 0.050885
[10:33:53.361] iteration 1502 : model1 loss : 0.448869 model2 loss : 0.050726
[10:33:53.532] iteration 1503 : model1 loss : 0.442886 model2 loss : 0.050164
[10:33:53.706] iteration 1504 : model1 loss : 0.458328 model2 loss : 0.082085
[10:33:53.872] iteration 1505 : model1 loss : 0.442157 model2 loss : 0.042258
[10:33:54.042] iteration 1506 : model1 loss : 0.444577 model2 loss : 0.046168
[10:33:54.213] iteration 1507 : model1 loss : 0.449197 model2 loss : 0.040349
[10:33:54.386] iteration 1508 : model1 loss : 0.447059 model2 loss : 0.053170
[10:33:54.553] iteration 1509 : model1 loss : 0.450314 model2 loss : 0.043319
[10:33:54.727] iteration 1510 : model1 loss : 0.444992 model2 loss : 0.041164
[10:33:54.898] iteration 1511 : model1 loss : 0.459987 model2 loss : 0.069380
[10:33:55.066] iteration 1512 : model1 loss : 0.440908 model2 loss : 0.045857
[10:33:55.234] iteration 1513 : model1 loss : 0.448746 model2 loss : 0.053167
[10:33:55.408] iteration 1514 : model1 loss : 0.448751 model2 loss : 0.050793
[10:33:55.577] iteration 1515 : model1 loss : 0.449253 model2 loss : 0.048779
[10:33:55.746] iteration 1516 : model1 loss : 0.449216 model2 loss : 0.046924
[10:33:55.919] iteration 1517 : model1 loss : 0.445436 model2 loss : 0.041696
[10:33:56.088] iteration 1518 : model1 loss : 0.446954 model2 loss : 0.043129
[10:33:58.061] iteration 1519 : model1 loss : 0.450435 model2 loss : 0.048573
[10:33:58.230] iteration 1520 : model1 loss : 0.449147 model2 loss : 0.051102
[10:33:58.402] iteration 1521 : model1 loss : 0.456029 model2 loss : 0.061247
[10:33:58.571] iteration 1522 : model1 loss : 0.448623 model2 loss : 0.040942
[10:33:58.744] iteration 1523 : model1 loss : 0.447510 model2 loss : 0.043725
[10:33:58.913] iteration 1524 : model1 loss : 0.446900 model2 loss : 0.047719
[10:33:59.083] iteration 1525 : model1 loss : 0.446389 model2 loss : 0.044002
[10:33:59.252] iteration 1526 : model1 loss : 0.441316 model2 loss : 0.034937
[10:33:59.421] iteration 1527 : model1 loss : 0.448897 model2 loss : 0.052812
[10:33:59.588] iteration 1528 : model1 loss : 0.445375 model2 loss : 0.048539
[10:33:59.763] iteration 1529 : model1 loss : 0.441634 model2 loss : 0.039304
[10:33:59.934] iteration 1530 : model1 loss : 0.457475 model2 loss : 0.072510
[10:34:00.106] iteration 1531 : model1 loss : 0.446018 model2 loss : 0.043167
[10:34:00.279] iteration 1532 : model1 loss : 0.456959 model2 loss : 0.059444
[10:34:00.452] iteration 1533 : model1 loss : 0.447916 model2 loss : 0.049436
[10:34:00.619] iteration 1534 : model1 loss : 0.440326 model2 loss : 0.037852
[10:34:00.790] iteration 1535 : model1 loss : 0.452004 model2 loss : 0.051978
[10:34:00.962] iteration 1536 : model1 loss : 0.445520 model2 loss : 0.041333
[10:34:01.131] iteration 1537 : model1 loss : 0.450180 model2 loss : 0.054486
[10:34:01.299] iteration 1538 : model1 loss : 0.442901 model2 loss : 0.040653
[10:34:01.481] iteration 1539 : model1 loss : 0.457425 model2 loss : 0.043787
[10:34:01.662] iteration 1540 : model1 loss : 0.443576 model2 loss : 0.046638
[10:34:01.835] iteration 1541 : model1 loss : 0.443344 model2 loss : 0.040292
[10:34:02.012] iteration 1542 : model1 loss : 0.444327 model2 loss : 0.039389
[10:34:02.190] iteration 1543 : model1 loss : 0.446361 model2 loss : 0.060093
[10:34:02.375] iteration 1544 : model1 loss : 0.459952 model2 loss : 0.082870
[10:34:02.555] iteration 1545 : model1 loss : 0.447601 model2 loss : 0.052111
[10:34:02.723] iteration 1546 : model1 loss : 0.452083 model2 loss : 0.043492
[10:34:02.907] iteration 1547 : model1 loss : 0.442666 model2 loss : 0.038814
[10:34:03.082] iteration 1548 : model1 loss : 0.444673 model2 loss : 0.040247
[10:34:03.269] iteration 1549 : model1 loss : 0.448907 model2 loss : 0.044744
[10:34:03.444] iteration 1550 : model1 loss : 0.455033 model2 loss : 0.056989
[10:34:03.629] iteration 1551 : model1 loss : 0.448212 model2 loss : 0.054525
[10:34:05.774] iteration 1552 : model1 loss : 0.451336 model2 loss : 0.048205
[10:34:05.963] iteration 1553 : model1 loss : 0.451734 model2 loss : 0.038586
[10:34:06.144] iteration 1554 : model1 loss : 0.447360 model2 loss : 0.047672
[10:34:06.323] iteration 1555 : model1 loss : 0.442261 model2 loss : 0.039311
[10:34:06.501] iteration 1556 : model1 loss : 0.447081 model2 loss : 0.041492
[10:34:06.680] iteration 1557 : model1 loss : 0.456532 model2 loss : 0.052883
[10:34:06.858] iteration 1558 : model1 loss : 0.441766 model2 loss : 0.036725
[10:34:07.039] iteration 1559 : model1 loss : 0.442651 model2 loss : 0.048804
[10:34:07.216] iteration 1560 : model1 loss : 0.451761 model2 loss : 0.048166
[10:34:07.394] iteration 1561 : model1 loss : 0.450604 model2 loss : 0.069139
[10:34:07.570] iteration 1562 : model1 loss : 0.454929 model2 loss : 0.065036
[10:34:07.745] iteration 1563 : model1 loss : 0.445718 model2 loss : 0.051943
[10:34:07.925] iteration 1564 : model1 loss : 0.448711 model2 loss : 0.048275
[10:34:08.095] iteration 1565 : model1 loss : 0.446868 model2 loss : 0.053503
[10:34:08.268] iteration 1566 : model1 loss : 0.447158 model2 loss : 0.050245
[10:34:08.438] iteration 1567 : model1 loss : 0.445732 model2 loss : 0.057880
[10:34:08.610] iteration 1568 : model1 loss : 0.451712 model2 loss : 0.045117
[10:34:08.776] iteration 1569 : model1 loss : 0.456790 model2 loss : 0.049180
[10:34:08.946] iteration 1570 : model1 loss : 0.445600 model2 loss : 0.039680
[10:34:09.115] iteration 1571 : model1 loss : 0.448855 model2 loss : 0.051929
[10:34:09.286] iteration 1572 : model1 loss : 0.446175 model2 loss : 0.051468
[10:34:09.454] iteration 1573 : model1 loss : 0.450590 model2 loss : 0.054084
[10:34:09.627] iteration 1574 : model1 loss : 0.444058 model2 loss : 0.038882
[10:34:09.794] iteration 1575 : model1 loss : 0.450265 model2 loss : 0.047329
[10:34:09.966] iteration 1576 : model1 loss : 0.447067 model2 loss : 0.057875
[10:34:10.139] iteration 1577 : model1 loss : 0.453656 model2 loss : 0.060444
[10:34:10.309] iteration 1578 : model1 loss : 0.449680 model2 loss : 0.042857
[10:34:10.477] iteration 1579 : model1 loss : 0.449848 model2 loss : 0.052398
[10:34:10.651] iteration 1580 : model1 loss : 0.447804 model2 loss : 0.054026
[10:34:10.822] iteration 1581 : model1 loss : 0.449018 model2 loss : 0.071927
[10:34:10.994] iteration 1582 : model1 loss : 0.449657 model2 loss : 0.048933
[10:34:11.163] iteration 1583 : model1 loss : 0.440044 model2 loss : 0.036925
[10:34:11.335] iteration 1584 : model1 loss : 0.447940 model2 loss : 0.062372
[10:34:13.367] iteration 1585 : model1 loss : 0.447709 model2 loss : 0.046363
[10:34:13.544] iteration 1586 : model1 loss : 0.443130 model2 loss : 0.033769
[10:34:13.718] iteration 1587 : model1 loss : 0.452774 model2 loss : 0.056852
[10:34:13.888] iteration 1588 : model1 loss : 0.440149 model2 loss : 0.040709
[10:34:14.066] iteration 1589 : model1 loss : 0.460360 model2 loss : 0.077432
[10:34:14.244] iteration 1590 : model1 loss : 0.448320 model2 loss : 0.057912
[10:34:14.427] iteration 1591 : model1 loss : 0.452243 model2 loss : 0.057959
[10:34:14.603] iteration 1592 : model1 loss : 0.444597 model2 loss : 0.041330
[10:34:14.789] iteration 1593 : model1 loss : 0.439501 model2 loss : 0.044406
[10:34:14.964] iteration 1594 : model1 loss : 0.453081 model2 loss : 0.058601
[10:34:15.140] iteration 1595 : model1 loss : 0.441696 model2 loss : 0.046059
[10:34:15.315] iteration 1596 : model1 loss : 0.440604 model2 loss : 0.034614
[10:34:15.497] iteration 1597 : model1 loss : 0.447091 model2 loss : 0.058203
[10:34:15.678] iteration 1598 : model1 loss : 0.446853 model2 loss : 0.047515
[10:34:15.865] iteration 1599 : model1 loss : 0.447004 model2 loss : 0.048390
[10:34:16.048] iteration 1600 : model1 loss : 0.441829 model2 loss : 0.043795
[10:34:16.234] iteration 1601 : model1 loss : 0.458332 model2 loss : 0.067043
[10:34:16.428] iteration 1602 : model1 loss : 0.448049 model2 loss : 0.046273
[10:34:16.601] iteration 1603 : model1 loss : 0.441958 model2 loss : 0.038956
[10:34:16.774] iteration 1604 : model1 loss : 0.449798 model2 loss : 0.047897
[10:34:16.959] iteration 1605 : model1 loss : 0.452928 model2 loss : 0.068366
[10:34:17.131] iteration 1606 : model1 loss : 0.444525 model2 loss : 0.057146
[10:34:17.308] iteration 1607 : model1 loss : 0.440748 model2 loss : 0.040676
[10:34:17.479] iteration 1608 : model1 loss : 0.447922 model2 loss : 0.050901
[10:34:17.652] iteration 1609 : model1 loss : 0.444193 model2 loss : 0.049266
[10:34:17.824] iteration 1610 : model1 loss : 0.442767 model2 loss : 0.046479
[10:34:17.993] iteration 1611 : model1 loss : 0.444008 model2 loss : 0.040812
[10:34:18.162] iteration 1612 : model1 loss : 0.447543 model2 loss : 0.042987
[10:34:18.356] iteration 1613 : model1 loss : 0.459582 model2 loss : 0.064153
[10:34:18.525] iteration 1614 : model1 loss : 0.448623 model2 loss : 0.062255
[10:34:18.704] iteration 1615 : model1 loss : 0.450686 model2 loss : 0.056333
[10:34:18.872] iteration 1616 : model1 loss : 0.443416 model2 loss : 0.045229
[10:34:19.048] iteration 1617 : model1 loss : 0.452463 model2 loss : 0.063503
[10:34:21.089] iteration 1618 : model1 loss : 0.443025 model2 loss : 0.042084
[10:34:21.277] iteration 1619 : model1 loss : 0.446379 model2 loss : 0.060730
[10:34:21.449] iteration 1620 : model1 loss : 0.444914 model2 loss : 0.053015
[10:34:21.630] iteration 1621 : model1 loss : 0.458211 model2 loss : 0.050890
[10:34:21.805] iteration 1622 : model1 loss : 0.456821 model2 loss : 0.060071
[10:34:22.004] iteration 1623 : model1 loss : 0.450026 model2 loss : 0.054597
[10:34:22.193] iteration 1624 : model1 loss : 0.441512 model2 loss : 0.040011
[10:34:22.372] iteration 1625 : model1 loss : 0.447826 model2 loss : 0.041727
[10:34:22.548] iteration 1626 : model1 loss : 0.450108 model2 loss : 0.054144
[10:34:22.723] iteration 1627 : model1 loss : 0.447064 model2 loss : 0.046894
[10:34:22.902] iteration 1628 : model1 loss : 0.444421 model2 loss : 0.047694
[10:34:23.077] iteration 1629 : model1 loss : 0.451045 model2 loss : 0.055244
[10:34:23.248] iteration 1630 : model1 loss : 0.448335 model2 loss : 0.045278
[10:34:23.416] iteration 1631 : model1 loss : 0.443656 model2 loss : 0.040711
[10:34:23.590] iteration 1632 : model1 loss : 0.454503 model2 loss : 0.050565
[10:34:23.767] iteration 1633 : model1 loss : 0.445544 model2 loss : 0.046288
[10:34:23.955] iteration 1634 : model1 loss : 0.439291 model2 loss : 0.037327
[10:34:24.122] iteration 1635 : model1 loss : 0.444582 model2 loss : 0.043045
[10:34:24.303] iteration 1636 : model1 loss : 0.448787 model2 loss : 0.047679
[10:34:24.484] iteration 1637 : model1 loss : 0.452925 model2 loss : 0.067033
[10:34:24.666] iteration 1638 : model1 loss : 0.441734 model2 loss : 0.037856
[10:34:24.839] iteration 1639 : model1 loss : 0.451572 model2 loss : 0.056502
[10:34:25.016] iteration 1640 : model1 loss : 0.446136 model2 loss : 0.041692
[10:34:25.192] iteration 1641 : model1 loss : 0.444848 model2 loss : 0.041044
[10:34:25.371] iteration 1642 : model1 loss : 0.449791 model2 loss : 0.049148
[10:34:25.541] iteration 1643 : model1 loss : 0.443911 model2 loss : 0.045300
[10:34:25.713] iteration 1644 : model1 loss : 0.447899 model2 loss : 0.042751
[10:34:25.885] iteration 1645 : model1 loss : 0.442699 model2 loss : 0.037267
[10:34:26.056] iteration 1646 : model1 loss : 0.441190 model2 loss : 0.045952
[10:34:26.224] iteration 1647 : model1 loss : 0.449257 model2 loss : 0.045101
[10:34:26.398] iteration 1648 : model1 loss : 0.442612 model2 loss : 0.041833
[10:34:26.576] iteration 1649 : model1 loss : 0.443226 model2 loss : 0.034812
[10:34:26.759] iteration 1650 : model1 loss : 0.447918 model2 loss : 0.066585
[10:34:28.910] iteration 1651 : model1 loss : 0.448141 model2 loss : 0.047327
[10:34:29.096] iteration 1652 : model1 loss : 0.439916 model2 loss : 0.042610
[10:34:29.278] iteration 1653 : model1 loss : 0.457811 model2 loss : 0.063923
[10:34:29.466] iteration 1654 : model1 loss : 0.449289 model2 loss : 0.042862
[10:34:29.659] iteration 1655 : model1 loss : 0.447746 model2 loss : 0.044104
[10:34:29.838] iteration 1656 : model1 loss : 0.447774 model2 loss : 0.050140
[10:34:30.009] iteration 1657 : model1 loss : 0.449205 model2 loss : 0.044329
[10:34:30.186] iteration 1658 : model1 loss : 0.440809 model2 loss : 0.036902
[10:34:30.361] iteration 1659 : model1 loss : 0.456029 model2 loss : 0.062057
[10:34:30.530] iteration 1660 : model1 loss : 0.452052 model2 loss : 0.046530
[10:34:30.707] iteration 1661 : model1 loss : 0.439962 model2 loss : 0.039760
[10:34:30.882] iteration 1662 : model1 loss : 0.450639 model2 loss : 0.054474
[10:34:31.052] iteration 1663 : model1 loss : 0.456688 model2 loss : 0.055729
[10:34:31.235] iteration 1664 : model1 loss : 0.446157 model2 loss : 0.050793
[10:34:31.408] iteration 1665 : model1 loss : 0.451374 model2 loss : 0.053122
[10:34:31.581] iteration 1666 : model1 loss : 0.445248 model2 loss : 0.052405
[10:34:31.765] iteration 1667 : model1 loss : 0.448093 model2 loss : 0.050483
[10:34:31.954] iteration 1668 : model1 loss : 0.449951 model2 loss : 0.041377
[10:34:32.140] iteration 1669 : model1 loss : 0.449223 model2 loss : 0.046416
[10:34:32.317] iteration 1670 : model1 loss : 0.451680 model2 loss : 0.061270
[10:34:32.490] iteration 1671 : model1 loss : 0.444457 model2 loss : 0.052261
[10:34:32.658] iteration 1672 : model1 loss : 0.451138 model2 loss : 0.049397
[10:34:32.832] iteration 1673 : model1 loss : 0.440587 model2 loss : 0.044888
[10:34:33.014] iteration 1674 : model1 loss : 0.444595 model2 loss : 0.045981
[10:34:33.194] iteration 1675 : model1 loss : 0.444507 model2 loss : 0.039918
[10:34:33.362] iteration 1676 : model1 loss : 0.445604 model2 loss : 0.056160
[10:34:33.542] iteration 1677 : model1 loss : 0.448417 model2 loss : 0.051977
[10:34:33.711] iteration 1678 : model1 loss : 0.441106 model2 loss : 0.043331
[10:34:33.882] iteration 1679 : model1 loss : 0.448362 model2 loss : 0.036715
[10:34:34.061] iteration 1680 : model1 loss : 0.441374 model2 loss : 0.044675
[10:34:34.237] iteration 1681 : model1 loss : 0.442158 model2 loss : 0.043082
[10:34:34.413] iteration 1682 : model1 loss : 0.448614 model2 loss : 0.047739
[10:34:34.606] iteration 1683 : model1 loss : 0.453953 model2 loss : 0.054573
[10:34:36.761] iteration 1684 : model1 loss : 0.449249 model2 loss : 0.049840
[10:34:36.938] iteration 1685 : model1 loss : 0.457835 model2 loss : 0.060070
[10:34:37.118] iteration 1686 : model1 loss : 0.450953 model2 loss : 0.055588
[10:34:37.310] iteration 1687 : model1 loss : 0.443223 model2 loss : 0.038223
[10:34:37.482] iteration 1688 : model1 loss : 0.448048 model2 loss : 0.046966
[10:34:37.652] iteration 1689 : model1 loss : 0.445984 model2 loss : 0.040318
[10:34:37.834] iteration 1690 : model1 loss : 0.445206 model2 loss : 0.052077
[10:34:38.018] iteration 1691 : model1 loss : 0.448603 model2 loss : 0.060115
[10:34:38.201] iteration 1692 : model1 loss : 0.445905 model2 loss : 0.042946
[10:34:38.384] iteration 1693 : model1 loss : 0.442965 model2 loss : 0.042498
[10:34:38.568] iteration 1694 : model1 loss : 0.449673 model2 loss : 0.037292
[10:34:38.742] iteration 1695 : model1 loss : 0.444748 model2 loss : 0.044213
[10:34:38.922] iteration 1696 : model1 loss : 0.449929 model2 loss : 0.042016
[10:34:39.102] iteration 1697 : model1 loss : 0.445164 model2 loss : 0.043239
[10:34:39.275] iteration 1698 : model1 loss : 0.444071 model2 loss : 0.042831
[10:34:39.449] iteration 1699 : model1 loss : 0.448455 model2 loss : 0.046611
[10:34:39.621] iteration 1700 : model1 loss : 0.440992 model2 loss : 0.044210
[10:34:39.802] iteration 1701 : model1 loss : 0.446636 model2 loss : 0.040176
[10:34:39.981] iteration 1702 : model1 loss : 0.438945 model2 loss : 0.034512
[10:34:40.169] iteration 1703 : model1 loss : 0.442349 model2 loss : 0.033301
[10:34:40.355] iteration 1704 : model1 loss : 0.458117 model2 loss : 0.046904
[10:34:40.526] iteration 1705 : model1 loss : 0.447898 model2 loss : 0.045234
[10:34:40.706] iteration 1706 : model1 loss : 0.449557 model2 loss : 0.051691
[10:34:40.884] iteration 1707 : model1 loss : 0.450897 model2 loss : 0.044270
[10:34:41.062] iteration 1708 : model1 loss : 0.445132 model2 loss : 0.044412
[10:34:41.246] iteration 1709 : model1 loss : 0.449799 model2 loss : 0.044623
[10:34:41.428] iteration 1710 : model1 loss : 0.454084 model2 loss : 0.051938
[10:34:41.596] iteration 1711 : model1 loss : 0.450355 model2 loss : 0.046675
[10:34:41.772] iteration 1712 : model1 loss : 0.445356 model2 loss : 0.039229
[10:34:41.942] iteration 1713 : model1 loss : 0.445972 model2 loss : 0.049542
[10:34:42.113] iteration 1714 : model1 loss : 0.441031 model2 loss : 0.036068
[10:34:42.283] iteration 1715 : model1 loss : 0.447712 model2 loss : 0.053872
[10:34:42.465] iteration 1716 : model1 loss : 0.460852 model2 loss : 0.044259
[10:34:44.452] iteration 1717 : model1 loss : 0.440116 model2 loss : 0.043590
[10:34:44.647] iteration 1718 : model1 loss : 0.442137 model2 loss : 0.037190
[10:34:44.821] iteration 1719 : model1 loss : 0.447238 model2 loss : 0.043572
[10:34:44.991] iteration 1720 : model1 loss : 0.448984 model2 loss : 0.047836
[10:34:45.168] iteration 1721 : model1 loss : 0.448821 model2 loss : 0.056196
[10:34:45.338] iteration 1722 : model1 loss : 0.447827 model2 loss : 0.051879
[10:34:45.519] iteration 1723 : model1 loss : 0.455249 model2 loss : 0.060771
[10:34:45.691] iteration 1724 : model1 loss : 0.450450 model2 loss : 0.054019
[10:34:45.877] iteration 1725 : model1 loss : 0.442549 model2 loss : 0.050696
[10:34:46.056] iteration 1726 : model1 loss : 0.445532 model2 loss : 0.055340
[10:34:46.228] iteration 1727 : model1 loss : 0.446507 model2 loss : 0.049147
[10:34:46.403] iteration 1728 : model1 loss : 0.452282 model2 loss : 0.054449
[10:34:46.577] iteration 1729 : model1 loss : 0.442520 model2 loss : 0.039779
[10:34:46.748] iteration 1730 : model1 loss : 0.444331 model2 loss : 0.045854
[10:34:46.924] iteration 1731 : model1 loss : 0.446665 model2 loss : 0.047365
[10:34:47.092] iteration 1732 : model1 loss : 0.441963 model2 loss : 0.043103
[10:34:47.267] iteration 1733 : model1 loss : 0.443097 model2 loss : 0.050186
[10:34:47.433] iteration 1734 : model1 loss : 0.443966 model2 loss : 0.041399
[10:34:47.602] iteration 1735 : model1 loss : 0.452694 model2 loss : 0.049308
[10:34:47.781] iteration 1736 : model1 loss : 0.453705 model2 loss : 0.056327
[10:34:47.960] iteration 1737 : model1 loss : 0.443843 model2 loss : 0.049958
[10:34:48.134] iteration 1738 : model1 loss : 0.450960 model2 loss : 0.047620
[10:34:48.316] iteration 1739 : model1 loss : 0.446063 model2 loss : 0.041023
[10:34:48.494] iteration 1740 : model1 loss : 0.456541 model2 loss : 0.058310
[10:34:48.674] iteration 1741 : model1 loss : 0.453925 model2 loss : 0.070589
[10:34:48.842] iteration 1742 : model1 loss : 0.439743 model2 loss : 0.037863
[10:34:49.026] iteration 1743 : model1 loss : 0.442219 model2 loss : 0.041835
[10:34:49.199] iteration 1744 : model1 loss : 0.445485 model2 loss : 0.044112
[10:34:49.376] iteration 1745 : model1 loss : 0.451026 model2 loss : 0.048541
[10:34:49.553] iteration 1746 : model1 loss : 0.439881 model2 loss : 0.035568
[10:34:49.728] iteration 1747 : model1 loss : 0.443788 model2 loss : 0.040816
[10:34:49.907] iteration 1748 : model1 loss : 0.447767 model2 loss : 0.046240
[10:34:50.083] iteration 1749 : model1 loss : 0.452219 model2 loss : 0.049917
[10:34:52.109] iteration 1750 : model1 loss : 0.446959 model2 loss : 0.046329
[10:34:52.289] iteration 1751 : model1 loss : 0.447595 model2 loss : 0.049400
[10:34:52.459] iteration 1752 : model1 loss : 0.453255 model2 loss : 0.053486
[10:34:52.633] iteration 1753 : model1 loss : 0.446282 model2 loss : 0.052537
[10:34:52.811] iteration 1754 : model1 loss : 0.445922 model2 loss : 0.041956
[10:34:53.004] iteration 1755 : model1 loss : 0.451416 model2 loss : 0.072877
[10:34:53.201] iteration 1756 : model1 loss : 0.448384 model2 loss : 0.067439
[10:34:53.400] iteration 1757 : model1 loss : 0.442798 model2 loss : 0.039871
[10:34:53.591] iteration 1758 : model1 loss : 0.443569 model2 loss : 0.041124
[10:34:53.778] iteration 1759 : model1 loss : 0.446587 model2 loss : 0.044686
[10:34:53.974] iteration 1760 : model1 loss : 0.444318 model2 loss : 0.046848
[10:34:54.165] iteration 1761 : model1 loss : 0.462660 model2 loss : 0.068009
[10:34:54.365] iteration 1762 : model1 loss : 0.438319 model2 loss : 0.039746
[10:34:54.561] iteration 1763 : model1 loss : 0.456184 model2 loss : 0.049921
[10:34:54.757] iteration 1764 : model1 loss : 0.446734 model2 loss : 0.041994
[10:34:54.951] iteration 1765 : model1 loss : 0.449874 model2 loss : 0.058952
[10:34:55.152] iteration 1766 : model1 loss : 0.448112 model2 loss : 0.048872
[10:34:55.339] iteration 1767 : model1 loss : 0.445597 model2 loss : 0.043170
[10:34:55.538] iteration 1768 : model1 loss : 0.455507 model2 loss : 0.074896
[10:34:55.730] iteration 1769 : model1 loss : 0.440749 model2 loss : 0.039996
[10:34:55.938] iteration 1770 : model1 loss : 0.446635 model2 loss : 0.048675
[10:34:56.150] iteration 1771 : model1 loss : 0.443340 model2 loss : 0.044306
[10:34:56.346] iteration 1772 : model1 loss : 0.450011 model2 loss : 0.074899
[10:34:56.553] iteration 1773 : model1 loss : 0.442522 model2 loss : 0.043512
[10:34:56.741] iteration 1774 : model1 loss : 0.448229 model2 loss : 0.052315
[10:34:56.935] iteration 1775 : model1 loss : 0.444485 model2 loss : 0.041655
[10:34:57.127] iteration 1776 : model1 loss : 0.444495 model2 loss : 0.046290
[10:34:57.332] iteration 1777 : model1 loss : 0.451054 model2 loss : 0.053868
[10:34:57.538] iteration 1778 : model1 loss : 0.446170 model2 loss : 0.056145
[10:34:57.735] iteration 1779 : model1 loss : 0.439978 model2 loss : 0.046895
[10:34:57.938] iteration 1780 : model1 loss : 0.447846 model2 loss : 0.043365
[10:34:58.129] iteration 1781 : model1 loss : 0.447362 model2 loss : 0.049168
[10:34:58.335] iteration 1782 : model1 loss : 0.444904 model2 loss : 0.041068
[10:35:00.465] iteration 1783 : model1 loss : 0.450100 model2 loss : 0.058773
[10:35:00.657] iteration 1784 : model1 loss : 0.449037 model2 loss : 0.057488
[10:35:00.862] iteration 1785 : model1 loss : 0.444002 model2 loss : 0.036579
[10:35:01.057] iteration 1786 : model1 loss : 0.443292 model2 loss : 0.045324
[10:35:01.251] iteration 1787 : model1 loss : 0.444181 model2 loss : 0.044364
[10:35:01.448] iteration 1788 : model1 loss : 0.440520 model2 loss : 0.035480
[10:35:01.647] iteration 1789 : model1 loss : 0.444877 model2 loss : 0.039063
[10:35:01.835] iteration 1790 : model1 loss : 0.445637 model2 loss : 0.045456
[10:35:02.029] iteration 1791 : model1 loss : 0.445104 model2 loss : 0.048537
[10:35:02.229] iteration 1792 : model1 loss : 0.443840 model2 loss : 0.040666
[10:35:02.426] iteration 1793 : model1 loss : 0.453717 model2 loss : 0.061704
[10:35:02.607] iteration 1794 : model1 loss : 0.443263 model2 loss : 0.046011
[10:35:02.792] iteration 1795 : model1 loss : 0.450965 model2 loss : 0.046244
[10:35:02.974] iteration 1796 : model1 loss : 0.442146 model2 loss : 0.047146
[10:35:03.160] iteration 1797 : model1 loss : 0.443208 model2 loss : 0.041038
[10:35:03.335] iteration 1798 : model1 loss : 0.454956 model2 loss : 0.051844
[10:35:03.528] iteration 1799 : model1 loss : 0.450183 model2 loss : 0.052773
[10:35:03.698] iteration 1800 : model1 loss : 0.449539 model2 loss : 0.057841
[10:35:03.885] iteration 1801 : model1 loss : 0.440836 model2 loss : 0.040954
[10:35:04.078] iteration 1802 : model1 loss : 0.441379 model2 loss : 0.043507
[10:35:04.265] iteration 1803 : model1 loss : 0.449035 model2 loss : 0.072697
[10:35:04.438] iteration 1804 : model1 loss : 0.447071 model2 loss : 0.044095
[10:35:04.612] iteration 1805 : model1 loss : 0.443702 model2 loss : 0.048114
[10:35:04.781] iteration 1806 : model1 loss : 0.439622 model2 loss : 0.033490
[10:35:04.962] iteration 1807 : model1 loss : 0.441275 model2 loss : 0.039905
[10:35:05.135] iteration 1808 : model1 loss : 0.453032 model2 loss : 0.038536
[10:35:05.314] iteration 1809 : model1 loss : 0.449100 model2 loss : 0.040683
[10:35:05.492] iteration 1810 : model1 loss : 0.445723 model2 loss : 0.048838
[10:35:05.667] iteration 1811 : model1 loss : 0.443168 model2 loss : 0.041010
[10:35:05.853] iteration 1812 : model1 loss : 0.447125 model2 loss : 0.046617
[10:35:06.038] iteration 1813 : model1 loss : 0.442079 model2 loss : 0.037543
[10:35:06.204] iteration 1814 : model1 loss : 0.450395 model2 loss : 0.054423
[10:35:06.379] iteration 1815 : model1 loss : 0.448626 model2 loss : 0.050920
[10:35:08.495] iteration 1816 : model1 loss : 0.445574 model2 loss : 0.045651
[10:35:08.676] iteration 1817 : model1 loss : 0.441349 model2 loss : 0.041355
[10:35:08.856] iteration 1818 : model1 loss : 0.441440 model2 loss : 0.042480
[10:35:09.030] iteration 1819 : model1 loss : 0.451813 model2 loss : 0.044966
[10:35:09.200] iteration 1820 : model1 loss : 0.441719 model2 loss : 0.040427
[10:35:09.370] iteration 1821 : model1 loss : 0.447126 model2 loss : 0.042881
[10:35:09.541] iteration 1822 : model1 loss : 0.446150 model2 loss : 0.041012
[10:35:09.709] iteration 1823 : model1 loss : 0.449214 model2 loss : 0.054425
[10:35:09.882] iteration 1824 : model1 loss : 0.455717 model2 loss : 0.058602
[10:35:10.050] iteration 1825 : model1 loss : 0.444354 model2 loss : 0.039347
[10:35:10.219] iteration 1826 : model1 loss : 0.446134 model2 loss : 0.038730
[10:35:10.391] iteration 1827 : model1 loss : 0.446578 model2 loss : 0.043835
[10:35:10.564] iteration 1828 : model1 loss : 0.445100 model2 loss : 0.038684
[10:35:10.731] iteration 1829 : model1 loss : 0.437426 model2 loss : 0.042399
[10:35:10.905] iteration 1830 : model1 loss : 0.447326 model2 loss : 0.044994
[10:35:11.076] iteration 1831 : model1 loss : 0.439497 model2 loss : 0.033840
[10:35:11.245] iteration 1832 : model1 loss : 0.444330 model2 loss : 0.045879
[10:35:11.415] iteration 1833 : model1 loss : 0.442537 model2 loss : 0.041500
[10:35:11.588] iteration 1834 : model1 loss : 0.452539 model2 loss : 0.049968
[10:35:11.759] iteration 1835 : model1 loss : 0.449532 model2 loss : 0.056665
[10:35:11.931] iteration 1836 : model1 loss : 0.441152 model2 loss : 0.036500
[10:35:12.102] iteration 1837 : model1 loss : 0.443779 model2 loss : 0.037863
[10:35:12.274] iteration 1838 : model1 loss : 0.444216 model2 loss : 0.041631
[10:35:12.442] iteration 1839 : model1 loss : 0.457814 model2 loss : 0.057791
[10:35:12.615] iteration 1840 : model1 loss : 0.444558 model2 loss : 0.042378
[10:35:12.786] iteration 1841 : model1 loss : 0.442565 model2 loss : 0.042965
[10:35:12.955] iteration 1842 : model1 loss : 0.449724 model2 loss : 0.055271
[10:35:13.126] iteration 1843 : model1 loss : 0.447541 model2 loss : 0.045462
[10:35:13.299] iteration 1844 : model1 loss : 0.444430 model2 loss : 0.047378
[10:35:13.467] iteration 1845 : model1 loss : 0.449479 model2 loss : 0.048298
[10:35:13.641] iteration 1846 : model1 loss : 0.441058 model2 loss : 0.040214
[10:35:13.812] iteration 1847 : model1 loss : 0.450254 model2 loss : 0.057905
[10:35:13.981] iteration 1848 : model1 loss : 0.446171 model2 loss : 0.044125
[10:35:16.044] iteration 1849 : model1 loss : 0.441152 model2 loss : 0.034886
[10:35:16.213] iteration 1850 : model1 loss : 0.444020 model2 loss : 0.052648
[10:35:16.385] iteration 1851 : model1 loss : 0.450852 model2 loss : 0.041837
[10:35:16.557] iteration 1852 : model1 loss : 0.444574 model2 loss : 0.040762
[10:35:16.727] iteration 1853 : model1 loss : 0.449852 model2 loss : 0.051250
[10:35:16.896] iteration 1854 : model1 loss : 0.448159 model2 loss : 0.048274
[10:35:17.067] iteration 1855 : model1 loss : 0.445400 model2 loss : 0.042101
[10:35:17.235] iteration 1856 : model1 loss : 0.440893 model2 loss : 0.046336
[10:35:17.407] iteration 1857 : model1 loss : 0.451035 model2 loss : 0.069250
[10:35:17.577] iteration 1858 : model1 loss : 0.445368 model2 loss : 0.042081
[10:35:17.750] iteration 1859 : model1 loss : 0.440423 model2 loss : 0.042387
[10:35:17.920] iteration 1860 : model1 loss : 0.447767 model2 loss : 0.051003
[10:35:18.090] iteration 1861 : model1 loss : 0.443702 model2 loss : 0.044884
[10:35:18.263] iteration 1862 : model1 loss : 0.449660 model2 loss : 0.045101
[10:35:18.434] iteration 1863 : model1 loss : 0.450886 model2 loss : 0.057530
[10:35:18.613] iteration 1864 : model1 loss : 0.449183 model2 loss : 0.062932
[10:35:18.798] iteration 1865 : model1 loss : 0.441244 model2 loss : 0.038753
[10:35:18.977] iteration 1866 : model1 loss : 0.447329 model2 loss : 0.044555
[10:35:19.173] iteration 1867 : model1 loss : 0.448377 model2 loss : 0.047377
[10:35:19.344] iteration 1868 : model1 loss : 0.440284 model2 loss : 0.036463
[10:35:19.540] iteration 1869 : model1 loss : 0.448391 model2 loss : 0.058859
[10:35:19.712] iteration 1870 : model1 loss : 0.446408 model2 loss : 0.049467
[10:35:19.888] iteration 1871 : model1 loss : 0.442628 model2 loss : 0.051321
[10:35:20.060] iteration 1872 : model1 loss : 0.441724 model2 loss : 0.057131
[10:35:20.236] iteration 1873 : model1 loss : 0.445085 model2 loss : 0.043998
[10:35:20.405] iteration 1874 : model1 loss : 0.446640 model2 loss : 0.047285
[10:35:20.576] iteration 1875 : model1 loss : 0.458286 model2 loss : 0.092047
[10:35:20.749] iteration 1876 : model1 loss : 0.441537 model2 loss : 0.043975
[10:35:20.923] iteration 1877 : model1 loss : 0.443072 model2 loss : 0.057751
[10:35:21.091] iteration 1878 : model1 loss : 0.444935 model2 loss : 0.039225
[10:35:21.265] iteration 1879 : model1 loss : 0.435666 model2 loss : 0.037526
[10:35:21.432] iteration 1880 : model1 loss : 0.440876 model2 loss : 0.039393
[10:35:21.603] iteration 1881 : model1 loss : 0.441834 model2 loss : 0.066133
[10:35:23.630] iteration 1882 : model1 loss : 0.451116 model2 loss : 0.069750
[10:35:23.807] iteration 1883 : model1 loss : 0.455084 model2 loss : 0.089055
[10:35:23.997] iteration 1884 : model1 loss : 0.444577 model2 loss : 0.046690
[10:35:24.167] iteration 1885 : model1 loss : 0.447469 model2 loss : 0.053602
[10:35:24.351] iteration 1886 : model1 loss : 0.443860 model2 loss : 0.049787
[10:35:24.534] iteration 1887 : model1 loss : 0.444831 model2 loss : 0.059976
[10:35:24.714] iteration 1888 : model1 loss : 0.442556 model2 loss : 0.042223
[10:35:24.906] iteration 1889 : model1 loss : 0.447692 model2 loss : 0.055884
[10:35:25.078] iteration 1890 : model1 loss : 0.442276 model2 loss : 0.046803
[10:35:25.252] iteration 1891 : model1 loss : 0.438465 model2 loss : 0.039695
[10:35:25.426] iteration 1892 : model1 loss : 0.445235 model2 loss : 0.049496
[10:35:25.614] iteration 1893 : model1 loss : 0.437563 model2 loss : 0.044989
[10:35:25.793] iteration 1894 : model1 loss : 0.443112 model2 loss : 0.045385
[10:35:25.963] iteration 1895 : model1 loss : 0.441831 model2 loss : 0.043401
[10:35:26.137] iteration 1896 : model1 loss : 0.448946 model2 loss : 0.044597
[10:35:26.312] iteration 1897 : model1 loss : 0.450004 model2 loss : 0.065641
[10:35:26.502] iteration 1898 : model1 loss : 0.442729 model2 loss : 0.049138
[10:35:26.677] iteration 1899 : model1 loss : 0.444655 model2 loss : 0.044178
[10:35:26.876] iteration 1900 : model1 loss : 0.446896 model2 loss : 0.044520
[10:35:27.053] iteration 1901 : model1 loss : 0.445085 model2 loss : 0.054051
[10:35:27.251] iteration 1902 : model1 loss : 0.438384 model2 loss : 0.041186
[10:35:27.434] iteration 1903 : model1 loss : 0.443841 model2 loss : 0.044587
[10:35:27.625] iteration 1904 : model1 loss : 0.440111 model2 loss : 0.042560
[10:35:27.804] iteration 1905 : model1 loss : 0.445868 model2 loss : 0.051408
[10:35:27.984] iteration 1906 : model1 loss : 0.448277 model2 loss : 0.063059
[10:35:28.170] iteration 1907 : model1 loss : 0.448585 model2 loss : 0.050518
[10:35:28.352] iteration 1908 : model1 loss : 0.443253 model2 loss : 0.051731
[10:35:28.530] iteration 1909 : model1 loss : 0.447430 model2 loss : 0.051600
[10:35:28.706] iteration 1910 : model1 loss : 0.442779 model2 loss : 0.046079
[10:35:28.886] iteration 1911 : model1 loss : 0.447224 model2 loss : 0.052033
[10:35:29.065] iteration 1912 : model1 loss : 0.439124 model2 loss : 0.035103
[10:35:29.233] iteration 1913 : model1 loss : 0.444979 model2 loss : 0.045069
[10:35:29.411] iteration 1914 : model1 loss : 0.447048 model2 loss : 0.048221
[10:35:31.556] iteration 1915 : model1 loss : 0.445468 model2 loss : 0.057834
[10:35:31.732] iteration 1916 : model1 loss : 0.449305 model2 loss : 0.047925
[10:35:31.910] iteration 1917 : model1 loss : 0.439613 model2 loss : 0.037158
[10:35:32.083] iteration 1918 : model1 loss : 0.439785 model2 loss : 0.044996
[10:35:32.269] iteration 1919 : model1 loss : 0.441048 model2 loss : 0.054462
[10:35:32.458] iteration 1920 : model1 loss : 0.437161 model2 loss : 0.037535
[10:35:32.634] iteration 1921 : model1 loss : 0.442256 model2 loss : 0.037720
[10:35:32.808] iteration 1922 : model1 loss : 0.439837 model2 loss : 0.040515
[10:35:32.997] iteration 1923 : model1 loss : 0.453770 model2 loss : 0.043025
[10:35:33.172] iteration 1924 : model1 loss : 0.444884 model2 loss : 0.050764
[10:35:33.357] iteration 1925 : model1 loss : 0.449113 model2 loss : 0.055580
[10:35:33.534] iteration 1926 : model1 loss : 0.436556 model2 loss : 0.036308
[10:35:33.706] iteration 1927 : model1 loss : 0.446288 model2 loss : 0.045533
[10:35:33.882] iteration 1928 : model1 loss : 0.451304 model2 loss : 0.047292
[10:35:34.059] iteration 1929 : model1 loss : 0.451940 model2 loss : 0.063429
[10:35:34.236] iteration 1930 : model1 loss : 0.440348 model2 loss : 0.042610
[10:35:34.415] iteration 1931 : model1 loss : 0.443423 model2 loss : 0.039260
[10:35:34.586] iteration 1932 : model1 loss : 0.444138 model2 loss : 0.040912
[10:35:34.761] iteration 1933 : model1 loss : 0.440769 model2 loss : 0.035936
[10:35:34.945] iteration 1934 : model1 loss : 0.440419 model2 loss : 0.036124
[10:35:35.135] iteration 1935 : model1 loss : 0.448597 model2 loss : 0.073239
[10:35:35.311] iteration 1936 : model1 loss : 0.448545 model2 loss : 0.063861
[10:35:35.491] iteration 1937 : model1 loss : 0.447812 model2 loss : 0.051178
[10:35:35.661] iteration 1938 : model1 loss : 0.445240 model2 loss : 0.040811
[10:35:35.840] iteration 1939 : model1 loss : 0.449921 model2 loss : 0.045111
[10:35:36.011] iteration 1940 : model1 loss : 0.440327 model2 loss : 0.037197
[10:35:36.181] iteration 1941 : model1 loss : 0.442333 model2 loss : 0.049752
[10:35:36.358] iteration 1942 : model1 loss : 0.447691 model2 loss : 0.045298
[10:35:36.535] iteration 1943 : model1 loss : 0.453692 model2 loss : 0.055728
[10:35:36.703] iteration 1944 : model1 loss : 0.437545 model2 loss : 0.037062
[10:35:36.881] iteration 1945 : model1 loss : 0.442284 model2 loss : 0.037190
[10:35:37.049] iteration 1946 : model1 loss : 0.449414 model2 loss : 0.045566
[10:35:37.227] iteration 1947 : model1 loss : 0.446119 model2 loss : 0.053050
[10:35:39.313] iteration 1948 : model1 loss : 0.440407 model2 loss : 0.032699
[10:35:39.489] iteration 1949 : model1 loss : 0.445279 model2 loss : 0.041436
[10:35:39.668] iteration 1950 : model1 loss : 0.446413 model2 loss : 0.049336
[10:35:39.851] iteration 1951 : model1 loss : 0.445811 model2 loss : 0.044623
[10:35:40.040] iteration 1952 : model1 loss : 0.447563 model2 loss : 0.049670
[10:35:40.219] iteration 1953 : model1 loss : 0.438423 model2 loss : 0.034460
[10:35:40.397] iteration 1954 : model1 loss : 0.445627 model2 loss : 0.046745
[10:35:40.571] iteration 1955 : model1 loss : 0.436564 model2 loss : 0.034167
[10:35:40.742] iteration 1956 : model1 loss : 0.443680 model2 loss : 0.037704
[10:35:40.913] iteration 1957 : model1 loss : 0.445393 model2 loss : 0.041280
[10:35:41.100] iteration 1958 : model1 loss : 0.451899 model2 loss : 0.043435
[10:35:41.275] iteration 1959 : model1 loss : 0.442805 model2 loss : 0.047533
[10:35:41.450] iteration 1960 : model1 loss : 0.448641 model2 loss : 0.048579
[10:35:41.624] iteration 1961 : model1 loss : 0.453066 model2 loss : 0.052589
[10:35:41.805] iteration 1962 : model1 loss : 0.444535 model2 loss : 0.051895
[10:35:41.975] iteration 1963 : model1 loss : 0.443636 model2 loss : 0.038477
[10:35:42.152] iteration 1964 : model1 loss : 0.440591 model2 loss : 0.035865
[10:35:42.356] iteration 1965 : model1 loss : 0.445099 model2 loss : 0.040944
[10:35:42.545] iteration 1966 : model1 loss : 0.440263 model2 loss : 0.041481
[10:35:42.725] iteration 1967 : model1 loss : 0.444776 model2 loss : 0.044519
[10:35:42.903] iteration 1968 : model1 loss : 0.445891 model2 loss : 0.042269
[10:35:43.073] iteration 1969 : model1 loss : 0.446939 model2 loss : 0.054188
[10:35:43.245] iteration 1970 : model1 loss : 0.438780 model2 loss : 0.034857
[10:35:43.431] iteration 1971 : model1 loss : 0.445846 model2 loss : 0.040177
[10:35:43.619] iteration 1972 : model1 loss : 0.445764 model2 loss : 0.044921
[10:35:43.794] iteration 1973 : model1 loss : 0.444225 model2 loss : 0.042650
[10:35:43.964] iteration 1974 : model1 loss : 0.441591 model2 loss : 0.042099
[10:35:44.139] iteration 1975 : model1 loss : 0.447949 model2 loss : 0.042735
[10:35:44.322] iteration 1976 : model1 loss : 0.443923 model2 loss : 0.045089
[10:35:44.493] iteration 1977 : model1 loss : 0.450720 model2 loss : 0.052597
[10:35:44.668] iteration 1978 : model1 loss : 0.444381 model2 loss : 0.040312
[10:35:44.835] iteration 1979 : model1 loss : 0.447151 model2 loss : 0.043576
[10:35:45.006] iteration 1980 : model1 loss : 0.451553 model2 loss : 0.056830
[10:35:47.210] iteration 1981 : model1 loss : 0.436291 model2 loss : 0.032209
[10:35:47.388] iteration 1982 : model1 loss : 0.439906 model2 loss : 0.036438
[10:35:47.560] iteration 1983 : model1 loss : 0.443067 model2 loss : 0.040608
[10:35:47.737] iteration 1984 : model1 loss : 0.439239 model2 loss : 0.038272
[10:35:47.919] iteration 1985 : model1 loss : 0.442777 model2 loss : 0.041474
[10:35:48.100] iteration 1986 : model1 loss : 0.445423 model2 loss : 0.044762
[10:35:48.274] iteration 1987 : model1 loss : 0.447092 model2 loss : 0.045300
[10:35:48.463] iteration 1988 : model1 loss : 0.439768 model2 loss : 0.045531
[10:35:48.660] iteration 1989 : model1 loss : 0.442242 model2 loss : 0.037488
[10:35:48.830] iteration 1990 : model1 loss : 0.441493 model2 loss : 0.037159
[10:35:49.000] iteration 1991 : model1 loss : 0.443411 model2 loss : 0.038416
[10:35:49.170] iteration 1992 : model1 loss : 0.457949 model2 loss : 0.058411
[10:35:49.348] iteration 1993 : model1 loss : 0.441736 model2 loss : 0.036429
[10:35:49.518] iteration 1994 : model1 loss : 0.444378 model2 loss : 0.049319
[10:35:49.692] iteration 1995 : model1 loss : 0.454315 model2 loss : 0.060033
[10:35:49.866] iteration 1996 : model1 loss : 0.442896 model2 loss : 0.041006
[10:35:50.037] iteration 1997 : model1 loss : 0.442870 model2 loss : 0.044954
[10:35:50.207] iteration 1998 : model1 loss : 0.443242 model2 loss : 0.047999
[10:35:50.397] iteration 1999 : model1 loss : 0.441190 model2 loss : 0.033286
[10:35:50.580] iteration 2000 : model1 loss : 0.449376 model2 loss : 0.065845
[10:35:59.582] iteration 2000 : model1_mean_dice : 0.665263 model1_mean_hd95 : 6.038864
[10:36:08.532] iteration 2000 : model2_mean_dice : 0.847973 model2_mean_hd95 : 1.982305
[10:36:08.720] iteration 2001 : model1 loss : 0.440236 model2 loss : 0.036802
[10:36:08.916] iteration 2002 : model1 loss : 0.449550 model2 loss : 0.057775
[10:36:09.090] iteration 2003 : model1 loss : 0.440892 model2 loss : 0.043717
[10:36:09.272] iteration 2004 : model1 loss : 0.441068 model2 loss : 0.038026
[10:36:09.444] iteration 2005 : model1 loss : 0.441500 model2 loss : 0.038804
[10:36:09.625] iteration 2006 : model1 loss : 0.441044 model2 loss : 0.038835
[10:36:09.823] iteration 2007 : model1 loss : 0.446400 model2 loss : 0.042386
[10:36:10.029] iteration 2008 : model1 loss : 0.444358 model2 loss : 0.045769
[10:36:10.199] iteration 2009 : model1 loss : 0.441874 model2 loss : 0.039378
[10:36:10.374] iteration 2010 : model1 loss : 0.451372 model2 loss : 0.052427
[10:36:10.560] iteration 2011 : model1 loss : 0.449528 model2 loss : 0.054486
[10:36:10.730] iteration 2012 : model1 loss : 0.446013 model2 loss : 0.051949
[10:36:10.902] iteration 2013 : model1 loss : 0.446370 model2 loss : 0.043120
[10:36:13.319] iteration 2014 : model1 loss : 0.446032 model2 loss : 0.037212
[10:36:13.501] iteration 2015 : model1 loss : 0.442770 model2 loss : 0.035604
[10:36:13.681] iteration 2016 : model1 loss : 0.440968 model2 loss : 0.042353
[10:36:13.848] iteration 2017 : model1 loss : 0.444198 model2 loss : 0.049317
[10:36:14.018] iteration 2018 : model1 loss : 0.449726 model2 loss : 0.049071
[10:36:14.188] iteration 2019 : model1 loss : 0.441824 model2 loss : 0.046619
[10:36:14.361] iteration 2020 : model1 loss : 0.440087 model2 loss : 0.041201
[10:36:14.545] iteration 2021 : model1 loss : 0.440604 model2 loss : 0.040869
[10:36:14.719] iteration 2022 : model1 loss : 0.443137 model2 loss : 0.044973
[10:36:14.887] iteration 2023 : model1 loss : 0.450563 model2 loss : 0.067845
[10:36:15.058] iteration 2024 : model1 loss : 0.445904 model2 loss : 0.036948
[10:36:15.227] iteration 2025 : model1 loss : 0.445182 model2 loss : 0.041230
[10:36:15.401] iteration 2026 : model1 loss : 0.455471 model2 loss : 0.055896
[10:36:15.567] iteration 2027 : model1 loss : 0.451739 model2 loss : 0.063560
[10:36:15.742] iteration 2028 : model1 loss : 0.441868 model2 loss : 0.046544
[10:36:15.912] iteration 2029 : model1 loss : 0.443335 model2 loss : 0.039727
[10:36:16.083] iteration 2030 : model1 loss : 0.442146 model2 loss : 0.039578
[10:36:16.254] iteration 2031 : model1 loss : 0.438771 model2 loss : 0.038942
[10:36:16.427] iteration 2032 : model1 loss : 0.443958 model2 loss : 0.053159
[10:36:16.597] iteration 2033 : model1 loss : 0.440838 model2 loss : 0.043202
[10:36:16.772] iteration 2034 : model1 loss : 0.445455 model2 loss : 0.038718
[10:36:16.939] iteration 2035 : model1 loss : 0.451421 model2 loss : 0.050362
[10:36:17.111] iteration 2036 : model1 loss : 0.441522 model2 loss : 0.034327
[10:36:17.283] iteration 2037 : model1 loss : 0.447585 model2 loss : 0.054408
[10:36:17.454] iteration 2038 : model1 loss : 0.440642 model2 loss : 0.038377
[10:36:17.623] iteration 2039 : model1 loss : 0.448720 model2 loss : 0.050184
[10:36:17.795] iteration 2040 : model1 loss : 0.440750 model2 loss : 0.038449
[10:36:17.964] iteration 2041 : model1 loss : 0.447316 model2 loss : 0.044944
[10:36:18.136] iteration 2042 : model1 loss : 0.441194 model2 loss : 0.037845
[10:36:18.307] iteration 2043 : model1 loss : 0.448883 model2 loss : 0.036032
[10:36:18.478] iteration 2044 : model1 loss : 0.437969 model2 loss : 0.039163
[10:36:18.648] iteration 2045 : model1 loss : 0.444767 model2 loss : 0.042276
[10:36:18.820] iteration 2046 : model1 loss : 0.442468 model2 loss : 0.053969
[10:36:20.795] iteration 2047 : model1 loss : 0.438866 model2 loss : 0.037531
[10:36:20.964] iteration 2048 : model1 loss : 0.445336 model2 loss : 0.061526
[10:36:21.140] iteration 2049 : model1 loss : 0.440227 model2 loss : 0.044818
[10:36:21.308] iteration 2050 : model1 loss : 0.434126 model2 loss : 0.037656
[10:36:21.481] iteration 2051 : model1 loss : 0.441879 model2 loss : 0.038013
[10:36:21.649] iteration 2052 : model1 loss : 0.440952 model2 loss : 0.055563
[10:36:21.819] iteration 2053 : model1 loss : 0.450188 model2 loss : 0.049724
[10:36:21.988] iteration 2054 : model1 loss : 0.442215 model2 loss : 0.051701
[10:36:22.162] iteration 2055 : model1 loss : 0.447792 model2 loss : 0.043668
[10:36:22.345] iteration 2056 : model1 loss : 0.441297 model2 loss : 0.034450
[10:36:22.519] iteration 2057 : model1 loss : 0.447561 model2 loss : 0.067631
[10:36:22.689] iteration 2058 : model1 loss : 0.443559 model2 loss : 0.048503
[10:36:22.862] iteration 2059 : model1 loss : 0.445415 model2 loss : 0.057389
[10:36:23.028] iteration 2060 : model1 loss : 0.443909 model2 loss : 0.045403
[10:36:23.201] iteration 2061 : model1 loss : 0.447864 model2 loss : 0.047967
[10:36:23.369] iteration 2062 : model1 loss : 0.436552 model2 loss : 0.036819
[10:36:23.555] iteration 2063 : model1 loss : 0.442574 model2 loss : 0.041052
[10:36:23.725] iteration 2064 : model1 loss : 0.447394 model2 loss : 0.057935
[10:36:23.899] iteration 2065 : model1 loss : 0.447602 model2 loss : 0.055869
[10:36:24.065] iteration 2066 : model1 loss : 0.453241 model2 loss : 0.047800
[10:36:24.235] iteration 2067 : model1 loss : 0.445158 model2 loss : 0.035432
[10:36:24.404] iteration 2068 : model1 loss : 0.441565 model2 loss : 0.045084
[10:36:24.577] iteration 2069 : model1 loss : 0.442366 model2 loss : 0.038692
[10:36:24.749] iteration 2070 : model1 loss : 0.445625 model2 loss : 0.048186
[10:36:24.924] iteration 2071 : model1 loss : 0.445330 model2 loss : 0.049211
[10:36:25.089] iteration 2072 : model1 loss : 0.448909 model2 loss : 0.044394
[10:36:25.264] iteration 2073 : model1 loss : 0.443977 model2 loss : 0.038935
[10:36:25.431] iteration 2074 : model1 loss : 0.441433 model2 loss : 0.039215
[10:36:25.603] iteration 2075 : model1 loss : 0.440686 model2 loss : 0.042821
[10:36:25.774] iteration 2076 : model1 loss : 0.445282 model2 loss : 0.040384
[10:36:25.946] iteration 2077 : model1 loss : 0.442000 model2 loss : 0.038522
[10:36:26.112] iteration 2078 : model1 loss : 0.437141 model2 loss : 0.037430
[10:36:26.283] iteration 2079 : model1 loss : 0.449109 model2 loss : 0.057618
[10:36:28.272] iteration 2080 : model1 loss : 0.446848 model2 loss : 0.038950
[10:36:28.442] iteration 2081 : model1 loss : 0.440205 model2 loss : 0.037431
[10:36:28.616] iteration 2082 : model1 loss : 0.441998 model2 loss : 0.049188
[10:36:28.787] iteration 2083 : model1 loss : 0.437897 model2 loss : 0.034727
[10:36:28.959] iteration 2084 : model1 loss : 0.440706 model2 loss : 0.038463
[10:36:29.125] iteration 2085 : model1 loss : 0.454539 model2 loss : 0.058536
[10:36:29.299] iteration 2086 : model1 loss : 0.450420 model2 loss : 0.059244
[10:36:29.465] iteration 2087 : model1 loss : 0.451516 model2 loss : 0.055026
[10:36:29.639] iteration 2088 : model1 loss : 0.444998 model2 loss : 0.062440
[10:36:29.809] iteration 2089 : model1 loss : 0.438644 model2 loss : 0.036707
[10:36:29.980] iteration 2090 : model1 loss : 0.442123 model2 loss : 0.036170
[10:36:30.150] iteration 2091 : model1 loss : 0.447555 model2 loss : 0.051846
[10:36:30.323] iteration 2092 : model1 loss : 0.441180 model2 loss : 0.041082
[10:36:30.491] iteration 2093 : model1 loss : 0.448114 model2 loss : 0.049175
[10:36:30.664] iteration 2094 : model1 loss : 0.449161 model2 loss : 0.043936
[10:36:30.855] iteration 2095 : model1 loss : 0.447552 model2 loss : 0.045487
[10:36:31.028] iteration 2096 : model1 loss : 0.437957 model2 loss : 0.034543
[10:36:31.197] iteration 2097 : model1 loss : 0.444798 model2 loss : 0.049873
[10:36:31.370] iteration 2098 : model1 loss : 0.440443 model2 loss : 0.032053
[10:36:31.542] iteration 2099 : model1 loss : 0.440828 model2 loss : 0.038887
[10:36:31.714] iteration 2100 : model1 loss : 0.443441 model2 loss : 0.051815
[10:36:31.882] iteration 2101 : model1 loss : 0.440469 model2 loss : 0.044823
[10:36:32.052] iteration 2102 : model1 loss : 0.446995 model2 loss : 0.065082
[10:36:32.223] iteration 2103 : model1 loss : 0.443841 model2 loss : 0.043982
[10:36:32.394] iteration 2104 : model1 loss : 0.438667 model2 loss : 0.037398
[10:36:32.561] iteration 2105 : model1 loss : 0.439146 model2 loss : 0.033903
[10:36:32.733] iteration 2106 : model1 loss : 0.449458 model2 loss : 0.047734
[10:36:32.903] iteration 2107 : model1 loss : 0.447582 model2 loss : 0.054175
[10:36:33.075] iteration 2108 : model1 loss : 0.450374 model2 loss : 0.053886
[10:36:33.246] iteration 2109 : model1 loss : 0.438541 model2 loss : 0.033526
[10:36:33.419] iteration 2110 : model1 loss : 0.452388 model2 loss : 0.063108
[10:36:33.584] iteration 2111 : model1 loss : 0.440766 model2 loss : 0.039586
[10:36:33.754] iteration 2112 : model1 loss : 0.439622 model2 loss : 0.032601
[10:36:35.721] iteration 2113 : model1 loss : 0.450220 model2 loss : 0.040865
[10:36:35.896] iteration 2114 : model1 loss : 0.444009 model2 loss : 0.042816
[10:36:36.067] iteration 2115 : model1 loss : 0.439783 model2 loss : 0.048608
[10:36:36.236] iteration 2116 : model1 loss : 0.446625 model2 loss : 0.053760
[10:36:36.409] iteration 2117 : model1 loss : 0.436796 model2 loss : 0.031590
[10:36:36.577] iteration 2118 : model1 loss : 0.445298 model2 loss : 0.043053
[10:36:36.749] iteration 2119 : model1 loss : 0.439079 model2 loss : 0.043292
[10:36:36.920] iteration 2120 : model1 loss : 0.441866 model2 loss : 0.040554
[10:36:37.093] iteration 2121 : model1 loss : 0.443682 model2 loss : 0.042110
[10:36:37.262] iteration 2122 : model1 loss : 0.444693 model2 loss : 0.047237
[10:36:37.433] iteration 2123 : model1 loss : 0.446103 model2 loss : 0.041656
[10:36:37.600] iteration 2124 : model1 loss : 0.438576 model2 loss : 0.034411
[10:36:37.771] iteration 2125 : model1 loss : 0.445618 model2 loss : 0.042193
[10:36:37.941] iteration 2126 : model1 loss : 0.441098 model2 loss : 0.043610
[10:36:38.112] iteration 2127 : model1 loss : 0.441086 model2 loss : 0.040185
[10:36:38.284] iteration 2128 : model1 loss : 0.448037 model2 loss : 0.045390
[10:36:38.456] iteration 2129 : model1 loss : 0.442037 model2 loss : 0.040799
[10:36:38.622] iteration 2130 : model1 loss : 0.439872 model2 loss : 0.036546
[10:36:38.805] iteration 2131 : model1 loss : 0.444685 model2 loss : 0.038706
[10:36:38.974] iteration 2132 : model1 loss : 0.450027 model2 loss : 0.058907
[10:36:39.149] iteration 2133 : model1 loss : 0.447313 model2 loss : 0.063632
[10:36:39.319] iteration 2134 : model1 loss : 0.447327 model2 loss : 0.058729
[10:36:39.491] iteration 2135 : model1 loss : 0.443181 model2 loss : 0.042358
[10:36:39.659] iteration 2136 : model1 loss : 0.444279 model2 loss : 0.046666
[10:36:39.832] iteration 2137 : model1 loss : 0.442999 model2 loss : 0.044512
[10:36:40.002] iteration 2138 : model1 loss : 0.441944 model2 loss : 0.045562
[10:36:40.174] iteration 2139 : model1 loss : 0.445344 model2 loss : 0.048634
[10:36:40.344] iteration 2140 : model1 loss : 0.443112 model2 loss : 0.053340
[10:36:40.519] iteration 2141 : model1 loss : 0.440472 model2 loss : 0.039141
[10:36:40.688] iteration 2142 : model1 loss : 0.449284 model2 loss : 0.052158
[10:36:40.862] iteration 2143 : model1 loss : 0.437832 model2 loss : 0.040753
[10:36:41.029] iteration 2144 : model1 loss : 0.446634 model2 loss : 0.053417
[10:36:41.202] iteration 2145 : model1 loss : 0.441709 model2 loss : 0.044461
[10:36:43.193] iteration 2146 : model1 loss : 0.451006 model2 loss : 0.051561
[10:36:43.364] iteration 2147 : model1 loss : 0.442109 model2 loss : 0.047071
[10:36:43.537] iteration 2148 : model1 loss : 0.444548 model2 loss : 0.040257
[10:36:43.707] iteration 2149 : model1 loss : 0.446641 model2 loss : 0.069079
[10:36:43.880] iteration 2150 : model1 loss : 0.442677 model2 loss : 0.049299
[10:36:44.048] iteration 2151 : model1 loss : 0.445474 model2 loss : 0.053806
[10:36:44.220] iteration 2152 : model1 loss : 0.441729 model2 loss : 0.041326
[10:36:44.398] iteration 2153 : model1 loss : 0.439338 model2 loss : 0.040121
[10:36:44.568] iteration 2154 : model1 loss : 0.444292 model2 loss : 0.041698
[10:36:44.737] iteration 2155 : model1 loss : 0.438113 model2 loss : 0.038154
[10:36:44.913] iteration 2156 : model1 loss : 0.447488 model2 loss : 0.044854
[10:36:45.079] iteration 2157 : model1 loss : 0.442820 model2 loss : 0.047122
[10:36:45.251] iteration 2158 : model1 loss : 0.442655 model2 loss : 0.040818
[10:36:45.418] iteration 2159 : model1 loss : 0.440769 model2 loss : 0.041786
[10:36:45.589] iteration 2160 : model1 loss : 0.449001 model2 loss : 0.064278
[10:36:45.757] iteration 2161 : model1 loss : 0.450608 model2 loss : 0.065261
[10:36:45.931] iteration 2162 : model1 loss : 0.443668 model2 loss : 0.043384
[10:36:46.098] iteration 2163 : model1 loss : 0.442226 model2 loss : 0.041836
[10:36:46.270] iteration 2164 : model1 loss : 0.447831 model2 loss : 0.051870
[10:36:46.437] iteration 2165 : model1 loss : 0.435431 model2 loss : 0.036099
[10:36:46.609] iteration 2166 : model1 loss : 0.442790 model2 loss : 0.046665
[10:36:46.780] iteration 2167 : model1 loss : 0.444192 model2 loss : 0.048535
[10:36:46.950] iteration 2168 : model1 loss : 0.441161 model2 loss : 0.035816
[10:36:47.117] iteration 2169 : model1 loss : 0.439065 model2 loss : 0.040241
[10:36:47.294] iteration 2170 : model1 loss : 0.445613 model2 loss : 0.042418
[10:36:47.462] iteration 2171 : model1 loss : 0.444004 model2 loss : 0.040323
[10:36:47.633] iteration 2172 : model1 loss : 0.446442 model2 loss : 0.044066
[10:36:47.801] iteration 2173 : model1 loss : 0.441058 model2 loss : 0.041546
[10:36:47.971] iteration 2174 : model1 loss : 0.447704 model2 loss : 0.054580
[10:36:48.137] iteration 2175 : model1 loss : 0.446124 model2 loss : 0.056616
[10:36:48.312] iteration 2176 : model1 loss : 0.441807 model2 loss : 0.043758
[10:36:48.478] iteration 2177 : model1 loss : 0.437426 model2 loss : 0.035995
[10:36:48.649] iteration 2178 : model1 loss : 0.445045 model2 loss : 0.043348
[10:36:50.611] iteration 2179 : model1 loss : 0.447298 model2 loss : 0.039319
[10:36:50.782] iteration 2180 : model1 loss : 0.440197 model2 loss : 0.034481
[10:36:50.956] iteration 2181 : model1 loss : 0.445602 model2 loss : 0.049682
[10:36:51.123] iteration 2182 : model1 loss : 0.443336 model2 loss : 0.039599
[10:36:51.298] iteration 2183 : model1 loss : 0.437579 model2 loss : 0.035119
[10:36:51.466] iteration 2184 : model1 loss : 0.440778 model2 loss : 0.042400
[10:36:51.637] iteration 2185 : model1 loss : 0.446802 model2 loss : 0.051893
[10:36:51.807] iteration 2186 : model1 loss : 0.446770 model2 loss : 0.039588
[10:36:51.979] iteration 2187 : model1 loss : 0.445315 model2 loss : 0.046312
[10:36:52.151] iteration 2188 : model1 loss : 0.440124 model2 loss : 0.041942
[10:36:52.324] iteration 2189 : model1 loss : 0.454721 model2 loss : 0.061036
[10:36:52.491] iteration 2190 : model1 loss : 0.442222 model2 loss : 0.038826
[10:36:52.663] iteration 2191 : model1 loss : 0.436389 model2 loss : 0.038675
[10:36:52.832] iteration 2192 : model1 loss : 0.452931 model2 loss : 0.042655
[10:36:53.005] iteration 2193 : model1 loss : 0.441567 model2 loss : 0.044721
[10:36:53.174] iteration 2194 : model1 loss : 0.442526 model2 loss : 0.037828
[10:36:53.348] iteration 2195 : model1 loss : 0.443091 model2 loss : 0.042239
[10:36:53.518] iteration 2196 : model1 loss : 0.446502 model2 loss : 0.051626
[10:36:53.693] iteration 2197 : model1 loss : 0.445587 model2 loss : 0.042074
[10:36:53.864] iteration 2198 : model1 loss : 0.453957 model2 loss : 0.057148
[10:36:54.036] iteration 2199 : model1 loss : 0.442241 model2 loss : 0.035695
[10:36:54.206] iteration 2200 : model1 loss : 0.449581 model2 loss : 0.057866
[10:36:54.380] iteration 2201 : model1 loss : 0.440301 model2 loss : 0.038755
[10:36:54.549] iteration 2202 : model1 loss : 0.448404 model2 loss : 0.044805
[10:36:54.722] iteration 2203 : model1 loss : 0.441778 model2 loss : 0.047241
[10:36:54.889] iteration 2204 : model1 loss : 0.440431 model2 loss : 0.037527
[10:36:55.062] iteration 2205 : model1 loss : 0.440222 model2 loss : 0.035982
[10:36:55.231] iteration 2206 : model1 loss : 0.449742 model2 loss : 0.042745
[10:36:55.404] iteration 2207 : model1 loss : 0.449079 model2 loss : 0.059699
[10:36:55.572] iteration 2208 : model1 loss : 0.449009 model2 loss : 0.047809
[10:36:55.747] iteration 2209 : model1 loss : 0.438746 model2 loss : 0.039046
[10:36:55.918] iteration 2210 : model1 loss : 0.438668 model2 loss : 0.036851
[10:36:56.088] iteration 2211 : model1 loss : 0.436530 model2 loss : 0.038525
[10:36:58.075] iteration 2212 : model1 loss : 0.443917 model2 loss : 0.041060
[10:36:58.246] iteration 2213 : model1 loss : 0.441484 model2 loss : 0.045807
[10:36:58.424] iteration 2214 : model1 loss : 0.449485 model2 loss : 0.057662
[10:36:58.592] iteration 2215 : model1 loss : 0.445042 model2 loss : 0.040718
[10:36:58.764] iteration 2216 : model1 loss : 0.448742 model2 loss : 0.047566
[10:36:58.933] iteration 2217 : model1 loss : 0.442718 model2 loss : 0.041612
[10:36:59.107] iteration 2218 : model1 loss : 0.442822 model2 loss : 0.037429
[10:36:59.277] iteration 2219 : model1 loss : 0.444596 model2 loss : 0.053828
[10:36:59.449] iteration 2220 : model1 loss : 0.444865 model2 loss : 0.044175
[10:36:59.616] iteration 2221 : model1 loss : 0.443517 model2 loss : 0.039076
[10:36:59.789] iteration 2222 : model1 loss : 0.442696 model2 loss : 0.052267
[10:36:59.958] iteration 2223 : model1 loss : 0.443988 model2 loss : 0.036633
[10:37:00.137] iteration 2224 : model1 loss : 0.440308 model2 loss : 0.040890
[10:37:00.309] iteration 2225 : model1 loss : 0.443772 model2 loss : 0.043511
[10:37:00.482] iteration 2226 : model1 loss : 0.439624 model2 loss : 0.041318
[10:37:00.649] iteration 2227 : model1 loss : 0.438436 model2 loss : 0.036638
[10:37:00.822] iteration 2228 : model1 loss : 0.441102 model2 loss : 0.039986
[10:37:00.990] iteration 2229 : model1 loss : 0.443978 model2 loss : 0.042258
[10:37:01.163] iteration 2230 : model1 loss : 0.437436 model2 loss : 0.031149
[10:37:01.333] iteration 2231 : model1 loss : 0.451246 model2 loss : 0.054503
[10:37:01.507] iteration 2232 : model1 loss : 0.442739 model2 loss : 0.045151
[10:37:01.675] iteration 2233 : model1 loss : 0.444571 model2 loss : 0.061839
[10:37:01.849] iteration 2234 : model1 loss : 0.445148 model2 loss : 0.052897
[10:37:02.015] iteration 2235 : model1 loss : 0.446674 model2 loss : 0.049667
[10:37:02.188] iteration 2236 : model1 loss : 0.445298 model2 loss : 0.045011
[10:37:02.356] iteration 2237 : model1 loss : 0.443530 model2 loss : 0.045856
[10:37:02.531] iteration 2238 : model1 loss : 0.445286 model2 loss : 0.040897
[10:37:02.701] iteration 2239 : model1 loss : 0.437186 model2 loss : 0.039506
[10:37:02.873] iteration 2240 : model1 loss : 0.443750 model2 loss : 0.049606
[10:37:03.042] iteration 2241 : model1 loss : 0.436712 model2 loss : 0.036088
[10:37:03.215] iteration 2242 : model1 loss : 0.440889 model2 loss : 0.041077
[10:37:03.384] iteration 2243 : model1 loss : 0.439588 model2 loss : 0.041304
[10:37:03.556] iteration 2244 : model1 loss : 0.438948 model2 loss : 0.035513
[10:37:05.542] iteration 2245 : model1 loss : 0.438742 model2 loss : 0.032986
[10:37:05.712] iteration 2246 : model1 loss : 0.443936 model2 loss : 0.043621
[10:37:05.890] iteration 2247 : model1 loss : 0.443647 model2 loss : 0.041901
[10:37:06.056] iteration 2248 : model1 loss : 0.444935 model2 loss : 0.042924
[10:37:06.229] iteration 2249 : model1 loss : 0.448538 model2 loss : 0.043521
[10:37:06.400] iteration 2250 : model1 loss : 0.442788 model2 loss : 0.046678
[10:37:06.572] iteration 2251 : model1 loss : 0.438178 model2 loss : 0.038402
[10:37:06.740] iteration 2252 : model1 loss : 0.445338 model2 loss : 0.036056
[10:37:06.916] iteration 2253 : model1 loss : 0.438463 model2 loss : 0.038370
[10:37:07.083] iteration 2254 : model1 loss : 0.443930 model2 loss : 0.044649
[10:37:07.256] iteration 2255 : model1 loss : 0.441725 model2 loss : 0.036657
[10:37:07.424] iteration 2256 : model1 loss : 0.443465 model2 loss : 0.035907
[10:37:07.599] iteration 2257 : model1 loss : 0.458353 model2 loss : 0.060017
[10:37:07.769] iteration 2258 : model1 loss : 0.443822 model2 loss : 0.057962
[10:37:07.946] iteration 2259 : model1 loss : 0.441209 model2 loss : 0.038837
[10:37:08.113] iteration 2260 : model1 loss : 0.440701 model2 loss : 0.040190
[10:37:08.286] iteration 2261 : model1 loss : 0.445913 model2 loss : 0.044083
[10:37:08.454] iteration 2262 : model1 loss : 0.444473 model2 loss : 0.043269
[10:37:08.624] iteration 2263 : model1 loss : 0.444714 model2 loss : 0.048207
[10:37:08.795] iteration 2264 : model1 loss : 0.440569 model2 loss : 0.031225
[10:37:08.967] iteration 2265 : model1 loss : 0.443020 model2 loss : 0.038669
[10:37:09.134] iteration 2266 : model1 loss : 0.447073 model2 loss : 0.051807
[10:37:09.309] iteration 2267 : model1 loss : 0.439989 model2 loss : 0.036608
[10:37:09.477] iteration 2268 : model1 loss : 0.440463 model2 loss : 0.032621
[10:37:09.649] iteration 2269 : model1 loss : 0.445962 model2 loss : 0.040301
[10:37:09.819] iteration 2270 : model1 loss : 0.447198 model2 loss : 0.037136
[10:37:09.992] iteration 2271 : model1 loss : 0.439136 model2 loss : 0.037849
[10:37:10.161] iteration 2272 : model1 loss : 0.438263 model2 loss : 0.029208
[10:37:10.339] iteration 2273 : model1 loss : 0.442689 model2 loss : 0.045251
[10:37:10.509] iteration 2274 : model1 loss : 0.451523 model2 loss : 0.046731
[10:37:10.684] iteration 2275 : model1 loss : 0.443034 model2 loss : 0.038797
[10:37:10.854] iteration 2276 : model1 loss : 0.444675 model2 loss : 0.050359
[10:37:11.024] iteration 2277 : model1 loss : 0.445141 model2 loss : 0.043999
[10:37:13.023] iteration 2278 : model1 loss : 0.444101 model2 loss : 0.038065
[10:37:13.194] iteration 2279 : model1 loss : 0.445392 model2 loss : 0.038131
[10:37:13.370] iteration 2280 : model1 loss : 0.442568 model2 loss : 0.036461
[10:37:13.539] iteration 2281 : model1 loss : 0.449177 model2 loss : 0.062823
[10:37:13.713] iteration 2282 : model1 loss : 0.442770 model2 loss : 0.040654
[10:37:13.882] iteration 2283 : model1 loss : 0.440743 model2 loss : 0.038547
[10:37:14.054] iteration 2284 : model1 loss : 0.443656 model2 loss : 0.040793
[10:37:14.225] iteration 2285 : model1 loss : 0.437159 model2 loss : 0.032793
[10:37:14.399] iteration 2286 : model1 loss : 0.445386 model2 loss : 0.049917
[10:37:14.567] iteration 2287 : model1 loss : 0.441064 model2 loss : 0.033881
[10:37:14.739] iteration 2288 : model1 loss : 0.443760 model2 loss : 0.041535
[10:37:14.910] iteration 2289 : model1 loss : 0.443014 model2 loss : 0.035668
[10:37:15.081] iteration 2290 : model1 loss : 0.438865 model2 loss : 0.037571
[10:37:15.253] iteration 2291 : model1 loss : 0.438061 model2 loss : 0.032492
[10:37:15.423] iteration 2292 : model1 loss : 0.446042 model2 loss : 0.041709
[10:37:15.592] iteration 2293 : model1 loss : 0.445188 model2 loss : 0.045504
[10:37:15.765] iteration 2294 : model1 loss : 0.440160 model2 loss : 0.037299
[10:37:15.934] iteration 2295 : model1 loss : 0.442493 model2 loss : 0.039089
[10:37:16.108] iteration 2296 : model1 loss : 0.446931 model2 loss : 0.043356
[10:37:16.280] iteration 2297 : model1 loss : 0.442102 model2 loss : 0.036031
[10:37:16.452] iteration 2298 : model1 loss : 0.446006 model2 loss : 0.043738
[10:37:16.620] iteration 2299 : model1 loss : 0.439423 model2 loss : 0.042267
[10:37:16.794] iteration 2300 : model1 loss : 0.440279 model2 loss : 0.036927
[10:37:16.963] iteration 2301 : model1 loss : 0.443633 model2 loss : 0.037373
[10:37:17.136] iteration 2302 : model1 loss : 0.446478 model2 loss : 0.039707
[10:37:17.308] iteration 2303 : model1 loss : 0.449247 model2 loss : 0.040954
[10:37:17.479] iteration 2304 : model1 loss : 0.443542 model2 loss : 0.038901
[10:37:17.649] iteration 2305 : model1 loss : 0.444325 model2 loss : 0.034579
[10:37:17.824] iteration 2306 : model1 loss : 0.443687 model2 loss : 0.037175
[10:37:17.992] iteration 2307 : model1 loss : 0.443986 model2 loss : 0.039031
[10:37:18.169] iteration 2308 : model1 loss : 0.443227 model2 loss : 0.034880
[10:37:18.341] iteration 2309 : model1 loss : 0.445959 model2 loss : 0.043033
[10:37:18.517] iteration 2310 : model1 loss : 0.441205 model2 loss : 0.034231
[10:37:20.486] iteration 2311 : model1 loss : 0.447227 model2 loss : 0.041594
[10:37:20.659] iteration 2312 : model1 loss : 0.449937 model2 loss : 0.053148
[10:37:20.839] iteration 2313 : model1 loss : 0.452785 model2 loss : 0.039969
[10:37:21.006] iteration 2314 : model1 loss : 0.443112 model2 loss : 0.037077
[10:37:21.178] iteration 2315 : model1 loss : 0.436424 model2 loss : 0.031351
[10:37:21.349] iteration 2316 : model1 loss : 0.440447 model2 loss : 0.040016
[10:37:21.522] iteration 2317 : model1 loss : 0.441013 model2 loss : 0.037485
[10:37:21.692] iteration 2318 : model1 loss : 0.436819 model2 loss : 0.032379
[10:37:21.864] iteration 2319 : model1 loss : 0.451086 model2 loss : 0.052128
[10:37:22.036] iteration 2320 : model1 loss : 0.444206 model2 loss : 0.034697
[10:37:22.211] iteration 2321 : model1 loss : 0.437164 model2 loss : 0.033695
[10:37:22.382] iteration 2322 : model1 loss : 0.445645 model2 loss : 0.052200
[10:37:22.554] iteration 2323 : model1 loss : 0.440514 model2 loss : 0.036366
[10:37:22.724] iteration 2324 : model1 loss : 0.444275 model2 loss : 0.045306
[10:37:22.895] iteration 2325 : model1 loss : 0.437259 model2 loss : 0.040967
[10:37:23.065] iteration 2326 : model1 loss : 0.441998 model2 loss : 0.034333
[10:37:23.239] iteration 2327 : model1 loss : 0.440497 model2 loss : 0.040080
[10:37:23.409] iteration 2328 : model1 loss : 0.440311 model2 loss : 0.039596
[10:37:23.580] iteration 2329 : model1 loss : 0.441888 model2 loss : 0.042139
[10:37:23.750] iteration 2330 : model1 loss : 0.442001 model2 loss : 0.038985
[10:37:23.926] iteration 2331 : model1 loss : 0.450835 model2 loss : 0.041153
[10:37:24.095] iteration 2332 : model1 loss : 0.444741 model2 loss : 0.035778
[10:37:24.271] iteration 2333 : model1 loss : 0.436093 model2 loss : 0.030351
[10:37:24.441] iteration 2334 : model1 loss : 0.443176 model2 loss : 0.033125
[10:37:24.613] iteration 2335 : model1 loss : 0.437343 model2 loss : 0.032977
[10:37:24.784] iteration 2336 : model1 loss : 0.439813 model2 loss : 0.049758
[10:37:24.955] iteration 2337 : model1 loss : 0.438367 model2 loss : 0.042552
[10:37:25.124] iteration 2338 : model1 loss : 0.447665 model2 loss : 0.040702
[10:37:25.296] iteration 2339 : model1 loss : 0.445329 model2 loss : 0.038466
[10:37:25.464] iteration 2340 : model1 loss : 0.443501 model2 loss : 0.039720
[10:37:25.638] iteration 2341 : model1 loss : 0.449957 model2 loss : 0.042866
[10:37:25.809] iteration 2342 : model1 loss : 0.439787 model2 loss : 0.038851
[10:37:25.983] iteration 2343 : model1 loss : 0.445938 model2 loss : 0.037832
[10:37:28.017] iteration 2344 : model1 loss : 0.439869 model2 loss : 0.031683
[10:37:28.190] iteration 2345 : model1 loss : 0.443843 model2 loss : 0.038968
[10:37:28.368] iteration 2346 : model1 loss : 0.439086 model2 loss : 0.033331
[10:37:28.536] iteration 2347 : model1 loss : 0.441451 model2 loss : 0.043135
[10:37:28.712] iteration 2348 : model1 loss : 0.449136 model2 loss : 0.057923
[10:37:28.883] iteration 2349 : model1 loss : 0.440227 model2 loss : 0.038413
[10:37:29.053] iteration 2350 : model1 loss : 0.448943 model2 loss : 0.039347
[10:37:29.226] iteration 2351 : model1 loss : 0.439401 model2 loss : 0.034977
[10:37:29.399] iteration 2352 : model1 loss : 0.446029 model2 loss : 0.042279
[10:37:29.566] iteration 2353 : model1 loss : 0.452603 model2 loss : 0.038650
[10:37:29.741] iteration 2354 : model1 loss : 0.442384 model2 loss : 0.037816
[10:37:29.914] iteration 2355 : model1 loss : 0.436747 model2 loss : 0.037428
[10:37:30.085] iteration 2356 : model1 loss : 0.442991 model2 loss : 0.041798
[10:37:30.258] iteration 2357 : model1 loss : 0.447148 model2 loss : 0.036727
[10:37:30.434] iteration 2358 : model1 loss : 0.438970 model2 loss : 0.032002
[10:37:30.604] iteration 2359 : model1 loss : 0.450417 model2 loss : 0.056808
[10:37:30.780] iteration 2360 : model1 loss : 0.451617 model2 loss : 0.045523
[10:37:30.948] iteration 2361 : model1 loss : 0.447153 model2 loss : 0.041531
[10:37:31.119] iteration 2362 : model1 loss : 0.439206 model2 loss : 0.034255
[10:37:31.289] iteration 2363 : model1 loss : 0.444191 model2 loss : 0.044647
[10:37:31.466] iteration 2364 : model1 loss : 0.438568 model2 loss : 0.032263
[10:37:31.633] iteration 2365 : model1 loss : 0.448359 model2 loss : 0.046178
[10:37:31.806] iteration 2366 : model1 loss : 0.441097 model2 loss : 0.044747
[10:37:31.976] iteration 2367 : model1 loss : 0.440639 model2 loss : 0.040799
[10:37:32.148] iteration 2368 : model1 loss : 0.449024 model2 loss : 0.043236
[10:37:32.319] iteration 2369 : model1 loss : 0.444655 model2 loss : 0.037550
[10:37:32.495] iteration 2370 : model1 loss : 0.443019 model2 loss : 0.045627
[10:37:32.663] iteration 2371 : model1 loss : 0.441786 model2 loss : 0.036961
[10:37:32.837] iteration 2372 : model1 loss : 0.437223 model2 loss : 0.031140
[10:37:33.004] iteration 2373 : model1 loss : 0.448221 model2 loss : 0.049420
[10:37:33.179] iteration 2374 : model1 loss : 0.445646 model2 loss : 0.039573
[10:37:33.350] iteration 2375 : model1 loss : 0.437794 model2 loss : 0.032609
[10:37:33.522] iteration 2376 : model1 loss : 0.448223 model2 loss : 0.040494
[10:37:35.497] iteration 2377 : model1 loss : 0.443055 model2 loss : 0.040470
[10:37:35.664] iteration 2378 : model1 loss : 0.448426 model2 loss : 0.053543
[10:37:35.845] iteration 2379 : model1 loss : 0.441472 model2 loss : 0.037446
[10:37:36.012] iteration 2380 : model1 loss : 0.440990 model2 loss : 0.045334
[10:37:36.186] iteration 2381 : model1 loss : 0.446370 model2 loss : 0.063344
[10:37:36.365] iteration 2382 : model1 loss : 0.446649 model2 loss : 0.047553
[10:37:36.542] iteration 2383 : model1 loss : 0.445369 model2 loss : 0.041671
[10:37:36.710] iteration 2384 : model1 loss : 0.441808 model2 loss : 0.038194
[10:37:36.881] iteration 2385 : model1 loss : 0.442284 model2 loss : 0.047473
[10:37:37.049] iteration 2386 : model1 loss : 0.433582 model2 loss : 0.034373
[10:37:37.225] iteration 2387 : model1 loss : 0.444740 model2 loss : 0.038534
[10:37:37.396] iteration 2388 : model1 loss : 0.441591 model2 loss : 0.036901
[10:37:37.569] iteration 2389 : model1 loss : 0.444552 model2 loss : 0.039916
[10:37:37.738] iteration 2390 : model1 loss : 0.442681 model2 loss : 0.037095
[10:37:37.915] iteration 2391 : model1 loss : 0.439789 model2 loss : 0.034407
[10:37:38.083] iteration 2392 : model1 loss : 0.442138 model2 loss : 0.037664
[10:37:38.258] iteration 2393 : model1 loss : 0.438400 model2 loss : 0.032962
[10:37:38.431] iteration 2394 : model1 loss : 0.453097 model2 loss : 0.052776
[10:37:38.605] iteration 2395 : model1 loss : 0.448002 model2 loss : 0.039661
[10:37:38.775] iteration 2396 : model1 loss : 0.442426 model2 loss : 0.037734
[10:37:38.948] iteration 2397 : model1 loss : 0.443432 model2 loss : 0.040689
[10:37:39.116] iteration 2398 : model1 loss : 0.436968 model2 loss : 0.038635
[10:37:39.289] iteration 2399 : model1 loss : 0.439194 model2 loss : 0.036048
[10:37:39.460] iteration 2400 : model1 loss : 0.445287 model2 loss : 0.031205
[10:37:39.634] iteration 2401 : model1 loss : 0.444342 model2 loss : 0.042344
[10:37:39.804] iteration 2402 : model1 loss : 0.441429 model2 loss : 0.036993
[10:37:39.975] iteration 2403 : model1 loss : 0.446342 model2 loss : 0.041252
[10:37:40.146] iteration 2404 : model1 loss : 0.438991 model2 loss : 0.030032
[10:37:40.318] iteration 2405 : model1 loss : 0.445712 model2 loss : 0.042422
[10:37:40.487] iteration 2406 : model1 loss : 0.442814 model2 loss : 0.033040
[10:37:40.659] iteration 2407 : model1 loss : 0.437174 model2 loss : 0.030812
[10:37:40.831] iteration 2408 : model1 loss : 0.441431 model2 loss : 0.032719
[10:37:41.001] iteration 2409 : model1 loss : 0.439766 model2 loss : 0.032661
[10:37:42.973] iteration 2410 : model1 loss : 0.444682 model2 loss : 0.049673
[10:37:43.140] iteration 2411 : model1 loss : 0.438648 model2 loss : 0.037471
[10:37:43.315] iteration 2412 : model1 loss : 0.448054 model2 loss : 0.047148
[10:37:43.482] iteration 2413 : model1 loss : 0.446911 model2 loss : 0.050835
[10:37:43.653] iteration 2414 : model1 loss : 0.440452 model2 loss : 0.035717
[10:37:43.824] iteration 2415 : model1 loss : 0.439913 model2 loss : 0.035128
[10:37:43.996] iteration 2416 : model1 loss : 0.444197 model2 loss : 0.035565
[10:37:44.163] iteration 2417 : model1 loss : 0.442873 model2 loss : 0.039147
[10:37:44.339] iteration 2418 : model1 loss : 0.441739 model2 loss : 0.036912
[10:37:44.509] iteration 2419 : model1 loss : 0.437096 model2 loss : 0.035891
[10:37:44.680] iteration 2420 : model1 loss : 0.442131 model2 loss : 0.039358
[10:37:44.851] iteration 2421 : model1 loss : 0.443880 model2 loss : 0.035604
[10:37:45.021] iteration 2422 : model1 loss : 0.435996 model2 loss : 0.032467
[10:37:45.190] iteration 2423 : model1 loss : 0.441794 model2 loss : 0.037545
[10:37:45.365] iteration 2424 : model1 loss : 0.448235 model2 loss : 0.045493
[10:37:45.546] iteration 2425 : model1 loss : 0.447372 model2 loss : 0.036935
[10:37:45.721] iteration 2426 : model1 loss : 0.440023 model2 loss : 0.037102
[10:37:45.893] iteration 2427 : model1 loss : 0.441014 model2 loss : 0.035813
[10:37:46.065] iteration 2428 : model1 loss : 0.439315 model2 loss : 0.036676
[10:37:46.236] iteration 2429 : model1 loss : 0.448518 model2 loss : 0.033225
[10:37:46.411] iteration 2430 : model1 loss : 0.441959 model2 loss : 0.040810
[10:37:46.579] iteration 2431 : model1 loss : 0.437348 model2 loss : 0.033867
[10:37:46.753] iteration 2432 : model1 loss : 0.441725 model2 loss : 0.032691
[10:37:46.924] iteration 2433 : model1 loss : 0.446554 model2 loss : 0.040174
[10:37:47.096] iteration 2434 : model1 loss : 0.441701 model2 loss : 0.035901
[10:37:47.267] iteration 2435 : model1 loss : 0.440658 model2 loss : 0.042063
[10:37:47.444] iteration 2436 : model1 loss : 0.438737 model2 loss : 0.034952
[10:37:47.612] iteration 2437 : model1 loss : 0.446756 model2 loss : 0.036335
[10:37:47.785] iteration 2438 : model1 loss : 0.442286 model2 loss : 0.037465
[10:37:47.954] iteration 2439 : model1 loss : 0.446870 model2 loss : 0.045103
[10:37:48.126] iteration 2440 : model1 loss : 0.441058 model2 loss : 0.041425
[10:37:48.295] iteration 2441 : model1 loss : 0.447354 model2 loss : 0.033733
[10:37:48.467] iteration 2442 : model1 loss : 0.444921 model2 loss : 0.036010
[10:37:50.483] iteration 2443 : model1 loss : 0.437815 model2 loss : 0.035081
[10:37:50.659] iteration 2444 : model1 loss : 0.439262 model2 loss : 0.031758
[10:37:50.836] iteration 2445 : model1 loss : 0.442147 model2 loss : 0.034488
[10:37:51.001] iteration 2446 : model1 loss : 0.437490 model2 loss : 0.031033
[10:37:51.172] iteration 2447 : model1 loss : 0.442641 model2 loss : 0.034428
[10:37:51.345] iteration 2448 : model1 loss : 0.442320 model2 loss : 0.032701
[10:37:51.518] iteration 2449 : model1 loss : 0.444132 model2 loss : 0.040459
[10:37:51.686] iteration 2450 : model1 loss : 0.448140 model2 loss : 0.044047
[10:37:51.858] iteration 2451 : model1 loss : 0.441704 model2 loss : 0.036903
[10:37:52.026] iteration 2452 : model1 loss : 0.438779 model2 loss : 0.035751
[10:37:52.197] iteration 2453 : model1 loss : 0.437239 model2 loss : 0.032968
[10:37:52.369] iteration 2454 : model1 loss : 0.437961 model2 loss : 0.034188
[10:37:52.540] iteration 2455 : model1 loss : 0.460250 model2 loss : 0.054855
[10:37:52.709] iteration 2456 : model1 loss : 0.442005 model2 loss : 0.042996
[10:37:52.885] iteration 2457 : model1 loss : 0.437604 model2 loss : 0.035235
[10:37:53.053] iteration 2458 : model1 loss : 0.445555 model2 loss : 0.041772
[10:37:53.227] iteration 2459 : model1 loss : 0.446963 model2 loss : 0.045608
[10:37:53.397] iteration 2460 : model1 loss : 0.444161 model2 loss : 0.036009
[10:37:53.570] iteration 2461 : model1 loss : 0.435444 model2 loss : 0.032805
[10:37:53.740] iteration 2462 : model1 loss : 0.442905 model2 loss : 0.043746
[10:37:53.917] iteration 2463 : model1 loss : 0.443305 model2 loss : 0.044626
[10:37:54.085] iteration 2464 : model1 loss : 0.441160 model2 loss : 0.033469
[10:37:54.259] iteration 2465 : model1 loss : 0.437497 model2 loss : 0.036730
[10:37:54.428] iteration 2466 : model1 loss : 0.445429 model2 loss : 0.039362
[10:37:54.603] iteration 2467 : model1 loss : 0.446380 model2 loss : 0.047294
[10:37:54.773] iteration 2468 : model1 loss : 0.445273 model2 loss : 0.040532
[10:37:54.948] iteration 2469 : model1 loss : 0.447229 model2 loss : 0.058472
[10:37:55.116] iteration 2470 : model1 loss : 0.442539 model2 loss : 0.047335
[10:37:55.300] iteration 2471 : model1 loss : 0.437656 model2 loss : 0.036852
[10:37:55.470] iteration 2472 : model1 loss : 0.443720 model2 loss : 0.042574
[10:37:55.643] iteration 2473 : model1 loss : 0.440923 model2 loss : 0.039251
[10:37:55.813] iteration 2474 : model1 loss : 0.443670 model2 loss : 0.041213
[10:37:55.986] iteration 2475 : model1 loss : 0.441176 model2 loss : 0.037478
[10:37:57.947] iteration 2476 : model1 loss : 0.441483 model2 loss : 0.043947
[10:37:58.125] iteration 2477 : model1 loss : 0.436930 model2 loss : 0.034170
[10:37:58.301] iteration 2478 : model1 loss : 0.441502 model2 loss : 0.037792
[10:37:58.468] iteration 2479 : model1 loss : 0.441428 model2 loss : 0.042470
[10:37:58.643] iteration 2480 : model1 loss : 0.439562 model2 loss : 0.038503
[10:37:58.812] iteration 2481 : model1 loss : 0.450444 model2 loss : 0.049147
[10:37:58.985] iteration 2482 : model1 loss : 0.444459 model2 loss : 0.048739
[10:37:59.151] iteration 2483 : model1 loss : 0.436554 model2 loss : 0.034506
[10:37:59.327] iteration 2484 : model1 loss : 0.436190 model2 loss : 0.033568
[10:37:59.496] iteration 2485 : model1 loss : 0.438583 model2 loss : 0.034642
[10:37:59.670] iteration 2486 : model1 loss : 0.439812 model2 loss : 0.041461
[10:37:59.840] iteration 2487 : model1 loss : 0.443899 model2 loss : 0.037981
[10:38:00.011] iteration 2488 : model1 loss : 0.439576 model2 loss : 0.034696
[10:38:00.183] iteration 2489 : model1 loss : 0.443016 model2 loss : 0.041681
[10:38:00.355] iteration 2490 : model1 loss : 0.444406 model2 loss : 0.042406
[10:38:00.525] iteration 2491 : model1 loss : 0.438602 model2 loss : 0.037614
[10:38:00.696] iteration 2492 : model1 loss : 0.441613 model2 loss : 0.039091
[10:38:00.870] iteration 2493 : model1 loss : 0.439499 model2 loss : 0.033379
[10:38:01.044] iteration 2494 : model1 loss : 0.446525 model2 loss : 0.046690
[10:38:01.212] iteration 2495 : model1 loss : 0.440522 model2 loss : 0.036914
[10:38:01.386] iteration 2496 : model1 loss : 0.439194 model2 loss : 0.043918
[10:38:01.554] iteration 2497 : model1 loss : 0.451157 model2 loss : 0.044153
[10:38:01.724] iteration 2498 : model1 loss : 0.441065 model2 loss : 0.045375
[10:38:01.897] iteration 2499 : model1 loss : 0.444879 model2 loss : 0.056029
[10:38:02.071] iteration 2500 : model1 loss : 0.442458 model2 loss : 0.041303
[10:38:02.240] iteration 2501 : model1 loss : 0.448127 model2 loss : 0.042264
[10:38:02.415] iteration 2502 : model1 loss : 0.442691 model2 loss : 0.040338
[10:38:02.583] iteration 2503 : model1 loss : 0.447742 model2 loss : 0.045003
[10:38:02.758] iteration 2504 : model1 loss : 0.443953 model2 loss : 0.043136
[10:38:02.929] iteration 2505 : model1 loss : 0.442975 model2 loss : 0.035007
[10:38:03.100] iteration 2506 : model1 loss : 0.442907 model2 loss : 0.044482
[10:38:03.269] iteration 2507 : model1 loss : 0.447828 model2 loss : 0.043344
[10:38:03.445] iteration 2508 : model1 loss : 0.440794 model2 loss : 0.043879
[10:38:05.404] iteration 2509 : model1 loss : 0.440178 model2 loss : 0.037182
[10:38:05.576] iteration 2510 : model1 loss : 0.438752 model2 loss : 0.040477
[10:38:05.751] iteration 2511 : model1 loss : 0.444188 model2 loss : 0.036338
[10:38:05.922] iteration 2512 : model1 loss : 0.447627 model2 loss : 0.048339
[10:38:06.096] iteration 2513 : model1 loss : 0.439993 model2 loss : 0.040175
[10:38:06.265] iteration 2514 : model1 loss : 0.445070 model2 loss : 0.042748
[10:38:06.441] iteration 2515 : model1 loss : 0.442839 model2 loss : 0.042826
[10:38:06.610] iteration 2516 : model1 loss : 0.436883 model2 loss : 0.037116
[10:38:06.783] iteration 2517 : model1 loss : 0.441561 model2 loss : 0.032803
[10:38:06.955] iteration 2518 : model1 loss : 0.443772 model2 loss : 0.041771
[10:38:07.126] iteration 2519 : model1 loss : 0.450215 model2 loss : 0.046164
[10:38:07.296] iteration 2520 : model1 loss : 0.443879 model2 loss : 0.039203
[10:38:07.471] iteration 2521 : model1 loss : 0.455416 model2 loss : 0.048560
[10:38:07.639] iteration 2522 : model1 loss : 0.441507 model2 loss : 0.033912
[10:38:07.813] iteration 2523 : model1 loss : 0.443564 model2 loss : 0.035016
[10:38:07.982] iteration 2524 : model1 loss : 0.443981 model2 loss : 0.036986
[10:38:08.155] iteration 2525 : model1 loss : 0.446939 model2 loss : 0.041312
[10:38:08.326] iteration 2526 : model1 loss : 0.442486 model2 loss : 0.038703
[10:38:08.501] iteration 2527 : model1 loss : 0.438937 model2 loss : 0.035845
[10:38:08.668] iteration 2528 : model1 loss : 0.446558 model2 loss : 0.042704
[10:38:08.843] iteration 2529 : model1 loss : 0.445032 model2 loss : 0.041797
[10:38:09.011] iteration 2530 : model1 loss : 0.437853 model2 loss : 0.033778
[10:38:09.183] iteration 2531 : model1 loss : 0.446015 model2 loss : 0.041647
[10:38:09.352] iteration 2532 : model1 loss : 0.450880 model2 loss : 0.049883
[10:38:09.526] iteration 2533 : model1 loss : 0.439573 model2 loss : 0.039378
[10:38:09.694] iteration 2534 : model1 loss : 0.440339 model2 loss : 0.038123
[10:38:09.867] iteration 2535 : model1 loss : 0.438058 model2 loss : 0.035325
[10:38:10.035] iteration 2536 : model1 loss : 0.446660 model2 loss : 0.043497
[10:38:10.208] iteration 2537 : model1 loss : 0.447434 model2 loss : 0.064103
[10:38:10.380] iteration 2538 : model1 loss : 0.442592 model2 loss : 0.038978
[10:38:10.552] iteration 2539 : model1 loss : 0.440824 model2 loss : 0.040234
[10:38:10.718] iteration 2540 : model1 loss : 0.439650 model2 loss : 0.038700
[10:38:10.892] iteration 2541 : model1 loss : 0.439536 model2 loss : 0.036932
[10:38:12.865] iteration 2542 : model1 loss : 0.441845 model2 loss : 0.045646
[10:38:13.035] iteration 2543 : model1 loss : 0.441316 model2 loss : 0.046692
[10:38:13.210] iteration 2544 : model1 loss : 0.434000 model2 loss : 0.033933
[10:38:13.381] iteration 2545 : model1 loss : 0.446245 model2 loss : 0.047281
[10:38:13.554] iteration 2546 : model1 loss : 0.455682 model2 loss : 0.048747
[10:38:13.721] iteration 2547 : model1 loss : 0.441472 model2 loss : 0.028822
[10:38:13.894] iteration 2548 : model1 loss : 0.440581 model2 loss : 0.043631
[10:38:14.063] iteration 2549 : model1 loss : 0.442293 model2 loss : 0.040075
[10:38:14.236] iteration 2550 : model1 loss : 0.437954 model2 loss : 0.037999
[10:38:14.408] iteration 2551 : model1 loss : 0.442227 model2 loss : 0.035814
[10:38:14.582] iteration 2552 : model1 loss : 0.436092 model2 loss : 0.036960
[10:38:14.750] iteration 2553 : model1 loss : 0.446027 model2 loss : 0.040946
[10:38:14.929] iteration 2554 : model1 loss : 0.442077 model2 loss : 0.038986
[10:38:15.097] iteration 2555 : model1 loss : 0.439142 model2 loss : 0.035911
[10:38:15.274] iteration 2556 : model1 loss : 0.443772 model2 loss : 0.035622
[10:38:15.445] iteration 2557 : model1 loss : 0.445588 model2 loss : 0.037071
[10:38:15.618] iteration 2558 : model1 loss : 0.441812 model2 loss : 0.039374
[10:38:15.788] iteration 2559 : model1 loss : 0.447964 model2 loss : 0.052424
[10:38:15.961] iteration 2560 : model1 loss : 0.440935 model2 loss : 0.041669
[10:38:16.128] iteration 2561 : model1 loss : 0.442467 model2 loss : 0.035568
[10:38:16.305] iteration 2562 : model1 loss : 0.443328 model2 loss : 0.040105
[10:38:16.476] iteration 2563 : model1 loss : 0.437326 model2 loss : 0.033662
[10:38:16.647] iteration 2564 : model1 loss : 0.437294 model2 loss : 0.037173
[10:38:16.817] iteration 2565 : model1 loss : 0.437868 model2 loss : 0.035304
[10:38:16.989] iteration 2566 : model1 loss : 0.445655 model2 loss : 0.043074
[10:38:17.157] iteration 2567 : model1 loss : 0.442211 model2 loss : 0.034423
[10:38:17.335] iteration 2568 : model1 loss : 0.448758 model2 loss : 0.038178
[10:38:17.505] iteration 2569 : model1 loss : 0.438858 model2 loss : 0.043745
[10:38:17.680] iteration 2570 : model1 loss : 0.440026 model2 loss : 0.043736
[10:38:17.851] iteration 2571 : model1 loss : 0.446058 model2 loss : 0.051587
[10:38:18.023] iteration 2572 : model1 loss : 0.442950 model2 loss : 0.036376
[10:38:18.190] iteration 2573 : model1 loss : 0.441879 model2 loss : 0.042534
[10:38:18.364] iteration 2574 : model1 loss : 0.441155 model2 loss : 0.044312
[10:38:20.351] iteration 2575 : model1 loss : 0.441676 model2 loss : 0.055693
[10:38:20.526] iteration 2576 : model1 loss : 0.440028 model2 loss : 0.037426
[10:38:20.700] iteration 2577 : model1 loss : 0.445062 model2 loss : 0.054334
[10:38:20.874] iteration 2578 : model1 loss : 0.436336 model2 loss : 0.030786
[10:38:21.047] iteration 2579 : model1 loss : 0.435520 model2 loss : 0.035560
[10:38:21.214] iteration 2580 : model1 loss : 0.444770 model2 loss : 0.039977
[10:38:21.386] iteration 2581 : model1 loss : 0.452178 model2 loss : 0.054706
[10:38:21.555] iteration 2582 : model1 loss : 0.436129 model2 loss : 0.034827
[10:38:21.726] iteration 2583 : model1 loss : 0.442137 model2 loss : 0.044037
[10:38:21.898] iteration 2584 : model1 loss : 0.438129 model2 loss : 0.037131
[10:38:22.072] iteration 2585 : model1 loss : 0.447390 model2 loss : 0.052009
[10:38:22.240] iteration 2586 : model1 loss : 0.443163 model2 loss : 0.050756
[10:38:22.415] iteration 2587 : model1 loss : 0.443350 model2 loss : 0.046257
[10:38:22.586] iteration 2588 : model1 loss : 0.441009 model2 loss : 0.036085
[10:38:22.756] iteration 2589 : model1 loss : 0.445426 model2 loss : 0.048217
[10:38:22.929] iteration 2590 : model1 loss : 0.436302 model2 loss : 0.035383
[10:38:23.104] iteration 2591 : model1 loss : 0.451207 model2 loss : 0.059365
[10:38:23.272] iteration 2592 : model1 loss : 0.438971 model2 loss : 0.044137
[10:38:23.447] iteration 2593 : model1 loss : 0.437519 model2 loss : 0.034017
[10:38:23.624] iteration 2594 : model1 loss : 0.437250 model2 loss : 0.038041
[10:38:23.799] iteration 2595 : model1 loss : 0.447299 model2 loss : 0.051618
[10:38:23.969] iteration 2596 : model1 loss : 0.439959 model2 loss : 0.038385
[10:38:24.143] iteration 2597 : model1 loss : 0.442071 model2 loss : 0.034386
[10:38:24.312] iteration 2598 : model1 loss : 0.441205 model2 loss : 0.035291
[10:38:24.485] iteration 2599 : model1 loss : 0.440498 model2 loss : 0.039146
[10:38:24.652] iteration 2600 : model1 loss : 0.435665 model2 loss : 0.036427
[10:38:24.826] iteration 2601 : model1 loss : 0.449148 model2 loss : 0.046638
[10:38:24.995] iteration 2602 : model1 loss : 0.449671 model2 loss : 0.048948
[10:38:25.167] iteration 2603 : model1 loss : 0.448428 model2 loss : 0.047289
[10:38:25.337] iteration 2604 : model1 loss : 0.439421 model2 loss : 0.039646
[10:38:25.515] iteration 2605 : model1 loss : 0.438975 model2 loss : 0.040226
[10:38:25.682] iteration 2606 : model1 loss : 0.440368 model2 loss : 0.042573
[10:38:25.857] iteration 2607 : model1 loss : 0.443136 model2 loss : 0.033510
[10:38:27.797] iteration 2608 : model1 loss : 0.447063 model2 loss : 0.049793
[10:38:27.964] iteration 2609 : model1 loss : 0.448040 model2 loss : 0.049295
[10:38:28.140] iteration 2610 : model1 loss : 0.436515 model2 loss : 0.036054
[10:38:28.310] iteration 2611 : model1 loss : 0.441313 model2 loss : 0.040047
[10:38:28.484] iteration 2612 : model1 loss : 0.445926 model2 loss : 0.041988
[10:38:28.653] iteration 2613 : model1 loss : 0.435765 model2 loss : 0.036557
[10:38:28.827] iteration 2614 : model1 loss : 0.440334 model2 loss : 0.041939
[10:38:28.993] iteration 2615 : model1 loss : 0.440940 model2 loss : 0.034636
[10:38:29.166] iteration 2616 : model1 loss : 0.442666 model2 loss : 0.040322
[10:38:29.338] iteration 2617 : model1 loss : 0.440274 model2 loss : 0.043715
[10:38:29.515] iteration 2618 : model1 loss : 0.443808 model2 loss : 0.039044
[10:38:29.683] iteration 2619 : model1 loss : 0.445198 model2 loss : 0.050409
[10:38:29.858] iteration 2620 : model1 loss : 0.438139 model2 loss : 0.037239
[10:38:30.027] iteration 2621 : model1 loss : 0.446005 model2 loss : 0.046863
[10:38:30.202] iteration 2622 : model1 loss : 0.448332 model2 loss : 0.056839
[10:38:30.372] iteration 2623 : model1 loss : 0.434018 model2 loss : 0.029260
[10:38:30.549] iteration 2624 : model1 loss : 0.441512 model2 loss : 0.036215
[10:38:30.717] iteration 2625 : model1 loss : 0.436895 model2 loss : 0.034112
[10:38:30.890] iteration 2626 : model1 loss : 0.434222 model2 loss : 0.038668
[10:38:31.059] iteration 2627 : model1 loss : 0.448440 model2 loss : 0.042005
[10:38:31.230] iteration 2628 : model1 loss : 0.445631 model2 loss : 0.046272
[10:38:31.402] iteration 2629 : model1 loss : 0.438952 model2 loss : 0.035520
[10:38:31.579] iteration 2630 : model1 loss : 0.439153 model2 loss : 0.036886
[10:38:31.746] iteration 2631 : model1 loss : 0.440457 model2 loss : 0.047331
[10:38:31.923] iteration 2632 : model1 loss : 0.434246 model2 loss : 0.028172
[10:38:32.091] iteration 2633 : model1 loss : 0.442943 model2 loss : 0.040782
[10:38:32.264] iteration 2634 : model1 loss : 0.446132 model2 loss : 0.052046
[10:38:32.436] iteration 2635 : model1 loss : 0.443546 model2 loss : 0.038848
[10:38:32.607] iteration 2636 : model1 loss : 0.446179 model2 loss : 0.043510
[10:38:32.778] iteration 2637 : model1 loss : 0.440712 model2 loss : 0.043650
[10:38:32.952] iteration 2638 : model1 loss : 0.440624 model2 loss : 0.038363
[10:38:33.120] iteration 2639 : model1 loss : 0.443319 model2 loss : 0.038838
[10:38:33.292] iteration 2640 : model1 loss : 0.438290 model2 loss : 0.039907
[10:38:35.239] iteration 2641 : model1 loss : 0.434062 model2 loss : 0.030447
[10:38:35.412] iteration 2642 : model1 loss : 0.447053 model2 loss : 0.050199
[10:38:35.589] iteration 2643 : model1 loss : 0.437654 model2 loss : 0.031832
[10:38:35.756] iteration 2644 : model1 loss : 0.442525 model2 loss : 0.040450
[10:38:35.932] iteration 2645 : model1 loss : 0.433967 model2 loss : 0.031400
[10:38:36.101] iteration 2646 : model1 loss : 0.440236 model2 loss : 0.041036
[10:38:36.276] iteration 2647 : model1 loss : 0.438171 model2 loss : 0.035398
[10:38:36.447] iteration 2648 : model1 loss : 0.440883 model2 loss : 0.041437
[10:38:36.620] iteration 2649 : model1 loss : 0.442314 model2 loss : 0.035761
[10:38:36.788] iteration 2650 : model1 loss : 0.449708 model2 loss : 0.041983
[10:38:36.964] iteration 2651 : model1 loss : 0.441329 model2 loss : 0.038364
[10:38:37.133] iteration 2652 : model1 loss : 0.445904 model2 loss : 0.049970
[10:38:37.307] iteration 2653 : model1 loss : 0.445426 model2 loss : 0.045298
[10:38:37.480] iteration 2654 : model1 loss : 0.438062 model2 loss : 0.035727
[10:38:37.653] iteration 2655 : model1 loss : 0.443754 model2 loss : 0.037249
[10:38:37.824] iteration 2656 : model1 loss : 0.451224 model2 loss : 0.069335
[10:38:37.996] iteration 2657 : model1 loss : 0.442664 model2 loss : 0.047844
[10:38:38.166] iteration 2658 : model1 loss : 0.441780 model2 loss : 0.035600
[10:38:38.340] iteration 2659 : model1 loss : 0.442252 model2 loss : 0.037760
[10:38:38.512] iteration 2660 : model1 loss : 0.443886 model2 loss : 0.037541
[10:38:38.684] iteration 2661 : model1 loss : 0.443855 model2 loss : 0.038589
[10:38:38.855] iteration 2662 : model1 loss : 0.444180 model2 loss : 0.033626
[10:38:39.027] iteration 2663 : model1 loss : 0.440144 model2 loss : 0.038943
[10:38:39.195] iteration 2664 : model1 loss : 0.445290 model2 loss : 0.038375
[10:38:39.368] iteration 2665 : model1 loss : 0.444402 model2 loss : 0.046522
[10:38:39.537] iteration 2666 : model1 loss : 0.440469 model2 loss : 0.038366
[10:38:39.712] iteration 2667 : model1 loss : 0.435513 model2 loss : 0.033038
[10:38:39.883] iteration 2668 : model1 loss : 0.446046 model2 loss : 0.054889
[10:38:40.056] iteration 2669 : model1 loss : 0.436396 model2 loss : 0.038286
[10:38:40.224] iteration 2670 : model1 loss : 0.442442 model2 loss : 0.037093
[10:38:40.397] iteration 2671 : model1 loss : 0.441121 model2 loss : 0.039795
[10:38:40.566] iteration 2672 : model1 loss : 0.441487 model2 loss : 0.037389
[10:38:40.739] iteration 2673 : model1 loss : 0.440626 model2 loss : 0.039512
[10:38:42.721] iteration 2674 : model1 loss : 0.442113 model2 loss : 0.036360
[10:38:42.893] iteration 2675 : model1 loss : 0.442685 model2 loss : 0.040118
[10:38:43.069] iteration 2676 : model1 loss : 0.435598 model2 loss : 0.035093
[10:38:43.237] iteration 2677 : model1 loss : 0.443141 model2 loss : 0.051804
[10:38:43.409] iteration 2678 : model1 loss : 0.438360 model2 loss : 0.037393
[10:38:43.577] iteration 2679 : model1 loss : 0.442423 model2 loss : 0.040476
[10:38:43.748] iteration 2680 : model1 loss : 0.437544 model2 loss : 0.037661
[10:38:43.929] iteration 2681 : model1 loss : 0.442433 model2 loss : 0.047059
[10:38:44.103] iteration 2682 : model1 loss : 0.444975 model2 loss : 0.044188
[10:38:44.272] iteration 2683 : model1 loss : 0.439367 model2 loss : 0.038885
[10:38:44.447] iteration 2684 : model1 loss : 0.440164 model2 loss : 0.037758
[10:38:44.616] iteration 2685 : model1 loss : 0.444835 model2 loss : 0.038617
[10:38:44.786] iteration 2686 : model1 loss : 0.438093 model2 loss : 0.036925
[10:38:44.958] iteration 2687 : model1 loss : 0.444231 model2 loss : 0.040912
[10:38:45.132] iteration 2688 : model1 loss : 0.440039 model2 loss : 0.035305
[10:38:45.300] iteration 2689 : model1 loss : 0.437308 model2 loss : 0.034310
[10:38:45.476] iteration 2690 : model1 loss : 0.445666 model2 loss : 0.045767
[10:38:45.645] iteration 2691 : model1 loss : 0.439838 model2 loss : 0.035771
[10:38:45.820] iteration 2692 : model1 loss : 0.437921 model2 loss : 0.039154
[10:38:45.990] iteration 2693 : model1 loss : 0.441801 model2 loss : 0.042894
[10:38:46.162] iteration 2694 : model1 loss : 0.438732 model2 loss : 0.038614
[10:38:46.332] iteration 2695 : model1 loss : 0.442097 model2 loss : 0.039941
[10:38:46.506] iteration 2696 : model1 loss : 0.445051 model2 loss : 0.044349
[10:38:46.675] iteration 2697 : model1 loss : 0.445944 model2 loss : 0.037646
[10:38:46.848] iteration 2698 : model1 loss : 0.446884 model2 loss : 0.050137
[10:38:47.018] iteration 2699 : model1 loss : 0.443800 model2 loss : 0.036519
[10:38:47.190] iteration 2700 : model1 loss : 0.440635 model2 loss : 0.035947
[10:38:47.362] iteration 2701 : model1 loss : 0.439567 model2 loss : 0.035108
[10:38:47.538] iteration 2702 : model1 loss : 0.440465 model2 loss : 0.041090
[10:38:47.708] iteration 2703 : model1 loss : 0.439129 model2 loss : 0.043388
[10:38:47.880] iteration 2704 : model1 loss : 0.436220 model2 loss : 0.032096
[10:38:48.050] iteration 2705 : model1 loss : 0.441097 model2 loss : 0.034319
[10:38:48.220] iteration 2706 : model1 loss : 0.438426 model2 loss : 0.033408
[10:38:50.172] iteration 2707 : model1 loss : 0.440912 model2 loss : 0.036993
[10:38:50.341] iteration 2708 : model1 loss : 0.442448 model2 loss : 0.045709
[10:38:50.520] iteration 2709 : model1 loss : 0.439166 model2 loss : 0.034503
[10:38:50.688] iteration 2710 : model1 loss : 0.441260 model2 loss : 0.039781
[10:38:50.866] iteration 2711 : model1 loss : 0.443457 model2 loss : 0.040672
[10:38:51.034] iteration 2712 : model1 loss : 0.443546 model2 loss : 0.044015
[10:38:51.205] iteration 2713 : model1 loss : 0.442933 model2 loss : 0.037722
[10:38:51.377] iteration 2714 : model1 loss : 0.437814 model2 loss : 0.036450
[10:38:51.552] iteration 2715 : model1 loss : 0.437692 model2 loss : 0.029478
[10:38:51.719] iteration 2716 : model1 loss : 0.448265 model2 loss : 0.050884
[10:38:51.895] iteration 2717 : model1 loss : 0.441175 model2 loss : 0.043201
[10:38:52.064] iteration 2718 : model1 loss : 0.443623 model2 loss : 0.045442
[10:38:52.237] iteration 2719 : model1 loss : 0.447528 model2 loss : 0.045176
[10:38:52.411] iteration 2720 : model1 loss : 0.434890 model2 loss : 0.032287
[10:38:52.585] iteration 2721 : model1 loss : 0.443154 model2 loss : 0.038221
[10:38:52.753] iteration 2722 : model1 loss : 0.446302 model2 loss : 0.041595
[10:38:52.928] iteration 2723 : model1 loss : 0.440629 model2 loss : 0.037860
[10:38:53.096] iteration 2724 : model1 loss : 0.438996 model2 loss : 0.036955
[10:38:53.268] iteration 2725 : model1 loss : 0.444861 model2 loss : 0.039038
[10:38:53.439] iteration 2726 : model1 loss : 0.437921 model2 loss : 0.031822
[10:38:53.610] iteration 2727 : model1 loss : 0.442975 model2 loss : 0.036473
[10:38:53.779] iteration 2728 : model1 loss : 0.440656 model2 loss : 0.040103
[10:38:53.952] iteration 2729 : model1 loss : 0.437554 model2 loss : 0.032747
[10:38:54.120] iteration 2730 : model1 loss : 0.441244 model2 loss : 0.040931
[10:38:54.292] iteration 2731 : model1 loss : 0.441519 model2 loss : 0.034115
[10:38:54.464] iteration 2732 : model1 loss : 0.444877 model2 loss : 0.042688
[10:38:54.636] iteration 2733 : model1 loss : 0.438823 model2 loss : 0.031091
[10:38:54.804] iteration 2734 : model1 loss : 0.439022 model2 loss : 0.035490
[10:38:54.979] iteration 2735 : model1 loss : 0.442108 model2 loss : 0.045933
[10:38:55.147] iteration 2736 : model1 loss : 0.440477 model2 loss : 0.041787
[10:38:55.319] iteration 2737 : model1 loss : 0.442326 model2 loss : 0.039700
[10:38:55.489] iteration 2738 : model1 loss : 0.444700 model2 loss : 0.049424
[10:38:55.661] iteration 2739 : model1 loss : 0.439022 model2 loss : 0.039421
[10:38:57.675] iteration 2740 : model1 loss : 0.442538 model2 loss : 0.034709
[10:38:57.850] iteration 2741 : model1 loss : 0.445060 model2 loss : 0.044553
[10:38:58.028] iteration 2742 : model1 loss : 0.444501 model2 loss : 0.037560
[10:38:58.195] iteration 2743 : model1 loss : 0.443732 model2 loss : 0.034914
[10:38:58.371] iteration 2744 : model1 loss : 0.445976 model2 loss : 0.038512
[10:38:58.541] iteration 2745 : model1 loss : 0.435849 model2 loss : 0.038002
[10:38:58.712] iteration 2746 : model1 loss : 0.443642 model2 loss : 0.035781
[10:38:58.885] iteration 2747 : model1 loss : 0.435396 model2 loss : 0.032876
[10:38:59.071] iteration 2748 : model1 loss : 0.446741 model2 loss : 0.041400
[10:38:59.243] iteration 2749 : model1 loss : 0.442105 model2 loss : 0.035845
[10:38:59.418] iteration 2750 : model1 loss : 0.442544 model2 loss : 0.035708
[10:38:59.586] iteration 2751 : model1 loss : 0.443066 model2 loss : 0.040662
[10:38:59.759] iteration 2752 : model1 loss : 0.436122 model2 loss : 0.030999
[10:38:59.932] iteration 2753 : model1 loss : 0.440861 model2 loss : 0.040480
[10:39:00.106] iteration 2754 : model1 loss : 0.439212 model2 loss : 0.031891
[10:39:00.282] iteration 2755 : model1 loss : 0.438725 model2 loss : 0.031323
[10:39:00.456] iteration 2756 : model1 loss : 0.440973 model2 loss : 0.050159
[10:39:00.625] iteration 2757 : model1 loss : 0.443253 model2 loss : 0.031250
[10:39:00.801] iteration 2758 : model1 loss : 0.439898 model2 loss : 0.036809
[10:39:00.971] iteration 2759 : model1 loss : 0.441982 model2 loss : 0.033276
[10:39:01.145] iteration 2760 : model1 loss : 0.442115 model2 loss : 0.036072
[10:39:01.315] iteration 2761 : model1 loss : 0.438546 model2 loss : 0.037425
[10:39:01.491] iteration 2762 : model1 loss : 0.442126 model2 loss : 0.036520
[10:39:01.660] iteration 2763 : model1 loss : 0.437610 model2 loss : 0.038919
[10:39:01.833] iteration 2764 : model1 loss : 0.436086 model2 loss : 0.036817
[10:39:02.003] iteration 2765 : model1 loss : 0.442060 model2 loss : 0.033209
[10:39:02.177] iteration 2766 : model1 loss : 0.437352 model2 loss : 0.034440
[10:39:02.345] iteration 2767 : model1 loss : 0.436879 model2 loss : 0.031514
[10:39:02.522] iteration 2768 : model1 loss : 0.445975 model2 loss : 0.047666
[10:39:02.692] iteration 2769 : model1 loss : 0.442671 model2 loss : 0.040532
[10:39:02.867] iteration 2770 : model1 loss : 0.442687 model2 loss : 0.032480
[10:39:03.036] iteration 2771 : model1 loss : 0.449131 model2 loss : 0.055822
[10:39:03.209] iteration 2772 : model1 loss : 0.438382 model2 loss : 0.033840
[10:39:05.181] iteration 2773 : model1 loss : 0.445464 model2 loss : 0.039613
[10:39:05.354] iteration 2774 : model1 loss : 0.447751 model2 loss : 0.036730
[10:39:05.529] iteration 2775 : model1 loss : 0.436725 model2 loss : 0.032688
[10:39:05.698] iteration 2776 : model1 loss : 0.445295 model2 loss : 0.038273
[10:39:05.877] iteration 2777 : model1 loss : 0.442363 model2 loss : 0.035280
[10:39:06.045] iteration 2778 : model1 loss : 0.442480 model2 loss : 0.037924
[10:39:06.218] iteration 2779 : model1 loss : 0.444985 model2 loss : 0.033748
[10:39:06.389] iteration 2780 : model1 loss : 0.444138 model2 loss : 0.032568
[10:39:06.564] iteration 2781 : model1 loss : 0.442106 model2 loss : 0.032699
[10:39:06.731] iteration 2782 : model1 loss : 0.447849 model2 loss : 0.041228
[10:39:06.906] iteration 2783 : model1 loss : 0.442074 model2 loss : 0.042947
[10:39:07.074] iteration 2784 : model1 loss : 0.437633 model2 loss : 0.032541
[10:39:07.246] iteration 2785 : model1 loss : 0.444554 model2 loss : 0.037300
[10:39:07.416] iteration 2786 : model1 loss : 0.441800 model2 loss : 0.037741
[10:39:07.589] iteration 2787 : model1 loss : 0.442253 model2 loss : 0.037366
[10:39:07.758] iteration 2788 : model1 loss : 0.438993 model2 loss : 0.030493
[10:39:07.935] iteration 2789 : model1 loss : 0.442529 model2 loss : 0.033476
[10:39:08.104] iteration 2790 : model1 loss : 0.445178 model2 loss : 0.036503
[10:39:08.278] iteration 2791 : model1 loss : 0.439169 model2 loss : 0.037945
[10:39:08.450] iteration 2792 : model1 loss : 0.435573 model2 loss : 0.032539
[10:39:08.621] iteration 2793 : model1 loss : 0.443051 model2 loss : 0.048200
[10:39:08.790] iteration 2794 : model1 loss : 0.435353 model2 loss : 0.036177
[10:39:08.963] iteration 2795 : model1 loss : 0.437550 model2 loss : 0.034070
[10:39:09.131] iteration 2796 : model1 loss : 0.437970 model2 loss : 0.039157
[10:39:09.304] iteration 2797 : model1 loss : 0.439891 model2 loss : 0.040197
[10:39:09.477] iteration 2798 : model1 loss : 0.443601 model2 loss : 0.040155
[10:39:09.650] iteration 2799 : model1 loss : 0.440330 model2 loss : 0.040376
[10:39:09.818] iteration 2800 : model1 loss : 0.438319 model2 loss : 0.036117
[10:39:09.993] iteration 2801 : model1 loss : 0.442062 model2 loss : 0.039066
[10:39:10.160] iteration 2802 : model1 loss : 0.440057 model2 loss : 0.034132
[10:39:10.333] iteration 2803 : model1 loss : 0.443519 model2 loss : 0.034731
[10:39:10.506] iteration 2804 : model1 loss : 0.440559 model2 loss : 0.036892
[10:39:10.680] iteration 2805 : model1 loss : 0.439725 model2 loss : 0.040916
[10:39:12.697] iteration 2806 : model1 loss : 0.444720 model2 loss : 0.048450
[10:39:12.866] iteration 2807 : model1 loss : 0.437532 model2 loss : 0.036565
[10:39:13.040] iteration 2808 : model1 loss : 0.439544 model2 loss : 0.029742
[10:39:13.212] iteration 2809 : model1 loss : 0.449128 model2 loss : 0.052657
[10:39:13.386] iteration 2810 : model1 loss : 0.443781 model2 loss : 0.051543
[10:39:13.555] iteration 2811 : model1 loss : 0.443777 model2 loss : 0.040360
[10:39:13.728] iteration 2812 : model1 loss : 0.441731 model2 loss : 0.039521
[10:39:13.898] iteration 2813 : model1 loss : 0.443054 model2 loss : 0.042234
[10:39:14.073] iteration 2814 : model1 loss : 0.439879 model2 loss : 0.038037
[10:39:14.240] iteration 2815 : model1 loss : 0.435153 model2 loss : 0.033295
[10:39:14.415] iteration 2816 : model1 loss : 0.437219 model2 loss : 0.041196
[10:39:14.583] iteration 2817 : model1 loss : 0.440252 model2 loss : 0.040725
[10:39:14.753] iteration 2818 : model1 loss : 0.443512 model2 loss : 0.040201
[10:39:14.928] iteration 2819 : model1 loss : 0.440597 model2 loss : 0.036903
[10:39:15.101] iteration 2820 : model1 loss : 0.439762 model2 loss : 0.032984
[10:39:15.268] iteration 2821 : model1 loss : 0.439641 model2 loss : 0.038766
[10:39:15.443] iteration 2822 : model1 loss : 0.445983 model2 loss : 0.043792
[10:39:15.611] iteration 2823 : model1 loss : 0.441326 model2 loss : 0.053549
[10:39:15.783] iteration 2824 : model1 loss : 0.441412 model2 loss : 0.038629
[10:39:15.955] iteration 2825 : model1 loss : 0.435721 model2 loss : 0.035634
[10:39:16.127] iteration 2826 : model1 loss : 0.438062 model2 loss : 0.036143
[10:39:16.294] iteration 2827 : model1 loss : 0.440350 model2 loss : 0.032575
[10:39:16.468] iteration 2828 : model1 loss : 0.445422 model2 loss : 0.044875
[10:39:16.637] iteration 2829 : model1 loss : 0.441797 model2 loss : 0.033889
[10:39:16.808] iteration 2830 : model1 loss : 0.436192 model2 loss : 0.032690
[10:39:16.980] iteration 2831 : model1 loss : 0.436593 model2 loss : 0.034468
[10:39:17.153] iteration 2832 : model1 loss : 0.445307 model2 loss : 0.038628
[10:39:17.320] iteration 2833 : model1 loss : 0.440842 model2 loss : 0.043148
[10:39:17.495] iteration 2834 : model1 loss : 0.435975 model2 loss : 0.032276
[10:39:17.663] iteration 2835 : model1 loss : 0.449366 model2 loss : 0.057951
[10:39:17.836] iteration 2836 : model1 loss : 0.438981 model2 loss : 0.031642
[10:39:18.006] iteration 2837 : model1 loss : 0.441832 model2 loss : 0.031881
[10:39:18.179] iteration 2838 : model1 loss : 0.445756 model2 loss : 0.049450
[10:39:20.160] iteration 2839 : model1 loss : 0.443863 model2 loss : 0.049146
[10:39:20.328] iteration 2840 : model1 loss : 0.435319 model2 loss : 0.029693
[10:39:20.504] iteration 2841 : model1 loss : 0.437185 model2 loss : 0.031671
[10:39:20.672] iteration 2842 : model1 loss : 0.450995 model2 loss : 0.055401
[10:39:20.845] iteration 2843 : model1 loss : 0.443996 model2 loss : 0.042195
[10:39:21.015] iteration 2844 : model1 loss : 0.441808 model2 loss : 0.038325
[10:39:21.187] iteration 2845 : model1 loss : 0.443312 model2 loss : 0.043384
[10:39:21.355] iteration 2846 : model1 loss : 0.441831 model2 loss : 0.051609
[10:39:21.533] iteration 2847 : model1 loss : 0.442468 model2 loss : 0.038541
[10:39:21.699] iteration 2848 : model1 loss : 0.438699 model2 loss : 0.033686
[10:39:21.872] iteration 2849 : model1 loss : 0.438430 model2 loss : 0.034381
[10:39:22.044] iteration 2850 : model1 loss : 0.445037 model2 loss : 0.033660
[10:39:22.216] iteration 2851 : model1 loss : 0.452249 model2 loss : 0.058645
[10:39:22.384] iteration 2852 : model1 loss : 0.441352 model2 loss : 0.045105
[10:39:22.560] iteration 2853 : model1 loss : 0.439851 model2 loss : 0.039950
[10:39:22.727] iteration 2854 : model1 loss : 0.438256 model2 loss : 0.032153
[10:39:22.903] iteration 2855 : model1 loss : 0.439001 model2 loss : 0.036245
[10:39:23.073] iteration 2856 : model1 loss : 0.437390 model2 loss : 0.029417
[10:39:23.249] iteration 2857 : model1 loss : 0.449934 model2 loss : 0.050535
[10:39:23.418] iteration 2858 : model1 loss : 0.443402 model2 loss : 0.048791
[10:39:23.591] iteration 2859 : model1 loss : 0.437079 model2 loss : 0.035314
[10:39:23.759] iteration 2860 : model1 loss : 0.441836 model2 loss : 0.045559
[10:39:23.936] iteration 2861 : model1 loss : 0.441444 model2 loss : 0.037580
[10:39:24.107] iteration 2862 : model1 loss : 0.438903 model2 loss : 0.037371
[10:39:24.280] iteration 2863 : model1 loss : 0.448762 model2 loss : 0.048585
[10:39:24.449] iteration 2864 : model1 loss : 0.438569 model2 loss : 0.037806
[10:39:24.622] iteration 2865 : model1 loss : 0.441301 model2 loss : 0.035986
[10:39:24.790] iteration 2866 : model1 loss : 0.440585 model2 loss : 0.037800
[10:39:24.964] iteration 2867 : model1 loss : 0.446848 model2 loss : 0.039913
[10:39:25.133] iteration 2868 : model1 loss : 0.447648 model2 loss : 0.041803
[10:39:25.308] iteration 2869 : model1 loss : 0.433562 model2 loss : 0.034973
[10:39:25.477] iteration 2870 : model1 loss : 0.437250 model2 loss : 0.034000
[10:39:25.648] iteration 2871 : model1 loss : 0.442479 model2 loss : 0.040946
[10:39:27.650] iteration 2872 : model1 loss : 0.443712 model2 loss : 0.043495
[10:39:27.823] iteration 2873 : model1 loss : 0.439380 model2 loss : 0.035722
[10:39:28.000] iteration 2874 : model1 loss : 0.442627 model2 loss : 0.033420
[10:39:28.168] iteration 2875 : model1 loss : 0.440872 model2 loss : 0.033402
[10:39:28.339] iteration 2876 : model1 loss : 0.445724 model2 loss : 0.047073
[10:39:28.513] iteration 2877 : model1 loss : 0.441179 model2 loss : 0.035308
[10:39:28.688] iteration 2878 : model1 loss : 0.435972 model2 loss : 0.030538
[10:39:28.855] iteration 2879 : model1 loss : 0.438465 model2 loss : 0.037281
[10:39:29.028] iteration 2880 : model1 loss : 0.446878 model2 loss : 0.052855
[10:39:29.195] iteration 2881 : model1 loss : 0.438946 model2 loss : 0.035404
[10:39:29.366] iteration 2882 : model1 loss : 0.441069 model2 loss : 0.038239
[10:39:29.539] iteration 2883 : model1 loss : 0.438611 model2 loss : 0.033527
[10:39:29.711] iteration 2884 : model1 loss : 0.441882 model2 loss : 0.036456
[10:39:29.880] iteration 2885 : model1 loss : 0.443391 model2 loss : 0.035265
[10:39:30.053] iteration 2886 : model1 loss : 0.441558 model2 loss : 0.030350
[10:39:30.221] iteration 2887 : model1 loss : 0.439790 model2 loss : 0.032679
[10:39:30.394] iteration 2888 : model1 loss : 0.444712 model2 loss : 0.038064
[10:39:30.565] iteration 2889 : model1 loss : 0.434059 model2 loss : 0.035056
[10:39:30.740] iteration 2890 : model1 loss : 0.435902 model2 loss : 0.039932
[10:39:30.912] iteration 2891 : model1 loss : 0.440150 model2 loss : 0.038578
[10:39:31.083] iteration 2892 : model1 loss : 0.443123 model2 loss : 0.035725
[10:39:31.251] iteration 2893 : model1 loss : 0.441134 model2 loss : 0.036374
[10:39:31.426] iteration 2894 : model1 loss : 0.443102 model2 loss : 0.042254
[10:39:31.595] iteration 2895 : model1 loss : 0.439147 model2 loss : 0.037854
[10:39:31.767] iteration 2896 : model1 loss : 0.440913 model2 loss : 0.045714
[10:39:31.937] iteration 2897 : model1 loss : 0.445226 model2 loss : 0.044741
[10:39:32.113] iteration 2898 : model1 loss : 0.443792 model2 loss : 0.037705
[10:39:32.280] iteration 2899 : model1 loss : 0.438120 model2 loss : 0.035238
[10:39:32.454] iteration 2900 : model1 loss : 0.438049 model2 loss : 0.043187
[10:39:32.623] iteration 2901 : model1 loss : 0.440119 model2 loss : 0.035971
[10:39:32.795] iteration 2902 : model1 loss : 0.444340 model2 loss : 0.033294
[10:39:32.966] iteration 2903 : model1 loss : 0.440365 model2 loss : 0.039541
[10:39:33.135] iteration 2904 : model1 loss : 0.442854 model2 loss : 0.035579
[10:39:35.109] iteration 2905 : model1 loss : 0.438410 model2 loss : 0.034511
[10:39:35.281] iteration 2906 : model1 loss : 0.441011 model2 loss : 0.041426
[10:39:35.460] iteration 2907 : model1 loss : 0.446195 model2 loss : 0.052329
[10:39:35.628] iteration 2908 : model1 loss : 0.444530 model2 loss : 0.041087
[10:39:35.800] iteration 2909 : model1 loss : 0.442221 model2 loss : 0.035185
[10:39:35.971] iteration 2910 : model1 loss : 0.441876 model2 loss : 0.036029
[10:39:36.144] iteration 2911 : model1 loss : 0.442292 model2 loss : 0.036785
[10:39:36.312] iteration 2912 : model1 loss : 0.436967 model2 loss : 0.032978
[10:39:36.486] iteration 2913 : model1 loss : 0.442273 model2 loss : 0.035744
[10:39:36.656] iteration 2914 : model1 loss : 0.440544 model2 loss : 0.033587
[10:39:36.827] iteration 2915 : model1 loss : 0.439334 model2 loss : 0.034079
[10:39:36.998] iteration 2916 : model1 loss : 0.441584 model2 loss : 0.034771
[10:39:37.172] iteration 2917 : model1 loss : 0.437139 model2 loss : 0.035124
[10:39:37.340] iteration 2918 : model1 loss : 0.442812 model2 loss : 0.034164
[10:39:37.517] iteration 2919 : model1 loss : 0.442182 model2 loss : 0.032708
[10:39:37.687] iteration 2920 : model1 loss : 0.444284 model2 loss : 0.041936
[10:39:37.860] iteration 2921 : model1 loss : 0.440926 model2 loss : 0.031755
[10:39:38.030] iteration 2922 : model1 loss : 0.435478 model2 loss : 0.031599
[10:39:38.203] iteration 2923 : model1 loss : 0.441497 model2 loss : 0.035727
[10:39:38.372] iteration 2924 : model1 loss : 0.442216 model2 loss : 0.033337
[10:39:38.547] iteration 2925 : model1 loss : 0.439051 model2 loss : 0.030223
[10:39:38.714] iteration 2926 : model1 loss : 0.446600 model2 loss : 0.035069
[10:39:38.888] iteration 2927 : model1 loss : 0.437575 model2 loss : 0.029215
[10:39:39.060] iteration 2928 : model1 loss : 0.443613 model2 loss : 0.043641
[10:39:39.232] iteration 2929 : model1 loss : 0.444166 model2 loss : 0.041759
[10:39:39.401] iteration 2930 : model1 loss : 0.443715 model2 loss : 0.046943
[10:39:39.576] iteration 2931 : model1 loss : 0.437380 model2 loss : 0.033511
[10:39:39.744] iteration 2932 : model1 loss : 0.440954 model2 loss : 0.035588
[10:39:39.920] iteration 2933 : model1 loss : 0.442003 model2 loss : 0.032780
[10:39:40.090] iteration 2934 : model1 loss : 0.444452 model2 loss : 0.037228
[10:39:40.262] iteration 2935 : model1 loss : 0.443271 model2 loss : 0.036697
[10:39:40.432] iteration 2936 : model1 loss : 0.440932 model2 loss : 0.033923
[10:39:40.608] iteration 2937 : model1 loss : 0.438547 model2 loss : 0.036641
[10:39:42.608] iteration 2938 : model1 loss : 0.442887 model2 loss : 0.035615
[10:39:42.776] iteration 2939 : model1 loss : 0.446891 model2 loss : 0.036266
[10:39:42.953] iteration 2940 : model1 loss : 0.436745 model2 loss : 0.033062
[10:39:43.121] iteration 2941 : model1 loss : 0.440751 model2 loss : 0.035428
[10:39:43.295] iteration 2942 : model1 loss : 0.445260 model2 loss : 0.032964
[10:39:43.465] iteration 2943 : model1 loss : 0.440799 model2 loss : 0.034805
[10:39:43.642] iteration 2944 : model1 loss : 0.445115 model2 loss : 0.043105
[10:39:43.810] iteration 2945 : model1 loss : 0.444100 model2 loss : 0.042398
[10:39:43.983] iteration 2946 : model1 loss : 0.443039 model2 loss : 0.045067
[10:39:44.153] iteration 2947 : model1 loss : 0.434598 model2 loss : 0.032380
[10:39:44.326] iteration 2948 : model1 loss : 0.439896 model2 loss : 0.037627
[10:39:44.500] iteration 2949 : model1 loss : 0.440758 model2 loss : 0.030767
[10:39:44.679] iteration 2950 : model1 loss : 0.445098 model2 loss : 0.059214
[10:39:44.847] iteration 2951 : model1 loss : 0.442365 model2 loss : 0.035648
[10:39:45.019] iteration 2952 : model1 loss : 0.442442 model2 loss : 0.038691
[10:39:45.186] iteration 2953 : model1 loss : 0.443991 model2 loss : 0.037590
[10:39:45.359] iteration 2954 : model1 loss : 0.442499 model2 loss : 0.042266
[10:39:45.530] iteration 2955 : model1 loss : 0.445043 model2 loss : 0.042795
[10:39:45.704] iteration 2956 : model1 loss : 0.438852 model2 loss : 0.036038
[10:39:45.873] iteration 2957 : model1 loss : 0.440609 model2 loss : 0.038545
[10:39:46.046] iteration 2958 : model1 loss : 0.444291 model2 loss : 0.044657
[10:39:46.213] iteration 2959 : model1 loss : 0.449983 model2 loss : 0.066210
[10:39:46.386] iteration 2960 : model1 loss : 0.439867 model2 loss : 0.040449
[10:39:46.559] iteration 2961 : model1 loss : 0.440162 model2 loss : 0.033292
[10:39:46.733] iteration 2962 : model1 loss : 0.439529 model2 loss : 0.034252
[10:39:46.903] iteration 2963 : model1 loss : 0.436829 model2 loss : 0.037618
[10:39:47.079] iteration 2964 : model1 loss : 0.444694 model2 loss : 0.041864
[10:39:47.248] iteration 2965 : model1 loss : 0.437363 model2 loss : 0.033690
[10:39:47.421] iteration 2966 : model1 loss : 0.438404 model2 loss : 0.035953
[10:39:47.592] iteration 2967 : model1 loss : 0.444582 model2 loss : 0.032862
[10:39:47.771] iteration 2968 : model1 loss : 0.437863 model2 loss : 0.035372
[10:39:47.939] iteration 2969 : model1 loss : 0.436323 model2 loss : 0.031894
[10:39:48.111] iteration 2970 : model1 loss : 0.433760 model2 loss : 0.032720
[10:39:50.101] iteration 2971 : model1 loss : 0.438134 model2 loss : 0.033431
[10:39:50.268] iteration 2972 : model1 loss : 0.440196 model2 loss : 0.038759
[10:39:50.446] iteration 2973 : model1 loss : 0.443988 model2 loss : 0.040433
[10:39:50.616] iteration 2974 : model1 loss : 0.443419 model2 loss : 0.043476
[10:39:50.789] iteration 2975 : model1 loss : 0.441012 model2 loss : 0.034777
[10:39:50.962] iteration 2976 : model1 loss : 0.444388 model2 loss : 0.046090
[10:39:51.135] iteration 2977 : model1 loss : 0.436158 model2 loss : 0.029195
[10:39:51.305] iteration 2978 : model1 loss : 0.437261 model2 loss : 0.035856
[10:39:51.482] iteration 2979 : model1 loss : 0.439601 model2 loss : 0.034659
[10:39:51.652] iteration 2980 : model1 loss : 0.435304 model2 loss : 0.033782
[10:39:51.822] iteration 2981 : model1 loss : 0.443247 model2 loss : 0.049792
[10:39:51.992] iteration 2982 : model1 loss : 0.440949 model2 loss : 0.034581
[10:39:52.163] iteration 2983 : model1 loss : 0.438154 model2 loss : 0.029242
[10:39:52.331] iteration 2984 : model1 loss : 0.444431 model2 loss : 0.040228
[10:39:52.509] iteration 2985 : model1 loss : 0.441717 model2 loss : 0.034881
[10:39:52.677] iteration 2986 : model1 loss : 0.444141 model2 loss : 0.043544
[10:39:52.850] iteration 2987 : model1 loss : 0.438603 model2 loss : 0.040372
[10:39:53.018] iteration 2988 : model1 loss : 0.442148 model2 loss : 0.046017
[10:39:53.191] iteration 2989 : model1 loss : 0.439376 model2 loss : 0.036578
[10:39:53.358] iteration 2990 : model1 loss : 0.436821 model2 loss : 0.032076
[10:39:53.534] iteration 2991 : model1 loss : 0.439201 model2 loss : 0.040883
[10:39:53.703] iteration 2992 : model1 loss : 0.444452 model2 loss : 0.042917
[10:39:53.874] iteration 2993 : model1 loss : 0.439856 model2 loss : 0.034542
[10:39:54.045] iteration 2994 : model1 loss : 0.440911 model2 loss : 0.035452
[10:39:54.216] iteration 2995 : model1 loss : 0.436773 model2 loss : 0.036518
[10:39:54.387] iteration 2996 : model1 loss : 0.439178 model2 loss : 0.038794
[10:39:54.562] iteration 2997 : model1 loss : 0.443523 model2 loss : 0.035567
[10:39:54.730] iteration 2998 : model1 loss : 0.439743 model2 loss : 0.035781
[10:39:54.903] iteration 2999 : model1 loss : 0.443056 model2 loss : 0.041013
[10:39:55.075] iteration 3000 : model1 loss : 0.439491 model2 loss : 0.039546
[10:40:03.658] iteration 3000 : model1_mean_dice : 0.811785 model1_mean_hd95 : 6.633409
[10:40:12.226] iteration 3000 : model2_mean_dice : 0.874068 model2_mean_hd95 : 4.962882
[10:40:12.246] save model1 to ../model/ACDC/EVILv1_kl0.5_tau0.25_21_1337/unet\model1_iter_3000.pth
[10:40:12.265] save model2 to ../model/ACDC/EVILv1_kl0.5_tau0.25_21_1337/unet\model2_iter_3000.pth
[10:40:12.439] iteration 3001 : model1 loss : 0.440399 model2 loss : 0.037833
[10:40:12.613] iteration 3002 : model1 loss : 0.443167 model2 loss : 0.038939
[10:40:12.785] iteration 3003 : model1 loss : 0.432919 model2 loss : 0.030285
[10:40:14.808] iteration 3004 : model1 loss : 0.441267 model2 loss : 0.035768
[10:40:14.979] iteration 3005 : model1 loss : 0.443763 model2 loss : 0.034269
[10:40:15.155] iteration 3006 : model1 loss : 0.448226 model2 loss : 0.046976
[10:40:15.322] iteration 3007 : model1 loss : 0.438593 model2 loss : 0.030706
[10:40:15.496] iteration 3008 : model1 loss : 0.442236 model2 loss : 0.036446
[10:40:15.665] iteration 3009 : model1 loss : 0.440264 model2 loss : 0.034323
[10:40:15.839] iteration 3010 : model1 loss : 0.439545 model2 loss : 0.034450
[10:40:16.007] iteration 3011 : model1 loss : 0.437453 model2 loss : 0.027777
[10:40:16.180] iteration 3012 : model1 loss : 0.437086 model2 loss : 0.028927
[10:40:16.348] iteration 3013 : model1 loss : 0.438190 model2 loss : 0.036280
[10:40:16.525] iteration 3014 : model1 loss : 0.439762 model2 loss : 0.035850
[10:40:16.694] iteration 3015 : model1 loss : 0.441010 model2 loss : 0.030821
[10:40:16.866] iteration 3016 : model1 loss : 0.436195 model2 loss : 0.034767
[10:40:17.037] iteration 3017 : model1 loss : 0.437782 model2 loss : 0.035701
[10:40:17.209] iteration 3018 : model1 loss : 0.445669 model2 loss : 0.036243
[10:40:17.377] iteration 3019 : model1 loss : 0.439003 model2 loss : 0.034678
[10:40:17.550] iteration 3020 : model1 loss : 0.439946 model2 loss : 0.032413
[10:40:17.720] iteration 3021 : model1 loss : 0.439241 model2 loss : 0.032914
[10:40:17.895] iteration 3022 : model1 loss : 0.438355 model2 loss : 0.032959
[10:40:18.066] iteration 3023 : model1 loss : 0.439186 model2 loss : 0.036992
[10:40:18.238] iteration 3024 : model1 loss : 0.451389 model2 loss : 0.041903
[10:40:18.406] iteration 3025 : model1 loss : 0.435419 model2 loss : 0.034746
[10:40:18.578] iteration 3026 : model1 loss : 0.441237 model2 loss : 0.032446
[10:40:18.745] iteration 3027 : model1 loss : 0.438138 model2 loss : 0.035930
[10:40:18.920] iteration 3028 : model1 loss : 0.448468 model2 loss : 0.040611
[10:40:19.095] iteration 3029 : model1 loss : 0.444006 model2 loss : 0.040334
[10:40:19.267] iteration 3030 : model1 loss : 0.444286 model2 loss : 0.044075
[10:40:19.436] iteration 3031 : model1 loss : 0.440729 model2 loss : 0.038525
[10:40:19.610] iteration 3032 : model1 loss : 0.440891 model2 loss : 0.037755
[10:40:19.778] iteration 3033 : model1 loss : 0.439111 model2 loss : 0.033077
[10:40:19.951] iteration 3034 : model1 loss : 0.444478 model2 loss : 0.039638
[10:40:20.120] iteration 3035 : model1 loss : 0.442285 model2 loss : 0.044116
[10:40:20.288] iteration 3036 : model1 loss : 0.441768 model2 loss : 0.039690
[10:40:22.278] iteration 3037 : model1 loss : 0.444405 model2 loss : 0.038977
[10:40:22.448] iteration 3038 : model1 loss : 0.443141 model2 loss : 0.031999
[10:40:22.624] iteration 3039 : model1 loss : 0.451625 model2 loss : 0.059292
[10:40:22.790] iteration 3040 : model1 loss : 0.440218 model2 loss : 0.036638
[10:40:22.963] iteration 3041 : model1 loss : 0.442704 model2 loss : 0.039030
[10:40:23.133] iteration 3042 : model1 loss : 0.440733 model2 loss : 0.035893
[10:40:23.306] iteration 3043 : model1 loss : 0.445335 model2 loss : 0.035491
[10:40:23.476] iteration 3044 : model1 loss : 0.445859 model2 loss : 0.045462
[10:40:23.649] iteration 3045 : model1 loss : 0.443693 model2 loss : 0.035703
[10:40:23.816] iteration 3046 : model1 loss : 0.444603 model2 loss : 0.037140
[10:40:23.989] iteration 3047 : model1 loss : 0.441176 model2 loss : 0.035553
[10:40:24.159] iteration 3048 : model1 loss : 0.442586 model2 loss : 0.038864
[10:40:24.331] iteration 3049 : model1 loss : 0.443278 model2 loss : 0.036381
[10:40:24.505] iteration 3050 : model1 loss : 0.440193 model2 loss : 0.034590
[10:40:24.681] iteration 3051 : model1 loss : 0.435691 model2 loss : 0.027902
[10:40:24.848] iteration 3052 : model1 loss : 0.435013 model2 loss : 0.032389
[10:40:25.022] iteration 3053 : model1 loss : 0.442886 model2 loss : 0.041521
[10:40:25.188] iteration 3054 : model1 loss : 0.443670 model2 loss : 0.036199
[10:40:25.360] iteration 3055 : model1 loss : 0.439962 model2 loss : 0.036821
[10:40:25.532] iteration 3056 : model1 loss : 0.451770 model2 loss : 0.043095
[10:40:25.704] iteration 3057 : model1 loss : 0.446486 model2 loss : 0.038931
[10:40:25.873] iteration 3058 : model1 loss : 0.441558 model2 loss : 0.032760
[10:40:26.046] iteration 3059 : model1 loss : 0.447602 model2 loss : 0.043963
[10:40:26.215] iteration 3060 : model1 loss : 0.440843 model2 loss : 0.039815
[10:40:26.386] iteration 3061 : model1 loss : 0.441182 model2 loss : 0.036459
[10:40:26.558] iteration 3062 : model1 loss : 0.437675 model2 loss : 0.035921
[10:40:26.732] iteration 3063 : model1 loss : 0.448930 model2 loss : 0.055612
[10:40:26.902] iteration 3064 : model1 loss : 0.437151 model2 loss : 0.034806
[10:40:27.077] iteration 3065 : model1 loss : 0.437183 model2 loss : 0.032267
[10:40:27.244] iteration 3066 : model1 loss : 0.437701 model2 loss : 0.030678
[10:40:27.417] iteration 3067 : model1 loss : 0.438892 model2 loss : 0.034907
[10:40:27.585] iteration 3068 : model1 loss : 0.437856 model2 loss : 0.034789
[10:40:27.755] iteration 3069 : model1 loss : 0.442818 model2 loss : 0.038349
[10:40:29.742] iteration 3070 : model1 loss : 0.446770 model2 loss : 0.048480
[10:40:29.911] iteration 3071 : model1 loss : 0.441048 model2 loss : 0.038209
[10:40:30.085] iteration 3072 : model1 loss : 0.441120 model2 loss : 0.037608
[10:40:30.254] iteration 3073 : model1 loss : 0.446281 model2 loss : 0.046629
[10:40:30.426] iteration 3074 : model1 loss : 0.442388 model2 loss : 0.030395
[10:40:30.596] iteration 3075 : model1 loss : 0.442260 model2 loss : 0.042017
[10:40:30.770] iteration 3076 : model1 loss : 0.442297 model2 loss : 0.043897
[10:40:30.941] iteration 3077 : model1 loss : 0.446381 model2 loss : 0.043261
[10:40:31.116] iteration 3078 : model1 loss : 0.437608 model2 loss : 0.037693
[10:40:31.283] iteration 3079 : model1 loss : 0.437998 model2 loss : 0.034147
[10:40:31.455] iteration 3080 : model1 loss : 0.440882 model2 loss : 0.039997
[10:40:31.627] iteration 3081 : model1 loss : 0.441561 model2 loss : 0.036598
[10:40:31.799] iteration 3082 : model1 loss : 0.443132 model2 loss : 0.042381
[10:40:31.967] iteration 3083 : model1 loss : 0.439926 model2 loss : 0.038588
[10:40:32.142] iteration 3084 : model1 loss : 0.436898 model2 loss : 0.029290
[10:40:32.311] iteration 3085 : model1 loss : 0.445276 model2 loss : 0.043952
[10:40:32.485] iteration 3086 : model1 loss : 0.438883 model2 loss : 0.033330
[10:40:32.653] iteration 3087 : model1 loss : 0.437011 model2 loss : 0.032788
[10:40:32.826] iteration 3088 : model1 loss : 0.435570 model2 loss : 0.029485
[10:40:32.997] iteration 3089 : model1 loss : 0.438324 model2 loss : 0.029232
[10:40:33.171] iteration 3090 : model1 loss : 0.439437 model2 loss : 0.043591
[10:40:33.340] iteration 3091 : model1 loss : 0.437602 model2 loss : 0.030835
[10:40:33.517] iteration 3092 : model1 loss : 0.439346 model2 loss : 0.040838
[10:40:33.684] iteration 3093 : model1 loss : 0.442873 model2 loss : 0.044980
[10:40:33.858] iteration 3094 : model1 loss : 0.441117 model2 loss : 0.037271
[10:40:34.028] iteration 3095 : model1 loss : 0.444261 model2 loss : 0.042481
[10:40:34.203] iteration 3096 : model1 loss : 0.441421 model2 loss : 0.033610
[10:40:34.368] iteration 3097 : model1 loss : 0.439323 model2 loss : 0.036241
[10:40:34.543] iteration 3098 : model1 loss : 0.439303 model2 loss : 0.031093
[10:40:34.712] iteration 3099 : model1 loss : 0.438425 model2 loss : 0.033012
[10:40:34.883] iteration 3100 : model1 loss : 0.443686 model2 loss : 0.036736
[10:40:35.051] iteration 3101 : model1 loss : 0.438665 model2 loss : 0.031962
[10:40:35.221] iteration 3102 : model1 loss : 0.442206 model2 loss : 0.041457
[10:40:37.190] iteration 3103 : model1 loss : 0.440823 model2 loss : 0.038510
[10:40:37.355] iteration 3104 : model1 loss : 0.439866 model2 loss : 0.031376
[10:40:37.538] iteration 3105 : model1 loss : 0.438407 model2 loss : 0.032473
[10:40:37.708] iteration 3106 : model1 loss : 0.440850 model2 loss : 0.032989
[10:40:37.879] iteration 3107 : model1 loss : 0.444836 model2 loss : 0.032604
[10:40:38.049] iteration 3108 : model1 loss : 0.440568 model2 loss : 0.044149
[10:40:38.219] iteration 3109 : model1 loss : 0.441196 model2 loss : 0.032619
[10:40:38.386] iteration 3110 : model1 loss : 0.439398 model2 loss : 0.035525
[10:40:38.563] iteration 3111 : model1 loss : 0.441066 model2 loss : 0.034573
[10:40:38.731] iteration 3112 : model1 loss : 0.436561 model2 loss : 0.029511
[10:40:38.907] iteration 3113 : model1 loss : 0.443708 model2 loss : 0.036873
[10:40:39.077] iteration 3114 : model1 loss : 0.440538 model2 loss : 0.034248
[10:40:39.253] iteration 3115 : model1 loss : 0.439979 model2 loss : 0.034252
[10:40:39.420] iteration 3116 : model1 loss : 0.445197 model2 loss : 0.036851
[10:40:39.592] iteration 3117 : model1 loss : 0.440088 model2 loss : 0.031692
[10:40:39.760] iteration 3118 : model1 loss : 0.436768 model2 loss : 0.031534
[10:40:39.934] iteration 3119 : model1 loss : 0.447345 model2 loss : 0.036845
[10:40:40.106] iteration 3120 : model1 loss : 0.439353 model2 loss : 0.032883
[10:40:40.279] iteration 3121 : model1 loss : 0.442456 model2 loss : 0.040144
[10:40:40.448] iteration 3122 : model1 loss : 0.438522 model2 loss : 0.035337
[10:40:40.623] iteration 3123 : model1 loss : 0.442518 model2 loss : 0.039789
[10:40:40.792] iteration 3124 : model1 loss : 0.440160 model2 loss : 0.036771
[10:40:40.964] iteration 3125 : model1 loss : 0.435429 model2 loss : 0.031285
[10:40:41.134] iteration 3126 : model1 loss : 0.445628 model2 loss : 0.047931
[10:40:41.308] iteration 3127 : model1 loss : 0.439583 model2 loss : 0.048689
[10:40:41.476] iteration 3128 : model1 loss : 0.436610 model2 loss : 0.030341
[10:40:41.649] iteration 3129 : model1 loss : 0.441302 model2 loss : 0.037170
[10:40:41.817] iteration 3130 : model1 loss : 0.445075 model2 loss : 0.034688
[10:40:41.988] iteration 3131 : model1 loss : 0.440070 model2 loss : 0.037587
[10:40:42.159] iteration 3132 : model1 loss : 0.444243 model2 loss : 0.037135
[10:40:42.330] iteration 3133 : model1 loss : 0.447889 model2 loss : 0.041905
[10:40:42.499] iteration 3134 : model1 loss : 0.441706 model2 loss : 0.045497
[10:40:42.671] iteration 3135 : model1 loss : 0.440126 model2 loss : 0.034935
[10:40:44.638] iteration 3136 : model1 loss : 0.444709 model2 loss : 0.037879
[10:40:44.806] iteration 3137 : model1 loss : 0.437627 model2 loss : 0.032791
[10:40:44.979] iteration 3138 : model1 loss : 0.440785 model2 loss : 0.038791
[10:40:45.151] iteration 3139 : model1 loss : 0.442313 model2 loss : 0.043371
[10:40:45.321] iteration 3140 : model1 loss : 0.442020 model2 loss : 0.034787
[10:40:45.489] iteration 3141 : model1 loss : 0.442546 model2 loss : 0.035880
[10:40:45.663] iteration 3142 : model1 loss : 0.438790 model2 loss : 0.044488
[10:40:45.831] iteration 3143 : model1 loss : 0.441876 model2 loss : 0.028995
[10:40:46.005] iteration 3144 : model1 loss : 0.442193 model2 loss : 0.039732
[10:40:46.174] iteration 3145 : model1 loss : 0.438627 model2 loss : 0.032035
[10:40:46.344] iteration 3146 : model1 loss : 0.446030 model2 loss : 0.039134
[10:40:46.521] iteration 3147 : model1 loss : 0.445074 model2 loss : 0.045364
[10:40:46.696] iteration 3148 : model1 loss : 0.443036 model2 loss : 0.037594
[10:40:46.865] iteration 3149 : model1 loss : 0.445139 model2 loss : 0.050246
[10:40:47.038] iteration 3150 : model1 loss : 0.437890 model2 loss : 0.030601
[10:40:47.207] iteration 3151 : model1 loss : 0.438772 model2 loss : 0.037329
[10:40:47.380] iteration 3152 : model1 loss : 0.439465 model2 loss : 0.035606
[10:40:47.554] iteration 3153 : model1 loss : 0.438484 model2 loss : 0.036793
[10:40:47.727] iteration 3154 : model1 loss : 0.437910 model2 loss : 0.043281
[10:40:47.896] iteration 3155 : model1 loss : 0.447627 model2 loss : 0.033746
[10:40:48.072] iteration 3156 : model1 loss : 0.436476 model2 loss : 0.031717
[10:40:48.239] iteration 3157 : model1 loss : 0.441211 model2 loss : 0.030047
[10:40:48.412] iteration 3158 : model1 loss : 0.435196 model2 loss : 0.029320
[10:40:48.585] iteration 3159 : model1 loss : 0.436300 model2 loss : 0.036062
[10:40:48.757] iteration 3160 : model1 loss : 0.436816 model2 loss : 0.031980
[10:40:48.927] iteration 3161 : model1 loss : 0.440828 model2 loss : 0.039271
[10:40:49.099] iteration 3162 : model1 loss : 0.439209 model2 loss : 0.036605
[10:40:49.277] iteration 3163 : model1 loss : 0.441933 model2 loss : 0.033077
[10:40:49.451] iteration 3164 : model1 loss : 0.439856 model2 loss : 0.037264
[10:40:49.620] iteration 3165 : model1 loss : 0.441510 model2 loss : 0.036839
[10:40:49.792] iteration 3166 : model1 loss : 0.437038 model2 loss : 0.036337
[10:40:49.959] iteration 3167 : model1 loss : 0.438005 model2 loss : 0.034441
[10:40:50.131] iteration 3168 : model1 loss : 0.445818 model2 loss : 0.043669
[10:40:52.110] iteration 3169 : model1 loss : 0.443588 model2 loss : 0.040415
[10:40:52.278] iteration 3170 : model1 loss : 0.448285 model2 loss : 0.052839
[10:40:52.454] iteration 3171 : model1 loss : 0.436196 model2 loss : 0.033801
[10:40:52.625] iteration 3172 : model1 loss : 0.443938 model2 loss : 0.033711
[10:40:52.798] iteration 3173 : model1 loss : 0.435973 model2 loss : 0.030733
[10:40:52.965] iteration 3174 : model1 loss : 0.438411 model2 loss : 0.039086
[10:40:53.138] iteration 3175 : model1 loss : 0.437785 model2 loss : 0.035226
[10:40:53.307] iteration 3176 : model1 loss : 0.440328 model2 loss : 0.036317
[10:40:53.482] iteration 3177 : model1 loss : 0.443635 model2 loss : 0.037977
[10:40:53.652] iteration 3178 : model1 loss : 0.446154 model2 loss : 0.036442
[10:40:53.823] iteration 3179 : model1 loss : 0.441616 model2 loss : 0.033626
[10:40:53.990] iteration 3180 : model1 loss : 0.440368 model2 loss : 0.035585
[10:40:54.166] iteration 3181 : model1 loss : 0.442266 model2 loss : 0.035632
[10:40:54.333] iteration 3182 : model1 loss : 0.446346 model2 loss : 0.037299
[10:40:54.508] iteration 3183 : model1 loss : 0.441453 model2 loss : 0.039018
[10:40:54.679] iteration 3184 : model1 loss : 0.447129 model2 loss : 0.038229
[10:40:54.851] iteration 3185 : model1 loss : 0.437498 model2 loss : 0.033936
[10:40:55.020] iteration 3186 : model1 loss : 0.440440 model2 loss : 0.040429
[10:40:55.193] iteration 3187 : model1 loss : 0.434687 model2 loss : 0.034427
[10:40:55.360] iteration 3188 : model1 loss : 0.438977 model2 loss : 0.035061
[10:40:55.538] iteration 3189 : model1 loss : 0.434233 model2 loss : 0.034105
[10:40:55.707] iteration 3190 : model1 loss : 0.440739 model2 loss : 0.043037
[10:40:55.879] iteration 3191 : model1 loss : 0.441573 model2 loss : 0.041106
[10:40:56.048] iteration 3192 : model1 loss : 0.437644 model2 loss : 0.032437
[10:40:56.221] iteration 3193 : model1 loss : 0.438336 model2 loss : 0.030693
[10:40:56.388] iteration 3194 : model1 loss : 0.442948 model2 loss : 0.035601
[10:40:56.563] iteration 3195 : model1 loss : 0.445786 model2 loss : 0.043282
[10:40:56.731] iteration 3196 : model1 loss : 0.439070 model2 loss : 0.032501
[10:40:56.907] iteration 3197 : model1 loss : 0.434793 model2 loss : 0.037573
[10:40:57.077] iteration 3198 : model1 loss : 0.440397 model2 loss : 0.035357
[10:40:57.251] iteration 3199 : model1 loss : 0.441530 model2 loss : 0.040449
[10:40:57.418] iteration 3200 : model1 loss : 0.441501 model2 loss : 0.036043
[10:40:57.588] iteration 3201 : model1 loss : 0.444432 model2 loss : 0.037697
[10:40:59.557] iteration 3202 : model1 loss : 0.445304 model2 loss : 0.042095
[10:40:59.724] iteration 3203 : model1 loss : 0.440459 model2 loss : 0.037956
[10:40:59.898] iteration 3204 : model1 loss : 0.442935 model2 loss : 0.039479
[10:41:00.069] iteration 3205 : model1 loss : 0.441519 model2 loss : 0.032414
[10:41:00.243] iteration 3206 : model1 loss : 0.441865 model2 loss : 0.033180
[10:41:00.412] iteration 3207 : model1 loss : 0.441804 model2 loss : 0.043302
[10:41:00.588] iteration 3208 : model1 loss : 0.438500 model2 loss : 0.035690
[10:41:00.756] iteration 3209 : model1 loss : 0.438942 model2 loss : 0.031592
[10:41:00.929] iteration 3210 : model1 loss : 0.435254 model2 loss : 0.040186
[10:41:01.100] iteration 3211 : model1 loss : 0.446876 model2 loss : 0.047086
[10:41:01.272] iteration 3212 : model1 loss : 0.435945 model2 loss : 0.028991
[10:41:01.440] iteration 3213 : model1 loss : 0.442228 model2 loss : 0.035008
[10:41:01.611] iteration 3214 : model1 loss : 0.434321 model2 loss : 0.032389
[10:41:01.779] iteration 3215 : model1 loss : 0.437995 model2 loss : 0.031497
[10:41:01.951] iteration 3216 : model1 loss : 0.443588 model2 loss : 0.037379
[10:41:02.120] iteration 3217 : model1 loss : 0.441096 model2 loss : 0.034770
[10:41:02.290] iteration 3218 : model1 loss : 0.442655 model2 loss : 0.037791
[10:41:02.457] iteration 3219 : model1 loss : 0.439533 model2 loss : 0.033627
[10:41:02.632] iteration 3220 : model1 loss : 0.436712 model2 loss : 0.039821
[10:41:02.799] iteration 3221 : model1 loss : 0.438352 model2 loss : 0.035497
[10:41:02.974] iteration 3222 : model1 loss : 0.439680 model2 loss : 0.032651
[10:41:03.145] iteration 3223 : model1 loss : 0.437817 model2 loss : 0.034161
[10:41:03.318] iteration 3224 : model1 loss : 0.434499 model2 loss : 0.031977
[10:41:03.485] iteration 3225 : model1 loss : 0.442516 model2 loss : 0.034931
[10:41:03.658] iteration 3226 : model1 loss : 0.437215 model2 loss : 0.032075
[10:41:03.826] iteration 3227 : model1 loss : 0.437364 model2 loss : 0.036333
[10:41:03.999] iteration 3228 : model1 loss : 0.437061 model2 loss : 0.034669
[10:41:04.169] iteration 3229 : model1 loss : 0.439939 model2 loss : 0.040331
[10:41:04.342] iteration 3230 : model1 loss : 0.442181 model2 loss : 0.034337
[10:41:04.517] iteration 3231 : model1 loss : 0.437980 model2 loss : 0.035844
[10:41:04.690] iteration 3232 : model1 loss : 0.438229 model2 loss : 0.035280
[10:41:04.857] iteration 3233 : model1 loss : 0.446290 model2 loss : 0.038504
[10:41:05.028] iteration 3234 : model1 loss : 0.440906 model2 loss : 0.042488
[10:41:07.045] iteration 3235 : model1 loss : 0.436508 model2 loss : 0.032744
[10:41:07.220] iteration 3236 : model1 loss : 0.437337 model2 loss : 0.031690
[10:41:07.395] iteration 3237 : model1 loss : 0.441069 model2 loss : 0.033887
[10:41:07.566] iteration 3238 : model1 loss : 0.436499 model2 loss : 0.032960
[10:41:07.741] iteration 3239 : model1 loss : 0.438862 model2 loss : 0.036757
[10:41:07.911] iteration 3240 : model1 loss : 0.443470 model2 loss : 0.039550
[10:41:08.084] iteration 3241 : model1 loss : 0.440940 model2 loss : 0.033497
[10:41:08.253] iteration 3242 : model1 loss : 0.444162 model2 loss : 0.042532
[10:41:08.425] iteration 3243 : model1 loss : 0.437598 model2 loss : 0.033211
[10:41:08.596] iteration 3244 : model1 loss : 0.437060 model2 loss : 0.032009
[10:41:08.769] iteration 3245 : model1 loss : 0.441882 model2 loss : 0.040414
[10:41:08.938] iteration 3246 : model1 loss : 0.438217 model2 loss : 0.032009
[10:41:09.114] iteration 3247 : model1 loss : 0.438036 model2 loss : 0.030803
[10:41:09.282] iteration 3248 : model1 loss : 0.438236 model2 loss : 0.038645
[10:41:09.455] iteration 3249 : model1 loss : 0.437534 model2 loss : 0.031142
[10:41:09.624] iteration 3250 : model1 loss : 0.443450 model2 loss : 0.041669
[10:41:09.798] iteration 3251 : model1 loss : 0.438270 model2 loss : 0.031317
[10:41:09.969] iteration 3252 : model1 loss : 0.444849 model2 loss : 0.053167
[10:41:10.142] iteration 3253 : model1 loss : 0.434421 model2 loss : 0.027951
[10:41:10.311] iteration 3254 : model1 loss : 0.440616 model2 loss : 0.038212
[10:41:10.482] iteration 3255 : model1 loss : 0.441189 model2 loss : 0.033943
[10:41:10.654] iteration 3256 : model1 loss : 0.438573 model2 loss : 0.030632
[10:41:10.828] iteration 3257 : model1 loss : 0.437440 model2 loss : 0.032348
[10:41:10.997] iteration 3258 : model1 loss : 0.440900 model2 loss : 0.037377
[10:41:11.171] iteration 3259 : model1 loss : 0.438826 model2 loss : 0.034370
[10:41:11.339] iteration 3260 : model1 loss : 0.438220 model2 loss : 0.034644
[10:41:11.515] iteration 3261 : model1 loss : 0.441757 model2 loss : 0.043012
[10:41:11.686] iteration 3262 : model1 loss : 0.441644 model2 loss : 0.034934
[10:41:11.857] iteration 3263 : model1 loss : 0.443193 model2 loss : 0.043311
[10:41:12.025] iteration 3264 : model1 loss : 0.434518 model2 loss : 0.026778
[10:41:12.200] iteration 3265 : model1 loss : 0.438505 model2 loss : 0.036477
[10:41:12.366] iteration 3266 : model1 loss : 0.452488 model2 loss : 0.054953
[10:41:12.540] iteration 3267 : model1 loss : 0.449849 model2 loss : 0.052223
[10:41:14.535] iteration 3268 : model1 loss : 0.437072 model2 loss : 0.033610
[10:41:14.709] iteration 3269 : model1 loss : 0.433448 model2 loss : 0.033851
[10:41:14.890] iteration 3270 : model1 loss : 0.440877 model2 loss : 0.042928
[10:41:15.060] iteration 3271 : model1 loss : 0.443355 model2 loss : 0.038166
[10:41:15.233] iteration 3272 : model1 loss : 0.437334 model2 loss : 0.038236
[10:41:15.402] iteration 3273 : model1 loss : 0.444981 model2 loss : 0.041054
[10:41:15.579] iteration 3274 : model1 loss : 0.440322 model2 loss : 0.031900
[10:41:15.747] iteration 3275 : model1 loss : 0.439440 model2 loss : 0.035823
[10:41:15.921] iteration 3276 : model1 loss : 0.447477 model2 loss : 0.042364
[10:41:16.091] iteration 3277 : model1 loss : 0.439797 model2 loss : 0.030505
[10:41:16.265] iteration 3278 : model1 loss : 0.441092 model2 loss : 0.032148
[10:41:16.434] iteration 3279 : model1 loss : 0.437633 model2 loss : 0.031072
[10:41:16.608] iteration 3280 : model1 loss : 0.441654 model2 loss : 0.040264
[10:41:16.777] iteration 3281 : model1 loss : 0.438167 model2 loss : 0.037727
[10:41:16.949] iteration 3282 : model1 loss : 0.446496 model2 loss : 0.045015
[10:41:17.120] iteration 3283 : model1 loss : 0.443210 model2 loss : 0.035200
[10:41:17.292] iteration 3284 : model1 loss : 0.439441 model2 loss : 0.037394
[10:41:17.458] iteration 3285 : model1 loss : 0.436599 model2 loss : 0.029940
[10:41:17.633] iteration 3286 : model1 loss : 0.439566 model2 loss : 0.033710
[10:41:17.801] iteration 3287 : model1 loss : 0.443286 model2 loss : 0.035910
[10:41:17.974] iteration 3288 : model1 loss : 0.442406 model2 loss : 0.040008
[10:41:18.145] iteration 3289 : model1 loss : 0.447387 model2 loss : 0.044685
[10:41:18.316] iteration 3290 : model1 loss : 0.438566 model2 loss : 0.032991
[10:41:18.485] iteration 3291 : model1 loss : 0.437660 model2 loss : 0.028895
[10:41:18.658] iteration 3292 : model1 loss : 0.442974 model2 loss : 0.041446
[10:41:18.827] iteration 3293 : model1 loss : 0.438749 model2 loss : 0.031181
[10:41:19.002] iteration 3294 : model1 loss : 0.444111 model2 loss : 0.038501
[10:41:19.175] iteration 3295 : model1 loss : 0.439977 model2 loss : 0.033399
[10:41:19.346] iteration 3296 : model1 loss : 0.433167 model2 loss : 0.030323
[10:41:19.522] iteration 3297 : model1 loss : 0.443266 model2 loss : 0.050398
[10:41:19.696] iteration 3298 : model1 loss : 0.441132 model2 loss : 0.036043
[10:41:19.862] iteration 3299 : model1 loss : 0.446286 model2 loss : 0.034902
[10:41:20.032] iteration 3300 : model1 loss : 0.442297 model2 loss : 0.055803
[10:41:22.041] iteration 3301 : model1 loss : 0.443358 model2 loss : 0.035137
[10:41:22.210] iteration 3302 : model1 loss : 0.440774 model2 loss : 0.036367
[10:41:22.386] iteration 3303 : model1 loss : 0.440364 model2 loss : 0.037299
[10:41:22.554] iteration 3304 : model1 loss : 0.436157 model2 loss : 0.031346
[10:41:22.727] iteration 3305 : model1 loss : 0.436441 model2 loss : 0.033482
[10:41:22.898] iteration 3306 : model1 loss : 0.443209 model2 loss : 0.037088
[10:41:23.070] iteration 3307 : model1 loss : 0.438269 model2 loss : 0.036399
[10:41:23.240] iteration 3308 : model1 loss : 0.433250 model2 loss : 0.027240
[10:41:23.413] iteration 3309 : model1 loss : 0.440120 model2 loss : 0.038864
[10:41:23.583] iteration 3310 : model1 loss : 0.443301 model2 loss : 0.046208
[10:41:23.754] iteration 3311 : model1 loss : 0.442825 model2 loss : 0.039793
[10:41:23.925] iteration 3312 : model1 loss : 0.440219 model2 loss : 0.040202
[10:41:24.100] iteration 3313 : model1 loss : 0.444503 model2 loss : 0.033752
[10:41:24.268] iteration 3314 : model1 loss : 0.449081 model2 loss : 0.039568
[10:41:24.440] iteration 3315 : model1 loss : 0.437599 model2 loss : 0.033552
[10:41:24.610] iteration 3316 : model1 loss : 0.442292 model2 loss : 0.040662
[10:41:24.784] iteration 3317 : model1 loss : 0.440861 model2 loss : 0.031626
[10:41:24.955] iteration 3318 : model1 loss : 0.445487 model2 loss : 0.036223
[10:41:25.130] iteration 3319 : model1 loss : 0.440527 model2 loss : 0.033965
[10:41:25.298] iteration 3320 : model1 loss : 0.441112 model2 loss : 0.035974
[10:41:25.469] iteration 3321 : model1 loss : 0.439010 model2 loss : 0.033541
[10:41:25.640] iteration 3322 : model1 loss : 0.440126 model2 loss : 0.029152
[10:41:25.816] iteration 3323 : model1 loss : 0.442885 model2 loss : 0.037953
[10:41:25.983] iteration 3324 : model1 loss : 0.441904 model2 loss : 0.041578
[10:41:26.155] iteration 3325 : model1 loss : 0.437620 model2 loss : 0.033070
[10:41:26.323] iteration 3326 : model1 loss : 0.437681 model2 loss : 0.032687
[10:41:26.496] iteration 3327 : model1 loss : 0.443103 model2 loss : 0.037411
[10:41:26.666] iteration 3328 : model1 loss : 0.435789 model2 loss : 0.029632
[10:41:26.840] iteration 3329 : model1 loss : 0.443204 model2 loss : 0.038157
[10:41:27.008] iteration 3330 : model1 loss : 0.445963 model2 loss : 0.035521
[10:41:27.181] iteration 3331 : model1 loss : 0.444550 model2 loss : 0.037856
[10:41:27.348] iteration 3332 : model1 loss : 0.445031 model2 loss : 0.040299
[10:41:27.520] iteration 3333 : model1 loss : 0.444126 model2 loss : 0.034868
[10:41:29.481] iteration 3334 : model1 loss : 0.442663 model2 loss : 0.033864
[10:41:29.651] iteration 3335 : model1 loss : 0.439704 model2 loss : 0.036460
[10:41:29.825] iteration 3336 : model1 loss : 0.440268 model2 loss : 0.033650
[10:41:29.992] iteration 3337 : model1 loss : 0.438423 model2 loss : 0.038865
[10:41:30.166] iteration 3338 : model1 loss : 0.441187 model2 loss : 0.034016
[10:41:30.332] iteration 3339 : model1 loss : 0.444391 model2 loss : 0.040845
[10:41:30.507] iteration 3340 : model1 loss : 0.441333 model2 loss : 0.045030
[10:41:30.675] iteration 3341 : model1 loss : 0.436353 model2 loss : 0.031612
[10:41:30.850] iteration 3342 : model1 loss : 0.447151 model2 loss : 0.036541
[10:41:31.018] iteration 3343 : model1 loss : 0.448800 model2 loss : 0.036094
[10:41:31.189] iteration 3344 : model1 loss : 0.437107 model2 loss : 0.034420
[10:41:31.356] iteration 3345 : model1 loss : 0.444393 model2 loss : 0.036896
[10:41:31.534] iteration 3346 : model1 loss : 0.441709 model2 loss : 0.033871
[10:41:31.705] iteration 3347 : model1 loss : 0.435920 model2 loss : 0.031383
[10:41:31.876] iteration 3348 : model1 loss : 0.442806 model2 loss : 0.039065
[10:41:32.043] iteration 3349 : model1 loss : 0.445975 model2 loss : 0.039384
[10:41:32.217] iteration 3350 : model1 loss : 0.442808 model2 loss : 0.035249
[10:41:32.385] iteration 3351 : model1 loss : 0.438636 model2 loss : 0.032770
[10:41:32.557] iteration 3352 : model1 loss : 0.440262 model2 loss : 0.032972
[10:41:32.728] iteration 3353 : model1 loss : 0.439205 model2 loss : 0.029714
[10:41:32.902] iteration 3354 : model1 loss : 0.434388 model2 loss : 0.027996
[10:41:33.071] iteration 3355 : model1 loss : 0.438143 model2 loss : 0.035128
[10:41:33.245] iteration 3356 : model1 loss : 0.443825 model2 loss : 0.043450
[10:41:33.415] iteration 3357 : model1 loss : 0.437793 model2 loss : 0.031367
[10:41:33.588] iteration 3358 : model1 loss : 0.444563 model2 loss : 0.031465
[10:41:33.756] iteration 3359 : model1 loss : 0.440105 model2 loss : 0.033024
[10:41:33.931] iteration 3360 : model1 loss : 0.437482 model2 loss : 0.033329
[10:41:34.101] iteration 3361 : model1 loss : 0.437959 model2 loss : 0.033419
[10:41:34.274] iteration 3362 : model1 loss : 0.439755 model2 loss : 0.034385
[10:41:34.441] iteration 3363 : model1 loss : 0.441821 model2 loss : 0.038126
[10:41:34.616] iteration 3364 : model1 loss : 0.441329 model2 loss : 0.035285
[10:41:34.784] iteration 3365 : model1 loss : 0.446756 model2 loss : 0.039007
[10:41:34.955] iteration 3366 : model1 loss : 0.438201 model2 loss : 0.035819
[10:41:36.972] iteration 3367 : model1 loss : 0.436888 model2 loss : 0.031313
[10:41:37.143] iteration 3368 : model1 loss : 0.440069 model2 loss : 0.035479
[10:41:37.318] iteration 3369 : model1 loss : 0.441219 model2 loss : 0.039303
[10:41:37.489] iteration 3370 : model1 loss : 0.442458 model2 loss : 0.039545
[10:41:37.662] iteration 3371 : model1 loss : 0.441724 model2 loss : 0.037060
[10:41:37.831] iteration 3372 : model1 loss : 0.449063 model2 loss : 0.037979
[10:41:38.003] iteration 3373 : model1 loss : 0.436223 model2 loss : 0.032231
[10:41:38.174] iteration 3374 : model1 loss : 0.433050 model2 loss : 0.031253
[10:41:38.346] iteration 3375 : model1 loss : 0.442521 model2 loss : 0.035792
[10:41:38.520] iteration 3376 : model1 loss : 0.437880 model2 loss : 0.027201
[10:41:38.692] iteration 3377 : model1 loss : 0.441185 model2 loss : 0.039464
[10:41:38.861] iteration 3378 : model1 loss : 0.442001 model2 loss : 0.032923
[10:41:39.034] iteration 3379 : model1 loss : 0.437519 model2 loss : 0.034672
[10:41:39.203] iteration 3380 : model1 loss : 0.437453 model2 loss : 0.032292
[10:41:39.376] iteration 3381 : model1 loss : 0.437756 model2 loss : 0.030993
[10:41:39.544] iteration 3382 : model1 loss : 0.444620 model2 loss : 0.043770
[10:41:39.717] iteration 3383 : model1 loss : 0.439325 model2 loss : 0.032151
[10:41:39.885] iteration 3384 : model1 loss : 0.440962 model2 loss : 0.029164
[10:41:40.059] iteration 3385 : model1 loss : 0.437941 model2 loss : 0.030243
[10:41:40.230] iteration 3386 : model1 loss : 0.444805 model2 loss : 0.054645
[10:41:40.404] iteration 3387 : model1 loss : 0.436304 model2 loss : 0.032032
[10:41:40.574] iteration 3388 : model1 loss : 0.441225 model2 loss : 0.032724
[10:41:40.751] iteration 3389 : model1 loss : 0.441206 model2 loss : 0.032171
[10:41:40.924] iteration 3390 : model1 loss : 0.435628 model2 loss : 0.032721
[10:41:41.096] iteration 3391 : model1 loss : 0.442840 model2 loss : 0.041792
[10:41:41.266] iteration 3392 : model1 loss : 0.438001 model2 loss : 0.034916
[10:41:41.437] iteration 3393 : model1 loss : 0.438346 model2 loss : 0.033628
[10:41:41.605] iteration 3394 : model1 loss : 0.440513 model2 loss : 0.041027
[10:41:41.778] iteration 3395 : model1 loss : 0.444176 model2 loss : 0.041951
[10:41:41.945] iteration 3396 : model1 loss : 0.437231 model2 loss : 0.034109
[10:41:42.119] iteration 3397 : model1 loss : 0.438860 model2 loss : 0.033457
[10:41:42.285] iteration 3398 : model1 loss : 0.441323 model2 loss : 0.044747
[10:41:42.457] iteration 3399 : model1 loss : 0.440554 model2 loss : 0.040363
[10:41:44.430] iteration 3400 : model1 loss : 0.439080 model2 loss : 0.034184
[10:41:44.601] iteration 3401 : model1 loss : 0.441491 model2 loss : 0.036528
[10:41:44.775] iteration 3402 : model1 loss : 0.442102 model2 loss : 0.039006
[10:41:44.943] iteration 3403 : model1 loss : 0.440118 model2 loss : 0.030141
[10:41:45.118] iteration 3404 : model1 loss : 0.437135 model2 loss : 0.032533
[10:41:45.285] iteration 3405 : model1 loss : 0.440991 model2 loss : 0.029045
[10:41:45.456] iteration 3406 : model1 loss : 0.437272 model2 loss : 0.030462
[10:41:45.624] iteration 3407 : model1 loss : 0.435423 model2 loss : 0.029962
[10:41:45.796] iteration 3408 : model1 loss : 0.442291 model2 loss : 0.037118
[10:41:45.963] iteration 3409 : model1 loss : 0.433490 model2 loss : 0.027287
[10:41:46.139] iteration 3410 : model1 loss : 0.440281 model2 loss : 0.030831
[10:41:46.308] iteration 3411 : model1 loss : 0.436391 model2 loss : 0.032014
[10:41:46.481] iteration 3412 : model1 loss : 0.443296 model2 loss : 0.035101
[10:41:46.651] iteration 3413 : model1 loss : 0.439717 model2 loss : 0.029912
[10:41:46.824] iteration 3414 : model1 loss : 0.438949 model2 loss : 0.041358
[10:41:46.991] iteration 3415 : model1 loss : 0.437412 model2 loss : 0.030959
[10:41:47.166] iteration 3416 : model1 loss : 0.438091 model2 loss : 0.031791
[10:41:47.334] iteration 3417 : model1 loss : 0.440731 model2 loss : 0.034256
[10:41:47.508] iteration 3418 : model1 loss : 0.439198 model2 loss : 0.033888
[10:41:47.678] iteration 3419 : model1 loss : 0.446657 model2 loss : 0.035473
[10:41:47.852] iteration 3420 : model1 loss : 0.439548 model2 loss : 0.036294
[10:41:48.020] iteration 3421 : model1 loss : 0.440830 model2 loss : 0.042211
[10:41:48.192] iteration 3422 : model1 loss : 0.432570 model2 loss : 0.031114
[10:41:48.360] iteration 3423 : model1 loss : 0.440886 model2 loss : 0.040439
[10:41:48.536] iteration 3424 : model1 loss : 0.434928 model2 loss : 0.028822
[10:41:48.707] iteration 3425 : model1 loss : 0.442190 model2 loss : 0.041283
[10:41:48.881] iteration 3426 : model1 loss : 0.441151 model2 loss : 0.032849
[10:41:49.048] iteration 3427 : model1 loss : 0.447180 model2 loss : 0.041061
[10:41:49.222] iteration 3428 : model1 loss : 0.436177 model2 loss : 0.045917
[10:41:49.388] iteration 3429 : model1 loss : 0.443872 model2 loss : 0.038034
[10:41:49.561] iteration 3430 : model1 loss : 0.437891 model2 loss : 0.033132
[10:41:49.730] iteration 3431 : model1 loss : 0.440405 model2 loss : 0.032732
[10:41:49.903] iteration 3432 : model1 loss : 0.437427 model2 loss : 0.032876
[10:41:51.867] iteration 3433 : model1 loss : 0.439154 model2 loss : 0.032250
[10:41:52.034] iteration 3434 : model1 loss : 0.441756 model2 loss : 0.036693
[10:41:52.210] iteration 3435 : model1 loss : 0.438712 model2 loss : 0.034056
[10:41:52.378] iteration 3436 : model1 loss : 0.439733 model2 loss : 0.031926
[10:41:52.552] iteration 3437 : model1 loss : 0.437391 model2 loss : 0.032621
[10:41:52.727] iteration 3438 : model1 loss : 0.439484 model2 loss : 0.034653
[10:41:52.901] iteration 3439 : model1 loss : 0.441192 model2 loss : 0.034702
[10:41:53.073] iteration 3440 : model1 loss : 0.434625 model2 loss : 0.029045
[10:41:53.247] iteration 3441 : model1 loss : 0.438361 model2 loss : 0.035486
[10:41:53.415] iteration 3442 : model1 loss : 0.443548 model2 loss : 0.039975
[10:41:53.586] iteration 3443 : model1 loss : 0.439955 model2 loss : 0.038623
[10:41:53.757] iteration 3444 : model1 loss : 0.442820 model2 loss : 0.038493
[10:41:53.933] iteration 3445 : model1 loss : 0.438372 model2 loss : 0.042525
[10:41:54.104] iteration 3446 : model1 loss : 0.442236 model2 loss : 0.037446
[10:41:54.279] iteration 3447 : model1 loss : 0.441414 model2 loss : 0.034366
[10:41:54.447] iteration 3448 : model1 loss : 0.438217 model2 loss : 0.033819
[10:41:54.620] iteration 3449 : model1 loss : 0.435486 model2 loss : 0.030950
[10:41:54.789] iteration 3450 : model1 loss : 0.439499 model2 loss : 0.031727
[10:41:54.964] iteration 3451 : model1 loss : 0.436991 model2 loss : 0.034441
[10:41:55.135] iteration 3452 : model1 loss : 0.438330 model2 loss : 0.031184
[10:41:55.309] iteration 3453 : model1 loss : 0.446884 model2 loss : 0.042973
[10:41:55.478] iteration 3454 : model1 loss : 0.432173 model2 loss : 0.030144
[10:41:55.650] iteration 3455 : model1 loss : 0.443708 model2 loss : 0.035492
[10:41:55.822] iteration 3456 : model1 loss : 0.439329 model2 loss : 0.034849
[10:41:55.993] iteration 3457 : model1 loss : 0.443921 model2 loss : 0.037060
[10:41:56.163] iteration 3458 : model1 loss : 0.438142 model2 loss : 0.037566
[10:41:56.337] iteration 3459 : model1 loss : 0.439821 model2 loss : 0.032736
[10:41:56.510] iteration 3460 : model1 loss : 0.442693 model2 loss : 0.036703
[10:41:56.685] iteration 3461 : model1 loss : 0.439748 model2 loss : 0.030179
[10:41:56.852] iteration 3462 : model1 loss : 0.441041 model2 loss : 0.038766
[10:41:57.025] iteration 3463 : model1 loss : 0.442282 model2 loss : 0.035126
[10:41:57.194] iteration 3464 : model1 loss : 0.444256 model2 loss : 0.045652
[10:41:57.365] iteration 3465 : model1 loss : 0.440942 model2 loss : 0.041596
[10:41:59.330] iteration 3466 : model1 loss : 0.442920 model2 loss : 0.043646
[10:41:59.506] iteration 3467 : model1 loss : 0.440479 model2 loss : 0.032189
[10:41:59.682] iteration 3468 : model1 loss : 0.436039 model2 loss : 0.030615
[10:41:59.851] iteration 3469 : model1 loss : 0.443528 model2 loss : 0.039136
[10:42:00.024] iteration 3470 : model1 loss : 0.435754 model2 loss : 0.028553
[10:42:00.198] iteration 3471 : model1 loss : 0.440418 model2 loss : 0.030381
[10:42:00.373] iteration 3472 : model1 loss : 0.446479 model2 loss : 0.034904
[10:42:00.543] iteration 3473 : model1 loss : 0.438531 model2 loss : 0.030254
[10:42:00.717] iteration 3474 : model1 loss : 0.441470 model2 loss : 0.035711
[10:42:00.888] iteration 3475 : model1 loss : 0.433380 model2 loss : 0.033373
[10:42:01.062] iteration 3476 : model1 loss : 0.445500 model2 loss : 0.041715
[10:42:01.232] iteration 3477 : model1 loss : 0.438170 model2 loss : 0.034113
[10:42:01.407] iteration 3478 : model1 loss : 0.435514 model2 loss : 0.030926
[10:42:01.574] iteration 3479 : model1 loss : 0.438407 model2 loss : 0.031694
[10:42:01.749] iteration 3480 : model1 loss : 0.435579 model2 loss : 0.029097
[10:42:01.919] iteration 3481 : model1 loss : 0.444686 model2 loss : 0.038607
[10:42:02.093] iteration 3482 : model1 loss : 0.443102 model2 loss : 0.034826
[10:42:02.266] iteration 3483 : model1 loss : 0.442545 model2 loss : 0.031867
[10:42:02.440] iteration 3484 : model1 loss : 0.437749 model2 loss : 0.039382
[10:42:02.608] iteration 3485 : model1 loss : 0.437848 model2 loss : 0.034139
[10:42:02.781] iteration 3486 : model1 loss : 0.442067 model2 loss : 0.035725
[10:42:02.950] iteration 3487 : model1 loss : 0.441147 model2 loss : 0.039404
[10:42:03.123] iteration 3488 : model1 loss : 0.434022 model2 loss : 0.033290
[10:42:03.292] iteration 3489 : model1 loss : 0.443219 model2 loss : 0.038102
[10:42:03.465] iteration 3490 : model1 loss : 0.436248 model2 loss : 0.029407
[10:42:03.635] iteration 3491 : model1 loss : 0.445203 model2 loss : 0.045244
[10:42:03.808] iteration 3492 : model1 loss : 0.440275 model2 loss : 0.030572
[10:42:03.978] iteration 3493 : model1 loss : 0.437288 model2 loss : 0.029580
[10:42:04.152] iteration 3494 : model1 loss : 0.439494 model2 loss : 0.031110
[10:42:04.318] iteration 3495 : model1 loss : 0.442896 model2 loss : 0.034176
[10:42:04.493] iteration 3496 : model1 loss : 0.446528 model2 loss : 0.038216
[10:42:04.662] iteration 3497 : model1 loss : 0.437331 model2 loss : 0.032093
[10:42:04.834] iteration 3498 : model1 loss : 0.435841 model2 loss : 0.034957
[10:42:06.811] iteration 3499 : model1 loss : 0.444053 model2 loss : 0.033884
[10:42:06.984] iteration 3500 : model1 loss : 0.433828 model2 loss : 0.031929
[10:42:07.159] iteration 3501 : model1 loss : 0.443007 model2 loss : 0.040604
[10:42:07.329] iteration 3502 : model1 loss : 0.436908 model2 loss : 0.031680
[10:42:07.505] iteration 3503 : model1 loss : 0.441513 model2 loss : 0.037875
[10:42:07.675] iteration 3504 : model1 loss : 0.447785 model2 loss : 0.043985
[10:42:07.848] iteration 3505 : model1 loss : 0.439627 model2 loss : 0.030535
[10:42:08.015] iteration 3506 : model1 loss : 0.440774 model2 loss : 0.036245
[10:42:08.188] iteration 3507 : model1 loss : 0.438011 model2 loss : 0.033932
[10:42:08.354] iteration 3508 : model1 loss : 0.438755 model2 loss : 0.032264
[10:42:08.530] iteration 3509 : model1 loss : 0.437103 model2 loss : 0.029868
[10:42:08.699] iteration 3510 : model1 loss : 0.444110 model2 loss : 0.032225
[10:42:08.872] iteration 3511 : model1 loss : 0.440957 model2 loss : 0.036962
[10:42:09.040] iteration 3512 : model1 loss : 0.437991 model2 loss : 0.030972
[10:42:09.215] iteration 3513 : model1 loss : 0.441249 model2 loss : 0.041821
[10:42:09.386] iteration 3514 : model1 loss : 0.440602 model2 loss : 0.026432
[10:42:09.560] iteration 3515 : model1 loss : 0.436534 model2 loss : 0.030690
[10:42:09.730] iteration 3516 : model1 loss : 0.442104 model2 loss : 0.033234
[10:42:09.906] iteration 3517 : model1 loss : 0.438537 model2 loss : 0.031684
[10:42:10.073] iteration 3518 : model1 loss : 0.444190 model2 loss : 0.041683
[10:42:10.248] iteration 3519 : model1 loss : 0.442679 model2 loss : 0.043848
[10:42:10.415] iteration 3520 : model1 loss : 0.438850 model2 loss : 0.032163
[10:42:10.589] iteration 3521 : model1 loss : 0.443563 model2 loss : 0.040561
[10:42:10.760] iteration 3522 : model1 loss : 0.439770 model2 loss : 0.031877
[10:42:10.936] iteration 3523 : model1 loss : 0.443194 model2 loss : 0.031861
[10:42:11.102] iteration 3524 : model1 loss : 0.435966 model2 loss : 0.036837
[10:42:11.275] iteration 3525 : model1 loss : 0.440850 model2 loss : 0.042142
[10:42:11.444] iteration 3526 : model1 loss : 0.435461 model2 loss : 0.034527
[10:42:11.617] iteration 3527 : model1 loss : 0.439602 model2 loss : 0.034049
[10:42:11.788] iteration 3528 : model1 loss : 0.437324 model2 loss : 0.033120
[10:42:11.960] iteration 3529 : model1 loss : 0.434788 model2 loss : 0.031294
[10:42:12.128] iteration 3530 : model1 loss : 0.442473 model2 loss : 0.037760
[10:42:12.300] iteration 3531 : model1 loss : 0.439394 model2 loss : 0.037728
[10:42:14.313] iteration 3532 : model1 loss : 0.437292 model2 loss : 0.030654
[10:42:14.483] iteration 3533 : model1 loss : 0.437801 model2 loss : 0.035298
[10:42:14.660] iteration 3534 : model1 loss : 0.440352 model2 loss : 0.038304
[10:42:14.828] iteration 3535 : model1 loss : 0.441058 model2 loss : 0.036338
[10:42:15.001] iteration 3536 : model1 loss : 0.435393 model2 loss : 0.026792
[10:42:15.175] iteration 3537 : model1 loss : 0.442012 model2 loss : 0.032051
[10:42:15.349] iteration 3538 : model1 loss : 0.439629 model2 loss : 0.034500
[10:42:15.519] iteration 3539 : model1 loss : 0.439424 model2 loss : 0.034756
[10:42:15.695] iteration 3540 : model1 loss : 0.443132 model2 loss : 0.041912
[10:42:15.867] iteration 3541 : model1 loss : 0.436952 model2 loss : 0.033539
[10:42:16.040] iteration 3542 : model1 loss : 0.442492 model2 loss : 0.038703
[10:42:16.211] iteration 3543 : model1 loss : 0.439115 model2 loss : 0.033008
[10:42:16.383] iteration 3544 : model1 loss : 0.443479 model2 loss : 0.042774
[10:42:16.553] iteration 3545 : model1 loss : 0.436528 model2 loss : 0.032554
[10:42:16.728] iteration 3546 : model1 loss : 0.438734 model2 loss : 0.031359
[10:42:16.899] iteration 3547 : model1 loss : 0.435918 model2 loss : 0.036397
[10:42:17.072] iteration 3548 : model1 loss : 0.439711 model2 loss : 0.033213
[10:42:17.244] iteration 3549 : model1 loss : 0.442639 model2 loss : 0.036883
[10:42:17.418] iteration 3550 : model1 loss : 0.441079 model2 loss : 0.041949
[10:42:17.586] iteration 3551 : model1 loss : 0.437510 model2 loss : 0.030948
[10:42:17.758] iteration 3552 : model1 loss : 0.440620 model2 loss : 0.036978
[10:42:17.929] iteration 3553 : model1 loss : 0.440314 model2 loss : 0.034946
[10:42:18.103] iteration 3554 : model1 loss : 0.441435 model2 loss : 0.035563
[10:42:18.276] iteration 3555 : model1 loss : 0.442636 model2 loss : 0.037461
[10:42:18.451] iteration 3556 : model1 loss : 0.432635 model2 loss : 0.028052
[10:42:18.617] iteration 3557 : model1 loss : 0.439037 model2 loss : 0.033196
[10:42:18.790] iteration 3558 : model1 loss : 0.437523 model2 loss : 0.032524
[10:42:18.963] iteration 3559 : model1 loss : 0.438113 model2 loss : 0.034544
[10:42:19.139] iteration 3560 : model1 loss : 0.439698 model2 loss : 0.037380
[10:42:19.310] iteration 3561 : model1 loss : 0.435725 model2 loss : 0.031849
[10:42:19.484] iteration 3562 : model1 loss : 0.437504 model2 loss : 0.042594
[10:42:19.652] iteration 3563 : model1 loss : 0.447941 model2 loss : 0.046409
[10:42:19.823] iteration 3564 : model1 loss : 0.437730 model2 loss : 0.031993
[10:42:21.824] iteration 3565 : model1 loss : 0.433365 model2 loss : 0.028291
[10:42:21.992] iteration 3566 : model1 loss : 0.436603 model2 loss : 0.035960
[10:42:22.167] iteration 3567 : model1 loss : 0.437616 model2 loss : 0.035466
[10:42:22.336] iteration 3568 : model1 loss : 0.441131 model2 loss : 0.037528
[10:42:22.512] iteration 3569 : model1 loss : 0.444649 model2 loss : 0.034376
[10:42:22.682] iteration 3570 : model1 loss : 0.436434 model2 loss : 0.026989
[10:42:22.856] iteration 3571 : model1 loss : 0.439946 model2 loss : 0.030387
[10:42:23.024] iteration 3572 : model1 loss : 0.439205 model2 loss : 0.030516
[10:42:23.197] iteration 3573 : model1 loss : 0.441062 model2 loss : 0.036029
[10:42:23.365] iteration 3574 : model1 loss : 0.440571 model2 loss : 0.029747
[10:42:23.539] iteration 3575 : model1 loss : 0.441971 model2 loss : 0.036533
[10:42:23.710] iteration 3576 : model1 loss : 0.438599 model2 loss : 0.030551
[10:42:23.882] iteration 3577 : model1 loss : 0.438623 model2 loss : 0.036676
[10:42:24.051] iteration 3578 : model1 loss : 0.438069 model2 loss : 0.038508
[10:42:24.224] iteration 3579 : model1 loss : 0.439063 model2 loss : 0.031769
[10:42:24.392] iteration 3580 : model1 loss : 0.442204 model2 loss : 0.040576
[10:42:24.567] iteration 3581 : model1 loss : 0.437599 model2 loss : 0.029740
[10:42:24.736] iteration 3582 : model1 loss : 0.437912 model2 loss : 0.037140
[10:42:24.910] iteration 3583 : model1 loss : 0.442549 model2 loss : 0.040599
[10:42:25.077] iteration 3584 : model1 loss : 0.448258 model2 loss : 0.035913
[10:42:25.251] iteration 3585 : model1 loss : 0.441236 model2 loss : 0.036913
[10:42:25.420] iteration 3586 : model1 loss : 0.443139 model2 loss : 0.041940
[10:42:25.594] iteration 3587 : model1 loss : 0.440499 model2 loss : 0.036473
[10:42:25.766] iteration 3588 : model1 loss : 0.440846 model2 loss : 0.033579
[10:42:25.943] iteration 3589 : model1 loss : 0.444734 model2 loss : 0.036327
[10:42:26.111] iteration 3590 : model1 loss : 0.442427 model2 loss : 0.031368
[10:42:26.283] iteration 3591 : model1 loss : 0.438230 model2 loss : 0.031790
[10:42:26.451] iteration 3592 : model1 loss : 0.435216 model2 loss : 0.027034
[10:42:26.622] iteration 3593 : model1 loss : 0.440510 model2 loss : 0.034426
[10:42:26.791] iteration 3594 : model1 loss : 0.441609 model2 loss : 0.034439
[10:42:26.965] iteration 3595 : model1 loss : 0.433977 model2 loss : 0.032702
[10:42:27.130] iteration 3596 : model1 loss : 0.437871 model2 loss : 0.035048
[10:42:27.305] iteration 3597 : model1 loss : 0.441561 model2 loss : 0.041494
[10:42:29.312] iteration 3598 : model1 loss : 0.440623 model2 loss : 0.037837
[10:42:29.486] iteration 3599 : model1 loss : 0.440786 model2 loss : 0.029935
[10:42:29.662] iteration 3600 : model1 loss : 0.436997 model2 loss : 0.028007
[10:42:29.832] iteration 3601 : model1 loss : 0.449483 model2 loss : 0.049156
[10:42:30.004] iteration 3602 : model1 loss : 0.439199 model2 loss : 0.034703
[10:42:30.173] iteration 3603 : model1 loss : 0.430851 model2 loss : 0.030267
[10:42:30.351] iteration 3604 : model1 loss : 0.441503 model2 loss : 0.039156
[10:42:30.525] iteration 3605 : model1 loss : 0.438958 model2 loss : 0.035520
[10:42:30.703] iteration 3606 : model1 loss : 0.439234 model2 loss : 0.036761
[10:42:30.875] iteration 3607 : model1 loss : 0.436148 model2 loss : 0.029810
[10:42:31.048] iteration 3608 : model1 loss : 0.437470 model2 loss : 0.033515
[10:42:31.220] iteration 3609 : model1 loss : 0.442690 model2 loss : 0.040609
[10:42:31.394] iteration 3610 : model1 loss : 0.436062 model2 loss : 0.030041
[10:42:31.564] iteration 3611 : model1 loss : 0.436971 model2 loss : 0.033672
[10:42:31.740] iteration 3612 : model1 loss : 0.438807 model2 loss : 0.033769
[10:42:31.912] iteration 3613 : model1 loss : 0.441848 model2 loss : 0.035084
[10:42:32.085] iteration 3614 : model1 loss : 0.438248 model2 loss : 0.033905
[10:42:32.255] iteration 3615 : model1 loss : 0.435363 model2 loss : 0.032247
[10:42:32.427] iteration 3616 : model1 loss : 0.444718 model2 loss : 0.039087
[10:42:32.594] iteration 3617 : model1 loss : 0.443292 model2 loss : 0.036477
[10:42:32.768] iteration 3618 : model1 loss : 0.440407 model2 loss : 0.034202
[10:42:32.937] iteration 3619 : model1 loss : 0.444103 model2 loss : 0.039677
[10:42:33.109] iteration 3620 : model1 loss : 0.442685 model2 loss : 0.040411
[10:42:33.280] iteration 3621 : model1 loss : 0.440409 model2 loss : 0.034152
[10:42:33.455] iteration 3622 : model1 loss : 0.442609 model2 loss : 0.038914
[10:42:33.626] iteration 3623 : model1 loss : 0.448765 model2 loss : 0.036912
[10:42:33.799] iteration 3624 : model1 loss : 0.439217 model2 loss : 0.030579
[10:42:33.968] iteration 3625 : model1 loss : 0.437623 model2 loss : 0.036487
[10:42:34.140] iteration 3626 : model1 loss : 0.439631 model2 loss : 0.032335
[10:42:34.312] iteration 3627 : model1 loss : 0.442721 model2 loss : 0.037797
[10:42:34.487] iteration 3628 : model1 loss : 0.438313 model2 loss : 0.030687
[10:42:34.655] iteration 3629 : model1 loss : 0.441961 model2 loss : 0.032397
[10:42:34.828] iteration 3630 : model1 loss : 0.435034 model2 loss : 0.027806
[10:42:36.814] iteration 3631 : model1 loss : 0.440108 model2 loss : 0.033438
[10:42:36.984] iteration 3632 : model1 loss : 0.439141 model2 loss : 0.041672
[10:42:37.157] iteration 3633 : model1 loss : 0.445743 model2 loss : 0.060433
[10:42:37.327] iteration 3634 : model1 loss : 0.440279 model2 loss : 0.027734
[10:42:37.504] iteration 3635 : model1 loss : 0.445756 model2 loss : 0.033617
[10:42:37.670] iteration 3636 : model1 loss : 0.443681 model2 loss : 0.030056
[10:42:37.843] iteration 3637 : model1 loss : 0.439633 model2 loss : 0.031836
[10:42:38.011] iteration 3638 : model1 loss : 0.440644 model2 loss : 0.041655
[10:42:38.184] iteration 3639 : model1 loss : 0.440561 model2 loss : 0.034123
[10:42:38.354] iteration 3640 : model1 loss : 0.440751 model2 loss : 0.039377
[10:42:38.531] iteration 3641 : model1 loss : 0.439105 model2 loss : 0.036283
[10:42:38.700] iteration 3642 : model1 loss : 0.435080 model2 loss : 0.029346
[10:42:38.874] iteration 3643 : model1 loss : 0.441108 model2 loss : 0.033049
[10:42:39.042] iteration 3644 : model1 loss : 0.433125 model2 loss : 0.030265
[10:42:39.216] iteration 3645 : model1 loss : 0.436502 model2 loss : 0.029373
[10:42:39.385] iteration 3646 : model1 loss : 0.441898 model2 loss : 0.038279
[10:42:39.560] iteration 3647 : model1 loss : 0.435648 model2 loss : 0.027604
[10:42:39.731] iteration 3648 : model1 loss : 0.445843 model2 loss : 0.036342
[10:42:39.908] iteration 3649 : model1 loss : 0.442944 model2 loss : 0.030893
[10:42:40.074] iteration 3650 : model1 loss : 0.437117 model2 loss : 0.029029
[10:42:40.248] iteration 3651 : model1 loss : 0.440915 model2 loss : 0.034135
[10:42:40.416] iteration 3652 : model1 loss : 0.442899 model2 loss : 0.034584
[10:42:40.588] iteration 3653 : model1 loss : 0.436537 model2 loss : 0.030811
[10:42:40.757] iteration 3654 : model1 loss : 0.442122 model2 loss : 0.033857
[10:42:40.932] iteration 3655 : model1 loss : 0.443084 model2 loss : 0.040158
[10:42:41.099] iteration 3656 : model1 loss : 0.439168 model2 loss : 0.030152
[10:42:41.276] iteration 3657 : model1 loss : 0.443135 model2 loss : 0.034724
[10:42:41.446] iteration 3658 : model1 loss : 0.445660 model2 loss : 0.038480
[10:42:41.618] iteration 3659 : model1 loss : 0.434164 model2 loss : 0.031600
[10:42:41.788] iteration 3660 : model1 loss : 0.439528 model2 loss : 0.033161
[10:42:41.960] iteration 3661 : model1 loss : 0.441825 model2 loss : 0.034268
[10:42:42.127] iteration 3662 : model1 loss : 0.439410 model2 loss : 0.032542
[10:42:42.300] iteration 3663 : model1 loss : 0.442107 model2 loss : 0.036978
[10:42:44.301] iteration 3664 : model1 loss : 0.442131 model2 loss : 0.032995
[10:42:44.470] iteration 3665 : model1 loss : 0.437197 model2 loss : 0.030128
[10:42:44.643] iteration 3666 : model1 loss : 0.444565 model2 loss : 0.035478
[10:42:44.815] iteration 3667 : model1 loss : 0.439755 model2 loss : 0.031371
[10:42:44.987] iteration 3668 : model1 loss : 0.435891 model2 loss : 0.031166
[10:42:45.155] iteration 3669 : model1 loss : 0.441616 model2 loss : 0.038167
[10:42:45.328] iteration 3670 : model1 loss : 0.442334 model2 loss : 0.038508
[10:42:45.498] iteration 3671 : model1 loss : 0.431610 model2 loss : 0.028753
[10:42:45.670] iteration 3672 : model1 loss : 0.440681 model2 loss : 0.031764
[10:42:45.844] iteration 3673 : model1 loss : 0.438411 model2 loss : 0.036149
[10:42:46.016] iteration 3674 : model1 loss : 0.437526 model2 loss : 0.031844
[10:42:46.183] iteration 3675 : model1 loss : 0.443289 model2 loss : 0.035456
[10:42:46.358] iteration 3676 : model1 loss : 0.433592 model2 loss : 0.028149
[10:42:46.530] iteration 3677 : model1 loss : 0.442454 model2 loss : 0.037944
[10:42:46.705] iteration 3678 : model1 loss : 0.439719 model2 loss : 0.034439
[10:42:46.875] iteration 3679 : model1 loss : 0.438336 model2 loss : 0.036237
[10:42:47.049] iteration 3680 : model1 loss : 0.439836 model2 loss : 0.037433
[10:42:47.219] iteration 3681 : model1 loss : 0.436079 model2 loss : 0.032850
[10:42:47.393] iteration 3682 : model1 loss : 0.444210 model2 loss : 0.042177
[10:42:47.560] iteration 3683 : model1 loss : 0.437361 model2 loss : 0.030405
[10:42:47.734] iteration 3684 : model1 loss : 0.439925 model2 loss : 0.033648
[10:42:47.907] iteration 3685 : model1 loss : 0.441390 model2 loss : 0.035738
[10:42:48.080] iteration 3686 : model1 loss : 0.437395 model2 loss : 0.030256
[10:42:48.252] iteration 3687 : model1 loss : 0.438444 model2 loss : 0.038014
[10:42:48.426] iteration 3688 : model1 loss : 0.439922 model2 loss : 0.030476
[10:42:48.596] iteration 3689 : model1 loss : 0.440999 model2 loss : 0.031708
[10:42:48.771] iteration 3690 : model1 loss : 0.438033 model2 loss : 0.032299
[10:42:48.942] iteration 3691 : model1 loss : 0.440505 model2 loss : 0.031658
[10:42:49.115] iteration 3692 : model1 loss : 0.443369 model2 loss : 0.037232
[10:42:49.288] iteration 3693 : model1 loss : 0.437056 model2 loss : 0.030379
[10:42:49.460] iteration 3694 : model1 loss : 0.433343 model2 loss : 0.030149
[10:42:49.626] iteration 3695 : model1 loss : 0.442659 model2 loss : 0.037474
[10:42:49.798] iteration 3696 : model1 loss : 0.439523 model2 loss : 0.032708
[10:42:51.768] iteration 3697 : model1 loss : 0.435327 model2 loss : 0.030364
[10:42:51.936] iteration 3698 : model1 loss : 0.437605 model2 loss : 0.036999
[10:42:52.112] iteration 3699 : model1 loss : 0.444515 model2 loss : 0.043735
[10:42:52.281] iteration 3700 : model1 loss : 0.439393 model2 loss : 0.036238
[10:42:52.454] iteration 3701 : model1 loss : 0.440543 model2 loss : 0.037389
[10:42:52.621] iteration 3702 : model1 loss : 0.435520 model2 loss : 0.029480
[10:42:52.797] iteration 3703 : model1 loss : 0.435601 model2 loss : 0.026167
[10:42:52.965] iteration 3704 : model1 loss : 0.442163 model2 loss : 0.033267
[10:42:53.138] iteration 3705 : model1 loss : 0.440646 model2 loss : 0.035951
[10:42:53.309] iteration 3706 : model1 loss : 0.446869 model2 loss : 0.041279
[10:42:53.481] iteration 3707 : model1 loss : 0.436700 model2 loss : 0.033485
[10:42:53.650] iteration 3708 : model1 loss : 0.437935 model2 loss : 0.029836
[10:42:53.823] iteration 3709 : model1 loss : 0.441237 model2 loss : 0.035895
[10:42:53.991] iteration 3710 : model1 loss : 0.443137 model2 loss : 0.045020
[10:42:54.164] iteration 3711 : model1 loss : 0.437161 model2 loss : 0.036030
[10:42:54.334] iteration 3712 : model1 loss : 0.442394 model2 loss : 0.031746
[10:42:54.518] iteration 3713 : model1 loss : 0.440618 model2 loss : 0.034877
[10:42:54.686] iteration 3714 : model1 loss : 0.436529 model2 loss : 0.032911
[10:42:54.859] iteration 3715 : model1 loss : 0.442516 model2 loss : 0.039863
[10:42:55.028] iteration 3716 : model1 loss : 0.439425 model2 loss : 0.037200
[10:42:55.202] iteration 3717 : model1 loss : 0.444734 model2 loss : 0.034075
[10:42:55.373] iteration 3718 : model1 loss : 0.436251 model2 loss : 0.032896
[10:42:55.548] iteration 3719 : model1 loss : 0.440991 model2 loss : 0.038710
[10:42:55.717] iteration 3720 : model1 loss : 0.442155 model2 loss : 0.041008
[10:42:55.892] iteration 3721 : model1 loss : 0.436880 model2 loss : 0.029849
[10:42:56.061] iteration 3722 : model1 loss : 0.442082 model2 loss : 0.052285
[10:42:56.236] iteration 3723 : model1 loss : 0.439405 model2 loss : 0.034583
[10:42:56.404] iteration 3724 : model1 loss : 0.442636 model2 loss : 0.046924
[10:42:56.578] iteration 3725 : model1 loss : 0.441482 model2 loss : 0.034544
[10:42:56.749] iteration 3726 : model1 loss : 0.434658 model2 loss : 0.033109
[10:42:56.924] iteration 3727 : model1 loss : 0.433452 model2 loss : 0.031037
[10:42:57.090] iteration 3728 : model1 loss : 0.440412 model2 loss : 0.029392
[10:42:57.263] iteration 3729 : model1 loss : 0.437163 model2 loss : 0.036822
[10:42:59.222] iteration 3730 : model1 loss : 0.440193 model2 loss : 0.031881
[10:42:59.394] iteration 3731 : model1 loss : 0.438684 model2 loss : 0.032344
[10:42:59.569] iteration 3732 : model1 loss : 0.441937 model2 loss : 0.032685
[10:42:59.737] iteration 3733 : model1 loss : 0.443755 model2 loss : 0.036569
[10:42:59.912] iteration 3734 : model1 loss : 0.442195 model2 loss : 0.031408
[10:43:00.080] iteration 3735 : model1 loss : 0.444114 model2 loss : 0.037137
[10:43:00.258] iteration 3736 : model1 loss : 0.443472 model2 loss : 0.031860
[10:43:00.429] iteration 3737 : model1 loss : 0.438043 model2 loss : 0.038522
[10:43:00.603] iteration 3738 : model1 loss : 0.445540 model2 loss : 0.037112
[10:43:00.773] iteration 3739 : model1 loss : 0.440110 model2 loss : 0.035471
[10:43:00.949] iteration 3740 : model1 loss : 0.439905 model2 loss : 0.051254
[10:43:01.118] iteration 3741 : model1 loss : 0.439867 model2 loss : 0.034772
[10:43:01.292] iteration 3742 : model1 loss : 0.438131 model2 loss : 0.031750
[10:43:01.461] iteration 3743 : model1 loss : 0.437237 model2 loss : 0.026388
[10:43:01.635] iteration 3744 : model1 loss : 0.439284 model2 loss : 0.034013
[10:43:01.804] iteration 3745 : model1 loss : 0.445547 model2 loss : 0.036463
[10:43:01.979] iteration 3746 : model1 loss : 0.444665 model2 loss : 0.040649
[10:43:02.147] iteration 3747 : model1 loss : 0.440992 model2 loss : 0.036278
[10:43:02.319] iteration 3748 : model1 loss : 0.444265 model2 loss : 0.041920
[10:43:02.488] iteration 3749 : model1 loss : 0.443523 model2 loss : 0.038617
[10:43:02.660] iteration 3750 : model1 loss : 0.435874 model2 loss : 0.033938
[10:43:02.830] iteration 3751 : model1 loss : 0.433883 model2 loss : 0.028480
[10:43:03.003] iteration 3752 : model1 loss : 0.445009 model2 loss : 0.038709
[10:43:03.171] iteration 3753 : model1 loss : 0.438857 model2 loss : 0.031682
[10:43:03.344] iteration 3754 : model1 loss : 0.438426 model2 loss : 0.038074
[10:43:03.518] iteration 3755 : model1 loss : 0.439796 model2 loss : 0.033903
[10:43:03.690] iteration 3756 : model1 loss : 0.436149 model2 loss : 0.027605
[10:43:03.861] iteration 3757 : model1 loss : 0.435621 model2 loss : 0.031597
[10:43:04.035] iteration 3758 : model1 loss : 0.434553 model2 loss : 0.030057
[10:43:04.205] iteration 3759 : model1 loss : 0.440493 model2 loss : 0.040953
[10:43:04.381] iteration 3760 : model1 loss : 0.435406 model2 loss : 0.030705
[10:43:04.548] iteration 3761 : model1 loss : 0.441547 model2 loss : 0.034018
[10:43:04.718] iteration 3762 : model1 loss : 0.437768 model2 loss : 0.036773
[10:43:06.711] iteration 3763 : model1 loss : 0.430629 model2 loss : 0.035042
[10:43:06.883] iteration 3764 : model1 loss : 0.440329 model2 loss : 0.031619
[10:43:07.056] iteration 3765 : model1 loss : 0.440832 model2 loss : 0.033917
[10:43:07.224] iteration 3766 : model1 loss : 0.444441 model2 loss : 0.040073
[10:43:07.401] iteration 3767 : model1 loss : 0.435480 model2 loss : 0.030080
[10:43:07.570] iteration 3768 : model1 loss : 0.437975 model2 loss : 0.030864
[10:43:07.744] iteration 3769 : model1 loss : 0.434925 model2 loss : 0.026832
[10:43:07.917] iteration 3770 : model1 loss : 0.439216 model2 loss : 0.037315
[10:43:08.089] iteration 3771 : model1 loss : 0.444601 model2 loss : 0.036231
[10:43:08.256] iteration 3772 : model1 loss : 0.439788 model2 loss : 0.037761
[10:43:08.432] iteration 3773 : model1 loss : 0.439122 model2 loss : 0.031298
[10:43:08.601] iteration 3774 : model1 loss : 0.441827 model2 loss : 0.034221
[10:43:08.774] iteration 3775 : model1 loss : 0.440928 model2 loss : 0.032310
[10:43:08.944] iteration 3776 : model1 loss : 0.442902 model2 loss : 0.034584
[10:43:09.115] iteration 3777 : model1 loss : 0.440275 model2 loss : 0.031520
[10:43:09.284] iteration 3778 : model1 loss : 0.441693 model2 loss : 0.037436
[10:43:09.456] iteration 3779 : model1 loss : 0.441067 model2 loss : 0.031993
[10:43:09.625] iteration 3780 : model1 loss : 0.440210 model2 loss : 0.031096
[10:43:09.800] iteration 3781 : model1 loss : 0.442039 model2 loss : 0.030785
[10:43:09.974] iteration 3782 : model1 loss : 0.443068 model2 loss : 0.034206
[10:43:10.149] iteration 3783 : model1 loss : 0.440155 model2 loss : 0.034850
[10:43:10.317] iteration 3784 : model1 loss : 0.433772 model2 loss : 0.030742
[10:43:10.490] iteration 3785 : model1 loss : 0.441405 model2 loss : 0.036643
[10:43:10.658] iteration 3786 : model1 loss : 0.438182 model2 loss : 0.036017
[10:43:10.835] iteration 3787 : model1 loss : 0.437204 model2 loss : 0.039838
[10:43:11.002] iteration 3788 : model1 loss : 0.441085 model2 loss : 0.035585
[10:43:11.174] iteration 3789 : model1 loss : 0.439507 model2 loss : 0.032338
[10:43:11.345] iteration 3790 : model1 loss : 0.441524 model2 loss : 0.030799
[10:43:11.520] iteration 3791 : model1 loss : 0.438772 model2 loss : 0.034734
[10:43:11.688] iteration 3792 : model1 loss : 0.439977 model2 loss : 0.037222
[10:43:11.862] iteration 3793 : model1 loss : 0.444136 model2 loss : 0.038323
[10:43:12.028] iteration 3794 : model1 loss : 0.437385 model2 loss : 0.030715
[10:43:12.200] iteration 3795 : model1 loss : 0.436261 model2 loss : 0.031513
[10:43:14.202] iteration 3796 : model1 loss : 0.440064 model2 loss : 0.035565
[10:43:14.377] iteration 3797 : model1 loss : 0.438730 model2 loss : 0.035038
[10:43:14.551] iteration 3798 : model1 loss : 0.433787 model2 loss : 0.027874
[10:43:14.718] iteration 3799 : model1 loss : 0.441877 model2 loss : 0.033290
[10:43:14.891] iteration 3800 : model1 loss : 0.442781 model2 loss : 0.044114
[10:43:15.059] iteration 3801 : model1 loss : 0.434568 model2 loss : 0.028604
[10:43:15.232] iteration 3802 : model1 loss : 0.438232 model2 loss : 0.031433
[10:43:15.403] iteration 3803 : model1 loss : 0.441299 model2 loss : 0.040128
[10:43:15.578] iteration 3804 : model1 loss : 0.433935 model2 loss : 0.029777
[10:43:15.745] iteration 3805 : model1 loss : 0.440164 model2 loss : 0.032502
[10:43:15.922] iteration 3806 : model1 loss : 0.437159 model2 loss : 0.036945
[10:43:16.090] iteration 3807 : model1 loss : 0.438809 model2 loss : 0.032431
[10:43:16.263] iteration 3808 : model1 loss : 0.440686 model2 loss : 0.032494
[10:43:16.434] iteration 3809 : model1 loss : 0.440438 model2 loss : 0.035775
[10:43:16.609] iteration 3810 : model1 loss : 0.435299 model2 loss : 0.028331
[10:43:16.779] iteration 3811 : model1 loss : 0.439754 model2 loss : 0.033577
[10:43:16.951] iteration 3812 : model1 loss : 0.441752 model2 loss : 0.036988
[10:43:17.120] iteration 3813 : model1 loss : 0.436423 model2 loss : 0.030895
[10:43:17.296] iteration 3814 : model1 loss : 0.439231 model2 loss : 0.031310
[10:43:17.467] iteration 3815 : model1 loss : 0.435702 model2 loss : 0.031910
[10:43:17.640] iteration 3816 : model1 loss : 0.438607 model2 loss : 0.032974
[10:43:17.810] iteration 3817 : model1 loss : 0.438478 model2 loss : 0.032462
[10:43:17.987] iteration 3818 : model1 loss : 0.436294 model2 loss : 0.029508
[10:43:18.155] iteration 3819 : model1 loss : 0.437941 model2 loss : 0.033187
[10:43:18.328] iteration 3820 : model1 loss : 0.442867 model2 loss : 0.039729
[10:43:18.529] iteration 3821 : model1 loss : 0.438467 model2 loss : 0.030012
[10:43:18.706] iteration 3822 : model1 loss : 0.441561 model2 loss : 0.045274
[10:43:18.877] iteration 3823 : model1 loss : 0.436135 model2 loss : 0.031813
[10:43:19.050] iteration 3824 : model1 loss : 0.439233 model2 loss : 0.031149
[10:43:19.219] iteration 3825 : model1 loss : 0.449429 model2 loss : 0.038825
[10:43:19.391] iteration 3826 : model1 loss : 0.436837 model2 loss : 0.030841
[10:43:19.559] iteration 3827 : model1 loss : 0.446846 model2 loss : 0.047609
[10:43:19.729] iteration 3828 : model1 loss : 0.440284 model2 loss : 0.033809
[10:43:21.720] iteration 3829 : model1 loss : 0.435124 model2 loss : 0.031796
[10:43:21.894] iteration 3830 : model1 loss : 0.439678 model2 loss : 0.033562
[10:43:22.068] iteration 3831 : model1 loss : 0.439221 model2 loss : 0.044478
[10:43:22.237] iteration 3832 : model1 loss : 0.437087 model2 loss : 0.037437
[10:43:22.412] iteration 3833 : model1 loss : 0.438325 model2 loss : 0.033552
[10:43:22.580] iteration 3834 : model1 loss : 0.439280 model2 loss : 0.032046
[10:43:22.752] iteration 3835 : model1 loss : 0.439917 model2 loss : 0.031518
[10:43:22.926] iteration 3836 : model1 loss : 0.439774 model2 loss : 0.036800
[10:43:23.098] iteration 3837 : model1 loss : 0.439865 model2 loss : 0.042454
[10:43:23.266] iteration 3838 : model1 loss : 0.445221 model2 loss : 0.033548
[10:43:23.442] iteration 3839 : model1 loss : 0.445466 model2 loss : 0.047088
[10:43:23.610] iteration 3840 : model1 loss : 0.437956 model2 loss : 0.031732
[10:43:23.784] iteration 3841 : model1 loss : 0.436173 model2 loss : 0.028802
[10:43:23.954] iteration 3842 : model1 loss : 0.439654 model2 loss : 0.036340
[10:43:24.124] iteration 3843 : model1 loss : 0.434563 model2 loss : 0.031361
[10:43:24.294] iteration 3844 : model1 loss : 0.435353 model2 loss : 0.034105
[10:43:24.470] iteration 3845 : model1 loss : 0.445430 model2 loss : 0.041316
[10:43:24.639] iteration 3846 : model1 loss : 0.435608 model2 loss : 0.035919
[10:43:24.814] iteration 3847 : model1 loss : 0.435540 model2 loss : 0.038583
[10:43:24.985] iteration 3848 : model1 loss : 0.433315 model2 loss : 0.029321
[10:43:25.157] iteration 3849 : model1 loss : 0.441528 model2 loss : 0.035923
[10:43:25.329] iteration 3850 : model1 loss : 0.441667 model2 loss : 0.033630
[10:43:25.505] iteration 3851 : model1 loss : 0.440093 model2 loss : 0.041604
[10:43:25.672] iteration 3852 : model1 loss : 0.445259 model2 loss : 0.040191
[10:43:25.848] iteration 3853 : model1 loss : 0.434911 model2 loss : 0.028354
[10:43:26.015] iteration 3854 : model1 loss : 0.438999 model2 loss : 0.035608
[10:43:26.188] iteration 3855 : model1 loss : 0.434796 model2 loss : 0.028856
[10:43:26.360] iteration 3856 : model1 loss : 0.439643 model2 loss : 0.032756
[10:43:26.537] iteration 3857 : model1 loss : 0.442115 model2 loss : 0.032050
[10:43:26.706] iteration 3858 : model1 loss : 0.440255 model2 loss : 0.036361
[10:43:26.882] iteration 3859 : model1 loss : 0.446331 model2 loss : 0.047947
[10:43:27.051] iteration 3860 : model1 loss : 0.442085 model2 loss : 0.036701
[10:43:27.220] iteration 3861 : model1 loss : 0.436926 model2 loss : 0.033755
[10:43:29.183] iteration 3862 : model1 loss : 0.437877 model2 loss : 0.032313
[10:43:29.355] iteration 3863 : model1 loss : 0.441424 model2 loss : 0.033022
[10:43:29.537] iteration 3864 : model1 loss : 0.439364 model2 loss : 0.032090
[10:43:29.704] iteration 3865 : model1 loss : 0.440690 model2 loss : 0.034383
[10:43:29.878] iteration 3866 : model1 loss : 0.442206 model2 loss : 0.032999
[10:43:30.046] iteration 3867 : model1 loss : 0.439280 model2 loss : 0.035557
[10:43:30.220] iteration 3868 : model1 loss : 0.435511 model2 loss : 0.035719
[10:43:30.390] iteration 3869 : model1 loss : 0.434786 model2 loss : 0.032662
[10:43:30.564] iteration 3870 : model1 loss : 0.437666 model2 loss : 0.033487
[10:43:30.732] iteration 3871 : model1 loss : 0.437410 model2 loss : 0.037945
[10:43:30.910] iteration 3872 : model1 loss : 0.441604 model2 loss : 0.035405
[10:43:31.078] iteration 3873 : model1 loss : 0.437748 model2 loss : 0.030724
[10:43:31.250] iteration 3874 : model1 loss : 0.438962 model2 loss : 0.033041
[10:43:31.419] iteration 3875 : model1 loss : 0.440711 model2 loss : 0.035888
[10:43:31.591] iteration 3876 : model1 loss : 0.442777 model2 loss : 0.037431
[10:43:31.758] iteration 3877 : model1 loss : 0.440220 model2 loss : 0.037791
[10:43:31.933] iteration 3878 : model1 loss : 0.439346 model2 loss : 0.035334
[10:43:32.102] iteration 3879 : model1 loss : 0.436010 model2 loss : 0.030710
[10:43:32.273] iteration 3880 : model1 loss : 0.434339 model2 loss : 0.035607
[10:43:32.448] iteration 3881 : model1 loss : 0.437872 model2 loss : 0.038219
[10:43:32.621] iteration 3882 : model1 loss : 0.439284 model2 loss : 0.046096
[10:43:32.788] iteration 3883 : model1 loss : 0.438832 model2 loss : 0.035394
[10:43:32.963] iteration 3884 : model1 loss : 0.441061 model2 loss : 0.039545
[10:43:33.130] iteration 3885 : model1 loss : 0.438722 model2 loss : 0.031413
[10:43:33.306] iteration 3886 : model1 loss : 0.444071 model2 loss : 0.031934
[10:43:33.476] iteration 3887 : model1 loss : 0.441413 model2 loss : 0.040183
[10:43:33.651] iteration 3888 : model1 loss : 0.440140 model2 loss : 0.034434
[10:43:33.821] iteration 3889 : model1 loss : 0.440103 model2 loss : 0.034112
[10:43:33.996] iteration 3890 : model1 loss : 0.439054 model2 loss : 0.038102
[10:43:34.166] iteration 3891 : model1 loss : 0.443125 model2 loss : 0.045110
[10:43:34.341] iteration 3892 : model1 loss : 0.437067 model2 loss : 0.033274
[10:43:34.511] iteration 3893 : model1 loss : 0.434421 model2 loss : 0.031413
[10:43:34.682] iteration 3894 : model1 loss : 0.438955 model2 loss : 0.035120
[10:43:36.734] iteration 3895 : model1 loss : 0.437266 model2 loss : 0.031328
[10:43:36.909] iteration 3896 : model1 loss : 0.435119 model2 loss : 0.036695
[10:43:37.083] iteration 3897 : model1 loss : 0.438764 model2 loss : 0.037186
[10:43:37.251] iteration 3898 : model1 loss : 0.437185 model2 loss : 0.032048
[10:43:37.439] iteration 3899 : model1 loss : 0.446130 model2 loss : 0.037951
[10:43:37.608] iteration 3900 : model1 loss : 0.438687 model2 loss : 0.037948
[10:43:37.780] iteration 3901 : model1 loss : 0.437371 model2 loss : 0.035000
[10:43:37.952] iteration 3902 : model1 loss : 0.441686 model2 loss : 0.034756
[10:43:38.122] iteration 3903 : model1 loss : 0.436167 model2 loss : 0.031891
[10:43:38.291] iteration 3904 : model1 loss : 0.439861 model2 loss : 0.030035
[10:43:38.465] iteration 3905 : model1 loss : 0.443110 model2 loss : 0.032723
[10:43:38.633] iteration 3906 : model1 loss : 0.445338 model2 loss : 0.044832
[10:43:38.807] iteration 3907 : model1 loss : 0.439984 model2 loss : 0.034138
[10:43:38.990] iteration 3908 : model1 loss : 0.436118 model2 loss : 0.033747
[10:43:39.164] iteration 3909 : model1 loss : 0.435997 model2 loss : 0.031945
[10:43:39.334] iteration 3910 : model1 loss : 0.443130 model2 loss : 0.040034
[10:43:39.511] iteration 3911 : model1 loss : 0.443798 model2 loss : 0.031654
[10:43:39.681] iteration 3912 : model1 loss : 0.439822 model2 loss : 0.032520
[10:43:39.856] iteration 3913 : model1 loss : 0.437824 model2 loss : 0.030979
[10:43:40.025] iteration 3914 : model1 loss : 0.435547 model2 loss : 0.031394
[10:43:40.198] iteration 3915 : model1 loss : 0.440782 model2 loss : 0.037366
[10:43:40.370] iteration 3916 : model1 loss : 0.442480 model2 loss : 0.037466
[10:43:40.549] iteration 3917 : model1 loss : 0.438589 model2 loss : 0.034876
[10:43:40.720] iteration 3918 : model1 loss : 0.436901 model2 loss : 0.031074
[10:43:40.895] iteration 3919 : model1 loss : 0.434953 model2 loss : 0.028569
[10:43:41.064] iteration 3920 : model1 loss : 0.440130 model2 loss : 0.035046
[10:43:41.237] iteration 3921 : model1 loss : 0.436953 model2 loss : 0.034193
[10:43:41.408] iteration 3922 : model1 loss : 0.439676 model2 loss : 0.034522
[10:43:41.582] iteration 3923 : model1 loss : 0.445833 model2 loss : 0.034061
[10:43:41.752] iteration 3924 : model1 loss : 0.431637 model2 loss : 0.028102
[10:43:41.924] iteration 3925 : model1 loss : 0.441275 model2 loss : 0.037181
[10:43:42.091] iteration 3926 : model1 loss : 0.438509 model2 loss : 0.032947
[10:43:42.262] iteration 3927 : model1 loss : 0.437900 model2 loss : 0.034094
[10:43:44.228] iteration 3928 : model1 loss : 0.442007 model2 loss : 0.033892
[10:43:44.402] iteration 3929 : model1 loss : 0.442034 model2 loss : 0.037243
[10:43:44.579] iteration 3930 : model1 loss : 0.437784 model2 loss : 0.030513
[10:43:44.747] iteration 3931 : model1 loss : 0.438475 model2 loss : 0.036147
[10:43:44.922] iteration 3932 : model1 loss : 0.437590 model2 loss : 0.046236
[10:43:45.093] iteration 3933 : model1 loss : 0.438865 model2 loss : 0.029250
[10:43:45.267] iteration 3934 : model1 loss : 0.440271 model2 loss : 0.038270
[10:43:45.439] iteration 3935 : model1 loss : 0.444945 model2 loss : 0.043765
[10:43:45.616] iteration 3936 : model1 loss : 0.438722 model2 loss : 0.034670
[10:43:45.785] iteration 3937 : model1 loss : 0.437534 model2 loss : 0.040328
[10:43:45.960] iteration 3938 : model1 loss : 0.442189 model2 loss : 0.034018
[10:43:46.131] iteration 3939 : model1 loss : 0.438187 model2 loss : 0.032130
[10:43:46.305] iteration 3940 : model1 loss : 0.440428 model2 loss : 0.037360
[10:43:46.476] iteration 3941 : model1 loss : 0.442956 model2 loss : 0.033870
[10:43:46.648] iteration 3942 : model1 loss : 0.436347 model2 loss : 0.030517
[10:43:46.818] iteration 3943 : model1 loss : 0.434976 model2 loss : 0.035134
[10:43:46.991] iteration 3944 : model1 loss : 0.436372 model2 loss : 0.027270
[10:43:47.162] iteration 3945 : model1 loss : 0.436252 model2 loss : 0.046077
[10:43:47.337] iteration 3946 : model1 loss : 0.446426 model2 loss : 0.033221
[10:43:47.511] iteration 3947 : model1 loss : 0.434554 model2 loss : 0.027404
[10:43:47.684] iteration 3948 : model1 loss : 0.438390 model2 loss : 0.039622
[10:43:47.855] iteration 3949 : model1 loss : 0.444040 model2 loss : 0.043002
[10:43:48.029] iteration 3950 : model1 loss : 0.441233 model2 loss : 0.039000
[10:43:48.197] iteration 3951 : model1 loss : 0.439965 model2 loss : 0.038985
[10:43:48.373] iteration 3952 : model1 loss : 0.442677 model2 loss : 0.034094
[10:43:48.543] iteration 3953 : model1 loss : 0.440168 model2 loss : 0.033431
[10:43:48.716] iteration 3954 : model1 loss : 0.441792 model2 loss : 0.041039
[10:43:48.887] iteration 3955 : model1 loss : 0.440422 model2 loss : 0.036864
[10:43:49.061] iteration 3956 : model1 loss : 0.437690 model2 loss : 0.032613
[10:43:49.231] iteration 3957 : model1 loss : 0.440665 model2 loss : 0.034271
[10:43:49.406] iteration 3958 : model1 loss : 0.435146 model2 loss : 0.033224
[10:43:49.575] iteration 3959 : model1 loss : 0.440025 model2 loss : 0.033483
[10:43:49.745] iteration 3960 : model1 loss : 0.437688 model2 loss : 0.032720
[10:43:51.750] iteration 3961 : model1 loss : 0.441384 model2 loss : 0.036484
[10:43:51.922] iteration 3962 : model1 loss : 0.436671 model2 loss : 0.036571
[10:43:52.097] iteration 3963 : model1 loss : 0.445067 model2 loss : 0.035481
[10:43:52.266] iteration 3964 : model1 loss : 0.436247 model2 loss : 0.027937
[10:43:52.443] iteration 3965 : model1 loss : 0.438016 model2 loss : 0.028730
[10:43:52.611] iteration 3966 : model1 loss : 0.437676 model2 loss : 0.035104
[10:43:52.782] iteration 3967 : model1 loss : 0.439128 model2 loss : 0.029294
[10:43:52.955] iteration 3968 : model1 loss : 0.440043 model2 loss : 0.034901
[10:43:53.128] iteration 3969 : model1 loss : 0.439498 model2 loss : 0.036024
[10:43:53.300] iteration 3970 : model1 loss : 0.437413 model2 loss : 0.034820
[10:43:53.478] iteration 3971 : model1 loss : 0.434823 model2 loss : 0.028150
[10:43:53.645] iteration 3972 : model1 loss : 0.439557 model2 loss : 0.034589
[10:43:53.817] iteration 3973 : model1 loss : 0.440153 model2 loss : 0.031429
[10:43:53.987] iteration 3974 : model1 loss : 0.439906 model2 loss : 0.042306
[10:43:54.162] iteration 3975 : model1 loss : 0.440492 model2 loss : 0.038970
[10:43:54.337] iteration 3976 : model1 loss : 0.440439 model2 loss : 0.034082
[10:43:54.516] iteration 3977 : model1 loss : 0.446241 model2 loss : 0.038464
[10:43:54.684] iteration 3978 : model1 loss : 0.444670 model2 loss : 0.033278
[10:43:54.859] iteration 3979 : model1 loss : 0.440114 model2 loss : 0.037854
[10:43:55.029] iteration 3980 : model1 loss : 0.446111 model2 loss : 0.043767
[10:43:55.201] iteration 3981 : model1 loss : 0.439484 model2 loss : 0.031170
[10:43:55.373] iteration 3982 : model1 loss : 0.441060 model2 loss : 0.029389
[10:43:55.548] iteration 3983 : model1 loss : 0.439119 model2 loss : 0.030867
[10:43:55.715] iteration 3984 : model1 loss : 0.444787 model2 loss : 0.039339
[10:43:55.890] iteration 3985 : model1 loss : 0.444408 model2 loss : 0.045679
[10:43:56.059] iteration 3986 : model1 loss : 0.441730 model2 loss : 0.036282
[10:43:56.232] iteration 3987 : model1 loss : 0.439512 model2 loss : 0.028635
[10:43:56.403] iteration 3988 : model1 loss : 0.437636 model2 loss : 0.029064
[10:43:56.577] iteration 3989 : model1 loss : 0.435817 model2 loss : 0.038246
[10:43:56.746] iteration 3990 : model1 loss : 0.435089 model2 loss : 0.029197
[10:43:56.924] iteration 3991 : model1 loss : 0.437045 model2 loss : 0.029710
[10:43:57.090] iteration 3992 : model1 loss : 0.439698 model2 loss : 0.043807
[10:43:57.262] iteration 3993 : model1 loss : 0.435487 model2 loss : 0.030927
[10:43:59.213] iteration 3994 : model1 loss : 0.439894 model2 loss : 0.032668
[10:43:59.384] iteration 3995 : model1 loss : 0.435193 model2 loss : 0.029910
[10:43:59.561] iteration 3996 : model1 loss : 0.442443 model2 loss : 0.043245
[10:43:59.728] iteration 3997 : model1 loss : 0.441014 model2 loss : 0.037004
[10:43:59.904] iteration 3998 : model1 loss : 0.440604 model2 loss : 0.040700
[10:44:00.072] iteration 3999 : model1 loss : 0.436661 model2 loss : 0.027337
[10:44:00.249] iteration 4000 : model1 loss : 0.441358 model2 loss : 0.031788
[10:44:08.860] iteration 4000 : model1_mean_dice : 0.828010 model1_mean_hd95 : 7.874767
[10:44:17.409] iteration 4000 : model2_mean_dice : 0.878528 model2_mean_hd95 : 5.738996
[10:44:17.588] iteration 4001 : model1 loss : 0.439149 model2 loss : 0.032166
[10:44:17.763] iteration 4002 : model1 loss : 0.434437 model2 loss : 0.026543
[10:44:17.937] iteration 4003 : model1 loss : 0.438097 model2 loss : 0.038202
[10:44:18.113] iteration 4004 : model1 loss : 0.433694 model2 loss : 0.031199
[10:44:18.280] iteration 4005 : model1 loss : 0.437349 model2 loss : 0.034540
[10:44:18.452] iteration 4006 : model1 loss : 0.438391 model2 loss : 0.034367
[10:44:18.619] iteration 4007 : model1 loss : 0.434233 model2 loss : 0.026854
[10:44:18.791] iteration 4008 : model1 loss : 0.437273 model2 loss : 0.034281
[10:44:18.962] iteration 4009 : model1 loss : 0.436484 model2 loss : 0.029939
[10:44:19.134] iteration 4010 : model1 loss : 0.436471 model2 loss : 0.032178
[10:44:19.304] iteration 4011 : model1 loss : 0.441148 model2 loss : 0.034780
[10:44:19.477] iteration 4012 : model1 loss : 0.436004 model2 loss : 0.033630
[10:44:19.644] iteration 4013 : model1 loss : 0.440853 model2 loss : 0.036229
[10:44:19.815] iteration 4014 : model1 loss : 0.441357 model2 loss : 0.032301
[10:44:19.986] iteration 4015 : model1 loss : 0.442468 model2 loss : 0.035712
[10:44:20.157] iteration 4016 : model1 loss : 0.444246 model2 loss : 0.047881
[10:44:20.323] iteration 4017 : model1 loss : 0.441625 model2 loss : 0.038835
[10:44:20.496] iteration 4018 : model1 loss : 0.441817 model2 loss : 0.036470
[10:44:20.663] iteration 4019 : model1 loss : 0.439225 model2 loss : 0.036284
[10:44:20.838] iteration 4020 : model1 loss : 0.439762 model2 loss : 0.032399
[10:44:21.007] iteration 4021 : model1 loss : 0.440597 model2 loss : 0.034082
[10:44:21.181] iteration 4022 : model1 loss : 0.443518 model2 loss : 0.039949
[10:44:21.351] iteration 4023 : model1 loss : 0.439337 model2 loss : 0.037264
[10:44:21.528] iteration 4024 : model1 loss : 0.437083 model2 loss : 0.034955
[10:44:21.695] iteration 4025 : model1 loss : 0.433785 model2 loss : 0.030329
[10:44:21.866] iteration 4026 : model1 loss : 0.441991 model2 loss : 0.029716
[10:44:23.892] iteration 4027 : model1 loss : 0.437733 model2 loss : 0.030804
[10:44:24.061] iteration 4028 : model1 loss : 0.437712 model2 loss : 0.032995
[10:44:24.233] iteration 4029 : model1 loss : 0.439671 model2 loss : 0.037087
[10:44:24.400] iteration 4030 : model1 loss : 0.432186 model2 loss : 0.029900
[10:44:24.577] iteration 4031 : model1 loss : 0.439695 model2 loss : 0.034951
[10:44:24.743] iteration 4032 : model1 loss : 0.441165 model2 loss : 0.034516
[10:44:24.920] iteration 4033 : model1 loss : 0.441981 model2 loss : 0.030554
[10:44:25.088] iteration 4034 : model1 loss : 0.438248 model2 loss : 0.031737
[10:44:25.262] iteration 4035 : model1 loss : 0.438678 model2 loss : 0.034842
[10:44:25.432] iteration 4036 : model1 loss : 0.441662 model2 loss : 0.031672
[10:44:25.608] iteration 4037 : model1 loss : 0.449439 model2 loss : 0.036616
[10:44:25.792] iteration 4038 : model1 loss : 0.438894 model2 loss : 0.033428
[10:44:25.966] iteration 4039 : model1 loss : 0.443252 model2 loss : 0.043082
[10:44:26.132] iteration 4040 : model1 loss : 0.443660 model2 loss : 0.042903
[10:44:26.305] iteration 4041 : model1 loss : 0.439954 model2 loss : 0.043900
[10:44:26.476] iteration 4042 : model1 loss : 0.440463 model2 loss : 0.042704
[10:44:26.650] iteration 4043 : model1 loss : 0.446284 model2 loss : 0.037336
[10:44:26.819] iteration 4044 : model1 loss : 0.440840 model2 loss : 0.034559
[10:44:26.992] iteration 4045 : model1 loss : 0.442331 model2 loss : 0.038515
[10:44:27.160] iteration 4046 : model1 loss : 0.440085 model2 loss : 0.036594
[10:44:27.332] iteration 4047 : model1 loss : 0.438383 model2 loss : 0.033225
[10:44:27.504] iteration 4048 : model1 loss : 0.441783 model2 loss : 0.034483
[10:44:27.679] iteration 4049 : model1 loss : 0.435598 model2 loss : 0.030847
[10:44:27.847] iteration 4050 : model1 loss : 0.437132 model2 loss : 0.032498
[10:44:28.020] iteration 4051 : model1 loss : 0.433541 model2 loss : 0.039535
[10:44:28.188] iteration 4052 : model1 loss : 0.433300 model2 loss : 0.031612
[10:44:28.360] iteration 4053 : model1 loss : 0.441379 model2 loss : 0.035915
[10:44:28.533] iteration 4054 : model1 loss : 0.437045 model2 loss : 0.032389
[10:44:28.707] iteration 4055 : model1 loss : 0.436199 model2 loss : 0.039075
[10:44:28.877] iteration 4056 : model1 loss : 0.444152 model2 loss : 0.035605
[10:44:29.050] iteration 4057 : model1 loss : 0.434832 model2 loss : 0.027638
[10:44:29.217] iteration 4058 : model1 loss : 0.445678 model2 loss : 0.036019
[10:44:29.386] iteration 4059 : model1 loss : 0.443633 model2 loss : 0.035604
[10:44:31.414] iteration 4060 : model1 loss : 0.435684 model2 loss : 0.031198
[10:44:31.589] iteration 4061 : model1 loss : 0.433432 model2 loss : 0.030009
[10:44:31.763] iteration 4062 : model1 loss : 0.439527 model2 loss : 0.037112
[10:44:31.931] iteration 4063 : model1 loss : 0.440092 model2 loss : 0.028102
[10:44:32.106] iteration 4064 : model1 loss : 0.433257 model2 loss : 0.029066
[10:44:32.275] iteration 4065 : model1 loss : 0.442250 model2 loss : 0.034481
[10:44:32.447] iteration 4066 : model1 loss : 0.446210 model2 loss : 0.057097
[10:44:32.617] iteration 4067 : model1 loss : 0.441989 model2 loss : 0.032270
[10:44:32.789] iteration 4068 : model1 loss : 0.440502 model2 loss : 0.036277
[10:44:32.960] iteration 4069 : model1 loss : 0.434734 model2 loss : 0.028496
[10:44:33.133] iteration 4070 : model1 loss : 0.442193 model2 loss : 0.038710
[10:44:33.303] iteration 4071 : model1 loss : 0.436585 model2 loss : 0.027481
[10:44:33.476] iteration 4072 : model1 loss : 0.435266 model2 loss : 0.033604
[10:44:33.643] iteration 4073 : model1 loss : 0.443429 model2 loss : 0.038063
[10:44:33.822] iteration 4074 : model1 loss : 0.438107 model2 loss : 0.032424
[10:44:33.993] iteration 4075 : model1 loss : 0.441960 model2 loss : 0.033644
[10:44:34.165] iteration 4076 : model1 loss : 0.441109 model2 loss : 0.030245
[10:44:34.334] iteration 4077 : model1 loss : 0.450834 model2 loss : 0.040750
[10:44:34.510] iteration 4078 : model1 loss : 0.450215 model2 loss : 0.053174
[10:44:34.678] iteration 4079 : model1 loss : 0.436595 model2 loss : 0.030667
[10:44:34.851] iteration 4080 : model1 loss : 0.436632 model2 loss : 0.031802
[10:44:35.021] iteration 4081 : model1 loss : 0.441134 model2 loss : 0.037403
[10:44:35.198] iteration 4082 : model1 loss : 0.439911 model2 loss : 0.035810
[10:44:35.364] iteration 4083 : model1 loss : 0.444031 model2 loss : 0.041669
[10:44:35.541] iteration 4084 : model1 loss : 0.440174 model2 loss : 0.039511
[10:44:35.709] iteration 4085 : model1 loss : 0.440075 model2 loss : 0.037308
[10:44:35.881] iteration 4086 : model1 loss : 0.437089 model2 loss : 0.039947
[10:44:36.053] iteration 4087 : model1 loss : 0.438131 model2 loss : 0.041074
[10:44:36.227] iteration 4088 : model1 loss : 0.438729 model2 loss : 0.034464
[10:44:36.396] iteration 4089 : model1 loss : 0.435492 model2 loss : 0.031124
[10:44:36.573] iteration 4090 : model1 loss : 0.439641 model2 loss : 0.039587
[10:44:36.738] iteration 4091 : model1 loss : 0.435156 model2 loss : 0.030480
[10:44:36.913] iteration 4092 : model1 loss : 0.442413 model2 loss : 0.038144
[10:44:38.876] iteration 4093 : model1 loss : 0.434045 model2 loss : 0.031466
[10:44:39.047] iteration 4094 : model1 loss : 0.443760 model2 loss : 0.037591
[10:44:39.223] iteration 4095 : model1 loss : 0.435962 model2 loss : 0.029014
[10:44:39.391] iteration 4096 : model1 loss : 0.441946 model2 loss : 0.044164
[10:44:39.566] iteration 4097 : model1 loss : 0.447939 model2 loss : 0.032165
[10:44:39.735] iteration 4098 : model1 loss : 0.438342 model2 loss : 0.034022
[10:44:39.912] iteration 4099 : model1 loss : 0.439534 model2 loss : 0.030080
[10:44:40.082] iteration 4100 : model1 loss : 0.438941 model2 loss : 0.031460
[10:44:40.254] iteration 4101 : model1 loss : 0.436653 model2 loss : 0.029011
[10:44:40.423] iteration 4102 : model1 loss : 0.439081 model2 loss : 0.036263
[10:44:40.597] iteration 4103 : model1 loss : 0.440361 model2 loss : 0.035359
[10:44:40.763] iteration 4104 : model1 loss : 0.446448 model2 loss : 0.037184
[10:44:40.939] iteration 4105 : model1 loss : 0.440252 model2 loss : 0.031778
[10:44:41.108] iteration 4106 : model1 loss : 0.437310 model2 loss : 0.029873
[10:44:41.283] iteration 4107 : model1 loss : 0.439948 model2 loss : 0.032310
[10:44:41.453] iteration 4108 : model1 loss : 0.433995 model2 loss : 0.027176
[10:44:41.628] iteration 4109 : model1 loss : 0.443408 model2 loss : 0.039382
[10:44:41.796] iteration 4110 : model1 loss : 0.442061 model2 loss : 0.036294
[10:44:41.970] iteration 4111 : model1 loss : 0.436092 model2 loss : 0.031867
[10:44:42.139] iteration 4112 : model1 loss : 0.437775 model2 loss : 0.034118
[10:44:42.312] iteration 4113 : model1 loss : 0.431457 model2 loss : 0.030894
[10:44:42.483] iteration 4114 : model1 loss : 0.439006 model2 loss : 0.037263
[10:44:42.656] iteration 4115 : model1 loss : 0.440264 model2 loss : 0.032477
[10:44:42.823] iteration 4116 : model1 loss : 0.439087 model2 loss : 0.036767
[10:44:42.999] iteration 4117 : model1 loss : 0.442695 model2 loss : 0.038778
[10:44:43.167] iteration 4118 : model1 loss : 0.439921 model2 loss : 0.036117
[10:44:43.342] iteration 4119 : model1 loss : 0.436633 model2 loss : 0.034593
[10:44:43.515] iteration 4120 : model1 loss : 0.438195 model2 loss : 0.036767
[10:44:43.687] iteration 4121 : model1 loss : 0.445118 model2 loss : 0.038112
[10:44:43.855] iteration 4122 : model1 loss : 0.442602 model2 loss : 0.034242
[10:44:44.027] iteration 4123 : model1 loss : 0.443076 model2 loss : 0.038160
[10:44:44.194] iteration 4124 : model1 loss : 0.443335 model2 loss : 0.046463
[10:44:44.364] iteration 4125 : model1 loss : 0.437680 model2 loss : 0.030019
[10:44:46.377] iteration 4126 : model1 loss : 0.439874 model2 loss : 0.036250
[10:44:46.553] iteration 4127 : model1 loss : 0.436821 model2 loss : 0.029063
[10:44:46.727] iteration 4128 : model1 loss : 0.438892 model2 loss : 0.029607
[10:44:46.895] iteration 4129 : model1 loss : 0.436537 model2 loss : 0.031493
[10:44:47.069] iteration 4130 : model1 loss : 0.443515 model2 loss : 0.051576
[10:44:47.238] iteration 4131 : model1 loss : 0.438735 model2 loss : 0.032706
[10:44:47.411] iteration 4132 : model1 loss : 0.444337 model2 loss : 0.037923
[10:44:47.582] iteration 4133 : model1 loss : 0.435723 model2 loss : 0.027811
[10:44:47.753] iteration 4134 : model1 loss : 0.437255 model2 loss : 0.037290
[10:44:47.926] iteration 4135 : model1 loss : 0.438044 model2 loss : 0.031434
[10:44:48.101] iteration 4136 : model1 loss : 0.438769 model2 loss : 0.040208
[10:44:48.270] iteration 4137 : model1 loss : 0.432737 model2 loss : 0.034244
[10:44:48.445] iteration 4138 : model1 loss : 0.437459 model2 loss : 0.034580
[10:44:48.614] iteration 4139 : model1 loss : 0.439151 model2 loss : 0.032403
[10:44:48.784] iteration 4140 : model1 loss : 0.435721 model2 loss : 0.029246
[10:44:48.955] iteration 4141 : model1 loss : 0.445042 model2 loss : 0.034406
[10:44:49.128] iteration 4142 : model1 loss : 0.440165 model2 loss : 0.031667
[10:44:49.295] iteration 4143 : model1 loss : 0.439360 model2 loss : 0.036402
[10:44:49.471] iteration 4144 : model1 loss : 0.439681 model2 loss : 0.037327
[10:44:49.639] iteration 4145 : model1 loss : 0.442968 model2 loss : 0.034670
[10:44:49.811] iteration 4146 : model1 loss : 0.439093 model2 loss : 0.031330
[10:44:49.982] iteration 4147 : model1 loss : 0.441365 model2 loss : 0.034685
[10:44:50.156] iteration 4148 : model1 loss : 0.440115 model2 loss : 0.038526
[10:44:50.323] iteration 4149 : model1 loss : 0.435821 model2 loss : 0.027713
[10:44:50.498] iteration 4150 : model1 loss : 0.441633 model2 loss : 0.036724
[10:44:50.666] iteration 4151 : model1 loss : 0.437959 model2 loss : 0.038537
[10:44:50.842] iteration 4152 : model1 loss : 0.436397 model2 loss : 0.033047
[10:44:51.013] iteration 4153 : model1 loss : 0.433821 model2 loss : 0.030850
[10:44:51.185] iteration 4154 : model1 loss : 0.443298 model2 loss : 0.040716
[10:44:51.353] iteration 4155 : model1 loss : 0.447083 model2 loss : 0.043614
[10:44:51.532] iteration 4156 : model1 loss : 0.438059 model2 loss : 0.037679
[10:44:51.699] iteration 4157 : model1 loss : 0.442171 model2 loss : 0.035945
[10:44:51.871] iteration 4158 : model1 loss : 0.440873 model2 loss : 0.035604
[10:44:53.852] iteration 4159 : model1 loss : 0.437382 model2 loss : 0.030806
[10:44:54.025] iteration 4160 : model1 loss : 0.440144 model2 loss : 0.034039
[10:44:54.199] iteration 4161 : model1 loss : 0.441314 model2 loss : 0.039844
[10:44:54.367] iteration 4162 : model1 loss : 0.441097 model2 loss : 0.031661
[10:44:54.543] iteration 4163 : model1 loss : 0.439576 model2 loss : 0.044594
[10:44:54.711] iteration 4164 : model1 loss : 0.442729 model2 loss : 0.030792
[10:44:54.885] iteration 4165 : model1 loss : 0.437926 model2 loss : 0.036322
[10:44:55.055] iteration 4166 : model1 loss : 0.436443 model2 loss : 0.029906
[10:44:55.229] iteration 4167 : model1 loss : 0.436445 model2 loss : 0.032410
[10:44:55.398] iteration 4168 : model1 loss : 0.439703 model2 loss : 0.032525
[10:44:55.574] iteration 4169 : model1 loss : 0.438265 model2 loss : 0.029274
[10:44:55.741] iteration 4170 : model1 loss : 0.444664 model2 loss : 0.039820
[10:44:55.917] iteration 4171 : model1 loss : 0.438696 model2 loss : 0.034591
[10:44:56.087] iteration 4172 : model1 loss : 0.443176 model2 loss : 0.034975
[10:44:56.261] iteration 4173 : model1 loss : 0.436612 model2 loss : 0.032674
[10:44:56.430] iteration 4174 : model1 loss : 0.438208 model2 loss : 0.030542
[10:44:56.606] iteration 4175 : model1 loss : 0.438913 model2 loss : 0.032534
[10:44:56.774] iteration 4176 : model1 loss : 0.437342 model2 loss : 0.034824
[10:44:56.947] iteration 4177 : model1 loss : 0.436066 model2 loss : 0.037451
[10:44:57.116] iteration 4178 : model1 loss : 0.443754 model2 loss : 0.035339
[10:44:57.290] iteration 4179 : model1 loss : 0.439585 model2 loss : 0.033852
[10:44:57.461] iteration 4180 : model1 loss : 0.440674 model2 loss : 0.030867
[10:44:57.632] iteration 4181 : model1 loss : 0.440532 model2 loss : 0.029325
[10:44:57.801] iteration 4182 : model1 loss : 0.442239 model2 loss : 0.036678
[10:44:57.974] iteration 4183 : model1 loss : 0.436764 model2 loss : 0.028260
[10:44:58.143] iteration 4184 : model1 loss : 0.437151 model2 loss : 0.033688
[10:44:58.314] iteration 4185 : model1 loss : 0.438715 model2 loss : 0.037309
[10:44:58.486] iteration 4186 : model1 loss : 0.436146 model2 loss : 0.028591
[10:44:58.658] iteration 4187 : model1 loss : 0.441162 model2 loss : 0.034651
[10:44:58.826] iteration 4188 : model1 loss : 0.439282 model2 loss : 0.029801
[10:44:59.001] iteration 4189 : model1 loss : 0.440719 model2 loss : 0.032310
[10:44:59.168] iteration 4190 : model1 loss : 0.438142 model2 loss : 0.028860
[10:44:59.338] iteration 4191 : model1 loss : 0.439994 model2 loss : 0.026026
[10:45:01.339] iteration 4192 : model1 loss : 0.442513 model2 loss : 0.035627
[10:45:01.519] iteration 4193 : model1 loss : 0.445973 model2 loss : 0.042163
[10:45:01.691] iteration 4194 : model1 loss : 0.438556 model2 loss : 0.029982
[10:45:01.859] iteration 4195 : model1 loss : 0.435096 model2 loss : 0.031121
[10:45:02.032] iteration 4196 : model1 loss : 0.441206 model2 loss : 0.032254
[10:45:02.198] iteration 4197 : model1 loss : 0.436431 model2 loss : 0.035069
[10:45:02.370] iteration 4198 : model1 loss : 0.440853 model2 loss : 0.032337
[10:45:02.541] iteration 4199 : model1 loss : 0.435861 model2 loss : 0.032091
[10:45:02.713] iteration 4200 : model1 loss : 0.437298 model2 loss : 0.030511
[10:45:02.880] iteration 4201 : model1 loss : 0.440120 model2 loss : 0.034276
[10:45:03.051] iteration 4202 : model1 loss : 0.437595 model2 loss : 0.029797
[10:45:03.219] iteration 4203 : model1 loss : 0.438228 model2 loss : 0.032666
[10:45:03.389] iteration 4204 : model1 loss : 0.431349 model2 loss : 0.024317
[10:45:03.559] iteration 4205 : model1 loss : 0.446523 model2 loss : 0.039368
[10:45:03.732] iteration 4206 : model1 loss : 0.439264 model2 loss : 0.030485
[10:45:03.902] iteration 4207 : model1 loss : 0.433670 model2 loss : 0.029456
[10:45:04.077] iteration 4208 : model1 loss : 0.437594 model2 loss : 0.033249
[10:45:04.245] iteration 4209 : model1 loss : 0.437426 model2 loss : 0.029577
[10:45:04.417] iteration 4210 : model1 loss : 0.438862 model2 loss : 0.030798
[10:45:04.589] iteration 4211 : model1 loss : 0.438824 model2 loss : 0.032762
[10:45:04.762] iteration 4212 : model1 loss : 0.442041 model2 loss : 0.033056
[10:45:04.933] iteration 4213 : model1 loss : 0.441500 model2 loss : 0.039468
[10:45:05.116] iteration 4214 : model1 loss : 0.442096 model2 loss : 0.033989
[10:45:05.285] iteration 4215 : model1 loss : 0.442580 model2 loss : 0.037155
[10:45:05.461] iteration 4216 : model1 loss : 0.443341 model2 loss : 0.038698
[10:45:05.631] iteration 4217 : model1 loss : 0.440539 model2 loss : 0.035307
[10:45:05.804] iteration 4218 : model1 loss : 0.440599 model2 loss : 0.035898
[10:45:05.974] iteration 4219 : model1 loss : 0.435241 model2 loss : 0.028290
[10:45:06.146] iteration 4220 : model1 loss : 0.438844 model2 loss : 0.028437
[10:45:06.314] iteration 4221 : model1 loss : 0.441998 model2 loss : 0.038036
[10:45:06.487] iteration 4222 : model1 loss : 0.441908 model2 loss : 0.031172
[10:45:06.655] iteration 4223 : model1 loss : 0.436490 model2 loss : 0.030910
[10:45:06.828] iteration 4224 : model1 loss : 0.436745 model2 loss : 0.032751
[10:45:08.789] iteration 4225 : model1 loss : 0.437345 model2 loss : 0.028559
[10:45:08.960] iteration 4226 : model1 loss : 0.439138 model2 loss : 0.040403
[10:45:09.136] iteration 4227 : model1 loss : 0.433977 model2 loss : 0.028081
[10:45:09.303] iteration 4228 : model1 loss : 0.439387 model2 loss : 0.033910
[10:45:09.479] iteration 4229 : model1 loss : 0.442412 model2 loss : 0.034545
[10:45:09.649] iteration 4230 : model1 loss : 0.439981 model2 loss : 0.037105
[10:45:09.821] iteration 4231 : model1 loss : 0.435548 model2 loss : 0.032713
[10:45:10.002] iteration 4232 : model1 loss : 0.437522 model2 loss : 0.032988
[10:45:10.176] iteration 4233 : model1 loss : 0.440811 model2 loss : 0.029534
[10:45:10.345] iteration 4234 : model1 loss : 0.434930 model2 loss : 0.027995
[10:45:10.521] iteration 4235 : model1 loss : 0.439523 model2 loss : 0.033861
[10:45:10.690] iteration 4236 : model1 loss : 0.442509 model2 loss : 0.039525
[10:45:10.863] iteration 4237 : model1 loss : 0.437230 model2 loss : 0.030432
[10:45:11.033] iteration 4238 : model1 loss : 0.437080 model2 loss : 0.028236
[10:45:11.207] iteration 4239 : model1 loss : 0.439392 model2 loss : 0.031839
[10:45:11.377] iteration 4240 : model1 loss : 0.442382 model2 loss : 0.028863
[10:45:11.553] iteration 4241 : model1 loss : 0.439256 model2 loss : 0.030990
[10:45:11.721] iteration 4242 : model1 loss : 0.435335 model2 loss : 0.029491
[10:45:11.894] iteration 4243 : model1 loss : 0.439893 model2 loss : 0.049058
[10:45:12.066] iteration 4244 : model1 loss : 0.441646 model2 loss : 0.039596
[10:45:12.241] iteration 4245 : model1 loss : 0.437437 model2 loss : 0.035823
[10:45:12.411] iteration 4246 : model1 loss : 0.443937 model2 loss : 0.039992
[10:45:12.586] iteration 4247 : model1 loss : 0.436394 model2 loss : 0.033117
[10:45:12.755] iteration 4248 : model1 loss : 0.445190 model2 loss : 0.040707
[10:45:12.929] iteration 4249 : model1 loss : 0.441160 model2 loss : 0.032153
[10:45:13.101] iteration 4250 : model1 loss : 0.439767 model2 loss : 0.031047
[10:45:13.276] iteration 4251 : model1 loss : 0.439782 model2 loss : 0.036219
[10:45:13.444] iteration 4252 : model1 loss : 0.441138 model2 loss : 0.036327
[10:45:13.620] iteration 4253 : model1 loss : 0.439863 model2 loss : 0.029517
[10:45:13.789] iteration 4254 : model1 loss : 0.434758 model2 loss : 0.032369
[10:45:13.962] iteration 4255 : model1 loss : 0.439698 model2 loss : 0.035196
[10:45:14.130] iteration 4256 : model1 loss : 0.442033 model2 loss : 0.034008
[10:45:14.301] iteration 4257 : model1 loss : 0.445422 model2 loss : 0.043724
[10:45:16.288] iteration 4258 : model1 loss : 0.442456 model2 loss : 0.035301
[10:45:16.458] iteration 4259 : model1 loss : 0.440576 model2 loss : 0.034085
[10:45:16.632] iteration 4260 : model1 loss : 0.440521 model2 loss : 0.033297
[10:45:16.801] iteration 4261 : model1 loss : 0.436711 model2 loss : 0.028562
[10:45:16.975] iteration 4262 : model1 loss : 0.440580 model2 loss : 0.032937
[10:45:17.143] iteration 4263 : model1 loss : 0.435529 model2 loss : 0.029703
[10:45:17.316] iteration 4264 : model1 loss : 0.445029 model2 loss : 0.031622
[10:45:17.488] iteration 4265 : model1 loss : 0.435581 model2 loss : 0.030577
[10:45:17.660] iteration 4266 : model1 loss : 0.442159 model2 loss : 0.027122
[10:45:17.829] iteration 4267 : model1 loss : 0.435329 model2 loss : 0.028706
[10:45:18.004] iteration 4268 : model1 loss : 0.439264 model2 loss : 0.030987
[10:45:18.174] iteration 4269 : model1 loss : 0.436431 model2 loss : 0.031169
[10:45:18.345] iteration 4270 : model1 loss : 0.434776 model2 loss : 0.031082
[10:45:18.517] iteration 4271 : model1 loss : 0.436477 model2 loss : 0.035653
[10:45:18.689] iteration 4272 : model1 loss : 0.446176 model2 loss : 0.038935
[10:45:18.856] iteration 4273 : model1 loss : 0.438882 model2 loss : 0.029909
[10:45:19.030] iteration 4274 : model1 loss : 0.438999 model2 loss : 0.034527
[10:45:19.199] iteration 4275 : model1 loss : 0.443155 model2 loss : 0.036717
[10:45:19.372] iteration 4276 : model1 loss : 0.441748 model2 loss : 0.035379
[10:45:19.545] iteration 4277 : model1 loss : 0.441928 model2 loss : 0.041548
[10:45:19.719] iteration 4278 : model1 loss : 0.448038 model2 loss : 0.046029
[10:45:19.887] iteration 4279 : model1 loss : 0.439508 model2 loss : 0.032345
[10:45:20.061] iteration 4280 : model1 loss : 0.444501 model2 loss : 0.027594
[10:45:20.229] iteration 4281 : model1 loss : 0.439587 model2 loss : 0.032989
[10:45:20.403] iteration 4282 : model1 loss : 0.435291 model2 loss : 0.028716
[10:45:20.576] iteration 4283 : model1 loss : 0.437444 model2 loss : 0.031965
[10:45:20.751] iteration 4284 : model1 loss : 0.440692 model2 loss : 0.039856
[10:45:20.922] iteration 4285 : model1 loss : 0.438646 model2 loss : 0.032561
[10:45:21.097] iteration 4286 : model1 loss : 0.445472 model2 loss : 0.041428
[10:45:21.265] iteration 4287 : model1 loss : 0.444082 model2 loss : 0.034770
[10:45:21.440] iteration 4288 : model1 loss : 0.437208 model2 loss : 0.031216
[10:45:21.609] iteration 4289 : model1 loss : 0.438674 model2 loss : 0.031630
[10:45:21.782] iteration 4290 : model1 loss : 0.441177 model2 loss : 0.032482
[10:45:23.744] iteration 4291 : model1 loss : 0.440042 model2 loss : 0.032749
[10:45:23.914] iteration 4292 : model1 loss : 0.440684 model2 loss : 0.035871
[10:45:24.091] iteration 4293 : model1 loss : 0.439310 model2 loss : 0.033341
[10:45:24.259] iteration 4294 : model1 loss : 0.437429 model2 loss : 0.030233
[10:45:24.433] iteration 4295 : model1 loss : 0.437460 model2 loss : 0.030579
[10:45:24.604] iteration 4296 : model1 loss : 0.437395 model2 loss : 0.027382
[10:45:24.778] iteration 4297 : model1 loss : 0.438148 model2 loss : 0.030384
[10:45:24.947] iteration 4298 : model1 loss : 0.442425 model2 loss : 0.037865
[10:45:25.122] iteration 4299 : model1 loss : 0.436720 model2 loss : 0.034912
[10:45:25.291] iteration 4300 : model1 loss : 0.434813 model2 loss : 0.024979
[10:45:25.467] iteration 4301 : model1 loss : 0.442379 model2 loss : 0.042104
[10:45:25.637] iteration 4302 : model1 loss : 0.438111 model2 loss : 0.030811
[10:45:25.815] iteration 4303 : model1 loss : 0.437354 model2 loss : 0.029966
[10:45:25.985] iteration 4304 : model1 loss : 0.439038 model2 loss : 0.033096
[10:45:26.157] iteration 4305 : model1 loss : 0.438421 model2 loss : 0.029673
[10:45:26.326] iteration 4306 : model1 loss : 0.445564 model2 loss : 0.038840
[10:45:26.502] iteration 4307 : model1 loss : 0.436195 model2 loss : 0.029424
[10:45:26.670] iteration 4308 : model1 loss : 0.437815 model2 loss : 0.031280
[10:45:26.841] iteration 4309 : model1 loss : 0.439301 model2 loss : 0.034604
[10:45:27.012] iteration 4310 : model1 loss : 0.438238 model2 loss : 0.030919
[10:45:27.186] iteration 4311 : model1 loss : 0.440238 model2 loss : 0.031417
[10:45:27.355] iteration 4312 : model1 loss : 0.437338 model2 loss : 0.032555
[10:45:27.534] iteration 4313 : model1 loss : 0.436991 model2 loss : 0.030021
[10:45:27.704] iteration 4314 : model1 loss : 0.440162 model2 loss : 0.035891
[10:45:27.879] iteration 4315 : model1 loss : 0.443413 model2 loss : 0.040261
[10:45:28.050] iteration 4316 : model1 loss : 0.446050 model2 loss : 0.035927
[10:45:28.222] iteration 4317 : model1 loss : 0.438281 model2 loss : 0.032408
[10:45:28.390] iteration 4318 : model1 loss : 0.446680 model2 loss : 0.042007
[10:45:28.563] iteration 4319 : model1 loss : 0.440679 model2 loss : 0.033064
[10:45:28.731] iteration 4320 : model1 loss : 0.441723 model2 loss : 0.030449
[10:45:28.906] iteration 4321 : model1 loss : 0.437977 model2 loss : 0.033248
[10:45:29.075] iteration 4322 : model1 loss : 0.440392 model2 loss : 0.034728
[10:45:29.246] iteration 4323 : model1 loss : 0.441029 model2 loss : 0.038541
[10:45:31.210] iteration 4324 : model1 loss : 0.446801 model2 loss : 0.033810
[10:45:31.383] iteration 4325 : model1 loss : 0.438027 model2 loss : 0.028013
[10:45:31.564] iteration 4326 : model1 loss : 0.443379 model2 loss : 0.045486
[10:45:31.731] iteration 4327 : model1 loss : 0.442762 model2 loss : 0.034810
[10:45:31.906] iteration 4328 : model1 loss : 0.439440 model2 loss : 0.028399
[10:45:32.078] iteration 4329 : model1 loss : 0.437264 model2 loss : 0.036821
[10:45:32.251] iteration 4330 : model1 loss : 0.439559 model2 loss : 0.031574
[10:45:32.418] iteration 4331 : model1 loss : 0.436818 model2 loss : 0.034308
[10:45:32.590] iteration 4332 : model1 loss : 0.441739 model2 loss : 0.028009
[10:45:32.758] iteration 4333 : model1 loss : 0.441382 model2 loss : 0.030212
[10:45:32.933] iteration 4334 : model1 loss : 0.442235 model2 loss : 0.042944
[10:45:33.103] iteration 4335 : model1 loss : 0.438848 model2 loss : 0.031212
[10:45:33.276] iteration 4336 : model1 loss : 0.439161 model2 loss : 0.028547
[10:45:33.444] iteration 4337 : model1 loss : 0.436032 model2 loss : 0.031822
[10:45:33.621] iteration 4338 : model1 loss : 0.440878 model2 loss : 0.042950
[10:45:33.787] iteration 4339 : model1 loss : 0.441580 model2 loss : 0.041557
[10:45:33.961] iteration 4340 : model1 loss : 0.443991 model2 loss : 0.034569
[10:45:34.133] iteration 4341 : model1 loss : 0.441942 model2 loss : 0.035115
[10:45:34.306] iteration 4342 : model1 loss : 0.438337 model2 loss : 0.032633
[10:45:34.477] iteration 4343 : model1 loss : 0.440937 model2 loss : 0.033931
[10:45:34.653] iteration 4344 : model1 loss : 0.443819 model2 loss : 0.031273
[10:45:34.821] iteration 4345 : model1 loss : 0.437697 model2 loss : 0.029317
[10:45:34.996] iteration 4346 : model1 loss : 0.438469 model2 loss : 0.026903
[10:45:35.167] iteration 4347 : model1 loss : 0.434655 model2 loss : 0.028437
[10:45:35.339] iteration 4348 : model1 loss : 0.440715 model2 loss : 0.029247
[10:45:35.514] iteration 4349 : model1 loss : 0.438940 model2 loss : 0.029516
[10:45:35.688] iteration 4350 : model1 loss : 0.438234 model2 loss : 0.031591
[10:45:35.861] iteration 4351 : model1 loss : 0.435667 model2 loss : 0.034321
[10:45:36.036] iteration 4352 : model1 loss : 0.441739 model2 loss : 0.029995
[10:45:36.205] iteration 4353 : model1 loss : 0.442257 model2 loss : 0.035940
[10:45:36.377] iteration 4354 : model1 loss : 0.441408 model2 loss : 0.037035
[10:45:36.550] iteration 4355 : model1 loss : 0.438176 model2 loss : 0.035983
[10:45:36.733] iteration 4356 : model1 loss : 0.437847 model2 loss : 0.027650
[10:45:38.725] iteration 4357 : model1 loss : 0.434264 model2 loss : 0.028148
[10:45:38.896] iteration 4358 : model1 loss : 0.436720 model2 loss : 0.031755
[10:45:39.072] iteration 4359 : model1 loss : 0.446053 model2 loss : 0.034646
[10:45:39.239] iteration 4360 : model1 loss : 0.442837 model2 loss : 0.034778
[10:45:39.411] iteration 4361 : model1 loss : 0.437595 model2 loss : 0.029047
[10:45:39.582] iteration 4362 : model1 loss : 0.440316 model2 loss : 0.033488
[10:45:39.754] iteration 4363 : model1 loss : 0.440555 model2 loss : 0.034535
[10:45:39.935] iteration 4364 : model1 loss : 0.437697 model2 loss : 0.031467
[10:45:40.109] iteration 4365 : model1 loss : 0.441562 model2 loss : 0.031220
[10:45:40.277] iteration 4366 : model1 loss : 0.434868 model2 loss : 0.029487
[10:45:40.450] iteration 4367 : model1 loss : 0.432937 model2 loss : 0.028615
[10:45:40.621] iteration 4368 : model1 loss : 0.439543 model2 loss : 0.038710
[10:45:40.794] iteration 4369 : model1 loss : 0.441981 model2 loss : 0.032466
[10:45:40.961] iteration 4370 : model1 loss : 0.442444 model2 loss : 0.027782
[10:45:41.136] iteration 4371 : model1 loss : 0.447389 model2 loss : 0.045686
[10:45:41.304] iteration 4372 : model1 loss : 0.438269 model2 loss : 0.027492
[10:45:41.478] iteration 4373 : model1 loss : 0.437343 model2 loss : 0.040687
[10:45:41.650] iteration 4374 : model1 loss : 0.441908 model2 loss : 0.035429
[10:45:41.822] iteration 4375 : model1 loss : 0.442784 model2 loss : 0.038070
[10:45:41.993] iteration 4376 : model1 loss : 0.437158 model2 loss : 0.033750
[10:45:42.164] iteration 4377 : model1 loss : 0.435964 model2 loss : 0.029012
[10:45:42.333] iteration 4378 : model1 loss : 0.447011 model2 loss : 0.034306
[10:45:42.509] iteration 4379 : model1 loss : 0.437166 model2 loss : 0.030678
[10:45:42.677] iteration 4380 : model1 loss : 0.440040 model2 loss : 0.033018
[10:45:42.848] iteration 4381 : model1 loss : 0.437023 model2 loss : 0.029076
[10:45:43.019] iteration 4382 : model1 loss : 0.436392 model2 loss : 0.031558
[10:45:43.192] iteration 4383 : model1 loss : 0.443967 model2 loss : 0.040532
[10:45:43.360] iteration 4384 : model1 loss : 0.442583 model2 loss : 0.037325
[10:45:43.538] iteration 4385 : model1 loss : 0.436216 model2 loss : 0.031430
[10:45:43.706] iteration 4386 : model1 loss : 0.433485 model2 loss : 0.026107
[10:45:43.878] iteration 4387 : model1 loss : 0.443035 model2 loss : 0.034220
[10:45:44.046] iteration 4388 : model1 loss : 0.443331 model2 loss : 0.034740
[10:45:44.219] iteration 4389 : model1 loss : 0.436211 model2 loss : 0.030871
[10:45:46.205] iteration 4390 : model1 loss : 0.443486 model2 loss : 0.040503
[10:45:46.374] iteration 4391 : model1 loss : 0.435466 model2 loss : 0.032872
[10:45:46.555] iteration 4392 : model1 loss : 0.438493 model2 loss : 0.034494
[10:45:46.722] iteration 4393 : model1 loss : 0.446282 model2 loss : 0.043973
[10:45:46.896] iteration 4394 : model1 loss : 0.435180 model2 loss : 0.030453
[10:45:47.068] iteration 4395 : model1 loss : 0.437136 model2 loss : 0.028383
[10:45:47.242] iteration 4396 : model1 loss : 0.435746 model2 loss : 0.029721
[10:45:47.409] iteration 4397 : model1 loss : 0.443994 model2 loss : 0.035983
[10:45:47.583] iteration 4398 : model1 loss : 0.437942 model2 loss : 0.028643
[10:45:47.753] iteration 4399 : model1 loss : 0.437278 model2 loss : 0.029158
[10:45:47.926] iteration 4400 : model1 loss : 0.436285 model2 loss : 0.028207
[10:45:48.111] iteration 4401 : model1 loss : 0.438771 model2 loss : 0.033027
[10:45:48.284] iteration 4402 : model1 loss : 0.448173 model2 loss : 0.062626
[10:45:48.452] iteration 4403 : model1 loss : 0.440429 model2 loss : 0.040203
[10:45:48.629] iteration 4404 : model1 loss : 0.443092 model2 loss : 0.031480
[10:45:48.797] iteration 4405 : model1 loss : 0.440491 model2 loss : 0.034735
[10:45:48.971] iteration 4406 : model1 loss : 0.441844 model2 loss : 0.036991
[10:45:49.142] iteration 4407 : model1 loss : 0.437273 model2 loss : 0.033424
[10:45:49.316] iteration 4408 : model1 loss : 0.436269 model2 loss : 0.039538
[10:45:49.485] iteration 4409 : model1 loss : 0.438147 model2 loss : 0.036229
[10:45:49.661] iteration 4410 : model1 loss : 0.437105 model2 loss : 0.028124
[10:45:49.829] iteration 4411 : model1 loss : 0.434317 model2 loss : 0.030929
[10:45:50.003] iteration 4412 : model1 loss : 0.440253 model2 loss : 0.033226
[10:45:50.173] iteration 4413 : model1 loss : 0.435388 model2 loss : 0.028116
[10:45:50.345] iteration 4414 : model1 loss : 0.438527 model2 loss : 0.031282
[10:45:50.520] iteration 4415 : model1 loss : 0.435655 model2 loss : 0.030910
[10:45:50.694] iteration 4416 : model1 loss : 0.438537 model2 loss : 0.036086
[10:45:50.867] iteration 4417 : model1 loss : 0.439394 model2 loss : 0.033140
[10:45:51.043] iteration 4418 : model1 loss : 0.438291 model2 loss : 0.037085
[10:45:51.211] iteration 4419 : model1 loss : 0.435952 model2 loss : 0.034372
[10:45:51.383] iteration 4420 : model1 loss : 0.440962 model2 loss : 0.030587
[10:45:51.553] iteration 4421 : model1 loss : 0.439221 model2 loss : 0.027900
[10:45:51.726] iteration 4422 : model1 loss : 0.443202 model2 loss : 0.028806
[10:45:53.705] iteration 4423 : model1 loss : 0.435782 model2 loss : 0.028006
[10:45:53.874] iteration 4424 : model1 loss : 0.439335 model2 loss : 0.031350
[10:45:54.050] iteration 4425 : model1 loss : 0.437939 model2 loss : 0.029367
[10:45:54.219] iteration 4426 : model1 loss : 0.434984 model2 loss : 0.028559
[10:45:54.392] iteration 4427 : model1 loss : 0.439132 model2 loss : 0.028128
[10:45:54.564] iteration 4428 : model1 loss : 0.439959 model2 loss : 0.039233
[10:45:54.738] iteration 4429 : model1 loss : 0.437363 model2 loss : 0.031895
[10:45:54.908] iteration 4430 : model1 loss : 0.444908 model2 loss : 0.030772
[10:45:55.080] iteration 4431 : model1 loss : 0.436926 model2 loss : 0.030894
[10:45:55.251] iteration 4432 : model1 loss : 0.441191 model2 loss : 0.031181
[10:45:55.427] iteration 4433 : model1 loss : 0.441318 model2 loss : 0.029007
[10:45:55.600] iteration 4434 : model1 loss : 0.441049 model2 loss : 0.034226
[10:45:55.775] iteration 4435 : model1 loss : 0.437599 model2 loss : 0.026796
[10:45:55.943] iteration 4436 : model1 loss : 0.440479 model2 loss : 0.031478
[10:45:56.115] iteration 4437 : model1 loss : 0.437734 model2 loss : 0.028171
[10:45:56.282] iteration 4438 : model1 loss : 0.439803 model2 loss : 0.033104
[10:45:56.456] iteration 4439 : model1 loss : 0.440780 model2 loss : 0.031610
[10:45:56.626] iteration 4440 : model1 loss : 0.439599 model2 loss : 0.027468
[10:45:56.799] iteration 4441 : model1 loss : 0.438243 model2 loss : 0.031986
[10:45:56.970] iteration 4442 : model1 loss : 0.447370 model2 loss : 0.038812
[10:45:57.144] iteration 4443 : model1 loss : 0.440420 model2 loss : 0.028978
[10:45:57.314] iteration 4444 : model1 loss : 0.437114 model2 loss : 0.030559
[10:45:57.487] iteration 4445 : model1 loss : 0.441275 model2 loss : 0.032862
[10:45:57.660] iteration 4446 : model1 loss : 0.438848 model2 loss : 0.029187
[10:45:57.833] iteration 4447 : model1 loss : 0.436629 model2 loss : 0.032117
[10:45:58.001] iteration 4448 : model1 loss : 0.438871 model2 loss : 0.031981
[10:45:58.175] iteration 4449 : model1 loss : 0.439188 model2 loss : 0.032118
[10:45:58.343] iteration 4450 : model1 loss : 0.436241 model2 loss : 0.033824
[10:45:58.521] iteration 4451 : model1 loss : 0.439927 model2 loss : 0.032702
[10:45:58.692] iteration 4452 : model1 loss : 0.437425 model2 loss : 0.031938
[10:45:58.863] iteration 4453 : model1 loss : 0.437109 model2 loss : 0.027558
[10:45:59.032] iteration 4454 : model1 loss : 0.438109 model2 loss : 0.027716
[10:45:59.204] iteration 4455 : model1 loss : 0.438670 model2 loss : 0.034027
[10:46:01.211] iteration 4456 : model1 loss : 0.438906 model2 loss : 0.032704
[10:46:01.382] iteration 4457 : model1 loss : 0.440398 model2 loss : 0.027767
[10:46:01.560] iteration 4458 : model1 loss : 0.444209 model2 loss : 0.035945
[10:46:01.728] iteration 4459 : model1 loss : 0.435496 model2 loss : 0.030757
[10:46:01.903] iteration 4460 : model1 loss : 0.433757 model2 loss : 0.029636
[10:46:02.073] iteration 4461 : model1 loss : 0.435752 model2 loss : 0.026385
[10:46:02.247] iteration 4462 : model1 loss : 0.442303 model2 loss : 0.034020
[10:46:02.414] iteration 4463 : model1 loss : 0.439244 model2 loss : 0.031033
[10:46:02.589] iteration 4464 : model1 loss : 0.443795 model2 loss : 0.047156
[10:46:02.757] iteration 4465 : model1 loss : 0.446237 model2 loss : 0.041190
[10:46:02.933] iteration 4466 : model1 loss : 0.439870 model2 loss : 0.030208
[10:46:03.105] iteration 4467 : model1 loss : 0.434302 model2 loss : 0.028941
[10:46:03.278] iteration 4468 : model1 loss : 0.439103 model2 loss : 0.033208
[10:46:03.447] iteration 4469 : model1 loss : 0.440510 model2 loss : 0.034800
[10:46:03.619] iteration 4470 : model1 loss : 0.440011 model2 loss : 0.031829
[10:46:03.788] iteration 4471 : model1 loss : 0.440869 model2 loss : 0.036907
[10:46:03.962] iteration 4472 : model1 loss : 0.437411 model2 loss : 0.028428
[10:46:04.132] iteration 4473 : model1 loss : 0.440139 model2 loss : 0.034977
[10:46:04.307] iteration 4474 : model1 loss : 0.442178 model2 loss : 0.027055
[10:46:04.476] iteration 4475 : model1 loss : 0.440982 model2 loss : 0.034005
[10:46:04.651] iteration 4476 : model1 loss : 0.437469 model2 loss : 0.033137
[10:46:04.820] iteration 4477 : model1 loss : 0.440791 model2 loss : 0.037602
[10:46:04.992] iteration 4478 : model1 loss : 0.434482 model2 loss : 0.031022
[10:46:05.164] iteration 4479 : model1 loss : 0.437384 model2 loss : 0.032816
[10:46:05.339] iteration 4480 : model1 loss : 0.437925 model2 loss : 0.033128
[10:46:05.510] iteration 4481 : model1 loss : 0.439954 model2 loss : 0.033652
[10:46:05.684] iteration 4482 : model1 loss : 0.437696 model2 loss : 0.030609
[10:46:05.855] iteration 4483 : model1 loss : 0.438965 model2 loss : 0.025409
[10:46:06.030] iteration 4484 : model1 loss : 0.437521 model2 loss : 0.031937
[10:46:06.199] iteration 4485 : model1 loss : 0.441414 model2 loss : 0.036137
[10:46:06.371] iteration 4486 : model1 loss : 0.434940 model2 loss : 0.033122
[10:46:06.542] iteration 4487 : model1 loss : 0.439179 model2 loss : 0.032106
[10:46:06.715] iteration 4488 : model1 loss : 0.444198 model2 loss : 0.033082
[10:46:08.714] iteration 4489 : model1 loss : 0.432749 model2 loss : 0.030628
[10:46:08.885] iteration 4490 : model1 loss : 0.439377 model2 loss : 0.031915
[10:46:09.061] iteration 4491 : model1 loss : 0.440039 model2 loss : 0.027753
[10:46:09.230] iteration 4492 : model1 loss : 0.439146 model2 loss : 0.030139
[10:46:09.404] iteration 4493 : model1 loss : 0.439202 model2 loss : 0.032726
[10:46:09.576] iteration 4494 : model1 loss : 0.441766 model2 loss : 0.035726
[10:46:09.748] iteration 4495 : model1 loss : 0.441369 model2 loss : 0.030327
[10:46:09.930] iteration 4496 : model1 loss : 0.439297 model2 loss : 0.032299
[10:46:10.108] iteration 4497 : model1 loss : 0.439629 model2 loss : 0.038833
[10:46:10.276] iteration 4498 : model1 loss : 0.438846 model2 loss : 0.033484
[10:46:10.447] iteration 4499 : model1 loss : 0.441380 model2 loss : 0.029462
[10:46:10.620] iteration 4500 : model1 loss : 0.444913 model2 loss : 0.035590
[10:46:10.794] iteration 4501 : model1 loss : 0.439411 model2 loss : 0.025731
[10:46:10.964] iteration 4502 : model1 loss : 0.438605 model2 loss : 0.031496
[10:46:11.137] iteration 4503 : model1 loss : 0.441397 model2 loss : 0.032353
[10:46:11.306] iteration 4504 : model1 loss : 0.436692 model2 loss : 0.030231
[10:46:11.483] iteration 4505 : model1 loss : 0.436632 model2 loss : 0.030999
[10:46:11.654] iteration 4506 : model1 loss : 0.437858 model2 loss : 0.032577
[10:46:11.828] iteration 4507 : model1 loss : 0.438874 model2 loss : 0.027146
[10:46:11.997] iteration 4508 : model1 loss : 0.442477 model2 loss : 0.033145
[10:46:12.174] iteration 4509 : model1 loss : 0.437964 model2 loss : 0.027514
[10:46:12.342] iteration 4510 : model1 loss : 0.441577 model2 loss : 0.033121
[10:46:12.517] iteration 4511 : model1 loss : 0.441155 model2 loss : 0.029893
[10:46:12.688] iteration 4512 : model1 loss : 0.435274 model2 loss : 0.030782
[10:46:12.861] iteration 4513 : model1 loss : 0.439828 model2 loss : 0.025214
[10:46:13.030] iteration 4514 : model1 loss : 0.436923 model2 loss : 0.030914
[10:46:13.205] iteration 4515 : model1 loss : 0.440903 model2 loss : 0.034381
[10:46:13.374] iteration 4516 : model1 loss : 0.439819 model2 loss : 0.030344
[10:46:13.553] iteration 4517 : model1 loss : 0.439359 model2 loss : 0.027813
[10:46:13.722] iteration 4518 : model1 loss : 0.445543 model2 loss : 0.043151
[10:46:13.895] iteration 4519 : model1 loss : 0.437696 model2 loss : 0.032036
[10:46:14.066] iteration 4520 : model1 loss : 0.436469 model2 loss : 0.031208
[10:46:14.240] iteration 4521 : model1 loss : 0.434122 model2 loss : 0.029362
[10:46:16.223] iteration 4522 : model1 loss : 0.435441 model2 loss : 0.029949
[10:46:16.393] iteration 4523 : model1 loss : 0.438074 model2 loss : 0.030700
[10:46:16.572] iteration 4524 : model1 loss : 0.441102 model2 loss : 0.038021
[10:46:16.741] iteration 4525 : model1 loss : 0.439146 model2 loss : 0.034020
[10:46:16.915] iteration 4526 : model1 loss : 0.438050 model2 loss : 0.028709
[10:46:17.085] iteration 4527 : model1 loss : 0.442623 model2 loss : 0.033313
[10:46:17.259] iteration 4528 : model1 loss : 0.440381 model2 loss : 0.031104
[10:46:17.427] iteration 4529 : model1 loss : 0.440205 model2 loss : 0.029177
[10:46:17.604] iteration 4530 : model1 loss : 0.436494 model2 loss : 0.029261
[10:46:17.773] iteration 4531 : model1 loss : 0.446938 model2 loss : 0.046991
[10:46:17.945] iteration 4532 : model1 loss : 0.439445 model2 loss : 0.032304
[10:46:18.116] iteration 4533 : model1 loss : 0.439349 model2 loss : 0.030444
[10:46:18.288] iteration 4534 : model1 loss : 0.443385 model2 loss : 0.037696
[10:46:18.455] iteration 4535 : model1 loss : 0.443643 model2 loss : 0.035367
[10:46:18.632] iteration 4536 : model1 loss : 0.444258 model2 loss : 0.040834
[10:46:18.800] iteration 4537 : model1 loss : 0.436748 model2 loss : 0.032577
[10:46:18.975] iteration 4538 : model1 loss : 0.435201 model2 loss : 0.030674
[10:46:19.146] iteration 4539 : model1 loss : 0.433176 model2 loss : 0.029164
[10:46:19.319] iteration 4540 : model1 loss : 0.436774 model2 loss : 0.029922
[10:46:19.489] iteration 4541 : model1 loss : 0.445519 model2 loss : 0.045063
[10:46:19.665] iteration 4542 : model1 loss : 0.436343 model2 loss : 0.030668
[10:46:19.833] iteration 4543 : model1 loss : 0.442389 model2 loss : 0.035638
[10:46:20.008] iteration 4544 : model1 loss : 0.447731 model2 loss : 0.032912
[10:46:20.179] iteration 4545 : model1 loss : 0.437226 model2 loss : 0.039529
[10:46:20.351] iteration 4546 : model1 loss : 0.438265 model2 loss : 0.032042
[10:46:20.523] iteration 4547 : model1 loss : 0.436967 model2 loss : 0.030075
[10:46:20.697] iteration 4548 : model1 loss : 0.439963 model2 loss : 0.034421
[10:46:20.869] iteration 4549 : model1 loss : 0.438791 model2 loss : 0.039092
[10:46:21.044] iteration 4550 : model1 loss : 0.436720 model2 loss : 0.029479
[10:46:21.214] iteration 4551 : model1 loss : 0.434130 model2 loss : 0.030856
[10:46:21.386] iteration 4552 : model1 loss : 0.438922 model2 loss : 0.040948
[10:46:21.559] iteration 4553 : model1 loss : 0.436353 model2 loss : 0.029821
[10:46:21.730] iteration 4554 : model1 loss : 0.438245 model2 loss : 0.035355
[10:46:23.698] iteration 4555 : model1 loss : 0.435722 model2 loss : 0.028071
[10:46:23.868] iteration 4556 : model1 loss : 0.440930 model2 loss : 0.036019
[10:46:24.044] iteration 4557 : model1 loss : 0.440267 model2 loss : 0.034331
[10:46:24.213] iteration 4558 : model1 loss : 0.441606 model2 loss : 0.033458
[10:46:24.386] iteration 4559 : model1 loss : 0.437097 model2 loss : 0.031526
[10:46:24.559] iteration 4560 : model1 loss : 0.439862 model2 loss : 0.036085
[10:46:24.733] iteration 4561 : model1 loss : 0.437569 model2 loss : 0.032542
[10:46:24.905] iteration 4562 : model1 loss : 0.436221 model2 loss : 0.029343
[10:46:25.078] iteration 4563 : model1 loss : 0.443093 model2 loss : 0.036734
[10:46:25.249] iteration 4564 : model1 loss : 0.435117 model2 loss : 0.030434
[10:46:25.422] iteration 4565 : model1 loss : 0.437897 model2 loss : 0.036436
[10:46:25.592] iteration 4566 : model1 loss : 0.442953 model2 loss : 0.035532
[10:46:25.766] iteration 4567 : model1 loss : 0.440094 model2 loss : 0.029351
[10:46:25.935] iteration 4568 : model1 loss : 0.436863 model2 loss : 0.030110
[10:46:26.109] iteration 4569 : model1 loss : 0.438710 model2 loss : 0.031777
[10:46:26.278] iteration 4570 : model1 loss : 0.438363 model2 loss : 0.033412
[10:46:26.451] iteration 4571 : model1 loss : 0.437009 model2 loss : 0.031529
[10:46:26.623] iteration 4572 : model1 loss : 0.442034 model2 loss : 0.046348
[10:46:26.798] iteration 4573 : model1 loss : 0.447063 model2 loss : 0.041903
[10:46:26.965] iteration 4574 : model1 loss : 0.434354 model2 loss : 0.031892
[10:46:27.140] iteration 4575 : model1 loss : 0.435408 model2 loss : 0.031243
[10:46:27.307] iteration 4576 : model1 loss : 0.436766 model2 loss : 0.030185
[10:46:27.481] iteration 4577 : model1 loss : 0.439066 model2 loss : 0.030734
[10:46:27.652] iteration 4578 : model1 loss : 0.436255 model2 loss : 0.027657
[10:46:27.825] iteration 4579 : model1 loss : 0.439820 model2 loss : 0.036980
[10:46:27.994] iteration 4580 : model1 loss : 0.441224 model2 loss : 0.032918
[10:46:28.168] iteration 4581 : model1 loss : 0.436624 model2 loss : 0.028687
[10:46:28.338] iteration 4582 : model1 loss : 0.441233 model2 loss : 0.031043
[10:46:28.513] iteration 4583 : model1 loss : 0.439410 model2 loss : 0.029798
[10:46:28.684] iteration 4584 : model1 loss : 0.436703 model2 loss : 0.041488
[10:46:28.856] iteration 4585 : model1 loss : 0.441990 model2 loss : 0.029981
[10:46:29.023] iteration 4586 : model1 loss : 0.435948 model2 loss : 0.026921
[10:46:29.196] iteration 4587 : model1 loss : 0.438345 model2 loss : 0.030114
[10:46:31.202] iteration 4588 : model1 loss : 0.440840 model2 loss : 0.033182
[10:46:31.373] iteration 4589 : model1 loss : 0.437480 model2 loss : 0.033413
[10:46:31.550] iteration 4590 : model1 loss : 0.440523 model2 loss : 0.027901
[10:46:31.720] iteration 4591 : model1 loss : 0.439582 model2 loss : 0.036453
[10:46:31.894] iteration 4592 : model1 loss : 0.438706 model2 loss : 0.030519
[10:46:32.066] iteration 4593 : model1 loss : 0.439474 model2 loss : 0.030525
[10:46:32.240] iteration 4594 : model1 loss : 0.445230 model2 loss : 0.035696
[10:46:32.409] iteration 4595 : model1 loss : 0.437869 model2 loss : 0.029630
[10:46:32.587] iteration 4596 : model1 loss : 0.441416 model2 loss : 0.033739
[10:46:32.756] iteration 4597 : model1 loss : 0.439322 model2 loss : 0.030487
[10:46:32.932] iteration 4598 : model1 loss : 0.436664 model2 loss : 0.030649
[10:46:33.101] iteration 4599 : model1 loss : 0.440110 model2 loss : 0.039115
[10:46:33.278] iteration 4600 : model1 loss : 0.440162 model2 loss : 0.030415
[10:46:33.447] iteration 4601 : model1 loss : 0.434840 model2 loss : 0.033367
[10:46:33.622] iteration 4602 : model1 loss : 0.442636 model2 loss : 0.041286
[10:46:33.791] iteration 4603 : model1 loss : 0.434209 model2 loss : 0.030168
[10:46:33.965] iteration 4604 : model1 loss : 0.443279 model2 loss : 0.047871
[10:46:34.135] iteration 4605 : model1 loss : 0.446400 model2 loss : 0.050570
[10:46:34.304] iteration 4606 : model1 loss : 0.443820 model2 loss : 0.033929
[10:46:34.472] iteration 4607 : model1 loss : 0.440735 model2 loss : 0.044565
[10:46:34.647] iteration 4608 : model1 loss : 0.438586 model2 loss : 0.032829
[10:46:34.814] iteration 4609 : model1 loss : 0.436675 model2 loss : 0.034944
[10:46:34.987] iteration 4610 : model1 loss : 0.439255 model2 loss : 0.039570
[10:46:35.158] iteration 4611 : model1 loss : 0.444344 model2 loss : 0.035761
[10:46:35.333] iteration 4612 : model1 loss : 0.440011 model2 loss : 0.055263
[10:46:35.503] iteration 4613 : model1 loss : 0.440615 model2 loss : 0.032893
[10:46:35.677] iteration 4614 : model1 loss : 0.436696 model2 loss : 0.033080
[10:46:35.848] iteration 4615 : model1 loss : 0.435316 model2 loss : 0.031481
[10:46:36.019] iteration 4616 : model1 loss : 0.436234 model2 loss : 0.037153
[10:46:36.190] iteration 4617 : model1 loss : 0.438527 model2 loss : 0.038398
[10:46:36.361] iteration 4618 : model1 loss : 0.433498 model2 loss : 0.035397
[10:46:36.532] iteration 4619 : model1 loss : 0.441545 model2 loss : 0.040572
[10:46:36.708] iteration 4620 : model1 loss : 0.439089 model2 loss : 0.034315
[10:46:38.727] iteration 4621 : model1 loss : 0.441467 model2 loss : 0.040900
[10:46:38.897] iteration 4622 : model1 loss : 0.438842 model2 loss : 0.029677
[10:46:39.075] iteration 4623 : model1 loss : 0.441257 model2 loss : 0.030459
[10:46:39.243] iteration 4624 : model1 loss : 0.438100 model2 loss : 0.036235
[10:46:39.416] iteration 4625 : model1 loss : 0.442746 model2 loss : 0.037961
[10:46:39.588] iteration 4626 : model1 loss : 0.438755 model2 loss : 0.035163
[10:46:39.763] iteration 4627 : model1 loss : 0.437403 model2 loss : 0.034253
[10:46:39.932] iteration 4628 : model1 loss : 0.434882 model2 loss : 0.033936
[10:46:40.108] iteration 4629 : model1 loss : 0.444248 model2 loss : 0.041322
[10:46:40.275] iteration 4630 : model1 loss : 0.434590 model2 loss : 0.028898
[10:46:40.447] iteration 4631 : model1 loss : 0.440057 model2 loss : 0.034144
[10:46:40.620] iteration 4632 : model1 loss : 0.444242 model2 loss : 0.039255
[10:46:40.791] iteration 4633 : model1 loss : 0.435523 model2 loss : 0.030900
[10:46:40.960] iteration 4634 : model1 loss : 0.436427 model2 loss : 0.033250
[10:46:41.133] iteration 4635 : model1 loss : 0.437850 model2 loss : 0.034656
[10:46:41.300] iteration 4636 : model1 loss : 0.439546 model2 loss : 0.034424
[10:46:41.473] iteration 4637 : model1 loss : 0.440722 model2 loss : 0.028874
[10:46:41.645] iteration 4638 : model1 loss : 0.439082 model2 loss : 0.033426
[10:46:41.817] iteration 4639 : model1 loss : 0.441155 model2 loss : 0.036807
[10:46:41.985] iteration 4640 : model1 loss : 0.436589 model2 loss : 0.031780
[10:46:42.154] iteration 4641 : model1 loss : 0.438388 model2 loss : 0.035337
[10:46:42.322] iteration 4642 : model1 loss : 0.438913 model2 loss : 0.036638
[10:46:42.497] iteration 4643 : model1 loss : 0.442185 model2 loss : 0.036102
[10:46:42.667] iteration 4644 : model1 loss : 0.435742 model2 loss : 0.031655
[10:46:42.840] iteration 4645 : model1 loss : 0.437713 model2 loss : 0.029489
[10:46:43.008] iteration 4646 : model1 loss : 0.441943 model2 loss : 0.034378
[10:46:43.181] iteration 4647 : model1 loss : 0.435791 model2 loss : 0.030526
[10:46:43.349] iteration 4648 : model1 loss : 0.436742 model2 loss : 0.028527
[10:46:43.523] iteration 4649 : model1 loss : 0.438561 model2 loss : 0.035264
[10:46:43.694] iteration 4650 : model1 loss : 0.437879 model2 loss : 0.032267
[10:46:43.866] iteration 4651 : model1 loss : 0.432775 model2 loss : 0.030496
[10:46:44.031] iteration 4652 : model1 loss : 0.435226 model2 loss : 0.031665
[10:46:44.205] iteration 4653 : model1 loss : 0.443414 model2 loss : 0.029485
[10:46:46.199] iteration 4654 : model1 loss : 0.432328 model2 loss : 0.026283
[10:46:46.366] iteration 4655 : model1 loss : 0.438944 model2 loss : 0.030308
[10:46:46.544] iteration 4656 : model1 loss : 0.442054 model2 loss : 0.036861
[10:46:46.715] iteration 4657 : model1 loss : 0.433585 model2 loss : 0.030721
[10:46:46.887] iteration 4658 : model1 loss : 0.436648 model2 loss : 0.027949
[10:46:47.057] iteration 4659 : model1 loss : 0.436012 model2 loss : 0.028352
[10:46:47.232] iteration 4660 : model1 loss : 0.436947 model2 loss : 0.030680
[10:46:47.399] iteration 4661 : model1 loss : 0.437178 model2 loss : 0.032173
[10:46:47.575] iteration 4662 : model1 loss : 0.441638 model2 loss : 0.036059
[10:46:47.749] iteration 4663 : model1 loss : 0.435124 model2 loss : 0.029840
[10:46:47.923] iteration 4664 : model1 loss : 0.442457 model2 loss : 0.036259
[10:46:48.094] iteration 4665 : model1 loss : 0.439447 model2 loss : 0.054707
[10:46:48.266] iteration 4666 : model1 loss : 0.441210 model2 loss : 0.034757
[10:46:48.434] iteration 4667 : model1 loss : 0.438455 model2 loss : 0.037438
[10:46:48.612] iteration 4668 : model1 loss : 0.438555 model2 loss : 0.044040
[10:46:48.781] iteration 4669 : model1 loss : 0.439490 model2 loss : 0.034976
[10:46:48.953] iteration 4670 : model1 loss : 0.438482 model2 loss : 0.037765
[10:46:49.125] iteration 4671 : model1 loss : 0.436154 model2 loss : 0.038596
[10:46:49.299] iteration 4672 : model1 loss : 0.436966 model2 loss : 0.031024
[10:46:49.467] iteration 4673 : model1 loss : 0.441045 model2 loss : 0.046281
[10:46:49.641] iteration 4674 : model1 loss : 0.434779 model2 loss : 0.032055
[10:46:49.811] iteration 4675 : model1 loss : 0.440417 model2 loss : 0.045000
[10:46:49.983] iteration 4676 : model1 loss : 0.441847 model2 loss : 0.038548
[10:46:50.153] iteration 4677 : model1 loss : 0.440402 model2 loss : 0.039579
[10:46:50.325] iteration 4678 : model1 loss : 0.442959 model2 loss : 0.042981
[10:46:50.495] iteration 4679 : model1 loss : 0.433130 model2 loss : 0.032637
[10:46:50.669] iteration 4680 : model1 loss : 0.434510 model2 loss : 0.036562
[10:46:50.840] iteration 4681 : model1 loss : 0.442878 model2 loss : 0.048936
[10:46:51.014] iteration 4682 : model1 loss : 0.442056 model2 loss : 0.039530
[10:46:51.185] iteration 4683 : model1 loss : 0.439986 model2 loss : 0.035462
[10:46:51.357] iteration 4684 : model1 loss : 0.443139 model2 loss : 0.036152
[10:46:51.526] iteration 4685 : model1 loss : 0.437944 model2 loss : 0.034904
[10:46:51.700] iteration 4686 : model1 loss : 0.441096 model2 loss : 0.036260
[10:46:53.711] iteration 4687 : model1 loss : 0.443546 model2 loss : 0.042481
[10:46:53.884] iteration 4688 : model1 loss : 0.437664 model2 loss : 0.035145
[10:46:54.061] iteration 4689 : model1 loss : 0.440528 model2 loss : 0.042630
[10:46:54.232] iteration 4690 : model1 loss : 0.437402 model2 loss : 0.030240
[10:46:54.405] iteration 4691 : model1 loss : 0.436235 model2 loss : 0.040335
[10:46:54.577] iteration 4692 : model1 loss : 0.435866 model2 loss : 0.031772
[10:46:54.753] iteration 4693 : model1 loss : 0.438694 model2 loss : 0.027960
[10:46:54.923] iteration 4694 : model1 loss : 0.436169 model2 loss : 0.027692
[10:46:55.097] iteration 4695 : model1 loss : 0.438584 model2 loss : 0.035702
[10:46:55.265] iteration 4696 : model1 loss : 0.434174 model2 loss : 0.035030
[10:46:55.440] iteration 4697 : model1 loss : 0.440352 model2 loss : 0.033850
[10:46:55.610] iteration 4698 : model1 loss : 0.445074 model2 loss : 0.042725
[10:46:55.785] iteration 4699 : model1 loss : 0.436914 model2 loss : 0.031059
[10:46:55.955] iteration 4700 : model1 loss : 0.434266 model2 loss : 0.030837
[10:46:56.128] iteration 4701 : model1 loss : 0.435806 model2 loss : 0.029401
[10:46:56.297] iteration 4702 : model1 loss : 0.439818 model2 loss : 0.035846
[10:46:56.469] iteration 4703 : model1 loss : 0.437556 model2 loss : 0.031627
[10:46:56.641] iteration 4704 : model1 loss : 0.445107 model2 loss : 0.034088
[10:46:56.815] iteration 4705 : model1 loss : 0.437680 model2 loss : 0.030593
[10:46:56.984] iteration 4706 : model1 loss : 0.440627 model2 loss : 0.037754
[10:46:57.161] iteration 4707 : model1 loss : 0.434574 model2 loss : 0.028174
[10:46:57.330] iteration 4708 : model1 loss : 0.436377 model2 loss : 0.029978
[10:46:57.504] iteration 4709 : model1 loss : 0.443077 model2 loss : 0.042095
[10:46:57.676] iteration 4710 : model1 loss : 0.437427 model2 loss : 0.029827
[10:46:57.848] iteration 4711 : model1 loss : 0.440266 model2 loss : 0.031962
[10:46:58.016] iteration 4712 : model1 loss : 0.439991 model2 loss : 0.033064
[10:46:58.188] iteration 4713 : model1 loss : 0.436486 model2 loss : 0.030942
[10:46:58.356] iteration 4714 : model1 loss : 0.437174 model2 loss : 0.030600
[10:46:58.532] iteration 4715 : model1 loss : 0.434452 model2 loss : 0.028351
[10:46:58.704] iteration 4716 : model1 loss : 0.441365 model2 loss : 0.031179
[10:46:58.877] iteration 4717 : model1 loss : 0.440225 model2 loss : 0.030289
[10:46:59.044] iteration 4718 : model1 loss : 0.438008 model2 loss : 0.028696
[10:46:59.216] iteration 4719 : model1 loss : 0.439280 model2 loss : 0.037729
[10:47:01.198] iteration 4720 : model1 loss : 0.437286 model2 loss : 0.031028
[10:47:01.367] iteration 4721 : model1 loss : 0.441093 model2 loss : 0.034200
[10:47:01.545] iteration 4722 : model1 loss : 0.437131 model2 loss : 0.035296
[10:47:01.718] iteration 4723 : model1 loss : 0.440299 model2 loss : 0.031739
[10:47:01.890] iteration 4724 : model1 loss : 0.436395 model2 loss : 0.025076
[10:47:02.058] iteration 4725 : model1 loss : 0.439674 model2 loss : 0.031595
[10:47:02.232] iteration 4726 : model1 loss : 0.437261 model2 loss : 0.030267
[10:47:02.401] iteration 4727 : model1 loss : 0.439305 model2 loss : 0.028702
[10:47:02.577] iteration 4728 : model1 loss : 0.436871 model2 loss : 0.029777
[10:47:02.746] iteration 4729 : model1 loss : 0.440454 model2 loss : 0.033184
[10:47:02.921] iteration 4730 : model1 loss : 0.436413 model2 loss : 0.030457
[10:47:03.091] iteration 4731 : model1 loss : 0.435363 model2 loss : 0.031312
[10:47:03.265] iteration 4732 : model1 loss : 0.434556 model2 loss : 0.029059
[10:47:03.436] iteration 4733 : model1 loss : 0.441616 model2 loss : 0.027305
[10:47:03.610] iteration 4734 : model1 loss : 0.441974 model2 loss : 0.036680
[10:47:03.780] iteration 4735 : model1 loss : 0.444152 model2 loss : 0.035520
[10:47:03.954] iteration 4736 : model1 loss : 0.441876 model2 loss : 0.032200
[10:47:04.123] iteration 4737 : model1 loss : 0.434476 model2 loss : 0.028379
[10:47:04.298] iteration 4738 : model1 loss : 0.434970 model2 loss : 0.027592
[10:47:04.468] iteration 4739 : model1 loss : 0.437467 model2 loss : 0.024780
[10:47:04.642] iteration 4740 : model1 loss : 0.436964 model2 loss : 0.031959
[10:47:04.810] iteration 4741 : model1 loss : 0.444094 model2 loss : 0.039757
[10:47:04.983] iteration 4742 : model1 loss : 0.437099 model2 loss : 0.032554
[10:47:05.155] iteration 4743 : model1 loss : 0.434580 model2 loss : 0.025079
[10:47:05.328] iteration 4744 : model1 loss : 0.440076 model2 loss : 0.029082
[10:47:05.498] iteration 4745 : model1 loss : 0.440066 model2 loss : 0.035015
[10:47:05.672] iteration 4746 : model1 loss : 0.443540 model2 loss : 0.039478
[10:47:05.842] iteration 4747 : model1 loss : 0.438757 model2 loss : 0.029363
[10:47:06.014] iteration 4748 : model1 loss : 0.439484 model2 loss : 0.033321
[10:47:06.185] iteration 4749 : model1 loss : 0.438566 model2 loss : 0.034572
[10:47:06.359] iteration 4750 : model1 loss : 0.437060 model2 loss : 0.031277
[10:47:06.529] iteration 4751 : model1 loss : 0.440731 model2 loss : 0.035523
[10:47:06.702] iteration 4752 : model1 loss : 0.440077 model2 loss : 0.033260
[10:47:08.698] iteration 4753 : model1 loss : 0.435122 model2 loss : 0.032453
[10:47:08.867] iteration 4754 : model1 loss : 0.441659 model2 loss : 0.030567
[10:47:09.041] iteration 4755 : model1 loss : 0.440427 model2 loss : 0.033675
[10:47:09.213] iteration 4756 : model1 loss : 0.436991 model2 loss : 0.031097
[10:47:09.387] iteration 4757 : model1 loss : 0.442566 model2 loss : 0.031892
[10:47:09.556] iteration 4758 : model1 loss : 0.436621 model2 loss : 0.030740
[10:47:09.729] iteration 4759 : model1 loss : 0.444252 model2 loss : 0.045684
[10:47:09.898] iteration 4760 : model1 loss : 0.443865 model2 loss : 0.035566
[10:47:10.072] iteration 4761 : model1 loss : 0.438151 model2 loss : 0.030567
[10:47:10.242] iteration 4762 : model1 loss : 0.437510 model2 loss : 0.029666
[10:47:10.414] iteration 4763 : model1 loss : 0.439908 model2 loss : 0.033893
[10:47:10.583] iteration 4764 : model1 loss : 0.438414 model2 loss : 0.034970
[10:47:10.757] iteration 4765 : model1 loss : 0.439768 model2 loss : 0.034590
[10:47:10.928] iteration 4766 : model1 loss : 0.440049 model2 loss : 0.034181
[10:47:11.104] iteration 4767 : model1 loss : 0.439754 model2 loss : 0.035228
[10:47:11.273] iteration 4768 : model1 loss : 0.436370 model2 loss : 0.030037
[10:47:11.447] iteration 4769 : model1 loss : 0.439804 model2 loss : 0.037561
[10:47:11.619] iteration 4770 : model1 loss : 0.437277 model2 loss : 0.031675
[10:47:11.792] iteration 4771 : model1 loss : 0.435614 model2 loss : 0.028752
[10:47:11.961] iteration 4772 : model1 loss : 0.438000 model2 loss : 0.033156
[10:47:12.135] iteration 4773 : model1 loss : 0.443374 model2 loss : 0.047350
[10:47:12.304] iteration 4774 : model1 loss : 0.435520 model2 loss : 0.031630
[10:47:12.477] iteration 4775 : model1 loss : 0.433304 model2 loss : 0.028237
[10:47:12.647] iteration 4776 : model1 loss : 0.438068 model2 loss : 0.028971
[10:47:12.822] iteration 4777 : model1 loss : 0.441361 model2 loss : 0.030163
[10:47:12.989] iteration 4778 : model1 loss : 0.439875 model2 loss : 0.029894
[10:47:13.163] iteration 4779 : model1 loss : 0.440704 model2 loss : 0.030411
[10:47:13.330] iteration 4780 : model1 loss : 0.437104 model2 loss : 0.029322
[10:47:13.504] iteration 4781 : model1 loss : 0.436629 model2 loss : 0.033115
[10:47:13.674] iteration 4782 : model1 loss : 0.442609 model2 loss : 0.037429
[10:47:13.846] iteration 4783 : model1 loss : 0.432812 model2 loss : 0.026530
[10:47:14.012] iteration 4784 : model1 loss : 0.440361 model2 loss : 0.040470
[10:47:14.182] iteration 4785 : model1 loss : 0.436710 model2 loss : 0.033125
[10:47:16.155] iteration 4786 : model1 loss : 0.437396 model2 loss : 0.032089
[10:47:16.323] iteration 4787 : model1 loss : 0.438754 model2 loss : 0.036230
[10:47:16.500] iteration 4788 : model1 loss : 0.438629 model2 loss : 0.035465
[10:47:16.669] iteration 4789 : model1 loss : 0.442819 model2 loss : 0.038912
[10:47:16.844] iteration 4790 : model1 loss : 0.443117 model2 loss : 0.035172
[10:47:17.012] iteration 4791 : model1 loss : 0.439286 model2 loss : 0.037587
[10:47:17.187] iteration 4792 : model1 loss : 0.439820 model2 loss : 0.030944
[10:47:17.356] iteration 4793 : model1 loss : 0.445276 model2 loss : 0.042364
[10:47:17.532] iteration 4794 : model1 loss : 0.439088 model2 loss : 0.032756
[10:47:17.703] iteration 4795 : model1 loss : 0.442372 model2 loss : 0.040924
[10:47:17.876] iteration 4796 : model1 loss : 0.443435 model2 loss : 0.047372
[10:47:18.045] iteration 4797 : model1 loss : 0.440722 model2 loss : 0.038487
[10:47:18.219] iteration 4798 : model1 loss : 0.433194 model2 loss : 0.030113
[10:47:18.387] iteration 4799 : model1 loss : 0.443025 model2 loss : 0.034664
[10:47:18.560] iteration 4800 : model1 loss : 0.439820 model2 loss : 0.032429
[10:47:18.733] iteration 4801 : model1 loss : 0.437862 model2 loss : 0.031857
[10:47:18.909] iteration 4802 : model1 loss : 0.440268 model2 loss : 0.037899
[10:47:19.078] iteration 4803 : model1 loss : 0.443743 model2 loss : 0.036230
[10:47:19.255] iteration 4804 : model1 loss : 0.435125 model2 loss : 0.028669
[10:47:19.424] iteration 4805 : model1 loss : 0.436078 model2 loss : 0.029797
[10:47:19.601] iteration 4806 : model1 loss : 0.437275 model2 loss : 0.035741
[10:47:19.770] iteration 4807 : model1 loss : 0.438698 model2 loss : 0.036386
[10:47:19.943] iteration 4808 : model1 loss : 0.433488 model2 loss : 0.031393
[10:47:20.114] iteration 4809 : model1 loss : 0.440177 model2 loss : 0.036465
[10:47:20.288] iteration 4810 : model1 loss : 0.438055 model2 loss : 0.030782
[10:47:20.454] iteration 4811 : model1 loss : 0.437654 model2 loss : 0.032114
[10:47:20.630] iteration 4812 : model1 loss : 0.433864 model2 loss : 0.031501
[10:47:20.799] iteration 4813 : model1 loss : 0.441043 model2 loss : 0.033038
[10:47:20.974] iteration 4814 : model1 loss : 0.445496 model2 loss : 0.035893
[10:47:21.145] iteration 4815 : model1 loss : 0.440238 model2 loss : 0.032201
[10:47:21.319] iteration 4816 : model1 loss : 0.434010 model2 loss : 0.028465
[10:47:21.486] iteration 4817 : model1 loss : 0.435500 model2 loss : 0.027904
[10:47:21.659] iteration 4818 : model1 loss : 0.431792 model2 loss : 0.027827
[10:47:23.631] iteration 4819 : model1 loss : 0.432806 model2 loss : 0.027315
[10:47:23.799] iteration 4820 : model1 loss : 0.438440 model2 loss : 0.034454
[10:47:23.974] iteration 4821 : model1 loss : 0.437628 model2 loss : 0.032712
[10:47:24.146] iteration 4822 : model1 loss : 0.437036 model2 loss : 0.033871
[10:47:24.319] iteration 4823 : model1 loss : 0.439293 model2 loss : 0.029769
[10:47:24.487] iteration 4824 : model1 loss : 0.438528 model2 loss : 0.030193
[10:47:24.662] iteration 4825 : model1 loss : 0.441828 model2 loss : 0.033891
[10:47:24.831] iteration 4826 : model1 loss : 0.443856 model2 loss : 0.037357
[10:47:25.004] iteration 4827 : model1 loss : 0.439943 model2 loss : 0.031956
[10:47:25.174] iteration 4828 : model1 loss : 0.439859 model2 loss : 0.029050
[10:47:25.349] iteration 4829 : model1 loss : 0.438510 model2 loss : 0.028650
[10:47:25.522] iteration 4830 : model1 loss : 0.446428 model2 loss : 0.034737
[10:47:25.696] iteration 4831 : model1 loss : 0.438730 model2 loss : 0.033582
[10:47:25.866] iteration 4832 : model1 loss : 0.441144 model2 loss : 0.031732
[10:47:26.038] iteration 4833 : model1 loss : 0.439921 model2 loss : 0.033267
[10:47:26.208] iteration 4834 : model1 loss : 0.435911 model2 loss : 0.028222
[10:47:26.380] iteration 4835 : model1 loss : 0.438139 model2 loss : 0.037331
[10:47:26.549] iteration 4836 : model1 loss : 0.438455 model2 loss : 0.029983
[10:47:26.721] iteration 4837 : model1 loss : 0.436074 model2 loss : 0.026871
[10:47:26.889] iteration 4838 : model1 loss : 0.439660 model2 loss : 0.027870
[10:47:27.061] iteration 4839 : model1 loss : 0.442323 model2 loss : 0.034129
[10:47:27.233] iteration 4840 : model1 loss : 0.437344 model2 loss : 0.031588
[10:47:27.403] iteration 4841 : model1 loss : 0.448200 model2 loss : 0.036475
[10:47:27.574] iteration 4842 : model1 loss : 0.447516 model2 loss : 0.036738
[10:47:27.751] iteration 4843 : model1 loss : 0.438960 model2 loss : 0.031974
[10:47:27.921] iteration 4844 : model1 loss : 0.439860 model2 loss : 0.032022
[10:47:28.095] iteration 4845 : model1 loss : 0.438679 model2 loss : 0.032582
[10:47:28.264] iteration 4846 : model1 loss : 0.438273 model2 loss : 0.032081
[10:47:28.437] iteration 4847 : model1 loss : 0.436128 model2 loss : 0.029754
[10:47:28.607] iteration 4848 : model1 loss : 0.435716 model2 loss : 0.028830
[10:47:28.783] iteration 4849 : model1 loss : 0.437648 model2 loss : 0.029638
[10:47:28.952] iteration 4850 : model1 loss : 0.435186 model2 loss : 0.029385
[10:47:29.124] iteration 4851 : model1 loss : 0.440643 model2 loss : 0.030137
[10:47:31.113] iteration 4852 : model1 loss : 0.437963 model2 loss : 0.031372
[10:47:31.289] iteration 4853 : model1 loss : 0.442614 model2 loss : 0.044300
[10:47:31.465] iteration 4854 : model1 loss : 0.437603 model2 loss : 0.028539
[10:47:31.638] iteration 4855 : model1 loss : 0.437678 model2 loss : 0.027298
[10:47:31.813] iteration 4856 : model1 loss : 0.432691 model2 loss : 0.030706
[10:47:31.981] iteration 4857 : model1 loss : 0.430856 model2 loss : 0.029013
[10:47:32.155] iteration 4858 : model1 loss : 0.438300 model2 loss : 0.029112
[10:47:32.322] iteration 4859 : model1 loss : 0.438748 model2 loss : 0.029176
[10:47:32.495] iteration 4860 : model1 loss : 0.438841 model2 loss : 0.032635
[10:47:32.668] iteration 4861 : model1 loss : 0.441292 model2 loss : 0.032017
[10:47:32.843] iteration 4862 : model1 loss : 0.435066 model2 loss : 0.027808
[10:47:33.011] iteration 4863 : model1 loss : 0.438845 model2 loss : 0.032109
[10:47:33.185] iteration 4864 : model1 loss : 0.440040 model2 loss : 0.033916
[10:47:33.353] iteration 4865 : model1 loss : 0.436239 model2 loss : 0.030394
[10:47:33.528] iteration 4866 : model1 loss : 0.443164 model2 loss : 0.036971
[10:47:33.701] iteration 4867 : model1 loss : 0.437061 model2 loss : 0.028157
[10:47:33.876] iteration 4868 : model1 loss : 0.441406 model2 loss : 0.034675
[10:47:34.044] iteration 4869 : model1 loss : 0.434738 model2 loss : 0.029950
[10:47:34.218] iteration 4870 : model1 loss : 0.441177 model2 loss : 0.032483
[10:47:34.385] iteration 4871 : model1 loss : 0.437006 model2 loss : 0.033009
[10:47:34.558] iteration 4872 : model1 loss : 0.436588 model2 loss : 0.027571
[10:47:34.729] iteration 4873 : model1 loss : 0.444203 model2 loss : 0.037551
[10:47:34.906] iteration 4874 : model1 loss : 0.441286 model2 loss : 0.031404
[10:47:35.074] iteration 4875 : model1 loss : 0.436382 model2 loss : 0.031563
[10:47:35.248] iteration 4876 : model1 loss : 0.439470 model2 loss : 0.028332
[10:47:35.417] iteration 4877 : model1 loss : 0.436529 model2 loss : 0.028869
[10:47:35.589] iteration 4878 : model1 loss : 0.439711 model2 loss : 0.029988
[10:47:35.761] iteration 4879 : model1 loss : 0.436937 model2 loss : 0.033436
[10:47:35.936] iteration 4880 : model1 loss : 0.441893 model2 loss : 0.035248
[10:47:36.104] iteration 4881 : model1 loss : 0.438972 model2 loss : 0.027303
[10:47:36.280] iteration 4882 : model1 loss : 0.437392 model2 loss : 0.030672
[10:47:36.446] iteration 4883 : model1 loss : 0.443085 model2 loss : 0.038324
[10:47:36.621] iteration 4884 : model1 loss : 0.437701 model2 loss : 0.036449
[10:47:38.586] iteration 4885 : model1 loss : 0.436863 model2 loss : 0.030023
[10:47:38.761] iteration 4886 : model1 loss : 0.443968 model2 loss : 0.040349
[10:47:38.936] iteration 4887 : model1 loss : 0.439394 model2 loss : 0.029034
[10:47:39.104] iteration 4888 : model1 loss : 0.443757 model2 loss : 0.035848
[10:47:39.280] iteration 4889 : model1 loss : 0.441744 model2 loss : 0.030834
[10:47:39.450] iteration 4890 : model1 loss : 0.442299 model2 loss : 0.032608
[10:47:39.626] iteration 4891 : model1 loss : 0.433366 model2 loss : 0.025379
[10:47:39.794] iteration 4892 : model1 loss : 0.437402 model2 loss : 0.029922
[10:47:39.968] iteration 4893 : model1 loss : 0.435457 model2 loss : 0.030803
[10:47:40.137] iteration 4894 : model1 loss : 0.438951 model2 loss : 0.031887
[10:47:40.313] iteration 4895 : model1 loss : 0.438880 model2 loss : 0.029611
[10:47:40.482] iteration 4896 : model1 loss : 0.435971 model2 loss : 0.029366
[10:47:40.657] iteration 4897 : model1 loss : 0.438542 model2 loss : 0.030661
[10:47:40.828] iteration 4898 : model1 loss : 0.436084 model2 loss : 0.033483
[10:47:41.001] iteration 4899 : model1 loss : 0.441345 model2 loss : 0.034728
[10:47:41.172] iteration 4900 : model1 loss : 0.438225 model2 loss : 0.030349
[10:47:41.349] iteration 4901 : model1 loss : 0.439989 model2 loss : 0.042370
[10:47:41.520] iteration 4902 : model1 loss : 0.439260 model2 loss : 0.035271
[10:47:41.693] iteration 4903 : model1 loss : 0.438585 model2 loss : 0.029784
[10:47:41.862] iteration 4904 : model1 loss : 0.435268 model2 loss : 0.028596
[10:47:42.036] iteration 4905 : model1 loss : 0.440689 model2 loss : 0.031190
[10:47:42.206] iteration 4906 : model1 loss : 0.435908 model2 loss : 0.030796
[10:47:42.377] iteration 4907 : model1 loss : 0.437955 model2 loss : 0.028539
[10:47:42.547] iteration 4908 : model1 loss : 0.434518 model2 loss : 0.027844
[10:47:42.722] iteration 4909 : model1 loss : 0.439868 model2 loss : 0.035522
[10:47:42.891] iteration 4910 : model1 loss : 0.438624 model2 loss : 0.025933
[10:47:43.063] iteration 4911 : model1 loss : 0.435954 model2 loss : 0.030615
[10:47:43.234] iteration 4912 : model1 loss : 0.439853 model2 loss : 0.031404
[10:47:43.409] iteration 4913 : model1 loss : 0.437246 model2 loss : 0.030323
[10:47:43.580] iteration 4914 : model1 loss : 0.441717 model2 loss : 0.036745
[10:47:43.755] iteration 4915 : model1 loss : 0.441075 model2 loss : 0.031125
[10:47:43.922] iteration 4916 : model1 loss : 0.440007 model2 loss : 0.032825
[10:47:44.093] iteration 4917 : model1 loss : 0.449036 model2 loss : 0.035482
[10:47:46.068] iteration 4918 : model1 loss : 0.438351 model2 loss : 0.029903
[10:47:46.241] iteration 4919 : model1 loss : 0.443396 model2 loss : 0.037306
[10:47:46.416] iteration 4920 : model1 loss : 0.438194 model2 loss : 0.030857
[10:47:46.585] iteration 4921 : model1 loss : 0.435905 model2 loss : 0.030955
[10:47:46.760] iteration 4922 : model1 loss : 0.437515 model2 loss : 0.037051
[10:47:46.930] iteration 4923 : model1 loss : 0.437848 model2 loss : 0.029294
[10:47:47.103] iteration 4924 : model1 loss : 0.440895 model2 loss : 0.028767
[10:47:47.276] iteration 4925 : model1 loss : 0.439409 model2 loss : 0.029697
[10:47:47.449] iteration 4926 : model1 loss : 0.433637 model2 loss : 0.027883
[10:47:47.617] iteration 4927 : model1 loss : 0.439687 model2 loss : 0.033565
[10:47:47.791] iteration 4928 : model1 loss : 0.434162 model2 loss : 0.029314
[10:47:47.959] iteration 4929 : model1 loss : 0.434675 model2 loss : 0.028330
[10:47:48.134] iteration 4930 : model1 loss : 0.439527 model2 loss : 0.040836
[10:47:48.304] iteration 4931 : model1 loss : 0.437566 model2 loss : 0.029678
[10:47:48.476] iteration 4932 : model1 loss : 0.443660 model2 loss : 0.030295
[10:47:48.647] iteration 4933 : model1 loss : 0.445184 model2 loss : 0.033430
[10:47:48.820] iteration 4934 : model1 loss : 0.439512 model2 loss : 0.036089
[10:47:48.988] iteration 4935 : model1 loss : 0.438263 model2 loss : 0.027661
[10:47:49.164] iteration 4936 : model1 loss : 0.434492 model2 loss : 0.026720
[10:47:49.335] iteration 4937 : model1 loss : 0.439948 model2 loss : 0.030805
[10:47:49.511] iteration 4938 : model1 loss : 0.442907 model2 loss : 0.030480
[10:47:49.681] iteration 4939 : model1 loss : 0.435932 model2 loss : 0.028808
[10:47:49.857] iteration 4940 : model1 loss : 0.439402 model2 loss : 0.028600
[10:47:50.029] iteration 4941 : model1 loss : 0.436612 model2 loss : 0.028277
[10:47:50.204] iteration 4942 : model1 loss : 0.436062 model2 loss : 0.027494
[10:47:50.372] iteration 4943 : model1 loss : 0.437463 model2 loss : 0.031155
[10:47:50.548] iteration 4944 : model1 loss : 0.434757 model2 loss : 0.031914
[10:47:50.719] iteration 4945 : model1 loss : 0.438440 model2 loss : 0.032596
[10:47:50.892] iteration 4946 : model1 loss : 0.437760 model2 loss : 0.036089
[10:47:51.062] iteration 4947 : model1 loss : 0.441018 model2 loss : 0.030989
[10:47:51.236] iteration 4948 : model1 loss : 0.441177 model2 loss : 0.033739
[10:47:51.402] iteration 4949 : model1 loss : 0.442342 model2 loss : 0.033616
[10:47:51.575] iteration 4950 : model1 loss : 0.441784 model2 loss : 0.033859
[10:47:53.531] iteration 4951 : model1 loss : 0.437332 model2 loss : 0.033018
[10:47:53.703] iteration 4952 : model1 loss : 0.441365 model2 loss : 0.035932
[10:47:53.880] iteration 4953 : model1 loss : 0.435823 model2 loss : 0.027254
[10:47:54.048] iteration 4954 : model1 loss : 0.442127 model2 loss : 0.037463
[10:47:54.222] iteration 4955 : model1 loss : 0.437179 model2 loss : 0.029769
[10:47:54.390] iteration 4956 : model1 loss : 0.433909 model2 loss : 0.028061
[10:47:54.562] iteration 4957 : model1 loss : 0.434747 model2 loss : 0.031456
[10:47:54.732] iteration 4958 : model1 loss : 0.446608 model2 loss : 0.053245
[10:47:54.908] iteration 4959 : model1 loss : 0.434171 model2 loss : 0.027176
[10:47:55.075] iteration 4960 : model1 loss : 0.438278 model2 loss : 0.028725
[10:47:55.248] iteration 4961 : model1 loss : 0.438990 model2 loss : 0.029139
[10:47:55.418] iteration 4962 : model1 loss : 0.434572 model2 loss : 0.026000
[10:47:55.590] iteration 4963 : model1 loss : 0.438267 model2 loss : 0.029542
[10:47:55.760] iteration 4964 : model1 loss : 0.438711 model2 loss : 0.031551
[10:47:55.936] iteration 4965 : model1 loss : 0.436779 model2 loss : 0.027613
[10:47:56.104] iteration 4966 : model1 loss : 0.437722 model2 loss : 0.029201
[10:47:56.279] iteration 4967 : model1 loss : 0.436958 model2 loss : 0.032204
[10:47:56.448] iteration 4968 : model1 loss : 0.442034 model2 loss : 0.033826
[10:47:56.619] iteration 4969 : model1 loss : 0.435553 model2 loss : 0.033190
[10:47:56.791] iteration 4970 : model1 loss : 0.439087 model2 loss : 0.027653
[10:47:56.965] iteration 4971 : model1 loss : 0.436694 model2 loss : 0.028481
[10:47:57.133] iteration 4972 : model1 loss : 0.439558 model2 loss : 0.030211
[10:47:57.308] iteration 4973 : model1 loss : 0.431936 model2 loss : 0.027916
[10:47:57.477] iteration 4974 : model1 loss : 0.437434 model2 loss : 0.027870
[10:47:57.653] iteration 4975 : model1 loss : 0.442485 model2 loss : 0.040002
[10:47:57.824] iteration 4976 : model1 loss : 0.442554 model2 loss : 0.033032
[10:47:57.997] iteration 4977 : model1 loss : 0.439616 model2 loss : 0.037608
[10:47:58.168] iteration 4978 : model1 loss : 0.436341 model2 loss : 0.027682
[10:47:58.342] iteration 4979 : model1 loss : 0.435816 model2 loss : 0.026724
[10:47:58.513] iteration 4980 : model1 loss : 0.437260 model2 loss : 0.028790
[10:47:58.688] iteration 4981 : model1 loss : 0.437821 model2 loss : 0.029400
[10:47:58.856] iteration 4982 : model1 loss : 0.436483 model2 loss : 0.032537
[10:47:59.028] iteration 4983 : model1 loss : 0.443888 model2 loss : 0.047572
[10:48:01.038] iteration 4984 : model1 loss : 0.439990 model2 loss : 0.029317
[10:48:01.210] iteration 4985 : model1 loss : 0.435636 model2 loss : 0.030961
[10:48:01.384] iteration 4986 : model1 loss : 0.440545 model2 loss : 0.032812
[10:48:01.552] iteration 4987 : model1 loss : 0.438043 model2 loss : 0.031672
[10:48:01.726] iteration 4988 : model1 loss : 0.440078 model2 loss : 0.030854
[10:48:01.896] iteration 4989 : model1 loss : 0.436384 model2 loss : 0.029208
[10:48:02.069] iteration 4990 : model1 loss : 0.440279 model2 loss : 0.034855
[10:48:02.241] iteration 4991 : model1 loss : 0.442334 model2 loss : 0.028828
[10:48:02.415] iteration 4992 : model1 loss : 0.443315 model2 loss : 0.034684
[10:48:02.583] iteration 4993 : model1 loss : 0.437274 model2 loss : 0.029997
[10:48:02.756] iteration 4994 : model1 loss : 0.438725 model2 loss : 0.032027
[10:48:02.927] iteration 4995 : model1 loss : 0.444445 model2 loss : 0.036285
[10:48:03.101] iteration 4996 : model1 loss : 0.439651 model2 loss : 0.031551
[10:48:03.272] iteration 4997 : model1 loss : 0.440823 model2 loss : 0.036384
[10:48:03.448] iteration 4998 : model1 loss : 0.434446 model2 loss : 0.027795
[10:48:03.617] iteration 4999 : model1 loss : 0.437034 model2 loss : 0.029487
[10:48:03.792] iteration 5000 : model1 loss : 0.434317 model2 loss : 0.024587
[10:48:12.290] iteration 5000 : model1_mean_dice : 0.824087 model1_mean_hd95 : 14.211337
[10:48:20.776] iteration 5000 : model2_mean_dice : 0.865964 model2_mean_hd95 : 4.774909
[10:48:20.957] iteration 5001 : model1 loss : 0.439796 model2 loss : 0.032427
[10:48:21.132] iteration 5002 : model1 loss : 0.437856 model2 loss : 0.028746
[10:48:21.300] iteration 5003 : model1 loss : 0.433488 model2 loss : 0.026506
[10:48:21.473] iteration 5004 : model1 loss : 0.442005 model2 loss : 0.029833
[10:48:21.640] iteration 5005 : model1 loss : 0.433180 model2 loss : 0.030226
[10:48:21.815] iteration 5006 : model1 loss : 0.435719 model2 loss : 0.026384
[10:48:21.981] iteration 5007 : model1 loss : 0.436365 model2 loss : 0.037856
[10:48:22.152] iteration 5008 : model1 loss : 0.439709 model2 loss : 0.032320
[10:48:22.322] iteration 5009 : model1 loss : 0.439195 model2 loss : 0.031522
[10:48:22.496] iteration 5010 : model1 loss : 0.438102 model2 loss : 0.031332
[10:48:22.662] iteration 5011 : model1 loss : 0.436964 model2 loss : 0.035530
[10:48:22.835] iteration 5012 : model1 loss : 0.434182 model2 loss : 0.028715
[10:48:23.003] iteration 5013 : model1 loss : 0.438617 model2 loss : 0.033751
[10:48:23.174] iteration 5014 : model1 loss : 0.434636 model2 loss : 0.029164
[10:48:23.343] iteration 5015 : model1 loss : 0.442934 model2 loss : 0.031122
[10:48:23.516] iteration 5016 : model1 loss : 0.437508 model2 loss : 0.034540
[10:48:25.486] iteration 5017 : model1 loss : 0.439929 model2 loss : 0.030466
[10:48:25.655] iteration 5018 : model1 loss : 0.446257 model2 loss : 0.059828
[10:48:25.832] iteration 5019 : model1 loss : 0.434894 model2 loss : 0.027708
[10:48:26.000] iteration 5020 : model1 loss : 0.437116 model2 loss : 0.030001
[10:48:26.173] iteration 5021 : model1 loss : 0.435770 model2 loss : 0.027983
[10:48:26.344] iteration 5022 : model1 loss : 0.437341 model2 loss : 0.028392
[10:48:26.518] iteration 5023 : model1 loss : 0.438183 model2 loss : 0.030832
[10:48:26.688] iteration 5024 : model1 loss : 0.437639 model2 loss : 0.031503
[10:48:26.860] iteration 5025 : model1 loss : 0.437486 model2 loss : 0.031127
[10:48:27.026] iteration 5026 : model1 loss : 0.442253 model2 loss : 0.032507
[10:48:27.200] iteration 5027 : model1 loss : 0.438214 model2 loss : 0.030717
[10:48:27.369] iteration 5028 : model1 loss : 0.443516 model2 loss : 0.036758
[10:48:27.544] iteration 5029 : model1 loss : 0.442078 model2 loss : 0.044672
[10:48:27.714] iteration 5030 : model1 loss : 0.437813 model2 loss : 0.027225
[10:48:27.885] iteration 5031 : model1 loss : 0.442927 model2 loss : 0.033039
[10:48:28.054] iteration 5032 : model1 loss : 0.437007 model2 loss : 0.033325
[10:48:28.227] iteration 5033 : model1 loss : 0.437871 model2 loss : 0.034424
[10:48:28.395] iteration 5034 : model1 loss : 0.438647 model2 loss : 0.035570
[10:48:28.571] iteration 5035 : model1 loss : 0.440470 model2 loss : 0.030665
[10:48:28.740] iteration 5036 : model1 loss : 0.439855 model2 loss : 0.031627
[10:48:28.914] iteration 5037 : model1 loss : 0.433926 model2 loss : 0.031066
[10:48:29.080] iteration 5038 : model1 loss : 0.437547 model2 loss : 0.033910
[10:48:29.255] iteration 5039 : model1 loss : 0.437433 model2 loss : 0.032703
[10:48:29.422] iteration 5040 : model1 loss : 0.436078 model2 loss : 0.031678
[10:48:29.594] iteration 5041 : model1 loss : 0.440601 model2 loss : 0.033520
[10:48:29.765] iteration 5042 : model1 loss : 0.437459 model2 loss : 0.027266
[10:48:29.938] iteration 5043 : model1 loss : 0.436889 model2 loss : 0.028806
[10:48:30.107] iteration 5044 : model1 loss : 0.431597 model2 loss : 0.027791
[10:48:30.283] iteration 5045 : model1 loss : 0.433245 model2 loss : 0.027716
[10:48:30.451] iteration 5046 : model1 loss : 0.437490 model2 loss : 0.029215
[10:48:30.624] iteration 5047 : model1 loss : 0.435388 model2 loss : 0.029744
[10:48:30.792] iteration 5048 : model1 loss : 0.441156 model2 loss : 0.037437
[10:48:30.963] iteration 5049 : model1 loss : 0.435668 model2 loss : 0.031398
[10:48:32.923] iteration 5050 : model1 loss : 0.441694 model2 loss : 0.037840
[10:48:33.095] iteration 5051 : model1 loss : 0.442113 model2 loss : 0.030080
[10:48:33.269] iteration 5052 : model1 loss : 0.441368 model2 loss : 0.034036
[10:48:33.436] iteration 5053 : model1 loss : 0.437656 model2 loss : 0.029183
[10:48:33.609] iteration 5054 : model1 loss : 0.436614 model2 loss : 0.031468
[10:48:33.779] iteration 5055 : model1 loss : 0.438022 model2 loss : 0.032748
[10:48:33.953] iteration 5056 : model1 loss : 0.430990 model2 loss : 0.024094
[10:48:34.122] iteration 5057 : model1 loss : 0.440652 model2 loss : 0.034142
[10:48:34.295] iteration 5058 : model1 loss : 0.439576 model2 loss : 0.026125
[10:48:34.462] iteration 5059 : model1 loss : 0.442064 model2 loss : 0.039349
[10:48:34.634] iteration 5060 : model1 loss : 0.436108 model2 loss : 0.029304
[10:48:34.804] iteration 5061 : model1 loss : 0.436953 model2 loss : 0.032754
[10:48:34.978] iteration 5062 : model1 loss : 0.435068 model2 loss : 0.028500
[10:48:35.147] iteration 5063 : model1 loss : 0.436092 model2 loss : 0.026953
[10:48:35.317] iteration 5064 : model1 loss : 0.438193 model2 loss : 0.032073
[10:48:35.485] iteration 5065 : model1 loss : 0.434870 model2 loss : 0.028099
[10:48:35.659] iteration 5066 : model1 loss : 0.438259 model2 loss : 0.031378
[10:48:35.831] iteration 5067 : model1 loss : 0.437119 model2 loss : 0.031880
[10:48:36.003] iteration 5068 : model1 loss : 0.436795 model2 loss : 0.027602
[10:48:36.172] iteration 5069 : model1 loss : 0.438609 model2 loss : 0.035278
[10:48:36.346] iteration 5070 : model1 loss : 0.433677 model2 loss : 0.027526
[10:48:36.517] iteration 5071 : model1 loss : 0.441165 model2 loss : 0.035311
[10:48:36.688] iteration 5072 : model1 loss : 0.441976 model2 loss : 0.036330
[10:48:36.861] iteration 5073 : model1 loss : 0.443068 model2 loss : 0.036095
[10:48:37.035] iteration 5074 : model1 loss : 0.438203 model2 loss : 0.028826
[10:48:37.203] iteration 5075 : model1 loss : 0.440504 model2 loss : 0.038907
[10:48:37.379] iteration 5076 : model1 loss : 0.436492 model2 loss : 0.031365
[10:48:37.549] iteration 5077 : model1 loss : 0.442082 model2 loss : 0.037929
[10:48:37.722] iteration 5078 : model1 loss : 0.435156 model2 loss : 0.029964
[10:48:37.891] iteration 5079 : model1 loss : 0.439211 model2 loss : 0.029097
[10:48:38.064] iteration 5080 : model1 loss : 0.440051 model2 loss : 0.027806
[10:48:38.231] iteration 5081 : model1 loss : 0.439111 model2 loss : 0.039777
[10:48:38.403] iteration 5082 : model1 loss : 0.435862 model2 loss : 0.030620
[10:48:40.360] iteration 5083 : model1 loss : 0.433173 model2 loss : 0.028430
[10:48:40.533] iteration 5084 : model1 loss : 0.432959 model2 loss : 0.025213
[10:48:40.708] iteration 5085 : model1 loss : 0.441565 model2 loss : 0.033526
[10:48:40.878] iteration 5086 : model1 loss : 0.438861 model2 loss : 0.031294
[10:48:41.049] iteration 5087 : model1 loss : 0.442519 model2 loss : 0.033569
[10:48:41.219] iteration 5088 : model1 loss : 0.439522 model2 loss : 0.032924
[10:48:41.391] iteration 5089 : model1 loss : 0.434005 model2 loss : 0.026606
[10:48:41.559] iteration 5090 : model1 loss : 0.446416 model2 loss : 0.031893
[10:48:41.734] iteration 5091 : model1 loss : 0.436591 model2 loss : 0.025829
[10:48:41.906] iteration 5092 : model1 loss : 0.439183 model2 loss : 0.030427
[10:48:42.079] iteration 5093 : model1 loss : 0.437101 model2 loss : 0.028424
[10:48:42.250] iteration 5094 : model1 loss : 0.442620 model2 loss : 0.036966
[10:48:42.422] iteration 5095 : model1 loss : 0.439223 model2 loss : 0.035719
[10:48:42.591] iteration 5096 : model1 loss : 0.437534 model2 loss : 0.033802
[10:48:42.766] iteration 5097 : model1 loss : 0.443839 model2 loss : 0.034776
[10:48:42.936] iteration 5098 : model1 loss : 0.443336 model2 loss : 0.032289
[10:48:43.109] iteration 5099 : model1 loss : 0.442437 model2 loss : 0.035948
[10:48:43.284] iteration 5100 : model1 loss : 0.440482 model2 loss : 0.030606
[10:48:43.457] iteration 5101 : model1 loss : 0.445455 model2 loss : 0.041260
[10:48:43.624] iteration 5102 : model1 loss : 0.437804 model2 loss : 0.029032
[10:48:43.798] iteration 5103 : model1 loss : 0.437228 model2 loss : 0.028896
[10:48:43.968] iteration 5104 : model1 loss : 0.435230 model2 loss : 0.032255
[10:48:44.142] iteration 5105 : model1 loss : 0.437400 model2 loss : 0.026987
[10:48:44.312] iteration 5106 : model1 loss : 0.438876 model2 loss : 0.031047
[10:48:44.485] iteration 5107 : model1 loss : 0.445233 model2 loss : 0.033927
[10:48:44.653] iteration 5108 : model1 loss : 0.433068 model2 loss : 0.033398
[10:48:44.825] iteration 5109 : model1 loss : 0.433292 model2 loss : 0.031591
[10:48:44.991] iteration 5110 : model1 loss : 0.441991 model2 loss : 0.042669
[10:48:45.165] iteration 5111 : model1 loss : 0.442162 model2 loss : 0.036500
[10:48:45.335] iteration 5112 : model1 loss : 0.438380 model2 loss : 0.032669
[10:48:45.513] iteration 5113 : model1 loss : 0.437210 model2 loss : 0.027284
[10:48:45.679] iteration 5114 : model1 loss : 0.438538 model2 loss : 0.035698
[10:48:45.853] iteration 5115 : model1 loss : 0.439180 model2 loss : 0.031681
[10:48:47.810] iteration 5116 : model1 loss : 0.437552 model2 loss : 0.030654
[10:48:47.980] iteration 5117 : model1 loss : 0.443688 model2 loss : 0.037168
[10:48:48.154] iteration 5118 : model1 loss : 0.439278 model2 loss : 0.030570
[10:48:48.323] iteration 5119 : model1 loss : 0.434325 model2 loss : 0.025935
[10:48:48.497] iteration 5120 : model1 loss : 0.435986 model2 loss : 0.033523
[10:48:48.663] iteration 5121 : model1 loss : 0.437226 model2 loss : 0.030071
[10:48:48.836] iteration 5122 : model1 loss : 0.433873 model2 loss : 0.028209
[10:48:49.004] iteration 5123 : model1 loss : 0.434809 model2 loss : 0.026394
[10:48:49.175] iteration 5124 : model1 loss : 0.437771 model2 loss : 0.034165
[10:48:49.347] iteration 5125 : model1 loss : 0.438998 model2 loss : 0.028406
[10:48:49.523] iteration 5126 : model1 loss : 0.446442 model2 loss : 0.041189
[10:48:49.691] iteration 5127 : model1 loss : 0.435772 model2 loss : 0.033684
[10:48:49.865] iteration 5128 : model1 loss : 0.439488 model2 loss : 0.031529
[10:48:50.032] iteration 5129 : model1 loss : 0.443620 model2 loss : 0.032145
[10:48:50.204] iteration 5130 : model1 loss : 0.436918 model2 loss : 0.026711
[10:48:50.375] iteration 5131 : model1 loss : 0.439331 model2 loss : 0.030090
[10:48:50.548] iteration 5132 : model1 loss : 0.437924 model2 loss : 0.030293
[10:48:50.717] iteration 5133 : model1 loss : 0.438714 model2 loss : 0.029425
[10:48:50.892] iteration 5134 : model1 loss : 0.435523 model2 loss : 0.030330
[10:48:51.059] iteration 5135 : model1 loss : 0.438311 model2 loss : 0.030557
[10:48:51.232] iteration 5136 : model1 loss : 0.436597 model2 loss : 0.034447
[10:48:51.401] iteration 5137 : model1 loss : 0.439607 model2 loss : 0.029006
[10:48:51.574] iteration 5138 : model1 loss : 0.441442 model2 loss : 0.036462
[10:48:51.744] iteration 5139 : model1 loss : 0.440128 model2 loss : 0.029521
[10:48:51.918] iteration 5140 : model1 loss : 0.436839 model2 loss : 0.031903
[10:48:52.086] iteration 5141 : model1 loss : 0.440340 model2 loss : 0.033529
[10:48:52.261] iteration 5142 : model1 loss : 0.438533 model2 loss : 0.030873
[10:48:52.429] iteration 5143 : model1 loss : 0.441905 model2 loss : 0.030129
[10:48:52.601] iteration 5144 : model1 loss : 0.435561 model2 loss : 0.026396
[10:48:52.770] iteration 5145 : model1 loss : 0.437980 model2 loss : 0.029789
[10:48:52.943] iteration 5146 : model1 loss : 0.441674 model2 loss : 0.032149
[10:48:53.111] iteration 5147 : model1 loss : 0.438633 model2 loss : 0.030763
[10:48:53.281] iteration 5148 : model1 loss : 0.443989 model2 loss : 0.032082
[10:48:55.246] iteration 5149 : model1 loss : 0.440680 model2 loss : 0.032563
[10:48:55.419] iteration 5150 : model1 loss : 0.438880 model2 loss : 0.026354
[10:48:55.593] iteration 5151 : model1 loss : 0.438294 model2 loss : 0.033162
[10:48:55.764] iteration 5152 : model1 loss : 0.439838 model2 loss : 0.031132
[10:48:55.939] iteration 5153 : model1 loss : 0.442779 model2 loss : 0.032423
[10:48:56.107] iteration 5154 : model1 loss : 0.441032 model2 loss : 0.031775
[10:48:56.281] iteration 5155 : model1 loss : 0.434608 model2 loss : 0.027054
[10:48:56.449] iteration 5156 : model1 loss : 0.435331 model2 loss : 0.029403
[10:48:56.623] iteration 5157 : model1 loss : 0.440172 model2 loss : 0.035895
[10:48:56.792] iteration 5158 : model1 loss : 0.451871 model2 loss : 0.046073
[10:48:56.964] iteration 5159 : model1 loss : 0.437243 model2 loss : 0.030277
[10:48:57.132] iteration 5160 : model1 loss : 0.439951 model2 loss : 0.031182
[10:48:57.305] iteration 5161 : model1 loss : 0.440588 model2 loss : 0.030757
[10:48:57.475] iteration 5162 : model1 loss : 0.433262 model2 loss : 0.037638
[10:48:57.647] iteration 5163 : model1 loss : 0.437282 model2 loss : 0.035368
[10:48:57.817] iteration 5164 : model1 loss : 0.441437 model2 loss : 0.032768
[10:48:57.989] iteration 5165 : model1 loss : 0.440733 model2 loss : 0.035432
[10:48:58.156] iteration 5166 : model1 loss : 0.437258 model2 loss : 0.030170
[10:48:58.329] iteration 5167 : model1 loss : 0.439801 model2 loss : 0.027166
[10:48:58.500] iteration 5168 : model1 loss : 0.437697 model2 loss : 0.028845
[10:48:58.675] iteration 5169 : model1 loss : 0.440266 model2 loss : 0.034611
[10:48:58.845] iteration 5170 : model1 loss : 0.445001 model2 loss : 0.040893
[10:48:59.016] iteration 5171 : model1 loss : 0.440657 model2 loss : 0.034734
[10:48:59.185] iteration 5172 : model1 loss : 0.437402 model2 loss : 0.031274
[10:48:59.357] iteration 5173 : model1 loss : 0.438735 model2 loss : 0.034849
[10:48:59.527] iteration 5174 : model1 loss : 0.431792 model2 loss : 0.029803
[10:48:59.702] iteration 5175 : model1 loss : 0.437427 model2 loss : 0.029524
[10:48:59.874] iteration 5176 : model1 loss : 0.440776 model2 loss : 0.031921
[10:49:00.045] iteration 5177 : model1 loss : 0.438466 model2 loss : 0.028719
[10:49:00.218] iteration 5178 : model1 loss : 0.439480 model2 loss : 0.032019
[10:49:00.392] iteration 5179 : model1 loss : 0.435713 model2 loss : 0.028261
[10:49:00.558] iteration 5180 : model1 loss : 0.438312 model2 loss : 0.033855
[10:49:00.730] iteration 5181 : model1 loss : 0.441187 model2 loss : 0.032153
[10:49:02.734] iteration 5182 : model1 loss : 0.440628 model2 loss : 0.034193
[10:49:02.909] iteration 5183 : model1 loss : 0.437546 model2 loss : 0.027949
[10:49:03.083] iteration 5184 : model1 loss : 0.438301 model2 loss : 0.037328
[10:49:03.253] iteration 5185 : model1 loss : 0.439129 model2 loss : 0.036722
[10:49:03.427] iteration 5186 : model1 loss : 0.438205 model2 loss : 0.030662
[10:49:03.595] iteration 5187 : model1 loss : 0.447351 model2 loss : 0.050640
[10:49:03.768] iteration 5188 : model1 loss : 0.438294 model2 loss : 0.031657
[10:49:03.937] iteration 5189 : model1 loss : 0.442936 model2 loss : 0.028595
[10:49:04.107] iteration 5190 : model1 loss : 0.440793 model2 loss : 0.033612
[10:49:04.278] iteration 5191 : model1 loss : 0.438090 model2 loss : 0.034292
[10:49:04.450] iteration 5192 : model1 loss : 0.438755 model2 loss : 0.035488
[10:49:04.617] iteration 5193 : model1 loss : 0.436709 model2 loss : 0.033485
[10:49:04.790] iteration 5194 : model1 loss : 0.433578 model2 loss : 0.026962
[10:49:04.961] iteration 5195 : model1 loss : 0.438119 model2 loss : 0.035628
[10:49:05.132] iteration 5196 : model1 loss : 0.438525 model2 loss : 0.030633
[10:49:05.303] iteration 5197 : model1 loss : 0.435425 model2 loss : 0.029111
[10:49:05.476] iteration 5198 : model1 loss : 0.435228 model2 loss : 0.034629
[10:49:05.645] iteration 5199 : model1 loss : 0.437116 model2 loss : 0.032546
[10:49:05.821] iteration 5200 : model1 loss : 0.442411 model2 loss : 0.038359
[10:49:05.989] iteration 5201 : model1 loss : 0.436839 model2 loss : 0.027834
[10:49:06.167] iteration 5202 : model1 loss : 0.436148 model2 loss : 0.029876
[10:49:06.338] iteration 5203 : model1 loss : 0.440406 model2 loss : 0.034715
[10:49:06.519] iteration 5204 : model1 loss : 0.434146 model2 loss : 0.029380
[10:49:06.687] iteration 5205 : model1 loss : 0.438712 model2 loss : 0.028086
[10:49:06.860] iteration 5206 : model1 loss : 0.438494 model2 loss : 0.028496
[10:49:07.027] iteration 5207 : model1 loss : 0.435200 model2 loss : 0.033547
[10:49:07.200] iteration 5208 : model1 loss : 0.438454 model2 loss : 0.029242
[10:49:07.372] iteration 5209 : model1 loss : 0.439377 model2 loss : 0.028343
[10:49:07.548] iteration 5210 : model1 loss : 0.440267 model2 loss : 0.031621
[10:49:07.716] iteration 5211 : model1 loss : 0.432925 model2 loss : 0.024710
[10:49:07.895] iteration 5212 : model1 loss : 0.439725 model2 loss : 0.031724
[10:49:08.062] iteration 5213 : model1 loss : 0.439694 model2 loss : 0.030014
[10:49:08.232] iteration 5214 : model1 loss : 0.439131 model2 loss : 0.033375
[10:49:10.207] iteration 5215 : model1 loss : 0.438466 model2 loss : 0.031499
[10:49:10.380] iteration 5216 : model1 loss : 0.439799 model2 loss : 0.030833
[10:49:10.554] iteration 5217 : model1 loss : 0.435966 model2 loss : 0.028831
[10:49:10.722] iteration 5218 : model1 loss : 0.438238 model2 loss : 0.030186
[10:49:10.897] iteration 5219 : model1 loss : 0.441882 model2 loss : 0.037188
[10:49:11.063] iteration 5220 : model1 loss : 0.437747 model2 loss : 0.033655
[10:49:11.235] iteration 5221 : model1 loss : 0.444393 model2 loss : 0.041315
[10:49:11.406] iteration 5222 : model1 loss : 0.439680 model2 loss : 0.032088
[10:49:11.581] iteration 5223 : model1 loss : 0.440869 model2 loss : 0.033709
[10:49:11.755] iteration 5224 : model1 loss : 0.443904 model2 loss : 0.036640
[10:49:11.932] iteration 5225 : model1 loss : 0.435504 model2 loss : 0.027163
[10:49:12.102] iteration 5226 : model1 loss : 0.435746 model2 loss : 0.031636
[10:49:12.276] iteration 5227 : model1 loss : 0.433630 model2 loss : 0.031159
[10:49:12.446] iteration 5228 : model1 loss : 0.437803 model2 loss : 0.033252
[10:49:12.618] iteration 5229 : model1 loss : 0.440257 model2 loss : 0.033589
[10:49:12.790] iteration 5230 : model1 loss : 0.439403 model2 loss : 0.030366
[10:49:12.962] iteration 5231 : model1 loss : 0.438935 model2 loss : 0.033685
[10:49:13.131] iteration 5232 : model1 loss : 0.441495 model2 loss : 0.037994
[10:49:13.306] iteration 5233 : model1 loss : 0.434402 model2 loss : 0.026093
[10:49:13.475] iteration 5234 : model1 loss : 0.441774 model2 loss : 0.038029
[10:49:13.647] iteration 5235 : model1 loss : 0.440747 model2 loss : 0.029124
[10:49:13.819] iteration 5236 : model1 loss : 0.441618 model2 loss : 0.047123
[10:49:13.992] iteration 5237 : model1 loss : 0.439950 model2 loss : 0.027233
[10:49:14.160] iteration 5238 : model1 loss : 0.438964 model2 loss : 0.032268
[10:49:14.333] iteration 5239 : model1 loss : 0.434012 model2 loss : 0.031648
[10:49:14.504] iteration 5240 : model1 loss : 0.439823 model2 loss : 0.031177
[10:49:14.675] iteration 5241 : model1 loss : 0.432854 model2 loss : 0.025282
[10:49:14.847] iteration 5242 : model1 loss : 0.432762 model2 loss : 0.026673
[10:49:15.018] iteration 5243 : model1 loss : 0.436256 model2 loss : 0.033583
[10:49:15.187] iteration 5244 : model1 loss : 0.438032 model2 loss : 0.034003
[10:49:15.362] iteration 5245 : model1 loss : 0.438785 model2 loss : 0.033602
[10:49:15.530] iteration 5246 : model1 loss : 0.439928 model2 loss : 0.032381
[10:49:15.703] iteration 5247 : model1 loss : 0.437109 model2 loss : 0.033381
[10:49:17.711] iteration 5248 : model1 loss : 0.436513 model2 loss : 0.040632
[10:49:17.882] iteration 5249 : model1 loss : 0.432582 model2 loss : 0.028472
[10:49:18.056] iteration 5250 : model1 loss : 0.447015 model2 loss : 0.032480
[10:49:18.226] iteration 5251 : model1 loss : 0.437285 model2 loss : 0.029564
[10:49:18.399] iteration 5252 : model1 loss : 0.436634 model2 loss : 0.032085
[10:49:18.568] iteration 5253 : model1 loss : 0.441018 model2 loss : 0.037767
[10:49:18.741] iteration 5254 : model1 loss : 0.439431 model2 loss : 0.031496
[10:49:18.913] iteration 5255 : model1 loss : 0.435784 model2 loss : 0.029465
[10:49:19.085] iteration 5256 : model1 loss : 0.438723 model2 loss : 0.033097
[10:49:19.251] iteration 5257 : model1 loss : 0.434266 model2 loss : 0.028502
[10:49:19.426] iteration 5258 : model1 loss : 0.442511 model2 loss : 0.034694
[10:49:19.597] iteration 5259 : model1 loss : 0.439736 model2 loss : 0.032620
[10:49:19.772] iteration 5260 : model1 loss : 0.443667 model2 loss : 0.037445
[10:49:19.946] iteration 5261 : model1 loss : 0.441734 model2 loss : 0.032602
[10:49:20.117] iteration 5262 : model1 loss : 0.442256 model2 loss : 0.028762
[10:49:20.288] iteration 5263 : model1 loss : 0.438998 model2 loss : 0.030472
[10:49:20.462] iteration 5264 : model1 loss : 0.438936 model2 loss : 0.028940
[10:49:20.630] iteration 5265 : model1 loss : 0.439199 model2 loss : 0.037592
[10:49:20.805] iteration 5266 : model1 loss : 0.439329 model2 loss : 0.038304
[10:49:20.974] iteration 5267 : model1 loss : 0.437953 model2 loss : 0.029790
[10:49:21.146] iteration 5268 : model1 loss : 0.436100 model2 loss : 0.031215
[10:49:21.317] iteration 5269 : model1 loss : 0.439820 model2 loss : 0.031556
[10:49:21.492] iteration 5270 : model1 loss : 0.436759 model2 loss : 0.029151
[10:49:21.660] iteration 5271 : model1 loss : 0.437194 model2 loss : 0.032953
[10:49:21.834] iteration 5272 : model1 loss : 0.443530 model2 loss : 0.032035
[10:49:22.004] iteration 5273 : model1 loss : 0.442450 model2 loss : 0.031785
[10:49:22.177] iteration 5274 : model1 loss : 0.430274 model2 loss : 0.031614
[10:49:22.349] iteration 5275 : model1 loss : 0.436183 model2 loss : 0.027715
[10:49:22.526] iteration 5276 : model1 loss : 0.444352 model2 loss : 0.034494
[10:49:22.696] iteration 5277 : model1 loss : 0.444599 model2 loss : 0.034870
[10:49:22.870] iteration 5278 : model1 loss : 0.442266 model2 loss : 0.033740
[10:49:23.036] iteration 5279 : model1 loss : 0.442532 model2 loss : 0.029099
[10:49:23.209] iteration 5280 : model1 loss : 0.440377 model2 loss : 0.031937
[10:49:25.169] iteration 5281 : model1 loss : 0.433404 model2 loss : 0.028767
[10:49:25.340] iteration 5282 : model1 loss : 0.436918 model2 loss : 0.031769
[10:49:25.519] iteration 5283 : model1 loss : 0.441795 model2 loss : 0.033726
[10:49:25.689] iteration 5284 : model1 loss : 0.439315 model2 loss : 0.028069
[10:49:25.865] iteration 5285 : model1 loss : 0.442123 model2 loss : 0.035910
[10:49:26.033] iteration 5286 : model1 loss : 0.439573 model2 loss : 0.030389
[10:49:26.206] iteration 5287 : model1 loss : 0.442707 model2 loss : 0.032395
[10:49:26.378] iteration 5288 : model1 loss : 0.431912 model2 loss : 0.026365
[10:49:26.554] iteration 5289 : model1 loss : 0.437170 model2 loss : 0.026142
[10:49:26.723] iteration 5290 : model1 loss : 0.436659 model2 loss : 0.037655
[10:49:26.899] iteration 5291 : model1 loss : 0.438055 model2 loss : 0.028100
[10:49:27.069] iteration 5292 : model1 loss : 0.437476 model2 loss : 0.026712
[10:49:27.240] iteration 5293 : model1 loss : 0.435943 model2 loss : 0.027475
[10:49:27.413] iteration 5294 : model1 loss : 0.439502 model2 loss : 0.033138
[10:49:27.586] iteration 5295 : model1 loss : 0.446433 model2 loss : 0.042905
[10:49:27.755] iteration 5296 : model1 loss : 0.435836 model2 loss : 0.029090
[10:49:27.932] iteration 5297 : model1 loss : 0.436175 model2 loss : 0.029646
[10:49:28.101] iteration 5298 : model1 loss : 0.436023 model2 loss : 0.029475
[10:49:28.275] iteration 5299 : model1 loss : 0.438015 model2 loss : 0.030299
[10:49:28.446] iteration 5300 : model1 loss : 0.440169 model2 loss : 0.030427
[10:49:28.620] iteration 5301 : model1 loss : 0.438678 model2 loss : 0.031478
[10:49:28.790] iteration 5302 : model1 loss : 0.439381 model2 loss : 0.029150
[10:49:28.967] iteration 5303 : model1 loss : 0.435155 model2 loss : 0.026310
[10:49:29.134] iteration 5304 : model1 loss : 0.438608 model2 loss : 0.029919
[10:49:29.312] iteration 5305 : model1 loss : 0.442799 model2 loss : 0.032590
[10:49:29.483] iteration 5306 : model1 loss : 0.441135 model2 loss : 0.030001
[10:49:29.655] iteration 5307 : model1 loss : 0.442509 model2 loss : 0.033157
[10:49:29.826] iteration 5308 : model1 loss : 0.440045 model2 loss : 0.027254
[10:49:30.003] iteration 5309 : model1 loss : 0.443722 model2 loss : 0.026747
[10:49:30.171] iteration 5310 : model1 loss : 0.438428 model2 loss : 0.032254
[10:49:30.348] iteration 5311 : model1 loss : 0.438505 model2 loss : 0.028039
[10:49:30.520] iteration 5312 : model1 loss : 0.442574 model2 loss : 0.030951
[10:49:30.691] iteration 5313 : model1 loss : 0.440153 model2 loss : 0.033929
[10:49:32.722] iteration 5314 : model1 loss : 0.442084 model2 loss : 0.034128
[10:49:32.895] iteration 5315 : model1 loss : 0.448068 model2 loss : 0.034089
[10:49:33.069] iteration 5316 : model1 loss : 0.438880 model2 loss : 0.029927
[10:49:33.236] iteration 5317 : model1 loss : 0.432983 model2 loss : 0.028195
[10:49:33.408] iteration 5318 : model1 loss : 0.437943 model2 loss : 0.031584
[10:49:33.579] iteration 5319 : model1 loss : 0.443676 model2 loss : 0.040990
[10:49:33.751] iteration 5320 : model1 loss : 0.444327 model2 loss : 0.030457
[10:49:33.924] iteration 5321 : model1 loss : 0.437674 model2 loss : 0.028760
[10:49:34.097] iteration 5322 : model1 loss : 0.433018 model2 loss : 0.024461
[10:49:34.265] iteration 5323 : model1 loss : 0.440408 model2 loss : 0.027638
[10:49:34.442] iteration 5324 : model1 loss : 0.439256 model2 loss : 0.031293
[10:49:34.610] iteration 5325 : model1 loss : 0.436587 model2 loss : 0.030865
[10:49:34.783] iteration 5326 : model1 loss : 0.440040 model2 loss : 0.025628
[10:49:34.955] iteration 5327 : model1 loss : 0.439781 model2 loss : 0.027073
[10:49:35.127] iteration 5328 : model1 loss : 0.448523 model2 loss : 0.038716
[10:49:35.296] iteration 5329 : model1 loss : 0.444104 model2 loss : 0.033023
[10:49:35.472] iteration 5330 : model1 loss : 0.440712 model2 loss : 0.030117
[10:49:35.641] iteration 5331 : model1 loss : 0.447414 model2 loss : 0.042866
[10:49:35.816] iteration 5332 : model1 loss : 0.434078 model2 loss : 0.028649
[10:49:35.985] iteration 5333 : model1 loss : 0.444674 model2 loss : 0.032528
[10:49:36.156] iteration 5334 : model1 loss : 0.446322 model2 loss : 0.032192
[10:49:36.327] iteration 5335 : model1 loss : 0.438488 model2 loss : 0.035429
[10:49:36.506] iteration 5336 : model1 loss : 0.444091 model2 loss : 0.038324
[10:49:36.676] iteration 5337 : model1 loss : 0.437477 model2 loss : 0.027550
[10:49:36.850] iteration 5338 : model1 loss : 0.438530 model2 loss : 0.029078
[10:49:37.023] iteration 5339 : model1 loss : 0.443494 model2 loss : 0.032005
[10:49:37.194] iteration 5340 : model1 loss : 0.438525 model2 loss : 0.032710
[10:49:37.365] iteration 5341 : model1 loss : 0.438326 model2 loss : 0.029996
[10:49:37.544] iteration 5342 : model1 loss : 0.437956 model2 loss : 0.032840
[10:49:37.711] iteration 5343 : model1 loss : 0.446263 model2 loss : 0.035046
[10:49:37.886] iteration 5344 : model1 loss : 0.446035 model2 loss : 0.029592
[10:49:38.053] iteration 5345 : model1 loss : 0.441736 model2 loss : 0.032151
[10:49:38.223] iteration 5346 : model1 loss : 0.441893 model2 loss : 0.038472
[10:49:40.189] iteration 5347 : model1 loss : 0.438477 model2 loss : 0.028566
[10:49:40.360] iteration 5348 : model1 loss : 0.439282 model2 loss : 0.036824
[10:49:40.536] iteration 5349 : model1 loss : 0.438030 model2 loss : 0.036199
[10:49:40.704] iteration 5350 : model1 loss : 0.440092 model2 loss : 0.031582
[10:49:40.883] iteration 5351 : model1 loss : 0.441326 model2 loss : 0.032083
[10:49:41.052] iteration 5352 : model1 loss : 0.440681 model2 loss : 0.030947
[10:49:41.223] iteration 5353 : model1 loss : 0.438367 model2 loss : 0.029138
[10:49:41.395] iteration 5354 : model1 loss : 0.443916 model2 loss : 0.032032
[10:49:41.570] iteration 5355 : model1 loss : 0.442361 model2 loss : 0.027922
[10:49:41.738] iteration 5356 : model1 loss : 0.450804 model2 loss : 0.053929
[10:49:41.913] iteration 5357 : model1 loss : 0.436810 model2 loss : 0.034630
[10:49:42.084] iteration 5358 : model1 loss : 0.438939 model2 loss : 0.034691
[10:49:42.257] iteration 5359 : model1 loss : 0.437660 model2 loss : 0.034593
[10:49:42.427] iteration 5360 : model1 loss : 0.438073 model2 loss : 0.031826
[10:49:42.599] iteration 5361 : model1 loss : 0.444669 model2 loss : 0.035418
[10:49:42.768] iteration 5362 : model1 loss : 0.437856 model2 loss : 0.027415
[10:49:42.953] iteration 5363 : model1 loss : 0.440512 model2 loss : 0.031637
[10:49:43.121] iteration 5364 : model1 loss : 0.444556 model2 loss : 0.036002
[10:49:43.295] iteration 5365 : model1 loss : 0.434830 model2 loss : 0.035056
[10:49:43.466] iteration 5366 : model1 loss : 0.438275 model2 loss : 0.032675
[10:49:43.639] iteration 5367 : model1 loss : 0.441257 model2 loss : 0.035371
[10:49:43.807] iteration 5368 : model1 loss : 0.435442 model2 loss : 0.029378
[10:49:43.982] iteration 5369 : model1 loss : 0.435783 model2 loss : 0.032926
[10:49:44.151] iteration 5370 : model1 loss : 0.433681 model2 loss : 0.027961
[10:49:44.326] iteration 5371 : model1 loss : 0.436893 model2 loss : 0.029295
[10:49:44.497] iteration 5372 : model1 loss : 0.438286 model2 loss : 0.045084
[10:49:44.671] iteration 5373 : model1 loss : 0.440470 model2 loss : 0.032673
[10:49:44.842] iteration 5374 : model1 loss : 0.435495 model2 loss : 0.029709
[10:49:45.017] iteration 5375 : model1 loss : 0.446200 model2 loss : 0.041529
[10:49:45.185] iteration 5376 : model1 loss : 0.437928 model2 loss : 0.047498
[10:49:45.359] iteration 5377 : model1 loss : 0.439435 model2 loss : 0.036190
[10:49:45.531] iteration 5378 : model1 loss : 0.438747 model2 loss : 0.030665
[10:49:45.704] iteration 5379 : model1 loss : 0.437372 model2 loss : 0.031423
[10:49:47.730] iteration 5380 : model1 loss : 0.439264 model2 loss : 0.073667
[10:49:47.910] iteration 5381 : model1 loss : 0.440696 model2 loss : 0.039035
[10:49:48.084] iteration 5382 : model1 loss : 0.436911 model2 loss : 0.043366
[10:49:48.254] iteration 5383 : model1 loss : 0.437368 model2 loss : 0.040177
[10:49:48.425] iteration 5384 : model1 loss : 0.438932 model2 loss : 0.037608
[10:49:48.595] iteration 5385 : model1 loss : 0.443117 model2 loss : 0.040086
[10:49:48.766] iteration 5386 : model1 loss : 0.437030 model2 loss : 0.039677
[10:49:48.938] iteration 5387 : model1 loss : 0.442014 model2 loss : 0.034404
[10:49:49.111] iteration 5388 : model1 loss : 0.436703 model2 loss : 0.029492
[10:49:49.281] iteration 5389 : model1 loss : 0.434415 model2 loss : 0.033657
[10:49:49.453] iteration 5390 : model1 loss : 0.439179 model2 loss : 0.039973
[10:49:49.621] iteration 5391 : model1 loss : 0.442134 model2 loss : 0.042704
[10:49:49.794] iteration 5392 : model1 loss : 0.439265 model2 loss : 0.037340
[10:49:49.966] iteration 5393 : model1 loss : 0.445316 model2 loss : 0.040699
[10:49:50.138] iteration 5394 : model1 loss : 0.439263 model2 loss : 0.036068
[10:49:50.307] iteration 5395 : model1 loss : 0.445160 model2 loss : 0.052975
[10:49:50.483] iteration 5396 : model1 loss : 0.436605 model2 loss : 0.031892
[10:49:50.650] iteration 5397 : model1 loss : 0.438315 model2 loss : 0.040190
[10:49:50.826] iteration 5398 : model1 loss : 0.440107 model2 loss : 0.036041
[10:49:50.997] iteration 5399 : model1 loss : 0.436390 model2 loss : 0.030945
[10:49:51.169] iteration 5400 : model1 loss : 0.434474 model2 loss : 0.032492
[10:49:51.338] iteration 5401 : model1 loss : 0.439383 model2 loss : 0.038269
[10:49:51.516] iteration 5402 : model1 loss : 0.441704 model2 loss : 0.037403
[10:49:51.686] iteration 5403 : model1 loss : 0.438007 model2 loss : 0.029556
[10:49:51.861] iteration 5404 : model1 loss : 0.442937 model2 loss : 0.034754
[10:49:52.029] iteration 5405 : model1 loss : 0.436215 model2 loss : 0.032147
[10:49:52.202] iteration 5406 : model1 loss : 0.436896 model2 loss : 0.033695
[10:49:52.375] iteration 5407 : model1 loss : 0.437472 model2 loss : 0.031280
[10:49:52.553] iteration 5408 : model1 loss : 0.437598 model2 loss : 0.037533
[10:49:52.722] iteration 5409 : model1 loss : 0.436507 model2 loss : 0.033131
[10:49:52.903] iteration 5410 : model1 loss : 0.438919 model2 loss : 0.032097
[10:49:53.071] iteration 5411 : model1 loss : 0.436175 model2 loss : 0.031679
[10:49:53.243] iteration 5412 : model1 loss : 0.437942 model2 loss : 0.031575
[10:49:55.200] iteration 5413 : model1 loss : 0.431357 model2 loss : 0.031526
[10:49:55.373] iteration 5414 : model1 loss : 0.439335 model2 loss : 0.031917
[10:49:55.554] iteration 5415 : model1 loss : 0.436857 model2 loss : 0.037699
[10:49:55.722] iteration 5416 : model1 loss : 0.438618 model2 loss : 0.030243
[10:49:55.905] iteration 5417 : model1 loss : 0.440989 model2 loss : 0.035049
[10:49:56.073] iteration 5418 : model1 loss : 0.440883 model2 loss : 0.039022
[10:49:56.246] iteration 5419 : model1 loss : 0.441742 model2 loss : 0.037797
[10:49:56.416] iteration 5420 : model1 loss : 0.439843 model2 loss : 0.031624
[10:49:56.591] iteration 5421 : model1 loss : 0.442731 model2 loss : 0.036529
[10:49:56.760] iteration 5422 : model1 loss : 0.437625 model2 loss : 0.029132
[10:49:56.935] iteration 5423 : model1 loss : 0.434783 model2 loss : 0.026519
[10:49:57.104] iteration 5424 : model1 loss : 0.443072 model2 loss : 0.036427
[10:49:57.280] iteration 5425 : model1 loss : 0.436880 model2 loss : 0.031579
[10:49:57.452] iteration 5426 : model1 loss : 0.435473 model2 loss : 0.031053
[10:49:57.626] iteration 5427 : model1 loss : 0.439431 model2 loss : 0.029061
[10:49:57.794] iteration 5428 : model1 loss : 0.439283 model2 loss : 0.033255
[10:49:57.968] iteration 5429 : model1 loss : 0.438546 model2 loss : 0.030527
[10:49:58.136] iteration 5430 : model1 loss : 0.439582 model2 loss : 0.035681
[10:49:58.312] iteration 5431 : model1 loss : 0.436099 model2 loss : 0.029781
[10:49:58.483] iteration 5432 : model1 loss : 0.436535 model2 loss : 0.027341
[10:49:58.657] iteration 5433 : model1 loss : 0.437566 model2 loss : 0.028551
[10:49:58.825] iteration 5434 : model1 loss : 0.440144 model2 loss : 0.031399
[10:49:59.001] iteration 5435 : model1 loss : 0.438828 model2 loss : 0.036618
[10:49:59.169] iteration 5436 : model1 loss : 0.440614 model2 loss : 0.036491
[10:49:59.345] iteration 5437 : model1 loss : 0.434225 model2 loss : 0.031014
[10:49:59.521] iteration 5438 : model1 loss : 0.432685 model2 loss : 0.027983
[10:49:59.695] iteration 5439 : model1 loss : 0.441325 model2 loss : 0.030591
[10:49:59.867] iteration 5440 : model1 loss : 0.432426 model2 loss : 0.027537
[10:50:00.044] iteration 5441 : model1 loss : 0.436879 model2 loss : 0.030031
[10:50:00.217] iteration 5442 : model1 loss : 0.440940 model2 loss : 0.031331
[10:50:00.395] iteration 5443 : model1 loss : 0.440796 model2 loss : 0.036541
[10:50:00.563] iteration 5444 : model1 loss : 0.438066 model2 loss : 0.031233
[10:50:00.734] iteration 5445 : model1 loss : 0.438432 model2 loss : 0.030685
[10:50:02.740] iteration 5446 : model1 loss : 0.436887 model2 loss : 0.032741
[10:50:02.912] iteration 5447 : model1 loss : 0.437367 model2 loss : 0.029702
[10:50:03.089] iteration 5448 : model1 loss : 0.434302 model2 loss : 0.031052
[10:50:03.256] iteration 5449 : model1 loss : 0.434704 model2 loss : 0.028706
[10:50:03.429] iteration 5450 : model1 loss : 0.434428 model2 loss : 0.027463
[10:50:03.597] iteration 5451 : model1 loss : 0.438628 model2 loss : 0.028583
[10:50:03.770] iteration 5452 : model1 loss : 0.440867 model2 loss : 0.038341
[10:50:03.942] iteration 5453 : model1 loss : 0.440616 model2 loss : 0.031856
[10:50:04.117] iteration 5454 : model1 loss : 0.438194 model2 loss : 0.031077
[10:50:04.286] iteration 5455 : model1 loss : 0.436664 model2 loss : 0.035738
[10:50:04.457] iteration 5456 : model1 loss : 0.434991 model2 loss : 0.029614
[10:50:04.625] iteration 5457 : model1 loss : 0.437868 model2 loss : 0.030734
[10:50:04.798] iteration 5458 : model1 loss : 0.438490 model2 loss : 0.033085
[10:50:04.969] iteration 5459 : model1 loss : 0.441745 model2 loss : 0.033010
[10:50:05.145] iteration 5460 : model1 loss : 0.437807 model2 loss : 0.027441
[10:50:05.313] iteration 5461 : model1 loss : 0.442196 model2 loss : 0.040503
[10:50:05.487] iteration 5462 : model1 loss : 0.436031 model2 loss : 0.030504
[10:50:05.657] iteration 5463 : model1 loss : 0.436140 model2 loss : 0.027728
[10:50:05.833] iteration 5464 : model1 loss : 0.439266 model2 loss : 0.038016
[10:50:06.004] iteration 5465 : model1 loss : 0.439748 model2 loss : 0.030800
[10:50:06.179] iteration 5466 : model1 loss : 0.438722 model2 loss : 0.036917
[10:50:06.349] iteration 5467 : model1 loss : 0.433007 model2 loss : 0.028384
[10:50:06.525] iteration 5468 : model1 loss : 0.439850 model2 loss : 0.036481
[10:50:06.693] iteration 5469 : model1 loss : 0.432589 model2 loss : 0.025058
[10:50:06.868] iteration 5470 : model1 loss : 0.440264 model2 loss : 0.031452
[10:50:07.037] iteration 5471 : model1 loss : 0.441602 model2 loss : 0.028385
[10:50:07.212] iteration 5472 : model1 loss : 0.444207 model2 loss : 0.032704
[10:50:07.381] iteration 5473 : model1 loss : 0.438680 model2 loss : 0.030495
[10:50:07.553] iteration 5474 : model1 loss : 0.439132 model2 loss : 0.031949
[10:50:07.722] iteration 5475 : model1 loss : 0.444227 model2 loss : 0.032355
[10:50:07.898] iteration 5476 : model1 loss : 0.441509 model2 loss : 0.034395
[10:50:08.065] iteration 5477 : model1 loss : 0.434118 model2 loss : 0.028347
[10:50:08.236] iteration 5478 : model1 loss : 0.437338 model2 loss : 0.030668
[10:50:10.201] iteration 5479 : model1 loss : 0.445407 model2 loss : 0.035463
[10:50:10.372] iteration 5480 : model1 loss : 0.437881 model2 loss : 0.037843
[10:50:10.549] iteration 5481 : model1 loss : 0.438195 model2 loss : 0.042239
[10:50:10.718] iteration 5482 : model1 loss : 0.439147 model2 loss : 0.032201
[10:50:10.898] iteration 5483 : model1 loss : 0.437582 model2 loss : 0.029824
[10:50:11.064] iteration 5484 : model1 loss : 0.439435 model2 loss : 0.032332
[10:50:11.237] iteration 5485 : model1 loss : 0.439640 model2 loss : 0.029732
[10:50:11.408] iteration 5486 : model1 loss : 0.439934 model2 loss : 0.034752
[10:50:11.583] iteration 5487 : model1 loss : 0.432914 model2 loss : 0.033495
[10:50:11.751] iteration 5488 : model1 loss : 0.438654 model2 loss : 0.033238
[10:50:11.931] iteration 5489 : model1 loss : 0.437309 model2 loss : 0.029564
[10:50:12.099] iteration 5490 : model1 loss : 0.437604 model2 loss : 0.033777
[10:50:12.273] iteration 5491 : model1 loss : 0.434025 model2 loss : 0.028997
[10:50:12.444] iteration 5492 : model1 loss : 0.435692 model2 loss : 0.028859
[10:50:12.619] iteration 5493 : model1 loss : 0.438847 model2 loss : 0.032171
[10:50:12.786] iteration 5494 : model1 loss : 0.439480 model2 loss : 0.031728
[10:50:12.962] iteration 5495 : model1 loss : 0.437605 model2 loss : 0.031362
[10:50:13.130] iteration 5496 : model1 loss : 0.436881 model2 loss : 0.033918
[10:50:13.303] iteration 5497 : model1 loss : 0.439145 model2 loss : 0.031391
[10:50:13.474] iteration 5498 : model1 loss : 0.441324 model2 loss : 0.033510
[10:50:13.649] iteration 5499 : model1 loss : 0.436455 model2 loss : 0.028967
[10:50:13.817] iteration 5500 : model1 loss : 0.441681 model2 loss : 0.031652
[10:50:13.990] iteration 5501 : model1 loss : 0.438531 model2 loss : 0.033358
[10:50:14.160] iteration 5502 : model1 loss : 0.441010 model2 loss : 0.030386
[10:50:14.332] iteration 5503 : model1 loss : 0.442149 model2 loss : 0.039150
[10:50:14.505] iteration 5504 : model1 loss : 0.441421 model2 loss : 0.038001
[10:50:14.680] iteration 5505 : model1 loss : 0.439221 model2 loss : 0.030218
[10:50:14.849] iteration 5506 : model1 loss : 0.433994 model2 loss : 0.026131
[10:50:15.023] iteration 5507 : model1 loss : 0.438340 model2 loss : 0.029426
[10:50:15.190] iteration 5508 : model1 loss : 0.438807 model2 loss : 0.033551
[10:50:15.364] iteration 5509 : model1 loss : 0.436516 model2 loss : 0.031887
[10:50:15.536] iteration 5510 : model1 loss : 0.435750 model2 loss : 0.027073
[10:50:15.709] iteration 5511 : model1 loss : 0.436682 model2 loss : 0.032489
[10:50:17.720] iteration 5512 : model1 loss : 0.439074 model2 loss : 0.028325
[10:50:17.895] iteration 5513 : model1 loss : 0.435589 model2 loss : 0.026027
[10:50:18.071] iteration 5514 : model1 loss : 0.436562 model2 loss : 0.028838
[10:50:18.239] iteration 5515 : model1 loss : 0.435549 model2 loss : 0.030361
[10:50:18.416] iteration 5516 : model1 loss : 0.438157 model2 loss : 0.031767
[10:50:18.586] iteration 5517 : model1 loss : 0.436541 model2 loss : 0.029958
[10:50:18.758] iteration 5518 : model1 loss : 0.433528 model2 loss : 0.029138
[10:50:18.931] iteration 5519 : model1 loss : 0.439795 model2 loss : 0.035898
[10:50:19.105] iteration 5520 : model1 loss : 0.440456 model2 loss : 0.028545
[10:50:19.273] iteration 5521 : model1 loss : 0.435678 model2 loss : 0.030002
[10:50:19.450] iteration 5522 : model1 loss : 0.439819 model2 loss : 0.031279
[10:50:19.621] iteration 5523 : model1 loss : 0.443214 model2 loss : 0.036605
[10:50:19.793] iteration 5524 : model1 loss : 0.443692 model2 loss : 0.038021
[10:50:19.965] iteration 5525 : model1 loss : 0.445226 model2 loss : 0.035075
[10:50:20.139] iteration 5526 : model1 loss : 0.440999 model2 loss : 0.038566
[10:50:20.307] iteration 5527 : model1 loss : 0.439840 model2 loss : 0.031031
[10:50:20.481] iteration 5528 : model1 loss : 0.436051 model2 loss : 0.028125
[10:50:20.653] iteration 5529 : model1 loss : 0.436176 model2 loss : 0.029584
[10:50:20.828] iteration 5530 : model1 loss : 0.438216 model2 loss : 0.029641
[10:50:20.999] iteration 5531 : model1 loss : 0.441910 model2 loss : 0.037102
[10:50:21.174] iteration 5532 : model1 loss : 0.435274 model2 loss : 0.028329
[10:50:21.343] iteration 5533 : model1 loss : 0.441248 model2 loss : 0.037213
[10:50:21.523] iteration 5534 : model1 loss : 0.440926 model2 loss : 0.034731
[10:50:21.691] iteration 5535 : model1 loss : 0.432283 model2 loss : 0.026345
[10:50:21.865] iteration 5536 : model1 loss : 0.435637 model2 loss : 0.028204
[10:50:22.036] iteration 5537 : model1 loss : 0.439380 model2 loss : 0.029143
[10:50:22.208] iteration 5538 : model1 loss : 0.436107 model2 loss : 0.032838
[10:50:22.379] iteration 5539 : model1 loss : 0.434939 model2 loss : 0.027160
[10:50:22.556] iteration 5540 : model1 loss : 0.437745 model2 loss : 0.028746
[10:50:22.724] iteration 5541 : model1 loss : 0.443270 model2 loss : 0.034975
[10:50:22.901] iteration 5542 : model1 loss : 0.433393 model2 loss : 0.027104
[10:50:23.068] iteration 5543 : model1 loss : 0.439790 model2 loss : 0.034032
[10:50:23.244] iteration 5544 : model1 loss : 0.438504 model2 loss : 0.031172
[10:50:25.212] iteration 5545 : model1 loss : 0.444948 model2 loss : 0.032694
[10:50:25.385] iteration 5546 : model1 loss : 0.431454 model2 loss : 0.028213
[10:50:25.562] iteration 5547 : model1 loss : 0.442537 model2 loss : 0.029417
[10:50:25.731] iteration 5548 : model1 loss : 0.434530 model2 loss : 0.025523
[10:50:25.910] iteration 5549 : model1 loss : 0.443002 model2 loss : 0.036851
[10:50:26.079] iteration 5550 : model1 loss : 0.440986 model2 loss : 0.032369
[10:50:26.252] iteration 5551 : model1 loss : 0.438544 model2 loss : 0.031784
[10:50:26.423] iteration 5552 : model1 loss : 0.442123 model2 loss : 0.033292
[10:50:26.599] iteration 5553 : model1 loss : 0.437245 model2 loss : 0.029323
[10:50:26.768] iteration 5554 : model1 loss : 0.437250 model2 loss : 0.031905
[10:50:26.943] iteration 5555 : model1 loss : 0.438715 model2 loss : 0.030574
[10:50:27.111] iteration 5556 : model1 loss : 0.434088 model2 loss : 0.028044
[10:50:27.284] iteration 5557 : model1 loss : 0.440001 model2 loss : 0.031313
[10:50:27.456] iteration 5558 : model1 loss : 0.435157 model2 loss : 0.026737
[10:50:27.632] iteration 5559 : model1 loss : 0.435658 model2 loss : 0.028908
[10:50:27.799] iteration 5560 : model1 loss : 0.436890 model2 loss : 0.030628
[10:50:27.976] iteration 5561 : model1 loss : 0.434270 model2 loss : 0.032822
[10:50:28.142] iteration 5562 : model1 loss : 0.439781 model2 loss : 0.026598
[10:50:28.316] iteration 5563 : model1 loss : 0.434942 model2 loss : 0.030438
[10:50:28.487] iteration 5564 : model1 loss : 0.442193 model2 loss : 0.030308
[10:50:28.661] iteration 5565 : model1 loss : 0.440471 model2 loss : 0.031892
[10:50:28.831] iteration 5566 : model1 loss : 0.445814 model2 loss : 0.035489
[10:50:29.004] iteration 5567 : model1 loss : 0.436093 model2 loss : 0.030690
[10:50:29.174] iteration 5568 : model1 loss : 0.437956 model2 loss : 0.032009
[10:50:29.348] iteration 5569 : model1 loss : 0.434091 model2 loss : 0.026638
[10:50:29.521] iteration 5570 : model1 loss : 0.433577 model2 loss : 0.027331
[10:50:29.695] iteration 5571 : model1 loss : 0.436594 model2 loss : 0.031382
[10:50:29.863] iteration 5572 : model1 loss : 0.434656 model2 loss : 0.030203
[10:50:30.039] iteration 5573 : model1 loss : 0.444165 model2 loss : 0.034745
[10:50:30.207] iteration 5574 : model1 loss : 0.439584 model2 loss : 0.038026
[10:50:30.381] iteration 5575 : model1 loss : 0.439248 model2 loss : 0.028775
[10:50:30.553] iteration 5576 : model1 loss : 0.438021 model2 loss : 0.029330
[10:50:30.724] iteration 5577 : model1 loss : 0.437387 model2 loss : 0.027797
[10:50:32.732] iteration 5578 : model1 loss : 0.444177 model2 loss : 0.031735
[10:50:32.904] iteration 5579 : model1 loss : 0.436555 model2 loss : 0.026850
[10:50:33.080] iteration 5580 : model1 loss : 0.441572 model2 loss : 0.034672
[10:50:33.249] iteration 5581 : model1 loss : 0.438405 model2 loss : 0.031396
[10:50:33.424] iteration 5582 : model1 loss : 0.439181 model2 loss : 0.029597
[10:50:33.595] iteration 5583 : model1 loss : 0.441299 model2 loss : 0.032186
[10:50:33.767] iteration 5584 : model1 loss : 0.434866 model2 loss : 0.027377
[10:50:33.939] iteration 5585 : model1 loss : 0.441569 model2 loss : 0.029899
[10:50:34.113] iteration 5586 : model1 loss : 0.434731 model2 loss : 0.031123
[10:50:34.282] iteration 5587 : model1 loss : 0.439678 model2 loss : 0.032421
[10:50:34.456] iteration 5588 : model1 loss : 0.436256 model2 loss : 0.026076
[10:50:34.626] iteration 5589 : model1 loss : 0.435488 model2 loss : 0.027566
[10:50:34.800] iteration 5590 : model1 loss : 0.439952 model2 loss : 0.036105
[10:50:34.971] iteration 5591 : model1 loss : 0.433278 model2 loss : 0.026216
[10:50:35.147] iteration 5592 : model1 loss : 0.436425 model2 loss : 0.035131
[10:50:35.314] iteration 5593 : model1 loss : 0.437265 model2 loss : 0.032414
[10:50:35.488] iteration 5594 : model1 loss : 0.439915 model2 loss : 0.032547
[10:50:35.657] iteration 5595 : model1 loss : 0.438476 model2 loss : 0.033555
[10:50:35.832] iteration 5596 : model1 loss : 0.434422 model2 loss : 0.033497
[10:50:36.001] iteration 5597 : model1 loss : 0.436130 model2 loss : 0.028143
[10:50:36.177] iteration 5598 : model1 loss : 0.434561 model2 loss : 0.026925
[10:50:36.345] iteration 5599 : model1 loss : 0.437320 model2 loss : 0.028791
[10:50:36.523] iteration 5600 : model1 loss : 0.433535 model2 loss : 0.026719
[10:50:36.691] iteration 5601 : model1 loss : 0.444328 model2 loss : 0.032112
[10:50:36.864] iteration 5602 : model1 loss : 0.444822 model2 loss : 0.031491
[10:50:37.033] iteration 5603 : model1 loss : 0.438282 model2 loss : 0.025243
[10:50:37.208] iteration 5604 : model1 loss : 0.440599 model2 loss : 0.032269
[10:50:37.377] iteration 5605 : model1 loss : 0.439565 model2 loss : 0.028608
[10:50:37.552] iteration 5606 : model1 loss : 0.432953 model2 loss : 0.025370
[10:50:37.722] iteration 5607 : model1 loss : 0.435155 model2 loss : 0.027030
[10:50:37.896] iteration 5608 : model1 loss : 0.443028 model2 loss : 0.035000
[10:50:38.064] iteration 5609 : model1 loss : 0.438578 model2 loss : 0.031361
[10:50:38.237] iteration 5610 : model1 loss : 0.439310 model2 loss : 0.029239
[10:50:40.210] iteration 5611 : model1 loss : 0.437534 model2 loss : 0.027814
[10:50:40.381] iteration 5612 : model1 loss : 0.438829 model2 loss : 0.029715
[10:50:40.560] iteration 5613 : model1 loss : 0.434047 model2 loss : 0.027400
[10:50:40.730] iteration 5614 : model1 loss : 0.438163 model2 loss : 0.027960
[10:50:40.910] iteration 5615 : model1 loss : 0.437963 model2 loss : 0.029841
[10:50:41.081] iteration 5616 : model1 loss : 0.441165 model2 loss : 0.027311
[10:50:41.254] iteration 5617 : model1 loss : 0.441872 model2 loss : 0.029264
[10:50:41.425] iteration 5618 : model1 loss : 0.431622 model2 loss : 0.026153
[10:50:41.598] iteration 5619 : model1 loss : 0.437869 model2 loss : 0.029444
[10:50:41.766] iteration 5620 : model1 loss : 0.442606 model2 loss : 0.034213
[10:50:41.943] iteration 5621 : model1 loss : 0.439064 model2 loss : 0.032732
[10:50:42.111] iteration 5622 : model1 loss : 0.439358 model2 loss : 0.030344
[10:50:42.283] iteration 5623 : model1 loss : 0.439974 model2 loss : 0.029488
[10:50:42.453] iteration 5624 : model1 loss : 0.435840 model2 loss : 0.026752
[10:50:42.629] iteration 5625 : model1 loss : 0.433610 model2 loss : 0.026380
[10:50:42.798] iteration 5626 : model1 loss : 0.436579 model2 loss : 0.027332
[10:50:42.972] iteration 5627 : model1 loss : 0.442572 model2 loss : 0.031446
[10:50:43.143] iteration 5628 : model1 loss : 0.437953 model2 loss : 0.031102
[10:50:43.315] iteration 5629 : model1 loss : 0.439357 model2 loss : 0.032056
[10:50:43.486] iteration 5630 : model1 loss : 0.436611 model2 loss : 0.027946
[10:50:43.660] iteration 5631 : model1 loss : 0.441563 model2 loss : 0.040291
[10:50:43.828] iteration 5632 : model1 loss : 0.435181 model2 loss : 0.030150
[10:50:44.004] iteration 5633 : model1 loss : 0.435432 model2 loss : 0.028415
[10:50:44.172] iteration 5634 : model1 loss : 0.440846 model2 loss : 0.029171
[10:50:44.347] iteration 5635 : model1 loss : 0.438398 model2 loss : 0.029843
[10:50:44.520] iteration 5636 : model1 loss : 0.435763 model2 loss : 0.027509
[10:50:44.694] iteration 5637 : model1 loss : 0.437663 model2 loss : 0.028772
[10:50:44.863] iteration 5638 : model1 loss : 0.437248 model2 loss : 0.031524
[10:50:45.037] iteration 5639 : model1 loss : 0.435825 model2 loss : 0.028999
[10:50:45.206] iteration 5640 : model1 loss : 0.441115 model2 loss : 0.030598
[10:50:45.379] iteration 5641 : model1 loss : 0.439942 model2 loss : 0.029036
[10:50:45.551] iteration 5642 : model1 loss : 0.442487 model2 loss : 0.032345
[10:50:45.724] iteration 5643 : model1 loss : 0.430509 model2 loss : 0.025926
[10:50:47.743] iteration 5644 : model1 loss : 0.437709 model2 loss : 0.032675
[10:50:47.916] iteration 5645 : model1 loss : 0.433953 model2 loss : 0.027839
[10:50:48.092] iteration 5646 : model1 loss : 0.437601 model2 loss : 0.032400
[10:50:48.259] iteration 5647 : model1 loss : 0.437735 model2 loss : 0.029560
[10:50:48.434] iteration 5648 : model1 loss : 0.432371 model2 loss : 0.026990
[10:50:48.605] iteration 5649 : model1 loss : 0.439663 model2 loss : 0.032515
[10:50:48.776] iteration 5650 : model1 loss : 0.438678 model2 loss : 0.027119
[10:50:48.947] iteration 5651 : model1 loss : 0.440405 model2 loss : 0.026984
[10:50:49.125] iteration 5652 : model1 loss : 0.439807 model2 loss : 0.027143
[10:50:49.293] iteration 5653 : model1 loss : 0.439766 model2 loss : 0.028537
[10:50:49.468] iteration 5654 : model1 loss : 0.438922 model2 loss : 0.030876
[10:50:49.637] iteration 5655 : model1 loss : 0.444756 model2 loss : 0.032005
[10:50:49.826] iteration 5656 : model1 loss : 0.434738 model2 loss : 0.028601
[10:50:49.999] iteration 5657 : model1 loss : 0.439727 model2 loss : 0.034700
[10:50:50.175] iteration 5658 : model1 loss : 0.438873 model2 loss : 0.027242
[10:50:50.343] iteration 5659 : model1 loss : 0.435616 model2 loss : 0.028464
[10:50:50.521] iteration 5660 : model1 loss : 0.436012 model2 loss : 0.027936
[10:50:50.689] iteration 5661 : model1 loss : 0.440408 model2 loss : 0.031247
[10:50:50.866] iteration 5662 : model1 loss : 0.435639 model2 loss : 0.024688
[10:50:51.038] iteration 5663 : model1 loss : 0.435819 model2 loss : 0.028335
[10:50:51.215] iteration 5664 : model1 loss : 0.435291 model2 loss : 0.030332
[10:50:51.383] iteration 5665 : model1 loss : 0.435088 model2 loss : 0.028572
[10:50:51.557] iteration 5666 : model1 loss : 0.443131 model2 loss : 0.039017
[10:50:51.726] iteration 5667 : model1 loss : 0.441550 model2 loss : 0.030838
[10:50:51.904] iteration 5668 : model1 loss : 0.440042 model2 loss : 0.031411
[10:50:52.075] iteration 5669 : model1 loss : 0.436192 model2 loss : 0.025022
[10:50:52.250] iteration 5670 : model1 loss : 0.438949 model2 loss : 0.024244
[10:50:52.422] iteration 5671 : model1 loss : 0.448240 model2 loss : 0.030992
[10:50:52.597] iteration 5672 : model1 loss : 0.438152 model2 loss : 0.027895
[10:50:52.766] iteration 5673 : model1 loss : 0.440651 model2 loss : 0.029369
[10:50:52.943] iteration 5674 : model1 loss : 0.436530 model2 loss : 0.028270
[10:50:53.113] iteration 5675 : model1 loss : 0.441840 model2 loss : 0.034946
[10:50:53.283] iteration 5676 : model1 loss : 0.439348 model2 loss : 0.025199
[10:50:55.250] iteration 5677 : model1 loss : 0.437355 model2 loss : 0.030912
[10:50:55.419] iteration 5678 : model1 loss : 0.439291 model2 loss : 0.027497
[10:50:55.595] iteration 5679 : model1 loss : 0.438783 model2 loss : 0.029146
[10:50:55.762] iteration 5680 : model1 loss : 0.435293 model2 loss : 0.027995
[10:50:55.938] iteration 5681 : model1 loss : 0.437456 model2 loss : 0.027975
[10:50:56.109] iteration 5682 : model1 loss : 0.438707 model2 loss : 0.027212
[10:50:56.282] iteration 5683 : model1 loss : 0.442224 model2 loss : 0.037640
[10:50:56.455] iteration 5684 : model1 loss : 0.435920 model2 loss : 0.029509
[10:50:56.630] iteration 5685 : model1 loss : 0.440365 model2 loss : 0.028463
[10:50:56.798] iteration 5686 : model1 loss : 0.437702 model2 loss : 0.026112
[10:50:56.972] iteration 5687 : model1 loss : 0.437402 model2 loss : 0.030684
[10:50:57.143] iteration 5688 : model1 loss : 0.434145 model2 loss : 0.024288
[10:50:57.315] iteration 5689 : model1 loss : 0.446315 model2 loss : 0.039721
[10:50:57.488] iteration 5690 : model1 loss : 0.434989 model2 loss : 0.029172
[10:50:57.661] iteration 5691 : model1 loss : 0.436709 model2 loss : 0.031857
[10:50:57.829] iteration 5692 : model1 loss : 0.438009 model2 loss : 0.030578
[10:50:58.003] iteration 5693 : model1 loss : 0.439464 model2 loss : 0.026017
[10:50:58.170] iteration 5694 : model1 loss : 0.434349 model2 loss : 0.030571
[10:50:58.344] iteration 5695 : model1 loss : 0.434236 model2 loss : 0.032121
[10:50:58.518] iteration 5696 : model1 loss : 0.440719 model2 loss : 0.029981
[10:50:58.691] iteration 5697 : model1 loss : 0.438970 model2 loss : 0.033142
[10:50:58.860] iteration 5698 : model1 loss : 0.441115 model2 loss : 0.032848
[10:50:59.036] iteration 5699 : model1 loss : 0.443538 model2 loss : 0.035320
[10:50:59.205] iteration 5700 : model1 loss : 0.435285 model2 loss : 0.026472
[10:50:59.380] iteration 5701 : model1 loss : 0.441410 model2 loss : 0.029367
[10:50:59.551] iteration 5702 : model1 loss : 0.442720 model2 loss : 0.035064
[10:50:59.724] iteration 5703 : model1 loss : 0.436977 model2 loss : 0.031864
[10:50:59.895] iteration 5704 : model1 loss : 0.439264 model2 loss : 0.031021
[10:51:00.071] iteration 5705 : model1 loss : 0.436379 model2 loss : 0.026388
[10:51:00.246] iteration 5706 : model1 loss : 0.440522 model2 loss : 0.039124
[10:51:00.423] iteration 5707 : model1 loss : 0.441025 model2 loss : 0.034923
[10:51:00.592] iteration 5708 : model1 loss : 0.432095 model2 loss : 0.031113
[10:51:00.763] iteration 5709 : model1 loss : 0.436142 model2 loss : 0.034648
[10:51:02.731] iteration 5710 : model1 loss : 0.434782 model2 loss : 0.028693
[10:51:02.901] iteration 5711 : model1 loss : 0.437216 model2 loss : 0.027825
[10:51:03.079] iteration 5712 : model1 loss : 0.436751 model2 loss : 0.026433
[10:51:03.248] iteration 5713 : model1 loss : 0.436612 model2 loss : 0.031440
[10:51:03.420] iteration 5714 : model1 loss : 0.440910 model2 loss : 0.031877
[10:51:03.590] iteration 5715 : model1 loss : 0.445167 model2 loss : 0.040686
[10:51:03.763] iteration 5716 : model1 loss : 0.437960 model2 loss : 0.025296
[10:51:03.934] iteration 5717 : model1 loss : 0.439530 model2 loss : 0.032413
[10:51:04.110] iteration 5718 : model1 loss : 0.435185 model2 loss : 0.030622
[10:51:04.278] iteration 5719 : model1 loss : 0.435855 model2 loss : 0.025372
[10:51:04.451] iteration 5720 : model1 loss : 0.437765 model2 loss : 0.030336
[10:51:04.623] iteration 5721 : model1 loss : 0.437760 model2 loss : 0.027825
[10:51:04.796] iteration 5722 : model1 loss : 0.435897 model2 loss : 0.027569
[10:51:04.965] iteration 5723 : model1 loss : 0.436672 model2 loss : 0.030036
[10:51:05.141] iteration 5724 : model1 loss : 0.437508 model2 loss : 0.029055
[10:51:05.311] iteration 5725 : model1 loss : 0.437862 model2 loss : 0.031747
[10:51:05.485] iteration 5726 : model1 loss : 0.434372 model2 loss : 0.029012
[10:51:05.655] iteration 5727 : model1 loss : 0.439077 model2 loss : 0.036429
[10:51:05.828] iteration 5728 : model1 loss : 0.440062 model2 loss : 0.031174
[10:51:06.000] iteration 5729 : model1 loss : 0.436263 model2 loss : 0.028463
[10:51:06.174] iteration 5730 : model1 loss : 0.437738 model2 loss : 0.028963
[10:51:06.345] iteration 5731 : model1 loss : 0.435341 model2 loss : 0.028384
[10:51:06.521] iteration 5732 : model1 loss : 0.437883 model2 loss : 0.033939
[10:51:06.689] iteration 5733 : model1 loss : 0.441053 model2 loss : 0.032210
[10:51:06.863] iteration 5734 : model1 loss : 0.440147 model2 loss : 0.029471
[10:51:07.033] iteration 5735 : model1 loss : 0.438740 model2 loss : 0.030379
[10:51:07.209] iteration 5736 : model1 loss : 0.438595 model2 loss : 0.033754
[10:51:07.377] iteration 5737 : model1 loss : 0.439576 model2 loss : 0.031164
[10:51:07.552] iteration 5738 : model1 loss : 0.438134 model2 loss : 0.030196
[10:51:07.720] iteration 5739 : model1 loss : 0.441799 model2 loss : 0.033611
[10:51:07.894] iteration 5740 : model1 loss : 0.437204 model2 loss : 0.030098
[10:51:08.063] iteration 5741 : model1 loss : 0.438610 model2 loss : 0.032454
[10:51:08.236] iteration 5742 : model1 loss : 0.440522 model2 loss : 0.034678
[10:51:10.221] iteration 5743 : model1 loss : 0.432697 model2 loss : 0.029261
[10:51:10.394] iteration 5744 : model1 loss : 0.435908 model2 loss : 0.030593
[10:51:10.572] iteration 5745 : model1 loss : 0.436896 model2 loss : 0.032081
[10:51:10.740] iteration 5746 : model1 loss : 0.437109 model2 loss : 0.028976
[10:51:10.916] iteration 5747 : model1 loss : 0.437361 model2 loss : 0.029472
[10:51:11.087] iteration 5748 : model1 loss : 0.442138 model2 loss : 0.036264
[10:51:11.258] iteration 5749 : model1 loss : 0.443926 model2 loss : 0.035023
[10:51:11.427] iteration 5750 : model1 loss : 0.432881 model2 loss : 0.027915
[10:51:11.602] iteration 5751 : model1 loss : 0.437869 model2 loss : 0.030490
[10:51:11.770] iteration 5752 : model1 loss : 0.443151 model2 loss : 0.040282
[10:51:11.944] iteration 5753 : model1 loss : 0.439773 model2 loss : 0.029255
[10:51:12.115] iteration 5754 : model1 loss : 0.437381 model2 loss : 0.027364
[10:51:12.287] iteration 5755 : model1 loss : 0.440042 model2 loss : 0.028871
[10:51:12.458] iteration 5756 : model1 loss : 0.433592 model2 loss : 0.028896
[10:51:12.635] iteration 5757 : model1 loss : 0.441110 model2 loss : 0.037537
[10:51:12.805] iteration 5758 : model1 loss : 0.436771 model2 loss : 0.027981
[10:51:12.980] iteration 5759 : model1 loss : 0.435969 model2 loss : 0.026840
[10:51:13.152] iteration 5760 : model1 loss : 0.437162 model2 loss : 0.027851
[10:51:13.324] iteration 5761 : model1 loss : 0.441752 model2 loss : 0.031205
[10:51:13.497] iteration 5762 : model1 loss : 0.435775 model2 loss : 0.028412
[10:51:13.672] iteration 5763 : model1 loss : 0.440465 model2 loss : 0.030971
[10:51:13.840] iteration 5764 : model1 loss : 0.438010 model2 loss : 0.027281
[10:51:14.014] iteration 5765 : model1 loss : 0.438975 model2 loss : 0.030133
[10:51:14.184] iteration 5766 : model1 loss : 0.440704 model2 loss : 0.028366
[10:51:14.357] iteration 5767 : model1 loss : 0.437608 model2 loss : 0.030927
[10:51:14.531] iteration 5768 : model1 loss : 0.433902 model2 loss : 0.027811
[10:51:14.708] iteration 5769 : model1 loss : 0.439075 model2 loss : 0.028691
[10:51:14.877] iteration 5770 : model1 loss : 0.437387 model2 loss : 0.028519
[10:51:15.049] iteration 5771 : model1 loss : 0.451608 model2 loss : 0.036971
[10:51:15.218] iteration 5772 : model1 loss : 0.440661 model2 loss : 0.029310
[10:51:15.391] iteration 5773 : model1 loss : 0.439027 model2 loss : 0.026445
[10:51:15.563] iteration 5774 : model1 loss : 0.440876 model2 loss : 0.031036
[10:51:15.736] iteration 5775 : model1 loss : 0.439472 model2 loss : 0.030184
[10:51:17.766] iteration 5776 : model1 loss : 0.440490 model2 loss : 0.033544
[10:51:17.938] iteration 5777 : model1 loss : 0.436648 model2 loss : 0.027391
[10:51:18.115] iteration 5778 : model1 loss : 0.434451 model2 loss : 0.028227
[10:51:18.284] iteration 5779 : model1 loss : 0.442083 model2 loss : 0.033190
[10:51:18.458] iteration 5780 : model1 loss : 0.435672 model2 loss : 0.034796
[10:51:18.628] iteration 5781 : model1 loss : 0.436316 model2 loss : 0.025664
[10:51:18.803] iteration 5782 : model1 loss : 0.436307 model2 loss : 0.027949
[10:51:18.975] iteration 5783 : model1 loss : 0.434565 model2 loss : 0.026786
[10:51:19.150] iteration 5784 : model1 loss : 0.434074 model2 loss : 0.028338
[10:51:19.316] iteration 5785 : model1 loss : 0.442002 model2 loss : 0.033944
[10:51:19.490] iteration 5786 : model1 loss : 0.440106 model2 loss : 0.027681
[10:51:19.659] iteration 5787 : model1 loss : 0.438675 model2 loss : 0.032085
[10:51:19.835] iteration 5788 : model1 loss : 0.438881 model2 loss : 0.032432
[10:51:20.006] iteration 5789 : model1 loss : 0.438145 model2 loss : 0.031312
[10:51:20.180] iteration 5790 : model1 loss : 0.445635 model2 loss : 0.035022
[10:51:20.348] iteration 5791 : model1 loss : 0.438624 model2 loss : 0.029076
[10:51:20.526] iteration 5792 : model1 loss : 0.437652 model2 loss : 0.030836
[10:51:20.694] iteration 5793 : model1 loss : 0.436717 model2 loss : 0.024809
[10:51:20.871] iteration 5794 : model1 loss : 0.436970 model2 loss : 0.032408
[10:51:21.041] iteration 5795 : model1 loss : 0.437126 model2 loss : 0.026966
[10:51:21.213] iteration 5796 : model1 loss : 0.442875 model2 loss : 0.033017
[10:51:21.380] iteration 5797 : model1 loss : 0.445319 model2 loss : 0.042562
[10:51:21.559] iteration 5798 : model1 loss : 0.443436 model2 loss : 0.029629
[10:51:21.727] iteration 5799 : model1 loss : 0.442526 model2 loss : 0.044216
[10:51:21.906] iteration 5800 : model1 loss : 0.438853 model2 loss : 0.030002
[10:51:22.076] iteration 5801 : model1 loss : 0.438412 model2 loss : 0.029220
[10:51:22.250] iteration 5802 : model1 loss : 0.438743 model2 loss : 0.027075
[10:51:22.418] iteration 5803 : model1 loss : 0.439745 model2 loss : 0.030916
[10:51:22.592] iteration 5804 : model1 loss : 0.442718 model2 loss : 0.035055
[10:51:22.761] iteration 5805 : model1 loss : 0.435587 model2 loss : 0.025338
[10:51:22.938] iteration 5806 : model1 loss : 0.436084 model2 loss : 0.029411
[10:51:23.108] iteration 5807 : model1 loss : 0.434973 model2 loss : 0.027623
[10:51:23.279] iteration 5808 : model1 loss : 0.443737 model2 loss : 0.032431
[10:51:25.233] iteration 5809 : model1 loss : 0.438622 model2 loss : 0.030317
[10:51:25.401] iteration 5810 : model1 loss : 0.436059 model2 loss : 0.029818
[10:51:25.580] iteration 5811 : model1 loss : 0.435806 model2 loss : 0.040840
[10:51:25.749] iteration 5812 : model1 loss : 0.443869 model2 loss : 0.031588
[10:51:25.927] iteration 5813 : model1 loss : 0.440591 model2 loss : 0.034765
[10:51:26.097] iteration 5814 : model1 loss : 0.443524 model2 loss : 0.028578
[10:51:26.273] iteration 5815 : model1 loss : 0.436897 model2 loss : 0.029808
[10:51:26.442] iteration 5816 : model1 loss : 0.439439 model2 loss : 0.031365
[10:51:26.619] iteration 5817 : model1 loss : 0.441697 model2 loss : 0.035074
[10:51:26.786] iteration 5818 : model1 loss : 0.432342 model2 loss : 0.026589
[10:51:26.963] iteration 5819 : model1 loss : 0.438309 model2 loss : 0.029413
[10:51:27.132] iteration 5820 : model1 loss : 0.441982 model2 loss : 0.031795
[10:51:27.306] iteration 5821 : model1 loss : 0.432230 model2 loss : 0.028893
[10:51:27.476] iteration 5822 : model1 loss : 0.439741 model2 loss : 0.032704
[10:51:27.650] iteration 5823 : model1 loss : 0.438910 model2 loss : 0.032963
[10:51:27.817] iteration 5824 : model1 loss : 0.435537 model2 loss : 0.028060
[10:51:27.992] iteration 5825 : model1 loss : 0.439210 model2 loss : 0.038723
[10:51:28.162] iteration 5826 : model1 loss : 0.441992 model2 loss : 0.030901
[10:51:28.334] iteration 5827 : model1 loss : 0.435349 model2 loss : 0.029324
[10:51:28.507] iteration 5828 : model1 loss : 0.440300 model2 loss : 0.031179
[10:51:28.683] iteration 5829 : model1 loss : 0.435828 model2 loss : 0.032280
[10:51:28.851] iteration 5830 : model1 loss : 0.437876 model2 loss : 0.027864
[10:51:29.025] iteration 5831 : model1 loss : 0.437031 model2 loss : 0.029335
[10:51:29.193] iteration 5832 : model1 loss : 0.434534 model2 loss : 0.026141
[10:51:29.366] iteration 5833 : model1 loss : 0.436310 model2 loss : 0.026403
[10:51:29.540] iteration 5834 : model1 loss : 0.440129 model2 loss : 0.030096
[10:51:29.715] iteration 5835 : model1 loss : 0.439239 model2 loss : 0.033230
[10:51:29.885] iteration 5836 : model1 loss : 0.438494 model2 loss : 0.031179
[10:51:30.062] iteration 5837 : model1 loss : 0.434715 model2 loss : 0.029040
[10:51:30.230] iteration 5838 : model1 loss : 0.434544 model2 loss : 0.028067
[10:51:30.404] iteration 5839 : model1 loss : 0.439764 model2 loss : 0.034815
[10:51:30.575] iteration 5840 : model1 loss : 0.445735 model2 loss : 0.029742
[10:51:30.745] iteration 5841 : model1 loss : 0.440345 model2 loss : 0.035964
[10:51:32.751] iteration 5842 : model1 loss : 0.436452 model2 loss : 0.027639
[10:51:32.920] iteration 5843 : model1 loss : 0.437712 model2 loss : 0.027991
[10:51:33.096] iteration 5844 : model1 loss : 0.432536 model2 loss : 0.026062
[10:51:33.264] iteration 5845 : model1 loss : 0.441742 model2 loss : 0.035706
[10:51:33.437] iteration 5846 : model1 loss : 0.439178 model2 loss : 0.024559
[10:51:33.609] iteration 5847 : model1 loss : 0.438091 model2 loss : 0.027914
[10:51:33.782] iteration 5848 : model1 loss : 0.442504 model2 loss : 0.030038
[10:51:33.951] iteration 5849 : model1 loss : 0.435525 model2 loss : 0.028866
[10:51:34.123] iteration 5850 : model1 loss : 0.440916 model2 loss : 0.032550
[10:51:34.290] iteration 5851 : model1 loss : 0.442597 model2 loss : 0.036707
[10:51:34.466] iteration 5852 : model1 loss : 0.433507 model2 loss : 0.028710
[10:51:34.636] iteration 5853 : model1 loss : 0.435333 model2 loss : 0.029723
[10:51:34.812] iteration 5854 : model1 loss : 0.437217 model2 loss : 0.030099
[10:51:34.981] iteration 5855 : model1 loss : 0.433669 model2 loss : 0.032324
[10:51:35.154] iteration 5856 : model1 loss : 0.440208 model2 loss : 0.032141
[10:51:35.321] iteration 5857 : model1 loss : 0.441644 model2 loss : 0.034277
[10:51:35.496] iteration 5858 : model1 loss : 0.439747 model2 loss : 0.030572
[10:51:35.665] iteration 5859 : model1 loss : 0.436973 model2 loss : 0.025317
[10:51:35.841] iteration 5860 : model1 loss : 0.435269 model2 loss : 0.029317
[10:51:36.012] iteration 5861 : model1 loss : 0.438692 model2 loss : 0.026369
[10:51:36.186] iteration 5862 : model1 loss : 0.440804 model2 loss : 0.031258
[10:51:36.356] iteration 5863 : model1 loss : 0.439498 model2 loss : 0.027795
[10:51:36.533] iteration 5864 : model1 loss : 0.440466 model2 loss : 0.029066
[10:51:36.703] iteration 5865 : model1 loss : 0.438202 model2 loss : 0.029982
[10:51:36.880] iteration 5866 : model1 loss : 0.437539 model2 loss : 0.030848
[10:51:37.053] iteration 5867 : model1 loss : 0.437747 model2 loss : 0.027498
[10:51:37.226] iteration 5868 : model1 loss : 0.436129 model2 loss : 0.031536
[10:51:37.394] iteration 5869 : model1 loss : 0.434924 model2 loss : 0.027600
[10:51:37.569] iteration 5870 : model1 loss : 0.442213 model2 loss : 0.031670
[10:51:37.737] iteration 5871 : model1 loss : 0.439378 model2 loss : 0.034569
[10:51:37.912] iteration 5872 : model1 loss : 0.436588 model2 loss : 0.032112
[10:51:38.083] iteration 5873 : model1 loss : 0.438665 model2 loss : 0.032745
[10:51:38.252] iteration 5874 : model1 loss : 0.438095 model2 loss : 0.034227
[10:51:40.201] iteration 5875 : model1 loss : 0.440746 model2 loss : 0.029627
[10:51:40.373] iteration 5876 : model1 loss : 0.442225 model2 loss : 0.030791
[10:51:40.551] iteration 5877 : model1 loss : 0.437768 model2 loss : 0.029145
[10:51:40.719] iteration 5878 : model1 loss : 0.433854 model2 loss : 0.027148
[10:51:40.897] iteration 5879 : model1 loss : 0.436113 model2 loss : 0.027028
[10:51:41.068] iteration 5880 : model1 loss : 0.433549 model2 loss : 0.027265
[10:51:41.242] iteration 5881 : model1 loss : 0.434898 model2 loss : 0.027533
[10:51:41.412] iteration 5882 : model1 loss : 0.444144 model2 loss : 0.039450
[10:51:41.583] iteration 5883 : model1 loss : 0.438292 model2 loss : 0.030100
[10:51:41.751] iteration 5884 : model1 loss : 0.443201 model2 loss : 0.028547
[10:51:41.928] iteration 5885 : model1 loss : 0.437894 model2 loss : 0.028766
[10:51:42.098] iteration 5886 : model1 loss : 0.433928 model2 loss : 0.025237
[10:51:42.273] iteration 5887 : model1 loss : 0.433187 model2 loss : 0.025444
[10:51:42.444] iteration 5888 : model1 loss : 0.440274 model2 loss : 0.028946
[10:51:42.622] iteration 5889 : model1 loss : 0.435559 model2 loss : 0.029184
[10:51:42.789] iteration 5890 : model1 loss : 0.440829 model2 loss : 0.031257
[10:51:42.964] iteration 5891 : model1 loss : 0.436748 model2 loss : 0.033019
[10:51:43.135] iteration 5892 : model1 loss : 0.435380 model2 loss : 0.023750
[10:51:43.308] iteration 5893 : model1 loss : 0.434625 model2 loss : 0.026558
[10:51:43.476] iteration 5894 : model1 loss : 0.436781 model2 loss : 0.029364
[10:51:43.651] iteration 5895 : model1 loss : 0.437757 model2 loss : 0.033001
[10:51:43.819] iteration 5896 : model1 loss : 0.439211 model2 loss : 0.030580
[10:51:43.993] iteration 5897 : model1 loss : 0.439053 model2 loss : 0.031647
[10:51:44.162] iteration 5898 : model1 loss : 0.437968 model2 loss : 0.028807
[10:51:44.336] iteration 5899 : model1 loss : 0.441814 model2 loss : 0.029644
[10:51:44.509] iteration 5900 : model1 loss : 0.440790 model2 loss : 0.028186
[10:51:44.684] iteration 5901 : model1 loss : 0.443419 model2 loss : 0.034117
[10:51:44.851] iteration 5902 : model1 loss : 0.439291 model2 loss : 0.041990
[10:51:45.026] iteration 5903 : model1 loss : 0.436262 model2 loss : 0.031532
[10:51:45.196] iteration 5904 : model1 loss : 0.439190 model2 loss : 0.034524
[10:51:45.371] iteration 5905 : model1 loss : 0.439709 model2 loss : 0.029976
[10:51:45.542] iteration 5906 : model1 loss : 0.434584 model2 loss : 0.028055
[10:51:45.716] iteration 5907 : model1 loss : 0.436041 model2 loss : 0.031530
[10:51:47.720] iteration 5908 : model1 loss : 0.436568 model2 loss : 0.026658
[10:51:47.890] iteration 5909 : model1 loss : 0.438657 model2 loss : 0.040144
[10:51:48.066] iteration 5910 : model1 loss : 0.437572 model2 loss : 0.029612
[10:51:48.233] iteration 5911 : model1 loss : 0.438944 model2 loss : 0.024956
[10:51:48.410] iteration 5912 : model1 loss : 0.438285 model2 loss : 0.028424
[10:51:48.581] iteration 5913 : model1 loss : 0.439122 model2 loss : 0.028074
[10:51:48.754] iteration 5914 : model1 loss : 0.443211 model2 loss : 0.031552
[10:51:48.925] iteration 5915 : model1 loss : 0.439716 model2 loss : 0.027928
[10:51:49.100] iteration 5916 : model1 loss : 0.440403 model2 loss : 0.029562
[10:51:49.268] iteration 5917 : model1 loss : 0.437183 model2 loss : 0.027121
[10:51:49.440] iteration 5918 : model1 loss : 0.440837 model2 loss : 0.034030
[10:51:49.614] iteration 5919 : model1 loss : 0.438054 model2 loss : 0.035700
[10:51:49.787] iteration 5920 : model1 loss : 0.440310 model2 loss : 0.030871
[10:51:49.956] iteration 5921 : model1 loss : 0.434864 model2 loss : 0.025170
[10:51:50.130] iteration 5922 : model1 loss : 0.437463 model2 loss : 0.030604
[10:51:50.308] iteration 5923 : model1 loss : 0.441286 model2 loss : 0.031755
[10:51:50.486] iteration 5924 : model1 loss : 0.440084 model2 loss : 0.030607
[10:51:50.655] iteration 5925 : model1 loss : 0.436545 model2 loss : 0.030434
[10:51:50.830] iteration 5926 : model1 loss : 0.437171 model2 loss : 0.032179
[10:51:51.000] iteration 5927 : model1 loss : 0.434777 model2 loss : 0.026094
[10:51:51.177] iteration 5928 : model1 loss : 0.439111 model2 loss : 0.032088
[10:51:51.345] iteration 5929 : model1 loss : 0.437056 model2 loss : 0.030670
[10:51:51.521] iteration 5930 : model1 loss : 0.433553 model2 loss : 0.025866
[10:51:51.691] iteration 5931 : model1 loss : 0.434808 model2 loss : 0.029589
[10:51:51.865] iteration 5932 : model1 loss : 0.440306 model2 loss : 0.031111
[10:51:52.037] iteration 5933 : model1 loss : 0.440586 model2 loss : 0.031600
[10:51:52.213] iteration 5934 : model1 loss : 0.433635 model2 loss : 0.027181
[10:51:52.381] iteration 5935 : model1 loss : 0.439950 model2 loss : 0.029963
[10:51:52.558] iteration 5936 : model1 loss : 0.435762 model2 loss : 0.028015
[10:51:52.726] iteration 5937 : model1 loss : 0.439987 model2 loss : 0.030319
[10:51:52.901] iteration 5938 : model1 loss : 0.438113 model2 loss : 0.034029
[10:51:53.071] iteration 5939 : model1 loss : 0.441729 model2 loss : 0.036955
[10:51:53.244] iteration 5940 : model1 loss : 0.442487 model2 loss : 0.034714
[10:51:55.207] iteration 5941 : model1 loss : 0.439028 model2 loss : 0.027368
[10:51:55.377] iteration 5942 : model1 loss : 0.436686 model2 loss : 0.028812
[10:51:55.557] iteration 5943 : model1 loss : 0.439139 model2 loss : 0.033065
[10:51:55.726] iteration 5944 : model1 loss : 0.438270 model2 loss : 0.028909
[10:51:55.904] iteration 5945 : model1 loss : 0.435227 model2 loss : 0.029964
[10:51:56.076] iteration 5946 : model1 loss : 0.435513 model2 loss : 0.028788
[10:51:56.247] iteration 5947 : model1 loss : 0.439483 model2 loss : 0.026069
[10:51:56.416] iteration 5948 : model1 loss : 0.436660 model2 loss : 0.033634
[10:51:56.590] iteration 5949 : model1 loss : 0.431535 model2 loss : 0.026611
[10:51:56.758] iteration 5950 : model1 loss : 0.437082 model2 loss : 0.028250
[10:51:56.933] iteration 5951 : model1 loss : 0.438905 model2 loss : 0.028818
[10:51:57.104] iteration 5952 : model1 loss : 0.441858 model2 loss : 0.033940
[10:51:57.280] iteration 5953 : model1 loss : 0.440004 model2 loss : 0.028332
[10:51:57.448] iteration 5954 : model1 loss : 0.437104 model2 loss : 0.028241
[10:51:57.621] iteration 5955 : model1 loss : 0.437203 model2 loss : 0.029723
[10:51:57.791] iteration 5956 : model1 loss : 0.437590 model2 loss : 0.025616
[10:51:57.962] iteration 5957 : model1 loss : 0.443248 model2 loss : 0.028319
[10:51:58.133] iteration 5958 : model1 loss : 0.442070 model2 loss : 0.034197
[10:51:58.305] iteration 5959 : model1 loss : 0.438342 model2 loss : 0.030036
[10:51:58.474] iteration 5960 : model1 loss : 0.438218 model2 loss : 0.029686
[10:51:58.650] iteration 5961 : model1 loss : 0.439846 model2 loss : 0.030371
[10:51:58.818] iteration 5962 : model1 loss : 0.433246 model2 loss : 0.023504
[10:51:58.990] iteration 5963 : model1 loss : 0.438011 model2 loss : 0.029035
[10:51:59.161] iteration 5964 : model1 loss : 0.437499 model2 loss : 0.032060
[10:51:59.335] iteration 5965 : model1 loss : 0.436073 model2 loss : 0.027306
[10:51:59.508] iteration 5966 : model1 loss : 0.440162 model2 loss : 0.028688
[10:51:59.682] iteration 5967 : model1 loss : 0.438587 model2 loss : 0.031006
[10:51:59.852] iteration 5968 : model1 loss : 0.438242 model2 loss : 0.031929
[10:52:00.026] iteration 5969 : model1 loss : 0.437421 model2 loss : 0.025967
[10:52:00.199] iteration 5970 : model1 loss : 0.432999 model2 loss : 0.027600
[10:52:00.372] iteration 5971 : model1 loss : 0.441734 model2 loss : 0.037784
[10:52:00.542] iteration 5972 : model1 loss : 0.440279 model2 loss : 0.030309
[10:52:00.714] iteration 5973 : model1 loss : 0.442427 model2 loss : 0.036663
[10:52:02.761] iteration 5974 : model1 loss : 0.437920 model2 loss : 0.028653
[10:52:02.933] iteration 5975 : model1 loss : 0.437904 model2 loss : 0.032121
[10:52:03.107] iteration 5976 : model1 loss : 0.440336 model2 loss : 0.030885
[10:52:03.275] iteration 5977 : model1 loss : 0.436284 model2 loss : 0.029107
[10:52:03.448] iteration 5978 : model1 loss : 0.437661 model2 loss : 0.027014
[10:52:03.618] iteration 5979 : model1 loss : 0.434870 model2 loss : 0.027333
[10:52:03.791] iteration 5980 : model1 loss : 0.438575 model2 loss : 0.026305
[10:52:03.960] iteration 5981 : model1 loss : 0.440406 model2 loss : 0.030720
[10:52:04.134] iteration 5982 : model1 loss : 0.435421 model2 loss : 0.029059
[10:52:04.303] iteration 5983 : model1 loss : 0.437134 model2 loss : 0.029801
[10:52:04.478] iteration 5984 : model1 loss : 0.437885 model2 loss : 0.030146
[10:52:04.651] iteration 5985 : model1 loss : 0.437572 model2 loss : 0.026890
[10:52:04.825] iteration 5986 : model1 loss : 0.443578 model2 loss : 0.034205
[10:52:04.992] iteration 5987 : model1 loss : 0.436918 model2 loss : 0.029527
[10:52:05.170] iteration 5988 : model1 loss : 0.440460 model2 loss : 0.025427
[10:52:05.338] iteration 5989 : model1 loss : 0.435386 model2 loss : 0.027436
[10:52:05.516] iteration 5990 : model1 loss : 0.437088 model2 loss : 0.027812
[10:52:05.689] iteration 5991 : model1 loss : 0.437274 model2 loss : 0.025372
[10:52:05.865] iteration 5992 : model1 loss : 0.443164 model2 loss : 0.038369
[10:52:06.036] iteration 5993 : model1 loss : 0.438092 model2 loss : 0.030489
[10:52:06.212] iteration 5994 : model1 loss : 0.441337 model2 loss : 0.028191
[10:52:06.381] iteration 5995 : model1 loss : 0.438937 model2 loss : 0.027901
[10:52:06.557] iteration 5996 : model1 loss : 0.441023 model2 loss : 0.029601
[10:52:06.725] iteration 5997 : model1 loss : 0.436880 model2 loss : 0.029120
[10:52:06.900] iteration 5998 : model1 loss : 0.437467 model2 loss : 0.032285
[10:52:07.070] iteration 5999 : model1 loss : 0.441880 model2 loss : 0.030899
[10:52:07.245] iteration 6000 : model1 loss : 0.436579 model2 loss : 0.031625
[10:52:15.796] iteration 6000 : model1_mean_dice : 0.865500 model1_mean_hd95 : 5.266126
[10:52:24.263] iteration 6000 : model2_mean_dice : 0.876430 model2_mean_hd95 : 6.497795
[10:52:24.283] save model1 to ../model/ACDC/EVILv1_kl0.5_tau0.25_21_1337/unet\model1_iter_6000.pth
[10:52:24.302] save model2 to ../model/ACDC/EVILv1_kl0.5_tau0.25_21_1337/unet\model2_iter_6000.pth
[10:52:24.480] iteration 6001 : model1 loss : 0.436365 model2 loss : 0.026775
[10:52:24.660] iteration 6002 : model1 loss : 0.439005 model2 loss : 0.032886
[10:52:24.832] iteration 6003 : model1 loss : 0.433596 model2 loss : 0.025614
[10:52:24.999] iteration 6004 : model1 loss : 0.436327 model2 loss : 0.027524
[10:52:25.174] iteration 6005 : model1 loss : 0.443140 model2 loss : 0.027323
[10:52:25.339] iteration 6006 : model1 loss : 0.437292 model2 loss : 0.027345
[10:52:27.326] iteration 6007 : model1 loss : 0.439495 model2 loss : 0.030659
[10:52:27.500] iteration 6008 : model1 loss : 0.440166 model2 loss : 0.027175
[10:52:27.677] iteration 6009 : model1 loss : 0.437993 model2 loss : 0.032837
[10:52:27.846] iteration 6010 : model1 loss : 0.438160 model2 loss : 0.030641
[10:52:28.017] iteration 6011 : model1 loss : 0.437960 model2 loss : 0.028535
[10:52:28.187] iteration 6012 : model1 loss : 0.435140 model2 loss : 0.033760
[10:52:28.360] iteration 6013 : model1 loss : 0.440453 model2 loss : 0.034270
[10:52:28.528] iteration 6014 : model1 loss : 0.437772 model2 loss : 0.031798
[10:52:28.705] iteration 6015 : model1 loss : 0.437986 model2 loss : 0.028572
[10:52:28.872] iteration 6016 : model1 loss : 0.434713 model2 loss : 0.027234
[10:52:29.045] iteration 6017 : model1 loss : 0.436691 model2 loss : 0.028082
[10:52:29.215] iteration 6018 : model1 loss : 0.437777 model2 loss : 0.033008
[10:52:29.389] iteration 6019 : model1 loss : 0.437785 model2 loss : 0.028789
[10:52:29.559] iteration 6020 : model1 loss : 0.436779 model2 loss : 0.029295
[10:52:29.731] iteration 6021 : model1 loss : 0.439057 model2 loss : 0.028523
[10:52:29.902] iteration 6022 : model1 loss : 0.437754 model2 loss : 0.031817
[10:52:30.077] iteration 6023 : model1 loss : 0.437557 model2 loss : 0.034374
[10:52:30.246] iteration 6024 : model1 loss : 0.435962 model2 loss : 0.027023
[10:52:30.419] iteration 6025 : model1 loss : 0.436484 model2 loss : 0.027767
[10:52:30.589] iteration 6026 : model1 loss : 0.436343 model2 loss : 0.030328
[10:52:30.763] iteration 6027 : model1 loss : 0.435606 model2 loss : 0.029996
[10:52:30.932] iteration 6028 : model1 loss : 0.437228 model2 loss : 0.031645
[10:52:31.107] iteration 6029 : model1 loss : 0.441987 model2 loss : 0.032496
[10:52:31.274] iteration 6030 : model1 loss : 0.440817 model2 loss : 0.032754
[10:52:31.449] iteration 6031 : model1 loss : 0.439940 model2 loss : 0.032714
[10:52:31.620] iteration 6032 : model1 loss : 0.435932 model2 loss : 0.027072
[10:52:31.792] iteration 6033 : model1 loss : 0.440132 model2 loss : 0.033142
[10:52:31.960] iteration 6034 : model1 loss : 0.441133 model2 loss : 0.032762
[10:52:32.133] iteration 6035 : model1 loss : 0.446024 model2 loss : 0.036574
[10:52:32.301] iteration 6036 : model1 loss : 0.437883 model2 loss : 0.029230
[10:52:32.472] iteration 6037 : model1 loss : 0.438558 model2 loss : 0.028365
[10:52:32.641] iteration 6038 : model1 loss : 0.437541 model2 loss : 0.036846
[10:52:32.811] iteration 6039 : model1 loss : 0.440699 model2 loss : 0.027817
[10:52:34.787] iteration 6040 : model1 loss : 0.438063 model2 loss : 0.032058
[10:52:34.958] iteration 6041 : model1 loss : 0.438231 model2 loss : 0.025566
[10:52:35.133] iteration 6042 : model1 loss : 0.437939 model2 loss : 0.031417
[10:52:35.300] iteration 6043 : model1 loss : 0.435231 model2 loss : 0.026871
[10:52:35.471] iteration 6044 : model1 loss : 0.435446 model2 loss : 0.030913
[10:52:35.641] iteration 6045 : model1 loss : 0.436743 model2 loss : 0.029954
[10:52:35.818] iteration 6046 : model1 loss : 0.438309 model2 loss : 0.036137
[10:52:35.986] iteration 6047 : model1 loss : 0.437092 model2 loss : 0.029924
[10:52:36.158] iteration 6048 : model1 loss : 0.436334 model2 loss : 0.029112
[10:52:36.326] iteration 6049 : model1 loss : 0.432259 model2 loss : 0.026494
[10:52:36.501] iteration 6050 : model1 loss : 0.440174 model2 loss : 0.026690
[10:52:36.671] iteration 6051 : model1 loss : 0.437881 model2 loss : 0.028768
[10:52:36.843] iteration 6052 : model1 loss : 0.438885 model2 loss : 0.028161
[10:52:37.011] iteration 6053 : model1 loss : 0.445856 model2 loss : 0.038594
[10:52:37.187] iteration 6054 : model1 loss : 0.440407 model2 loss : 0.028925
[10:52:37.354] iteration 6055 : model1 loss : 0.445009 model2 loss : 0.045650
[10:52:37.530] iteration 6056 : model1 loss : 0.434677 model2 loss : 0.031773
[10:52:37.699] iteration 6057 : model1 loss : 0.440611 model2 loss : 0.033214
[10:52:37.871] iteration 6058 : model1 loss : 0.437430 model2 loss : 0.031419
[10:52:38.037] iteration 6059 : model1 loss : 0.436578 model2 loss : 0.041590
[10:52:38.213] iteration 6060 : model1 loss : 0.433317 model2 loss : 0.026659
[10:52:38.379] iteration 6061 : model1 loss : 0.440543 model2 loss : 0.037168
[10:52:38.552] iteration 6062 : model1 loss : 0.441466 model2 loss : 0.030993
[10:52:38.721] iteration 6063 : model1 loss : 0.438383 model2 loss : 0.024642
[10:52:38.894] iteration 6064 : model1 loss : 0.438927 model2 loss : 0.030812
[10:52:39.064] iteration 6065 : model1 loss : 0.433821 model2 loss : 0.028709
[10:52:39.237] iteration 6066 : model1 loss : 0.434952 model2 loss : 0.033892
[10:52:39.405] iteration 6067 : model1 loss : 0.440358 model2 loss : 0.032503
[10:52:39.581] iteration 6068 : model1 loss : 0.436464 model2 loss : 0.028206
[10:52:39.750] iteration 6069 : model1 loss : 0.442805 model2 loss : 0.037177
[10:52:39.923] iteration 6070 : model1 loss : 0.439898 model2 loss : 0.033245
[10:52:40.091] iteration 6071 : model1 loss : 0.441229 model2 loss : 0.032625
[10:52:40.262] iteration 6072 : model1 loss : 0.438941 model2 loss : 0.035087
[10:52:42.264] iteration 6073 : model1 loss : 0.438241 model2 loss : 0.029640
[10:52:42.433] iteration 6074 : model1 loss : 0.437305 model2 loss : 0.026791
[10:52:42.610] iteration 6075 : model1 loss : 0.439870 model2 loss : 0.030887
[10:52:42.780] iteration 6076 : model1 loss : 0.443470 model2 loss : 0.032076
[10:52:42.952] iteration 6077 : model1 loss : 0.441389 model2 loss : 0.031887
[10:52:43.121] iteration 6078 : model1 loss : 0.436760 model2 loss : 0.032709
[10:52:43.293] iteration 6079 : model1 loss : 0.443037 model2 loss : 0.030364
[10:52:43.460] iteration 6080 : model1 loss : 0.437888 model2 loss : 0.026700
[10:52:43.636] iteration 6081 : model1 loss : 0.436187 model2 loss : 0.031037
[10:52:43.803] iteration 6082 : model1 loss : 0.437308 model2 loss : 0.024586
[10:52:43.978] iteration 6083 : model1 loss : 0.438471 model2 loss : 0.032400
[10:52:44.148] iteration 6084 : model1 loss : 0.441475 model2 loss : 0.033078
[10:52:44.322] iteration 6085 : model1 loss : 0.440596 model2 loss : 0.032644
[10:52:44.490] iteration 6086 : model1 loss : 0.439341 model2 loss : 0.032451
[10:52:44.665] iteration 6087 : model1 loss : 0.434884 model2 loss : 0.025152
[10:52:44.831] iteration 6088 : model1 loss : 0.441791 model2 loss : 0.034932
[10:52:45.003] iteration 6089 : model1 loss : 0.437819 model2 loss : 0.031283
[10:52:45.173] iteration 6090 : model1 loss : 0.437141 model2 loss : 0.028876
[10:52:45.346] iteration 6091 : model1 loss : 0.435237 model2 loss : 0.026611
[10:52:45.519] iteration 6092 : model1 loss : 0.436235 model2 loss : 0.027797
[10:52:45.692] iteration 6093 : model1 loss : 0.436202 model2 loss : 0.027959
[10:52:45.862] iteration 6094 : model1 loss : 0.435183 model2 loss : 0.025911
[10:52:46.034] iteration 6095 : model1 loss : 0.436611 model2 loss : 0.030253
[10:52:46.205] iteration 6096 : model1 loss : 0.434051 model2 loss : 0.027219
[10:52:46.376] iteration 6097 : model1 loss : 0.444368 model2 loss : 0.030697
[10:52:46.544] iteration 6098 : model1 loss : 0.439421 model2 loss : 0.030219
[10:52:46.716] iteration 6099 : model1 loss : 0.437293 model2 loss : 0.027647
[10:52:46.883] iteration 6100 : model1 loss : 0.443031 model2 loss : 0.041494
[10:52:47.056] iteration 6101 : model1 loss : 0.439321 model2 loss : 0.033766
[10:52:47.226] iteration 6102 : model1 loss : 0.439633 model2 loss : 0.030035
[10:52:47.399] iteration 6103 : model1 loss : 0.439041 model2 loss : 0.032621
[10:52:47.566] iteration 6104 : model1 loss : 0.441990 model2 loss : 0.032473
[10:52:47.737] iteration 6105 : model1 loss : 0.437004 model2 loss : 0.029570
[10:52:49.740] iteration 6106 : model1 loss : 0.438575 model2 loss : 0.033674
[10:52:49.911] iteration 6107 : model1 loss : 0.438692 model2 loss : 0.030246
[10:52:50.087] iteration 6108 : model1 loss : 0.435113 model2 loss : 0.028941
[10:52:50.256] iteration 6109 : model1 loss : 0.439544 model2 loss : 0.032929
[10:52:50.429] iteration 6110 : model1 loss : 0.436317 model2 loss : 0.028025
[10:52:50.600] iteration 6111 : model1 loss : 0.433354 model2 loss : 0.028960
[10:52:50.775] iteration 6112 : model1 loss : 0.439917 model2 loss : 0.026828
[10:52:50.943] iteration 6113 : model1 loss : 0.437123 model2 loss : 0.028767
[10:52:51.117] iteration 6114 : model1 loss : 0.438857 model2 loss : 0.035204
[10:52:51.283] iteration 6115 : model1 loss : 0.438232 model2 loss : 0.027940
[10:52:51.454] iteration 6116 : model1 loss : 0.436381 model2 loss : 0.029686
[10:52:51.628] iteration 6117 : model1 loss : 0.438852 model2 loss : 0.030764
[10:52:51.798] iteration 6118 : model1 loss : 0.442526 model2 loss : 0.040361
[10:52:51.965] iteration 6119 : model1 loss : 0.434676 model2 loss : 0.026850
[10:52:52.138] iteration 6120 : model1 loss : 0.434279 model2 loss : 0.028952
[10:52:52.306] iteration 6121 : model1 loss : 0.436220 model2 loss : 0.029628
[10:52:52.477] iteration 6122 : model1 loss : 0.439724 model2 loss : 0.029435
[10:52:52.647] iteration 6123 : model1 loss : 0.438918 model2 loss : 0.030358
[10:52:52.819] iteration 6124 : model1 loss : 0.438496 model2 loss : 0.030842
[10:52:52.986] iteration 6125 : model1 loss : 0.437077 model2 loss : 0.026983
[10:52:53.159] iteration 6126 : model1 loss : 0.433946 model2 loss : 0.036290
[10:52:53.327] iteration 6127 : model1 loss : 0.439330 model2 loss : 0.032664
[10:52:53.499] iteration 6128 : model1 loss : 0.437448 model2 loss : 0.029257
[10:52:53.670] iteration 6129 : model1 loss : 0.442115 model2 loss : 0.034323
[10:52:53.842] iteration 6130 : model1 loss : 0.437059 model2 loss : 0.029300
[10:52:54.009] iteration 6131 : model1 loss : 0.438771 model2 loss : 0.031329
[10:52:54.180] iteration 6132 : model1 loss : 0.445713 model2 loss : 0.040662
[10:52:54.348] iteration 6133 : model1 loss : 0.436733 model2 loss : 0.026981
[10:52:54.526] iteration 6134 : model1 loss : 0.437990 model2 loss : 0.029037
[10:52:54.696] iteration 6135 : model1 loss : 0.443185 model2 loss : 0.035023
[10:52:54.869] iteration 6136 : model1 loss : 0.437321 model2 loss : 0.031400
[10:52:55.035] iteration 6137 : model1 loss : 0.439970 model2 loss : 0.032310
[10:52:55.208] iteration 6138 : model1 loss : 0.435378 model2 loss : 0.027885
[10:52:57.191] iteration 6139 : model1 loss : 0.436866 model2 loss : 0.037352
[10:52:57.359] iteration 6140 : model1 loss : 0.435051 model2 loss : 0.032067
[10:52:57.536] iteration 6141 : model1 loss : 0.443303 model2 loss : 0.033072
[10:52:57.707] iteration 6142 : model1 loss : 0.443500 model2 loss : 0.032156
[10:52:57.879] iteration 6143 : model1 loss : 0.439501 model2 loss : 0.031811
[10:52:58.046] iteration 6144 : model1 loss : 0.438208 model2 loss : 0.033391
[10:52:58.220] iteration 6145 : model1 loss : 0.442973 model2 loss : 0.034169
[10:52:58.388] iteration 6146 : model1 loss : 0.439066 model2 loss : 0.029241
[10:52:58.558] iteration 6147 : model1 loss : 0.437610 model2 loss : 0.033632
[10:52:58.730] iteration 6148 : model1 loss : 0.434793 model2 loss : 0.033450
[10:52:58.906] iteration 6149 : model1 loss : 0.437631 model2 loss : 0.027411
[10:52:59.076] iteration 6150 : model1 loss : 0.440370 model2 loss : 0.030130
[10:52:59.249] iteration 6151 : model1 loss : 0.438991 model2 loss : 0.034416
[10:52:59.418] iteration 6152 : model1 loss : 0.440763 model2 loss : 0.029090
[10:52:59.594] iteration 6153 : model1 loss : 0.433758 model2 loss : 0.027901
[10:52:59.763] iteration 6154 : model1 loss : 0.441024 model2 loss : 0.030703
[10:52:59.938] iteration 6155 : model1 loss : 0.439054 model2 loss : 0.031397
[10:53:00.111] iteration 6156 : model1 loss : 0.434954 model2 loss : 0.026913
[10:53:00.285] iteration 6157 : model1 loss : 0.434175 model2 loss : 0.026042
[10:53:00.453] iteration 6158 : model1 loss : 0.440038 model2 loss : 0.033174
[10:53:00.628] iteration 6159 : model1 loss : 0.441284 model2 loss : 0.030998
[10:53:00.799] iteration 6160 : model1 loss : 0.437502 model2 loss : 0.028888
[10:53:00.969] iteration 6161 : model1 loss : 0.435952 model2 loss : 0.034539
[10:53:01.141] iteration 6162 : model1 loss : 0.439535 model2 loss : 0.039828
[10:53:01.313] iteration 6163 : model1 loss : 0.439051 model2 loss : 0.029447
[10:53:01.480] iteration 6164 : model1 loss : 0.439745 model2 loss : 0.028968
[10:53:01.656] iteration 6165 : model1 loss : 0.440332 model2 loss : 0.030423
[10:53:01.824] iteration 6166 : model1 loss : 0.437895 model2 loss : 0.027881
[10:53:01.996] iteration 6167 : model1 loss : 0.434648 model2 loss : 0.023645
[10:53:02.166] iteration 6168 : model1 loss : 0.437978 model2 loss : 0.027015
[10:53:02.341] iteration 6169 : model1 loss : 0.433395 model2 loss : 0.027421
[10:53:02.511] iteration 6170 : model1 loss : 0.437145 model2 loss : 0.029495
[10:53:02.682] iteration 6171 : model1 loss : 0.440537 model2 loss : 0.031556
[10:53:04.691] iteration 6172 : model1 loss : 0.433461 model2 loss : 0.027136
[10:53:04.859] iteration 6173 : model1 loss : 0.439027 model2 loss : 0.027961
[10:53:05.031] iteration 6174 : model1 loss : 0.442264 model2 loss : 0.035480
[10:53:05.203] iteration 6175 : model1 loss : 0.441645 model2 loss : 0.031670
[10:53:05.375] iteration 6176 : model1 loss : 0.439649 model2 loss : 0.026001
[10:53:05.546] iteration 6177 : model1 loss : 0.437269 model2 loss : 0.025145
[10:53:05.718] iteration 6178 : model1 loss : 0.437865 model2 loss : 0.029371
[10:53:05.891] iteration 6179 : model1 loss : 0.439016 model2 loss : 0.026383
[10:53:06.065] iteration 6180 : model1 loss : 0.437860 model2 loss : 0.030462
[10:53:06.236] iteration 6181 : model1 loss : 0.440781 model2 loss : 0.029318
[10:53:06.410] iteration 6182 : model1 loss : 0.437321 model2 loss : 0.027984
[10:53:06.580] iteration 6183 : model1 loss : 0.439186 model2 loss : 0.033030
[10:53:06.753] iteration 6184 : model1 loss : 0.444818 model2 loss : 0.035350
[10:53:06.922] iteration 6185 : model1 loss : 0.435126 model2 loss : 0.028381
[10:53:07.098] iteration 6186 : model1 loss : 0.443253 model2 loss : 0.032602
[10:53:07.268] iteration 6187 : model1 loss : 0.437838 model2 loss : 0.027755
[10:53:07.441] iteration 6188 : model1 loss : 0.438311 model2 loss : 0.033099
[10:53:07.614] iteration 6189 : model1 loss : 0.435318 model2 loss : 0.030084
[10:53:07.788] iteration 6190 : model1 loss : 0.439337 model2 loss : 0.031245
[10:53:07.958] iteration 6191 : model1 loss : 0.437929 model2 loss : 0.036289
[10:53:08.134] iteration 6192 : model1 loss : 0.435203 model2 loss : 0.028492
[10:53:08.302] iteration 6193 : model1 loss : 0.440792 model2 loss : 0.029427
[10:53:08.473] iteration 6194 : model1 loss : 0.437255 model2 loss : 0.027090
[10:53:08.644] iteration 6195 : model1 loss : 0.437448 model2 loss : 0.030831
[10:53:08.815] iteration 6196 : model1 loss : 0.435750 model2 loss : 0.028285
[10:53:08.983] iteration 6197 : model1 loss : 0.436382 model2 loss : 0.031110
[10:53:09.158] iteration 6198 : model1 loss : 0.439227 model2 loss : 0.027094
[10:53:09.327] iteration 6199 : model1 loss : 0.438254 model2 loss : 0.030010
[10:53:09.504] iteration 6200 : model1 loss : 0.442364 model2 loss : 0.038024
[10:53:09.675] iteration 6201 : model1 loss : 0.438175 model2 loss : 0.031070
[10:53:09.847] iteration 6202 : model1 loss : 0.435941 model2 loss : 0.028608
[10:53:10.026] iteration 6203 : model1 loss : 0.440183 model2 loss : 0.029029
[10:53:10.199] iteration 6204 : model1 loss : 0.434811 model2 loss : 0.029095
[10:53:12.197] iteration 6205 : model1 loss : 0.440683 model2 loss : 0.032431
[10:53:12.369] iteration 6206 : model1 loss : 0.439731 model2 loss : 0.026448
[10:53:12.546] iteration 6207 : model1 loss : 0.441692 model2 loss : 0.032880
[10:53:12.716] iteration 6208 : model1 loss : 0.441028 model2 loss : 0.026053
[10:53:12.888] iteration 6209 : model1 loss : 0.438949 model2 loss : 0.028715
[10:53:13.055] iteration 6210 : model1 loss : 0.438343 model2 loss : 0.031553
[10:53:13.228] iteration 6211 : model1 loss : 0.440542 model2 loss : 0.033798
[10:53:13.396] iteration 6212 : model1 loss : 0.437919 model2 loss : 0.028755
[10:53:13.571] iteration 6213 : model1 loss : 0.439253 model2 loss : 0.033163
[10:53:13.740] iteration 6214 : model1 loss : 0.435633 model2 loss : 0.028022
[10:53:13.915] iteration 6215 : model1 loss : 0.442418 model2 loss : 0.035105
[10:53:14.084] iteration 6216 : model1 loss : 0.436528 model2 loss : 0.025231
[10:53:14.266] iteration 6217 : model1 loss : 0.435805 model2 loss : 0.028451
[10:53:14.434] iteration 6218 : model1 loss : 0.443676 model2 loss : 0.042927
[10:53:14.609] iteration 6219 : model1 loss : 0.439404 model2 loss : 0.027270
[10:53:14.779] iteration 6220 : model1 loss : 0.441275 model2 loss : 0.029969
[10:53:14.951] iteration 6221 : model1 loss : 0.435853 model2 loss : 0.029276
[10:53:15.122] iteration 6222 : model1 loss : 0.435282 model2 loss : 0.029041
[10:53:15.297] iteration 6223 : model1 loss : 0.436952 model2 loss : 0.025629
[10:53:15.465] iteration 6224 : model1 loss : 0.439979 model2 loss : 0.032940
[10:53:15.641] iteration 6225 : model1 loss : 0.431133 model2 loss : 0.026714
[10:53:15.811] iteration 6226 : model1 loss : 0.440281 model2 loss : 0.031550
[10:53:15.984] iteration 6227 : model1 loss : 0.436981 model2 loss : 0.030981
[10:53:16.154] iteration 6228 : model1 loss : 0.440940 model2 loss : 0.037257
[10:53:16.327] iteration 6229 : model1 loss : 0.436760 model2 loss : 0.028562
[10:53:16.497] iteration 6230 : model1 loss : 0.433178 model2 loss : 0.026538
[10:53:16.674] iteration 6231 : model1 loss : 0.437615 model2 loss : 0.031910
[10:53:16.842] iteration 6232 : model1 loss : 0.442131 model2 loss : 0.033782
[10:53:17.012] iteration 6233 : model1 loss : 0.432438 model2 loss : 0.023221
[10:53:17.184] iteration 6234 : model1 loss : 0.434953 model2 loss : 0.026460
[10:53:17.356] iteration 6235 : model1 loss : 0.436575 model2 loss : 0.032470
[10:53:17.526] iteration 6236 : model1 loss : 0.438305 model2 loss : 0.028222
[10:53:17.698] iteration 6237 : model1 loss : 0.438458 model2 loss : 0.026261
[10:53:19.708] iteration 6238 : model1 loss : 0.441467 model2 loss : 0.031347
[10:53:19.879] iteration 6239 : model1 loss : 0.442534 model2 loss : 0.036839
[10:53:20.051] iteration 6240 : model1 loss : 0.436632 model2 loss : 0.030092
[10:53:20.223] iteration 6241 : model1 loss : 0.442236 model2 loss : 0.033026
[10:53:20.395] iteration 6242 : model1 loss : 0.440451 model2 loss : 0.034490
[10:53:20.564] iteration 6243 : model1 loss : 0.435864 model2 loss : 0.027602
[10:53:20.741] iteration 6244 : model1 loss : 0.441205 model2 loss : 0.031178
[10:53:20.910] iteration 6245 : model1 loss : 0.437738 model2 loss : 0.029445
[10:53:21.082] iteration 6246 : model1 loss : 0.436595 model2 loss : 0.033399
[10:53:21.252] iteration 6247 : model1 loss : 0.440169 model2 loss : 0.038062
[10:53:21.426] iteration 6248 : model1 loss : 0.439407 model2 loss : 0.027831
[10:53:21.595] iteration 6249 : model1 loss : 0.441998 model2 loss : 0.034295
[10:53:21.769] iteration 6250 : model1 loss : 0.440242 model2 loss : 0.029238
[10:53:21.940] iteration 6251 : model1 loss : 0.438513 model2 loss : 0.029291
[10:53:22.133] iteration 6252 : model1 loss : 0.436182 model2 loss : 0.027856
[10:53:22.301] iteration 6253 : model1 loss : 0.437397 model2 loss : 0.035700
[10:53:22.473] iteration 6254 : model1 loss : 0.436268 model2 loss : 0.027471
[10:53:22.646] iteration 6255 : model1 loss : 0.436438 model2 loss : 0.025589
[10:53:22.818] iteration 6256 : model1 loss : 0.438849 model2 loss : 0.027844
[10:53:22.986] iteration 6257 : model1 loss : 0.443388 model2 loss : 0.034881
[10:53:23.162] iteration 6258 : model1 loss : 0.439236 model2 loss : 0.027567
[10:53:23.330] iteration 6259 : model1 loss : 0.432929 model2 loss : 0.028205
[10:53:23.507] iteration 6260 : model1 loss : 0.433856 model2 loss : 0.029556
[10:53:23.677] iteration 6261 : model1 loss : 0.437855 model2 loss : 0.029538
[10:53:23.849] iteration 6262 : model1 loss : 0.441089 model2 loss : 0.027801
[10:53:24.017] iteration 6263 : model1 loss : 0.436445 model2 loss : 0.029079
[10:53:24.190] iteration 6264 : model1 loss : 0.436947 model2 loss : 0.028539
[10:53:24.359] iteration 6265 : model1 loss : 0.437684 model2 loss : 0.028979
[10:53:24.538] iteration 6266 : model1 loss : 0.442695 model2 loss : 0.030866
[10:53:24.709] iteration 6267 : model1 loss : 0.438480 model2 loss : 0.027834
[10:53:24.884] iteration 6268 : model1 loss : 0.432112 model2 loss : 0.024924
[10:53:25.050] iteration 6269 : model1 loss : 0.440991 model2 loss : 0.029649
[10:53:25.222] iteration 6270 : model1 loss : 0.436668 model2 loss : 0.027488
[10:53:27.203] iteration 6271 : model1 loss : 0.432921 model2 loss : 0.031745
[10:53:27.372] iteration 6272 : model1 loss : 0.442523 model2 loss : 0.034085
[10:53:27.548] iteration 6273 : model1 loss : 0.437966 model2 loss : 0.028175
[10:53:27.720] iteration 6274 : model1 loss : 0.440546 model2 loss : 0.031330
[10:53:27.893] iteration 6275 : model1 loss : 0.442597 model2 loss : 0.030749
[10:53:28.078] iteration 6276 : model1 loss : 0.441606 model2 loss : 0.032257
[10:53:28.252] iteration 6277 : model1 loss : 0.437924 model2 loss : 0.030669
[10:53:28.420] iteration 6278 : model1 loss : 0.438602 model2 loss : 0.028435
[10:53:28.594] iteration 6279 : model1 loss : 0.439648 model2 loss : 0.030416
[10:53:28.765] iteration 6280 : model1 loss : 0.437103 model2 loss : 0.030868
[10:53:28.939] iteration 6281 : model1 loss : 0.437483 model2 loss : 0.026910
[10:53:29.109] iteration 6282 : model1 loss : 0.433924 model2 loss : 0.025809
[10:53:29.283] iteration 6283 : model1 loss : 0.441006 model2 loss : 0.032119
[10:53:29.451] iteration 6284 : model1 loss : 0.437078 model2 loss : 0.027866
[10:53:29.627] iteration 6285 : model1 loss : 0.433621 model2 loss : 0.029284
[10:53:29.797] iteration 6286 : model1 loss : 0.441605 model2 loss : 0.030026
[10:53:29.972] iteration 6287 : model1 loss : 0.441040 model2 loss : 0.028786
[10:53:30.144] iteration 6288 : model1 loss : 0.441125 model2 loss : 0.035026
[10:53:30.319] iteration 6289 : model1 loss : 0.440190 model2 loss : 0.031582
[10:53:30.487] iteration 6290 : model1 loss : 0.438076 model2 loss : 0.027116
[10:53:30.662] iteration 6291 : model1 loss : 0.440919 model2 loss : 0.027605
[10:53:30.833] iteration 6292 : model1 loss : 0.437195 model2 loss : 0.028608
[10:53:31.005] iteration 6293 : model1 loss : 0.435097 model2 loss : 0.027478
[10:53:31.175] iteration 6294 : model1 loss : 0.439977 model2 loss : 0.029260
[10:53:31.348] iteration 6295 : model1 loss : 0.437021 model2 loss : 0.033153
[10:53:31.521] iteration 6296 : model1 loss : 0.435013 model2 loss : 0.027270
[10:53:31.695] iteration 6297 : model1 loss : 0.438829 model2 loss : 0.030322
[10:53:31.864] iteration 6298 : model1 loss : 0.435402 model2 loss : 0.027197
[10:53:32.036] iteration 6299 : model1 loss : 0.433180 model2 loss : 0.028215
[10:53:32.205] iteration 6300 : model1 loss : 0.436893 model2 loss : 0.029379
[10:53:32.380] iteration 6301 : model1 loss : 0.440199 model2 loss : 0.031317
[10:53:32.548] iteration 6302 : model1 loss : 0.443008 model2 loss : 0.031098
[10:53:32.719] iteration 6303 : model1 loss : 0.441594 model2 loss : 0.035316
[10:53:34.718] iteration 6304 : model1 loss : 0.439478 model2 loss : 0.032457
[10:53:34.892] iteration 6305 : model1 loss : 0.440303 model2 loss : 0.030012
[10:53:35.066] iteration 6306 : model1 loss : 0.435743 model2 loss : 0.030304
[10:53:35.238] iteration 6307 : model1 loss : 0.435453 model2 loss : 0.030723
[10:53:35.413] iteration 6308 : model1 loss : 0.441893 model2 loss : 0.046052
[10:53:35.582] iteration 6309 : model1 loss : 0.436674 model2 loss : 0.027111
[10:53:35.758] iteration 6310 : model1 loss : 0.437765 model2 loss : 0.029554
[10:53:35.929] iteration 6311 : model1 loss : 0.436538 model2 loss : 0.031567
[10:53:36.105] iteration 6312 : model1 loss : 0.439066 model2 loss : 0.028372
[10:53:36.276] iteration 6313 : model1 loss : 0.437696 model2 loss : 0.032434
[10:53:36.450] iteration 6314 : model1 loss : 0.436368 model2 loss : 0.027757
[10:53:36.624] iteration 6315 : model1 loss : 0.441899 model2 loss : 0.032242
[10:53:36.797] iteration 6316 : model1 loss : 0.435200 model2 loss : 0.028124
[10:53:36.965] iteration 6317 : model1 loss : 0.433112 model2 loss : 0.026400
[10:53:37.141] iteration 6318 : model1 loss : 0.438829 model2 loss : 0.030141
[10:53:37.310] iteration 6319 : model1 loss : 0.439511 model2 loss : 0.031894
[10:53:37.482] iteration 6320 : model1 loss : 0.439297 model2 loss : 0.025869
[10:53:37.653] iteration 6321 : model1 loss : 0.435812 model2 loss : 0.028808
[10:53:37.827] iteration 6322 : model1 loss : 0.443702 model2 loss : 0.036380
[10:53:37.996] iteration 6323 : model1 loss : 0.439981 model2 loss : 0.027427
[10:53:38.169] iteration 6324 : model1 loss : 0.437790 model2 loss : 0.027610
[10:53:38.340] iteration 6325 : model1 loss : 0.437403 model2 loss : 0.025500
[10:53:38.516] iteration 6326 : model1 loss : 0.435818 model2 loss : 0.028025
[10:53:38.688] iteration 6327 : model1 loss : 0.437468 model2 loss : 0.029708
[10:53:38.862] iteration 6328 : model1 loss : 0.434631 model2 loss : 0.030047
[10:53:39.029] iteration 6329 : model1 loss : 0.439295 model2 loss : 0.029084
[10:53:39.205] iteration 6330 : model1 loss : 0.444772 model2 loss : 0.033017
[10:53:39.373] iteration 6331 : model1 loss : 0.433902 model2 loss : 0.024115
[10:53:39.548] iteration 6332 : model1 loss : 0.441969 model2 loss : 0.032357
[10:53:39.719] iteration 6333 : model1 loss : 0.441590 model2 loss : 0.033599
[10:53:39.896] iteration 6334 : model1 loss : 0.436829 model2 loss : 0.026286
[10:53:40.063] iteration 6335 : model1 loss : 0.435351 model2 loss : 0.031172
[10:53:40.234] iteration 6336 : model1 loss : 0.434286 model2 loss : 0.023606
[10:53:42.204] iteration 6337 : model1 loss : 0.436918 model2 loss : 0.028056
[10:53:42.376] iteration 6338 : model1 loss : 0.437363 model2 loss : 0.026998
[10:53:42.554] iteration 6339 : model1 loss : 0.436751 model2 loss : 0.027772
[10:53:42.725] iteration 6340 : model1 loss : 0.433191 model2 loss : 0.025928
[10:53:42.901] iteration 6341 : model1 loss : 0.437256 model2 loss : 0.027216
[10:53:43.069] iteration 6342 : model1 loss : 0.436878 model2 loss : 0.028004
[10:53:43.243] iteration 6343 : model1 loss : 0.437280 model2 loss : 0.029457
[10:53:43.411] iteration 6344 : model1 loss : 0.441438 model2 loss : 0.028537
[10:53:43.583] iteration 6345 : model1 loss : 0.435070 model2 loss : 0.027674
[10:53:43.754] iteration 6346 : model1 loss : 0.435566 model2 loss : 0.032021
[10:53:43.930] iteration 6347 : model1 loss : 0.440991 model2 loss : 0.030853
[10:53:44.098] iteration 6348 : model1 loss : 0.439468 model2 loss : 0.028700
[10:53:44.272] iteration 6349 : model1 loss : 0.437527 model2 loss : 0.028780
[10:53:44.441] iteration 6350 : model1 loss : 0.434444 model2 loss : 0.028061
[10:53:44.618] iteration 6351 : model1 loss : 0.438824 model2 loss : 0.030112
[10:53:44.789] iteration 6352 : model1 loss : 0.435937 model2 loss : 0.027502
[10:53:44.963] iteration 6353 : model1 loss : 0.437036 model2 loss : 0.030138
[10:53:45.133] iteration 6354 : model1 loss : 0.442295 model2 loss : 0.033161
[10:53:45.309] iteration 6355 : model1 loss : 0.439386 model2 loss : 0.030703
[10:53:45.477] iteration 6356 : model1 loss : 0.434505 model2 loss : 0.026692
[10:53:45.653] iteration 6357 : model1 loss : 0.435094 model2 loss : 0.025911
[10:53:45.824] iteration 6358 : model1 loss : 0.438049 model2 loss : 0.034391
[10:53:45.998] iteration 6359 : model1 loss : 0.438980 model2 loss : 0.031137
[10:53:46.170] iteration 6360 : model1 loss : 0.445911 model2 loss : 0.029618
[10:53:46.344] iteration 6361 : model1 loss : 0.439671 model2 loss : 0.033573
[10:53:46.515] iteration 6362 : model1 loss : 0.439459 model2 loss : 0.027464
[10:53:46.692] iteration 6363 : model1 loss : 0.438374 model2 loss : 0.029473
[10:53:46.861] iteration 6364 : model1 loss : 0.437505 model2 loss : 0.027704
[10:53:47.033] iteration 6365 : model1 loss : 0.434608 model2 loss : 0.036672
[10:53:47.205] iteration 6366 : model1 loss : 0.435207 model2 loss : 0.026480
[10:53:47.379] iteration 6367 : model1 loss : 0.440751 model2 loss : 0.031240
[10:53:47.548] iteration 6368 : model1 loss : 0.437817 model2 loss : 0.027234
[10:53:47.722] iteration 6369 : model1 loss : 0.442408 model2 loss : 0.035598
[10:53:49.706] iteration 6370 : model1 loss : 0.439568 model2 loss : 0.035786
[10:53:49.875] iteration 6371 : model1 loss : 0.437364 model2 loss : 0.027098
[10:53:50.051] iteration 6372 : model1 loss : 0.440975 model2 loss : 0.027921
[10:53:50.222] iteration 6373 : model1 loss : 0.441032 model2 loss : 0.032526
[10:53:50.394] iteration 6374 : model1 loss : 0.433635 model2 loss : 0.027240
[10:53:50.563] iteration 6375 : model1 loss : 0.435109 model2 loss : 0.024888
[10:53:50.737] iteration 6376 : model1 loss : 0.440497 model2 loss : 0.030018
[10:53:50.908] iteration 6377 : model1 loss : 0.439376 model2 loss : 0.027310
[10:53:51.079] iteration 6378 : model1 loss : 0.436168 model2 loss : 0.024810
[10:53:51.249] iteration 6379 : model1 loss : 0.434080 model2 loss : 0.025546
[10:53:51.421] iteration 6380 : model1 loss : 0.437107 model2 loss : 0.029521
[10:53:51.589] iteration 6381 : model1 loss : 0.436571 model2 loss : 0.025819
[10:53:51.762] iteration 6382 : model1 loss : 0.440114 model2 loss : 0.028705
[10:53:51.931] iteration 6383 : model1 loss : 0.437017 model2 loss : 0.027038
[10:53:52.103] iteration 6384 : model1 loss : 0.443176 model2 loss : 0.031224
[10:53:52.275] iteration 6385 : model1 loss : 0.440195 model2 loss : 0.028100
[10:53:52.448] iteration 6386 : model1 loss : 0.433259 model2 loss : 0.023970
[10:53:52.619] iteration 6387 : model1 loss : 0.438113 model2 loss : 0.029753
[10:53:52.793] iteration 6388 : model1 loss : 0.438645 model2 loss : 0.030271
[10:53:52.962] iteration 6389 : model1 loss : 0.439009 model2 loss : 0.028953
[10:53:53.147] iteration 6390 : model1 loss : 0.437609 model2 loss : 0.026659
[10:53:53.318] iteration 6391 : model1 loss : 0.438203 model2 loss : 0.029048
[10:53:53.490] iteration 6392 : model1 loss : 0.437632 model2 loss : 0.030426
[10:53:53.661] iteration 6393 : model1 loss : 0.437339 model2 loss : 0.026000
[10:53:53.833] iteration 6394 : model1 loss : 0.433869 model2 loss : 0.026338
[10:53:54.001] iteration 6395 : model1 loss : 0.434807 model2 loss : 0.031078
[10:53:54.179] iteration 6396 : model1 loss : 0.440300 model2 loss : 0.035641
[10:53:54.347] iteration 6397 : model1 loss : 0.441177 model2 loss : 0.032135
[10:53:54.523] iteration 6398 : model1 loss : 0.436478 model2 loss : 0.028491
[10:53:54.694] iteration 6399 : model1 loss : 0.435714 model2 loss : 0.027992
[10:53:54.867] iteration 6400 : model1 loss : 0.439749 model2 loss : 0.025795
[10:53:55.032] iteration 6401 : model1 loss : 0.437654 model2 loss : 0.028472
[10:53:55.203] iteration 6402 : model1 loss : 0.438086 model2 loss : 0.029470
[10:53:57.192] iteration 6403 : model1 loss : 0.434527 model2 loss : 0.026333
[10:53:57.359] iteration 6404 : model1 loss : 0.438246 model2 loss : 0.028045
[10:53:57.533] iteration 6405 : model1 loss : 0.434820 model2 loss : 0.029734
[10:53:57.704] iteration 6406 : model1 loss : 0.437656 model2 loss : 0.022871
[10:53:57.879] iteration 6407 : model1 loss : 0.435559 model2 loss : 0.028131
[10:53:58.048] iteration 6408 : model1 loss : 0.437184 model2 loss : 0.027642
[10:53:58.223] iteration 6409 : model1 loss : 0.436352 model2 loss : 0.027929
[10:53:58.392] iteration 6410 : model1 loss : 0.437703 model2 loss : 0.028599
[10:53:58.567] iteration 6411 : model1 loss : 0.432852 model2 loss : 0.023188
[10:53:58.739] iteration 6412 : model1 loss : 0.444877 model2 loss : 0.039689
[10:53:58.915] iteration 6413 : model1 loss : 0.436567 model2 loss : 0.031484
[10:53:59.085] iteration 6414 : model1 loss : 0.438535 model2 loss : 0.031311
[10:53:59.257] iteration 6415 : model1 loss : 0.440609 model2 loss : 0.033639
[10:53:59.427] iteration 6416 : model1 loss : 0.440584 model2 loss : 0.031811
[10:53:59.602] iteration 6417 : model1 loss : 0.439782 model2 loss : 0.028421
[10:53:59.775] iteration 6418 : model1 loss : 0.435040 model2 loss : 0.029531
[10:53:59.948] iteration 6419 : model1 loss : 0.441265 model2 loss : 0.026410
[10:54:00.121] iteration 6420 : model1 loss : 0.436490 model2 loss : 0.026975
[10:54:00.298] iteration 6421 : model1 loss : 0.438983 model2 loss : 0.029628
[10:54:00.467] iteration 6422 : model1 loss : 0.444250 model2 loss : 0.041262
[10:54:00.642] iteration 6423 : model1 loss : 0.437317 model2 loss : 0.025521
[10:54:00.817] iteration 6424 : model1 loss : 0.437150 model2 loss : 0.030051
[10:54:00.990] iteration 6425 : model1 loss : 0.443901 model2 loss : 0.026548
[10:54:01.160] iteration 6426 : model1 loss : 0.438693 model2 loss : 0.028972
[10:54:01.338] iteration 6427 : model1 loss : 0.436287 model2 loss : 0.027464
[10:54:01.507] iteration 6428 : model1 loss : 0.434572 model2 loss : 0.023295
[10:54:01.684] iteration 6429 : model1 loss : 0.437461 model2 loss : 0.028527
[10:54:01.852] iteration 6430 : model1 loss : 0.436343 model2 loss : 0.027849
[10:54:02.025] iteration 6431 : model1 loss : 0.436556 model2 loss : 0.028424
[10:54:02.197] iteration 6432 : model1 loss : 0.449404 model2 loss : 0.027431
[10:54:02.373] iteration 6433 : model1 loss : 0.440637 model2 loss : 0.030547
[10:54:02.544] iteration 6434 : model1 loss : 0.434062 model2 loss : 0.026231
[10:54:02.718] iteration 6435 : model1 loss : 0.437424 model2 loss : 0.028632
[10:54:04.727] iteration 6436 : model1 loss : 0.437044 model2 loss : 0.026565
[10:54:04.901] iteration 6437 : model1 loss : 0.438000 model2 loss : 0.028068
[10:54:05.076] iteration 6438 : model1 loss : 0.443089 model2 loss : 0.030839
[10:54:05.247] iteration 6439 : model1 loss : 0.438074 model2 loss : 0.033128
[10:54:05.420] iteration 6440 : model1 loss : 0.435400 model2 loss : 0.027088
[10:54:05.590] iteration 6441 : model1 loss : 0.437756 model2 loss : 0.026811
[10:54:05.764] iteration 6442 : model1 loss : 0.439833 model2 loss : 0.030277
[10:54:05.934] iteration 6443 : model1 loss : 0.435672 model2 loss : 0.031950
[10:54:06.109] iteration 6444 : model1 loss : 0.436819 model2 loss : 0.027974
[10:54:06.279] iteration 6445 : model1 loss : 0.443225 model2 loss : 0.028845
[10:54:06.452] iteration 6446 : model1 loss : 0.441503 model2 loss : 0.029345
[10:54:06.623] iteration 6447 : model1 loss : 0.441475 model2 loss : 0.027244
[10:54:06.795] iteration 6448 : model1 loss : 0.438860 model2 loss : 0.026044
[10:54:06.963] iteration 6449 : model1 loss : 0.438965 model2 loss : 0.027058
[10:54:07.138] iteration 6450 : model1 loss : 0.435447 model2 loss : 0.026884
[10:54:07.309] iteration 6451 : model1 loss : 0.437214 model2 loss : 0.030662
[10:54:07.487] iteration 6452 : model1 loss : 0.442894 model2 loss : 0.034668
[10:54:07.654] iteration 6453 : model1 loss : 0.442780 model2 loss : 0.032032
[10:54:07.829] iteration 6454 : model1 loss : 0.441654 model2 loss : 0.028281
[10:54:07.996] iteration 6455 : model1 loss : 0.435339 model2 loss : 0.026521
[10:54:08.173] iteration 6456 : model1 loss : 0.439361 model2 loss : 0.024841
[10:54:08.343] iteration 6457 : model1 loss : 0.437241 model2 loss : 0.027963
[10:54:08.522] iteration 6458 : model1 loss : 0.436671 model2 loss : 0.029963
[10:54:08.694] iteration 6459 : model1 loss : 0.437938 model2 loss : 0.034239
[10:54:08.868] iteration 6460 : model1 loss : 0.442881 model2 loss : 0.033304
[10:54:09.035] iteration 6461 : model1 loss : 0.434732 model2 loss : 0.027178
[10:54:09.211] iteration 6462 : model1 loss : 0.441732 model2 loss : 0.026389
[10:54:09.380] iteration 6463 : model1 loss : 0.433694 model2 loss : 0.025822
[10:54:09.554] iteration 6464 : model1 loss : 0.442621 model2 loss : 0.038049
[10:54:09.725] iteration 6465 : model1 loss : 0.441806 model2 loss : 0.038171
[10:54:09.900] iteration 6466 : model1 loss : 0.435601 model2 loss : 0.026666
[10:54:10.068] iteration 6467 : model1 loss : 0.437002 model2 loss : 0.027027
[10:54:10.243] iteration 6468 : model1 loss : 0.441161 model2 loss : 0.030193
[10:54:12.234] iteration 6469 : model1 loss : 0.438349 model2 loss : 0.030551
[10:54:12.403] iteration 6470 : model1 loss : 0.439738 model2 loss : 0.025863
[10:54:12.580] iteration 6471 : model1 loss : 0.437923 model2 loss : 0.030374
[10:54:12.750] iteration 6472 : model1 loss : 0.439494 model2 loss : 0.029119
[10:54:12.926] iteration 6473 : model1 loss : 0.436504 model2 loss : 0.025366
[10:54:13.093] iteration 6474 : model1 loss : 0.439523 model2 loss : 0.029415
[10:54:13.267] iteration 6475 : model1 loss : 0.438164 model2 loss : 0.030397
[10:54:13.433] iteration 6476 : model1 loss : 0.440778 model2 loss : 0.032173
[10:54:13.607] iteration 6477 : model1 loss : 0.436899 model2 loss : 0.025703
[10:54:13.776] iteration 6478 : model1 loss : 0.435000 model2 loss : 0.024160
[10:54:13.948] iteration 6479 : model1 loss : 0.439657 model2 loss : 0.029604
[10:54:14.117] iteration 6480 : model1 loss : 0.438902 model2 loss : 0.028475
[10:54:14.287] iteration 6481 : model1 loss : 0.439759 model2 loss : 0.031165
[10:54:14.454] iteration 6482 : model1 loss : 0.439080 model2 loss : 0.032176
[10:54:14.625] iteration 6483 : model1 loss : 0.433740 model2 loss : 0.028151
[10:54:14.796] iteration 6484 : model1 loss : 0.436399 model2 loss : 0.025202
[10:54:14.968] iteration 6485 : model1 loss : 0.439874 model2 loss : 0.035267
[10:54:15.137] iteration 6486 : model1 loss : 0.433289 model2 loss : 0.029392
[10:54:15.312] iteration 6487 : model1 loss : 0.440944 model2 loss : 0.028364
[10:54:15.480] iteration 6488 : model1 loss : 0.437387 model2 loss : 0.028097
[10:54:15.653] iteration 6489 : model1 loss : 0.434356 model2 loss : 0.027498
[10:54:15.826] iteration 6490 : model1 loss : 0.437786 model2 loss : 0.031147
[10:54:16.001] iteration 6491 : model1 loss : 0.437718 model2 loss : 0.027164
[10:54:16.169] iteration 6492 : model1 loss : 0.438702 model2 loss : 0.027711
[10:54:16.344] iteration 6493 : model1 loss : 0.440687 model2 loss : 0.030083
[10:54:16.514] iteration 6494 : model1 loss : 0.434117 model2 loss : 0.026723
[10:54:16.691] iteration 6495 : model1 loss : 0.436742 model2 loss : 0.027582
[10:54:16.859] iteration 6496 : model1 loss : 0.437826 model2 loss : 0.029402
[10:54:17.032] iteration 6497 : model1 loss : 0.436864 model2 loss : 0.027530
[10:54:17.201] iteration 6498 : model1 loss : 0.439808 model2 loss : 0.034438
[10:54:17.375] iteration 6499 : model1 loss : 0.437881 model2 loss : 0.026152
[10:54:17.543] iteration 6500 : model1 loss : 0.436525 model2 loss : 0.028108
[10:54:17.714] iteration 6501 : model1 loss : 0.441327 model2 loss : 0.029381
[10:54:19.730] iteration 6502 : model1 loss : 0.437923 model2 loss : 0.029696
[10:54:19.902] iteration 6503 : model1 loss : 0.434536 model2 loss : 0.026445
[10:54:20.075] iteration 6504 : model1 loss : 0.435878 model2 loss : 0.027618
[10:54:20.246] iteration 6505 : model1 loss : 0.437399 model2 loss : 0.033525
[10:54:20.420] iteration 6506 : model1 loss : 0.441427 model2 loss : 0.033477
[10:54:20.589] iteration 6507 : model1 loss : 0.438994 model2 loss : 0.028032
[10:54:20.764] iteration 6508 : model1 loss : 0.437879 model2 loss : 0.025867
[10:54:20.934] iteration 6509 : model1 loss : 0.435383 model2 loss : 0.025220
[10:54:21.106] iteration 6510 : model1 loss : 0.442006 model2 loss : 0.031679
[10:54:21.278] iteration 6511 : model1 loss : 0.434966 model2 loss : 0.026072
[10:54:21.453] iteration 6512 : model1 loss : 0.435359 model2 loss : 0.035046
[10:54:21.621] iteration 6513 : model1 loss : 0.440979 model2 loss : 0.032815
[10:54:21.794] iteration 6514 : model1 loss : 0.438648 model2 loss : 0.027857
[10:54:21.962] iteration 6515 : model1 loss : 0.439866 model2 loss : 0.025802
[10:54:22.136] iteration 6516 : model1 loss : 0.433134 model2 loss : 0.028203
[10:54:22.308] iteration 6517 : model1 loss : 0.441378 model2 loss : 0.034938
[10:54:22.480] iteration 6518 : model1 loss : 0.436829 model2 loss : 0.025164
[10:54:22.650] iteration 6519 : model1 loss : 0.436879 model2 loss : 0.028010
[10:54:22.823] iteration 6520 : model1 loss : 0.438562 model2 loss : 0.027696
[10:54:22.989] iteration 6521 : model1 loss : 0.442663 model2 loss : 0.037756
[10:54:23.162] iteration 6522 : model1 loss : 0.432212 model2 loss : 0.027832
[10:54:23.331] iteration 6523 : model1 loss : 0.435878 model2 loss : 0.025920
[10:54:23.508] iteration 6524 : model1 loss : 0.435634 model2 loss : 0.026936
[10:54:23.677] iteration 6525 : model1 loss : 0.439215 model2 loss : 0.031691
[10:54:23.853] iteration 6526 : model1 loss : 0.432347 model2 loss : 0.027542
[10:54:24.022] iteration 6527 : model1 loss : 0.442007 model2 loss : 0.030945
[10:54:24.197] iteration 6528 : model1 loss : 0.437874 model2 loss : 0.029734
[10:54:24.366] iteration 6529 : model1 loss : 0.437587 model2 loss : 0.033831
[10:54:24.542] iteration 6530 : model1 loss : 0.438137 model2 loss : 0.028343
[10:54:24.712] iteration 6531 : model1 loss : 0.434655 model2 loss : 0.026987
[10:54:24.889] iteration 6532 : model1 loss : 0.433986 model2 loss : 0.027263
[10:54:25.056] iteration 6533 : model1 loss : 0.443867 model2 loss : 0.035691
[10:54:25.230] iteration 6534 : model1 loss : 0.438069 model2 loss : 0.024871
[10:54:27.190] iteration 6535 : model1 loss : 0.438191 model2 loss : 0.027092
[10:54:27.361] iteration 6536 : model1 loss : 0.435089 model2 loss : 0.025459
[10:54:27.538] iteration 6537 : model1 loss : 0.436756 model2 loss : 0.031523
[10:54:27.707] iteration 6538 : model1 loss : 0.437389 model2 loss : 0.029125
[10:54:27.882] iteration 6539 : model1 loss : 0.438128 model2 loss : 0.031096
[10:54:28.049] iteration 6540 : model1 loss : 0.439195 model2 loss : 0.030588
[10:54:28.224] iteration 6541 : model1 loss : 0.439738 model2 loss : 0.030953
[10:54:28.394] iteration 6542 : model1 loss : 0.437503 model2 loss : 0.028406
[10:54:28.566] iteration 6543 : model1 loss : 0.439970 model2 loss : 0.028427
[10:54:28.738] iteration 6544 : model1 loss : 0.441933 model2 loss : 0.028664
[10:54:28.916] iteration 6545 : model1 loss : 0.435846 model2 loss : 0.028197
[10:54:29.084] iteration 6546 : model1 loss : 0.439678 model2 loss : 0.029899
[10:54:29.257] iteration 6547 : model1 loss : 0.435377 model2 loss : 0.028833
[10:54:29.426] iteration 6548 : model1 loss : 0.436070 model2 loss : 0.027777
[10:54:29.600] iteration 6549 : model1 loss : 0.440929 model2 loss : 0.034760
[10:54:29.771] iteration 6550 : model1 loss : 0.443253 model2 loss : 0.030369
[10:54:29.946] iteration 6551 : model1 loss : 0.438238 model2 loss : 0.029906
[10:54:30.115] iteration 6552 : model1 loss : 0.441763 model2 loss : 0.034545
[10:54:30.289] iteration 6553 : model1 loss : 0.438407 model2 loss : 0.028017
[10:54:30.458] iteration 6554 : model1 loss : 0.441725 model2 loss : 0.033062
[10:54:30.631] iteration 6555 : model1 loss : 0.436319 model2 loss : 0.025502
[10:54:30.803] iteration 6556 : model1 loss : 0.441183 model2 loss : 0.030644
[10:54:30.977] iteration 6557 : model1 loss : 0.437222 model2 loss : 0.027209
[10:54:31.144] iteration 6558 : model1 loss : 0.439668 model2 loss : 0.029152
[10:54:31.317] iteration 6559 : model1 loss : 0.433961 model2 loss : 0.025799
[10:54:31.486] iteration 6560 : model1 loss : 0.434074 model2 loss : 0.026944
[10:54:31.662] iteration 6561 : model1 loss : 0.434042 model2 loss : 0.029100
[10:54:31.832] iteration 6562 : model1 loss : 0.434872 model2 loss : 0.027968
[10:54:32.012] iteration 6563 : model1 loss : 0.435765 model2 loss : 0.028152
[10:54:32.181] iteration 6564 : model1 loss : 0.437155 model2 loss : 0.028885
[10:54:32.355] iteration 6565 : model1 loss : 0.440218 model2 loss : 0.030567
[10:54:32.524] iteration 6566 : model1 loss : 0.438759 model2 loss : 0.030292
[10:54:32.697] iteration 6567 : model1 loss : 0.434898 model2 loss : 0.022816
[10:54:34.660] iteration 6568 : model1 loss : 0.439071 model2 loss : 0.030250
[10:54:34.831] iteration 6569 : model1 loss : 0.433786 model2 loss : 0.026849
[10:54:35.006] iteration 6570 : model1 loss : 0.436318 model2 loss : 0.029132
[10:54:35.173] iteration 6571 : model1 loss : 0.440339 model2 loss : 0.029144
[10:54:35.349] iteration 6572 : model1 loss : 0.446941 model2 loss : 0.029345
[10:54:35.520] iteration 6573 : model1 loss : 0.438632 model2 loss : 0.032827
[10:54:35.705] iteration 6574 : model1 loss : 0.441317 model2 loss : 0.024786
[10:54:35.879] iteration 6575 : model1 loss : 0.438001 model2 loss : 0.028513
[10:54:36.051] iteration 6576 : model1 loss : 0.440155 model2 loss : 0.026894
[10:54:36.222] iteration 6577 : model1 loss : 0.433274 model2 loss : 0.028514
[10:54:36.395] iteration 6578 : model1 loss : 0.439922 model2 loss : 0.029831
[10:54:36.564] iteration 6579 : model1 loss : 0.442208 model2 loss : 0.031076
[10:54:36.740] iteration 6580 : model1 loss : 0.439229 model2 loss : 0.028084
[10:54:36.911] iteration 6581 : model1 loss : 0.436512 model2 loss : 0.027789
[10:54:37.085] iteration 6582 : model1 loss : 0.437120 model2 loss : 0.027018
[10:54:37.256] iteration 6583 : model1 loss : 0.436177 model2 loss : 0.030088
[10:54:37.431] iteration 6584 : model1 loss : 0.443555 model2 loss : 0.030023
[10:54:37.601] iteration 6585 : model1 loss : 0.434388 model2 loss : 0.027535
[10:54:37.774] iteration 6586 : model1 loss : 0.438047 model2 loss : 0.026376
[10:54:37.944] iteration 6587 : model1 loss : 0.438681 model2 loss : 0.031453
[10:54:38.116] iteration 6588 : model1 loss : 0.439464 model2 loss : 0.025866
[10:54:38.288] iteration 6589 : model1 loss : 0.435425 model2 loss : 0.026783
[10:54:38.458] iteration 6590 : model1 loss : 0.436846 model2 loss : 0.027424
[10:54:38.626] iteration 6591 : model1 loss : 0.436118 model2 loss : 0.022991
[10:54:38.801] iteration 6592 : model1 loss : 0.437900 model2 loss : 0.027935
[10:54:38.970] iteration 6593 : model1 loss : 0.439981 model2 loss : 0.031013
[10:54:39.143] iteration 6594 : model1 loss : 0.435697 model2 loss : 0.027301
[10:54:39.315] iteration 6595 : model1 loss : 0.436390 model2 loss : 0.025780
[10:54:39.488] iteration 6596 : model1 loss : 0.437359 model2 loss : 0.026647
[10:54:39.659] iteration 6597 : model1 loss : 0.440758 model2 loss : 0.031249
[10:54:39.835] iteration 6598 : model1 loss : 0.436332 model2 loss : 0.027298
[10:54:40.002] iteration 6599 : model1 loss : 0.444161 model2 loss : 0.030311
[10:54:40.175] iteration 6600 : model1 loss : 0.436119 model2 loss : 0.025827
[10:54:42.237] iteration 6601 : model1 loss : 0.439416 model2 loss : 0.028386
[10:54:42.407] iteration 6602 : model1 loss : 0.438887 model2 loss : 0.025296
[10:54:42.583] iteration 6603 : model1 loss : 0.435503 model2 loss : 0.028025
[10:54:42.754] iteration 6604 : model1 loss : 0.440071 model2 loss : 0.028762
[10:54:42.932] iteration 6605 : model1 loss : 0.440227 model2 loss : 0.027731
[10:54:43.099] iteration 6606 : model1 loss : 0.437312 model2 loss : 0.033072
[10:54:43.275] iteration 6607 : model1 loss : 0.445572 model2 loss : 0.034084
[10:54:43.443] iteration 6608 : model1 loss : 0.442082 model2 loss : 0.028293
[10:54:43.615] iteration 6609 : model1 loss : 0.437312 model2 loss : 0.028344
[10:54:43.786] iteration 6610 : model1 loss : 0.442433 model2 loss : 0.031510
[10:54:43.956] iteration 6611 : model1 loss : 0.440026 model2 loss : 0.025853
[10:54:44.124] iteration 6612 : model1 loss : 0.442893 model2 loss : 0.032537
[10:54:44.300] iteration 6613 : model1 loss : 0.439744 model2 loss : 0.028235
[10:54:44.466] iteration 6614 : model1 loss : 0.438471 model2 loss : 0.027628
[10:54:44.640] iteration 6615 : model1 loss : 0.433563 model2 loss : 0.027769
[10:54:44.809] iteration 6616 : model1 loss : 0.437842 model2 loss : 0.028785
[10:54:44.982] iteration 6617 : model1 loss : 0.439183 model2 loss : 0.022819
[10:54:45.149] iteration 6618 : model1 loss : 0.441531 model2 loss : 0.029015
[10:54:45.324] iteration 6619 : model1 loss : 0.438919 model2 loss : 0.029054
[10:54:45.494] iteration 6620 : model1 loss : 0.433893 model2 loss : 0.024774
[10:54:45.666] iteration 6621 : model1 loss : 0.439307 model2 loss : 0.035347
[10:54:45.839] iteration 6622 : model1 loss : 0.437020 model2 loss : 0.025574
[10:54:46.012] iteration 6623 : model1 loss : 0.442005 model2 loss : 0.028245
[10:54:46.180] iteration 6624 : model1 loss : 0.443154 model2 loss : 0.032289
[10:54:46.355] iteration 6625 : model1 loss : 0.443427 model2 loss : 0.033837
[10:54:46.526] iteration 6626 : model1 loss : 0.440698 model2 loss : 0.029704
[10:54:46.699] iteration 6627 : model1 loss : 0.437698 model2 loss : 0.031118
[10:54:46.871] iteration 6628 : model1 loss : 0.436507 model2 loss : 0.023421
[10:54:47.045] iteration 6629 : model1 loss : 0.436774 model2 loss : 0.030943
[10:54:47.213] iteration 6630 : model1 loss : 0.435396 model2 loss : 0.027640
[10:54:47.387] iteration 6631 : model1 loss : 0.440860 model2 loss : 0.025973
[10:54:47.556] iteration 6632 : model1 loss : 0.435649 model2 loss : 0.026263
[10:54:47.728] iteration 6633 : model1 loss : 0.437406 model2 loss : 0.030413
[10:54:49.688] iteration 6634 : model1 loss : 0.439933 model2 loss : 0.028923
[10:54:49.858] iteration 6635 : model1 loss : 0.434576 model2 loss : 0.027591
[10:54:50.031] iteration 6636 : model1 loss : 0.440299 model2 loss : 0.033008
[10:54:50.200] iteration 6637 : model1 loss : 0.440217 model2 loss : 0.030056
[10:54:50.375] iteration 6638 : model1 loss : 0.439724 model2 loss : 0.025521
[10:54:50.545] iteration 6639 : model1 loss : 0.434199 model2 loss : 0.025883
[10:54:50.720] iteration 6640 : model1 loss : 0.437403 model2 loss : 0.025641
[10:54:50.895] iteration 6641 : model1 loss : 0.438884 model2 loss : 0.025903
[10:54:51.067] iteration 6642 : model1 loss : 0.433806 model2 loss : 0.024823
[10:54:51.235] iteration 6643 : model1 loss : 0.438767 model2 loss : 0.029535
[10:54:51.411] iteration 6644 : model1 loss : 0.439089 model2 loss : 0.028996
[10:54:51.580] iteration 6645 : model1 loss : 0.443537 model2 loss : 0.028061
[10:54:51.754] iteration 6646 : model1 loss : 0.441039 model2 loss : 0.030890
[10:54:51.925] iteration 6647 : model1 loss : 0.439285 model2 loss : 0.027412
[10:54:52.098] iteration 6648 : model1 loss : 0.442607 model2 loss : 0.038215
[10:54:52.268] iteration 6649 : model1 loss : 0.434680 model2 loss : 0.027845
[10:54:52.442] iteration 6650 : model1 loss : 0.437339 model2 loss : 0.026506
[10:54:52.611] iteration 6651 : model1 loss : 0.435165 model2 loss : 0.029136
[10:54:52.786] iteration 6652 : model1 loss : 0.436382 model2 loss : 0.024539
[10:54:52.956] iteration 6653 : model1 loss : 0.437796 model2 loss : 0.028381
[10:54:53.129] iteration 6654 : model1 loss : 0.436496 model2 loss : 0.027178
[10:54:53.299] iteration 6655 : model1 loss : 0.436159 model2 loss : 0.024304
[10:54:53.475] iteration 6656 : model1 loss : 0.435208 model2 loss : 0.024819
[10:54:53.644] iteration 6657 : model1 loss : 0.440866 model2 loss : 0.029726
[10:54:53.817] iteration 6658 : model1 loss : 0.439791 model2 loss : 0.030583
[10:54:53.992] iteration 6659 : model1 loss : 0.440888 model2 loss : 0.035429
[10:54:54.167] iteration 6660 : model1 loss : 0.441607 model2 loss : 0.028348
[10:54:54.336] iteration 6661 : model1 loss : 0.438141 model2 loss : 0.027196
[10:54:54.514] iteration 6662 : model1 loss : 0.434996 model2 loss : 0.033164
[10:54:54.683] iteration 6663 : model1 loss : 0.434075 model2 loss : 0.025328
[10:54:54.859] iteration 6664 : model1 loss : 0.440812 model2 loss : 0.028116
[10:54:55.027] iteration 6665 : model1 loss : 0.440039 model2 loss : 0.029497
[10:54:55.199] iteration 6666 : model1 loss : 0.439040 model2 loss : 0.033475
[10:54:57.183] iteration 6667 : model1 loss : 0.442320 model2 loss : 0.043182
[10:54:57.353] iteration 6668 : model1 loss : 0.438494 model2 loss : 0.029416
[10:54:57.530] iteration 6669 : model1 loss : 0.434298 model2 loss : 0.022812
[10:54:57.699] iteration 6670 : model1 loss : 0.441299 model2 loss : 0.028243
[10:54:57.873] iteration 6671 : model1 loss : 0.437613 model2 loss : 0.030634
[10:54:58.043] iteration 6672 : model1 loss : 0.437487 model2 loss : 0.030787
[10:54:58.216] iteration 6673 : model1 loss : 0.433570 model2 loss : 0.023538
[10:54:58.388] iteration 6674 : model1 loss : 0.438100 model2 loss : 0.026071
[10:54:58.562] iteration 6675 : model1 loss : 0.439504 model2 loss : 0.027367
[10:54:58.731] iteration 6676 : model1 loss : 0.440635 model2 loss : 0.032431
[10:54:58.911] iteration 6677 : model1 loss : 0.437998 model2 loss : 0.030742
[10:54:59.080] iteration 6678 : model1 loss : 0.435550 model2 loss : 0.029666
[10:54:59.254] iteration 6679 : model1 loss : 0.431127 model2 loss : 0.025924
[10:54:59.424] iteration 6680 : model1 loss : 0.436836 model2 loss : 0.027046
[10:54:59.598] iteration 6681 : model1 loss : 0.441771 model2 loss : 0.033088
[10:54:59.769] iteration 6682 : model1 loss : 0.436673 model2 loss : 0.027884
[10:54:59.945] iteration 6683 : model1 loss : 0.436306 model2 loss : 0.031144
[10:55:00.117] iteration 6684 : model1 loss : 0.441542 model2 loss : 0.033873
[10:55:00.294] iteration 6685 : model1 loss : 0.437088 model2 loss : 0.030344
[10:55:00.462] iteration 6686 : model1 loss : 0.436810 model2 loss : 0.030748
[10:55:00.642] iteration 6687 : model1 loss : 0.440240 model2 loss : 0.029048
[10:55:00.814] iteration 6688 : model1 loss : 0.439971 model2 loss : 0.029127
[10:55:00.989] iteration 6689 : model1 loss : 0.438911 model2 loss : 0.030259
[10:55:01.156] iteration 6690 : model1 loss : 0.436947 model2 loss : 0.028624
[10:55:01.333] iteration 6691 : model1 loss : 0.436560 model2 loss : 0.027020
[10:55:01.504] iteration 6692 : model1 loss : 0.439822 model2 loss : 0.024044
[10:55:01.680] iteration 6693 : model1 loss : 0.439960 model2 loss : 0.028591
[10:55:01.852] iteration 6694 : model1 loss : 0.441162 model2 loss : 0.033669
[10:55:02.023] iteration 6695 : model1 loss : 0.438901 model2 loss : 0.025807
[10:55:02.193] iteration 6696 : model1 loss : 0.438385 model2 loss : 0.028008
[10:55:02.365] iteration 6697 : model1 loss : 0.443261 model2 loss : 0.034787
[10:55:02.534] iteration 6698 : model1 loss : 0.442607 model2 loss : 0.030132
[10:55:02.709] iteration 6699 : model1 loss : 0.435696 model2 loss : 0.027726
[10:55:04.705] iteration 6700 : model1 loss : 0.440332 model2 loss : 0.031102
[10:55:04.879] iteration 6701 : model1 loss : 0.436360 model2 loss : 0.025810
[10:55:05.056] iteration 6702 : model1 loss : 0.436782 model2 loss : 0.024938
[10:55:05.223] iteration 6703 : model1 loss : 0.438822 model2 loss : 0.030662
[10:55:05.399] iteration 6704 : model1 loss : 0.438630 model2 loss : 0.032725
[10:55:05.569] iteration 6705 : model1 loss : 0.438306 model2 loss : 0.030789
[10:55:05.744] iteration 6706 : model1 loss : 0.438024 model2 loss : 0.026861
[10:55:05.921] iteration 6707 : model1 loss : 0.436071 model2 loss : 0.028327
[10:55:06.094] iteration 6708 : model1 loss : 0.437078 model2 loss : 0.030349
[10:55:06.264] iteration 6709 : model1 loss : 0.441726 model2 loss : 0.027258
[10:55:06.438] iteration 6710 : model1 loss : 0.435297 model2 loss : 0.025639
[10:55:06.607] iteration 6711 : model1 loss : 0.437693 model2 loss : 0.029699
[10:55:06.780] iteration 6712 : model1 loss : 0.440187 model2 loss : 0.034405
[10:55:06.961] iteration 6713 : model1 loss : 0.439150 model2 loss : 0.030803
[10:55:07.133] iteration 6714 : model1 loss : 0.437993 model2 loss : 0.028507
[10:55:07.303] iteration 6715 : model1 loss : 0.439125 model2 loss : 0.026466
[10:55:07.478] iteration 6716 : model1 loss : 0.437613 model2 loss : 0.028440
[10:55:07.649] iteration 6717 : model1 loss : 0.436017 model2 loss : 0.028215
[10:55:07.825] iteration 6718 : model1 loss : 0.435314 model2 loss : 0.026542
[10:55:07.994] iteration 6719 : model1 loss : 0.442269 model2 loss : 0.032051
[10:55:08.168] iteration 6720 : model1 loss : 0.438920 model2 loss : 0.026924
[10:55:08.341] iteration 6721 : model1 loss : 0.440174 model2 loss : 0.031821
[10:55:08.516] iteration 6722 : model1 loss : 0.432523 model2 loss : 0.030062
[10:55:08.685] iteration 6723 : model1 loss : 0.451057 model2 loss : 0.040232
[10:55:08.862] iteration 6724 : model1 loss : 0.439449 model2 loss : 0.029369
[10:55:09.032] iteration 6725 : model1 loss : 0.431067 model2 loss : 0.024972
[10:55:09.206] iteration 6726 : model1 loss : 0.438687 model2 loss : 0.025670
[10:55:09.378] iteration 6727 : model1 loss : 0.437425 model2 loss : 0.028119
[10:55:09.552] iteration 6728 : model1 loss : 0.442123 model2 loss : 0.034953
[10:55:09.721] iteration 6729 : model1 loss : 0.435089 model2 loss : 0.026822
[10:55:09.900] iteration 6730 : model1 loss : 0.440643 model2 loss : 0.029983
[10:55:10.066] iteration 6731 : model1 loss : 0.441365 model2 loss : 0.032790
[10:55:10.239] iteration 6732 : model1 loss : 0.439999 model2 loss : 0.034891
[10:55:12.191] iteration 6733 : model1 loss : 0.440709 model2 loss : 0.031350
[10:55:12.365] iteration 6734 : model1 loss : 0.438956 model2 loss : 0.025876
[10:55:12.542] iteration 6735 : model1 loss : 0.442188 model2 loss : 0.035736
[10:55:12.710] iteration 6736 : model1 loss : 0.439892 model2 loss : 0.035331
[10:55:12.884] iteration 6737 : model1 loss : 0.436661 model2 loss : 0.028909
[10:55:13.052] iteration 6738 : model1 loss : 0.440230 model2 loss : 0.033063
[10:55:13.224] iteration 6739 : model1 loss : 0.443477 model2 loss : 0.036165
[10:55:13.394] iteration 6740 : model1 loss : 0.438877 model2 loss : 0.033312
[10:55:13.567] iteration 6741 : model1 loss : 0.439430 model2 loss : 0.040524
[10:55:13.736] iteration 6742 : model1 loss : 0.439430 model2 loss : 0.029597
[10:55:13.912] iteration 6743 : model1 loss : 0.437231 model2 loss : 0.034554
[10:55:14.081] iteration 6744 : model1 loss : 0.439370 model2 loss : 0.027302
[10:55:14.253] iteration 6745 : model1 loss : 0.435476 model2 loss : 0.030869
[10:55:14.424] iteration 6746 : model1 loss : 0.433548 model2 loss : 0.032302
[10:55:14.599] iteration 6747 : model1 loss : 0.439071 model2 loss : 0.039996
[10:55:14.774] iteration 6748 : model1 loss : 0.434324 model2 loss : 0.031665
[10:55:14.948] iteration 6749 : model1 loss : 0.435378 model2 loss : 0.028122
[10:55:15.116] iteration 6750 : model1 loss : 0.434139 model2 loss : 0.027247
[10:55:15.293] iteration 6751 : model1 loss : 0.434413 model2 loss : 0.030648
[10:55:15.462] iteration 6752 : model1 loss : 0.443240 model2 loss : 0.036385
[10:55:15.637] iteration 6753 : model1 loss : 0.439024 model2 loss : 0.030283
[10:55:15.809] iteration 6754 : model1 loss : 0.440038 model2 loss : 0.026429
[10:55:15.983] iteration 6755 : model1 loss : 0.438577 model2 loss : 0.029935
[10:55:16.153] iteration 6756 : model1 loss : 0.437357 model2 loss : 0.031601
[10:55:16.328] iteration 6757 : model1 loss : 0.435656 model2 loss : 0.027126
[10:55:16.498] iteration 6758 : model1 loss : 0.440699 model2 loss : 0.031881
[10:55:16.675] iteration 6759 : model1 loss : 0.433839 model2 loss : 0.031782
[10:55:16.847] iteration 6760 : model1 loss : 0.434036 model2 loss : 0.029497
[10:55:17.019] iteration 6761 : model1 loss : 0.440573 model2 loss : 0.029599
[10:55:17.188] iteration 6762 : model1 loss : 0.441773 model2 loss : 0.032440
[10:55:17.372] iteration 6763 : model1 loss : 0.437146 model2 loss : 0.024541
[10:55:17.541] iteration 6764 : model1 loss : 0.436720 model2 loss : 0.029883
[10:55:17.715] iteration 6765 : model1 loss : 0.436632 model2 loss : 0.029404
[10:55:19.734] iteration 6766 : model1 loss : 0.442372 model2 loss : 0.031651
[10:55:19.909] iteration 6767 : model1 loss : 0.435032 model2 loss : 0.030391
[10:55:20.084] iteration 6768 : model1 loss : 0.433040 model2 loss : 0.024075
[10:55:20.254] iteration 6769 : model1 loss : 0.434639 model2 loss : 0.025600
[10:55:20.427] iteration 6770 : model1 loss : 0.441047 model2 loss : 0.029836
[10:55:20.596] iteration 6771 : model1 loss : 0.436174 model2 loss : 0.028869
[10:55:20.770] iteration 6772 : model1 loss : 0.442840 model2 loss : 0.032941
[10:55:20.943] iteration 6773 : model1 loss : 0.438898 model2 loss : 0.036359
[10:55:21.118] iteration 6774 : model1 loss : 0.440147 model2 loss : 0.031062
[10:55:21.289] iteration 6775 : model1 loss : 0.442126 model2 loss : 0.041143
[10:55:21.462] iteration 6776 : model1 loss : 0.440889 model2 loss : 0.030839
[10:55:21.630] iteration 6777 : model1 loss : 0.435856 model2 loss : 0.025331
[10:55:21.818] iteration 6778 : model1 loss : 0.438710 model2 loss : 0.027809
[10:55:21.988] iteration 6779 : model1 loss : 0.439673 model2 loss : 0.029675
[10:55:22.162] iteration 6780 : model1 loss : 0.439049 model2 loss : 0.028662
[10:55:22.333] iteration 6781 : model1 loss : 0.433689 model2 loss : 0.025738
[10:55:22.509] iteration 6782 : model1 loss : 0.437805 model2 loss : 0.030123
[10:55:22.679] iteration 6783 : model1 loss : 0.438742 model2 loss : 0.036875
[10:55:22.855] iteration 6784 : model1 loss : 0.434198 model2 loss : 0.026795
[10:55:23.022] iteration 6785 : model1 loss : 0.440021 model2 loss : 0.029348
[10:55:23.198] iteration 6786 : model1 loss : 0.441737 model2 loss : 0.029552
[10:55:23.371] iteration 6787 : model1 loss : 0.437847 model2 loss : 0.029213
[10:55:23.545] iteration 6788 : model1 loss : 0.441830 model2 loss : 0.030423
[10:55:23.714] iteration 6789 : model1 loss : 0.440387 model2 loss : 0.031666
[10:55:23.888] iteration 6790 : model1 loss : 0.441293 model2 loss : 0.037414
[10:55:24.056] iteration 6791 : model1 loss : 0.437187 model2 loss : 0.027342
[10:55:24.231] iteration 6792 : model1 loss : 0.434178 model2 loss : 0.028571
[10:55:24.403] iteration 6793 : model1 loss : 0.440453 model2 loss : 0.030485
[10:55:24.579] iteration 6794 : model1 loss : 0.437597 model2 loss : 0.026808
[10:55:24.748] iteration 6795 : model1 loss : 0.435101 model2 loss : 0.035016
[10:55:24.934] iteration 6796 : model1 loss : 0.436660 model2 loss : 0.028025
[10:55:25.101] iteration 6797 : model1 loss : 0.434170 model2 loss : 0.033168
[10:55:25.277] iteration 6798 : model1 loss : 0.437191 model2 loss : 0.026453
[10:55:27.264] iteration 6799 : model1 loss : 0.438161 model2 loss : 0.027969
[10:55:27.437] iteration 6800 : model1 loss : 0.435211 model2 loss : 0.027235
[10:55:27.611] iteration 6801 : model1 loss : 0.438232 model2 loss : 0.030154
[10:55:27.779] iteration 6802 : model1 loss : 0.437678 model2 loss : 0.028593
[10:55:27.953] iteration 6803 : model1 loss : 0.438880 model2 loss : 0.032752
[10:55:28.120] iteration 6804 : model1 loss : 0.433799 model2 loss : 0.027214
[10:55:28.292] iteration 6805 : model1 loss : 0.438724 model2 loss : 0.028600
[10:55:28.462] iteration 6806 : model1 loss : 0.434314 model2 loss : 0.024405
[10:55:28.634] iteration 6807 : model1 loss : 0.436979 model2 loss : 0.030575
[10:55:28.803] iteration 6808 : model1 loss : 0.437259 model2 loss : 0.031174
[10:55:28.979] iteration 6809 : model1 loss : 0.435804 model2 loss : 0.024525
[10:55:29.146] iteration 6810 : model1 loss : 0.438361 model2 loss : 0.030340
[10:55:29.321] iteration 6811 : model1 loss : 0.435421 model2 loss : 0.028292
[10:55:29.491] iteration 6812 : model1 loss : 0.441264 model2 loss : 0.029116
[10:55:29.664] iteration 6813 : model1 loss : 0.442994 model2 loss : 0.028382
[10:55:29.833] iteration 6814 : model1 loss : 0.439091 model2 loss : 0.026950
[10:55:30.007] iteration 6815 : model1 loss : 0.439173 model2 loss : 0.030922
[10:55:30.174] iteration 6816 : model1 loss : 0.439070 model2 loss : 0.029623
[10:55:30.350] iteration 6817 : model1 loss : 0.436158 model2 loss : 0.028038
[10:55:30.523] iteration 6818 : model1 loss : 0.436199 model2 loss : 0.026955
[10:55:30.696] iteration 6819 : model1 loss : 0.437205 model2 loss : 0.031333
[10:55:30.870] iteration 6820 : model1 loss : 0.441578 model2 loss : 0.033396
[10:55:31.047] iteration 6821 : model1 loss : 0.436117 model2 loss : 0.025232
[10:55:31.216] iteration 6822 : model1 loss : 0.439416 model2 loss : 0.036242
[10:55:31.394] iteration 6823 : model1 loss : 0.440338 model2 loss : 0.032703
[10:55:31.563] iteration 6824 : model1 loss : 0.435562 model2 loss : 0.027811
[10:55:31.736] iteration 6825 : model1 loss : 0.440472 model2 loss : 0.031281
[10:55:31.910] iteration 6826 : model1 loss : 0.438233 model2 loss : 0.026569
[10:55:32.085] iteration 6827 : model1 loss : 0.436872 model2 loss : 0.034509
[10:55:32.253] iteration 6828 : model1 loss : 0.442498 model2 loss : 0.031058
[10:55:32.429] iteration 6829 : model1 loss : 0.438880 model2 loss : 0.026366
[10:55:32.597] iteration 6830 : model1 loss : 0.439223 model2 loss : 0.030919
[10:55:32.770] iteration 6831 : model1 loss : 0.441866 model2 loss : 0.032006
[10:55:34.769] iteration 6832 : model1 loss : 0.437954 model2 loss : 0.028561
[10:55:34.941] iteration 6833 : model1 loss : 0.440622 model2 loss : 0.031883
[10:55:35.115] iteration 6834 : model1 loss : 0.441517 model2 loss : 0.028487
[10:55:35.284] iteration 6835 : model1 loss : 0.439027 model2 loss : 0.025046
[10:55:35.461] iteration 6836 : model1 loss : 0.439385 model2 loss : 0.030446
[10:55:35.630] iteration 6837 : model1 loss : 0.437356 model2 loss : 0.025109
[10:55:35.803] iteration 6838 : model1 loss : 0.435266 model2 loss : 0.028344
[10:55:35.974] iteration 6839 : model1 loss : 0.439561 model2 loss : 0.027463
[10:55:36.147] iteration 6840 : model1 loss : 0.437936 model2 loss : 0.026094
[10:55:36.325] iteration 6841 : model1 loss : 0.435055 model2 loss : 0.027482
[10:55:36.500] iteration 6842 : model1 loss : 0.440228 model2 loss : 0.028917
[10:55:36.669] iteration 6843 : model1 loss : 0.437114 model2 loss : 0.027520
[10:55:36.846] iteration 6844 : model1 loss : 0.431868 model2 loss : 0.026744
[10:55:37.016] iteration 6845 : model1 loss : 0.433478 model2 loss : 0.025158
[10:55:37.187] iteration 6846 : model1 loss : 0.439245 model2 loss : 0.031007
[10:55:37.359] iteration 6847 : model1 loss : 0.441465 model2 loss : 0.030778
[10:55:37.536] iteration 6848 : model1 loss : 0.433803 model2 loss : 0.027582
[10:55:37.704] iteration 6849 : model1 loss : 0.438481 model2 loss : 0.028419
[10:55:37.879] iteration 6850 : model1 loss : 0.440104 model2 loss : 0.033491
[10:55:38.048] iteration 6851 : model1 loss : 0.441829 model2 loss : 0.031690
[10:55:38.221] iteration 6852 : model1 loss : 0.439999 model2 loss : 0.028397
[10:55:38.394] iteration 6853 : model1 loss : 0.431738 model2 loss : 0.025139
[10:55:38.569] iteration 6854 : model1 loss : 0.438116 model2 loss : 0.025981
[10:55:38.738] iteration 6855 : model1 loss : 0.439755 model2 loss : 0.036594
[10:55:38.914] iteration 6856 : model1 loss : 0.439678 model2 loss : 0.032760
[10:55:39.084] iteration 6857 : model1 loss : 0.439781 model2 loss : 0.029816
[10:55:39.256] iteration 6858 : model1 loss : 0.437601 model2 loss : 0.027122
[10:55:39.427] iteration 6859 : model1 loss : 0.436062 model2 loss : 0.026320
[10:55:39.607] iteration 6860 : model1 loss : 0.437094 model2 loss : 0.026820
[10:55:39.775] iteration 6861 : model1 loss : 0.434638 model2 loss : 0.024999
[10:55:39.950] iteration 6862 : model1 loss : 0.439180 model2 loss : 0.031051
[10:55:40.118] iteration 6863 : model1 loss : 0.438376 model2 loss : 0.029166
[10:55:40.290] iteration 6864 : model1 loss : 0.438923 model2 loss : 0.030226
[10:55:42.305] iteration 6865 : model1 loss : 0.439406 model2 loss : 0.028759
[10:55:42.482] iteration 6866 : model1 loss : 0.440584 model2 loss : 0.029144
[10:55:42.657] iteration 6867 : model1 loss : 0.435979 model2 loss : 0.027182
[10:55:42.827] iteration 6868 : model1 loss : 0.438572 model2 loss : 0.027088
[10:55:43.001] iteration 6869 : model1 loss : 0.439505 model2 loss : 0.033030
[10:55:43.168] iteration 6870 : model1 loss : 0.439414 model2 loss : 0.033277
[10:55:43.342] iteration 6871 : model1 loss : 0.439983 model2 loss : 0.032130
[10:55:43.513] iteration 6872 : model1 loss : 0.437401 model2 loss : 0.024700
[10:55:43.689] iteration 6873 : model1 loss : 0.440012 model2 loss : 0.029855
[10:55:43.858] iteration 6874 : model1 loss : 0.436663 model2 loss : 0.027701
[10:55:44.032] iteration 6875 : model1 loss : 0.440200 model2 loss : 0.028821
[10:55:44.202] iteration 6876 : model1 loss : 0.431269 model2 loss : 0.026696
[10:55:44.377] iteration 6877 : model1 loss : 0.438752 model2 loss : 0.031481
[10:55:44.547] iteration 6878 : model1 loss : 0.437083 model2 loss : 0.027261
[10:55:44.720] iteration 6879 : model1 loss : 0.437723 model2 loss : 0.025063
[10:55:44.891] iteration 6880 : model1 loss : 0.436975 model2 loss : 0.026546
[10:55:45.065] iteration 6881 : model1 loss : 0.438654 model2 loss : 0.030153
[10:55:45.234] iteration 6882 : model1 loss : 0.442383 model2 loss : 0.030915
[10:55:45.410] iteration 6883 : model1 loss : 0.435422 model2 loss : 0.029615
[10:55:45.582] iteration 6884 : model1 loss : 0.438425 model2 loss : 0.027137
[10:55:45.758] iteration 6885 : model1 loss : 0.440336 model2 loss : 0.031311
[10:55:45.933] iteration 6886 : model1 loss : 0.441386 model2 loss : 0.041309
[10:55:46.107] iteration 6887 : model1 loss : 0.437294 model2 loss : 0.026451
[10:55:46.278] iteration 6888 : model1 loss : 0.444423 model2 loss : 0.028226
[10:55:46.453] iteration 6889 : model1 loss : 0.434345 model2 loss : 0.026209
[10:55:46.624] iteration 6890 : model1 loss : 0.436049 model2 loss : 0.030268
[10:55:46.800] iteration 6891 : model1 loss : 0.438036 model2 loss : 0.029080
[10:55:46.974] iteration 6892 : model1 loss : 0.439035 model2 loss : 0.023369
[10:55:47.152] iteration 6893 : model1 loss : 0.437377 model2 loss : 0.027410
[10:55:47.322] iteration 6894 : model1 loss : 0.435764 model2 loss : 0.030173
[10:55:47.495] iteration 6895 : model1 loss : 0.434719 model2 loss : 0.027902
[10:55:47.663] iteration 6896 : model1 loss : 0.438662 model2 loss : 0.030792
[10:55:47.835] iteration 6897 : model1 loss : 0.435530 model2 loss : 0.028530
[10:55:49.803] iteration 6898 : model1 loss : 0.436454 model2 loss : 0.027834
[10:55:49.978] iteration 6899 : model1 loss : 0.436082 model2 loss : 0.025073
[10:55:50.152] iteration 6900 : model1 loss : 0.435309 model2 loss : 0.026075
[10:55:50.322] iteration 6901 : model1 loss : 0.438022 model2 loss : 0.031743
[10:55:50.500] iteration 6902 : model1 loss : 0.436215 model2 loss : 0.025307
[10:55:50.669] iteration 6903 : model1 loss : 0.440142 model2 loss : 0.030224
[10:55:50.846] iteration 6904 : model1 loss : 0.440130 model2 loss : 0.030651
[10:55:51.016] iteration 6905 : model1 loss : 0.436302 model2 loss : 0.030193
[10:55:51.187] iteration 6906 : model1 loss : 0.443090 model2 loss : 0.035726
[10:55:51.358] iteration 6907 : model1 loss : 0.441123 model2 loss : 0.029451
[10:55:51.536] iteration 6908 : model1 loss : 0.434466 model2 loss : 0.026218
[10:55:51.705] iteration 6909 : model1 loss : 0.441520 model2 loss : 0.028735
[10:55:51.879] iteration 6910 : model1 loss : 0.438468 model2 loss : 0.028288
[10:55:52.048] iteration 6911 : model1 loss : 0.437840 model2 loss : 0.027773
[10:55:52.237] iteration 6912 : model1 loss : 0.443446 model2 loss : 0.030032
[10:55:52.408] iteration 6913 : model1 loss : 0.437568 model2 loss : 0.033131
[10:55:52.582] iteration 6914 : model1 loss : 0.441395 model2 loss : 0.030426
[10:55:52.751] iteration 6915 : model1 loss : 0.436148 model2 loss : 0.038943
[10:55:52.931] iteration 6916 : model1 loss : 0.434693 model2 loss : 0.026902
[10:55:53.100] iteration 6917 : model1 loss : 0.437623 model2 loss : 0.026891
[10:55:53.273] iteration 6918 : model1 loss : 0.441909 model2 loss : 0.029899
[10:55:53.444] iteration 6919 : model1 loss : 0.445408 model2 loss : 0.034134
[10:55:53.616] iteration 6920 : model1 loss : 0.440398 model2 loss : 0.034945
[10:55:53.784] iteration 6921 : model1 loss : 0.439735 model2 loss : 0.030530
[10:55:53.959] iteration 6922 : model1 loss : 0.438828 model2 loss : 0.027458
[10:55:54.128] iteration 6923 : model1 loss : 0.435360 model2 loss : 0.025203
[10:55:54.302] iteration 6924 : model1 loss : 0.436920 model2 loss : 0.030391
[10:55:54.474] iteration 6925 : model1 loss : 0.441991 model2 loss : 0.033575
[10:55:54.646] iteration 6926 : model1 loss : 0.433193 model2 loss : 0.023990
[10:55:54.813] iteration 6927 : model1 loss : 0.440123 model2 loss : 0.026611
[10:55:54.993] iteration 6928 : model1 loss : 0.436843 model2 loss : 0.029074
[10:55:55.161] iteration 6929 : model1 loss : 0.434685 model2 loss : 0.028988
[10:55:55.333] iteration 6930 : model1 loss : 0.431151 model2 loss : 0.024966
[10:55:57.310] iteration 6931 : model1 loss : 0.442462 model2 loss : 0.027426
[10:55:57.482] iteration 6932 : model1 loss : 0.439414 model2 loss : 0.029134
[10:55:57.657] iteration 6933 : model1 loss : 0.438108 model2 loss : 0.027162
[10:55:57.826] iteration 6934 : model1 loss : 0.437412 model2 loss : 0.031403
[10:55:58.002] iteration 6935 : model1 loss : 0.437869 model2 loss : 0.029802
[10:55:58.171] iteration 6936 : model1 loss : 0.442366 model2 loss : 0.033140
[10:55:58.345] iteration 6937 : model1 loss : 0.439322 model2 loss : 0.026660
[10:55:58.520] iteration 6938 : model1 loss : 0.432411 model2 loss : 0.024001
[10:55:58.693] iteration 6939 : model1 loss : 0.439564 model2 loss : 0.024939
[10:55:58.863] iteration 6940 : model1 loss : 0.435861 model2 loss : 0.028933
[10:55:59.040] iteration 6941 : model1 loss : 0.441080 model2 loss : 0.026894
[10:55:59.207] iteration 6942 : model1 loss : 0.438966 model2 loss : 0.027514
[10:55:59.384] iteration 6943 : model1 loss : 0.439034 model2 loss : 0.025860
[10:55:59.553] iteration 6944 : model1 loss : 0.437679 model2 loss : 0.028666
[10:55:59.728] iteration 6945 : model1 loss : 0.441095 model2 loss : 0.035286
[10:55:59.902] iteration 6946 : model1 loss : 0.437127 model2 loss : 0.029737
[10:56:00.076] iteration 6947 : model1 loss : 0.436599 model2 loss : 0.029427
[10:56:00.250] iteration 6948 : model1 loss : 0.441983 model2 loss : 0.039966
[10:56:00.427] iteration 6949 : model1 loss : 0.436961 model2 loss : 0.032558
[10:56:00.597] iteration 6950 : model1 loss : 0.434900 model2 loss : 0.026732
[10:56:00.770] iteration 6951 : model1 loss : 0.435555 model2 loss : 0.029217
[10:56:00.947] iteration 6952 : model1 loss : 0.436663 model2 loss : 0.025886
[10:56:01.119] iteration 6953 : model1 loss : 0.434292 model2 loss : 0.030579
[10:56:01.287] iteration 6954 : model1 loss : 0.437756 model2 loss : 0.028682
[10:56:01.461] iteration 6955 : model1 loss : 0.447335 model2 loss : 0.042371
[10:56:01.631] iteration 6956 : model1 loss : 0.439711 model2 loss : 0.031575
[10:56:01.804] iteration 6957 : model1 loss : 0.441027 model2 loss : 0.029201
[10:56:01.975] iteration 6958 : model1 loss : 0.437976 model2 loss : 0.027736
[10:56:02.149] iteration 6959 : model1 loss : 0.435084 model2 loss : 0.028909
[10:56:02.317] iteration 6960 : model1 loss : 0.440908 model2 loss : 0.032460
[10:56:02.494] iteration 6961 : model1 loss : 0.442148 model2 loss : 0.031311
[10:56:02.663] iteration 6962 : model1 loss : 0.437293 model2 loss : 0.027253
[10:56:02.834] iteration 6963 : model1 loss : 0.438534 model2 loss : 0.029230
[10:56:04.783] iteration 6964 : model1 loss : 0.436691 model2 loss : 0.029779
[10:56:04.954] iteration 6965 : model1 loss : 0.439198 model2 loss : 0.027045
[10:56:05.130] iteration 6966 : model1 loss : 0.435715 model2 loss : 0.025043
[10:56:05.299] iteration 6967 : model1 loss : 0.439835 model2 loss : 0.030547
[10:56:05.473] iteration 6968 : model1 loss : 0.431354 model2 loss : 0.026824
[10:56:05.642] iteration 6969 : model1 loss : 0.444677 model2 loss : 0.031311
[10:56:05.815] iteration 6970 : model1 loss : 0.439897 model2 loss : 0.032242
[10:56:05.987] iteration 6971 : model1 loss : 0.436318 model2 loss : 0.030648
[10:56:06.160] iteration 6972 : model1 loss : 0.437724 model2 loss : 0.028593
[10:56:06.328] iteration 6973 : model1 loss : 0.437483 model2 loss : 0.030673
[10:56:06.505] iteration 6974 : model1 loss : 0.439331 model2 loss : 0.031956
[10:56:06.676] iteration 6975 : model1 loss : 0.436939 model2 loss : 0.031300
[10:56:06.849] iteration 6976 : model1 loss : 0.435847 model2 loss : 0.033326
[10:56:07.021] iteration 6977 : model1 loss : 0.441117 model2 loss : 0.031609
[10:56:07.194] iteration 6978 : model1 loss : 0.440039 model2 loss : 0.026128
[10:56:07.364] iteration 6979 : model1 loss : 0.439457 model2 loss : 0.030423
[10:56:07.539] iteration 6980 : model1 loss : 0.438551 model2 loss : 0.028452
[10:56:07.708] iteration 6981 : model1 loss : 0.434141 model2 loss : 0.029217
[10:56:07.882] iteration 6982 : model1 loss : 0.445483 model2 loss : 0.035472
[10:56:08.052] iteration 6983 : model1 loss : 0.437720 model2 loss : 0.027543
[10:56:08.227] iteration 6984 : model1 loss : 0.441969 model2 loss : 0.036778
[10:56:08.398] iteration 6985 : model1 loss : 0.438639 model2 loss : 0.028776
[10:56:08.575] iteration 6986 : model1 loss : 0.433903 model2 loss : 0.029658
[10:56:08.745] iteration 6987 : model1 loss : 0.435151 model2 loss : 0.024842
[10:56:08.925] iteration 6988 : model1 loss : 0.435793 model2 loss : 0.029052
[10:56:09.095] iteration 6989 : model1 loss : 0.438171 model2 loss : 0.027732
[10:56:09.269] iteration 6990 : model1 loss : 0.440134 model2 loss : 0.031773
[10:56:09.441] iteration 6991 : model1 loss : 0.436299 model2 loss : 0.029026
[10:56:09.616] iteration 6992 : model1 loss : 0.440097 model2 loss : 0.029582
[10:56:09.784] iteration 6993 : model1 loss : 0.438788 model2 loss : 0.027222
[10:56:09.960] iteration 6994 : model1 loss : 0.440657 model2 loss : 0.035186
[10:56:10.128] iteration 6995 : model1 loss : 0.438773 model2 loss : 0.031927
[10:56:10.300] iteration 6996 : model1 loss : 0.437770 model2 loss : 0.034666
[10:56:12.288] iteration 6997 : model1 loss : 0.441693 model2 loss : 0.027860
[10:56:12.464] iteration 6998 : model1 loss : 0.440666 model2 loss : 0.031765
[10:56:12.641] iteration 6999 : model1 loss : 0.436155 model2 loss : 0.027404
[10:56:12.812] iteration 7000 : model1 loss : 0.435919 model2 loss : 0.026933
[10:56:21.296] iteration 7000 : model1_mean_dice : 0.866454 model1_mean_hd95 : 3.128442
[10:56:30.673] iteration 7000 : model2_mean_dice : 0.855335 model2_mean_hd95 : 19.548541
[10:56:30.852] iteration 7001 : model1 loss : 0.438212 model2 loss : 0.029903
[10:56:31.029] iteration 7002 : model1 loss : 0.439502 model2 loss : 0.029397
[10:56:31.195] iteration 7003 : model1 loss : 0.433552 model2 loss : 0.026536
[10:56:31.363] iteration 7004 : model1 loss : 0.437864 model2 loss : 0.028083
[10:56:31.530] iteration 7005 : model1 loss : 0.437861 model2 loss : 0.031581
[10:56:31.696] iteration 7006 : model1 loss : 0.438795 model2 loss : 0.030859
[10:56:31.862] iteration 7007 : model1 loss : 0.437972 model2 loss : 0.027359
[10:56:32.027] iteration 7008 : model1 loss : 0.439977 model2 loss : 0.029664
[10:56:32.194] iteration 7009 : model1 loss : 0.438776 model2 loss : 0.034212
[10:56:32.363] iteration 7010 : model1 loss : 0.437265 model2 loss : 0.027176
[10:56:32.531] iteration 7011 : model1 loss : 0.444909 model2 loss : 0.034872
[10:56:32.716] iteration 7012 : model1 loss : 0.440552 model2 loss : 0.035644
[10:56:32.883] iteration 7013 : model1 loss : 0.435226 model2 loss : 0.028674
[10:56:33.051] iteration 7014 : model1 loss : 0.439884 model2 loss : 0.032080
[10:56:33.217] iteration 7015 : model1 loss : 0.434744 model2 loss : 0.025653
[10:56:33.386] iteration 7016 : model1 loss : 0.440806 model2 loss : 0.039070
[10:56:33.554] iteration 7017 : model1 loss : 0.438914 model2 loss : 0.028063
[10:56:33.721] iteration 7018 : model1 loss : 0.436870 model2 loss : 0.025786
[10:56:33.899] iteration 7019 : model1 loss : 0.437125 model2 loss : 0.032339
[10:56:34.069] iteration 7020 : model1 loss : 0.438215 model2 loss : 0.027944
[10:56:34.235] iteration 7021 : model1 loss : 0.437410 model2 loss : 0.028238
[10:56:34.402] iteration 7022 : model1 loss : 0.435530 model2 loss : 0.031139
[10:56:34.569] iteration 7023 : model1 loss : 0.440100 model2 loss : 0.034628
[10:56:34.737] iteration 7024 : model1 loss : 0.435499 model2 loss : 0.027577
[10:56:34.905] iteration 7025 : model1 loss : 0.441596 model2 loss : 0.029323
[10:56:35.073] iteration 7026 : model1 loss : 0.436805 model2 loss : 0.028410
[10:56:35.241] iteration 7027 : model1 loss : 0.435784 model2 loss : 0.030740
[10:56:35.409] iteration 7028 : model1 loss : 0.435660 model2 loss : 0.028748
[10:56:35.575] iteration 7029 : model1 loss : 0.439475 model2 loss : 0.034327
[10:56:37.510] iteration 7030 : model1 loss : 0.437760 model2 loss : 0.027036
[10:56:37.676] iteration 7031 : model1 loss : 0.440930 model2 loss : 0.028811
[10:56:37.850] iteration 7032 : model1 loss : 0.439681 model2 loss : 0.031588
[10:56:38.016] iteration 7033 : model1 loss : 0.439693 model2 loss : 0.032996
[10:56:38.186] iteration 7034 : model1 loss : 0.436791 model2 loss : 0.032070
[10:56:38.353] iteration 7035 : model1 loss : 0.432812 model2 loss : 0.027276
[10:56:38.522] iteration 7036 : model1 loss : 0.439835 model2 loss : 0.035750
[10:56:38.688] iteration 7037 : model1 loss : 0.441706 model2 loss : 0.030244
[10:56:38.856] iteration 7038 : model1 loss : 0.437527 model2 loss : 0.029177
[10:56:39.023] iteration 7039 : model1 loss : 0.439808 model2 loss : 0.033639
[10:56:39.192] iteration 7040 : model1 loss : 0.435920 model2 loss : 0.029018
[10:56:39.359] iteration 7041 : model1 loss : 0.438576 model2 loss : 0.029788
[10:56:39.528] iteration 7042 : model1 loss : 0.435932 model2 loss : 0.028127
[10:56:39.694] iteration 7043 : model1 loss : 0.434452 model2 loss : 0.028854
[10:56:39.864] iteration 7044 : model1 loss : 0.435477 model2 loss : 0.029859
[10:56:40.030] iteration 7045 : model1 loss : 0.435021 model2 loss : 0.027592
[10:56:40.199] iteration 7046 : model1 loss : 0.438853 model2 loss : 0.029319
[10:56:40.365] iteration 7047 : model1 loss : 0.435666 model2 loss : 0.028159
[10:56:40.536] iteration 7048 : model1 loss : 0.437548 model2 loss : 0.025355
[10:56:40.700] iteration 7049 : model1 loss : 0.437557 model2 loss : 0.028380
[10:56:40.872] iteration 7050 : model1 loss : 0.441106 model2 loss : 0.033568
[10:56:41.040] iteration 7051 : model1 loss : 0.438501 model2 loss : 0.026900
[10:56:41.208] iteration 7052 : model1 loss : 0.434455 model2 loss : 0.037493
[10:56:41.374] iteration 7053 : model1 loss : 0.433712 model2 loss : 0.027276
[10:56:41.540] iteration 7054 : model1 loss : 0.436638 model2 loss : 0.026225
[10:56:41.706] iteration 7055 : model1 loss : 0.437332 model2 loss : 0.025213
[10:56:41.875] iteration 7056 : model1 loss : 0.434141 model2 loss : 0.021920
[10:56:42.043] iteration 7057 : model1 loss : 0.437719 model2 loss : 0.027001
[10:56:42.211] iteration 7058 : model1 loss : 0.438701 model2 loss : 0.027739
[10:56:42.378] iteration 7059 : model1 loss : 0.441860 model2 loss : 0.031142
[10:56:42.547] iteration 7060 : model1 loss : 0.443501 model2 loss : 0.034760
[10:56:42.713] iteration 7061 : model1 loss : 0.441543 model2 loss : 0.028406
[10:56:42.880] iteration 7062 : model1 loss : 0.439362 model2 loss : 0.030467
[10:56:44.823] iteration 7063 : model1 loss : 0.438809 model2 loss : 0.033206
[10:56:44.992] iteration 7064 : model1 loss : 0.433914 model2 loss : 0.030100
[10:56:45.162] iteration 7065 : model1 loss : 0.439405 model2 loss : 0.029831
[10:56:45.329] iteration 7066 : model1 loss : 0.438874 model2 loss : 0.030989
[10:56:45.499] iteration 7067 : model1 loss : 0.437210 model2 loss : 0.026986
[10:56:45.665] iteration 7068 : model1 loss : 0.436508 model2 loss : 0.026249
[10:56:45.834] iteration 7069 : model1 loss : 0.436434 model2 loss : 0.029144
[10:56:45.999] iteration 7070 : model1 loss : 0.433536 model2 loss : 0.026474
[10:56:46.169] iteration 7071 : model1 loss : 0.434247 model2 loss : 0.023820
[10:56:46.335] iteration 7072 : model1 loss : 0.441804 model2 loss : 0.032482
[10:56:46.504] iteration 7073 : model1 loss : 0.436145 model2 loss : 0.027724
[10:56:46.671] iteration 7074 : model1 loss : 0.439109 model2 loss : 0.028360
[10:56:46.841] iteration 7075 : model1 loss : 0.439481 model2 loss : 0.031133
[10:56:47.007] iteration 7076 : model1 loss : 0.437823 model2 loss : 0.033190
[10:56:47.175] iteration 7077 : model1 loss : 0.442010 model2 loss : 0.027950
[10:56:47.341] iteration 7078 : model1 loss : 0.436520 model2 loss : 0.029137
[10:56:47.512] iteration 7079 : model1 loss : 0.441463 model2 loss : 0.028023
[10:56:47.676] iteration 7080 : model1 loss : 0.440261 model2 loss : 0.034255
[10:56:47.844] iteration 7081 : model1 loss : 0.438687 model2 loss : 0.026743
[10:56:48.009] iteration 7082 : model1 loss : 0.436402 model2 loss : 0.030565
[10:56:48.177] iteration 7083 : model1 loss : 0.436724 model2 loss : 0.025170
[10:56:48.342] iteration 7084 : model1 loss : 0.437133 model2 loss : 0.028242
[10:56:48.513] iteration 7085 : model1 loss : 0.435221 model2 loss : 0.025427
[10:56:48.680] iteration 7086 : model1 loss : 0.439866 model2 loss : 0.031713
[10:56:48.849] iteration 7087 : model1 loss : 0.438388 model2 loss : 0.030678
[10:56:49.014] iteration 7088 : model1 loss : 0.442307 model2 loss : 0.033764
[10:56:49.183] iteration 7089 : model1 loss : 0.441012 model2 loss : 0.027807
[10:56:49.349] iteration 7090 : model1 loss : 0.442624 model2 loss : 0.028250
[10:56:49.519] iteration 7091 : model1 loss : 0.437782 model2 loss : 0.027116
[10:56:49.686] iteration 7092 : model1 loss : 0.439194 model2 loss : 0.029978
[10:56:49.852] iteration 7093 : model1 loss : 0.432620 model2 loss : 0.023076
[10:56:50.017] iteration 7094 : model1 loss : 0.435954 model2 loss : 0.023668
[10:56:50.184] iteration 7095 : model1 loss : 0.437442 model2 loss : 0.029422
[10:56:52.149] iteration 7096 : model1 loss : 0.440413 model2 loss : 0.028593
[10:56:52.320] iteration 7097 : model1 loss : 0.441562 model2 loss : 0.026515
[10:56:52.490] iteration 7098 : model1 loss : 0.442335 model2 loss : 0.027696
[10:56:52.656] iteration 7099 : model1 loss : 0.443695 model2 loss : 0.032834
[10:56:52.826] iteration 7100 : model1 loss : 0.436435 model2 loss : 0.026153
[10:56:52.992] iteration 7101 : model1 loss : 0.434248 model2 loss : 0.024783
[10:56:53.161] iteration 7102 : model1 loss : 0.442038 model2 loss : 0.037611
[10:56:53.327] iteration 7103 : model1 loss : 0.437082 model2 loss : 0.028305
[10:56:53.498] iteration 7104 : model1 loss : 0.438324 model2 loss : 0.027254
[10:56:53.665] iteration 7105 : model1 loss : 0.443435 model2 loss : 0.031724
[10:56:53.833] iteration 7106 : model1 loss : 0.441581 model2 loss : 0.028777
[10:56:54.001] iteration 7107 : model1 loss : 0.436604 model2 loss : 0.028024
[10:56:54.169] iteration 7108 : model1 loss : 0.432037 model2 loss : 0.025085
[10:56:54.337] iteration 7109 : model1 loss : 0.439353 model2 loss : 0.027538
[10:56:54.508] iteration 7110 : model1 loss : 0.439813 model2 loss : 0.029347
[10:56:54.673] iteration 7111 : model1 loss : 0.436574 model2 loss : 0.029077
[10:56:54.841] iteration 7112 : model1 loss : 0.443413 model2 loss : 0.030873
[10:56:55.012] iteration 7113 : model1 loss : 0.442898 model2 loss : 0.035448
[10:56:55.180] iteration 7114 : model1 loss : 0.437950 model2 loss : 0.026609
[10:56:55.348] iteration 7115 : model1 loss : 0.442327 model2 loss : 0.031597
[10:56:55.518] iteration 7116 : model1 loss : 0.435307 model2 loss : 0.027877
[10:56:55.685] iteration 7117 : model1 loss : 0.442933 model2 loss : 0.029893
[10:56:55.854] iteration 7118 : model1 loss : 0.443001 model2 loss : 0.035658
[10:56:56.024] iteration 7119 : model1 loss : 0.436680 model2 loss : 0.026334
[10:56:56.191] iteration 7120 : model1 loss : 0.434207 model2 loss : 0.028164
[10:56:56.357] iteration 7121 : model1 loss : 0.432483 model2 loss : 0.026874
[10:56:56.525] iteration 7122 : model1 loss : 0.434986 model2 loss : 0.024157
[10:56:56.692] iteration 7123 : model1 loss : 0.437759 model2 loss : 0.025327
[10:56:56.861] iteration 7124 : model1 loss : 0.447480 model2 loss : 0.034848
[10:56:57.030] iteration 7125 : model1 loss : 0.436402 model2 loss : 0.030998
[10:56:57.199] iteration 7126 : model1 loss : 0.435750 model2 loss : 0.026131
[10:56:57.364] iteration 7127 : model1 loss : 0.440084 model2 loss : 0.032650
[10:56:57.533] iteration 7128 : model1 loss : 0.441576 model2 loss : 0.030585
[10:56:59.484] iteration 7129 : model1 loss : 0.441388 model2 loss : 0.030648
[10:56:59.651] iteration 7130 : model1 loss : 0.431637 model2 loss : 0.022830
[10:56:59.819] iteration 7131 : model1 loss : 0.441726 model2 loss : 0.032434
[10:56:59.984] iteration 7132 : model1 loss : 0.436400 model2 loss : 0.029050
[10:57:00.153] iteration 7133 : model1 loss : 0.439358 model2 loss : 0.030225
[10:57:00.320] iteration 7134 : model1 loss : 0.439823 model2 loss : 0.028228
[10:57:00.489] iteration 7135 : model1 loss : 0.438429 model2 loss : 0.031163
[10:57:00.655] iteration 7136 : model1 loss : 0.434483 model2 loss : 0.027637
[10:57:00.827] iteration 7137 : model1 loss : 0.434549 model2 loss : 0.027204
[10:57:00.992] iteration 7138 : model1 loss : 0.436148 model2 loss : 0.024014
[10:57:01.160] iteration 7139 : model1 loss : 0.442623 model2 loss : 0.030748
[10:57:01.327] iteration 7140 : model1 loss : 0.435813 model2 loss : 0.026624
[10:57:01.496] iteration 7141 : model1 loss : 0.439824 model2 loss : 0.029790
[10:57:01.664] iteration 7142 : model1 loss : 0.439885 model2 loss : 0.028745
[10:57:01.834] iteration 7143 : model1 loss : 0.439338 model2 loss : 0.025835
[10:57:02.002] iteration 7144 : model1 loss : 0.435663 model2 loss : 0.028483
[10:57:02.171] iteration 7145 : model1 loss : 0.440806 model2 loss : 0.030568
[10:57:02.337] iteration 7146 : model1 loss : 0.442207 model2 loss : 0.030693
[10:57:02.509] iteration 7147 : model1 loss : 0.434449 model2 loss : 0.030709
[10:57:02.674] iteration 7148 : model1 loss : 0.441104 model2 loss : 0.033359
[10:57:02.844] iteration 7149 : model1 loss : 0.440528 model2 loss : 0.027013
[10:57:03.010] iteration 7150 : model1 loss : 0.436852 model2 loss : 0.026699
[10:57:03.202] iteration 7151 : model1 loss : 0.441426 model2 loss : 0.028631
[10:57:03.370] iteration 7152 : model1 loss : 0.437248 model2 loss : 0.028714
[10:57:03.541] iteration 7153 : model1 loss : 0.441161 model2 loss : 0.031300
[10:57:03.708] iteration 7154 : model1 loss : 0.437843 model2 loss : 0.028717
[10:57:03.877] iteration 7155 : model1 loss : 0.440095 model2 loss : 0.031587
[10:57:04.047] iteration 7156 : model1 loss : 0.436858 model2 loss : 0.028020
[10:57:04.216] iteration 7157 : model1 loss : 0.436448 model2 loss : 0.027839
[10:57:04.384] iteration 7158 : model1 loss : 0.435652 model2 loss : 0.023568
[10:57:04.554] iteration 7159 : model1 loss : 0.439014 model2 loss : 0.025766
[10:57:04.719] iteration 7160 : model1 loss : 0.433692 model2 loss : 0.027937
[10:57:04.887] iteration 7161 : model1 loss : 0.435613 model2 loss : 0.027372
[10:57:06.859] iteration 7162 : model1 loss : 0.440203 model2 loss : 0.032453
[10:57:07.030] iteration 7163 : model1 loss : 0.435501 model2 loss : 0.027697
[10:57:07.200] iteration 7164 : model1 loss : 0.438219 model2 loss : 0.026454
[10:57:07.365] iteration 7165 : model1 loss : 0.436935 model2 loss : 0.028392
[10:57:07.538] iteration 7166 : model1 loss : 0.439460 model2 loss : 0.029000
[10:57:07.707] iteration 7167 : model1 loss : 0.434303 model2 loss : 0.025410
[10:57:07.876] iteration 7168 : model1 loss : 0.432579 model2 loss : 0.025579
[10:57:08.045] iteration 7169 : model1 loss : 0.438065 model2 loss : 0.027075
[10:57:08.213] iteration 7170 : model1 loss : 0.439557 model2 loss : 0.026337
[10:57:08.379] iteration 7171 : model1 loss : 0.439128 model2 loss : 0.031400
[10:57:08.549] iteration 7172 : model1 loss : 0.438497 model2 loss : 0.028266
[10:57:08.714] iteration 7173 : model1 loss : 0.442727 model2 loss : 0.034621
[10:57:08.883] iteration 7174 : model1 loss : 0.438500 model2 loss : 0.027254
[10:57:09.054] iteration 7175 : model1 loss : 0.437439 model2 loss : 0.027468
[10:57:09.223] iteration 7176 : model1 loss : 0.438781 model2 loss : 0.028464
[10:57:09.392] iteration 7177 : model1 loss : 0.436183 model2 loss : 0.025326
[10:57:09.558] iteration 7178 : model1 loss : 0.433798 model2 loss : 0.023550
[10:57:09.725] iteration 7179 : model1 loss : 0.440236 model2 loss : 0.032721
[10:57:09.894] iteration 7180 : model1 loss : 0.437739 model2 loss : 0.027999
[10:57:10.067] iteration 7181 : model1 loss : 0.435563 model2 loss : 0.027721
[10:57:10.235] iteration 7182 : model1 loss : 0.444747 model2 loss : 0.034903
[10:57:10.403] iteration 7183 : model1 loss : 0.439533 model2 loss : 0.030422
[10:57:10.574] iteration 7184 : model1 loss : 0.442150 model2 loss : 0.026179
[10:57:10.740] iteration 7185 : model1 loss : 0.440664 model2 loss : 0.029974
[10:57:10.911] iteration 7186 : model1 loss : 0.437313 model2 loss : 0.026599
[10:57:11.080] iteration 7187 : model1 loss : 0.434412 model2 loss : 0.029465
[10:57:11.252] iteration 7188 : model1 loss : 0.434082 model2 loss : 0.022474
[10:57:11.419] iteration 7189 : model1 loss : 0.439637 model2 loss : 0.031921
[10:57:11.588] iteration 7190 : model1 loss : 0.443079 model2 loss : 0.032227
[10:57:11.754] iteration 7191 : model1 loss : 0.439905 model2 loss : 0.029894
[10:57:11.924] iteration 7192 : model1 loss : 0.437470 model2 loss : 0.028741
[10:57:12.089] iteration 7193 : model1 loss : 0.441475 model2 loss : 0.031724
[10:57:12.255] iteration 7194 : model1 loss : 0.441562 model2 loss : 0.034056
[10:57:14.166] iteration 7195 : model1 loss : 0.443631 model2 loss : 0.024313
[10:57:14.332] iteration 7196 : model1 loss : 0.438250 model2 loss : 0.027798
[10:57:14.504] iteration 7197 : model1 loss : 0.436582 model2 loss : 0.031967
[10:57:14.670] iteration 7198 : model1 loss : 0.435533 model2 loss : 0.024483
[10:57:14.839] iteration 7199 : model1 loss : 0.443421 model2 loss : 0.036545
[10:57:15.007] iteration 7200 : model1 loss : 0.439594 model2 loss : 0.029128
[10:57:15.176] iteration 7201 : model1 loss : 0.439764 model2 loss : 0.030825
[10:57:15.343] iteration 7202 : model1 loss : 0.436859 model2 loss : 0.025038
[10:57:15.516] iteration 7203 : model1 loss : 0.436727 model2 loss : 0.025610
[10:57:15.683] iteration 7204 : model1 loss : 0.437689 model2 loss : 0.030730
[10:57:15.855] iteration 7205 : model1 loss : 0.437513 model2 loss : 0.028086
[10:57:16.022] iteration 7206 : model1 loss : 0.433614 model2 loss : 0.026703
[10:57:16.192] iteration 7207 : model1 loss : 0.440376 model2 loss : 0.027343
[10:57:16.359] iteration 7208 : model1 loss : 0.437163 model2 loss : 0.025275
[10:57:16.531] iteration 7209 : model1 loss : 0.443897 model2 loss : 0.025737
[10:57:16.700] iteration 7210 : model1 loss : 0.437703 model2 loss : 0.027069
[10:57:16.867] iteration 7211 : model1 loss : 0.438639 model2 loss : 0.029337
[10:57:17.035] iteration 7212 : model1 loss : 0.439638 model2 loss : 0.028583
[10:57:17.204] iteration 7213 : model1 loss : 0.436590 model2 loss : 0.026639
[10:57:17.371] iteration 7214 : model1 loss : 0.438682 model2 loss : 0.029859
[10:57:17.540] iteration 7215 : model1 loss : 0.439561 model2 loss : 0.029182
[10:57:17.706] iteration 7216 : model1 loss : 0.437134 model2 loss : 0.025540
[10:57:17.875] iteration 7217 : model1 loss : 0.443319 model2 loss : 0.033696
[10:57:18.042] iteration 7218 : model1 loss : 0.438080 model2 loss : 0.032205
[10:57:18.212] iteration 7219 : model1 loss : 0.436878 model2 loss : 0.027654
[10:57:18.380] iteration 7220 : model1 loss : 0.439788 model2 loss : 0.028019
[10:57:18.550] iteration 7221 : model1 loss : 0.435638 model2 loss : 0.028961
[10:57:18.720] iteration 7222 : model1 loss : 0.432882 model2 loss : 0.027903
[10:57:18.887] iteration 7223 : model1 loss : 0.436220 model2 loss : 0.026004
[10:57:19.052] iteration 7224 : model1 loss : 0.439568 model2 loss : 0.031838
[10:57:19.220] iteration 7225 : model1 loss : 0.436186 model2 loss : 0.027192
[10:57:19.385] iteration 7226 : model1 loss : 0.432372 model2 loss : 0.024135
[10:57:19.553] iteration 7227 : model1 loss : 0.442573 model2 loss : 0.030618
[10:57:21.497] iteration 7228 : model1 loss : 0.441195 model2 loss : 0.032418
[10:57:21.673] iteration 7229 : model1 loss : 0.434178 model2 loss : 0.023710
[10:57:21.844] iteration 7230 : model1 loss : 0.436833 model2 loss : 0.029251
[10:57:22.011] iteration 7231 : model1 loss : 0.437286 model2 loss : 0.029230
[10:57:22.179] iteration 7232 : model1 loss : 0.434914 model2 loss : 0.022423
[10:57:22.347] iteration 7233 : model1 loss : 0.436860 model2 loss : 0.028762
[10:57:22.518] iteration 7234 : model1 loss : 0.438941 model2 loss : 0.027269
[10:57:22.687] iteration 7235 : model1 loss : 0.437948 model2 loss : 0.024095
[10:57:22.857] iteration 7236 : model1 loss : 0.441019 model2 loss : 0.026436
[10:57:23.023] iteration 7237 : model1 loss : 0.438661 model2 loss : 0.027343
[10:57:23.194] iteration 7238 : model1 loss : 0.438076 model2 loss : 0.027201
[10:57:23.362] iteration 7239 : model1 loss : 0.432764 model2 loss : 0.029687
[10:57:23.532] iteration 7240 : model1 loss : 0.438360 model2 loss : 0.028731
[10:57:23.698] iteration 7241 : model1 loss : 0.436592 model2 loss : 0.025004
[10:57:23.868] iteration 7242 : model1 loss : 0.438668 model2 loss : 0.028139
[10:57:24.035] iteration 7243 : model1 loss : 0.439797 model2 loss : 0.026479
[10:57:24.204] iteration 7244 : model1 loss : 0.434360 model2 loss : 0.030914
[10:57:24.372] iteration 7245 : model1 loss : 0.435104 model2 loss : 0.026806
[10:57:24.545] iteration 7246 : model1 loss : 0.435139 model2 loss : 0.028463
[10:57:24.712] iteration 7247 : model1 loss : 0.434959 model2 loss : 0.028731
[10:57:24.882] iteration 7248 : model1 loss : 0.439013 model2 loss : 0.028452
[10:57:25.049] iteration 7249 : model1 loss : 0.441938 model2 loss : 0.029979
[10:57:25.221] iteration 7250 : model1 loss : 0.436201 model2 loss : 0.028145
[10:57:25.387] iteration 7251 : model1 loss : 0.441460 model2 loss : 0.029434
[10:57:25.558] iteration 7252 : model1 loss : 0.435573 model2 loss : 0.028066
[10:57:25.725] iteration 7253 : model1 loss : 0.440613 model2 loss : 0.029039
[10:57:25.897] iteration 7254 : model1 loss : 0.442217 model2 loss : 0.028155
[10:57:26.063] iteration 7255 : model1 loss : 0.440614 model2 loss : 0.035984
[10:57:26.231] iteration 7256 : model1 loss : 0.439442 model2 loss : 0.025616
[10:57:26.396] iteration 7257 : model1 loss : 0.438477 model2 loss : 0.026363
[10:57:26.568] iteration 7258 : model1 loss : 0.436244 model2 loss : 0.029526
[10:57:26.734] iteration 7259 : model1 loss : 0.435884 model2 loss : 0.026937
[10:57:26.903] iteration 7260 : model1 loss : 0.438489 model2 loss : 0.029159
[10:57:28.818] iteration 7261 : model1 loss : 0.443537 model2 loss : 0.034969
[10:57:28.988] iteration 7262 : model1 loss : 0.442732 model2 loss : 0.027483
[10:57:29.161] iteration 7263 : model1 loss : 0.433943 model2 loss : 0.028997
[10:57:29.327] iteration 7264 : model1 loss : 0.435499 model2 loss : 0.024096
[10:57:29.497] iteration 7265 : model1 loss : 0.435840 model2 loss : 0.028228
[10:57:29.664] iteration 7266 : model1 loss : 0.433078 model2 loss : 0.029997
[10:57:29.833] iteration 7267 : model1 loss : 0.439175 model2 loss : 0.031184
[10:57:30.002] iteration 7268 : model1 loss : 0.434589 model2 loss : 0.025359
[10:57:30.188] iteration 7269 : model1 loss : 0.441401 model2 loss : 0.031213
[10:57:30.355] iteration 7270 : model1 loss : 0.440252 model2 loss : 0.027738
[10:57:30.529] iteration 7271 : model1 loss : 0.436699 model2 loss : 0.026419
[10:57:30.695] iteration 7272 : model1 loss : 0.433588 model2 loss : 0.025928
[10:57:30.868] iteration 7273 : model1 loss : 0.439595 model2 loss : 0.033869
[10:57:31.039] iteration 7274 : model1 loss : 0.437201 model2 loss : 0.025875
[10:57:31.210] iteration 7275 : model1 loss : 0.435531 model2 loss : 0.026201
[10:57:31.377] iteration 7276 : model1 loss : 0.434350 model2 loss : 0.024138
[10:57:31.547] iteration 7277 : model1 loss : 0.436577 model2 loss : 0.024991
[10:57:31.714] iteration 7278 : model1 loss : 0.437800 model2 loss : 0.028901
[10:57:31.881] iteration 7279 : model1 loss : 0.440958 model2 loss : 0.030071
[10:57:32.048] iteration 7280 : model1 loss : 0.436173 model2 loss : 0.024978
[10:57:32.217] iteration 7281 : model1 loss : 0.440416 model2 loss : 0.031272
[10:57:32.386] iteration 7282 : model1 loss : 0.440520 model2 loss : 0.030382
[10:57:32.554] iteration 7283 : model1 loss : 0.434630 model2 loss : 0.030372
[10:57:32.722] iteration 7284 : model1 loss : 0.437921 model2 loss : 0.026453
[10:57:32.891] iteration 7285 : model1 loss : 0.436895 model2 loss : 0.032220
[10:57:33.060] iteration 7286 : model1 loss : 0.433978 model2 loss : 0.024127
[10:57:33.230] iteration 7287 : model1 loss : 0.436462 model2 loss : 0.026955
[10:57:33.398] iteration 7288 : model1 loss : 0.434973 model2 loss : 0.027822
[10:57:33.567] iteration 7289 : model1 loss : 0.437599 model2 loss : 0.029476
[10:57:33.734] iteration 7290 : model1 loss : 0.441750 model2 loss : 0.029075
[10:57:33.905] iteration 7291 : model1 loss : 0.440623 model2 loss : 0.031405
[10:57:34.071] iteration 7292 : model1 loss : 0.439682 model2 loss : 0.029897
[10:57:34.239] iteration 7293 : model1 loss : 0.438789 model2 loss : 0.027384
[10:57:36.176] iteration 7294 : model1 loss : 0.437475 model2 loss : 0.030447
[10:57:36.346] iteration 7295 : model1 loss : 0.441346 model2 loss : 0.028695
[10:57:36.522] iteration 7296 : model1 loss : 0.435859 model2 loss : 0.026340
[10:57:36.691] iteration 7297 : model1 loss : 0.438726 model2 loss : 0.032859
[10:57:36.859] iteration 7298 : model1 loss : 0.438459 model2 loss : 0.030777
[10:57:37.026] iteration 7299 : model1 loss : 0.434684 model2 loss : 0.028423
[10:57:37.201] iteration 7300 : model1 loss : 0.436166 model2 loss : 0.027023
[10:57:37.369] iteration 7301 : model1 loss : 0.433541 model2 loss : 0.025072
[10:57:37.540] iteration 7302 : model1 loss : 0.441716 model2 loss : 0.038114
[10:57:37.705] iteration 7303 : model1 loss : 0.439035 model2 loss : 0.028448
[10:57:37.874] iteration 7304 : model1 loss : 0.433170 model2 loss : 0.026905
[10:57:38.041] iteration 7305 : model1 loss : 0.437249 model2 loss : 0.026137
[10:57:38.213] iteration 7306 : model1 loss : 0.442054 model2 loss : 0.039487
[10:57:38.381] iteration 7307 : model1 loss : 0.436261 model2 loss : 0.024862
[10:57:38.552] iteration 7308 : model1 loss : 0.437315 model2 loss : 0.025180
[10:57:38.719] iteration 7309 : model1 loss : 0.439928 model2 loss : 0.030895
[10:57:38.889] iteration 7310 : model1 loss : 0.434348 model2 loss : 0.028568
[10:57:39.054] iteration 7311 : model1 loss : 0.438369 model2 loss : 0.030682
[10:57:39.225] iteration 7312 : model1 loss : 0.437865 model2 loss : 0.029572
[10:57:39.392] iteration 7313 : model1 loss : 0.435602 model2 loss : 0.025827
[10:57:39.560] iteration 7314 : model1 loss : 0.438764 model2 loss : 0.028586
[10:57:39.726] iteration 7315 : model1 loss : 0.439294 model2 loss : 0.029428
[10:57:39.895] iteration 7316 : model1 loss : 0.439398 model2 loss : 0.028572
[10:57:40.063] iteration 7317 : model1 loss : 0.438684 model2 loss : 0.030296
[10:57:40.232] iteration 7318 : model1 loss : 0.434343 model2 loss : 0.025899
[10:57:40.400] iteration 7319 : model1 loss : 0.437357 model2 loss : 0.029587
[10:57:40.570] iteration 7320 : model1 loss : 0.438584 model2 loss : 0.028426
[10:57:40.737] iteration 7321 : model1 loss : 0.444233 model2 loss : 0.030173
[10:57:40.909] iteration 7322 : model1 loss : 0.439261 model2 loss : 0.027077
[10:57:41.076] iteration 7323 : model1 loss : 0.436770 model2 loss : 0.028599
[10:57:41.245] iteration 7324 : model1 loss : 0.441160 model2 loss : 0.031276
[10:57:41.410] iteration 7325 : model1 loss : 0.440812 model2 loss : 0.026671
[10:57:41.576] iteration 7326 : model1 loss : 0.438508 model2 loss : 0.029747
[10:57:43.503] iteration 7327 : model1 loss : 0.439494 model2 loss : 0.032506
[10:57:43.672] iteration 7328 : model1 loss : 0.433637 model2 loss : 0.030634
[10:57:43.844] iteration 7329 : model1 loss : 0.437793 model2 loss : 0.031468
[10:57:44.011] iteration 7330 : model1 loss : 0.436774 model2 loss : 0.026444
[10:57:44.181] iteration 7331 : model1 loss : 0.444811 model2 loss : 0.032343
[10:57:44.350] iteration 7332 : model1 loss : 0.434704 model2 loss : 0.025608
[10:57:44.521] iteration 7333 : model1 loss : 0.436835 model2 loss : 0.028149
[10:57:44.688] iteration 7334 : model1 loss : 0.445196 model2 loss : 0.036823
[10:57:44.858] iteration 7335 : model1 loss : 0.434583 model2 loss : 0.029313
[10:57:45.026] iteration 7336 : model1 loss : 0.435756 model2 loss : 0.028009
[10:57:45.201] iteration 7337 : model1 loss : 0.437483 model2 loss : 0.027477
[10:57:45.370] iteration 7338 : model1 loss : 0.434463 model2 loss : 0.026475
[10:57:45.540] iteration 7339 : model1 loss : 0.436226 model2 loss : 0.026417
[10:57:45.708] iteration 7340 : model1 loss : 0.435425 model2 loss : 0.028445
[10:57:45.881] iteration 7341 : model1 loss : 0.436997 model2 loss : 0.026647
[10:57:46.049] iteration 7342 : model1 loss : 0.443873 model2 loss : 0.033974
[10:57:46.222] iteration 7343 : model1 loss : 0.434895 model2 loss : 0.027162
[10:57:46.391] iteration 7344 : model1 loss : 0.430472 model2 loss : 0.023922
[10:57:46.561] iteration 7345 : model1 loss : 0.440281 model2 loss : 0.027872
[10:57:46.731] iteration 7346 : model1 loss : 0.440276 model2 loss : 0.025671
[10:57:46.900] iteration 7347 : model1 loss : 0.441185 model2 loss : 0.030330
[10:57:47.067] iteration 7348 : model1 loss : 0.440272 model2 loss : 0.031444
[10:57:47.235] iteration 7349 : model1 loss : 0.441050 model2 loss : 0.031202
[10:57:47.402] iteration 7350 : model1 loss : 0.440433 model2 loss : 0.029210
[10:57:47.575] iteration 7351 : model1 loss : 0.434547 model2 loss : 0.026070
[10:57:47.742] iteration 7352 : model1 loss : 0.436723 model2 loss : 0.027398
[10:57:47.913] iteration 7353 : model1 loss : 0.438395 model2 loss : 0.034046
[10:57:48.080] iteration 7354 : model1 loss : 0.434996 model2 loss : 0.026383
[10:57:48.252] iteration 7355 : model1 loss : 0.444780 model2 loss : 0.038735
[10:57:48.420] iteration 7356 : model1 loss : 0.438562 model2 loss : 0.031192
[10:57:48.589] iteration 7357 : model1 loss : 0.439748 model2 loss : 0.027972
[10:57:48.756] iteration 7358 : model1 loss : 0.438205 model2 loss : 0.027110
[10:57:48.924] iteration 7359 : model1 loss : 0.439605 model2 loss : 0.028224
[10:57:50.982] iteration 7360 : model1 loss : 0.439556 model2 loss : 0.025910
[10:57:51.149] iteration 7361 : model1 loss : 0.440534 model2 loss : 0.032573
[10:57:51.321] iteration 7362 : model1 loss : 0.435343 model2 loss : 0.032116
[10:57:51.491] iteration 7363 : model1 loss : 0.434125 model2 loss : 0.028704
[10:57:51.659] iteration 7364 : model1 loss : 0.439044 model2 loss : 0.028689
[10:57:51.826] iteration 7365 : model1 loss : 0.434655 model2 loss : 0.026761
[10:57:51.994] iteration 7366 : model1 loss : 0.435521 model2 loss : 0.025651
[10:57:52.163] iteration 7367 : model1 loss : 0.437592 model2 loss : 0.029010
[10:57:52.332] iteration 7368 : model1 loss : 0.439004 model2 loss : 0.028399
[10:57:52.501] iteration 7369 : model1 loss : 0.436550 model2 loss : 0.029607
[10:57:52.670] iteration 7370 : model1 loss : 0.435290 model2 loss : 0.026391
[10:57:52.837] iteration 7371 : model1 loss : 0.434218 model2 loss : 0.025289
[10:57:53.005] iteration 7372 : model1 loss : 0.440066 model2 loss : 0.027542
[10:57:53.172] iteration 7373 : model1 loss : 0.438145 model2 loss : 0.032288
[10:57:53.342] iteration 7374 : model1 loss : 0.435782 model2 loss : 0.024107
[10:57:53.514] iteration 7375 : model1 loss : 0.441631 model2 loss : 0.039459
[10:57:53.682] iteration 7376 : model1 loss : 0.437899 model2 loss : 0.027716
[10:57:53.851] iteration 7377 : model1 loss : 0.437211 model2 loss : 0.028876
[10:57:54.021] iteration 7378 : model1 loss : 0.437164 model2 loss : 0.024783
[10:57:54.189] iteration 7379 : model1 loss : 0.437123 model2 loss : 0.027219
[10:57:54.359] iteration 7380 : model1 loss : 0.437221 model2 loss : 0.026389
[10:57:54.528] iteration 7381 : model1 loss : 0.439261 model2 loss : 0.030169
[10:57:54.711] iteration 7382 : model1 loss : 0.440054 model2 loss : 0.034875
[10:57:54.879] iteration 7383 : model1 loss : 0.438397 model2 loss : 0.026584
[10:57:55.048] iteration 7384 : model1 loss : 0.439738 model2 loss : 0.028720
[10:57:55.217] iteration 7385 : model1 loss : 0.442333 model2 loss : 0.030841
[10:57:55.387] iteration 7386 : model1 loss : 0.433966 model2 loss : 0.022718
[10:57:55.554] iteration 7387 : model1 loss : 0.439819 model2 loss : 0.028863
[10:57:55.721] iteration 7388 : model1 loss : 0.439449 model2 loss : 0.027734
[10:57:55.889] iteration 7389 : model1 loss : 0.440272 model2 loss : 0.035207
[10:57:56.057] iteration 7390 : model1 loss : 0.439083 model2 loss : 0.027181
[10:57:56.225] iteration 7391 : model1 loss : 0.438841 model2 loss : 0.029597
[10:57:56.392] iteration 7392 : model1 loss : 0.436017 model2 loss : 0.024850
[10:57:58.308] iteration 7393 : model1 loss : 0.439084 model2 loss : 0.027913
[10:57:58.479] iteration 7394 : model1 loss : 0.440895 model2 loss : 0.030068
[10:57:58.653] iteration 7395 : model1 loss : 0.436683 model2 loss : 0.028431
[10:57:58.820] iteration 7396 : model1 loss : 0.437671 model2 loss : 0.025940
[10:57:58.989] iteration 7397 : model1 loss : 0.436865 model2 loss : 0.029996
[10:57:59.158] iteration 7398 : model1 loss : 0.442239 model2 loss : 0.033991
[10:57:59.327] iteration 7399 : model1 loss : 0.438701 model2 loss : 0.026657
[10:57:59.496] iteration 7400 : model1 loss : 0.436409 model2 loss : 0.029188
[10:57:59.664] iteration 7401 : model1 loss : 0.437172 model2 loss : 0.026388
[10:57:59.832] iteration 7402 : model1 loss : 0.441325 model2 loss : 0.031576
[10:58:00.001] iteration 7403 : model1 loss : 0.439268 model2 loss : 0.034756
[10:58:00.170] iteration 7404 : model1 loss : 0.434672 model2 loss : 0.024077
[10:58:00.340] iteration 7405 : model1 loss : 0.434884 model2 loss : 0.027012
[10:58:00.509] iteration 7406 : model1 loss : 0.440118 model2 loss : 0.027505
[10:58:00.678] iteration 7407 : model1 loss : 0.436932 model2 loss : 0.027679
[10:58:00.850] iteration 7408 : model1 loss : 0.439812 model2 loss : 0.030212
[10:58:01.020] iteration 7409 : model1 loss : 0.432693 model2 loss : 0.025845
[10:58:01.188] iteration 7410 : model1 loss : 0.432606 model2 loss : 0.026041
[10:58:01.357] iteration 7411 : model1 loss : 0.439415 model2 loss : 0.029739
[10:58:01.528] iteration 7412 : model1 loss : 0.438410 model2 loss : 0.030873
[10:58:01.698] iteration 7413 : model1 loss : 0.438752 model2 loss : 0.029275
[10:58:01.865] iteration 7414 : model1 loss : 0.438855 model2 loss : 0.029015
[10:58:02.035] iteration 7415 : model1 loss : 0.438891 model2 loss : 0.027388
[10:58:02.203] iteration 7416 : model1 loss : 0.436527 model2 loss : 0.027014
[10:58:02.373] iteration 7417 : model1 loss : 0.440752 model2 loss : 0.033383
[10:58:02.539] iteration 7418 : model1 loss : 0.442132 model2 loss : 0.034732
[10:58:02.708] iteration 7419 : model1 loss : 0.433589 model2 loss : 0.024137
[10:58:02.876] iteration 7420 : model1 loss : 0.439511 model2 loss : 0.027361
[10:58:03.046] iteration 7421 : model1 loss : 0.443332 model2 loss : 0.035009
[10:58:03.216] iteration 7422 : model1 loss : 0.439994 model2 loss : 0.028885
[10:58:03.386] iteration 7423 : model1 loss : 0.438916 model2 loss : 0.025604
[10:58:03.551] iteration 7424 : model1 loss : 0.432850 model2 loss : 0.025775
[10:58:03.719] iteration 7425 : model1 loss : 0.431664 model2 loss : 0.032600
[10:58:05.651] iteration 7426 : model1 loss : 0.434134 model2 loss : 0.030883
[10:58:05.819] iteration 7427 : model1 loss : 0.437160 model2 loss : 0.029047
[10:58:05.988] iteration 7428 : model1 loss : 0.444622 model2 loss : 0.030282
[10:58:06.156] iteration 7429 : model1 loss : 0.442046 model2 loss : 0.031009
[10:58:06.325] iteration 7430 : model1 loss : 0.435108 model2 loss : 0.030384
[10:58:06.494] iteration 7431 : model1 loss : 0.435603 model2 loss : 0.027099
[10:58:06.663] iteration 7432 : model1 loss : 0.436271 model2 loss : 0.031168
[10:58:06.833] iteration 7433 : model1 loss : 0.443616 model2 loss : 0.032561
[10:58:07.001] iteration 7434 : model1 loss : 0.439973 model2 loss : 0.028650
[10:58:07.168] iteration 7435 : model1 loss : 0.437172 model2 loss : 0.028595
[10:58:07.339] iteration 7436 : model1 loss : 0.436434 model2 loss : 0.025204
[10:58:07.509] iteration 7437 : model1 loss : 0.437981 model2 loss : 0.030603
[10:58:07.677] iteration 7438 : model1 loss : 0.441338 model2 loss : 0.027291
[10:58:07.845] iteration 7439 : model1 loss : 0.438776 model2 loss : 0.026189
[10:58:08.012] iteration 7440 : model1 loss : 0.439524 model2 loss : 0.031528
[10:58:08.179] iteration 7441 : model1 loss : 0.434544 model2 loss : 0.026056
[10:58:08.345] iteration 7442 : model1 loss : 0.440347 model2 loss : 0.029540
[10:58:08.514] iteration 7443 : model1 loss : 0.438758 model2 loss : 0.028535
[10:58:08.681] iteration 7444 : model1 loss : 0.439488 model2 loss : 0.030822
[10:58:08.847] iteration 7445 : model1 loss : 0.441218 model2 loss : 0.031456
[10:58:09.016] iteration 7446 : model1 loss : 0.438912 model2 loss : 0.030844
[10:58:09.182] iteration 7447 : model1 loss : 0.434282 model2 loss : 0.028458
[10:58:09.350] iteration 7448 : model1 loss : 0.439544 model2 loss : 0.030751
[10:58:09.520] iteration 7449 : model1 loss : 0.440545 model2 loss : 0.028775
[10:58:09.689] iteration 7450 : model1 loss : 0.435811 model2 loss : 0.025273
[10:58:09.856] iteration 7451 : model1 loss : 0.434293 model2 loss : 0.028970
[10:58:10.025] iteration 7452 : model1 loss : 0.439287 model2 loss : 0.027258
[10:58:10.190] iteration 7453 : model1 loss : 0.435567 model2 loss : 0.029270
[10:58:10.383] iteration 7454 : model1 loss : 0.439201 model2 loss : 0.029068
[10:58:10.550] iteration 7455 : model1 loss : 0.444886 model2 loss : 0.030914
[10:58:10.720] iteration 7456 : model1 loss : 0.439074 model2 loss : 0.025911
[10:58:10.889] iteration 7457 : model1 loss : 0.433212 model2 loss : 0.025191
[10:58:11.055] iteration 7458 : model1 loss : 0.436988 model2 loss : 0.026418
[10:58:12.952] iteration 7459 : model1 loss : 0.438163 model2 loss : 0.024241
[10:58:13.120] iteration 7460 : model1 loss : 0.433642 model2 loss : 0.024884
[10:58:13.293] iteration 7461 : model1 loss : 0.438401 model2 loss : 0.029374
[10:58:13.461] iteration 7462 : model1 loss : 0.436144 model2 loss : 0.027022
[10:58:13.629] iteration 7463 : model1 loss : 0.436507 model2 loss : 0.025543
[10:58:13.796] iteration 7464 : model1 loss : 0.439427 model2 loss : 0.027234
[10:58:13.964] iteration 7465 : model1 loss : 0.443263 model2 loss : 0.031358
[10:58:14.131] iteration 7466 : model1 loss : 0.438894 model2 loss : 0.027508
[10:58:14.301] iteration 7467 : model1 loss : 0.438384 model2 loss : 0.024685
[10:58:14.467] iteration 7468 : model1 loss : 0.440933 model2 loss : 0.027648
[10:58:14.637] iteration 7469 : model1 loss : 0.439970 model2 loss : 0.033782
[10:58:14.803] iteration 7470 : model1 loss : 0.439202 model2 loss : 0.027443
[10:58:14.972] iteration 7471 : model1 loss : 0.438592 model2 loss : 0.025836
[10:58:15.140] iteration 7472 : model1 loss : 0.438822 model2 loss : 0.027746
[10:58:15.311] iteration 7473 : model1 loss : 0.438058 model2 loss : 0.029071
[10:58:15.478] iteration 7474 : model1 loss : 0.439410 model2 loss : 0.025767
[10:58:15.648] iteration 7475 : model1 loss : 0.434974 model2 loss : 0.026393
[10:58:15.815] iteration 7476 : model1 loss : 0.438651 model2 loss : 0.030055
[10:58:15.981] iteration 7477 : model1 loss : 0.436947 model2 loss : 0.027049
[10:58:16.148] iteration 7478 : model1 loss : 0.441166 model2 loss : 0.028370
[10:58:16.318] iteration 7479 : model1 loss : 0.440773 model2 loss : 0.028807
[10:58:16.485] iteration 7480 : model1 loss : 0.437181 model2 loss : 0.029058
[10:58:16.656] iteration 7481 : model1 loss : 0.440054 model2 loss : 0.027762
[10:58:16.822] iteration 7482 : model1 loss : 0.435583 model2 loss : 0.023896
[10:58:16.992] iteration 7483 : model1 loss : 0.435533 model2 loss : 0.026609
[10:58:17.160] iteration 7484 : model1 loss : 0.437974 model2 loss : 0.028164
[10:58:17.329] iteration 7485 : model1 loss : 0.437670 model2 loss : 0.027394
[10:58:17.506] iteration 7486 : model1 loss : 0.452060 model2 loss : 0.043908
[10:58:17.677] iteration 7487 : model1 loss : 0.439999 model2 loss : 0.028784
[10:58:17.845] iteration 7488 : model1 loss : 0.441934 model2 loss : 0.034087
[10:58:18.013] iteration 7489 : model1 loss : 0.438149 model2 loss : 0.027863
[10:58:18.179] iteration 7490 : model1 loss : 0.438861 model2 loss : 0.032951
[10:58:18.348] iteration 7491 : model1 loss : 0.436425 model2 loss : 0.026711
[10:58:20.265] iteration 7492 : model1 loss : 0.436904 model2 loss : 0.028737
[10:58:20.433] iteration 7493 : model1 loss : 0.440433 model2 loss : 0.030860
[10:58:20.605] iteration 7494 : model1 loss : 0.437800 model2 loss : 0.026204
[10:58:20.774] iteration 7495 : model1 loss : 0.438187 model2 loss : 0.025616
[10:58:20.943] iteration 7496 : model1 loss : 0.440878 model2 loss : 0.031770
[10:58:21.113] iteration 7497 : model1 loss : 0.434895 model2 loss : 0.026540
[10:58:21.285] iteration 7498 : model1 loss : 0.431608 model2 loss : 0.025612
[10:58:21.452] iteration 7499 : model1 loss : 0.433278 model2 loss : 0.027444
[10:58:21.620] iteration 7500 : model1 loss : 0.439517 model2 loss : 0.032912
[10:58:21.788] iteration 7501 : model1 loss : 0.434524 model2 loss : 0.027132
[10:58:21.956] iteration 7502 : model1 loss : 0.437764 model2 loss : 0.038547
[10:58:22.121] iteration 7503 : model1 loss : 0.435907 model2 loss : 0.031450
[10:58:22.292] iteration 7504 : model1 loss : 0.436538 model2 loss : 0.025854
[10:58:22.458] iteration 7505 : model1 loss : 0.438015 model2 loss : 0.034466
[10:58:22.628] iteration 7506 : model1 loss : 0.440232 model2 loss : 0.029660
[10:58:22.793] iteration 7507 : model1 loss : 0.438015 model2 loss : 0.034183
[10:58:22.962] iteration 7508 : model1 loss : 0.435532 model2 loss : 0.024071
[10:58:23.129] iteration 7509 : model1 loss : 0.440768 model2 loss : 0.030632
[10:58:23.299] iteration 7510 : model1 loss : 0.441902 model2 loss : 0.037641
[10:58:23.465] iteration 7511 : model1 loss : 0.440172 model2 loss : 0.029529
[10:58:23.632] iteration 7512 : model1 loss : 0.442207 model2 loss : 0.024754
[10:58:23.798] iteration 7513 : model1 loss : 0.443144 model2 loss : 0.027820
[10:58:23.966] iteration 7514 : model1 loss : 0.434235 model2 loss : 0.024989
[10:58:24.131] iteration 7515 : model1 loss : 0.438274 model2 loss : 0.031675
[10:58:24.300] iteration 7516 : model1 loss : 0.436205 model2 loss : 0.028737
[10:58:24.467] iteration 7517 : model1 loss : 0.439392 model2 loss : 0.031755
[10:58:24.637] iteration 7518 : model1 loss : 0.443675 model2 loss : 0.033309
[10:58:24.803] iteration 7519 : model1 loss : 0.436437 model2 loss : 0.022938
[10:58:24.973] iteration 7520 : model1 loss : 0.440088 model2 loss : 0.032516
[10:58:25.143] iteration 7521 : model1 loss : 0.442122 model2 loss : 0.030336
[10:58:25.313] iteration 7522 : model1 loss : 0.433958 model2 loss : 0.027343
[10:58:25.479] iteration 7523 : model1 loss : 0.434846 model2 loss : 0.027424
[10:58:25.646] iteration 7524 : model1 loss : 0.433919 model2 loss : 0.027118
[10:58:27.581] iteration 7525 : model1 loss : 0.442444 model2 loss : 0.025171
[10:58:27.749] iteration 7526 : model1 loss : 0.436859 model2 loss : 0.025227
[10:58:27.922] iteration 7527 : model1 loss : 0.437069 model2 loss : 0.031961
[10:58:28.087] iteration 7528 : model1 loss : 0.440353 model2 loss : 0.031643
[10:58:28.255] iteration 7529 : model1 loss : 0.436888 model2 loss : 0.023098
[10:58:28.431] iteration 7530 : model1 loss : 0.438340 model2 loss : 0.028016
[10:58:28.601] iteration 7531 : model1 loss : 0.439863 model2 loss : 0.026168
[10:58:28.768] iteration 7532 : model1 loss : 0.441009 model2 loss : 0.032038
[10:58:28.939] iteration 7533 : model1 loss : 0.436361 model2 loss : 0.025705
[10:58:29.107] iteration 7534 : model1 loss : 0.439925 model2 loss : 0.033542
[10:58:29.274] iteration 7535 : model1 loss : 0.439354 model2 loss : 0.030577
[10:58:29.444] iteration 7536 : model1 loss : 0.439937 model2 loss : 0.040200
[10:58:29.611] iteration 7537 : model1 loss : 0.437341 model2 loss : 0.026147
[10:58:29.779] iteration 7538 : model1 loss : 0.438168 model2 loss : 0.029532
[10:58:29.949] iteration 7539 : model1 loss : 0.438672 model2 loss : 0.030323
[10:58:30.115] iteration 7540 : model1 loss : 0.435868 model2 loss : 0.029635
[10:58:30.306] iteration 7541 : model1 loss : 0.437849 model2 loss : 0.026479
[10:58:30.474] iteration 7542 : model1 loss : 0.433604 model2 loss : 0.025026
[10:58:30.642] iteration 7543 : model1 loss : 0.436900 model2 loss : 0.026744
[10:58:30.809] iteration 7544 : model1 loss : 0.437224 model2 loss : 0.027644
[10:58:30.977] iteration 7545 : model1 loss : 0.437740 model2 loss : 0.025799
[10:58:31.144] iteration 7546 : model1 loss : 0.436086 model2 loss : 0.032487
[10:58:31.315] iteration 7547 : model1 loss : 0.437626 model2 loss : 0.029338
[10:58:31.483] iteration 7548 : model1 loss : 0.437115 model2 loss : 0.033162
[10:58:31.652] iteration 7549 : model1 loss : 0.441790 model2 loss : 0.027097
[10:58:31.819] iteration 7550 : model1 loss : 0.436798 model2 loss : 0.027166
[10:58:31.988] iteration 7551 : model1 loss : 0.437612 model2 loss : 0.029774
[10:58:32.156] iteration 7552 : model1 loss : 0.439478 model2 loss : 0.037221
[10:58:32.327] iteration 7553 : model1 loss : 0.437894 model2 loss : 0.028016
[10:58:32.495] iteration 7554 : model1 loss : 0.438497 model2 loss : 0.029434
[10:58:32.664] iteration 7555 : model1 loss : 0.437166 model2 loss : 0.029684
[10:58:32.830] iteration 7556 : model1 loss : 0.438695 model2 loss : 0.029953
[10:58:32.996] iteration 7557 : model1 loss : 0.435078 model2 loss : 0.026407
[10:58:34.921] iteration 7558 : model1 loss : 0.437966 model2 loss : 0.027886
[10:58:35.093] iteration 7559 : model1 loss : 0.433542 model2 loss : 0.024278
[10:58:35.262] iteration 7560 : model1 loss : 0.437804 model2 loss : 0.028197
[10:58:35.431] iteration 7561 : model1 loss : 0.438392 model2 loss : 0.030282
[10:58:35.600] iteration 7562 : model1 loss : 0.435993 model2 loss : 0.027119
[10:58:35.766] iteration 7563 : model1 loss : 0.436711 model2 loss : 0.030254
[10:58:35.936] iteration 7564 : model1 loss : 0.439682 model2 loss : 0.031470
[10:58:36.103] iteration 7565 : model1 loss : 0.443850 model2 loss : 0.040570
[10:58:36.273] iteration 7566 : model1 loss : 0.434722 model2 loss : 0.024906
[10:58:36.441] iteration 7567 : model1 loss : 0.442824 model2 loss : 0.029529
[10:58:36.611] iteration 7568 : model1 loss : 0.440156 model2 loss : 0.030250
[10:58:36.777] iteration 7569 : model1 loss : 0.436727 model2 loss : 0.028455
[10:58:36.943] iteration 7570 : model1 loss : 0.436385 model2 loss : 0.029476
[10:58:37.109] iteration 7571 : model1 loss : 0.433747 model2 loss : 0.029084
[10:58:37.278] iteration 7572 : model1 loss : 0.436116 model2 loss : 0.025793
[10:58:37.445] iteration 7573 : model1 loss : 0.440881 model2 loss : 0.036264
[10:58:37.615] iteration 7574 : model1 loss : 0.438248 model2 loss : 0.027530
[10:58:37.782] iteration 7575 : model1 loss : 0.433737 model2 loss : 0.027448
[10:58:37.952] iteration 7576 : model1 loss : 0.440304 model2 loss : 0.028114
[10:58:38.120] iteration 7577 : model1 loss : 0.442230 model2 loss : 0.027508
[10:58:38.292] iteration 7578 : model1 loss : 0.437648 model2 loss : 0.029123
[10:58:38.459] iteration 7579 : model1 loss : 0.434805 model2 loss : 0.026289
[10:58:38.630] iteration 7580 : model1 loss : 0.436952 model2 loss : 0.029970
[10:58:38.797] iteration 7581 : model1 loss : 0.436302 model2 loss : 0.023933
[10:58:38.965] iteration 7582 : model1 loss : 0.439574 model2 loss : 0.026733
[10:58:39.133] iteration 7583 : model1 loss : 0.434578 model2 loss : 0.025731
[10:58:39.305] iteration 7584 : model1 loss : 0.436289 model2 loss : 0.026019
[10:58:39.472] iteration 7585 : model1 loss : 0.436559 model2 loss : 0.028365
[10:58:39.641] iteration 7586 : model1 loss : 0.436004 model2 loss : 0.026036
[10:58:39.809] iteration 7587 : model1 loss : 0.439846 model2 loss : 0.026190
[10:58:39.976] iteration 7588 : model1 loss : 0.436012 model2 loss : 0.027239
[10:58:40.143] iteration 7589 : model1 loss : 0.442847 model2 loss : 0.031102
[10:58:40.313] iteration 7590 : model1 loss : 0.440664 model2 loss : 0.030414
[10:58:42.262] iteration 7591 : model1 loss : 0.435287 model2 loss : 0.026485
[10:58:42.431] iteration 7592 : model1 loss : 0.433758 model2 loss : 0.025128
[10:58:42.602] iteration 7593 : model1 loss : 0.439468 model2 loss : 0.028010
[10:58:42.769] iteration 7594 : model1 loss : 0.438260 model2 loss : 0.029503
[10:58:42.940] iteration 7595 : model1 loss : 0.439711 model2 loss : 0.033521
[10:58:43.107] iteration 7596 : model1 loss : 0.435073 model2 loss : 0.027077
[10:58:43.276] iteration 7597 : model1 loss : 0.437884 model2 loss : 0.027412
[10:58:43.444] iteration 7598 : model1 loss : 0.435942 model2 loss : 0.024566
[10:58:43.613] iteration 7599 : model1 loss : 0.437617 model2 loss : 0.026798
[10:58:43.781] iteration 7600 : model1 loss : 0.434168 model2 loss : 0.027029
[10:58:43.951] iteration 7601 : model1 loss : 0.439409 model2 loss : 0.029157
[10:58:44.119] iteration 7602 : model1 loss : 0.436592 model2 loss : 0.026289
[10:58:44.291] iteration 7603 : model1 loss : 0.437740 model2 loss : 0.028589
[10:58:44.460] iteration 7604 : model1 loss : 0.443149 model2 loss : 0.027920
[10:58:44.631] iteration 7605 : model1 loss : 0.439335 model2 loss : 0.025325
[10:58:44.798] iteration 7606 : model1 loss : 0.434068 model2 loss : 0.027723
[10:58:44.966] iteration 7607 : model1 loss : 0.439382 model2 loss : 0.027551
[10:58:45.132] iteration 7608 : model1 loss : 0.435658 model2 loss : 0.026683
[10:58:45.304] iteration 7609 : model1 loss : 0.437490 model2 loss : 0.028075
[10:58:45.471] iteration 7610 : model1 loss : 0.436478 model2 loss : 0.024001
[10:58:45.639] iteration 7611 : model1 loss : 0.437930 model2 loss : 0.034656
[10:58:45.806] iteration 7612 : model1 loss : 0.439607 model2 loss : 0.030955
[10:58:45.975] iteration 7613 : model1 loss : 0.440260 model2 loss : 0.028964
[10:58:46.140] iteration 7614 : model1 loss : 0.437655 model2 loss : 0.026098
[10:58:46.312] iteration 7615 : model1 loss : 0.442215 model2 loss : 0.031781
[10:58:46.480] iteration 7616 : model1 loss : 0.438901 model2 loss : 0.026533
[10:58:46.650] iteration 7617 : model1 loss : 0.434401 model2 loss : 0.026956
[10:58:46.818] iteration 7618 : model1 loss : 0.440360 model2 loss : 0.026781
[10:58:46.986] iteration 7619 : model1 loss : 0.442202 model2 loss : 0.028416
[10:58:47.154] iteration 7620 : model1 loss : 0.436268 model2 loss : 0.025806
[10:58:47.324] iteration 7621 : model1 loss : 0.438782 model2 loss : 0.027103
[10:58:47.491] iteration 7622 : model1 loss : 0.436192 model2 loss : 0.026952
[10:58:47.658] iteration 7623 : model1 loss : 0.441190 model2 loss : 0.031674
[10:58:49.560] iteration 7624 : model1 loss : 0.440503 model2 loss : 0.029134
[10:58:49.727] iteration 7625 : model1 loss : 0.438515 model2 loss : 0.028092
[10:58:49.897] iteration 7626 : model1 loss : 0.437315 model2 loss : 0.025947
[10:58:50.063] iteration 7627 : model1 loss : 0.436168 model2 loss : 0.024610
[10:58:50.232] iteration 7628 : model1 loss : 0.439626 model2 loss : 0.029005
[10:58:50.399] iteration 7629 : model1 loss : 0.442081 model2 loss : 0.029928
[10:58:50.568] iteration 7630 : model1 loss : 0.438162 model2 loss : 0.029484
[10:58:50.735] iteration 7631 : model1 loss : 0.441711 model2 loss : 0.032585
[10:58:50.908] iteration 7632 : model1 loss : 0.440051 model2 loss : 0.027477
[10:58:51.075] iteration 7633 : model1 loss : 0.440593 model2 loss : 0.025802
[10:58:51.256] iteration 7634 : model1 loss : 0.440116 model2 loss : 0.025912
[10:58:51.421] iteration 7635 : model1 loss : 0.430230 model2 loss : 0.025071
[10:58:51.590] iteration 7636 : model1 loss : 0.434888 model2 loss : 0.028590
[10:58:51.757] iteration 7637 : model1 loss : 0.442941 model2 loss : 0.029119
[10:58:51.925] iteration 7638 : model1 loss : 0.435491 model2 loss : 0.025887
[10:58:52.095] iteration 7639 : model1 loss : 0.438090 model2 loss : 0.025591
[10:58:52.263] iteration 7640 : model1 loss : 0.437474 model2 loss : 0.028267
[10:58:52.430] iteration 7641 : model1 loss : 0.436260 model2 loss : 0.024751
[10:58:52.600] iteration 7642 : model1 loss : 0.431720 model2 loss : 0.023482
[10:58:52.767] iteration 7643 : model1 loss : 0.441577 model2 loss : 0.030460
[10:58:52.936] iteration 7644 : model1 loss : 0.438211 model2 loss : 0.026358
[10:58:53.102] iteration 7645 : model1 loss : 0.434083 model2 loss : 0.029387
[10:58:53.271] iteration 7646 : model1 loss : 0.434727 model2 loss : 0.027256
[10:58:53.437] iteration 7647 : model1 loss : 0.435469 model2 loss : 0.026559
[10:58:53.606] iteration 7648 : model1 loss : 0.435326 model2 loss : 0.025534
[10:58:53.773] iteration 7649 : model1 loss : 0.440129 model2 loss : 0.027642
[10:58:53.941] iteration 7650 : model1 loss : 0.438628 model2 loss : 0.032879
[10:58:54.132] iteration 7651 : model1 loss : 0.437192 model2 loss : 0.025666
[10:58:54.301] iteration 7652 : model1 loss : 0.442474 model2 loss : 0.031212
[10:58:54.467] iteration 7653 : model1 loss : 0.438554 model2 loss : 0.025094
[10:58:54.638] iteration 7654 : model1 loss : 0.439565 model2 loss : 0.028687
[10:58:54.804] iteration 7655 : model1 loss : 0.439092 model2 loss : 0.027701
[10:58:54.973] iteration 7656 : model1 loss : 0.438916 model2 loss : 0.030747
[10:58:56.891] iteration 7657 : model1 loss : 0.442047 model2 loss : 0.025017
[10:58:57.059] iteration 7658 : model1 loss : 0.439475 model2 loss : 0.025013
[10:58:57.230] iteration 7659 : model1 loss : 0.438255 model2 loss : 0.032093
[10:58:57.396] iteration 7660 : model1 loss : 0.437876 model2 loss : 0.031041
[10:58:57.567] iteration 7661 : model1 loss : 0.439846 model2 loss : 0.031188
[10:58:57.734] iteration 7662 : model1 loss : 0.437842 model2 loss : 0.028254
[10:58:57.905] iteration 7663 : model1 loss : 0.437753 model2 loss : 0.026447
[10:58:58.072] iteration 7664 : model1 loss : 0.437189 model2 loss : 0.027274
[10:58:58.240] iteration 7665 : model1 loss : 0.435769 model2 loss : 0.025136
[10:58:58.406] iteration 7666 : model1 loss : 0.435342 model2 loss : 0.024471
[10:58:58.576] iteration 7667 : model1 loss : 0.436769 model2 loss : 0.028278
[10:58:58.743] iteration 7668 : model1 loss : 0.429783 model2 loss : 0.022833
[10:58:58.918] iteration 7669 : model1 loss : 0.439468 model2 loss : 0.029351
[10:58:59.084] iteration 7670 : model1 loss : 0.439718 model2 loss : 0.027387
[10:58:59.253] iteration 7671 : model1 loss : 0.441504 model2 loss : 0.027582
[10:58:59.421] iteration 7672 : model1 loss : 0.440368 model2 loss : 0.027229
[10:58:59.590] iteration 7673 : model1 loss : 0.440164 model2 loss : 0.030464
[10:58:59.755] iteration 7674 : model1 loss : 0.438452 model2 loss : 0.027370
[10:58:59.924] iteration 7675 : model1 loss : 0.440991 model2 loss : 0.028158
[10:59:00.093] iteration 7676 : model1 loss : 0.433978 model2 loss : 0.027950
[10:59:00.263] iteration 7677 : model1 loss : 0.440146 model2 loss : 0.028366
[10:59:00.431] iteration 7678 : model1 loss : 0.436216 model2 loss : 0.026121
[10:59:00.602] iteration 7679 : model1 loss : 0.437146 model2 loss : 0.022512
[10:59:00.769] iteration 7680 : model1 loss : 0.436851 model2 loss : 0.027168
[10:59:00.937] iteration 7681 : model1 loss : 0.434890 model2 loss : 0.022726
[10:59:01.104] iteration 7682 : model1 loss : 0.437574 model2 loss : 0.031197
[10:59:01.273] iteration 7683 : model1 loss : 0.436040 model2 loss : 0.029696
[10:59:01.440] iteration 7684 : model1 loss : 0.437690 model2 loss : 0.024745
[10:59:01.610] iteration 7685 : model1 loss : 0.439073 model2 loss : 0.030306
[10:59:01.777] iteration 7686 : model1 loss : 0.434769 model2 loss : 0.027432
[10:59:01.944] iteration 7687 : model1 loss : 0.442053 model2 loss : 0.028870
[10:59:02.109] iteration 7688 : model1 loss : 0.438752 model2 loss : 0.028682
[10:59:02.278] iteration 7689 : model1 loss : 0.440962 model2 loss : 0.031872
[10:59:04.196] iteration 7690 : model1 loss : 0.437182 model2 loss : 0.029466
[10:59:04.362] iteration 7691 : model1 loss : 0.439335 model2 loss : 0.028506
[10:59:04.533] iteration 7692 : model1 loss : 0.438830 model2 loss : 0.027906
[10:59:04.699] iteration 7693 : model1 loss : 0.440204 model2 loss : 0.032011
[10:59:04.867] iteration 7694 : model1 loss : 0.439502 model2 loss : 0.028840
[10:59:05.037] iteration 7695 : model1 loss : 0.438086 model2 loss : 0.026406
[10:59:05.208] iteration 7696 : model1 loss : 0.434637 model2 loss : 0.026775
[10:59:05.377] iteration 7697 : model1 loss : 0.439354 model2 loss : 0.028631
[10:59:05.550] iteration 7698 : model1 loss : 0.432488 model2 loss : 0.027345
[10:59:05.717] iteration 7699 : model1 loss : 0.435379 model2 loss : 0.026366
[10:59:05.889] iteration 7700 : model1 loss : 0.436234 model2 loss : 0.027155
[10:59:06.057] iteration 7701 : model1 loss : 0.437887 model2 loss : 0.023722
[10:59:06.227] iteration 7702 : model1 loss : 0.436023 model2 loss : 0.028820
[10:59:06.398] iteration 7703 : model1 loss : 0.432151 model2 loss : 0.026087
[10:59:06.569] iteration 7704 : model1 loss : 0.436638 model2 loss : 0.026330
[10:59:06.737] iteration 7705 : model1 loss : 0.434835 model2 loss : 0.026250
[10:59:06.904] iteration 7706 : model1 loss : 0.436299 model2 loss : 0.025745
[10:59:07.072] iteration 7707 : model1 loss : 0.440516 model2 loss : 0.030241
[10:59:07.239] iteration 7708 : model1 loss : 0.435145 model2 loss : 0.028074
[10:59:07.409] iteration 7709 : model1 loss : 0.434603 model2 loss : 0.025531
[10:59:07.580] iteration 7710 : model1 loss : 0.437237 model2 loss : 0.025768
[10:59:07.748] iteration 7711 : model1 loss : 0.436843 model2 loss : 0.025451
[10:59:07.917] iteration 7712 : model1 loss : 0.435852 model2 loss : 0.024180
[10:59:08.083] iteration 7713 : model1 loss : 0.435222 model2 loss : 0.028974
[10:59:08.252] iteration 7714 : model1 loss : 0.437237 model2 loss : 0.023549
[10:59:08.420] iteration 7715 : model1 loss : 0.438163 model2 loss : 0.026748
[10:59:08.590] iteration 7716 : model1 loss : 0.438957 model2 loss : 0.027945
[10:59:08.756] iteration 7717 : model1 loss : 0.437697 model2 loss : 0.031468
[10:59:08.927] iteration 7718 : model1 loss : 0.436713 model2 loss : 0.026751
[10:59:09.096] iteration 7719 : model1 loss : 0.443435 model2 loss : 0.031457
[10:59:09.265] iteration 7720 : model1 loss : 0.441578 model2 loss : 0.025533
[10:59:09.430] iteration 7721 : model1 loss : 0.440798 model2 loss : 0.029474
[10:59:09.598] iteration 7722 : model1 loss : 0.439876 model2 loss : 0.030838
[10:59:11.551] iteration 7723 : model1 loss : 0.439448 model2 loss : 0.025173
[10:59:11.723] iteration 7724 : model1 loss : 0.437770 model2 loss : 0.026151
[10:59:11.893] iteration 7725 : model1 loss : 0.438385 model2 loss : 0.026164
[10:59:12.060] iteration 7726 : model1 loss : 0.440524 model2 loss : 0.028020
[10:59:12.228] iteration 7727 : model1 loss : 0.436867 model2 loss : 0.025402
[10:59:12.400] iteration 7728 : model1 loss : 0.437710 model2 loss : 0.026507
[10:59:12.569] iteration 7729 : model1 loss : 0.441684 model2 loss : 0.024005
[10:59:12.736] iteration 7730 : model1 loss : 0.435382 model2 loss : 0.022756
[10:59:12.905] iteration 7731 : model1 loss : 0.437138 model2 loss : 0.029249
[10:59:13.072] iteration 7732 : model1 loss : 0.441069 model2 loss : 0.035534
[10:59:13.241] iteration 7733 : model1 loss : 0.436254 model2 loss : 0.025416
[10:59:13.409] iteration 7734 : model1 loss : 0.437623 model2 loss : 0.026646
[10:59:13.579] iteration 7735 : model1 loss : 0.440965 model2 loss : 0.031773
[10:59:13.757] iteration 7736 : model1 loss : 0.440433 model2 loss : 0.031522
[10:59:13.928] iteration 7737 : model1 loss : 0.438560 model2 loss : 0.028606
[10:59:14.095] iteration 7738 : model1 loss : 0.442469 model2 loss : 0.030187
[10:59:14.265] iteration 7739 : model1 loss : 0.438702 model2 loss : 0.021968
[10:59:14.432] iteration 7740 : model1 loss : 0.438395 model2 loss : 0.028420
[10:59:14.601] iteration 7741 : model1 loss : 0.436015 model2 loss : 0.035704
[10:59:14.769] iteration 7742 : model1 loss : 0.442934 model2 loss : 0.031739
[10:59:14.938] iteration 7743 : model1 loss : 0.437827 model2 loss : 0.026278
[10:59:15.105] iteration 7744 : model1 loss : 0.436753 model2 loss : 0.029930
[10:59:15.274] iteration 7745 : model1 loss : 0.436870 model2 loss : 0.027594
[10:59:15.444] iteration 7746 : model1 loss : 0.434406 model2 loss : 0.028928
[10:59:15.614] iteration 7747 : model1 loss : 0.436849 model2 loss : 0.027391
[10:59:15.781] iteration 7748 : model1 loss : 0.436547 model2 loss : 0.029192
[10:59:15.951] iteration 7749 : model1 loss : 0.441686 model2 loss : 0.029803
[10:59:16.119] iteration 7750 : model1 loss : 0.439262 model2 loss : 0.026487
[10:59:16.289] iteration 7751 : model1 loss : 0.438878 model2 loss : 0.026682
[10:59:16.456] iteration 7752 : model1 loss : 0.434790 model2 loss : 0.026652
[10:59:16.626] iteration 7753 : model1 loss : 0.436338 model2 loss : 0.028210
[10:59:16.791] iteration 7754 : model1 loss : 0.436333 model2 loss : 0.028971
[10:59:16.959] iteration 7755 : model1 loss : 0.437578 model2 loss : 0.029832
[10:59:18.885] iteration 7756 : model1 loss : 0.436224 model2 loss : 0.028494
[10:59:19.052] iteration 7757 : model1 loss : 0.440663 model2 loss : 0.023682
[10:59:19.223] iteration 7758 : model1 loss : 0.436360 model2 loss : 0.025341
[10:59:19.389] iteration 7759 : model1 loss : 0.437154 model2 loss : 0.027769
[10:59:19.558] iteration 7760 : model1 loss : 0.441834 model2 loss : 0.033073
[10:59:19.725] iteration 7761 : model1 loss : 0.436175 model2 loss : 0.026134
[10:59:19.894] iteration 7762 : model1 loss : 0.438465 model2 loss : 0.030365
[10:59:20.062] iteration 7763 : model1 loss : 0.438569 model2 loss : 0.026839
[10:59:20.229] iteration 7764 : model1 loss : 0.441303 model2 loss : 0.029571
[10:59:20.396] iteration 7765 : model1 loss : 0.434911 model2 loss : 0.027673
[10:59:20.566] iteration 7766 : model1 loss : 0.438218 model2 loss : 0.034031
[10:59:20.734] iteration 7767 : model1 loss : 0.434036 model2 loss : 0.026591
[10:59:20.907] iteration 7768 : model1 loss : 0.440635 model2 loss : 0.029811
[10:59:21.073] iteration 7769 : model1 loss : 0.439115 model2 loss : 0.028406
[10:59:21.244] iteration 7770 : model1 loss : 0.440059 model2 loss : 0.028462
[10:59:21.410] iteration 7771 : model1 loss : 0.445580 model2 loss : 0.037507
[10:59:21.580] iteration 7772 : model1 loss : 0.438733 model2 loss : 0.030870
[10:59:21.747] iteration 7773 : model1 loss : 0.438473 model2 loss : 0.029197
[10:59:21.918] iteration 7774 : model1 loss : 0.435699 model2 loss : 0.027679
[10:59:22.086] iteration 7775 : model1 loss : 0.436473 model2 loss : 0.031027
[10:59:22.255] iteration 7776 : model1 loss : 0.433786 model2 loss : 0.024204
[10:59:22.424] iteration 7777 : model1 loss : 0.438779 model2 loss : 0.027597
[10:59:22.593] iteration 7778 : model1 loss : 0.437059 model2 loss : 0.027989
[10:59:22.761] iteration 7779 : model1 loss : 0.436499 model2 loss : 0.029398
[10:59:22.930] iteration 7780 : model1 loss : 0.440629 model2 loss : 0.030597
[10:59:23.099] iteration 7781 : model1 loss : 0.435999 model2 loss : 0.035792
[10:59:23.268] iteration 7782 : model1 loss : 0.433617 model2 loss : 0.026683
[10:59:23.439] iteration 7783 : model1 loss : 0.444042 model2 loss : 0.039665
[10:59:23.609] iteration 7784 : model1 loss : 0.435645 model2 loss : 0.028091
[10:59:23.777] iteration 7785 : model1 loss : 0.437129 model2 loss : 0.028881
[10:59:23.947] iteration 7786 : model1 loss : 0.434509 model2 loss : 0.027658
[10:59:24.113] iteration 7787 : model1 loss : 0.433217 model2 loss : 0.027966
[10:59:24.281] iteration 7788 : model1 loss : 0.437709 model2 loss : 0.027620
[10:59:26.233] iteration 7789 : model1 loss : 0.438564 model2 loss : 0.028833
[10:59:26.404] iteration 7790 : model1 loss : 0.437585 model2 loss : 0.026044
[10:59:26.574] iteration 7791 : model1 loss : 0.438815 model2 loss : 0.034788
[10:59:26.741] iteration 7792 : model1 loss : 0.436573 model2 loss : 0.027403
[10:59:26.910] iteration 7793 : model1 loss : 0.436998 model2 loss : 0.026953
[10:59:27.078] iteration 7794 : model1 loss : 0.435607 model2 loss : 0.028949
[10:59:27.247] iteration 7795 : model1 loss : 0.439318 model2 loss : 0.033972
[10:59:27.415] iteration 7796 : model1 loss : 0.437391 model2 loss : 0.024996
[10:59:27.584] iteration 7797 : model1 loss : 0.442292 model2 loss : 0.031706
[10:59:27.752] iteration 7798 : model1 loss : 0.433872 model2 loss : 0.026067
[10:59:27.922] iteration 7799 : model1 loss : 0.441268 model2 loss : 0.029862
[10:59:28.088] iteration 7800 : model1 loss : 0.439796 model2 loss : 0.028341
[10:59:28.258] iteration 7801 : model1 loss : 0.436868 model2 loss : 0.033696
[10:59:28.425] iteration 7802 : model1 loss : 0.438753 model2 loss : 0.030664
[10:59:28.595] iteration 7803 : model1 loss : 0.445137 model2 loss : 0.032309
[10:59:28.761] iteration 7804 : model1 loss : 0.439800 model2 loss : 0.030488
[10:59:28.930] iteration 7805 : model1 loss : 0.435930 model2 loss : 0.025976
[10:59:29.098] iteration 7806 : model1 loss : 0.438880 model2 loss : 0.029869
[10:59:29.266] iteration 7807 : model1 loss : 0.432476 model2 loss : 0.029100
[10:59:29.435] iteration 7808 : model1 loss : 0.438444 model2 loss : 0.032420
[10:59:29.603] iteration 7809 : model1 loss : 0.439775 model2 loss : 0.034915
[10:59:29.770] iteration 7810 : model1 loss : 0.437868 model2 loss : 0.032432
[10:59:29.939] iteration 7811 : model1 loss : 0.436787 model2 loss : 0.027180
[10:59:30.107] iteration 7812 : model1 loss : 0.435571 model2 loss : 0.031737
[10:59:30.276] iteration 7813 : model1 loss : 0.436906 model2 loss : 0.027092
[10:59:30.446] iteration 7814 : model1 loss : 0.442216 model2 loss : 0.030107
[10:59:30.615] iteration 7815 : model1 loss : 0.436296 model2 loss : 0.026642
[10:59:30.783] iteration 7816 : model1 loss : 0.438824 model2 loss : 0.028267
[10:59:30.952] iteration 7817 : model1 loss : 0.439516 model2 loss : 0.030969
[10:59:31.120] iteration 7818 : model1 loss : 0.440443 model2 loss : 0.028520
[10:59:31.289] iteration 7819 : model1 loss : 0.438213 model2 loss : 0.027594
[10:59:31.457] iteration 7820 : model1 loss : 0.438499 model2 loss : 0.026047
[10:59:31.625] iteration 7821 : model1 loss : 0.438210 model2 loss : 0.032790
[10:59:33.556] iteration 7822 : model1 loss : 0.439777 model2 loss : 0.028362
[10:59:33.724] iteration 7823 : model1 loss : 0.439791 model2 loss : 0.027105
[10:59:33.894] iteration 7824 : model1 loss : 0.440430 model2 loss : 0.031384
[10:59:34.060] iteration 7825 : model1 loss : 0.436466 model2 loss : 0.026192
[10:59:34.230] iteration 7826 : model1 loss : 0.435905 model2 loss : 0.029303
[10:59:34.395] iteration 7827 : model1 loss : 0.439277 model2 loss : 0.026993
[10:59:34.565] iteration 7828 : model1 loss : 0.437668 model2 loss : 0.026247
[10:59:34.731] iteration 7829 : model1 loss : 0.440521 model2 loss : 0.027327
[10:59:34.904] iteration 7830 : model1 loss : 0.438322 model2 loss : 0.025227
[10:59:35.073] iteration 7831 : model1 loss : 0.436937 model2 loss : 0.025377
[10:59:35.240] iteration 7832 : model1 loss : 0.440805 model2 loss : 0.028755
[10:59:35.407] iteration 7833 : model1 loss : 0.439371 model2 loss : 0.026480
[10:59:35.576] iteration 7834 : model1 loss : 0.437920 model2 loss : 0.026594
[10:59:35.741] iteration 7835 : model1 loss : 0.439516 model2 loss : 0.022859
[10:59:35.911] iteration 7836 : model1 loss : 0.445424 model2 loss : 0.029538
[10:59:36.079] iteration 7837 : model1 loss : 0.435827 model2 loss : 0.026504
[10:59:36.249] iteration 7838 : model1 loss : 0.440428 model2 loss : 0.026370
[10:59:36.417] iteration 7839 : model1 loss : 0.439796 model2 loss : 0.027644
[10:59:36.587] iteration 7840 : model1 loss : 0.435216 model2 loss : 0.026250
[10:59:36.753] iteration 7841 : model1 loss : 0.437597 model2 loss : 0.030144
[10:59:36.922] iteration 7842 : model1 loss : 0.441966 model2 loss : 0.030018
[10:59:37.089] iteration 7843 : model1 loss : 0.435098 model2 loss : 0.027762
[10:59:37.258] iteration 7844 : model1 loss : 0.437204 model2 loss : 0.029395
[10:59:37.425] iteration 7845 : model1 loss : 0.437300 model2 loss : 0.028239
[10:59:37.595] iteration 7846 : model1 loss : 0.434717 model2 loss : 0.027871
[10:59:37.761] iteration 7847 : model1 loss : 0.437578 model2 loss : 0.027319
[10:59:37.929] iteration 7848 : model1 loss : 0.433216 model2 loss : 0.024644
[10:59:38.095] iteration 7849 : model1 loss : 0.436034 model2 loss : 0.027145
[10:59:38.266] iteration 7850 : model1 loss : 0.437813 model2 loss : 0.028927
[10:59:38.431] iteration 7851 : model1 loss : 0.436825 model2 loss : 0.029616
[10:59:38.600] iteration 7852 : model1 loss : 0.436612 model2 loss : 0.028614
[10:59:38.765] iteration 7853 : model1 loss : 0.435586 model2 loss : 0.027161
[10:59:38.933] iteration 7854 : model1 loss : 0.443397 model2 loss : 0.032201
[10:59:40.849] iteration 7855 : model1 loss : 0.436331 model2 loss : 0.025698
[10:59:41.019] iteration 7856 : model1 loss : 0.437637 model2 loss : 0.024902
[10:59:41.190] iteration 7857 : model1 loss : 0.436431 model2 loss : 0.028547
[10:59:41.357] iteration 7858 : model1 loss : 0.437209 model2 loss : 0.028262
[10:59:41.527] iteration 7859 : model1 loss : 0.438020 model2 loss : 0.026176
[10:59:41.693] iteration 7860 : model1 loss : 0.439663 model2 loss : 0.028330
[10:59:41.862] iteration 7861 : model1 loss : 0.438837 model2 loss : 0.026414
[10:59:42.027] iteration 7862 : model1 loss : 0.435756 model2 loss : 0.024843
[10:59:42.197] iteration 7863 : model1 loss : 0.437124 model2 loss : 0.026081
[10:59:42.364] iteration 7864 : model1 loss : 0.437704 model2 loss : 0.030321
[10:59:42.537] iteration 7865 : model1 loss : 0.441633 model2 loss : 0.029034
[10:59:42.704] iteration 7866 : model1 loss : 0.439914 model2 loss : 0.031697
[10:59:42.872] iteration 7867 : model1 loss : 0.437530 model2 loss : 0.029888
[10:59:43.039] iteration 7868 : model1 loss : 0.429771 model2 loss : 0.023588
[10:59:43.208] iteration 7869 : model1 loss : 0.443594 model2 loss : 0.031151
[10:59:43.376] iteration 7870 : model1 loss : 0.442642 model2 loss : 0.030311
[10:59:43.545] iteration 7871 : model1 loss : 0.441445 model2 loss : 0.030785
[10:59:43.713] iteration 7872 : model1 loss : 0.434013 model2 loss : 0.028173
[10:59:43.881] iteration 7873 : model1 loss : 0.437103 model2 loss : 0.027525
[10:59:44.048] iteration 7874 : model1 loss : 0.436180 model2 loss : 0.026607
[10:59:44.218] iteration 7875 : model1 loss : 0.441275 model2 loss : 0.030560
[10:59:44.386] iteration 7876 : model1 loss : 0.436585 model2 loss : 0.026257
[10:59:44.562] iteration 7877 : model1 loss : 0.439406 model2 loss : 0.029182
[10:59:44.729] iteration 7878 : model1 loss : 0.440650 model2 loss : 0.027231
[10:59:44.898] iteration 7879 : model1 loss : 0.444415 model2 loss : 0.033257
[10:59:45.063] iteration 7880 : model1 loss : 0.437929 model2 loss : 0.027141
[10:59:45.233] iteration 7881 : model1 loss : 0.439670 model2 loss : 0.025000
[10:59:45.400] iteration 7882 : model1 loss : 0.438705 model2 loss : 0.030281
[10:59:45.570] iteration 7883 : model1 loss : 0.434614 model2 loss : 0.024842
[10:59:45.738] iteration 7884 : model1 loss : 0.442164 model2 loss : 0.029987
[10:59:45.905] iteration 7885 : model1 loss : 0.432961 model2 loss : 0.026417
[10:59:46.072] iteration 7886 : model1 loss : 0.435092 model2 loss : 0.027702
[10:59:46.239] iteration 7887 : model1 loss : 0.433812 model2 loss : 0.024985
[10:59:48.165] iteration 7888 : model1 loss : 0.437991 model2 loss : 0.026721
[10:59:48.335] iteration 7889 : model1 loss : 0.434458 model2 loss : 0.025048
[10:59:48.506] iteration 7890 : model1 loss : 0.434742 model2 loss : 0.024719
[10:59:48.673] iteration 7891 : model1 loss : 0.434635 model2 loss : 0.026202
[10:59:48.842] iteration 7892 : model1 loss : 0.438455 model2 loss : 0.022326
[10:59:49.010] iteration 7893 : model1 loss : 0.440995 model2 loss : 0.025888
[10:59:49.178] iteration 7894 : model1 loss : 0.438098 model2 loss : 0.028293
[10:59:49.342] iteration 7895 : model1 loss : 0.440081 model2 loss : 0.031141
[10:59:49.515] iteration 7896 : model1 loss : 0.435131 model2 loss : 0.024262
[10:59:49.681] iteration 7897 : model1 loss : 0.437410 model2 loss : 0.025411
[10:59:49.849] iteration 7898 : model1 loss : 0.436360 model2 loss : 0.021869
[10:59:50.018] iteration 7899 : model1 loss : 0.438659 model2 loss : 0.023411
[10:59:50.185] iteration 7900 : model1 loss : 0.438048 model2 loss : 0.026756
[10:59:50.353] iteration 7901 : model1 loss : 0.438948 model2 loss : 0.031374
[10:59:50.525] iteration 7902 : model1 loss : 0.442156 model2 loss : 0.026653
[10:59:50.691] iteration 7903 : model1 loss : 0.437550 model2 loss : 0.026467
[10:59:50.861] iteration 7904 : model1 loss : 0.440086 model2 loss : 0.026887
[10:59:51.030] iteration 7905 : model1 loss : 0.439440 model2 loss : 0.028056
[10:59:51.200] iteration 7906 : model1 loss : 0.442006 model2 loss : 0.030373
[10:59:51.366] iteration 7907 : model1 loss : 0.439884 model2 loss : 0.025980
[10:59:51.535] iteration 7908 : model1 loss : 0.437964 model2 loss : 0.029545
[10:59:51.700] iteration 7909 : model1 loss : 0.438134 model2 loss : 0.027291
[10:59:51.868] iteration 7910 : model1 loss : 0.439251 model2 loss : 0.026709
[10:59:52.035] iteration 7911 : model1 loss : 0.436778 model2 loss : 0.029275
[10:59:52.202] iteration 7912 : model1 loss : 0.432258 model2 loss : 0.028624
[10:59:52.370] iteration 7913 : model1 loss : 0.434211 model2 loss : 0.025543
[10:59:52.541] iteration 7914 : model1 loss : 0.436642 model2 loss : 0.028237
[10:59:52.707] iteration 7915 : model1 loss : 0.437940 model2 loss : 0.027206
[10:59:52.875] iteration 7916 : model1 loss : 0.438308 model2 loss : 0.029947
[10:59:53.041] iteration 7917 : model1 loss : 0.434555 model2 loss : 0.027202
[10:59:53.210] iteration 7918 : model1 loss : 0.432890 model2 loss : 0.025028
[10:59:53.375] iteration 7919 : model1 loss : 0.436000 model2 loss : 0.025864
[10:59:53.544] iteration 7920 : model1 loss : 0.441174 model2 loss : 0.031054
[10:59:55.434] iteration 7921 : model1 loss : 0.439338 model2 loss : 0.024417
[10:59:55.601] iteration 7922 : model1 loss : 0.435247 model2 loss : 0.027132
[10:59:55.772] iteration 7923 : model1 loss : 0.433343 model2 loss : 0.029085
[10:59:55.938] iteration 7924 : model1 loss : 0.441605 model2 loss : 0.028705
[10:59:56.106] iteration 7925 : model1 loss : 0.432875 model2 loss : 0.027878
[10:59:56.274] iteration 7926 : model1 loss : 0.437793 model2 loss : 0.028192
[10:59:56.442] iteration 7927 : model1 loss : 0.436341 model2 loss : 0.025285
[10:59:56.609] iteration 7928 : model1 loss : 0.442907 model2 loss : 0.035769
[10:59:56.778] iteration 7929 : model1 loss : 0.443629 model2 loss : 0.035746
[10:59:56.944] iteration 7930 : model1 loss : 0.437109 model2 loss : 0.023477
[10:59:57.114] iteration 7931 : model1 loss : 0.437130 model2 loss : 0.026308
[10:59:57.279] iteration 7932 : model1 loss : 0.439578 model2 loss : 0.031407
[10:59:57.447] iteration 7933 : model1 loss : 0.436588 model2 loss : 0.024475
[10:59:57.613] iteration 7934 : model1 loss : 0.435069 model2 loss : 0.029915
[10:59:57.782] iteration 7935 : model1 loss : 0.439491 model2 loss : 0.025872
[10:59:57.949] iteration 7936 : model1 loss : 0.439510 model2 loss : 0.025513
[10:59:58.119] iteration 7937 : model1 loss : 0.434400 model2 loss : 0.028052
[10:59:58.288] iteration 7938 : model1 loss : 0.437245 model2 loss : 0.029416
[10:59:58.457] iteration 7939 : model1 loss : 0.435610 model2 loss : 0.027427
[10:59:58.622] iteration 7940 : model1 loss : 0.438594 model2 loss : 0.029851
[10:59:58.794] iteration 7941 : model1 loss : 0.436072 model2 loss : 0.027178
[10:59:58.959] iteration 7942 : model1 loss : 0.437553 model2 loss : 0.028465
[10:59:59.127] iteration 7943 : model1 loss : 0.433409 model2 loss : 0.025300
[10:59:59.293] iteration 7944 : model1 loss : 0.435477 model2 loss : 0.024577
[10:59:59.463] iteration 7945 : model1 loss : 0.435728 model2 loss : 0.025872
[10:59:59.630] iteration 7946 : model1 loss : 0.434303 model2 loss : 0.025272
[10:59:59.799] iteration 7947 : model1 loss : 0.439761 model2 loss : 0.030085
[10:59:59.967] iteration 7948 : model1 loss : 0.439687 model2 loss : 0.029539
[11:00:00.137] iteration 7949 : model1 loss : 0.436898 model2 loss : 0.028905
[11:00:00.302] iteration 7950 : model1 loss : 0.439664 model2 loss : 0.026270
[11:00:00.475] iteration 7951 : model1 loss : 0.433751 model2 loss : 0.026104
[11:00:00.640] iteration 7952 : model1 loss : 0.438721 model2 loss : 0.023912
[11:00:00.808] iteration 7953 : model1 loss : 0.436925 model2 loss : 0.026245
[11:00:02.739] iteration 7954 : model1 loss : 0.436933 model2 loss : 0.025342
[11:00:02.907] iteration 7955 : model1 loss : 0.440488 model2 loss : 0.027202
[11:00:03.076] iteration 7956 : model1 loss : 0.435840 model2 loss : 0.024345
[11:00:03.242] iteration 7957 : model1 loss : 0.435921 model2 loss : 0.022866
[11:00:03.409] iteration 7958 : model1 loss : 0.437958 model2 loss : 0.027684
[11:00:03.576] iteration 7959 : model1 loss : 0.439958 model2 loss : 0.027405
[11:00:03.744] iteration 7960 : model1 loss : 0.441237 model2 loss : 0.026349
[11:00:03.913] iteration 7961 : model1 loss : 0.436795 model2 loss : 0.024544
[11:00:04.082] iteration 7962 : model1 loss : 0.433913 model2 loss : 0.024894
[11:00:04.247] iteration 7963 : model1 loss : 0.433260 model2 loss : 0.024800
[11:00:04.416] iteration 7964 : model1 loss : 0.440376 model2 loss : 0.025810
[11:00:04.583] iteration 7965 : model1 loss : 0.436070 model2 loss : 0.026605
[11:00:04.752] iteration 7966 : model1 loss : 0.438693 model2 loss : 0.028463
[11:00:04.920] iteration 7967 : model1 loss : 0.438276 model2 loss : 0.029006
[11:00:05.089] iteration 7968 : model1 loss : 0.437296 model2 loss : 0.025951
[11:00:05.257] iteration 7969 : model1 loss : 0.438829 model2 loss : 0.024125
[11:00:05.425] iteration 7970 : model1 loss : 0.435113 model2 loss : 0.026354
[11:00:05.593] iteration 7971 : model1 loss : 0.434772 model2 loss : 0.028174
[11:00:05.762] iteration 7972 : model1 loss : 0.436164 model2 loss : 0.024100
[11:00:05.930] iteration 7973 : model1 loss : 0.442388 model2 loss : 0.027980
[11:00:06.099] iteration 7974 : model1 loss : 0.439179 model2 loss : 0.028635
[11:00:06.266] iteration 7975 : model1 loss : 0.439270 model2 loss : 0.028481
[11:00:06.435] iteration 7976 : model1 loss : 0.440035 model2 loss : 0.028603
[11:00:06.602] iteration 7977 : model1 loss : 0.431671 model2 loss : 0.024317
[11:00:06.771] iteration 7978 : model1 loss : 0.433687 model2 loss : 0.025519
[11:00:06.937] iteration 7979 : model1 loss : 0.434171 model2 loss : 0.022957
[11:00:07.104] iteration 7980 : model1 loss : 0.439682 model2 loss : 0.025163
[11:00:07.271] iteration 7981 : model1 loss : 0.433499 model2 loss : 0.023642
[11:00:07.439] iteration 7982 : model1 loss : 0.443335 model2 loss : 0.029334
[11:00:07.607] iteration 7983 : model1 loss : 0.443660 model2 loss : 0.030065
[11:00:07.776] iteration 7984 : model1 loss : 0.435082 model2 loss : 0.026109
[11:00:07.943] iteration 7985 : model1 loss : 0.436936 model2 loss : 0.026671
[11:00:08.111] iteration 7986 : model1 loss : 0.439351 model2 loss : 0.026888
[11:00:10.024] iteration 7987 : model1 loss : 0.438086 model2 loss : 0.027327
[11:00:10.196] iteration 7988 : model1 loss : 0.440842 model2 loss : 0.030764
[11:00:10.366] iteration 7989 : model1 loss : 0.433250 model2 loss : 0.023676
[11:00:10.535] iteration 7990 : model1 loss : 0.439017 model2 loss : 0.023634
[11:00:10.703] iteration 7991 : model1 loss : 0.440560 model2 loss : 0.026950
[11:00:10.873] iteration 7992 : model1 loss : 0.434184 model2 loss : 0.022951
[11:00:11.042] iteration 7993 : model1 loss : 0.436339 model2 loss : 0.024292
[11:00:11.210] iteration 7994 : model1 loss : 0.435198 model2 loss : 0.026371
[11:00:11.378] iteration 7995 : model1 loss : 0.440669 model2 loss : 0.027799
[11:00:11.549] iteration 7996 : model1 loss : 0.439138 model2 loss : 0.026556
[11:00:11.715] iteration 7997 : model1 loss : 0.438103 model2 loss : 0.027307
[11:00:11.883] iteration 7998 : model1 loss : 0.435958 model2 loss : 0.026291
[11:00:12.051] iteration 7999 : model1 loss : 0.440213 model2 loss : 0.027667
[11:00:12.218] iteration 8000 : model1 loss : 0.437361 model2 loss : 0.026997
[11:00:20.520] iteration 8000 : model1_mean_dice : 0.861372 model1_mean_hd95 : 9.166207
[11:00:28.823] iteration 8000 : model2_mean_dice : 0.887699 model2_mean_hd95 : 2.999520
[11:00:28.994] iteration 8001 : model1 loss : 0.439226 model2 loss : 0.028880
[11:00:29.166] iteration 8002 : model1 loss : 0.437621 model2 loss : 0.029071
[11:00:29.332] iteration 8003 : model1 loss : 0.435830 model2 loss : 0.026488
[11:00:29.503] iteration 8004 : model1 loss : 0.440727 model2 loss : 0.034512
[11:00:29.669] iteration 8005 : model1 loss : 0.437410 model2 loss : 0.025415
[11:00:29.836] iteration 8006 : model1 loss : 0.440145 model2 loss : 0.028443
[11:00:30.003] iteration 8007 : model1 loss : 0.442325 model2 loss : 0.030091
[11:00:30.171] iteration 8008 : model1 loss : 0.442603 model2 loss : 0.032810
[11:00:30.336] iteration 8009 : model1 loss : 0.433563 model2 loss : 0.022556
[11:00:30.505] iteration 8010 : model1 loss : 0.439085 model2 loss : 0.028438
[11:00:30.672] iteration 8011 : model1 loss : 0.434207 model2 loss : 0.024790
[11:00:30.841] iteration 8012 : model1 loss : 0.439341 model2 loss : 0.029451
[11:00:31.007] iteration 8013 : model1 loss : 0.434704 model2 loss : 0.024884
[11:00:31.175] iteration 8014 : model1 loss : 0.439137 model2 loss : 0.028015
[11:00:31.340] iteration 8015 : model1 loss : 0.439979 model2 loss : 0.028168
[11:00:31.508] iteration 8016 : model1 loss : 0.441564 model2 loss : 0.029115
[11:00:31.672] iteration 8017 : model1 loss : 0.436953 model2 loss : 0.030307
[11:00:31.839] iteration 8018 : model1 loss : 0.441870 model2 loss : 0.026185
[11:00:32.005] iteration 8019 : model1 loss : 0.433394 model2 loss : 0.031329
[11:00:33.945] iteration 8020 : model1 loss : 0.439666 model2 loss : 0.026452
[11:00:34.111] iteration 8021 : model1 loss : 0.437542 model2 loss : 0.027716
[11:00:34.277] iteration 8022 : model1 loss : 0.438091 model2 loss : 0.028479
[11:00:34.443] iteration 8023 : model1 loss : 0.441591 model2 loss : 0.028662
[11:00:34.615] iteration 8024 : model1 loss : 0.436708 model2 loss : 0.024848
[11:00:34.781] iteration 8025 : model1 loss : 0.436050 model2 loss : 0.027265
[11:00:34.950] iteration 8026 : model1 loss : 0.438932 model2 loss : 0.027445
[11:00:35.115] iteration 8027 : model1 loss : 0.440976 model2 loss : 0.025693
[11:00:35.283] iteration 8028 : model1 loss : 0.435343 model2 loss : 0.026807
[11:00:35.449] iteration 8029 : model1 loss : 0.438854 model2 loss : 0.029452
[11:00:35.620] iteration 8030 : model1 loss : 0.438203 model2 loss : 0.027697
[11:00:35.785] iteration 8031 : model1 loss : 0.437955 model2 loss : 0.028899
[11:00:35.954] iteration 8032 : model1 loss : 0.436762 model2 loss : 0.023713
[11:00:36.119] iteration 8033 : model1 loss : 0.438873 model2 loss : 0.026225
[11:00:36.287] iteration 8034 : model1 loss : 0.441260 model2 loss : 0.027323
[11:00:36.454] iteration 8035 : model1 loss : 0.439966 model2 loss : 0.025038
[11:00:36.625] iteration 8036 : model1 loss : 0.437499 model2 loss : 0.027510
[11:00:36.791] iteration 8037 : model1 loss : 0.433463 model2 loss : 0.021677
[11:00:36.958] iteration 8038 : model1 loss : 0.439149 model2 loss : 0.030066
[11:00:37.123] iteration 8039 : model1 loss : 0.440309 model2 loss : 0.028620
[11:00:37.292] iteration 8040 : model1 loss : 0.435221 model2 loss : 0.023847
[11:00:37.458] iteration 8041 : model1 loss : 0.436093 model2 loss : 0.026046
[11:00:37.626] iteration 8042 : model1 loss : 0.440886 model2 loss : 0.027340
[11:00:37.793] iteration 8043 : model1 loss : 0.439270 model2 loss : 0.029816
[11:00:37.960] iteration 8044 : model1 loss : 0.436902 model2 loss : 0.026552
[11:00:38.126] iteration 8045 : model1 loss : 0.432230 model2 loss : 0.023310
[11:00:38.294] iteration 8046 : model1 loss : 0.430686 model2 loss : 0.024295
[11:00:38.461] iteration 8047 : model1 loss : 0.436087 model2 loss : 0.027012
[11:00:38.630] iteration 8048 : model1 loss : 0.438109 model2 loss : 0.027339
[11:00:38.795] iteration 8049 : model1 loss : 0.440060 model2 loss : 0.028645
[11:00:38.963] iteration 8050 : model1 loss : 0.435861 model2 loss : 0.024682
[11:00:39.127] iteration 8051 : model1 loss : 0.440210 model2 loss : 0.029921
[11:00:39.295] iteration 8052 : model1 loss : 0.437954 model2 loss : 0.028033
[11:00:41.232] iteration 8053 : model1 loss : 0.442831 model2 loss : 0.032065
[11:00:41.403] iteration 8054 : model1 loss : 0.440708 model2 loss : 0.028673
[11:00:41.572] iteration 8055 : model1 loss : 0.439325 model2 loss : 0.029437
[11:00:41.737] iteration 8056 : model1 loss : 0.430755 model2 loss : 0.025591
[11:00:41.905] iteration 8057 : model1 loss : 0.437497 model2 loss : 0.025113
[11:00:42.073] iteration 8058 : model1 loss : 0.435876 model2 loss : 0.026534
[11:00:42.241] iteration 8059 : model1 loss : 0.436120 model2 loss : 0.026211
[11:00:42.407] iteration 8060 : model1 loss : 0.439213 model2 loss : 0.025844
[11:00:42.580] iteration 8061 : model1 loss : 0.433967 model2 loss : 0.026929
[11:00:42.746] iteration 8062 : model1 loss : 0.435407 model2 loss : 0.025779
[11:00:42.914] iteration 8063 : model1 loss : 0.438732 model2 loss : 0.027665
[11:00:43.080] iteration 8064 : model1 loss : 0.438428 model2 loss : 0.025115
[11:00:43.246] iteration 8065 : model1 loss : 0.434449 model2 loss : 0.024083
[11:00:43.413] iteration 8066 : model1 loss : 0.434155 model2 loss : 0.027697
[11:00:43.582] iteration 8067 : model1 loss : 0.441644 model2 loss : 0.027451
[11:00:43.748] iteration 8068 : model1 loss : 0.439414 model2 loss : 0.034056
[11:00:43.916] iteration 8069 : model1 loss : 0.441724 model2 loss : 0.034211
[11:00:44.080] iteration 8070 : model1 loss : 0.438123 model2 loss : 0.029466
[11:00:44.249] iteration 8071 : model1 loss : 0.437805 model2 loss : 0.027317
[11:00:44.415] iteration 8072 : model1 loss : 0.439164 model2 loss : 0.029855
[11:00:44.585] iteration 8073 : model1 loss : 0.435953 model2 loss : 0.025674
[11:00:44.750] iteration 8074 : model1 loss : 0.433613 model2 loss : 0.026524
[11:00:44.917] iteration 8075 : model1 loss : 0.436195 model2 loss : 0.029133
[11:00:45.082] iteration 8076 : model1 loss : 0.434919 model2 loss : 0.026210
[11:00:45.250] iteration 8077 : model1 loss : 0.439961 model2 loss : 0.032359
[11:00:45.415] iteration 8078 : model1 loss : 0.437127 model2 loss : 0.025030
[11:00:45.585] iteration 8079 : model1 loss : 0.443684 model2 loss : 0.030417
[11:00:45.751] iteration 8080 : model1 loss : 0.437304 model2 loss : 0.025661
[11:00:45.921] iteration 8081 : model1 loss : 0.436457 model2 loss : 0.027788
[11:00:46.089] iteration 8082 : model1 loss : 0.436465 model2 loss : 0.025309
[11:00:46.257] iteration 8083 : model1 loss : 0.440279 model2 loss : 0.031017
[11:00:46.422] iteration 8084 : model1 loss : 0.436275 model2 loss : 0.023329
[11:00:46.592] iteration 8085 : model1 loss : 0.436109 model2 loss : 0.027125
[11:00:48.508] iteration 8086 : model1 loss : 0.435308 model2 loss : 0.025996
[11:00:48.673] iteration 8087 : model1 loss : 0.438356 model2 loss : 0.026883
[11:00:48.840] iteration 8088 : model1 loss : 0.435423 model2 loss : 0.027213
[11:00:49.007] iteration 8089 : model1 loss : 0.441518 model2 loss : 0.028539
[11:00:49.175] iteration 8090 : model1 loss : 0.435856 model2 loss : 0.026426
[11:00:49.341] iteration 8091 : model1 loss : 0.438454 model2 loss : 0.027447
[11:00:49.512] iteration 8092 : model1 loss : 0.433843 model2 loss : 0.025664
[11:00:49.679] iteration 8093 : model1 loss : 0.438182 model2 loss : 0.024808
[11:00:49.846] iteration 8094 : model1 loss : 0.438936 model2 loss : 0.028919
[11:00:50.011] iteration 8095 : model1 loss : 0.438657 model2 loss : 0.026266
[11:00:50.179] iteration 8096 : model1 loss : 0.434426 model2 loss : 0.025405
[11:00:50.344] iteration 8097 : model1 loss : 0.437805 model2 loss : 0.024890
[11:00:50.515] iteration 8098 : model1 loss : 0.436773 model2 loss : 0.028227
[11:00:50.682] iteration 8099 : model1 loss : 0.439984 model2 loss : 0.026887
[11:00:50.852] iteration 8100 : model1 loss : 0.439407 model2 loss : 0.034245
[11:00:51.018] iteration 8101 : model1 loss : 0.434657 model2 loss : 0.027775
[11:00:51.186] iteration 8102 : model1 loss : 0.444934 model2 loss : 0.034489
[11:00:51.351] iteration 8103 : model1 loss : 0.434652 model2 loss : 0.027453
[11:00:51.524] iteration 8104 : model1 loss : 0.434929 model2 loss : 0.026106
[11:00:51.691] iteration 8105 : model1 loss : 0.439122 model2 loss : 0.024841
[11:00:51.860] iteration 8106 : model1 loss : 0.438617 model2 loss : 0.026556
[11:00:52.031] iteration 8107 : model1 loss : 0.433166 model2 loss : 0.026055
[11:00:52.199] iteration 8108 : model1 loss : 0.434352 model2 loss : 0.025227
[11:00:52.365] iteration 8109 : model1 loss : 0.438177 model2 loss : 0.028250
[11:00:52.534] iteration 8110 : model1 loss : 0.437272 model2 loss : 0.022978
[11:00:52.700] iteration 8111 : model1 loss : 0.436996 model2 loss : 0.025201
[11:00:52.869] iteration 8112 : model1 loss : 0.439533 model2 loss : 0.026316
[11:00:53.034] iteration 8113 : model1 loss : 0.438566 model2 loss : 0.024891
[11:00:53.204] iteration 8114 : model1 loss : 0.440819 model2 loss : 0.030839
[11:00:53.371] iteration 8115 : model1 loss : 0.436388 model2 loss : 0.029146
[11:00:53.539] iteration 8116 : model1 loss : 0.437787 model2 loss : 0.026448
[11:00:53.704] iteration 8117 : model1 loss : 0.440673 model2 loss : 0.028267
[11:00:53.869] iteration 8118 : model1 loss : 0.443055 model2 loss : 0.029490
[11:00:55.788] iteration 8119 : model1 loss : 0.440908 model2 loss : 0.032103
[11:00:55.955] iteration 8120 : model1 loss : 0.439195 model2 loss : 0.029256
[11:00:56.125] iteration 8121 : model1 loss : 0.434769 model2 loss : 0.023617
[11:00:56.291] iteration 8122 : model1 loss : 0.432463 model2 loss : 0.021589
[11:00:56.459] iteration 8123 : model1 loss : 0.439006 model2 loss : 0.027182
[11:00:56.628] iteration 8124 : model1 loss : 0.441456 model2 loss : 0.031145
[11:00:56.796] iteration 8125 : model1 loss : 0.438413 model2 loss : 0.025674
[11:00:56.962] iteration 8126 : model1 loss : 0.434864 model2 loss : 0.022895
[11:00:57.132] iteration 8127 : model1 loss : 0.436204 model2 loss : 0.026866
[11:00:57.296] iteration 8128 : model1 loss : 0.441036 model2 loss : 0.028576
[11:00:57.461] iteration 8129 : model1 loss : 0.437591 model2 loss : 0.027375
[11:00:57.627] iteration 8130 : model1 loss : 0.435365 model2 loss : 0.027265
[11:00:57.794] iteration 8131 : model1 loss : 0.440234 model2 loss : 0.034090
[11:00:57.960] iteration 8132 : model1 loss : 0.436361 model2 loss : 0.028035
[11:00:58.125] iteration 8133 : model1 loss : 0.434924 model2 loss : 0.028089
[11:00:58.292] iteration 8134 : model1 loss : 0.439415 model2 loss : 0.026736
[11:00:58.459] iteration 8135 : model1 loss : 0.435920 model2 loss : 0.027044
[11:00:58.626] iteration 8136 : model1 loss : 0.436769 model2 loss : 0.027122
[11:00:58.796] iteration 8137 : model1 loss : 0.438889 model2 loss : 0.028725
[11:00:58.961] iteration 8138 : model1 loss : 0.436748 model2 loss : 0.024494
[11:00:59.129] iteration 8139 : model1 loss : 0.438089 model2 loss : 0.029660
[11:00:59.295] iteration 8140 : model1 loss : 0.434831 model2 loss : 0.027859
[11:00:59.464] iteration 8141 : model1 loss : 0.437460 model2 loss : 0.024762
[11:00:59.630] iteration 8142 : model1 loss : 0.440953 model2 loss : 0.029588
[11:00:59.797] iteration 8143 : model1 loss : 0.441027 model2 loss : 0.029926
[11:00:59.963] iteration 8144 : model1 loss : 0.433927 model2 loss : 0.026711
[11:01:00.134] iteration 8145 : model1 loss : 0.437669 model2 loss : 0.027692
[11:01:00.299] iteration 8146 : model1 loss : 0.436537 model2 loss : 0.028723
[11:01:00.468] iteration 8147 : model1 loss : 0.436636 model2 loss : 0.027859
[11:01:00.640] iteration 8148 : model1 loss : 0.437618 model2 loss : 0.026145
[11:01:00.808] iteration 8149 : model1 loss : 0.440026 model2 loss : 0.027928
[11:01:00.974] iteration 8150 : model1 loss : 0.439973 model2 loss : 0.025279
[11:01:01.140] iteration 8151 : model1 loss : 0.439261 model2 loss : 0.028251
[11:01:03.072] iteration 8152 : model1 loss : 0.433442 model2 loss : 0.026637
[11:01:03.243] iteration 8153 : model1 loss : 0.434970 model2 loss : 0.027467
[11:01:03.412] iteration 8154 : model1 loss : 0.436262 model2 loss : 0.024288
[11:01:03.580] iteration 8155 : model1 loss : 0.444039 model2 loss : 0.032034
[11:01:03.748] iteration 8156 : model1 loss : 0.435373 model2 loss : 0.025701
[11:01:03.914] iteration 8157 : model1 loss : 0.436037 model2 loss : 0.027026
[11:01:04.082] iteration 8158 : model1 loss : 0.436065 model2 loss : 0.026383
[11:01:04.247] iteration 8159 : model1 loss : 0.435519 model2 loss : 0.027455
[11:01:04.416] iteration 8160 : model1 loss : 0.440375 model2 loss : 0.025046
[11:01:04.587] iteration 8161 : model1 loss : 0.439231 model2 loss : 0.030899
[11:01:04.754] iteration 8162 : model1 loss : 0.439480 model2 loss : 0.030191
[11:01:04.920] iteration 8163 : model1 loss : 0.436262 model2 loss : 0.025228
[11:01:05.090] iteration 8164 : model1 loss : 0.436880 model2 loss : 0.025832
[11:01:05.254] iteration 8165 : model1 loss : 0.440372 model2 loss : 0.030566
[11:01:05.423] iteration 8166 : model1 loss : 0.437377 model2 loss : 0.026787
[11:01:05.590] iteration 8167 : model1 loss : 0.438511 model2 loss : 0.025457
[11:01:05.759] iteration 8168 : model1 loss : 0.442314 model2 loss : 0.029921
[11:01:05.927] iteration 8169 : model1 loss : 0.437019 model2 loss : 0.027172
[11:01:06.095] iteration 8170 : model1 loss : 0.435707 model2 loss : 0.026442
[11:01:06.260] iteration 8171 : model1 loss : 0.433690 model2 loss : 0.027921
[11:01:06.430] iteration 8172 : model1 loss : 0.435685 model2 loss : 0.025212
[11:01:06.599] iteration 8173 : model1 loss : 0.440189 model2 loss : 0.029062
[11:01:06.767] iteration 8174 : model1 loss : 0.433988 model2 loss : 0.023830
[11:01:06.932] iteration 8175 : model1 loss : 0.436712 model2 loss : 0.026214
[11:01:07.099] iteration 8176 : model1 loss : 0.440838 model2 loss : 0.026656
[11:01:07.264] iteration 8177 : model1 loss : 0.437470 model2 loss : 0.028273
[11:01:07.432] iteration 8178 : model1 loss : 0.438735 model2 loss : 0.029042
[11:01:07.601] iteration 8179 : model1 loss : 0.436771 model2 loss : 0.030684
[11:01:07.769] iteration 8180 : model1 loss : 0.435282 model2 loss : 0.024984
[11:01:07.935] iteration 8181 : model1 loss : 0.440115 model2 loss : 0.027383
[11:01:08.103] iteration 8182 : model1 loss : 0.438309 model2 loss : 0.026740
[11:01:08.269] iteration 8183 : model1 loss : 0.436960 model2 loss : 0.022589
[11:01:08.437] iteration 8184 : model1 loss : 0.439742 model2 loss : 0.027402
[11:01:10.362] iteration 8185 : model1 loss : 0.440970 model2 loss : 0.025243
[11:01:10.533] iteration 8186 : model1 loss : 0.438031 model2 loss : 0.026965
[11:01:10.704] iteration 8187 : model1 loss : 0.438317 model2 loss : 0.025252
[11:01:10.873] iteration 8188 : model1 loss : 0.436465 model2 loss : 0.024389
[11:01:11.043] iteration 8189 : model1 loss : 0.437834 model2 loss : 0.025980
[11:01:11.209] iteration 8190 : model1 loss : 0.435085 model2 loss : 0.027747
[11:01:11.377] iteration 8191 : model1 loss : 0.442302 model2 loss : 0.026264
[11:01:11.545] iteration 8192 : model1 loss : 0.442603 model2 loss : 0.027639
[11:01:11.711] iteration 8193 : model1 loss : 0.435345 model2 loss : 0.025395
[11:01:11.876] iteration 8194 : model1 loss : 0.439144 model2 loss : 0.024818
[11:01:12.043] iteration 8195 : model1 loss : 0.440203 model2 loss : 0.032274
[11:01:12.208] iteration 8196 : model1 loss : 0.441276 model2 loss : 0.028219
[11:01:12.378] iteration 8197 : model1 loss : 0.437395 model2 loss : 0.025476
[11:01:12.546] iteration 8198 : model1 loss : 0.435791 model2 loss : 0.030747
[11:01:12.714] iteration 8199 : model1 loss : 0.433523 model2 loss : 0.025656
[11:01:12.882] iteration 8200 : model1 loss : 0.438779 model2 loss : 0.027447
[11:01:13.050] iteration 8201 : model1 loss : 0.432899 model2 loss : 0.025750
[11:01:13.215] iteration 8202 : model1 loss : 0.433384 model2 loss : 0.024399
[11:01:13.383] iteration 8203 : model1 loss : 0.437092 model2 loss : 0.027248
[11:01:13.550] iteration 8204 : model1 loss : 0.439162 model2 loss : 0.029687
[11:01:13.719] iteration 8205 : model1 loss : 0.444991 model2 loss : 0.034611
[11:01:13.884] iteration 8206 : model1 loss : 0.438822 model2 loss : 0.028297
[11:01:14.054] iteration 8207 : model1 loss : 0.437130 model2 loss : 0.028369
[11:01:14.218] iteration 8208 : model1 loss : 0.435877 model2 loss : 0.025164
[11:01:14.390] iteration 8209 : model1 loss : 0.434403 model2 loss : 0.024531
[11:01:14.557] iteration 8210 : model1 loss : 0.435660 model2 loss : 0.027780
[11:01:14.725] iteration 8211 : model1 loss : 0.436137 model2 loss : 0.027368
[11:01:14.892] iteration 8212 : model1 loss : 0.442846 model2 loss : 0.028761
[11:01:15.059] iteration 8213 : model1 loss : 0.439002 model2 loss : 0.027096
[11:01:15.226] iteration 8214 : model1 loss : 0.433830 model2 loss : 0.023329
[11:01:15.394] iteration 8215 : model1 loss : 0.437640 model2 loss : 0.027612
[11:01:15.562] iteration 8216 : model1 loss : 0.438085 model2 loss : 0.026744
[11:01:15.730] iteration 8217 : model1 loss : 0.437667 model2 loss : 0.025510
[11:01:17.696] iteration 8218 : model1 loss : 0.437509 model2 loss : 0.028768
[11:01:17.864] iteration 8219 : model1 loss : 0.436951 model2 loss : 0.028146
[11:01:18.032] iteration 8220 : model1 loss : 0.437263 model2 loss : 0.025617
[11:01:18.201] iteration 8221 : model1 loss : 0.436925 model2 loss : 0.024817
[11:01:18.367] iteration 8222 : model1 loss : 0.436749 model2 loss : 0.026726
[11:01:18.535] iteration 8223 : model1 loss : 0.437208 model2 loss : 0.025927
[11:01:18.708] iteration 8224 : model1 loss : 0.441707 model2 loss : 0.035418
[11:01:18.873] iteration 8225 : model1 loss : 0.438534 model2 loss : 0.026336
[11:01:19.042] iteration 8226 : model1 loss : 0.432702 model2 loss : 0.024564
[11:01:19.206] iteration 8227 : model1 loss : 0.442561 model2 loss : 0.027157
[11:01:19.376] iteration 8228 : model1 loss : 0.433361 model2 loss : 0.025790
[11:01:19.542] iteration 8229 : model1 loss : 0.435530 model2 loss : 0.024085
[11:01:19.710] iteration 8230 : model1 loss : 0.437747 model2 loss : 0.029098
[11:01:19.878] iteration 8231 : model1 loss : 0.437866 model2 loss : 0.025307
[11:01:20.047] iteration 8232 : model1 loss : 0.434579 model2 loss : 0.023124
[11:01:20.212] iteration 8233 : model1 loss : 0.434335 model2 loss : 0.026708
[11:01:20.381] iteration 8234 : model1 loss : 0.437904 model2 loss : 0.025917
[11:01:20.548] iteration 8235 : model1 loss : 0.436790 model2 loss : 0.027463
[11:01:20.717] iteration 8236 : model1 loss : 0.439510 model2 loss : 0.026185
[11:01:20.890] iteration 8237 : model1 loss : 0.441470 model2 loss : 0.031809
[11:01:21.059] iteration 8238 : model1 loss : 0.433944 model2 loss : 0.025699
[11:01:21.227] iteration 8239 : model1 loss : 0.442129 model2 loss : 0.029248
[11:01:21.397] iteration 8240 : model1 loss : 0.434275 model2 loss : 0.025021
[11:01:21.562] iteration 8241 : model1 loss : 0.438694 model2 loss : 0.032270
[11:01:21.731] iteration 8242 : model1 loss : 0.439397 model2 loss : 0.025728
[11:01:21.898] iteration 8243 : model1 loss : 0.438694 model2 loss : 0.026877
[11:01:22.068] iteration 8244 : model1 loss : 0.438528 model2 loss : 0.026616
[11:01:22.234] iteration 8245 : model1 loss : 0.439377 model2 loss : 0.025422
[11:01:22.403] iteration 8246 : model1 loss : 0.435261 model2 loss : 0.024190
[11:01:22.570] iteration 8247 : model1 loss : 0.438657 model2 loss : 0.025164
[11:01:22.741] iteration 8248 : model1 loss : 0.436953 model2 loss : 0.027494
[11:01:22.906] iteration 8249 : model1 loss : 0.433806 model2 loss : 0.028572
[11:01:23.073] iteration 8250 : model1 loss : 0.437983 model2 loss : 0.029436
[11:01:25.007] iteration 8251 : model1 loss : 0.437031 model2 loss : 0.026082
[11:01:25.173] iteration 8252 : model1 loss : 0.434384 model2 loss : 0.024870
[11:01:25.343] iteration 8253 : model1 loss : 0.436414 model2 loss : 0.022803
[11:01:25.516] iteration 8254 : model1 loss : 0.437786 model2 loss : 0.028732
[11:01:25.687] iteration 8255 : model1 loss : 0.436602 model2 loss : 0.021590
[11:01:25.855] iteration 8256 : model1 loss : 0.436057 model2 loss : 0.023800
[11:01:26.022] iteration 8257 : model1 loss : 0.440801 model2 loss : 0.028434
[11:01:26.188] iteration 8258 : model1 loss : 0.440655 model2 loss : 0.028724
[11:01:26.359] iteration 8259 : model1 loss : 0.439733 model2 loss : 0.027475
[11:01:26.529] iteration 8260 : model1 loss : 0.432754 model2 loss : 0.022911
[11:01:26.698] iteration 8261 : model1 loss : 0.439114 model2 loss : 0.027814
[11:01:26.865] iteration 8262 : model1 loss : 0.435192 model2 loss : 0.025171
[11:01:27.032] iteration 8263 : model1 loss : 0.434587 model2 loss : 0.025783
[11:01:27.199] iteration 8264 : model1 loss : 0.438203 model2 loss : 0.026915
[11:01:27.368] iteration 8265 : model1 loss : 0.437713 model2 loss : 0.028452
[11:01:27.536] iteration 8266 : model1 loss : 0.443616 model2 loss : 0.031556
[11:01:27.706] iteration 8267 : model1 loss : 0.437022 model2 loss : 0.028705
[11:01:27.872] iteration 8268 : model1 loss : 0.436493 model2 loss : 0.024634
[11:01:28.043] iteration 8269 : model1 loss : 0.438101 model2 loss : 0.026809
[11:01:28.209] iteration 8270 : model1 loss : 0.437826 model2 loss : 0.027125
[11:01:28.389] iteration 8271 : model1 loss : 0.439692 model2 loss : 0.029836
[11:01:28.556] iteration 8272 : model1 loss : 0.441010 model2 loss : 0.026553
[11:01:28.727] iteration 8273 : model1 loss : 0.435345 model2 loss : 0.030595
[11:01:28.895] iteration 8274 : model1 loss : 0.438374 model2 loss : 0.026121
[11:01:29.064] iteration 8275 : model1 loss : 0.440968 model2 loss : 0.027892
[11:01:29.232] iteration 8276 : model1 loss : 0.435526 model2 loss : 0.027253
[11:01:29.401] iteration 8277 : model1 loss : 0.437408 model2 loss : 0.031500
[11:01:29.569] iteration 8278 : model1 loss : 0.435612 model2 loss : 0.028642
[11:01:29.741] iteration 8279 : model1 loss : 0.435386 model2 loss : 0.023776
[11:01:29.907] iteration 8280 : model1 loss : 0.434420 model2 loss : 0.024375
[11:01:30.077] iteration 8281 : model1 loss : 0.434501 model2 loss : 0.022739
[11:01:30.242] iteration 8282 : model1 loss : 0.440150 model2 loss : 0.026741
[11:01:30.410] iteration 8283 : model1 loss : 0.436577 model2 loss : 0.030950
[11:01:32.355] iteration 8284 : model1 loss : 0.438817 model2 loss : 0.028025
[11:01:32.522] iteration 8285 : model1 loss : 0.437392 model2 loss : 0.026010
[11:01:32.693] iteration 8286 : model1 loss : 0.435387 model2 loss : 0.024881
[11:01:32.860] iteration 8287 : model1 loss : 0.440315 model2 loss : 0.030110
[11:01:33.028] iteration 8288 : model1 loss : 0.443748 model2 loss : 0.032623
[11:01:33.194] iteration 8289 : model1 loss : 0.441579 model2 loss : 0.029532
[11:01:33.362] iteration 8290 : model1 loss : 0.438027 model2 loss : 0.027148
[11:01:33.531] iteration 8291 : model1 loss : 0.436399 model2 loss : 0.023879
[11:01:33.703] iteration 8292 : model1 loss : 0.439890 model2 loss : 0.029145
[11:01:33.869] iteration 8293 : model1 loss : 0.438915 model2 loss : 0.026430
[11:01:34.040] iteration 8294 : model1 loss : 0.436846 model2 loss : 0.027472
[11:01:34.207] iteration 8295 : model1 loss : 0.435795 model2 loss : 0.025205
[11:01:34.376] iteration 8296 : model1 loss : 0.432384 model2 loss : 0.025247
[11:01:34.544] iteration 8297 : model1 loss : 0.437759 model2 loss : 0.027791
[11:01:34.716] iteration 8298 : model1 loss : 0.436878 model2 loss : 0.027895
[11:01:34.883] iteration 8299 : model1 loss : 0.432203 model2 loss : 0.023751
[11:01:35.051] iteration 8300 : model1 loss : 0.436978 model2 loss : 0.025621
[11:01:35.217] iteration 8301 : model1 loss : 0.433496 model2 loss : 0.023891
[11:01:35.387] iteration 8302 : model1 loss : 0.435253 model2 loss : 0.023480
[11:01:35.554] iteration 8303 : model1 loss : 0.439279 model2 loss : 0.030203
[11:01:35.726] iteration 8304 : model1 loss : 0.439444 model2 loss : 0.026973
[11:01:35.898] iteration 8305 : model1 loss : 0.432307 model2 loss : 0.024448
[11:01:36.070] iteration 8306 : model1 loss : 0.435635 model2 loss : 0.023208
[11:01:36.235] iteration 8307 : model1 loss : 0.444042 model2 loss : 0.026969
[11:01:36.406] iteration 8308 : model1 loss : 0.440912 model2 loss : 0.027789
[11:01:36.573] iteration 8309 : model1 loss : 0.437783 model2 loss : 0.026384
[11:01:36.747] iteration 8310 : model1 loss : 0.434418 model2 loss : 0.028635
[11:01:36.916] iteration 8311 : model1 loss : 0.440040 model2 loss : 0.025233
[11:01:37.085] iteration 8312 : model1 loss : 0.438136 model2 loss : 0.028767
[11:01:37.251] iteration 8313 : model1 loss : 0.435068 model2 loss : 0.025658
[11:01:37.420] iteration 8314 : model1 loss : 0.437244 model2 loss : 0.030842
[11:01:37.587] iteration 8315 : model1 loss : 0.438327 model2 loss : 0.029714
[11:01:37.771] iteration 8316 : model1 loss : 0.438007 model2 loss : 0.030151
[11:01:39.725] iteration 8317 : model1 loss : 0.433317 model2 loss : 0.026234
[11:01:39.898] iteration 8318 : model1 loss : 0.437860 model2 loss : 0.024915
[11:01:40.070] iteration 8319 : model1 loss : 0.437911 model2 loss : 0.028308
[11:01:40.236] iteration 8320 : model1 loss : 0.439296 model2 loss : 0.031692
[11:01:40.406] iteration 8321 : model1 loss : 0.435669 model2 loss : 0.024247
[11:01:40.577] iteration 8322 : model1 loss : 0.437742 model2 loss : 0.027750
[11:01:40.749] iteration 8323 : model1 loss : 0.433307 model2 loss : 0.024709
[11:01:40.936] iteration 8324 : model1 loss : 0.438511 model2 loss : 0.023937
[11:01:41.108] iteration 8325 : model1 loss : 0.432539 model2 loss : 0.026254
[11:01:41.276] iteration 8326 : model1 loss : 0.440306 model2 loss : 0.028781
[11:01:41.444] iteration 8327 : model1 loss : 0.440287 model2 loss : 0.032938
[11:01:41.612] iteration 8328 : model1 loss : 0.436805 model2 loss : 0.028672
[11:01:41.781] iteration 8329 : model1 loss : 0.442142 model2 loss : 0.025306
[11:01:41.948] iteration 8330 : model1 loss : 0.438065 model2 loss : 0.026139
[11:01:42.118] iteration 8331 : model1 loss : 0.439083 model2 loss : 0.026165
[11:01:42.285] iteration 8332 : model1 loss : 0.437697 model2 loss : 0.024498
[11:01:42.454] iteration 8333 : model1 loss : 0.433614 model2 loss : 0.024909
[11:01:42.621] iteration 8334 : model1 loss : 0.436497 model2 loss : 0.025849
[11:01:42.791] iteration 8335 : model1 loss : 0.441329 model2 loss : 0.030146
[11:01:42.957] iteration 8336 : model1 loss : 0.436102 model2 loss : 0.025733
[11:01:43.126] iteration 8337 : model1 loss : 0.436586 model2 loss : 0.027204
[11:01:43.295] iteration 8338 : model1 loss : 0.441109 model2 loss : 0.026263
[11:01:43.465] iteration 8339 : model1 loss : 0.433396 model2 loss : 0.025083
[11:01:43.633] iteration 8340 : model1 loss : 0.439563 model2 loss : 0.026173
[11:01:43.803] iteration 8341 : model1 loss : 0.432981 model2 loss : 0.022126
[11:01:43.970] iteration 8342 : model1 loss : 0.439486 model2 loss : 0.030217
[11:01:44.139] iteration 8343 : model1 loss : 0.438808 model2 loss : 0.030193
[11:01:44.306] iteration 8344 : model1 loss : 0.436631 model2 loss : 0.024363
[11:01:44.475] iteration 8345 : model1 loss : 0.440600 model2 loss : 0.028987
[11:01:44.646] iteration 8346 : model1 loss : 0.440098 model2 loss : 0.025109
[11:01:44.821] iteration 8347 : model1 loss : 0.438692 model2 loss : 0.029077
[11:01:44.987] iteration 8348 : model1 loss : 0.431859 model2 loss : 0.029074
[11:01:45.154] iteration 8349 : model1 loss : 0.436425 model2 loss : 0.025410
[11:01:47.076] iteration 8350 : model1 loss : 0.437666 model2 loss : 0.026015
[11:01:47.244] iteration 8351 : model1 loss : 0.435816 model2 loss : 0.024563
[11:01:47.414] iteration 8352 : model1 loss : 0.438327 model2 loss : 0.026463
[11:01:47.582] iteration 8353 : model1 loss : 0.435833 model2 loss : 0.024340
[11:01:47.755] iteration 8354 : model1 loss : 0.439231 model2 loss : 0.024733
[11:01:47.921] iteration 8355 : model1 loss : 0.438080 model2 loss : 0.026305
[11:01:48.091] iteration 8356 : model1 loss : 0.436392 model2 loss : 0.026861
[11:01:48.259] iteration 8357 : model1 loss : 0.435566 model2 loss : 0.024012
[11:01:48.428] iteration 8358 : model1 loss : 0.438708 model2 loss : 0.026499
[11:01:48.595] iteration 8359 : model1 loss : 0.436219 model2 loss : 0.026017
[11:01:48.767] iteration 8360 : model1 loss : 0.435565 model2 loss : 0.025856
[11:01:48.933] iteration 8361 : model1 loss : 0.438327 model2 loss : 0.024699
[11:01:49.103] iteration 8362 : model1 loss : 0.437979 model2 loss : 0.028442
[11:01:49.269] iteration 8363 : model1 loss : 0.436178 model2 loss : 0.027684
[11:01:49.437] iteration 8364 : model1 loss : 0.437859 model2 loss : 0.026034
[11:01:49.605] iteration 8365 : model1 loss : 0.438299 model2 loss : 0.025748
[11:01:49.777] iteration 8366 : model1 loss : 0.437705 model2 loss : 0.027451
[11:01:49.944] iteration 8367 : model1 loss : 0.436847 model2 loss : 0.028615
[11:01:50.111] iteration 8368 : model1 loss : 0.436693 model2 loss : 0.025115
[11:01:50.279] iteration 8369 : model1 loss : 0.439348 model2 loss : 0.025624
[11:01:50.448] iteration 8370 : model1 loss : 0.433844 model2 loss : 0.024242
[11:01:50.615] iteration 8371 : model1 loss : 0.436042 model2 loss : 0.027277
[11:01:50.783] iteration 8372 : model1 loss : 0.437941 model2 loss : 0.028018
[11:01:50.949] iteration 8373 : model1 loss : 0.441812 model2 loss : 0.032529
[11:01:51.120] iteration 8374 : model1 loss : 0.438119 model2 loss : 0.026475
[11:01:51.286] iteration 8375 : model1 loss : 0.434245 model2 loss : 0.027895
[11:01:51.454] iteration 8376 : model1 loss : 0.438906 model2 loss : 0.028903
[11:01:51.621] iteration 8377 : model1 loss : 0.436149 model2 loss : 0.028059
[11:01:51.788] iteration 8378 : model1 loss : 0.440310 model2 loss : 0.032107
[11:01:51.954] iteration 8379 : model1 loss : 0.440362 model2 loss : 0.030493
[11:01:52.122] iteration 8380 : model1 loss : 0.433542 model2 loss : 0.025539
[11:01:52.287] iteration 8381 : model1 loss : 0.439263 model2 loss : 0.028106
[11:01:52.454] iteration 8382 : model1 loss : 0.434906 model2 loss : 0.024579
[11:01:54.371] iteration 8383 : model1 loss : 0.438899 model2 loss : 0.024714
[11:01:54.538] iteration 8384 : model1 loss : 0.437355 model2 loss : 0.026043
[11:01:54.709] iteration 8385 : model1 loss : 0.433451 model2 loss : 0.023107
[11:01:54.876] iteration 8386 : model1 loss : 0.442602 model2 loss : 0.023816
[11:01:55.045] iteration 8387 : model1 loss : 0.445255 model2 loss : 0.028450
[11:01:55.213] iteration 8388 : model1 loss : 0.438853 model2 loss : 0.031842
[11:01:55.390] iteration 8389 : model1 loss : 0.435261 model2 loss : 0.024072
[11:01:55.556] iteration 8390 : model1 loss : 0.433363 model2 loss : 0.023303
[11:01:55.726] iteration 8391 : model1 loss : 0.436644 model2 loss : 0.024471
[11:01:55.895] iteration 8392 : model1 loss : 0.437197 model2 loss : 0.028173
[11:01:56.064] iteration 8393 : model1 loss : 0.439451 model2 loss : 0.026743
[11:01:56.231] iteration 8394 : model1 loss : 0.439224 model2 loss : 0.023479
[11:01:56.398] iteration 8395 : model1 loss : 0.438240 model2 loss : 0.024308
[11:01:56.565] iteration 8396 : model1 loss : 0.434209 model2 loss : 0.026822
[11:01:56.736] iteration 8397 : model1 loss : 0.435160 model2 loss : 0.025327
[11:01:56.904] iteration 8398 : model1 loss : 0.438065 model2 loss : 0.030261
[11:01:57.072] iteration 8399 : model1 loss : 0.440463 model2 loss : 0.027402
[11:01:57.241] iteration 8400 : model1 loss : 0.439461 model2 loss : 0.027376
[11:01:57.409] iteration 8401 : model1 loss : 0.433859 model2 loss : 0.030137
[11:01:57.576] iteration 8402 : model1 loss : 0.437660 model2 loss : 0.022495
[11:01:57.748] iteration 8403 : model1 loss : 0.440459 model2 loss : 0.025474
[11:01:57.914] iteration 8404 : model1 loss : 0.438823 model2 loss : 0.026818
[11:01:58.083] iteration 8405 : model1 loss : 0.436126 model2 loss : 0.028755
[11:01:58.249] iteration 8406 : model1 loss : 0.443133 model2 loss : 0.027912
[11:01:58.419] iteration 8407 : model1 loss : 0.441315 model2 loss : 0.032770
[11:01:58.587] iteration 8408 : model1 loss : 0.434716 model2 loss : 0.021323
[11:01:58.760] iteration 8409 : model1 loss : 0.438380 model2 loss : 0.028566
[11:01:58.928] iteration 8410 : model1 loss : 0.437426 model2 loss : 0.024840
[11:01:59.097] iteration 8411 : model1 loss : 0.438933 model2 loss : 0.028450
[11:01:59.264] iteration 8412 : model1 loss : 0.440486 model2 loss : 0.027620
[11:01:59.434] iteration 8413 : model1 loss : 0.448663 model2 loss : 0.028155
[11:01:59.601] iteration 8414 : model1 loss : 0.439274 model2 loss : 0.025500
[11:01:59.773] iteration 8415 : model1 loss : 0.443542 model2 loss : 0.027566
[11:02:01.736] iteration 8416 : model1 loss : 0.440276 model2 loss : 0.029580
[11:02:01.903] iteration 8417 : model1 loss : 0.436185 model2 loss : 0.027050
[11:02:02.071] iteration 8418 : model1 loss : 0.439702 model2 loss : 0.030548
[11:02:02.238] iteration 8419 : model1 loss : 0.440499 model2 loss : 0.026375
[11:02:02.409] iteration 8420 : model1 loss : 0.436778 model2 loss : 0.025784
[11:02:02.575] iteration 8421 : model1 loss : 0.444337 model2 loss : 0.028453
[11:02:02.742] iteration 8422 : model1 loss : 0.447470 model2 loss : 0.033946
[11:02:02.908] iteration 8423 : model1 loss : 0.434567 model2 loss : 0.026310
[11:02:03.076] iteration 8424 : model1 loss : 0.436231 model2 loss : 0.027026
[11:02:03.241] iteration 8425 : model1 loss : 0.435640 model2 loss : 0.023907
[11:02:03.409] iteration 8426 : model1 loss : 0.435238 model2 loss : 0.027908
[11:02:03.578] iteration 8427 : model1 loss : 0.438970 model2 loss : 0.024408
[11:02:03.749] iteration 8428 : model1 loss : 0.440133 model2 loss : 0.030582
[11:02:03.917] iteration 8429 : model1 loss : 0.437849 model2 loss : 0.031106
[11:02:04.085] iteration 8430 : model1 loss : 0.437734 model2 loss : 0.028493
[11:02:04.252] iteration 8431 : model1 loss : 0.439467 model2 loss : 0.027022
[11:02:04.421] iteration 8432 : model1 loss : 0.436638 model2 loss : 0.027126
[11:02:04.587] iteration 8433 : model1 loss : 0.437086 model2 loss : 0.025583
[11:02:04.758] iteration 8434 : model1 loss : 0.435357 model2 loss : 0.024774
[11:02:04.925] iteration 8435 : model1 loss : 0.436982 model2 loss : 0.023388
[11:02:05.094] iteration 8436 : model1 loss : 0.436663 model2 loss : 0.028235
[11:02:05.260] iteration 8437 : model1 loss : 0.440244 model2 loss : 0.028490
[11:02:05.430] iteration 8438 : model1 loss : 0.434371 model2 loss : 0.024236
[11:02:05.596] iteration 8439 : model1 loss : 0.436664 model2 loss : 0.027251
[11:02:05.775] iteration 8440 : model1 loss : 0.434316 model2 loss : 0.023794
[11:02:05.943] iteration 8441 : model1 loss : 0.439538 model2 loss : 0.026039
[11:02:06.111] iteration 8442 : model1 loss : 0.438300 model2 loss : 0.027102
[11:02:06.277] iteration 8443 : model1 loss : 0.437240 model2 loss : 0.023974
[11:02:06.447] iteration 8444 : model1 loss : 0.437145 model2 loss : 0.024691
[11:02:06.615] iteration 8445 : model1 loss : 0.438514 model2 loss : 0.027128
[11:02:06.786] iteration 8446 : model1 loss : 0.438928 model2 loss : 0.024509
[11:02:06.952] iteration 8447 : model1 loss : 0.434743 model2 loss : 0.022106
[11:02:07.118] iteration 8448 : model1 loss : 0.439349 model2 loss : 0.030134
[11:02:09.035] iteration 8449 : model1 loss : 0.431651 model2 loss : 0.023729
[11:02:09.203] iteration 8450 : model1 loss : 0.442604 model2 loss : 0.026797
[11:02:09.374] iteration 8451 : model1 loss : 0.435511 model2 loss : 0.025895
[11:02:09.544] iteration 8452 : model1 loss : 0.437553 model2 loss : 0.027764
[11:02:09.714] iteration 8453 : model1 loss : 0.439200 model2 loss : 0.026081
[11:02:09.883] iteration 8454 : model1 loss : 0.443137 model2 loss : 0.028947
[11:02:10.053] iteration 8455 : model1 loss : 0.433985 model2 loss : 0.027400
[11:02:10.219] iteration 8456 : model1 loss : 0.443396 model2 loss : 0.032462
[11:02:10.387] iteration 8457 : model1 loss : 0.439495 model2 loss : 0.028654
[11:02:10.558] iteration 8458 : model1 loss : 0.444403 model2 loss : 0.028984
[11:02:10.728] iteration 8459 : model1 loss : 0.433725 model2 loss : 0.023557
[11:02:10.897] iteration 8460 : model1 loss : 0.441145 model2 loss : 0.032497
[11:02:11.066] iteration 8461 : model1 loss : 0.436528 model2 loss : 0.026946
[11:02:11.233] iteration 8462 : model1 loss : 0.440051 model2 loss : 0.030731
[11:02:11.401] iteration 8463 : model1 loss : 0.439937 model2 loss : 0.029635
[11:02:11.570] iteration 8464 : model1 loss : 0.437761 model2 loss : 0.024606
[11:02:11.737] iteration 8465 : model1 loss : 0.437395 model2 loss : 0.026486
[11:02:11.905] iteration 8466 : model1 loss : 0.436331 model2 loss : 0.028434
[11:02:12.074] iteration 8467 : model1 loss : 0.434420 model2 loss : 0.025218
[11:02:12.242] iteration 8468 : model1 loss : 0.439876 model2 loss : 0.025111
[11:02:12.409] iteration 8469 : model1 loss : 0.434183 model2 loss : 0.024494
[11:02:12.577] iteration 8470 : model1 loss : 0.437922 model2 loss : 0.024822
[11:02:12.744] iteration 8471 : model1 loss : 0.439908 model2 loss : 0.029920
[11:02:12.911] iteration 8472 : model1 loss : 0.437679 model2 loss : 0.027844
[11:02:13.078] iteration 8473 : model1 loss : 0.441499 model2 loss : 0.028494
[11:02:13.246] iteration 8474 : model1 loss : 0.439810 model2 loss : 0.026771
[11:02:13.416] iteration 8475 : model1 loss : 0.442845 model2 loss : 0.033422
[11:02:13.581] iteration 8476 : model1 loss : 0.440466 model2 loss : 0.029817
[11:02:13.753] iteration 8477 : model1 loss : 0.437688 model2 loss : 0.027349
[11:02:13.919] iteration 8478 : model1 loss : 0.435287 model2 loss : 0.028460
[11:02:14.086] iteration 8479 : model1 loss : 0.432810 model2 loss : 0.027626
[11:02:14.253] iteration 8480 : model1 loss : 0.433879 model2 loss : 0.025922
[11:02:14.421] iteration 8481 : model1 loss : 0.438280 model2 loss : 0.026147
[11:02:16.378] iteration 8482 : model1 loss : 0.437012 model2 loss : 0.023586
[11:02:16.548] iteration 8483 : model1 loss : 0.437426 model2 loss : 0.025800
[11:02:16.720] iteration 8484 : model1 loss : 0.435448 model2 loss : 0.023963
[11:02:16.887] iteration 8485 : model1 loss : 0.440014 model2 loss : 0.028068
[11:02:17.056] iteration 8486 : model1 loss : 0.440052 model2 loss : 0.030723
[11:02:17.221] iteration 8487 : model1 loss : 0.434619 model2 loss : 0.025853
[11:02:17.391] iteration 8488 : model1 loss : 0.436318 model2 loss : 0.028599
[11:02:17.560] iteration 8489 : model1 loss : 0.440686 model2 loss : 0.028008
[11:02:17.728] iteration 8490 : model1 loss : 0.440346 model2 loss : 0.026383
[11:02:17.895] iteration 8491 : model1 loss : 0.438020 model2 loss : 0.027816
[11:02:18.064] iteration 8492 : model1 loss : 0.436985 model2 loss : 0.026527
[11:02:18.234] iteration 8493 : model1 loss : 0.437868 model2 loss : 0.029951
[11:02:18.402] iteration 8494 : model1 loss : 0.438560 model2 loss : 0.026433
[11:02:18.568] iteration 8495 : model1 loss : 0.441263 model2 loss : 0.027503
[11:02:18.737] iteration 8496 : model1 loss : 0.435452 model2 loss : 0.025474
[11:02:18.906] iteration 8497 : model1 loss : 0.436380 model2 loss : 0.026432
[11:02:19.076] iteration 8498 : model1 loss : 0.434924 model2 loss : 0.026543
[11:02:19.242] iteration 8499 : model1 loss : 0.438558 model2 loss : 0.029044
[11:02:19.411] iteration 8500 : model1 loss : 0.439158 model2 loss : 0.029079
[11:02:19.579] iteration 8501 : model1 loss : 0.439130 model2 loss : 0.027937
[11:02:19.750] iteration 8502 : model1 loss : 0.434420 model2 loss : 0.026877
[11:02:19.918] iteration 8503 : model1 loss : 0.433212 model2 loss : 0.027760
[11:02:20.087] iteration 8504 : model1 loss : 0.438911 model2 loss : 0.031342
[11:02:20.255] iteration 8505 : model1 loss : 0.434571 model2 loss : 0.026655
[11:02:20.425] iteration 8506 : model1 loss : 0.439765 model2 loss : 0.029476
[11:02:20.592] iteration 8507 : model1 loss : 0.437496 model2 loss : 0.026407
[11:02:20.761] iteration 8508 : model1 loss : 0.440247 model2 loss : 0.024671
[11:02:20.928] iteration 8509 : model1 loss : 0.438560 model2 loss : 0.027286
[11:02:21.099] iteration 8510 : model1 loss : 0.435258 model2 loss : 0.027711
[11:02:21.265] iteration 8511 : model1 loss : 0.438288 model2 loss : 0.026326
[11:02:21.434] iteration 8512 : model1 loss : 0.436349 model2 loss : 0.027529
[11:02:21.601] iteration 8513 : model1 loss : 0.435123 model2 loss : 0.026864
[11:02:21.785] iteration 8514 : model1 loss : 0.437874 model2 loss : 0.024980
[11:02:23.681] iteration 8515 : model1 loss : 0.435801 model2 loss : 0.023524
[11:02:23.853] iteration 8516 : model1 loss : 0.436473 model2 loss : 0.026493
[11:02:24.024] iteration 8517 : model1 loss : 0.437493 model2 loss : 0.025390
[11:02:24.190] iteration 8518 : model1 loss : 0.440640 model2 loss : 0.026243
[11:02:24.360] iteration 8519 : model1 loss : 0.440120 model2 loss : 0.025339
[11:02:24.530] iteration 8520 : model1 loss : 0.437047 model2 loss : 0.029308
[11:02:24.699] iteration 8521 : model1 loss : 0.441253 model2 loss : 0.028856
[11:02:24.869] iteration 8522 : model1 loss : 0.442054 model2 loss : 0.036428
[11:02:25.036] iteration 8523 : model1 loss : 0.438580 model2 loss : 0.027732
[11:02:25.204] iteration 8524 : model1 loss : 0.438437 model2 loss : 0.027882
[11:02:25.372] iteration 8525 : model1 loss : 0.433245 model2 loss : 0.025756
[11:02:25.540] iteration 8526 : model1 loss : 0.440147 model2 loss : 0.030098
[11:02:25.708] iteration 8527 : model1 loss : 0.430950 model2 loss : 0.024214
[11:02:25.876] iteration 8528 : model1 loss : 0.438763 model2 loss : 0.027039
[11:02:26.046] iteration 8529 : model1 loss : 0.442945 model2 loss : 0.032546
[11:02:26.214] iteration 8530 : model1 loss : 0.435360 model2 loss : 0.037410
[11:02:26.383] iteration 8531 : model1 loss : 0.431066 model2 loss : 0.026614
[11:02:26.549] iteration 8532 : model1 loss : 0.440521 model2 loss : 0.029819
[11:02:26.717] iteration 8533 : model1 loss : 0.437311 model2 loss : 0.028250
[11:02:26.884] iteration 8534 : model1 loss : 0.440339 model2 loss : 0.023842
[11:02:27.053] iteration 8535 : model1 loss : 0.442782 model2 loss : 0.031127
[11:02:27.220] iteration 8536 : model1 loss : 0.431928 model2 loss : 0.024851
[11:02:27.387] iteration 8537 : model1 loss : 0.436528 model2 loss : 0.034659
[11:02:27.554] iteration 8538 : model1 loss : 0.434716 model2 loss : 0.025787
[11:02:27.722] iteration 8539 : model1 loss : 0.440505 model2 loss : 0.040050
[11:02:27.889] iteration 8540 : model1 loss : 0.437256 model2 loss : 0.027148
[11:02:28.058] iteration 8541 : model1 loss : 0.434711 model2 loss : 0.026486
[11:02:28.225] iteration 8542 : model1 loss : 0.436912 model2 loss : 0.023005
[11:02:28.394] iteration 8543 : model1 loss : 0.442239 model2 loss : 0.031135
[11:02:28.562] iteration 8544 : model1 loss : 0.435139 model2 loss : 0.031030
[11:02:28.730] iteration 8545 : model1 loss : 0.434465 model2 loss : 0.027233
[11:02:28.896] iteration 8546 : model1 loss : 0.439437 model2 loss : 0.032231
[11:02:29.065] iteration 8547 : model1 loss : 0.435414 model2 loss : 0.024951
[11:02:31.013] iteration 8548 : model1 loss : 0.437166 model2 loss : 0.028869
[11:02:31.186] iteration 8549 : model1 loss : 0.432165 model2 loss : 0.024974
[11:02:31.357] iteration 8550 : model1 loss : 0.438812 model2 loss : 0.027785
[11:02:31.527] iteration 8551 : model1 loss : 0.436502 model2 loss : 0.024654
[11:02:31.694] iteration 8552 : model1 loss : 0.438911 model2 loss : 0.031299
[11:02:31.861] iteration 8553 : model1 loss : 0.438657 model2 loss : 0.027078
[11:02:32.033] iteration 8554 : model1 loss : 0.437085 model2 loss : 0.024921
[11:02:32.200] iteration 8555 : model1 loss : 0.432979 model2 loss : 0.026594
[11:02:32.371] iteration 8556 : model1 loss : 0.437391 model2 loss : 0.028530
[11:02:32.539] iteration 8557 : model1 loss : 0.436178 model2 loss : 0.044871
[11:02:32.710] iteration 8558 : model1 loss : 0.431575 model2 loss : 0.026019
[11:02:32.877] iteration 8559 : model1 loss : 0.438500 model2 loss : 0.029367
[11:02:33.047] iteration 8560 : model1 loss : 0.439351 model2 loss : 0.029543
[11:02:33.216] iteration 8561 : model1 loss : 0.438120 model2 loss : 0.026580
[11:02:33.386] iteration 8562 : model1 loss : 0.438055 model2 loss : 0.033681
[11:02:33.554] iteration 8563 : model1 loss : 0.443041 model2 loss : 0.034816
[11:02:33.724] iteration 8564 : model1 loss : 0.435285 model2 loss : 0.027771
[11:02:33.892] iteration 8565 : model1 loss : 0.438380 model2 loss : 0.027469
[11:02:34.063] iteration 8566 : model1 loss : 0.435402 model2 loss : 0.026204
[11:02:34.230] iteration 8567 : model1 loss : 0.433467 model2 loss : 0.027202
[11:02:34.398] iteration 8568 : model1 loss : 0.435113 model2 loss : 0.026838
[11:02:34.568] iteration 8569 : model1 loss : 0.442676 model2 loss : 0.027483
[11:02:34.738] iteration 8570 : model1 loss : 0.438371 model2 loss : 0.033293
[11:02:34.904] iteration 8571 : model1 loss : 0.436829 model2 loss : 0.028038
[11:02:35.074] iteration 8572 : model1 loss : 0.441315 model2 loss : 0.029781
[11:02:35.243] iteration 8573 : model1 loss : 0.438963 model2 loss : 0.028159
[11:02:35.414] iteration 8574 : model1 loss : 0.436579 model2 loss : 0.029012
[11:02:35.582] iteration 8575 : model1 loss : 0.439263 model2 loss : 0.028575
[11:02:35.753] iteration 8576 : model1 loss : 0.437678 model2 loss : 0.024730
[11:02:35.920] iteration 8577 : model1 loss : 0.440571 model2 loss : 0.031868
[11:02:36.092] iteration 8578 : model1 loss : 0.431295 model2 loss : 0.022940
[11:02:36.258] iteration 8579 : model1 loss : 0.440289 model2 loss : 0.032349
[11:02:36.426] iteration 8580 : model1 loss : 0.434498 model2 loss : 0.028762
[11:02:38.314] iteration 8581 : model1 loss : 0.440262 model2 loss : 0.027199
[11:02:38.485] iteration 8582 : model1 loss : 0.439993 model2 loss : 0.028283
[11:02:38.653] iteration 8583 : model1 loss : 0.433096 model2 loss : 0.025811
[11:02:38.821] iteration 8584 : model1 loss : 0.433425 model2 loss : 0.025721
[11:02:38.993] iteration 8585 : model1 loss : 0.439960 model2 loss : 0.029638
[11:02:39.162] iteration 8586 : model1 loss : 0.437230 model2 loss : 0.028685
[11:02:39.330] iteration 8587 : model1 loss : 0.434705 model2 loss : 0.026371
[11:02:39.499] iteration 8588 : model1 loss : 0.435731 model2 loss : 0.026423
[11:02:39.670] iteration 8589 : model1 loss : 0.438509 model2 loss : 0.025658
[11:02:39.843] iteration 8590 : model1 loss : 0.435439 model2 loss : 0.024558
[11:02:40.014] iteration 8591 : model1 loss : 0.438299 model2 loss : 0.029931
[11:02:40.182] iteration 8592 : model1 loss : 0.435798 model2 loss : 0.025448
[11:02:40.351] iteration 8593 : model1 loss : 0.434986 model2 loss : 0.030572
[11:02:40.525] iteration 8594 : model1 loss : 0.437442 model2 loss : 0.031044
[11:02:40.694] iteration 8595 : model1 loss : 0.434924 model2 loss : 0.029980
[11:02:40.865] iteration 8596 : model1 loss : 0.437998 model2 loss : 0.028974
[11:02:41.039] iteration 8597 : model1 loss : 0.440026 model2 loss : 0.029290
[11:02:41.208] iteration 8598 : model1 loss : 0.440404 model2 loss : 0.028545
[11:02:41.376] iteration 8599 : model1 loss : 0.437129 model2 loss : 0.027735
[11:02:41.543] iteration 8600 : model1 loss : 0.435032 model2 loss : 0.025682
[11:02:41.712] iteration 8601 : model1 loss : 0.438941 model2 loss : 0.032271
[11:02:41.879] iteration 8602 : model1 loss : 0.439148 model2 loss : 0.027956
[11:02:42.051] iteration 8603 : model1 loss : 0.439961 model2 loss : 0.031597
[11:02:42.220] iteration 8604 : model1 loss : 0.443765 model2 loss : 0.034404
[11:02:42.388] iteration 8605 : model1 loss : 0.436412 model2 loss : 0.029675
[11:02:42.555] iteration 8606 : model1 loss : 0.438937 model2 loss : 0.030287
[11:02:42.727] iteration 8607 : model1 loss : 0.438370 model2 loss : 0.027731
[11:02:42.899] iteration 8608 : model1 loss : 0.439562 model2 loss : 0.028796
[11:02:43.069] iteration 8609 : model1 loss : 0.437231 model2 loss : 0.028321
[11:02:43.236] iteration 8610 : model1 loss : 0.436798 model2 loss : 0.027878
[11:02:43.405] iteration 8611 : model1 loss : 0.437821 model2 loss : 0.024374
[11:02:43.573] iteration 8612 : model1 loss : 0.432072 model2 loss : 0.027979
[11:02:43.741] iteration 8613 : model1 loss : 0.433628 model2 loss : 0.024475
[11:02:45.700] iteration 8614 : model1 loss : 0.436062 model2 loss : 0.025229
[11:02:45.874] iteration 8615 : model1 loss : 0.437233 model2 loss : 0.024516
[11:02:46.046] iteration 8616 : model1 loss : 0.438792 model2 loss : 0.029081
[11:02:46.213] iteration 8617 : model1 loss : 0.439138 model2 loss : 0.026551
[11:02:46.383] iteration 8618 : model1 loss : 0.431020 model2 loss : 0.024119
[11:02:46.551] iteration 8619 : model1 loss : 0.437399 model2 loss : 0.029783
[11:02:46.735] iteration 8620 : model1 loss : 0.435120 model2 loss : 0.027407
[11:02:46.903] iteration 8621 : model1 loss : 0.438612 model2 loss : 0.030162
[11:02:47.072] iteration 8622 : model1 loss : 0.437166 model2 loss : 0.031107
[11:02:47.241] iteration 8623 : model1 loss : 0.434044 model2 loss : 0.025000
[11:02:47.411] iteration 8624 : model1 loss : 0.436826 model2 loss : 0.024644
[11:02:47.578] iteration 8625 : model1 loss : 0.443464 model2 loss : 0.035020
[11:02:47.748] iteration 8626 : model1 loss : 0.437774 model2 loss : 0.024274
[11:02:47.918] iteration 8627 : model1 loss : 0.438296 model2 loss : 0.026952
[11:02:48.088] iteration 8628 : model1 loss : 0.433980 model2 loss : 0.026581
[11:02:48.255] iteration 8629 : model1 loss : 0.437934 model2 loss : 0.028854
[11:02:48.424] iteration 8630 : model1 loss : 0.435599 model2 loss : 0.029077
[11:02:48.593] iteration 8631 : model1 loss : 0.439289 model2 loss : 0.032919
[11:02:48.765] iteration 8632 : model1 loss : 0.445588 model2 loss : 0.035566
[11:02:48.932] iteration 8633 : model1 loss : 0.434613 model2 loss : 0.025830
[11:02:49.102] iteration 8634 : model1 loss : 0.436051 model2 loss : 0.022467
[11:02:49.270] iteration 8635 : model1 loss : 0.438318 model2 loss : 0.037192
[11:02:49.439] iteration 8636 : model1 loss : 0.438370 model2 loss : 0.027093
[11:02:49.606] iteration 8637 : model1 loss : 0.435663 model2 loss : 0.024763
[11:02:49.776] iteration 8638 : model1 loss : 0.436382 model2 loss : 0.027040
[11:02:49.948] iteration 8639 : model1 loss : 0.441431 model2 loss : 0.026486
[11:02:50.118] iteration 8640 : model1 loss : 0.436156 model2 loss : 0.028352
[11:02:50.286] iteration 8641 : model1 loss : 0.437075 model2 loss : 0.025051
[11:02:50.455] iteration 8642 : model1 loss : 0.439713 model2 loss : 0.026058
[11:02:50.623] iteration 8643 : model1 loss : 0.437985 model2 loss : 0.025505
[11:02:50.793] iteration 8644 : model1 loss : 0.436796 model2 loss : 0.027917
[11:02:50.958] iteration 8645 : model1 loss : 0.441125 model2 loss : 0.027812
[11:02:51.126] iteration 8646 : model1 loss : 0.435096 model2 loss : 0.024377
[11:02:53.026] iteration 8647 : model1 loss : 0.439159 model2 loss : 0.026361
[11:02:53.193] iteration 8648 : model1 loss : 0.434168 model2 loss : 0.026611
[11:02:53.362] iteration 8649 : model1 loss : 0.433753 model2 loss : 0.024403
[11:02:53.529] iteration 8650 : model1 loss : 0.434494 model2 loss : 0.026787
[11:02:53.698] iteration 8651 : model1 loss : 0.435227 model2 loss : 0.026446
[11:02:53.865] iteration 8652 : model1 loss : 0.440540 model2 loss : 0.027101
[11:02:54.036] iteration 8653 : model1 loss : 0.438770 model2 loss : 0.028486
[11:02:54.202] iteration 8654 : model1 loss : 0.436552 model2 loss : 0.024334
[11:02:54.371] iteration 8655 : model1 loss : 0.438111 model2 loss : 0.027258
[11:02:54.542] iteration 8656 : model1 loss : 0.438423 model2 loss : 0.025775
[11:02:54.711] iteration 8657 : model1 loss : 0.438852 model2 loss : 0.026794
[11:02:54.878] iteration 8658 : model1 loss : 0.432746 model2 loss : 0.026582
[11:02:55.047] iteration 8659 : model1 loss : 0.435960 model2 loss : 0.025766
[11:02:55.214] iteration 8660 : model1 loss : 0.442291 model2 loss : 0.028982
[11:02:55.384] iteration 8661 : model1 loss : 0.435963 model2 loss : 0.024333
[11:02:55.554] iteration 8662 : model1 loss : 0.433558 model2 loss : 0.023527
[11:02:55.722] iteration 8663 : model1 loss : 0.444648 model2 loss : 0.040102
[11:02:55.894] iteration 8664 : model1 loss : 0.436737 model2 loss : 0.028398
[11:02:56.063] iteration 8665 : model1 loss : 0.435399 model2 loss : 0.023717
[11:02:56.229] iteration 8666 : model1 loss : 0.437805 model2 loss : 0.029503
[11:02:56.398] iteration 8667 : model1 loss : 0.438502 model2 loss : 0.031205
[11:02:56.570] iteration 8668 : model1 loss : 0.439763 model2 loss : 0.024712
[11:02:56.740] iteration 8669 : model1 loss : 0.443347 model2 loss : 0.033325
[11:02:56.909] iteration 8670 : model1 loss : 0.437390 model2 loss : 0.023459
[11:02:57.080] iteration 8671 : model1 loss : 0.438038 model2 loss : 0.027941
[11:02:57.245] iteration 8672 : model1 loss : 0.438369 model2 loss : 0.027575
[11:02:57.417] iteration 8673 : model1 loss : 0.436610 model2 loss : 0.025204
[11:02:57.584] iteration 8674 : model1 loss : 0.436156 model2 loss : 0.030489
[11:02:57.754] iteration 8675 : model1 loss : 0.436511 model2 loss : 0.026010
[11:02:57.923] iteration 8676 : model1 loss : 0.438802 model2 loss : 0.026592
[11:02:58.094] iteration 8677 : model1 loss : 0.438907 model2 loss : 0.031828
[11:02:58.259] iteration 8678 : model1 loss : 0.436685 model2 loss : 0.025288
[11:02:58.430] iteration 8679 : model1 loss : 0.436393 model2 loss : 0.024904
[11:03:00.337] iteration 8680 : model1 loss : 0.439126 model2 loss : 0.029338
[11:03:00.510] iteration 8681 : model1 loss : 0.438052 model2 loss : 0.028329
[11:03:00.680] iteration 8682 : model1 loss : 0.437804 model2 loss : 0.027638
[11:03:00.849] iteration 8683 : model1 loss : 0.438587 model2 loss : 0.032313
[11:03:01.019] iteration 8684 : model1 loss : 0.440190 model2 loss : 0.029788
[11:03:01.186] iteration 8685 : model1 loss : 0.434759 model2 loss : 0.027204
[11:03:01.358] iteration 8686 : model1 loss : 0.436661 model2 loss : 0.028674
[11:03:01.527] iteration 8687 : model1 loss : 0.435822 model2 loss : 0.025334
[11:03:01.697] iteration 8688 : model1 loss : 0.441317 model2 loss : 0.029445
[11:03:01.865] iteration 8689 : model1 loss : 0.435818 model2 loss : 0.033526
[11:03:02.033] iteration 8690 : model1 loss : 0.433930 model2 loss : 0.028196
[11:03:02.200] iteration 8691 : model1 loss : 0.442717 model2 loss : 0.031321
[11:03:02.368] iteration 8692 : model1 loss : 0.438344 model2 loss : 0.027279
[11:03:02.537] iteration 8693 : model1 loss : 0.435632 model2 loss : 0.026608
[11:03:02.706] iteration 8694 : model1 loss : 0.436099 model2 loss : 0.028460
[11:03:02.875] iteration 8695 : model1 loss : 0.439858 model2 loss : 0.030322
[11:03:03.043] iteration 8696 : model1 loss : 0.436751 model2 loss : 0.025323
[11:03:03.211] iteration 8697 : model1 loss : 0.432960 model2 loss : 0.025706
[11:03:03.382] iteration 8698 : model1 loss : 0.437184 model2 loss : 0.028726
[11:03:03.551] iteration 8699 : model1 loss : 0.439387 model2 loss : 0.028492
[11:03:03.721] iteration 8700 : model1 loss : 0.436593 model2 loss : 0.025510
[11:03:03.889] iteration 8701 : model1 loss : 0.433398 model2 loss : 0.021967
[11:03:04.059] iteration 8702 : model1 loss : 0.443186 model2 loss : 0.029178
[11:03:04.226] iteration 8703 : model1 loss : 0.441807 model2 loss : 0.031856
[11:03:04.397] iteration 8704 : model1 loss : 0.436148 model2 loss : 0.025522
[11:03:04.566] iteration 8705 : model1 loss : 0.435969 model2 loss : 0.027031
[11:03:04.735] iteration 8706 : model1 loss : 0.435010 model2 loss : 0.028989
[11:03:04.902] iteration 8707 : model1 loss : 0.437585 model2 loss : 0.027168
[11:03:05.072] iteration 8708 : model1 loss : 0.442581 model2 loss : 0.032863
[11:03:05.239] iteration 8709 : model1 loss : 0.440038 model2 loss : 0.028875
[11:03:05.409] iteration 8710 : model1 loss : 0.439566 model2 loss : 0.028515
[11:03:05.576] iteration 8711 : model1 loss : 0.434221 model2 loss : 0.029675
[11:03:05.742] iteration 8712 : model1 loss : 0.436144 model2 loss : 0.027273
[11:03:07.711] iteration 8713 : model1 loss : 0.438403 model2 loss : 0.028942
[11:03:07.880] iteration 8714 : model1 loss : 0.439072 model2 loss : 0.027717
[11:03:08.049] iteration 8715 : model1 loss : 0.438564 model2 loss : 0.030648
[11:03:08.216] iteration 8716 : model1 loss : 0.437467 model2 loss : 0.025092
[11:03:08.386] iteration 8717 : model1 loss : 0.433152 model2 loss : 0.024782
[11:03:08.553] iteration 8718 : model1 loss : 0.434898 model2 loss : 0.024027
[11:03:08.722] iteration 8719 : model1 loss : 0.439097 model2 loss : 0.026639
[11:03:08.889] iteration 8720 : model1 loss : 0.436530 model2 loss : 0.025856
[11:03:09.057] iteration 8721 : model1 loss : 0.434691 model2 loss : 0.024769
[11:03:09.225] iteration 8722 : model1 loss : 0.440119 model2 loss : 0.025855
[11:03:09.393] iteration 8723 : model1 loss : 0.434384 model2 loss : 0.023543
[11:03:09.561] iteration 8724 : model1 loss : 0.436607 model2 loss : 0.027005
[11:03:09.728] iteration 8725 : model1 loss : 0.442810 model2 loss : 0.029938
[11:03:09.895] iteration 8726 : model1 loss : 0.438515 model2 loss : 0.030947
[11:03:10.064] iteration 8727 : model1 loss : 0.438791 model2 loss : 0.031645
[11:03:10.231] iteration 8728 : model1 loss : 0.434711 model2 loss : 0.025751
[11:03:10.399] iteration 8729 : model1 loss : 0.434678 model2 loss : 0.026282
[11:03:10.567] iteration 8730 : model1 loss : 0.432415 model2 loss : 0.024580
[11:03:10.736] iteration 8731 : model1 loss : 0.442946 model2 loss : 0.027988
[11:03:10.904] iteration 8732 : model1 loss : 0.438779 model2 loss : 0.028607
[11:03:11.074] iteration 8733 : model1 loss : 0.437719 model2 loss : 0.026928
[11:03:11.242] iteration 8734 : model1 loss : 0.436096 model2 loss : 0.024792
[11:03:11.412] iteration 8735 : model1 loss : 0.439262 model2 loss : 0.033808
[11:03:11.581] iteration 8736 : model1 loss : 0.434034 model2 loss : 0.024200
[11:03:11.752] iteration 8737 : model1 loss : 0.438536 model2 loss : 0.028697
[11:03:11.918] iteration 8738 : model1 loss : 0.436424 model2 loss : 0.028398
[11:03:12.086] iteration 8739 : model1 loss : 0.438560 model2 loss : 0.029195
[11:03:12.253] iteration 8740 : model1 loss : 0.438385 model2 loss : 0.029969
[11:03:12.422] iteration 8741 : model1 loss : 0.436645 model2 loss : 0.028679
[11:03:12.590] iteration 8742 : model1 loss : 0.438842 model2 loss : 0.030813
[11:03:12.759] iteration 8743 : model1 loss : 0.440049 model2 loss : 0.029587
[11:03:12.924] iteration 8744 : model1 loss : 0.437662 model2 loss : 0.025813
[11:03:13.092] iteration 8745 : model1 loss : 0.438359 model2 loss : 0.028288
[11:03:15.025] iteration 8746 : model1 loss : 0.435681 model2 loss : 0.030527
[11:03:15.192] iteration 8747 : model1 loss : 0.437539 model2 loss : 0.026606
[11:03:15.365] iteration 8748 : model1 loss : 0.437853 model2 loss : 0.027883
[11:03:15.534] iteration 8749 : model1 loss : 0.438257 model2 loss : 0.028913
[11:03:15.701] iteration 8750 : model1 loss : 0.436644 model2 loss : 0.025456
[11:03:15.869] iteration 8751 : model1 loss : 0.433500 model2 loss : 0.027669
[11:03:16.038] iteration 8752 : model1 loss : 0.441134 model2 loss : 0.029112
[11:03:16.205] iteration 8753 : model1 loss : 0.441049 model2 loss : 0.032726
[11:03:16.392] iteration 8754 : model1 loss : 0.437806 model2 loss : 0.026433
[11:03:16.561] iteration 8755 : model1 loss : 0.438204 model2 loss : 0.025505
[11:03:16.731] iteration 8756 : model1 loss : 0.440209 model2 loss : 0.027202
[11:03:16.899] iteration 8757 : model1 loss : 0.439593 model2 loss : 0.024742
[11:03:17.068] iteration 8758 : model1 loss : 0.433312 model2 loss : 0.027482
[11:03:17.235] iteration 8759 : model1 loss : 0.436326 model2 loss : 0.027366
[11:03:17.404] iteration 8760 : model1 loss : 0.440419 model2 loss : 0.022611
[11:03:17.572] iteration 8761 : model1 loss : 0.437632 model2 loss : 0.025249
[11:03:17.742] iteration 8762 : model1 loss : 0.435384 model2 loss : 0.031080
[11:03:17.909] iteration 8763 : model1 loss : 0.437618 model2 loss : 0.027771
[11:03:18.078] iteration 8764 : model1 loss : 0.439574 model2 loss : 0.026194
[11:03:18.244] iteration 8765 : model1 loss : 0.434410 model2 loss : 0.023735
[11:03:18.413] iteration 8766 : model1 loss : 0.437322 model2 loss : 0.028172
[11:03:18.581] iteration 8767 : model1 loss : 0.435999 model2 loss : 0.035518
[11:03:18.751] iteration 8768 : model1 loss : 0.442955 model2 loss : 0.034828
[11:03:18.918] iteration 8769 : model1 loss : 0.436761 model2 loss : 0.029142
[11:03:19.087] iteration 8770 : model1 loss : 0.436386 model2 loss : 0.025316
[11:03:19.255] iteration 8771 : model1 loss : 0.436432 model2 loss : 0.031533
[11:03:19.425] iteration 8772 : model1 loss : 0.438197 model2 loss : 0.033593
[11:03:19.593] iteration 8773 : model1 loss : 0.439010 model2 loss : 0.027142
[11:03:19.762] iteration 8774 : model1 loss : 0.436583 model2 loss : 0.031512
[11:03:19.930] iteration 8775 : model1 loss : 0.436350 model2 loss : 0.027141
[11:03:20.097] iteration 8776 : model1 loss : 0.434455 model2 loss : 0.025267
[11:03:20.264] iteration 8777 : model1 loss : 0.437998 model2 loss : 0.029455
[11:03:20.432] iteration 8778 : model1 loss : 0.440969 model2 loss : 0.034896
[11:03:22.344] iteration 8779 : model1 loss : 0.440347 model2 loss : 0.031311
[11:03:22.514] iteration 8780 : model1 loss : 0.439217 model2 loss : 0.039410
[11:03:22.685] iteration 8781 : model1 loss : 0.433836 model2 loss : 0.025781
[11:03:22.855] iteration 8782 : model1 loss : 0.430860 model2 loss : 0.026970
[11:03:23.024] iteration 8783 : model1 loss : 0.437643 model2 loss : 0.031263
[11:03:23.191] iteration 8784 : model1 loss : 0.445399 model2 loss : 0.033793
[11:03:23.360] iteration 8785 : model1 loss : 0.443807 model2 loss : 0.035271
[11:03:23.527] iteration 8786 : model1 loss : 0.436531 model2 loss : 0.029701
[11:03:23.697] iteration 8787 : model1 loss : 0.434397 model2 loss : 0.024733
[11:03:23.864] iteration 8788 : model1 loss : 0.440376 model2 loss : 0.030812
[11:03:24.036] iteration 8789 : model1 loss : 0.431747 model2 loss : 0.028363
[11:03:24.202] iteration 8790 : model1 loss : 0.441772 model2 loss : 0.035586
[11:03:24.370] iteration 8791 : model1 loss : 0.439551 model2 loss : 0.033431
[11:03:24.538] iteration 8792 : model1 loss : 0.435260 model2 loss : 0.028937
[11:03:24.707] iteration 8793 : model1 loss : 0.434318 model2 loss : 0.028514
[11:03:24.880] iteration 8794 : model1 loss : 0.438276 model2 loss : 0.028454
[11:03:25.048] iteration 8795 : model1 loss : 0.435656 model2 loss : 0.027728
[11:03:25.215] iteration 8796 : model1 loss : 0.433720 model2 loss : 0.025612
[11:03:25.382] iteration 8797 : model1 loss : 0.435732 model2 loss : 0.024496
[11:03:25.550] iteration 8798 : model1 loss : 0.435886 model2 loss : 0.025707
[11:03:25.718] iteration 8799 : model1 loss : 0.439219 model2 loss : 0.034274
[11:03:25.888] iteration 8800 : model1 loss : 0.439005 model2 loss : 0.029585
[11:03:26.058] iteration 8801 : model1 loss : 0.442420 model2 loss : 0.034949
[11:03:26.225] iteration 8802 : model1 loss : 0.439463 model2 loss : 0.033464
[11:03:26.393] iteration 8803 : model1 loss : 0.437751 model2 loss : 0.027427
[11:03:26.560] iteration 8804 : model1 loss : 0.439055 model2 loss : 0.027932
[11:03:26.730] iteration 8805 : model1 loss : 0.440149 model2 loss : 0.028994
[11:03:26.897] iteration 8806 : model1 loss : 0.432946 model2 loss : 0.026167
[11:03:27.067] iteration 8807 : model1 loss : 0.442533 model2 loss : 0.045244
[11:03:27.232] iteration 8808 : model1 loss : 0.441284 model2 loss : 0.029577
[11:03:27.402] iteration 8809 : model1 loss : 0.433423 model2 loss : 0.035712
[11:03:27.568] iteration 8810 : model1 loss : 0.435981 model2 loss : 0.031388
[11:03:27.734] iteration 8811 : model1 loss : 0.437055 model2 loss : 0.032695
[11:03:29.661] iteration 8812 : model1 loss : 0.436069 model2 loss : 0.027734
[11:03:29.828] iteration 8813 : model1 loss : 0.438772 model2 loss : 0.029887
[11:03:30.001] iteration 8814 : model1 loss : 0.434164 model2 loss : 0.027831
[11:03:30.168] iteration 8815 : model1 loss : 0.440798 model2 loss : 0.040761
[11:03:30.338] iteration 8816 : model1 loss : 0.435604 model2 loss : 0.036271
[11:03:30.507] iteration 8817 : model1 loss : 0.437602 model2 loss : 0.034588
[11:03:30.677] iteration 8818 : model1 loss : 0.439988 model2 loss : 0.034007
[11:03:30.846] iteration 8819 : model1 loss : 0.436458 model2 loss : 0.028368
[11:03:31.017] iteration 8820 : model1 loss : 0.436745 model2 loss : 0.030821
[11:03:31.183] iteration 8821 : model1 loss : 0.435948 model2 loss : 0.025958
[11:03:31.353] iteration 8822 : model1 loss : 0.438974 model2 loss : 0.029579
[11:03:31.520] iteration 8823 : model1 loss : 0.437169 model2 loss : 0.029363
[11:03:31.691] iteration 8824 : model1 loss : 0.439572 model2 loss : 0.028874
[11:03:31.859] iteration 8825 : model1 loss : 0.430052 model2 loss : 0.026656
[11:03:32.027] iteration 8826 : model1 loss : 0.433981 model2 loss : 0.028921
[11:03:32.195] iteration 8827 : model1 loss : 0.439735 model2 loss : 0.027564
[11:03:32.363] iteration 8828 : model1 loss : 0.436392 model2 loss : 0.029115
[11:03:32.534] iteration 8829 : model1 loss : 0.439536 model2 loss : 0.033052
[11:03:32.702] iteration 8830 : model1 loss : 0.440180 model2 loss : 0.033926
[11:03:32.871] iteration 8831 : model1 loss : 0.439096 model2 loss : 0.029562
[11:03:33.042] iteration 8832 : model1 loss : 0.440874 model2 loss : 0.034875
[11:03:33.211] iteration 8833 : model1 loss : 0.438687 model2 loss : 0.031799
[11:03:33.380] iteration 8834 : model1 loss : 0.442873 model2 loss : 0.035641
[11:03:33.546] iteration 8835 : model1 loss : 0.439321 model2 loss : 0.027743
[11:03:33.716] iteration 8836 : model1 loss : 0.435306 model2 loss : 0.029518
[11:03:33.881] iteration 8837 : model1 loss : 0.441712 model2 loss : 0.029897
[11:03:34.051] iteration 8838 : model1 loss : 0.436343 model2 loss : 0.027276
[11:03:34.217] iteration 8839 : model1 loss : 0.436069 model2 loss : 0.030046
[11:03:34.386] iteration 8840 : model1 loss : 0.435055 model2 loss : 0.030210
[11:03:34.554] iteration 8841 : model1 loss : 0.438322 model2 loss : 0.027153
[11:03:34.723] iteration 8842 : model1 loss : 0.435644 model2 loss : 0.024906
[11:03:34.887] iteration 8843 : model1 loss : 0.435612 model2 loss : 0.023303
[11:03:35.055] iteration 8844 : model1 loss : 0.434023 model2 loss : 0.027836
[11:03:37.006] iteration 8845 : model1 loss : 0.436295 model2 loss : 0.033619
[11:03:37.176] iteration 8846 : model1 loss : 0.438025 model2 loss : 0.027273
[11:03:37.348] iteration 8847 : model1 loss : 0.442722 model2 loss : 0.027764
[11:03:37.518] iteration 8848 : model1 loss : 0.439712 model2 loss : 0.036651
[11:03:37.687] iteration 8849 : model1 loss : 0.437486 model2 loss : 0.028459
[11:03:37.855] iteration 8850 : model1 loss : 0.438814 model2 loss : 0.035472
[11:03:38.025] iteration 8851 : model1 loss : 0.438732 model2 loss : 0.035782
[11:03:38.192] iteration 8852 : model1 loss : 0.435251 model2 loss : 0.027827
[11:03:38.362] iteration 8853 : model1 loss : 0.438564 model2 loss : 0.026203
[11:03:38.533] iteration 8854 : model1 loss : 0.434897 model2 loss : 0.026994
[11:03:38.700] iteration 8855 : model1 loss : 0.437897 model2 loss : 0.023677
[11:03:38.866] iteration 8856 : model1 loss : 0.438355 model2 loss : 0.028684
[11:03:39.036] iteration 8857 : model1 loss : 0.437064 model2 loss : 0.028910
[11:03:39.202] iteration 8858 : model1 loss : 0.438778 model2 loss : 0.029698
[11:03:39.373] iteration 8859 : model1 loss : 0.436950 model2 loss : 0.028893
[11:03:39.540] iteration 8860 : model1 loss : 0.439669 model2 loss : 0.030361
[11:03:39.709] iteration 8861 : model1 loss : 0.434958 model2 loss : 0.027380
[11:03:39.877] iteration 8862 : model1 loss : 0.441621 model2 loss : 0.036529
[11:03:40.047] iteration 8863 : model1 loss : 0.435588 model2 loss : 0.022642
[11:03:40.213] iteration 8864 : model1 loss : 0.433354 model2 loss : 0.028043
[11:03:40.383] iteration 8865 : model1 loss : 0.439659 model2 loss : 0.029622
[11:03:40.551] iteration 8866 : model1 loss : 0.436316 model2 loss : 0.026496
[11:03:40.720] iteration 8867 : model1 loss : 0.432692 model2 loss : 0.029106
[11:03:40.891] iteration 8868 : model1 loss : 0.435767 model2 loss : 0.030919
[11:03:41.063] iteration 8869 : model1 loss : 0.436531 model2 loss : 0.028249
[11:03:41.230] iteration 8870 : model1 loss : 0.439828 model2 loss : 0.034119
[11:03:41.400] iteration 8871 : model1 loss : 0.437343 model2 loss : 0.031120
[11:03:41.571] iteration 8872 : model1 loss : 0.440461 model2 loss : 0.032852
[11:03:41.738] iteration 8873 : model1 loss : 0.438038 model2 loss : 0.044626
[11:03:41.907] iteration 8874 : model1 loss : 0.438499 model2 loss : 0.032458
[11:03:42.076] iteration 8875 : model1 loss : 0.434938 model2 loss : 0.030057
[11:03:42.243] iteration 8876 : model1 loss : 0.438255 model2 loss : 0.028895
[11:03:42.414] iteration 8877 : model1 loss : 0.440446 model2 loss : 0.031694
[11:03:44.339] iteration 8878 : model1 loss : 0.436843 model2 loss : 0.027812
[11:03:44.508] iteration 8879 : model1 loss : 0.438569 model2 loss : 0.027786
[11:03:44.680] iteration 8880 : model1 loss : 0.440485 model2 loss : 0.031134
[11:03:44.845] iteration 8881 : model1 loss : 0.440714 model2 loss : 0.032606
[11:03:45.019] iteration 8882 : model1 loss : 0.439194 model2 loss : 0.032698
[11:03:45.186] iteration 8883 : model1 loss : 0.437076 model2 loss : 0.036907
[11:03:45.355] iteration 8884 : model1 loss : 0.435288 model2 loss : 0.033346
[11:03:45.525] iteration 8885 : model1 loss : 0.435495 model2 loss : 0.025851
[11:03:45.694] iteration 8886 : model1 loss : 0.437771 model2 loss : 0.035257
[11:03:45.863] iteration 8887 : model1 loss : 0.439809 model2 loss : 0.031663
[11:03:46.037] iteration 8888 : model1 loss : 0.441391 model2 loss : 0.045945
[11:03:46.204] iteration 8889 : model1 loss : 0.436979 model2 loss : 0.028744
[11:03:46.372] iteration 8890 : model1 loss : 0.437729 model2 loss : 0.024680
[11:03:46.541] iteration 8891 : model1 loss : 0.436980 model2 loss : 0.027448
[11:03:46.712] iteration 8892 : model1 loss : 0.433985 model2 loss : 0.028190
[11:03:46.881] iteration 8893 : model1 loss : 0.433961 model2 loss : 0.030870
[11:03:47.053] iteration 8894 : model1 loss : 0.434881 model2 loss : 0.029064
[11:03:47.221] iteration 8895 : model1 loss : 0.436724 model2 loss : 0.033334
[11:03:47.392] iteration 8896 : model1 loss : 0.440993 model2 loss : 0.030431
[11:03:47.561] iteration 8897 : model1 loss : 0.437689 model2 loss : 0.029305
[11:03:47.731] iteration 8898 : model1 loss : 0.439731 model2 loss : 0.026741
[11:03:47.897] iteration 8899 : model1 loss : 0.435860 model2 loss : 0.027866
[11:03:48.068] iteration 8900 : model1 loss : 0.435116 model2 loss : 0.029780
[11:03:48.234] iteration 8901 : model1 loss : 0.431139 model2 loss : 0.025282
[11:03:48.404] iteration 8902 : model1 loss : 0.435846 model2 loss : 0.027847
[11:03:48.573] iteration 8903 : model1 loss : 0.437536 model2 loss : 0.027557
[11:03:48.743] iteration 8904 : model1 loss : 0.436749 model2 loss : 0.027835
[11:03:48.911] iteration 8905 : model1 loss : 0.438666 model2 loss : 0.027867
[11:03:49.082] iteration 8906 : model1 loss : 0.437307 model2 loss : 0.025249
[11:03:49.251] iteration 8907 : model1 loss : 0.437119 model2 loss : 0.028234
[11:03:49.430] iteration 8908 : model1 loss : 0.433986 model2 loss : 0.027462
[11:03:49.596] iteration 8909 : model1 loss : 0.438971 model2 loss : 0.030336
[11:03:49.764] iteration 8910 : model1 loss : 0.435943 model2 loss : 0.027383
[11:03:51.717] iteration 8911 : model1 loss : 0.434809 model2 loss : 0.030610
[11:03:51.886] iteration 8912 : model1 loss : 0.434991 model2 loss : 0.025546
[11:03:52.057] iteration 8913 : model1 loss : 0.438271 model2 loss : 0.028206
[11:03:52.225] iteration 8914 : model1 loss : 0.442391 model2 loss : 0.038680
[11:03:52.393] iteration 8915 : model1 loss : 0.437197 model2 loss : 0.023684
[11:03:52.560] iteration 8916 : model1 loss : 0.439193 model2 loss : 0.027500
[11:03:52.729] iteration 8917 : model1 loss : 0.435833 model2 loss : 0.026673
[11:03:52.897] iteration 8918 : model1 loss : 0.438277 model2 loss : 0.027493
[11:03:53.068] iteration 8919 : model1 loss : 0.435410 model2 loss : 0.028566
[11:03:53.236] iteration 8920 : model1 loss : 0.438266 model2 loss : 0.030276
[11:03:53.405] iteration 8921 : model1 loss : 0.436613 model2 loss : 0.027775
[11:03:53.575] iteration 8922 : model1 loss : 0.435971 model2 loss : 0.023630
[11:03:53.745] iteration 8923 : model1 loss : 0.439454 model2 loss : 0.029506
[11:03:53.911] iteration 8924 : model1 loss : 0.440290 model2 loss : 0.027278
[11:03:54.081] iteration 8925 : model1 loss : 0.432359 model2 loss : 0.024261
[11:03:54.250] iteration 8926 : model1 loss : 0.436405 model2 loss : 0.025536
[11:03:54.419] iteration 8927 : model1 loss : 0.433932 model2 loss : 0.026284
[11:03:54.586] iteration 8928 : model1 loss : 0.438525 model2 loss : 0.030217
[11:03:54.754] iteration 8929 : model1 loss : 0.434452 model2 loss : 0.025403
[11:03:54.922] iteration 8930 : model1 loss : 0.436873 model2 loss : 0.026156
[11:03:55.090] iteration 8931 : model1 loss : 0.439534 model2 loss : 0.030748
[11:03:55.261] iteration 8932 : model1 loss : 0.436998 model2 loss : 0.026427
[11:03:55.431] iteration 8933 : model1 loss : 0.437951 model2 loss : 0.024843
[11:03:55.601] iteration 8934 : model1 loss : 0.436159 model2 loss : 0.025916
[11:03:55.772] iteration 8935 : model1 loss : 0.435813 model2 loss : 0.027256
[11:03:55.942] iteration 8936 : model1 loss : 0.436577 model2 loss : 0.026403
[11:03:56.111] iteration 8937 : model1 loss : 0.437513 model2 loss : 0.026383
[11:03:56.280] iteration 8938 : model1 loss : 0.434286 model2 loss : 0.026851
[11:03:56.449] iteration 8939 : model1 loss : 0.438227 model2 loss : 0.027012
[11:03:56.616] iteration 8940 : model1 loss : 0.438345 model2 loss : 0.026750
[11:03:56.787] iteration 8941 : model1 loss : 0.433849 model2 loss : 0.024163
[11:03:56.953] iteration 8942 : model1 loss : 0.437038 model2 loss : 0.022797
[11:03:57.122] iteration 8943 : model1 loss : 0.432757 model2 loss : 0.025272
[11:03:59.031] iteration 8944 : model1 loss : 0.435672 model2 loss : 0.022537
[11:03:59.199] iteration 8945 : model1 loss : 0.440458 model2 loss : 0.036788
[11:03:59.369] iteration 8946 : model1 loss : 0.436132 model2 loss : 0.026804
[11:03:59.536] iteration 8947 : model1 loss : 0.439520 model2 loss : 0.031915
[11:03:59.705] iteration 8948 : model1 loss : 0.438198 model2 loss : 0.029648
[11:03:59.872] iteration 8949 : model1 loss : 0.437935 model2 loss : 0.024774
[11:04:00.041] iteration 8950 : model1 loss : 0.438387 model2 loss : 0.028733
[11:04:00.211] iteration 8951 : model1 loss : 0.430789 model2 loss : 0.025996
[11:04:00.380] iteration 8952 : model1 loss : 0.438399 model2 loss : 0.029720
[11:04:00.548] iteration 8953 : model1 loss : 0.438920 model2 loss : 0.028966
[11:04:00.717] iteration 8954 : model1 loss : 0.434546 model2 loss : 0.028278
[11:04:00.890] iteration 8955 : model1 loss : 0.436376 model2 loss : 0.023705
[11:04:01.064] iteration 8956 : model1 loss : 0.439338 model2 loss : 0.028388
[11:04:01.231] iteration 8957 : model1 loss : 0.435092 model2 loss : 0.025688
[11:04:01.400] iteration 8958 : model1 loss : 0.440888 model2 loss : 0.028673
[11:04:01.569] iteration 8959 : model1 loss : 0.436566 model2 loss : 0.025717
[11:04:01.739] iteration 8960 : model1 loss : 0.433155 model2 loss : 0.025901
[11:04:01.907] iteration 8961 : model1 loss : 0.435707 model2 loss : 0.027441
[11:04:02.078] iteration 8962 : model1 loss : 0.438101 model2 loss : 0.030275
[11:04:02.245] iteration 8963 : model1 loss : 0.436513 model2 loss : 0.029324
[11:04:02.415] iteration 8964 : model1 loss : 0.437791 model2 loss : 0.026591
[11:04:02.582] iteration 8965 : model1 loss : 0.436621 model2 loss : 0.026624
[11:04:02.750] iteration 8966 : model1 loss : 0.434817 model2 loss : 0.025272
[11:04:02.918] iteration 8967 : model1 loss : 0.438703 model2 loss : 0.027122
[11:04:03.090] iteration 8968 : model1 loss : 0.439788 model2 loss : 0.028903
[11:04:03.255] iteration 8969 : model1 loss : 0.437110 model2 loss : 0.026447
[11:04:03.425] iteration 8970 : model1 loss : 0.431189 model2 loss : 0.023880
[11:04:03.593] iteration 8971 : model1 loss : 0.436886 model2 loss : 0.026084
[11:04:03.763] iteration 8972 : model1 loss : 0.436362 model2 loss : 0.027088
[11:04:03.930] iteration 8973 : model1 loss : 0.442516 model2 loss : 0.032086
[11:04:04.101] iteration 8974 : model1 loss : 0.439082 model2 loss : 0.023903
[11:04:04.267] iteration 8975 : model1 loss : 0.436046 model2 loss : 0.029450
[11:04:04.434] iteration 8976 : model1 loss : 0.434899 model2 loss : 0.032715
[11:04:06.380] iteration 8977 : model1 loss : 0.436938 model2 loss : 0.026386
[11:04:06.549] iteration 8978 : model1 loss : 0.438418 model2 loss : 0.029844
[11:04:06.718] iteration 8979 : model1 loss : 0.438150 model2 loss : 0.030457
[11:04:06.887] iteration 8980 : model1 loss : 0.438181 model2 loss : 0.030748
[11:04:07.056] iteration 8981 : model1 loss : 0.436398 model2 loss : 0.026173
[11:04:07.224] iteration 8982 : model1 loss : 0.437065 model2 loss : 0.028637
[11:04:07.392] iteration 8983 : model1 loss : 0.440981 model2 loss : 0.032976
[11:04:07.559] iteration 8984 : model1 loss : 0.433212 model2 loss : 0.023436
[11:04:07.727] iteration 8985 : model1 loss : 0.437863 model2 loss : 0.028454
[11:04:07.894] iteration 8986 : model1 loss : 0.436823 model2 loss : 0.024383
[11:04:08.065] iteration 8987 : model1 loss : 0.435143 model2 loss : 0.028461
[11:04:08.233] iteration 8988 : model1 loss : 0.441406 model2 loss : 0.025833
[11:04:08.402] iteration 8989 : model1 loss : 0.438990 model2 loss : 0.022950
[11:04:08.572] iteration 8990 : model1 loss : 0.440551 model2 loss : 0.030439
[11:04:08.743] iteration 8991 : model1 loss : 0.437340 model2 loss : 0.029044
[11:04:08.911] iteration 8992 : model1 loss : 0.439281 model2 loss : 0.024399
[11:04:09.084] iteration 8993 : model1 loss : 0.434921 model2 loss : 0.025647
[11:04:09.252] iteration 8994 : model1 loss : 0.433164 model2 loss : 0.026588
[11:04:09.420] iteration 8995 : model1 loss : 0.436699 model2 loss : 0.027553
[11:04:09.588] iteration 8996 : model1 loss : 0.436318 model2 loss : 0.029207
[11:04:09.758] iteration 8997 : model1 loss : 0.433754 model2 loss : 0.025502
[11:04:09.926] iteration 8998 : model1 loss : 0.438296 model2 loss : 0.025996
[11:04:10.099] iteration 8999 : model1 loss : 0.436463 model2 loss : 0.024270
[11:04:10.265] iteration 9000 : model1 loss : 0.440192 model2 loss : 0.027536
[11:04:18.554] iteration 9000 : model1_mean_dice : 0.862362 model1_mean_hd95 : 3.914131
[11:04:26.793] iteration 9000 : model2_mean_dice : 0.879235 model2_mean_hd95 : 7.887659
[11:04:26.812] save model1 to ../model/ACDC/EVILv1_kl0.5_tau0.25_21_1337/unet\model1_iter_9000.pth
[11:04:26.831] save model2 to ../model/ACDC/EVILv1_kl0.5_tau0.25_21_1337/unet\model2_iter_9000.pth
[11:04:27.008] iteration 9001 : model1 loss : 0.444177 model2 loss : 0.029390
[11:04:27.183] iteration 9002 : model1 loss : 0.433329 model2 loss : 0.025215
[11:04:27.351] iteration 9003 : model1 loss : 0.439590 model2 loss : 0.028169
[11:04:27.519] iteration 9004 : model1 loss : 0.437587 model2 loss : 0.026595
[11:04:27.687] iteration 9005 : model1 loss : 0.437128 model2 loss : 0.027679
[11:04:27.852] iteration 9006 : model1 loss : 0.437038 model2 loss : 0.026753
[11:04:28.020] iteration 9007 : model1 loss : 0.439240 model2 loss : 0.032690
[11:04:28.185] iteration 9008 : model1 loss : 0.437494 model2 loss : 0.029423
[11:04:28.352] iteration 9009 : model1 loss : 0.438625 model2 loss : 0.031903
[11:04:30.265] iteration 9010 : model1 loss : 0.434190 model2 loss : 0.029724
[11:04:30.435] iteration 9011 : model1 loss : 0.436582 model2 loss : 0.025506
[11:04:30.606] iteration 9012 : model1 loss : 0.437699 model2 loss : 0.027992
[11:04:30.771] iteration 9013 : model1 loss : 0.433431 model2 loss : 0.026607
[11:04:30.940] iteration 9014 : model1 loss : 0.438670 model2 loss : 0.034207
[11:04:31.106] iteration 9015 : model1 loss : 0.439752 model2 loss : 0.030591
[11:04:31.273] iteration 9016 : model1 loss : 0.435618 model2 loss : 0.030738
[11:04:31.439] iteration 9017 : model1 loss : 0.434293 model2 loss : 0.027355
[11:04:31.607] iteration 9018 : model1 loss : 0.437401 model2 loss : 0.029714
[11:04:31.771] iteration 9019 : model1 loss : 0.440262 model2 loss : 0.032944
[11:04:31.939] iteration 9020 : model1 loss : 0.434896 model2 loss : 0.024995
[11:04:32.105] iteration 9021 : model1 loss : 0.434997 model2 loss : 0.027405
[11:04:32.276] iteration 9022 : model1 loss : 0.436768 model2 loss : 0.022810
[11:04:32.444] iteration 9023 : model1 loss : 0.435601 model2 loss : 0.026522
[11:04:32.611] iteration 9024 : model1 loss : 0.433208 model2 loss : 0.025447
[11:04:32.777] iteration 9025 : model1 loss : 0.441876 model2 loss : 0.030451
[11:04:32.946] iteration 9026 : model1 loss : 0.436529 model2 loss : 0.026448
[11:04:33.112] iteration 9027 : model1 loss : 0.435506 model2 loss : 0.027163
[11:04:33.281] iteration 9028 : model1 loss : 0.442365 model2 loss : 0.038540
[11:04:33.447] iteration 9029 : model1 loss : 0.437533 model2 loss : 0.029889
[11:04:33.614] iteration 9030 : model1 loss : 0.438570 model2 loss : 0.025268
[11:04:33.781] iteration 9031 : model1 loss : 0.437038 model2 loss : 0.025067
[11:04:33.947] iteration 9032 : model1 loss : 0.436770 model2 loss : 0.025355
[11:04:34.113] iteration 9033 : model1 loss : 0.437697 model2 loss : 0.031490
[11:04:34.281] iteration 9034 : model1 loss : 0.438145 model2 loss : 0.028276
[11:04:34.448] iteration 9035 : model1 loss : 0.441260 model2 loss : 0.034506
[11:04:34.614] iteration 9036 : model1 loss : 0.441011 model2 loss : 0.036852
[11:04:34.780] iteration 9037 : model1 loss : 0.432743 model2 loss : 0.022893
[11:04:34.948] iteration 9038 : model1 loss : 0.435477 model2 loss : 0.029422
[11:04:35.114] iteration 9039 : model1 loss : 0.435408 model2 loss : 0.029871
[11:04:35.282] iteration 9040 : model1 loss : 0.433394 model2 loss : 0.025119
[11:04:35.447] iteration 9041 : model1 loss : 0.439063 model2 loss : 0.028385
[11:04:35.615] iteration 9042 : model1 loss : 0.437542 model2 loss : 0.030890
[11:04:37.543] iteration 9043 : model1 loss : 0.437677 model2 loss : 0.026401
[11:04:37.714] iteration 9044 : model1 loss : 0.437363 model2 loss : 0.031686
[11:04:37.884] iteration 9045 : model1 loss : 0.439092 model2 loss : 0.024659
[11:04:38.050] iteration 9046 : model1 loss : 0.438805 model2 loss : 0.027775
[11:04:38.219] iteration 9047 : model1 loss : 0.437242 model2 loss : 0.035855
[11:04:38.386] iteration 9048 : model1 loss : 0.437293 model2 loss : 0.028353
[11:04:38.555] iteration 9049 : model1 loss : 0.435921 model2 loss : 0.027221
[11:04:38.721] iteration 9050 : model1 loss : 0.439054 model2 loss : 0.025121
[11:04:38.889] iteration 9051 : model1 loss : 0.436109 model2 loss : 0.026224
[11:04:39.057] iteration 9052 : model1 loss : 0.433371 model2 loss : 0.026632
[11:04:39.224] iteration 9053 : model1 loss : 0.439289 model2 loss : 0.028694
[11:04:39.391] iteration 9054 : model1 loss : 0.441013 model2 loss : 0.030929
[11:04:39.560] iteration 9055 : model1 loss : 0.439634 model2 loss : 0.031829
[11:04:39.727] iteration 9056 : model1 loss : 0.436482 model2 loss : 0.028317
[11:04:39.895] iteration 9057 : model1 loss : 0.434706 model2 loss : 0.032577
[11:04:40.060] iteration 9058 : model1 loss : 0.438747 model2 loss : 0.027544
[11:04:40.230] iteration 9059 : model1 loss : 0.435349 model2 loss : 0.026652
[11:04:40.397] iteration 9060 : model1 loss : 0.441497 model2 loss : 0.029868
[11:04:40.567] iteration 9061 : model1 loss : 0.437429 model2 loss : 0.026774
[11:04:40.735] iteration 9062 : model1 loss : 0.437191 model2 loss : 0.028252
[11:04:40.906] iteration 9063 : model1 loss : 0.434625 model2 loss : 0.033080
[11:04:41.073] iteration 9064 : model1 loss : 0.436704 model2 loss : 0.026789
[11:04:41.242] iteration 9065 : model1 loss : 0.437261 model2 loss : 0.027443
[11:04:41.407] iteration 9066 : model1 loss : 0.435361 model2 loss : 0.028999
[11:04:41.577] iteration 9067 : model1 loss : 0.439047 model2 loss : 0.025671
[11:04:41.746] iteration 9068 : model1 loss : 0.433999 model2 loss : 0.025504
[11:04:41.914] iteration 9069 : model1 loss : 0.431801 model2 loss : 0.026043
[11:04:42.080] iteration 9070 : model1 loss : 0.436059 model2 loss : 0.031442
[11:04:42.250] iteration 9071 : model1 loss : 0.441464 model2 loss : 0.031436
[11:04:42.416] iteration 9072 : model1 loss : 0.437708 model2 loss : 0.028239
[11:04:42.585] iteration 9073 : model1 loss : 0.438182 model2 loss : 0.040715
[11:04:42.752] iteration 9074 : model1 loss : 0.433847 model2 loss : 0.023511
[11:04:42.919] iteration 9075 : model1 loss : 0.439024 model2 loss : 0.029299
[11:04:44.827] iteration 9076 : model1 loss : 0.436678 model2 loss : 0.028291
[11:04:44.993] iteration 9077 : model1 loss : 0.440242 model2 loss : 0.031849
[11:04:45.162] iteration 9078 : model1 loss : 0.440259 model2 loss : 0.033185
[11:04:45.327] iteration 9079 : model1 loss : 0.443516 model2 loss : 0.035215
[11:04:45.498] iteration 9080 : model1 loss : 0.434985 model2 loss : 0.024828
[11:04:45.663] iteration 9081 : model1 loss : 0.436101 model2 loss : 0.032011
[11:04:45.832] iteration 9082 : model1 loss : 0.434734 model2 loss : 0.024296
[11:04:45.999] iteration 9083 : model1 loss : 0.440978 model2 loss : 0.028392
[11:04:46.166] iteration 9084 : model1 loss : 0.436402 model2 loss : 0.023279
[11:04:46.333] iteration 9085 : model1 loss : 0.440220 model2 loss : 0.031272
[11:04:46.501] iteration 9086 : model1 loss : 0.438075 model2 loss : 0.034884
[11:04:46.667] iteration 9087 : model1 loss : 0.435836 model2 loss : 0.027174
[11:04:46.840] iteration 9088 : model1 loss : 0.438124 model2 loss : 0.034228
[11:04:47.010] iteration 9089 : model1 loss : 0.434671 model2 loss : 0.030737
[11:04:47.184] iteration 9090 : model1 loss : 0.435726 model2 loss : 0.026251
[11:04:47.349] iteration 9091 : model1 loss : 0.443589 model2 loss : 0.035812
[11:04:47.520] iteration 9092 : model1 loss : 0.435967 model2 loss : 0.028446
[11:04:47.685] iteration 9093 : model1 loss : 0.436244 model2 loss : 0.025931
[11:04:47.853] iteration 9094 : model1 loss : 0.435108 model2 loss : 0.024255
[11:04:48.018] iteration 9095 : model1 loss : 0.437221 model2 loss : 0.026956
[11:04:48.200] iteration 9096 : model1 loss : 0.438815 model2 loss : 0.029659
[11:04:48.365] iteration 9097 : model1 loss : 0.434178 model2 loss : 0.026682
[11:04:48.537] iteration 9098 : model1 loss : 0.436733 model2 loss : 0.027856
[11:04:48.704] iteration 9099 : model1 loss : 0.439172 model2 loss : 0.026310
[11:04:48.871] iteration 9100 : model1 loss : 0.441117 model2 loss : 0.025943
[11:04:49.037] iteration 9101 : model1 loss : 0.439794 model2 loss : 0.028100
[11:04:49.205] iteration 9102 : model1 loss : 0.433447 model2 loss : 0.027286
[11:04:49.372] iteration 9103 : model1 loss : 0.436464 model2 loss : 0.032796
[11:04:49.540] iteration 9104 : model1 loss : 0.432814 model2 loss : 0.024503
[11:04:49.708] iteration 9105 : model1 loss : 0.435701 model2 loss : 0.025435
[11:04:49.877] iteration 9106 : model1 loss : 0.437016 model2 loss : 0.028510
[11:04:50.042] iteration 9107 : model1 loss : 0.439167 model2 loss : 0.026529
[11:04:50.209] iteration 9108 : model1 loss : 0.438645 model2 loss : 0.029203
[11:04:52.131] iteration 9109 : model1 loss : 0.442222 model2 loss : 0.040972
[11:04:52.295] iteration 9110 : model1 loss : 0.438031 model2 loss : 0.029361
[11:04:52.463] iteration 9111 : model1 loss : 0.442711 model2 loss : 0.028781
[11:04:52.629] iteration 9112 : model1 loss : 0.443861 model2 loss : 0.035804
[11:04:52.796] iteration 9113 : model1 loss : 0.434910 model2 loss : 0.025868
[11:04:52.964] iteration 9114 : model1 loss : 0.436081 model2 loss : 0.028581
[11:04:53.133] iteration 9115 : model1 loss : 0.438216 model2 loss : 0.028825
[11:04:53.300] iteration 9116 : model1 loss : 0.434730 model2 loss : 0.032799
[11:04:53.468] iteration 9117 : model1 loss : 0.436643 model2 loss : 0.029982
[11:04:53.635] iteration 9118 : model1 loss : 0.435468 model2 loss : 0.025669
[11:04:53.805] iteration 9119 : model1 loss : 0.441404 model2 loss : 0.031913
[11:04:53.972] iteration 9120 : model1 loss : 0.437308 model2 loss : 0.028857
[11:04:54.139] iteration 9121 : model1 loss : 0.433682 model2 loss : 0.027561
[11:04:54.306] iteration 9122 : model1 loss : 0.435080 model2 loss : 0.024345
[11:04:54.476] iteration 9123 : model1 loss : 0.437900 model2 loss : 0.027823
[11:04:54.642] iteration 9124 : model1 loss : 0.435512 model2 loss : 0.023807
[11:04:54.811] iteration 9125 : model1 loss : 0.437607 model2 loss : 0.026484
[11:04:54.977] iteration 9126 : model1 loss : 0.434081 model2 loss : 0.023187
[11:04:55.149] iteration 9127 : model1 loss : 0.437622 model2 loss : 0.027549
[11:04:55.314] iteration 9128 : model1 loss : 0.436269 model2 loss : 0.029483
[11:04:55.482] iteration 9129 : model1 loss : 0.436514 model2 loss : 0.023574
[11:04:55.647] iteration 9130 : model1 loss : 0.437348 model2 loss : 0.024586
[11:04:55.817] iteration 9131 : model1 loss : 0.439073 model2 loss : 0.025352
[11:04:55.983] iteration 9132 : model1 loss : 0.436267 model2 loss : 0.025574
[11:04:56.152] iteration 9133 : model1 loss : 0.439214 model2 loss : 0.026010
[11:04:56.320] iteration 9134 : model1 loss : 0.438346 model2 loss : 0.027701
[11:04:56.488] iteration 9135 : model1 loss : 0.440362 model2 loss : 0.029308
[11:04:56.656] iteration 9136 : model1 loss : 0.437870 model2 loss : 0.030195
[11:04:56.823] iteration 9137 : model1 loss : 0.433214 model2 loss : 0.027624
[11:04:56.988] iteration 9138 : model1 loss : 0.440919 model2 loss : 0.027526
[11:04:57.156] iteration 9139 : model1 loss : 0.436805 model2 loss : 0.026935
[11:04:57.319] iteration 9140 : model1 loss : 0.438192 model2 loss : 0.027831
[11:04:57.487] iteration 9141 : model1 loss : 0.435955 model2 loss : 0.029518
[11:04:59.387] iteration 9142 : model1 loss : 0.437233 model2 loss : 0.025281
[11:04:59.553] iteration 9143 : model1 loss : 0.437703 model2 loss : 0.027595
[11:04:59.721] iteration 9144 : model1 loss : 0.437239 model2 loss : 0.025313
[11:04:59.888] iteration 9145 : model1 loss : 0.438460 model2 loss : 0.027432
[11:05:00.058] iteration 9146 : model1 loss : 0.438360 model2 loss : 0.027297
[11:05:00.224] iteration 9147 : model1 loss : 0.440154 model2 loss : 0.030678
[11:05:00.391] iteration 9148 : model1 loss : 0.436360 model2 loss : 0.023451
[11:05:00.559] iteration 9149 : model1 loss : 0.438124 model2 loss : 0.027463
[11:05:00.726] iteration 9150 : model1 loss : 0.436508 model2 loss : 0.022367
[11:05:00.894] iteration 9151 : model1 loss : 0.437151 model2 loss : 0.026621
[11:05:01.063] iteration 9152 : model1 loss : 0.437263 model2 loss : 0.030670
[11:05:01.229] iteration 9153 : model1 loss : 0.437446 model2 loss : 0.026647
[11:05:01.398] iteration 9154 : model1 loss : 0.438445 model2 loss : 0.029538
[11:05:01.563] iteration 9155 : model1 loss : 0.435342 model2 loss : 0.026822
[11:05:01.732] iteration 9156 : model1 loss : 0.432623 model2 loss : 0.023131
[11:05:01.899] iteration 9157 : model1 loss : 0.437773 model2 loss : 0.025454
[11:05:02.067] iteration 9158 : model1 loss : 0.437679 model2 loss : 0.022901
[11:05:02.236] iteration 9159 : model1 loss : 0.437647 model2 loss : 0.031296
[11:05:02.404] iteration 9160 : model1 loss : 0.432424 model2 loss : 0.023526
[11:05:02.572] iteration 9161 : model1 loss : 0.440872 model2 loss : 0.029644
[11:05:02.741] iteration 9162 : model1 loss : 0.434890 model2 loss : 0.028317
[11:05:02.907] iteration 9163 : model1 loss : 0.437722 model2 loss : 0.026202
[11:05:03.077] iteration 9164 : model1 loss : 0.437937 model2 loss : 0.026406
[11:05:03.246] iteration 9165 : model1 loss : 0.434064 model2 loss : 0.025822
[11:05:03.416] iteration 9166 : model1 loss : 0.437166 model2 loss : 0.025406
[11:05:03.584] iteration 9167 : model1 loss : 0.435237 model2 loss : 0.029836
[11:05:03.753] iteration 9168 : model1 loss : 0.438409 model2 loss : 0.029552
[11:05:03.919] iteration 9169 : model1 loss : 0.437393 model2 loss : 0.022814
[11:05:04.088] iteration 9170 : model1 loss : 0.434296 model2 loss : 0.024214
[11:05:04.258] iteration 9171 : model1 loss : 0.436886 model2 loss : 0.027436
[11:05:04.427] iteration 9172 : model1 loss : 0.436168 model2 loss : 0.027173
[11:05:04.593] iteration 9173 : model1 loss : 0.440382 model2 loss : 0.028001
[11:05:04.761] iteration 9174 : model1 loss : 0.435588 model2 loss : 0.025628
[11:05:06.714] iteration 9175 : model1 loss : 0.439168 model2 loss : 0.026807
[11:05:06.884] iteration 9176 : model1 loss : 0.434612 model2 loss : 0.026101
[11:05:07.055] iteration 9177 : model1 loss : 0.442068 model2 loss : 0.029797
[11:05:07.222] iteration 9178 : model1 loss : 0.432299 model2 loss : 0.024996
[11:05:07.389] iteration 9179 : model1 loss : 0.435143 model2 loss : 0.026608
[11:05:07.557] iteration 9180 : model1 loss : 0.437179 model2 loss : 0.026040
[11:05:07.724] iteration 9181 : model1 loss : 0.436165 model2 loss : 0.023465
[11:05:07.891] iteration 9182 : model1 loss : 0.436710 model2 loss : 0.026641
[11:05:08.058] iteration 9183 : model1 loss : 0.435014 model2 loss : 0.025905
[11:05:08.223] iteration 9184 : model1 loss : 0.437517 model2 loss : 0.028451
[11:05:08.392] iteration 9185 : model1 loss : 0.439010 model2 loss : 0.026039
[11:05:08.560] iteration 9186 : model1 loss : 0.438195 model2 loss : 0.029554
[11:05:08.729] iteration 9187 : model1 loss : 0.433707 model2 loss : 0.021802
[11:05:08.896] iteration 9188 : model1 loss : 0.433367 model2 loss : 0.027848
[11:05:09.064] iteration 9189 : model1 loss : 0.436253 model2 loss : 0.031348
[11:05:09.230] iteration 9190 : model1 loss : 0.442435 model2 loss : 0.027110
[11:05:09.399] iteration 9191 : model1 loss : 0.438475 model2 loss : 0.028407
[11:05:09.565] iteration 9192 : model1 loss : 0.439602 model2 loss : 0.028385
[11:05:09.736] iteration 9193 : model1 loss : 0.436772 model2 loss : 0.029972
[11:05:09.902] iteration 9194 : model1 loss : 0.433006 model2 loss : 0.025636
[11:05:10.073] iteration 9195 : model1 loss : 0.435989 model2 loss : 0.026318
[11:05:10.242] iteration 9196 : model1 loss : 0.436825 model2 loss : 0.026637
[11:05:10.410] iteration 9197 : model1 loss : 0.434872 model2 loss : 0.025292
[11:05:10.578] iteration 9198 : model1 loss : 0.438153 model2 loss : 0.028294
[11:05:10.748] iteration 9199 : model1 loss : 0.439798 model2 loss : 0.027176
[11:05:10.917] iteration 9200 : model1 loss : 0.438564 model2 loss : 0.025884
[11:05:11.085] iteration 9201 : model1 loss : 0.436090 model2 loss : 0.026586
[11:05:11.255] iteration 9202 : model1 loss : 0.436781 model2 loss : 0.027065
[11:05:11.426] iteration 9203 : model1 loss : 0.432052 model2 loss : 0.023949
[11:05:11.590] iteration 9204 : model1 loss : 0.439796 model2 loss : 0.028308
[11:05:11.762] iteration 9205 : model1 loss : 0.437219 model2 loss : 0.026960
[11:05:11.929] iteration 9206 : model1 loss : 0.439900 model2 loss : 0.030740
[11:05:12.096] iteration 9207 : model1 loss : 0.440214 model2 loss : 0.028901
[11:05:14.011] iteration 9208 : model1 loss : 0.438966 model2 loss : 0.029989
[11:05:14.177] iteration 9209 : model1 loss : 0.435584 model2 loss : 0.028327
[11:05:14.348] iteration 9210 : model1 loss : 0.440930 model2 loss : 0.031092
[11:05:14.516] iteration 9211 : model1 loss : 0.439054 model2 loss : 0.028150
[11:05:14.684] iteration 9212 : model1 loss : 0.439617 model2 loss : 0.030566
[11:05:14.851] iteration 9213 : model1 loss : 0.434014 model2 loss : 0.026147
[11:05:15.019] iteration 9214 : model1 loss : 0.438270 model2 loss : 0.027145
[11:05:15.185] iteration 9215 : model1 loss : 0.435842 model2 loss : 0.024271
[11:05:15.353] iteration 9216 : model1 loss : 0.436663 model2 loss : 0.024417
[11:05:15.522] iteration 9217 : model1 loss : 0.438142 model2 loss : 0.026036
[11:05:15.689] iteration 9218 : model1 loss : 0.433254 model2 loss : 0.024692
[11:05:15.858] iteration 9219 : model1 loss : 0.437396 model2 loss : 0.022738
[11:05:16.025] iteration 9220 : model1 loss : 0.436662 model2 loss : 0.021221
[11:05:16.192] iteration 9221 : model1 loss : 0.439148 model2 loss : 0.029993
[11:05:16.360] iteration 9222 : model1 loss : 0.440382 model2 loss : 0.027361
[11:05:16.529] iteration 9223 : model1 loss : 0.438633 model2 loss : 0.028330
[11:05:16.696] iteration 9224 : model1 loss : 0.434880 model2 loss : 0.024729
[11:05:16.863] iteration 9225 : model1 loss : 0.436940 model2 loss : 0.028821
[11:05:17.053] iteration 9226 : model1 loss : 0.434008 model2 loss : 0.023371
[11:05:17.220] iteration 9227 : model1 loss : 0.435886 model2 loss : 0.030148
[11:05:17.390] iteration 9228 : model1 loss : 0.440789 model2 loss : 0.026249
[11:05:17.560] iteration 9229 : model1 loss : 0.437999 model2 loss : 0.026889
[11:05:17.727] iteration 9230 : model1 loss : 0.436524 model2 loss : 0.023809
[11:05:17.895] iteration 9231 : model1 loss : 0.440679 model2 loss : 0.028425
[11:05:18.063] iteration 9232 : model1 loss : 0.435802 model2 loss : 0.022974
[11:05:18.231] iteration 9233 : model1 loss : 0.435967 model2 loss : 0.026765
[11:05:18.397] iteration 9234 : model1 loss : 0.434019 model2 loss : 0.023725
[11:05:18.564] iteration 9235 : model1 loss : 0.437009 model2 loss : 0.026383
[11:05:18.733] iteration 9236 : model1 loss : 0.438378 model2 loss : 0.028452
[11:05:18.900] iteration 9237 : model1 loss : 0.438018 model2 loss : 0.025980
[11:05:19.071] iteration 9238 : model1 loss : 0.437155 model2 loss : 0.025166
[11:05:19.236] iteration 9239 : model1 loss : 0.441276 model2 loss : 0.040259
[11:05:19.403] iteration 9240 : model1 loss : 0.431850 model2 loss : 0.025285
[11:05:21.351] iteration 9241 : model1 loss : 0.438022 model2 loss : 0.030697
[11:05:21.525] iteration 9242 : model1 loss : 0.437085 model2 loss : 0.027076
[11:05:21.694] iteration 9243 : model1 loss : 0.435728 model2 loss : 0.027269
[11:05:21.859] iteration 9244 : model1 loss : 0.432915 model2 loss : 0.022683
[11:05:22.025] iteration 9245 : model1 loss : 0.431456 model2 loss : 0.029534
[11:05:22.192] iteration 9246 : model1 loss : 0.436705 model2 loss : 0.032762
[11:05:22.363] iteration 9247 : model1 loss : 0.437778 model2 loss : 0.030757
[11:05:22.529] iteration 9248 : model1 loss : 0.436394 model2 loss : 0.029290
[11:05:22.700] iteration 9249 : model1 loss : 0.435093 model2 loss : 0.022639
[11:05:22.866] iteration 9250 : model1 loss : 0.437026 model2 loss : 0.027634
[11:05:23.035] iteration 9251 : model1 loss : 0.433937 model2 loss : 0.025410
[11:05:23.204] iteration 9252 : model1 loss : 0.437854 model2 loss : 0.027094
[11:05:23.371] iteration 9253 : model1 loss : 0.439310 model2 loss : 0.027845
[11:05:23.541] iteration 9254 : model1 loss : 0.439964 model2 loss : 0.025324
[11:05:23.708] iteration 9255 : model1 loss : 0.435951 model2 loss : 0.025302
[11:05:23.875] iteration 9256 : model1 loss : 0.439725 model2 loss : 0.026268
[11:05:24.043] iteration 9257 : model1 loss : 0.431916 model2 loss : 0.023806
[11:05:24.208] iteration 9258 : model1 loss : 0.440869 model2 loss : 0.029212
[11:05:24.376] iteration 9259 : model1 loss : 0.434981 model2 loss : 0.024893
[11:05:24.543] iteration 9260 : model1 loss : 0.437630 model2 loss : 0.026766
[11:05:24.713] iteration 9261 : model1 loss : 0.440132 model2 loss : 0.030026
[11:05:24.880] iteration 9262 : model1 loss : 0.437372 model2 loss : 0.027471
[11:05:25.048] iteration 9263 : model1 loss : 0.439321 model2 loss : 0.025330
[11:05:25.215] iteration 9264 : model1 loss : 0.436292 model2 loss : 0.024840
[11:05:25.385] iteration 9265 : model1 loss : 0.436168 model2 loss : 0.025812
[11:05:25.554] iteration 9266 : model1 loss : 0.437170 model2 loss : 0.029029
[11:05:25.723] iteration 9267 : model1 loss : 0.436576 model2 loss : 0.023334
[11:05:25.892] iteration 9268 : model1 loss : 0.440785 model2 loss : 0.026606
[11:05:26.062] iteration 9269 : model1 loss : 0.440210 model2 loss : 0.032143
[11:05:26.227] iteration 9270 : model1 loss : 0.438563 model2 loss : 0.029637
[11:05:26.396] iteration 9271 : model1 loss : 0.436436 model2 loss : 0.027882
[11:05:26.563] iteration 9272 : model1 loss : 0.441203 model2 loss : 0.030161
[11:05:26.732] iteration 9273 : model1 loss : 0.439680 model2 loss : 0.027955
[11:05:28.661] iteration 9274 : model1 loss : 0.435406 model2 loss : 0.026385
[11:05:28.827] iteration 9275 : model1 loss : 0.441833 model2 loss : 0.025851
[11:05:28.995] iteration 9276 : model1 loss : 0.441183 model2 loss : 0.025688
[11:05:29.164] iteration 9277 : model1 loss : 0.439977 model2 loss : 0.025477
[11:05:29.332] iteration 9278 : model1 loss : 0.442252 model2 loss : 0.029884
[11:05:29.505] iteration 9279 : model1 loss : 0.434920 model2 loss : 0.024153
[11:05:29.674] iteration 9280 : model1 loss : 0.436866 model2 loss : 0.028195
[11:05:29.840] iteration 9281 : model1 loss : 0.438789 model2 loss : 0.038970
[11:05:30.008] iteration 9282 : model1 loss : 0.439304 model2 loss : 0.025131
[11:05:30.175] iteration 9283 : model1 loss : 0.437229 model2 loss : 0.027397
[11:05:30.343] iteration 9284 : model1 loss : 0.438365 model2 loss : 0.027112
[11:05:30.511] iteration 9285 : model1 loss : 0.434875 model2 loss : 0.026727
[11:05:30.680] iteration 9286 : model1 loss : 0.436921 model2 loss : 0.028981
[11:05:30.852] iteration 9287 : model1 loss : 0.439323 model2 loss : 0.025946
[11:05:31.020] iteration 9288 : model1 loss : 0.438901 model2 loss : 0.025241
[11:05:31.187] iteration 9289 : model1 loss : 0.441154 model2 loss : 0.029133
[11:05:31.355] iteration 9290 : model1 loss : 0.437607 model2 loss : 0.024988
[11:05:31.524] iteration 9291 : model1 loss : 0.435172 model2 loss : 0.025535
[11:05:31.693] iteration 9292 : model1 loss : 0.437841 model2 loss : 0.030606
[11:05:31.860] iteration 9293 : model1 loss : 0.434463 model2 loss : 0.024413
[11:05:32.030] iteration 9294 : model1 loss : 0.436000 model2 loss : 0.024254
[11:05:32.196] iteration 9295 : model1 loss : 0.438738 model2 loss : 0.030915
[11:05:32.365] iteration 9296 : model1 loss : 0.434570 model2 loss : 0.027827
[11:05:32.532] iteration 9297 : model1 loss : 0.434842 model2 loss : 0.029176
[11:05:32.700] iteration 9298 : model1 loss : 0.435828 model2 loss : 0.025164
[11:05:32.866] iteration 9299 : model1 loss : 0.437070 model2 loss : 0.025450
[11:05:33.037] iteration 9300 : model1 loss : 0.435206 model2 loss : 0.026324
[11:05:33.204] iteration 9301 : model1 loss : 0.442280 model2 loss : 0.035980
[11:05:33.373] iteration 9302 : model1 loss : 0.437118 model2 loss : 0.025770
[11:05:33.544] iteration 9303 : model1 loss : 0.434604 model2 loss : 0.027138
[11:05:33.711] iteration 9304 : model1 loss : 0.437253 model2 loss : 0.028241
[11:05:33.876] iteration 9305 : model1 loss : 0.434916 model2 loss : 0.024621
[11:05:34.044] iteration 9306 : model1 loss : 0.439264 model2 loss : 0.031301
[11:05:35.979] iteration 9307 : model1 loss : 0.439108 model2 loss : 0.028293
[11:05:36.145] iteration 9308 : model1 loss : 0.439440 model2 loss : 0.028829
[11:05:36.318] iteration 9309 : model1 loss : 0.437263 model2 loss : 0.026481
[11:05:36.486] iteration 9310 : model1 loss : 0.437364 model2 loss : 0.027086
[11:05:36.654] iteration 9311 : model1 loss : 0.433598 model2 loss : 0.026200
[11:05:36.822] iteration 9312 : model1 loss : 0.437806 model2 loss : 0.026010
[11:05:36.990] iteration 9313 : model1 loss : 0.434964 model2 loss : 0.022941
[11:05:37.157] iteration 9314 : model1 loss : 0.440125 model2 loss : 0.029950
[11:05:37.354] iteration 9315 : model1 loss : 0.433784 model2 loss : 0.025319
[11:05:37.525] iteration 9316 : model1 loss : 0.436625 model2 loss : 0.028830
[11:05:37.694] iteration 9317 : model1 loss : 0.434540 model2 loss : 0.026582
[11:05:37.862] iteration 9318 : model1 loss : 0.437988 model2 loss : 0.027109
[11:05:38.031] iteration 9319 : model1 loss : 0.437435 model2 loss : 0.022782
[11:05:38.198] iteration 9320 : model1 loss : 0.438848 model2 loss : 0.023843
[11:05:38.367] iteration 9321 : model1 loss : 0.434908 model2 loss : 0.027323
[11:05:38.538] iteration 9322 : model1 loss : 0.440018 model2 loss : 0.028457
[11:05:38.706] iteration 9323 : model1 loss : 0.439954 model2 loss : 0.028353
[11:05:38.873] iteration 9324 : model1 loss : 0.434544 model2 loss : 0.026386
[11:05:39.043] iteration 9325 : model1 loss : 0.441956 model2 loss : 0.030057
[11:05:39.209] iteration 9326 : model1 loss : 0.436037 model2 loss : 0.025056
[11:05:39.379] iteration 9327 : model1 loss : 0.434907 model2 loss : 0.026341
[11:05:39.544] iteration 9328 : model1 loss : 0.438563 model2 loss : 0.026511
[11:05:39.713] iteration 9329 : model1 loss : 0.438569 model2 loss : 0.028741
[11:05:39.879] iteration 9330 : model1 loss : 0.444333 model2 loss : 0.030564
[11:05:40.050] iteration 9331 : model1 loss : 0.440086 model2 loss : 0.028088
[11:05:40.215] iteration 9332 : model1 loss : 0.444670 model2 loss : 0.025846
[11:05:40.385] iteration 9333 : model1 loss : 0.439990 model2 loss : 0.025995
[11:05:40.553] iteration 9334 : model1 loss : 0.442087 model2 loss : 0.031205
[11:05:40.725] iteration 9335 : model1 loss : 0.437652 model2 loss : 0.028017
[11:05:40.896] iteration 9336 : model1 loss : 0.436362 model2 loss : 0.024007
[11:05:41.066] iteration 9337 : model1 loss : 0.436242 model2 loss : 0.027964
[11:05:41.231] iteration 9338 : model1 loss : 0.435103 model2 loss : 0.027157
[11:05:41.398] iteration 9339 : model1 loss : 0.444559 model2 loss : 0.025271
[11:05:43.331] iteration 9340 : model1 loss : 0.436996 model2 loss : 0.024615
[11:05:43.501] iteration 9341 : model1 loss : 0.441314 model2 loss : 0.029544
[11:05:43.670] iteration 9342 : model1 loss : 0.431436 model2 loss : 0.022646
[11:05:43.837] iteration 9343 : model1 loss : 0.447246 model2 loss : 0.046465
[11:05:44.004] iteration 9344 : model1 loss : 0.439349 model2 loss : 0.027443
[11:05:44.186] iteration 9345 : model1 loss : 0.444662 model2 loss : 0.031364
[11:05:44.361] iteration 9346 : model1 loss : 0.441991 model2 loss : 0.027223
[11:05:44.528] iteration 9347 : model1 loss : 0.435118 model2 loss : 0.024624
[11:05:44.698] iteration 9348 : model1 loss : 0.442370 model2 loss : 0.029110
[11:05:44.866] iteration 9349 : model1 loss : 0.437691 model2 loss : 0.027444
[11:05:45.033] iteration 9350 : model1 loss : 0.438035 model2 loss : 0.027989
[11:05:45.200] iteration 9351 : model1 loss : 0.434344 model2 loss : 0.031079
[11:05:45.368] iteration 9352 : model1 loss : 0.437273 model2 loss : 0.030261
[11:05:45.537] iteration 9353 : model1 loss : 0.440814 model2 loss : 0.029457
[11:05:45.706] iteration 9354 : model1 loss : 0.446894 model2 loss : 0.026896
[11:05:45.877] iteration 9355 : model1 loss : 0.442943 model2 loss : 0.029562
[11:05:46.047] iteration 9356 : model1 loss : 0.436661 model2 loss : 0.027472
[11:05:46.214] iteration 9357 : model1 loss : 0.436212 model2 loss : 0.026734
[11:05:46.384] iteration 9358 : model1 loss : 0.436412 model2 loss : 0.024192
[11:05:46.549] iteration 9359 : model1 loss : 0.438006 model2 loss : 0.027647
[11:05:46.717] iteration 9360 : model1 loss : 0.442483 model2 loss : 0.029256
[11:05:46.884] iteration 9361 : model1 loss : 0.438652 model2 loss : 0.025412
[11:05:47.052] iteration 9362 : model1 loss : 0.437371 model2 loss : 0.027925
[11:05:47.219] iteration 9363 : model1 loss : 0.436370 model2 loss : 0.025095
[11:05:47.387] iteration 9364 : model1 loss : 0.441498 model2 loss : 0.028167
[11:05:47.556] iteration 9365 : model1 loss : 0.440398 model2 loss : 0.026210
[11:05:47.729] iteration 9366 : model1 loss : 0.440131 model2 loss : 0.027778
[11:05:47.895] iteration 9367 : model1 loss : 0.437672 model2 loss : 0.025382
[11:05:48.065] iteration 9368 : model1 loss : 0.439695 model2 loss : 0.030171
[11:05:48.233] iteration 9369 : model1 loss : 0.444664 model2 loss : 0.029105
[11:05:48.402] iteration 9370 : model1 loss : 0.442565 model2 loss : 0.029134
[11:05:48.569] iteration 9371 : model1 loss : 0.440178 model2 loss : 0.026105
[11:05:48.738] iteration 9372 : model1 loss : 0.435926 model2 loss : 0.025728
[11:05:50.657] iteration 9373 : model1 loss : 0.441123 model2 loss : 0.023549
[11:05:50.824] iteration 9374 : model1 loss : 0.438658 model2 loss : 0.025814
[11:05:50.992] iteration 9375 : model1 loss : 0.436713 model2 loss : 0.024569
[11:05:51.160] iteration 9376 : model1 loss : 0.437313 model2 loss : 0.025616
[11:05:51.334] iteration 9377 : model1 loss : 0.441070 model2 loss : 0.026252
[11:05:51.504] iteration 9378 : model1 loss : 0.441259 model2 loss : 0.027724
[11:05:51.671] iteration 9379 : model1 loss : 0.434890 model2 loss : 0.026339
[11:05:51.837] iteration 9380 : model1 loss : 0.439877 model2 loss : 0.027908
[11:05:52.006] iteration 9381 : model1 loss : 0.442453 model2 loss : 0.031123
[11:05:52.173] iteration 9382 : model1 loss : 0.444545 model2 loss : 0.029088
[11:05:52.345] iteration 9383 : model1 loss : 0.440093 model2 loss : 0.030134
[11:05:52.515] iteration 9384 : model1 loss : 0.443361 model2 loss : 0.028583
[11:05:52.684] iteration 9385 : model1 loss : 0.438589 model2 loss : 0.027674
[11:05:52.850] iteration 9386 : model1 loss : 0.444622 model2 loss : 0.032069
[11:05:53.020] iteration 9387 : model1 loss : 0.440124 model2 loss : 0.026798
[11:05:53.186] iteration 9388 : model1 loss : 0.441963 model2 loss : 0.032409
[11:05:53.357] iteration 9389 : model1 loss : 0.441832 model2 loss : 0.031084
[11:05:53.529] iteration 9390 : model1 loss : 0.440932 model2 loss : 0.030004
[11:05:53.698] iteration 9391 : model1 loss : 0.443703 model2 loss : 0.029112
[11:05:53.864] iteration 9392 : model1 loss : 0.440270 model2 loss : 0.026034
[11:05:54.031] iteration 9393 : model1 loss : 0.440716 model2 loss : 0.026506
[11:05:54.196] iteration 9394 : model1 loss : 0.436885 model2 loss : 0.028108
[11:05:54.365] iteration 9395 : model1 loss : 0.441566 model2 loss : 0.026784
[11:05:54.532] iteration 9396 : model1 loss : 0.445583 model2 loss : 0.029088
[11:05:54.701] iteration 9397 : model1 loss : 0.440002 model2 loss : 0.028670
[11:05:54.869] iteration 9398 : model1 loss : 0.437899 model2 loss : 0.026421
[11:05:55.039] iteration 9399 : model1 loss : 0.438924 model2 loss : 0.025775
[11:05:55.207] iteration 9400 : model1 loss : 0.441502 model2 loss : 0.026807
[11:05:55.376] iteration 9401 : model1 loss : 0.444941 model2 loss : 0.025787
[11:05:55.541] iteration 9402 : model1 loss : 0.434031 model2 loss : 0.021175
[11:05:55.711] iteration 9403 : model1 loss : 0.438393 model2 loss : 0.034167
[11:05:55.881] iteration 9404 : model1 loss : 0.435304 model2 loss : 0.027325
[11:05:56.048] iteration 9405 : model1 loss : 0.442233 model2 loss : 0.027660
[11:05:58.002] iteration 9406 : model1 loss : 0.434549 model2 loss : 0.024807
[11:05:58.170] iteration 9407 : model1 loss : 0.438800 model2 loss : 0.026352
[11:05:58.340] iteration 9408 : model1 loss : 0.440518 model2 loss : 0.028358
[11:05:58.510] iteration 9409 : model1 loss : 0.440667 model2 loss : 0.035941
[11:05:58.680] iteration 9410 : model1 loss : 0.438193 model2 loss : 0.030749
[11:05:58.847] iteration 9411 : model1 loss : 0.442470 model2 loss : 0.025102
[11:05:59.015] iteration 9412 : model1 loss : 0.436773 model2 loss : 0.026126
[11:05:59.181] iteration 9413 : model1 loss : 0.438640 model2 loss : 0.027630
[11:05:59.354] iteration 9414 : model1 loss : 0.441705 model2 loss : 0.032552
[11:05:59.523] iteration 9415 : model1 loss : 0.437363 model2 loss : 0.027829
[11:05:59.692] iteration 9416 : model1 loss : 0.436771 model2 loss : 0.027157
[11:05:59.859] iteration 9417 : model1 loss : 0.437011 model2 loss : 0.027842
[11:06:00.026] iteration 9418 : model1 loss : 0.439254 model2 loss : 0.029561
[11:06:00.193] iteration 9419 : model1 loss : 0.439010 model2 loss : 0.028942
[11:06:00.364] iteration 9420 : model1 loss : 0.438267 model2 loss : 0.027189
[11:06:00.533] iteration 9421 : model1 loss : 0.439896 model2 loss : 0.026736
[11:06:00.703] iteration 9422 : model1 loss : 0.435181 model2 loss : 0.025300
[11:06:00.871] iteration 9423 : model1 loss : 0.439360 model2 loss : 0.028550
[11:06:01.041] iteration 9424 : model1 loss : 0.441492 model2 loss : 0.029967
[11:06:01.209] iteration 9425 : model1 loss : 0.436214 model2 loss : 0.025245
[11:06:01.381] iteration 9426 : model1 loss : 0.438039 model2 loss : 0.031254
[11:06:01.549] iteration 9427 : model1 loss : 0.441557 model2 loss : 0.028925
[11:06:01.720] iteration 9428 : model1 loss : 0.432982 model2 loss : 0.024693
[11:06:01.885] iteration 9429 : model1 loss : 0.436069 model2 loss : 0.025858
[11:06:02.054] iteration 9430 : model1 loss : 0.435234 model2 loss : 0.025719
[11:06:02.221] iteration 9431 : model1 loss : 0.436218 model2 loss : 0.029074
[11:06:02.391] iteration 9432 : model1 loss : 0.438527 model2 loss : 0.031269
[11:06:02.561] iteration 9433 : model1 loss : 0.440048 model2 loss : 0.027384
[11:06:02.732] iteration 9434 : model1 loss : 0.441393 model2 loss : 0.027996
[11:06:02.898] iteration 9435 : model1 loss : 0.447671 model2 loss : 0.036518
[11:06:03.069] iteration 9436 : model1 loss : 0.437336 model2 loss : 0.025757
[11:06:03.234] iteration 9437 : model1 loss : 0.441010 model2 loss : 0.026391
[11:06:03.401] iteration 9438 : model1 loss : 0.437277 model2 loss : 0.025291
[11:06:05.327] iteration 9439 : model1 loss : 0.439096 model2 loss : 0.027307
[11:06:05.499] iteration 9440 : model1 loss : 0.435364 model2 loss : 0.026345
[11:06:05.668] iteration 9441 : model1 loss : 0.437129 model2 loss : 0.030403
[11:06:05.837] iteration 9442 : model1 loss : 0.440657 model2 loss : 0.029418
[11:06:06.006] iteration 9443 : model1 loss : 0.438124 model2 loss : 0.027161
[11:06:06.173] iteration 9444 : model1 loss : 0.436860 model2 loss : 0.026635
[11:06:06.345] iteration 9445 : model1 loss : 0.439701 model2 loss : 0.030278
[11:06:06.514] iteration 9446 : model1 loss : 0.443146 model2 loss : 0.027529
[11:06:06.682] iteration 9447 : model1 loss : 0.435039 model2 loss : 0.028026
[11:06:06.850] iteration 9448 : model1 loss : 0.438824 model2 loss : 0.024708
[11:06:07.018] iteration 9449 : model1 loss : 0.439678 model2 loss : 0.029206
[11:06:07.185] iteration 9450 : model1 loss : 0.434216 model2 loss : 0.030014
[11:06:07.358] iteration 9451 : model1 loss : 0.442805 model2 loss : 0.033700
[11:06:07.528] iteration 9452 : model1 loss : 0.438218 model2 loss : 0.025761
[11:06:07.695] iteration 9453 : model1 loss : 0.438494 model2 loss : 0.026485
[11:06:07.863] iteration 9454 : model1 loss : 0.439496 model2 loss : 0.025476
[11:06:08.032] iteration 9455 : model1 loss : 0.439306 model2 loss : 0.026435
[11:06:08.199] iteration 9456 : model1 loss : 0.440873 model2 loss : 0.029616
[11:06:08.369] iteration 9457 : model1 loss : 0.439508 model2 loss : 0.023581
[11:06:08.536] iteration 9458 : model1 loss : 0.441935 model2 loss : 0.024678
[11:06:08.707] iteration 9459 : model1 loss : 0.434220 model2 loss : 0.027839
[11:06:08.874] iteration 9460 : model1 loss : 0.435855 model2 loss : 0.026275
[11:06:09.044] iteration 9461 : model1 loss : 0.436391 model2 loss : 0.028145
[11:06:09.211] iteration 9462 : model1 loss : 0.432351 model2 loss : 0.024754
[11:06:09.381] iteration 9463 : model1 loss : 0.432219 model2 loss : 0.023756
[11:06:09.549] iteration 9464 : model1 loss : 0.443021 model2 loss : 0.028227
[11:06:09.719] iteration 9465 : model1 loss : 0.439360 model2 loss : 0.025512
[11:06:09.885] iteration 9466 : model1 loss : 0.441821 model2 loss : 0.032563
[11:06:10.056] iteration 9467 : model1 loss : 0.442148 model2 loss : 0.028304
[11:06:10.223] iteration 9468 : model1 loss : 0.436760 model2 loss : 0.024764
[11:06:10.392] iteration 9469 : model1 loss : 0.437128 model2 loss : 0.023141
[11:06:10.556] iteration 9470 : model1 loss : 0.443190 model2 loss : 0.028183
[11:06:10.724] iteration 9471 : model1 loss : 0.437226 model2 loss : 0.026758
[11:06:12.700] iteration 9472 : model1 loss : 0.438616 model2 loss : 0.029883
[11:06:12.868] iteration 9473 : model1 loss : 0.436541 model2 loss : 0.028260
[11:06:13.039] iteration 9474 : model1 loss : 0.439117 model2 loss : 0.028096
[11:06:13.205] iteration 9475 : model1 loss : 0.439502 model2 loss : 0.027196
[11:06:13.378] iteration 9476 : model1 loss : 0.444396 model2 loss : 0.035126
[11:06:13.546] iteration 9477 : model1 loss : 0.440227 model2 loss : 0.026891
[11:06:13.714] iteration 9478 : model1 loss : 0.436967 model2 loss : 0.024226
[11:06:13.881] iteration 9479 : model1 loss : 0.435915 model2 loss : 0.026698
[11:06:14.051] iteration 9480 : model1 loss : 0.436602 model2 loss : 0.029514
[11:06:14.220] iteration 9481 : model1 loss : 0.441179 model2 loss : 0.032034
[11:06:14.388] iteration 9482 : model1 loss : 0.434906 model2 loss : 0.023164
[11:06:14.555] iteration 9483 : model1 loss : 0.440645 model2 loss : 0.029794
[11:06:14.724] iteration 9484 : model1 loss : 0.437620 model2 loss : 0.026740
[11:06:14.890] iteration 9485 : model1 loss : 0.439811 model2 loss : 0.026424
[11:06:15.060] iteration 9486 : model1 loss : 0.435340 model2 loss : 0.024559
[11:06:15.226] iteration 9487 : model1 loss : 0.436807 model2 loss : 0.027344
[11:06:15.395] iteration 9488 : model1 loss : 0.437547 model2 loss : 0.027717
[11:06:15.564] iteration 9489 : model1 loss : 0.439096 model2 loss : 0.026145
[11:06:15.733] iteration 9490 : model1 loss : 0.439896 model2 loss : 0.026448
[11:06:15.905] iteration 9491 : model1 loss : 0.437427 model2 loss : 0.026096
[11:06:16.074] iteration 9492 : model1 loss : 0.435254 model2 loss : 0.024835
[11:06:16.242] iteration 9493 : model1 loss : 0.432777 model2 loss : 0.023977
[11:06:16.413] iteration 9494 : model1 loss : 0.436258 model2 loss : 0.026392
[11:06:16.581] iteration 9495 : model1 loss : 0.437036 model2 loss : 0.030636
[11:06:16.749] iteration 9496 : model1 loss : 0.444472 model2 loss : 0.029683
[11:06:16.916] iteration 9497 : model1 loss : 0.435492 model2 loss : 0.026866
[11:06:17.085] iteration 9498 : model1 loss : 0.436682 model2 loss : 0.027587
[11:06:17.253] iteration 9499 : model1 loss : 0.442834 model2 loss : 0.031001
[11:06:17.424] iteration 9500 : model1 loss : 0.435804 model2 loss : 0.032342
[11:06:17.592] iteration 9501 : model1 loss : 0.434995 model2 loss : 0.025109
[11:06:17.761] iteration 9502 : model1 loss : 0.435180 model2 loss : 0.026857
[11:06:17.927] iteration 9503 : model1 loss : 0.443244 model2 loss : 0.027863
[11:06:18.096] iteration 9504 : model1 loss : 0.436469 model2 loss : 0.028357
[11:06:20.018] iteration 9505 : model1 loss : 0.434761 model2 loss : 0.026211
[11:06:20.186] iteration 9506 : model1 loss : 0.437570 model2 loss : 0.027974
[11:06:20.356] iteration 9507 : model1 loss : 0.436718 model2 loss : 0.029400
[11:06:20.526] iteration 9508 : model1 loss : 0.438886 model2 loss : 0.024673
[11:06:20.697] iteration 9509 : model1 loss : 0.438819 model2 loss : 0.027843
[11:06:20.867] iteration 9510 : model1 loss : 0.439294 model2 loss : 0.027782
[11:06:21.034] iteration 9511 : model1 loss : 0.437473 model2 loss : 0.026644
[11:06:21.201] iteration 9512 : model1 loss : 0.435247 model2 loss : 0.025552
[11:06:21.370] iteration 9513 : model1 loss : 0.437307 model2 loss : 0.026125
[11:06:21.538] iteration 9514 : model1 loss : 0.438221 model2 loss : 0.027277
[11:06:21.706] iteration 9515 : model1 loss : 0.436693 model2 loss : 0.029528
[11:06:21.874] iteration 9516 : model1 loss : 0.435059 model2 loss : 0.026365
[11:06:22.045] iteration 9517 : model1 loss : 0.440292 model2 loss : 0.029392
[11:06:22.211] iteration 9518 : model1 loss : 0.434980 model2 loss : 0.022767
[11:06:22.382] iteration 9519 : model1 loss : 0.434519 model2 loss : 0.024447
[11:06:22.572] iteration 9520 : model1 loss : 0.443099 model2 loss : 0.033435
[11:06:22.741] iteration 9521 : model1 loss : 0.432084 model2 loss : 0.022766
[11:06:22.907] iteration 9522 : model1 loss : 0.438795 model2 loss : 0.026357
[11:06:23.077] iteration 9523 : model1 loss : 0.435981 model2 loss : 0.024886
[11:06:23.245] iteration 9524 : model1 loss : 0.437679 model2 loss : 0.027378
[11:06:23.417] iteration 9525 : model1 loss : 0.436876 model2 loss : 0.026056
[11:06:23.585] iteration 9526 : model1 loss : 0.439129 model2 loss : 0.032393
[11:06:23.754] iteration 9527 : model1 loss : 0.436884 model2 loss : 0.025086
[11:06:23.922] iteration 9528 : model1 loss : 0.434058 model2 loss : 0.024348
[11:06:24.090] iteration 9529 : model1 loss : 0.437262 model2 loss : 0.025937
[11:06:24.259] iteration 9530 : model1 loss : 0.437232 model2 loss : 0.024967
[11:06:24.427] iteration 9531 : model1 loss : 0.441699 model2 loss : 0.030718
[11:06:24.594] iteration 9532 : model1 loss : 0.434128 model2 loss : 0.024941
[11:06:24.764] iteration 9533 : model1 loss : 0.440705 model2 loss : 0.028896
[11:06:24.932] iteration 9534 : model1 loss : 0.441312 model2 loss : 0.028009
[11:06:25.102] iteration 9535 : model1 loss : 0.438602 model2 loss : 0.026138
[11:06:25.267] iteration 9536 : model1 loss : 0.440495 model2 loss : 0.037938
[11:06:25.437] iteration 9537 : model1 loss : 0.437167 model2 loss : 0.027763
[11:06:27.353] iteration 9538 : model1 loss : 0.437789 model2 loss : 0.025450
[11:06:27.521] iteration 9539 : model1 loss : 0.431414 model2 loss : 0.023937
[11:06:27.691] iteration 9540 : model1 loss : 0.438158 model2 loss : 0.026523
[11:06:27.866] iteration 9541 : model1 loss : 0.438791 model2 loss : 0.028720
[11:06:28.036] iteration 9542 : model1 loss : 0.437569 model2 loss : 0.025054
[11:06:28.202] iteration 9543 : model1 loss : 0.438772 model2 loss : 0.024476
[11:06:28.372] iteration 9544 : model1 loss : 0.434022 model2 loss : 0.029108
[11:06:28.540] iteration 9545 : model1 loss : 0.439844 model2 loss : 0.027984
[11:06:28.708] iteration 9546 : model1 loss : 0.438358 model2 loss : 0.028006
[11:06:28.875] iteration 9547 : model1 loss : 0.439131 model2 loss : 0.028003
[11:06:29.044] iteration 9548 : model1 loss : 0.436059 model2 loss : 0.026506
[11:06:29.211] iteration 9549 : model1 loss : 0.435765 model2 loss : 0.024587
[11:06:29.380] iteration 9550 : model1 loss : 0.437379 model2 loss : 0.025269
[11:06:29.547] iteration 9551 : model1 loss : 0.440367 model2 loss : 0.029348
[11:06:29.716] iteration 9552 : model1 loss : 0.436669 model2 loss : 0.026447
[11:06:29.881] iteration 9553 : model1 loss : 0.439131 model2 loss : 0.025705
[11:06:30.049] iteration 9554 : model1 loss : 0.435062 model2 loss : 0.026768
[11:06:30.215] iteration 9555 : model1 loss : 0.436359 model2 loss : 0.026940
[11:06:30.385] iteration 9556 : model1 loss : 0.436357 model2 loss : 0.022441
[11:06:30.554] iteration 9557 : model1 loss : 0.434938 model2 loss : 0.027102
[11:06:30.722] iteration 9558 : model1 loss : 0.442680 model2 loss : 0.026411
[11:06:30.894] iteration 9559 : model1 loss : 0.440524 model2 loss : 0.025592
[11:06:31.062] iteration 9560 : model1 loss : 0.434477 model2 loss : 0.025091
[11:06:31.229] iteration 9561 : model1 loss : 0.436638 model2 loss : 0.027066
[11:06:31.401] iteration 9562 : model1 loss : 0.438854 model2 loss : 0.026275
[11:06:31.572] iteration 9563 : model1 loss : 0.433938 model2 loss : 0.027223
[11:06:31.740] iteration 9564 : model1 loss : 0.440752 model2 loss : 0.027407
[11:06:31.906] iteration 9565 : model1 loss : 0.437850 model2 loss : 0.029445
[11:06:32.074] iteration 9566 : model1 loss : 0.440139 model2 loss : 0.040558
[11:06:32.248] iteration 9567 : model1 loss : 0.433500 model2 loss : 0.024248
[11:06:32.420] iteration 9568 : model1 loss : 0.440152 model2 loss : 0.027299
[11:06:32.586] iteration 9569 : model1 loss : 0.437417 model2 loss : 0.025245
[11:06:32.754] iteration 9570 : model1 loss : 0.436186 model2 loss : 0.025934
[11:06:34.691] iteration 9571 : model1 loss : 0.432561 model2 loss : 0.024700
[11:06:34.860] iteration 9572 : model1 loss : 0.434307 model2 loss : 0.025663
[11:06:35.030] iteration 9573 : model1 loss : 0.436366 model2 loss : 0.024330
[11:06:35.197] iteration 9574 : model1 loss : 0.437606 model2 loss : 0.026669
[11:06:35.366] iteration 9575 : model1 loss : 0.435842 model2 loss : 0.028187
[11:06:35.535] iteration 9576 : model1 loss : 0.439913 model2 loss : 0.026288
[11:06:35.703] iteration 9577 : model1 loss : 0.438133 model2 loss : 0.025063
[11:06:35.872] iteration 9578 : model1 loss : 0.437453 model2 loss : 0.025093
[11:06:36.040] iteration 9579 : model1 loss : 0.434784 model2 loss : 0.027545
[11:06:36.207] iteration 9580 : model1 loss : 0.441073 model2 loss : 0.029799
[11:06:36.375] iteration 9581 : model1 loss : 0.435772 model2 loss : 0.023299
[11:06:36.542] iteration 9582 : model1 loss : 0.441929 model2 loss : 0.029647
[11:06:36.714] iteration 9583 : model1 loss : 0.437225 model2 loss : 0.023555
[11:06:36.882] iteration 9584 : model1 loss : 0.436174 model2 loss : 0.026573
[11:06:37.050] iteration 9585 : model1 loss : 0.440560 model2 loss : 0.033450
[11:06:37.218] iteration 9586 : model1 loss : 0.439966 model2 loss : 0.025192
[11:06:37.385] iteration 9587 : model1 loss : 0.436001 model2 loss : 0.031543
[11:06:37.551] iteration 9588 : model1 loss : 0.437106 model2 loss : 0.025606
[11:06:37.718] iteration 9589 : model1 loss : 0.436969 model2 loss : 0.027302
[11:06:37.886] iteration 9590 : model1 loss : 0.439757 model2 loss : 0.026713
[11:06:38.055] iteration 9591 : model1 loss : 0.437009 model2 loss : 0.031529
[11:06:38.223] iteration 9592 : model1 loss : 0.440050 model2 loss : 0.025734
[11:06:38.394] iteration 9593 : model1 loss : 0.438202 model2 loss : 0.023958
[11:06:38.561] iteration 9594 : model1 loss : 0.441293 model2 loss : 0.024470
[11:06:38.729] iteration 9595 : model1 loss : 0.440904 model2 loss : 0.029679
[11:06:38.915] iteration 9596 : model1 loss : 0.437902 model2 loss : 0.026097
[11:06:39.084] iteration 9597 : model1 loss : 0.434494 model2 loss : 0.025601
[11:06:39.250] iteration 9598 : model1 loss : 0.433269 model2 loss : 0.022787
[11:06:39.421] iteration 9599 : model1 loss : 0.438112 model2 loss : 0.027701
[11:06:39.588] iteration 9600 : model1 loss : 0.435786 model2 loss : 0.025412
[11:06:39.758] iteration 9601 : model1 loss : 0.437415 model2 loss : 0.026602
[11:06:39.924] iteration 9602 : model1 loss : 0.437653 model2 loss : 0.025078
[11:06:40.091] iteration 9603 : model1 loss : 0.436033 model2 loss : 0.023318
[11:06:42.022] iteration 9604 : model1 loss : 0.440897 model2 loss : 0.035289
[11:06:42.191] iteration 9605 : model1 loss : 0.441315 model2 loss : 0.025749
[11:06:42.361] iteration 9606 : model1 loss : 0.436896 model2 loss : 0.025036
[11:06:42.528] iteration 9607 : model1 loss : 0.434886 model2 loss : 0.025787
[11:06:42.699] iteration 9608 : model1 loss : 0.444514 model2 loss : 0.035062
[11:06:42.866] iteration 9609 : model1 loss : 0.437726 model2 loss : 0.029137
[11:06:43.034] iteration 9610 : model1 loss : 0.434447 model2 loss : 0.025676
[11:06:43.201] iteration 9611 : model1 loss : 0.435726 model2 loss : 0.027372
[11:06:43.371] iteration 9612 : model1 loss : 0.435752 model2 loss : 0.025253
[11:06:43.539] iteration 9613 : model1 loss : 0.439595 model2 loss : 0.027904
[11:06:43.708] iteration 9614 : model1 loss : 0.436089 model2 loss : 0.029556
[11:06:43.878] iteration 9615 : model1 loss : 0.435304 model2 loss : 0.024345
[11:06:44.047] iteration 9616 : model1 loss : 0.440399 model2 loss : 0.030007
[11:06:44.215] iteration 9617 : model1 loss : 0.439593 model2 loss : 0.028068
[11:06:44.385] iteration 9618 : model1 loss : 0.442327 model2 loss : 0.042013
[11:06:44.554] iteration 9619 : model1 loss : 0.437612 model2 loss : 0.027381
[11:06:44.721] iteration 9620 : model1 loss : 0.438197 model2 loss : 0.023447
[11:06:44.889] iteration 9621 : model1 loss : 0.439158 model2 loss : 0.027062
[11:06:45.056] iteration 9622 : model1 loss : 0.437182 model2 loss : 0.026526
[11:06:45.223] iteration 9623 : model1 loss : 0.434233 model2 loss : 0.025456
[11:06:45.394] iteration 9624 : model1 loss : 0.435662 model2 loss : 0.024294
[11:06:45.562] iteration 9625 : model1 loss : 0.434897 model2 loss : 0.028273
[11:06:45.731] iteration 9626 : model1 loss : 0.439522 model2 loss : 0.025522
[11:06:45.901] iteration 9627 : model1 loss : 0.436059 model2 loss : 0.026478
[11:06:46.070] iteration 9628 : model1 loss : 0.437284 model2 loss : 0.025517
[11:06:46.236] iteration 9629 : model1 loss : 0.438230 model2 loss : 0.028436
[11:06:46.410] iteration 9630 : model1 loss : 0.438985 model2 loss : 0.028986
[11:06:46.580] iteration 9631 : model1 loss : 0.433625 model2 loss : 0.029902
[11:06:46.748] iteration 9632 : model1 loss : 0.433635 model2 loss : 0.024804
[11:06:46.914] iteration 9633 : model1 loss : 0.439173 model2 loss : 0.027855
[11:06:47.084] iteration 9634 : model1 loss : 0.431397 model2 loss : 0.025031
[11:06:47.250] iteration 9635 : model1 loss : 0.437666 model2 loss : 0.030046
[11:06:47.420] iteration 9636 : model1 loss : 0.435556 model2 loss : 0.025675
[11:06:49.390] iteration 9637 : model1 loss : 0.435869 model2 loss : 0.027511
[11:06:49.562] iteration 9638 : model1 loss : 0.435723 model2 loss : 0.027606
[11:06:49.735] iteration 9639 : model1 loss : 0.440102 model2 loss : 0.030593
[11:06:49.901] iteration 9640 : model1 loss : 0.439462 model2 loss : 0.029100
[11:06:50.071] iteration 9641 : model1 loss : 0.438138 model2 loss : 0.025025
[11:06:50.238] iteration 9642 : model1 loss : 0.439960 model2 loss : 0.028002
[11:06:50.406] iteration 9643 : model1 loss : 0.433925 model2 loss : 0.025981
[11:06:50.574] iteration 9644 : model1 loss : 0.432144 model2 loss : 0.023246
[11:06:50.740] iteration 9645 : model1 loss : 0.440641 model2 loss : 0.026870
[11:06:50.912] iteration 9646 : model1 loss : 0.440544 model2 loss : 0.031301
[11:06:51.082] iteration 9647 : model1 loss : 0.441413 model2 loss : 0.027359
[11:06:51.248] iteration 9648 : model1 loss : 0.433160 model2 loss : 0.024842
[11:06:51.419] iteration 9649 : model1 loss : 0.434321 model2 loss : 0.026645
[11:06:51.585] iteration 9650 : model1 loss : 0.433255 model2 loss : 0.023518
[11:06:51.753] iteration 9651 : model1 loss : 0.437940 model2 loss : 0.023138
[11:06:51.920] iteration 9652 : model1 loss : 0.436949 model2 loss : 0.026762
[11:06:52.089] iteration 9653 : model1 loss : 0.437308 model2 loss : 0.025317
[11:06:52.257] iteration 9654 : model1 loss : 0.434173 model2 loss : 0.024691
[11:06:52.426] iteration 9655 : model1 loss : 0.436027 model2 loss : 0.028398
[11:06:52.595] iteration 9656 : model1 loss : 0.446610 model2 loss : 0.030760
[11:06:52.764] iteration 9657 : model1 loss : 0.438440 model2 loss : 0.025379
[11:06:52.931] iteration 9658 : model1 loss : 0.435826 model2 loss : 0.026571
[11:06:53.100] iteration 9659 : model1 loss : 0.433876 model2 loss : 0.027206
[11:06:53.266] iteration 9660 : model1 loss : 0.439678 model2 loss : 0.029651
[11:06:53.440] iteration 9661 : model1 loss : 0.440463 model2 loss : 0.025936
[11:06:53.606] iteration 9662 : model1 loss : 0.439687 model2 loss : 0.024605
[11:06:53.774] iteration 9663 : model1 loss : 0.438212 model2 loss : 0.027851
[11:06:53.942] iteration 9664 : model1 loss : 0.438817 model2 loss : 0.024467
[11:06:54.112] iteration 9665 : model1 loss : 0.438486 model2 loss : 0.026218
[11:06:54.278] iteration 9666 : model1 loss : 0.435181 model2 loss : 0.028113
[11:06:54.452] iteration 9667 : model1 loss : 0.437564 model2 loss : 0.025433
[11:06:54.618] iteration 9668 : model1 loss : 0.439551 model2 loss : 0.028185
[11:06:54.787] iteration 9669 : model1 loss : 0.441833 model2 loss : 0.028552
[11:06:56.732] iteration 9670 : model1 loss : 0.438534 model2 loss : 0.027396
[11:06:56.898] iteration 9671 : model1 loss : 0.440506 model2 loss : 0.030933
[11:06:57.078] iteration 9672 : model1 loss : 0.440398 model2 loss : 0.023532
[11:06:57.245] iteration 9673 : model1 loss : 0.435755 model2 loss : 0.023596
[11:06:57.415] iteration 9674 : model1 loss : 0.434151 model2 loss : 0.025410
[11:06:57.580] iteration 9675 : model1 loss : 0.434059 model2 loss : 0.024741
[11:06:57.750] iteration 9676 : model1 loss : 0.437696 model2 loss : 0.021801
[11:06:57.915] iteration 9677 : model1 loss : 0.434073 model2 loss : 0.022846
[11:06:58.088] iteration 9678 : model1 loss : 0.438075 model2 loss : 0.025636
[11:06:58.254] iteration 9679 : model1 loss : 0.437621 model2 loss : 0.030985
[11:06:58.425] iteration 9680 : model1 loss : 0.437158 model2 loss : 0.027779
[11:06:58.592] iteration 9681 : model1 loss : 0.438867 model2 loss : 0.033994
[11:06:58.761] iteration 9682 : model1 loss : 0.442741 model2 loss : 0.031126
[11:06:58.930] iteration 9683 : model1 loss : 0.432778 model2 loss : 0.026572
[11:06:59.104] iteration 9684 : model1 loss : 0.441548 model2 loss : 0.023707
[11:06:59.272] iteration 9685 : model1 loss : 0.434873 model2 loss : 0.025379
[11:06:59.441] iteration 9686 : model1 loss : 0.433575 model2 loss : 0.021158
[11:06:59.607] iteration 9687 : model1 loss : 0.442242 model2 loss : 0.029310
[11:06:59.776] iteration 9688 : model1 loss : 0.433854 model2 loss : 0.023474
[11:06:59.943] iteration 9689 : model1 loss : 0.436385 model2 loss : 0.036473
[11:07:00.114] iteration 9690 : model1 loss : 0.439458 model2 loss : 0.026968
[11:07:00.281] iteration 9691 : model1 loss : 0.434937 model2 loss : 0.024389
[11:07:00.451] iteration 9692 : model1 loss : 0.435610 model2 loss : 0.025566
[11:07:00.632] iteration 9693 : model1 loss : 0.438672 model2 loss : 0.025989
[11:07:00.803] iteration 9694 : model1 loss : 0.436407 model2 loss : 0.023254
[11:07:00.971] iteration 9695 : model1 loss : 0.437537 model2 loss : 0.027598
[11:07:01.140] iteration 9696 : model1 loss : 0.435772 model2 loss : 0.024921
[11:07:01.306] iteration 9697 : model1 loss : 0.437122 model2 loss : 0.028199
[11:07:01.478] iteration 9698 : model1 loss : 0.438598 model2 loss : 0.026373
[11:07:01.644] iteration 9699 : model1 loss : 0.444733 model2 loss : 0.033157
[11:07:01.814] iteration 9700 : model1 loss : 0.438533 model2 loss : 0.030660
[11:07:01.979] iteration 9701 : model1 loss : 0.438572 model2 loss : 0.025203
[11:07:02.147] iteration 9702 : model1 loss : 0.436912 model2 loss : 0.026409
[11:07:04.071] iteration 9703 : model1 loss : 0.440800 model2 loss : 0.025270
[11:07:04.242] iteration 9704 : model1 loss : 0.434134 model2 loss : 0.024880
[11:07:04.412] iteration 9705 : model1 loss : 0.437239 model2 loss : 0.027773
[11:07:04.580] iteration 9706 : model1 loss : 0.439459 model2 loss : 0.024610
[11:07:04.750] iteration 9707 : model1 loss : 0.442145 model2 loss : 0.027833
[11:07:04.916] iteration 9708 : model1 loss : 0.437949 model2 loss : 0.027482
[11:07:05.085] iteration 9709 : model1 loss : 0.438798 model2 loss : 0.027124
[11:07:05.253] iteration 9710 : model1 loss : 0.435094 model2 loss : 0.024058
[11:07:05.421] iteration 9711 : model1 loss : 0.438593 model2 loss : 0.027781
[11:07:05.588] iteration 9712 : model1 loss : 0.434977 model2 loss : 0.020554
[11:07:05.758] iteration 9713 : model1 loss : 0.436991 model2 loss : 0.025562
[11:07:05.927] iteration 9714 : model1 loss : 0.437072 model2 loss : 0.025574
[11:07:06.096] iteration 9715 : model1 loss : 0.436922 model2 loss : 0.026081
[11:07:06.263] iteration 9716 : model1 loss : 0.435770 model2 loss : 0.025547
[11:07:06.432] iteration 9717 : model1 loss : 0.434121 model2 loss : 0.024380
[11:07:06.602] iteration 9718 : model1 loss : 0.435731 model2 loss : 0.024964
[11:07:06.773] iteration 9719 : model1 loss : 0.439603 model2 loss : 0.029716
[11:07:06.943] iteration 9720 : model1 loss : 0.436892 model2 loss : 0.021876
[11:07:07.112] iteration 9721 : model1 loss : 0.442156 model2 loss : 0.032354
[11:07:07.280] iteration 9722 : model1 loss : 0.442610 model2 loss : 0.030027
[11:07:07.448] iteration 9723 : model1 loss : 0.438331 model2 loss : 0.032324
[11:07:07.615] iteration 9724 : model1 loss : 0.436486 model2 loss : 0.025108
[11:07:07.783] iteration 9725 : model1 loss : 0.436545 model2 loss : 0.024800
[11:07:07.951] iteration 9726 : model1 loss : 0.437543 model2 loss : 0.023007
[11:07:08.120] iteration 9727 : model1 loss : 0.438862 model2 loss : 0.027226
[11:07:08.287] iteration 9728 : model1 loss : 0.432095 model2 loss : 0.026058
[11:07:08.469] iteration 9729 : model1 loss : 0.437850 model2 loss : 0.026577
[11:07:08.635] iteration 9730 : model1 loss : 0.435997 model2 loss : 0.025600
[11:07:08.804] iteration 9731 : model1 loss : 0.434115 model2 loss : 0.025394
[11:07:08.971] iteration 9732 : model1 loss : 0.438800 model2 loss : 0.024493
[11:07:09.140] iteration 9733 : model1 loss : 0.440258 model2 loss : 0.027097
[11:07:09.308] iteration 9734 : model1 loss : 0.434794 model2 loss : 0.026901
[11:07:09.476] iteration 9735 : model1 loss : 0.436102 model2 loss : 0.025718
[11:07:11.424] iteration 9736 : model1 loss : 0.440139 model2 loss : 0.028189
[11:07:11.592] iteration 9737 : model1 loss : 0.436766 model2 loss : 0.026265
[11:07:11.761] iteration 9738 : model1 loss : 0.438552 model2 loss : 0.027363
[11:07:11.929] iteration 9739 : model1 loss : 0.440746 model2 loss : 0.026326
[11:07:12.096] iteration 9740 : model1 loss : 0.433782 model2 loss : 0.021081
[11:07:12.264] iteration 9741 : model1 loss : 0.431640 model2 loss : 0.026061
[11:07:12.433] iteration 9742 : model1 loss : 0.433378 model2 loss : 0.023155
[11:07:12.599] iteration 9743 : model1 loss : 0.436003 model2 loss : 0.026601
[11:07:12.769] iteration 9744 : model1 loss : 0.436705 model2 loss : 0.021552
[11:07:12.935] iteration 9745 : model1 loss : 0.436997 model2 loss : 0.026609
[11:07:13.105] iteration 9746 : model1 loss : 0.438829 model2 loss : 0.027740
[11:07:13.270] iteration 9747 : model1 loss : 0.435420 model2 loss : 0.025860
[11:07:13.440] iteration 9748 : model1 loss : 0.440423 model2 loss : 0.031233
[11:07:13.609] iteration 9749 : model1 loss : 0.439309 model2 loss : 0.028747
[11:07:13.777] iteration 9750 : model1 loss : 0.438227 model2 loss : 0.026396
[11:07:13.944] iteration 9751 : model1 loss : 0.437130 model2 loss : 0.026245
[11:07:14.114] iteration 9752 : model1 loss : 0.432602 model2 loss : 0.022102
[11:07:14.283] iteration 9753 : model1 loss : 0.439655 model2 loss : 0.024880
[11:07:14.451] iteration 9754 : model1 loss : 0.439806 model2 loss : 0.029429
[11:07:14.619] iteration 9755 : model1 loss : 0.440531 model2 loss : 0.029035
[11:07:14.790] iteration 9756 : model1 loss : 0.432477 model2 loss : 0.026112
[11:07:14.959] iteration 9757 : model1 loss : 0.436683 model2 loss : 0.026520
[11:07:15.126] iteration 9758 : model1 loss : 0.435484 model2 loss : 0.026337
[11:07:15.294] iteration 9759 : model1 loss : 0.436150 model2 loss : 0.025337
[11:07:15.463] iteration 9760 : model1 loss : 0.438711 model2 loss : 0.026649
[11:07:15.630] iteration 9761 : model1 loss : 0.436276 model2 loss : 0.026549
[11:07:15.797] iteration 9762 : model1 loss : 0.438834 model2 loss : 0.029125
[11:07:15.963] iteration 9763 : model1 loss : 0.438077 model2 loss : 0.024828
[11:07:16.131] iteration 9764 : model1 loss : 0.432620 model2 loss : 0.024267
[11:07:16.299] iteration 9765 : model1 loss : 0.438336 model2 loss : 0.026635
[11:07:16.468] iteration 9766 : model1 loss : 0.432892 model2 loss : 0.023247
[11:07:16.633] iteration 9767 : model1 loss : 0.440702 model2 loss : 0.030053
[11:07:16.801] iteration 9768 : model1 loss : 0.440573 model2 loss : 0.029401
[11:07:18.723] iteration 9769 : model1 loss : 0.436521 model2 loss : 0.022107
[11:07:18.889] iteration 9770 : model1 loss : 0.437546 model2 loss : 0.025359
[11:07:19.057] iteration 9771 : model1 loss : 0.433034 model2 loss : 0.023272
[11:07:19.222] iteration 9772 : model1 loss : 0.437276 model2 loss : 0.024002
[11:07:19.392] iteration 9773 : model1 loss : 0.439263 model2 loss : 0.027921
[11:07:19.562] iteration 9774 : model1 loss : 0.435588 model2 loss : 0.024784
[11:07:19.731] iteration 9775 : model1 loss : 0.436453 model2 loss : 0.027078
[11:07:19.898] iteration 9776 : model1 loss : 0.437080 model2 loss : 0.026678
[11:07:20.067] iteration 9777 : model1 loss : 0.437387 model2 loss : 0.024473
[11:07:20.235] iteration 9778 : model1 loss : 0.433446 model2 loss : 0.024582
[11:07:20.406] iteration 9779 : model1 loss : 0.440664 model2 loss : 0.029391
[11:07:20.575] iteration 9780 : model1 loss : 0.434890 model2 loss : 0.025273
[11:07:20.741] iteration 9781 : model1 loss : 0.432953 model2 loss : 0.024045
[11:07:20.910] iteration 9782 : model1 loss : 0.438905 model2 loss : 0.024041
[11:07:21.080] iteration 9783 : model1 loss : 0.438300 model2 loss : 0.024926
[11:07:21.248] iteration 9784 : model1 loss : 0.441544 model2 loss : 0.035713
[11:07:21.418] iteration 9785 : model1 loss : 0.440673 model2 loss : 0.026891
[11:07:21.590] iteration 9786 : model1 loss : 0.437752 model2 loss : 0.026448
[11:07:21.759] iteration 9787 : model1 loss : 0.436309 model2 loss : 0.025741
[11:07:21.928] iteration 9788 : model1 loss : 0.439173 model2 loss : 0.025874
[11:07:22.097] iteration 9789 : model1 loss : 0.440356 model2 loss : 0.025803
[11:07:22.265] iteration 9790 : model1 loss : 0.434732 model2 loss : 0.023613
[11:07:22.436] iteration 9791 : model1 loss : 0.437215 model2 loss : 0.026401
[11:07:22.606] iteration 9792 : model1 loss : 0.436930 model2 loss : 0.024964
[11:07:22.776] iteration 9793 : model1 loss : 0.436763 model2 loss : 0.025023
[11:07:22.944] iteration 9794 : model1 loss : 0.435346 model2 loss : 0.024070
[11:07:23.112] iteration 9795 : model1 loss : 0.437532 model2 loss : 0.026095
[11:07:23.278] iteration 9796 : model1 loss : 0.435821 model2 loss : 0.024407
[11:07:23.445] iteration 9797 : model1 loss : 0.435381 model2 loss : 0.028796
[11:07:23.613] iteration 9798 : model1 loss : 0.435629 model2 loss : 0.024530
[11:07:23.782] iteration 9799 : model1 loss : 0.437643 model2 loss : 0.026107
[11:07:23.949] iteration 9800 : model1 loss : 0.437114 model2 loss : 0.023409
[11:07:24.117] iteration 9801 : model1 loss : 0.437366 model2 loss : 0.028643
[11:07:26.086] iteration 9802 : model1 loss : 0.435289 model2 loss : 0.026296
[11:07:26.256] iteration 9803 : model1 loss : 0.440645 model2 loss : 0.027540
[11:07:26.426] iteration 9804 : model1 loss : 0.434804 model2 loss : 0.023470
[11:07:26.600] iteration 9805 : model1 loss : 0.438078 model2 loss : 0.024647
[11:07:26.768] iteration 9806 : model1 loss : 0.442355 model2 loss : 0.028700
[11:07:26.937] iteration 9807 : model1 loss : 0.435854 model2 loss : 0.027623
[11:07:27.107] iteration 9808 : model1 loss : 0.433477 model2 loss : 0.021846
[11:07:27.273] iteration 9809 : model1 loss : 0.431945 model2 loss : 0.023717
[11:07:27.442] iteration 9810 : model1 loss : 0.434123 model2 loss : 0.024739
[11:07:27.616] iteration 9811 : model1 loss : 0.437318 model2 loss : 0.024728
[11:07:27.787] iteration 9812 : model1 loss : 0.442137 model2 loss : 0.030138
[11:07:27.956] iteration 9813 : model1 loss : 0.435026 model2 loss : 0.024007
[11:07:28.126] iteration 9814 : model1 loss : 0.440024 model2 loss : 0.027699
[11:07:28.295] iteration 9815 : model1 loss : 0.438396 model2 loss : 0.026957
[11:07:28.464] iteration 9816 : model1 loss : 0.436261 model2 loss : 0.023327
[11:07:28.633] iteration 9817 : model1 loss : 0.440332 model2 loss : 0.027219
[11:07:28.802] iteration 9818 : model1 loss : 0.431649 model2 loss : 0.023520
[11:07:28.970] iteration 9819 : model1 loss : 0.439052 model2 loss : 0.027581
[11:07:29.139] iteration 9820 : model1 loss : 0.433943 model2 loss : 0.025157
[11:07:29.307] iteration 9821 : model1 loss : 0.435987 model2 loss : 0.024432
[11:07:29.478] iteration 9822 : model1 loss : 0.433549 model2 loss : 0.022849
[11:07:29.650] iteration 9823 : model1 loss : 0.436517 model2 loss : 0.026217
[11:07:29.818] iteration 9824 : model1 loss : 0.437978 model2 loss : 0.027092
[11:07:29.985] iteration 9825 : model1 loss : 0.439135 model2 loss : 0.025526
[11:07:30.156] iteration 9826 : model1 loss : 0.435668 model2 loss : 0.024884
[11:07:30.324] iteration 9827 : model1 loss : 0.437755 model2 loss : 0.023812
[11:07:30.496] iteration 9828 : model1 loss : 0.434622 model2 loss : 0.026156
[11:07:30.666] iteration 9829 : model1 loss : 0.436083 model2 loss : 0.024902
[11:07:30.838] iteration 9830 : model1 loss : 0.435676 model2 loss : 0.024359
[11:07:31.005] iteration 9831 : model1 loss : 0.440400 model2 loss : 0.029588
[11:07:31.174] iteration 9832 : model1 loss : 0.433017 model2 loss : 0.024928
[11:07:31.339] iteration 9833 : model1 loss : 0.439793 model2 loss : 0.024850
[11:07:31.509] iteration 9834 : model1 loss : 0.440780 model2 loss : 0.027993
[11:07:33.443] iteration 9835 : model1 loss : 0.437890 model2 loss : 0.023669
[11:07:33.616] iteration 9836 : model1 loss : 0.440651 model2 loss : 0.029453
[11:07:33.796] iteration 9837 : model1 loss : 0.436494 model2 loss : 0.026464
[11:07:33.966] iteration 9838 : model1 loss : 0.434610 model2 loss : 0.024294
[11:07:34.134] iteration 9839 : model1 loss : 0.434163 model2 loss : 0.023869
[11:07:34.304] iteration 9840 : model1 loss : 0.434897 model2 loss : 0.022303
[11:07:34.473] iteration 9841 : model1 loss : 0.437883 model2 loss : 0.027419
[11:07:34.642] iteration 9842 : model1 loss : 0.440211 model2 loss : 0.027580
[11:07:34.814] iteration 9843 : model1 loss : 0.438663 model2 loss : 0.025482
[11:07:34.981] iteration 9844 : model1 loss : 0.436425 model2 loss : 0.023963
[11:07:35.151] iteration 9845 : model1 loss : 0.437197 model2 loss : 0.026031
[11:07:35.318] iteration 9846 : model1 loss : 0.439749 model2 loss : 0.029276
[11:07:35.489] iteration 9847 : model1 loss : 0.435377 model2 loss : 0.023311
[11:07:35.660] iteration 9848 : model1 loss : 0.438993 model2 loss : 0.024385
[11:07:35.832] iteration 9849 : model1 loss : 0.434462 model2 loss : 0.024475
[11:07:35.997] iteration 9850 : model1 loss : 0.435795 model2 loss : 0.026232
[11:07:36.166] iteration 9851 : model1 loss : 0.436863 model2 loss : 0.024904
[11:07:36.332] iteration 9852 : model1 loss : 0.437943 model2 loss : 0.027009
[11:07:36.503] iteration 9853 : model1 loss : 0.438219 model2 loss : 0.022976
[11:07:36.672] iteration 9854 : model1 loss : 0.440452 model2 loss : 0.026276
[11:07:36.840] iteration 9855 : model1 loss : 0.436362 model2 loss : 0.027179
[11:07:37.009] iteration 9856 : model1 loss : 0.437860 model2 loss : 0.025133
[11:07:37.179] iteration 9857 : model1 loss : 0.439292 model2 loss : 0.029195
[11:07:37.350] iteration 9858 : model1 loss : 0.431938 model2 loss : 0.025636
[11:07:37.520] iteration 9859 : model1 loss : 0.442290 model2 loss : 0.032639
[11:07:37.687] iteration 9860 : model1 loss : 0.438565 model2 loss : 0.026763
[11:07:37.858] iteration 9861 : model1 loss : 0.439931 model2 loss : 0.026443
[11:07:38.026] iteration 9862 : model1 loss : 0.436833 model2 loss : 0.022960
[11:07:38.197] iteration 9863 : model1 loss : 0.436893 model2 loss : 0.027174
[11:07:38.366] iteration 9864 : model1 loss : 0.435153 model2 loss : 0.025454
[11:07:38.536] iteration 9865 : model1 loss : 0.436354 model2 loss : 0.027609
[11:07:38.702] iteration 9866 : model1 loss : 0.435776 model2 loss : 0.026299
[11:07:38.871] iteration 9867 : model1 loss : 0.436661 model2 loss : 0.025539
[11:07:40.771] iteration 9868 : model1 loss : 0.430830 model2 loss : 0.021719
[11:07:40.945] iteration 9869 : model1 loss : 0.434000 model2 loss : 0.026224
[11:07:41.115] iteration 9870 : model1 loss : 0.435042 model2 loss : 0.027172
[11:07:41.281] iteration 9871 : model1 loss : 0.437062 model2 loss : 0.028365
[11:07:41.449] iteration 9872 : model1 loss : 0.439093 model2 loss : 0.025596
[11:07:41.619] iteration 9873 : model1 loss : 0.442273 model2 loss : 0.029590
[11:07:41.790] iteration 9874 : model1 loss : 0.440203 model2 loss : 0.029555
[11:07:41.960] iteration 9875 : model1 loss : 0.432498 model2 loss : 0.023643
[11:07:42.133] iteration 9876 : model1 loss : 0.434864 model2 loss : 0.024046
[11:07:42.299] iteration 9877 : model1 loss : 0.432851 model2 loss : 0.023950
[11:07:42.469] iteration 9878 : model1 loss : 0.435904 model2 loss : 0.024438
[11:07:42.636] iteration 9879 : model1 loss : 0.439865 model2 loss : 0.028240
[11:07:42.806] iteration 9880 : model1 loss : 0.437781 model2 loss : 0.023569
[11:07:42.975] iteration 9881 : model1 loss : 0.436797 model2 loss : 0.023587
[11:07:43.145] iteration 9882 : model1 loss : 0.438050 model2 loss : 0.028271
[11:07:43.311] iteration 9883 : model1 loss : 0.438002 model2 loss : 0.026193
[11:07:43.482] iteration 9884 : model1 loss : 0.439844 model2 loss : 0.026979
[11:07:43.650] iteration 9885 : model1 loss : 0.438740 model2 loss : 0.027990
[11:07:43.819] iteration 9886 : model1 loss : 0.434605 model2 loss : 0.026072
[11:07:43.986] iteration 9887 : model1 loss : 0.441168 model2 loss : 0.028477
[11:07:44.157] iteration 9888 : model1 loss : 0.436713 model2 loss : 0.023460
[11:07:44.324] iteration 9889 : model1 loss : 0.440236 model2 loss : 0.026837
[11:07:44.492] iteration 9890 : model1 loss : 0.440731 model2 loss : 0.026083
[11:07:44.660] iteration 9891 : model1 loss : 0.443466 model2 loss : 0.029323
[11:07:44.830] iteration 9892 : model1 loss : 0.434996 model2 loss : 0.026591
[11:07:45.001] iteration 9893 : model1 loss : 0.432599 model2 loss : 0.022186
[11:07:45.170] iteration 9894 : model1 loss : 0.439471 model2 loss : 0.029475
[11:07:45.337] iteration 9895 : model1 loss : 0.438944 model2 loss : 0.026342
[11:07:45.507] iteration 9896 : model1 loss : 0.433101 model2 loss : 0.020838
[11:07:45.675] iteration 9897 : model1 loss : 0.434978 model2 loss : 0.027927
[11:07:45.847] iteration 9898 : model1 loss : 0.433992 model2 loss : 0.022805
[11:07:46.012] iteration 9899 : model1 loss : 0.441964 model2 loss : 0.029033
[11:07:46.179] iteration 9900 : model1 loss : 0.437523 model2 loss : 0.026008
[11:07:48.150] iteration 9901 : model1 loss : 0.433510 model2 loss : 0.022818
[11:07:48.321] iteration 9902 : model1 loss : 0.434050 model2 loss : 0.020784
[11:07:48.494] iteration 9903 : model1 loss : 0.436338 model2 loss : 0.023826
[11:07:48.662] iteration 9904 : model1 loss : 0.442795 model2 loss : 0.029930
[11:07:48.831] iteration 9905 : model1 loss : 0.439313 model2 loss : 0.027137
[11:07:48.998] iteration 9906 : model1 loss : 0.438727 model2 loss : 0.029668
[11:07:49.165] iteration 9907 : model1 loss : 0.435459 model2 loss : 0.027403
[11:07:49.333] iteration 9908 : model1 loss : 0.435722 model2 loss : 0.024551
[11:07:49.503] iteration 9909 : model1 loss : 0.432259 model2 loss : 0.022761
[11:07:49.673] iteration 9910 : model1 loss : 0.439447 model2 loss : 0.024282
[11:07:49.842] iteration 9911 : model1 loss : 0.438674 model2 loss : 0.025968
[11:07:50.008] iteration 9912 : model1 loss : 0.435090 model2 loss : 0.024037
[11:07:50.177] iteration 9913 : model1 loss : 0.438351 model2 loss : 0.024293
[11:07:50.344] iteration 9914 : model1 loss : 0.439234 model2 loss : 0.025841
[11:07:50.513] iteration 9915 : model1 loss : 0.436688 model2 loss : 0.022263
[11:07:50.679] iteration 9916 : model1 loss : 0.438818 model2 loss : 0.027915
[11:07:50.851] iteration 9917 : model1 loss : 0.441002 model2 loss : 0.022694
[11:07:51.018] iteration 9918 : model1 loss : 0.435246 model2 loss : 0.026118
[11:07:51.185] iteration 9919 : model1 loss : 0.435936 model2 loss : 0.025929
[11:07:51.351] iteration 9920 : model1 loss : 0.436364 model2 loss : 0.025285
[11:07:51.527] iteration 9921 : model1 loss : 0.434485 model2 loss : 0.025902
[11:07:51.695] iteration 9922 : model1 loss : 0.436022 model2 loss : 0.024697
[11:07:51.866] iteration 9923 : model1 loss : 0.435279 model2 loss : 0.025729
[11:07:52.032] iteration 9924 : model1 loss : 0.438329 model2 loss : 0.028409
[11:07:52.201] iteration 9925 : model1 loss : 0.436653 model2 loss : 0.025045
[11:07:52.368] iteration 9926 : model1 loss : 0.437795 model2 loss : 0.028686
[11:07:52.538] iteration 9927 : model1 loss : 0.435747 model2 loss : 0.026835
[11:07:52.704] iteration 9928 : model1 loss : 0.438624 model2 loss : 0.025694
[11:07:52.875] iteration 9929 : model1 loss : 0.435125 model2 loss : 0.025572
[11:07:53.043] iteration 9930 : model1 loss : 0.435821 model2 loss : 0.024017
[11:07:53.214] iteration 9931 : model1 loss : 0.437117 model2 loss : 0.026404
[11:07:53.381] iteration 9932 : model1 loss : 0.436736 model2 loss : 0.029158
[11:07:53.550] iteration 9933 : model1 loss : 0.439054 model2 loss : 0.026745
[11:07:55.476] iteration 9934 : model1 loss : 0.435619 model2 loss : 0.027083
[11:07:55.644] iteration 9935 : model1 loss : 0.436347 model2 loss : 0.026021
[11:07:55.816] iteration 9936 : model1 loss : 0.434473 model2 loss : 0.024783
[11:07:55.982] iteration 9937 : model1 loss : 0.441668 model2 loss : 0.028541
[11:07:56.150] iteration 9938 : model1 loss : 0.436760 model2 loss : 0.024253
[11:07:56.317] iteration 9939 : model1 loss : 0.435268 model2 loss : 0.022962
[11:07:56.485] iteration 9940 : model1 loss : 0.438154 model2 loss : 0.024541
[11:07:56.654] iteration 9941 : model1 loss : 0.437893 model2 loss : 0.026559
[11:07:56.822] iteration 9942 : model1 loss : 0.440162 model2 loss : 0.030224
[11:07:56.991] iteration 9943 : model1 loss : 0.434404 model2 loss : 0.023299
[11:07:57.161] iteration 9944 : model1 loss : 0.435384 model2 loss : 0.027132
[11:07:57.328] iteration 9945 : model1 loss : 0.438512 model2 loss : 0.029339
[11:07:57.501] iteration 9946 : model1 loss : 0.441321 model2 loss : 0.030719
[11:07:57.670] iteration 9947 : model1 loss : 0.441933 model2 loss : 0.037194
[11:07:57.840] iteration 9948 : model1 loss : 0.440274 model2 loss : 0.028601
[11:07:58.009] iteration 9949 : model1 loss : 0.436529 model2 loss : 0.025476
[11:07:58.176] iteration 9950 : model1 loss : 0.438764 model2 loss : 0.026524
[11:07:58.343] iteration 9951 : model1 loss : 0.439239 model2 loss : 0.027017
[11:07:58.514] iteration 9952 : model1 loss : 0.440197 model2 loss : 0.027604
[11:07:58.684] iteration 9953 : model1 loss : 0.435670 model2 loss : 0.022508
[11:07:58.855] iteration 9954 : model1 loss : 0.439055 model2 loss : 0.026396
[11:07:59.023] iteration 9955 : model1 loss : 0.435694 model2 loss : 0.023953
[11:07:59.202] iteration 9956 : model1 loss : 0.433487 model2 loss : 0.026242
[11:07:59.368] iteration 9957 : model1 loss : 0.435629 model2 loss : 0.026046
[11:07:59.548] iteration 9958 : model1 loss : 0.438788 model2 loss : 0.027679
[11:07:59.716] iteration 9959 : model1 loss : 0.441677 model2 loss : 0.028791
[11:07:59.886] iteration 9960 : model1 loss : 0.434050 model2 loss : 0.027576
[11:08:00.055] iteration 9961 : model1 loss : 0.433153 model2 loss : 0.023564
[11:08:00.223] iteration 9962 : model1 loss : 0.439202 model2 loss : 0.030424
[11:08:00.390] iteration 9963 : model1 loss : 0.434917 model2 loss : 0.023938
[11:08:00.562] iteration 9964 : model1 loss : 0.442097 model2 loss : 0.029320
[11:08:00.729] iteration 9965 : model1 loss : 0.434979 model2 loss : 0.022159
[11:08:00.899] iteration 9966 : model1 loss : 0.433896 model2 loss : 0.026960
[11:08:02.799] iteration 9967 : model1 loss : 0.438024 model2 loss : 0.026537
[11:08:02.970] iteration 9968 : model1 loss : 0.439176 model2 loss : 0.026094
[11:08:03.143] iteration 9969 : model1 loss : 0.437442 model2 loss : 0.021991
[11:08:03.310] iteration 9970 : model1 loss : 0.436764 model2 loss : 0.026829
[11:08:03.479] iteration 9971 : model1 loss : 0.439739 model2 loss : 0.029665
[11:08:03.647] iteration 9972 : model1 loss : 0.440583 model2 loss : 0.030050
[11:08:03.815] iteration 9973 : model1 loss : 0.440163 model2 loss : 0.028791
[11:08:03.982] iteration 9974 : model1 loss : 0.438258 model2 loss : 0.026719
[11:08:04.150] iteration 9975 : model1 loss : 0.435145 model2 loss : 0.026137
[11:08:04.319] iteration 9976 : model1 loss : 0.438460 model2 loss : 0.030322
[11:08:04.490] iteration 9977 : model1 loss : 0.435331 model2 loss : 0.027460
[11:08:04.657] iteration 9978 : model1 loss : 0.435727 model2 loss : 0.021529
[11:08:04.825] iteration 9979 : model1 loss : 0.436708 model2 loss : 0.023432
[11:08:04.993] iteration 9980 : model1 loss : 0.435582 model2 loss : 0.024200
[11:08:05.161] iteration 9981 : model1 loss : 0.438545 model2 loss : 0.027144
[11:08:05.328] iteration 9982 : model1 loss : 0.435594 model2 loss : 0.028447
[11:08:05.502] iteration 9983 : model1 loss : 0.440557 model2 loss : 0.027596
[11:08:05.667] iteration 9984 : model1 loss : 0.438878 model2 loss : 0.028328
[11:08:05.839] iteration 9985 : model1 loss : 0.436595 model2 loss : 0.029112
[11:08:06.006] iteration 9986 : model1 loss : 0.435799 model2 loss : 0.027395
[11:08:06.175] iteration 9987 : model1 loss : 0.436706 model2 loss : 0.024834
[11:08:06.341] iteration 9988 : model1 loss : 0.437274 model2 loss : 0.029187
[11:08:06.515] iteration 9989 : model1 loss : 0.436155 model2 loss : 0.026849
[11:08:06.683] iteration 9990 : model1 loss : 0.439307 model2 loss : 0.049610
[11:08:06.850] iteration 9991 : model1 loss : 0.440251 model2 loss : 0.025870
[11:08:07.020] iteration 9992 : model1 loss : 0.432046 model2 loss : 0.024979
[11:08:07.188] iteration 9993 : model1 loss : 0.435903 model2 loss : 0.024498
[11:08:07.355] iteration 9994 : model1 loss : 0.434167 model2 loss : 0.025480
[11:08:07.525] iteration 9995 : model1 loss : 0.440973 model2 loss : 0.031040
[11:08:07.696] iteration 9996 : model1 loss : 0.440220 model2 loss : 0.033475
[11:08:07.865] iteration 9997 : model1 loss : 0.436307 model2 loss : 0.026164
[11:08:08.031] iteration 9998 : model1 loss : 0.433174 model2 loss : 0.022642
[11:08:08.199] iteration 9999 : model1 loss : 0.437175 model2 loss : 0.026514
[11:08:10.140] iteration 10000 : model1 loss : 0.440801 model2 loss : 0.034080
[11:08:18.414] iteration 10000 : model1_mean_dice : 0.882846 model1_mean_hd95 : 3.839822
[11:08:26.669] iteration 10000 : model2_mean_dice : 0.885964 model2_mean_hd95 : 2.223725
[11:08:26.846] iteration 10001 : model1 loss : 0.443123 model2 loss : 0.032547
[11:08:27.015] iteration 10002 : model1 loss : 0.438850 model2 loss : 0.027418
[11:08:27.181] iteration 10003 : model1 loss : 0.436083 model2 loss : 0.027797
[11:08:27.348] iteration 10004 : model1 loss : 0.434196 model2 loss : 0.024020
[11:08:27.516] iteration 10005 : model1 loss : 0.435816 model2 loss : 0.025169
[11:08:27.686] iteration 10006 : model1 loss : 0.438890 model2 loss : 0.029066
[11:08:27.854] iteration 10007 : model1 loss : 0.431888 model2 loss : 0.023506
[11:08:28.022] iteration 10008 : model1 loss : 0.439392 model2 loss : 0.027389
[11:08:28.187] iteration 10009 : model1 loss : 0.431462 model2 loss : 0.025257
[11:08:28.357] iteration 10010 : model1 loss : 0.439399 model2 loss : 0.026567
[11:08:28.526] iteration 10011 : model1 loss : 0.437944 model2 loss : 0.027282
[11:08:28.694] iteration 10012 : model1 loss : 0.438890 model2 loss : 0.027947
[11:08:28.859] iteration 10013 : model1 loss : 0.437791 model2 loss : 0.024717
[11:08:29.028] iteration 10014 : model1 loss : 0.440944 model2 loss : 0.025093
[11:08:29.197] iteration 10015 : model1 loss : 0.438684 model2 loss : 0.032455
[11:08:29.365] iteration 10016 : model1 loss : 0.435532 model2 loss : 0.026455
[11:08:29.535] iteration 10017 : model1 loss : 0.436583 model2 loss : 0.022855
[11:08:29.703] iteration 10018 : model1 loss : 0.433992 model2 loss : 0.024414
[11:08:29.868] iteration 10019 : model1 loss : 0.436508 model2 loss : 0.027284
[11:08:30.038] iteration 10020 : model1 loss : 0.435428 model2 loss : 0.024706
[11:08:30.205] iteration 10021 : model1 loss : 0.434584 model2 loss : 0.027028
[11:08:30.373] iteration 10022 : model1 loss : 0.433748 model2 loss : 0.022177
[11:08:30.540] iteration 10023 : model1 loss : 0.442397 model2 loss : 0.028650
[11:08:30.709] iteration 10024 : model1 loss : 0.437459 model2 loss : 0.028567
[11:08:30.877] iteration 10025 : model1 loss : 0.441152 model2 loss : 0.030722
[11:08:31.046] iteration 10026 : model1 loss : 0.434322 model2 loss : 0.028652
[11:08:31.211] iteration 10027 : model1 loss : 0.435799 model2 loss : 0.025096
[11:08:31.381] iteration 10028 : model1 loss : 0.435059 model2 loss : 0.026282
[11:08:31.547] iteration 10029 : model1 loss : 0.442058 model2 loss : 0.029125
[11:08:31.715] iteration 10030 : model1 loss : 0.432703 model2 loss : 0.024065
[11:08:31.880] iteration 10031 : model1 loss : 0.439188 model2 loss : 0.029267
[11:08:32.049] iteration 10032 : model1 loss : 0.437616 model2 loss : 0.025289
[11:08:33.998] iteration 10033 : model1 loss : 0.434789 model2 loss : 0.024453
[11:08:34.169] iteration 10034 : model1 loss : 0.436191 model2 loss : 0.029337
[11:08:34.340] iteration 10035 : model1 loss : 0.440271 model2 loss : 0.030615
[11:08:34.508] iteration 10036 : model1 loss : 0.441422 model2 loss : 0.029799
[11:08:34.676] iteration 10037 : model1 loss : 0.438182 model2 loss : 0.023641
[11:08:34.845] iteration 10038 : model1 loss : 0.434914 model2 loss : 0.023856
[11:08:35.015] iteration 10039 : model1 loss : 0.438838 model2 loss : 0.028506
[11:08:35.180] iteration 10040 : model1 loss : 0.435473 model2 loss : 0.024513
[11:08:35.349] iteration 10041 : model1 loss : 0.439409 model2 loss : 0.031224
[11:08:35.516] iteration 10042 : model1 loss : 0.439716 model2 loss : 0.028537
[11:08:35.684] iteration 10043 : model1 loss : 0.437672 model2 loss : 0.023087
[11:08:35.853] iteration 10044 : model1 loss : 0.439130 model2 loss : 0.028939
[11:08:36.030] iteration 10045 : model1 loss : 0.433631 model2 loss : 0.023804
[11:08:36.198] iteration 10046 : model1 loss : 0.435880 model2 loss : 0.024813
[11:08:36.368] iteration 10047 : model1 loss : 0.441127 model2 loss : 0.029638
[11:08:36.538] iteration 10048 : model1 loss : 0.431911 model2 loss : 0.021321
[11:08:36.706] iteration 10049 : model1 loss : 0.443632 model2 loss : 0.032686
[11:08:36.875] iteration 10050 : model1 loss : 0.438110 model2 loss : 0.024870
[11:08:37.044] iteration 10051 : model1 loss : 0.435857 model2 loss : 0.024384
[11:08:37.210] iteration 10052 : model1 loss : 0.439361 model2 loss : 0.027482
[11:08:37.380] iteration 10053 : model1 loss : 0.434356 model2 loss : 0.026403
[11:08:37.547] iteration 10054 : model1 loss : 0.435751 model2 loss : 0.026277
[11:08:37.715] iteration 10055 : model1 loss : 0.437393 model2 loss : 0.029144
[11:08:37.883] iteration 10056 : model1 loss : 0.433920 model2 loss : 0.025728
[11:08:38.051] iteration 10057 : model1 loss : 0.437832 model2 loss : 0.023822
[11:08:38.220] iteration 10058 : model1 loss : 0.436415 model2 loss : 0.026620
[11:08:38.388] iteration 10059 : model1 loss : 0.437539 model2 loss : 0.027353
[11:08:38.554] iteration 10060 : model1 loss : 0.439478 model2 loss : 0.030706
[11:08:38.723] iteration 10061 : model1 loss : 0.437320 model2 loss : 0.025777
[11:08:38.890] iteration 10062 : model1 loss : 0.435808 model2 loss : 0.034388
[11:08:39.059] iteration 10063 : model1 loss : 0.436068 model2 loss : 0.024706
[11:08:39.225] iteration 10064 : model1 loss : 0.431954 model2 loss : 0.023906
[11:08:39.393] iteration 10065 : model1 loss : 0.441177 model2 loss : 0.026809
[11:08:41.372] iteration 10066 : model1 loss : 0.435610 model2 loss : 0.024222
[11:08:41.537] iteration 10067 : model1 loss : 0.439154 model2 loss : 0.023838
[11:08:41.706] iteration 10068 : model1 loss : 0.436123 model2 loss : 0.023158
[11:08:41.874] iteration 10069 : model1 loss : 0.439611 model2 loss : 0.027287
[11:08:42.042] iteration 10070 : model1 loss : 0.437198 model2 loss : 0.024211
[11:08:42.210] iteration 10071 : model1 loss : 0.436232 model2 loss : 0.029841
[11:08:42.402] iteration 10072 : model1 loss : 0.436074 model2 loss : 0.026315
[11:08:42.570] iteration 10073 : model1 loss : 0.439953 model2 loss : 0.026553
[11:08:42.738] iteration 10074 : model1 loss : 0.441130 model2 loss : 0.027783
[11:08:42.905] iteration 10075 : model1 loss : 0.435969 model2 loss : 0.027579
[11:08:43.074] iteration 10076 : model1 loss : 0.438467 model2 loss : 0.028664
[11:08:43.242] iteration 10077 : model1 loss : 0.435777 model2 loss : 0.027024
[11:08:43.411] iteration 10078 : model1 loss : 0.439855 model2 loss : 0.025398
[11:08:43.576] iteration 10079 : model1 loss : 0.439295 model2 loss : 0.027890
[11:08:43.745] iteration 10080 : model1 loss : 0.437919 model2 loss : 0.028697
[11:08:43.914] iteration 10081 : model1 loss : 0.435136 model2 loss : 0.025450
[11:08:44.083] iteration 10082 : model1 loss : 0.435828 model2 loss : 0.035011
[11:08:44.250] iteration 10083 : model1 loss : 0.440170 model2 loss : 0.027364
[11:08:44.419] iteration 10084 : model1 loss : 0.439079 model2 loss : 0.027884
[11:08:44.585] iteration 10085 : model1 loss : 0.434616 model2 loss : 0.024038
[11:08:44.754] iteration 10086 : model1 loss : 0.436187 model2 loss : 0.026538
[11:08:44.919] iteration 10087 : model1 loss : 0.437086 model2 loss : 0.029775
[11:08:45.087] iteration 10088 : model1 loss : 0.428180 model2 loss : 0.026999
[11:08:45.253] iteration 10089 : model1 loss : 0.432595 model2 loss : 0.024259
[11:08:45.420] iteration 10090 : model1 loss : 0.437744 model2 loss : 0.029949
[11:08:45.588] iteration 10091 : model1 loss : 0.434849 model2 loss : 0.027733
[11:08:45.756] iteration 10092 : model1 loss : 0.435208 model2 loss : 0.026093
[11:08:45.922] iteration 10093 : model1 loss : 0.435085 model2 loss : 0.024754
[11:08:46.091] iteration 10094 : model1 loss : 0.438214 model2 loss : 0.039682
[11:08:46.258] iteration 10095 : model1 loss : 0.432450 model2 loss : 0.020219
[11:08:46.426] iteration 10096 : model1 loss : 0.439864 model2 loss : 0.027030
[11:08:46.590] iteration 10097 : model1 loss : 0.441152 model2 loss : 0.028219
[11:08:46.757] iteration 10098 : model1 loss : 0.442822 model2 loss : 0.037213
[11:08:48.685] iteration 10099 : model1 loss : 0.440650 model2 loss : 0.031215
[11:08:48.855] iteration 10100 : model1 loss : 0.437363 model2 loss : 0.037079
[11:08:49.027] iteration 10101 : model1 loss : 0.435200 model2 loss : 0.025569
[11:08:49.194] iteration 10102 : model1 loss : 0.436304 model2 loss : 0.027954
[11:08:49.361] iteration 10103 : model1 loss : 0.435407 model2 loss : 0.024291
[11:08:49.530] iteration 10104 : model1 loss : 0.436666 model2 loss : 0.030137
[11:08:49.697] iteration 10105 : model1 loss : 0.439722 model2 loss : 0.033891
[11:08:49.865] iteration 10106 : model1 loss : 0.437532 model2 loss : 0.029676
[11:08:50.034] iteration 10107 : model1 loss : 0.435434 model2 loss : 0.024574
[11:08:50.199] iteration 10108 : model1 loss : 0.436172 model2 loss : 0.028240
[11:08:50.367] iteration 10109 : model1 loss : 0.438768 model2 loss : 0.035610
[11:08:50.536] iteration 10110 : model1 loss : 0.436829 model2 loss : 0.028621
[11:08:50.704] iteration 10111 : model1 loss : 0.438272 model2 loss : 0.025989
[11:08:50.873] iteration 10112 : model1 loss : 0.437141 model2 loss : 0.024895
[11:08:51.040] iteration 10113 : model1 loss : 0.432401 model2 loss : 0.028864
[11:08:51.206] iteration 10114 : model1 loss : 0.438469 model2 loss : 0.028062
[11:08:51.375] iteration 10115 : model1 loss : 0.434237 model2 loss : 0.026972
[11:08:51.543] iteration 10116 : model1 loss : 0.437421 model2 loss : 0.028046
[11:08:51.712] iteration 10117 : model1 loss : 0.436283 model2 loss : 0.026231
[11:08:51.878] iteration 10118 : model1 loss : 0.437877 model2 loss : 0.025769
[11:08:52.050] iteration 10119 : model1 loss : 0.440992 model2 loss : 0.030982
[11:08:52.215] iteration 10120 : model1 loss : 0.435925 model2 loss : 0.032900
[11:08:52.385] iteration 10121 : model1 loss : 0.438413 model2 loss : 0.027399
[11:08:52.554] iteration 10122 : model1 loss : 0.437507 model2 loss : 0.028904
[11:08:52.722] iteration 10123 : model1 loss : 0.440374 model2 loss : 0.025047
[11:08:52.888] iteration 10124 : model1 loss : 0.434679 model2 loss : 0.028933
[11:08:53.056] iteration 10125 : model1 loss : 0.435017 model2 loss : 0.027786
[11:08:53.223] iteration 10126 : model1 loss : 0.440669 model2 loss : 0.030131
[11:08:53.391] iteration 10127 : model1 loss : 0.432372 model2 loss : 0.025464
[11:08:53.559] iteration 10128 : model1 loss : 0.439750 model2 loss : 0.028131
[11:08:53.727] iteration 10129 : model1 loss : 0.433169 model2 loss : 0.024622
[11:08:53.892] iteration 10130 : model1 loss : 0.437997 model2 loss : 0.027650
[11:08:54.059] iteration 10131 : model1 loss : 0.446259 model2 loss : 0.032211
[11:08:56.049] iteration 10132 : model1 loss : 0.436099 model2 loss : 0.030742
[11:08:56.217] iteration 10133 : model1 loss : 0.432489 model2 loss : 0.027012
[11:08:56.389] iteration 10134 : model1 loss : 0.436323 model2 loss : 0.023536
[11:08:56.556] iteration 10135 : model1 loss : 0.437540 model2 loss : 0.027750
[11:08:56.724] iteration 10136 : model1 loss : 0.438480 model2 loss : 0.034108
[11:08:56.893] iteration 10137 : model1 loss : 0.433446 model2 loss : 0.026749
[11:08:57.063] iteration 10138 : model1 loss : 0.431743 model2 loss : 0.025544
[11:08:57.253] iteration 10139 : model1 loss : 0.440893 model2 loss : 0.028811
[11:08:57.421] iteration 10140 : model1 loss : 0.437147 model2 loss : 0.027822
[11:08:57.590] iteration 10141 : model1 loss : 0.438721 model2 loss : 0.029620
[11:08:57.757] iteration 10142 : model1 loss : 0.435364 model2 loss : 0.022363
[11:08:57.925] iteration 10143 : model1 loss : 0.432898 model2 loss : 0.030302
[11:08:58.094] iteration 10144 : model1 loss : 0.434616 model2 loss : 0.027213
[11:08:58.262] iteration 10145 : model1 loss : 0.438709 model2 loss : 0.033069
[11:08:58.432] iteration 10146 : model1 loss : 0.441084 model2 loss : 0.029008
[11:08:58.602] iteration 10147 : model1 loss : 0.436802 model2 loss : 0.026877
[11:08:58.769] iteration 10148 : model1 loss : 0.441022 model2 loss : 0.024662
[11:08:58.937] iteration 10149 : model1 loss : 0.437643 model2 loss : 0.026731
[11:08:59.108] iteration 10150 : model1 loss : 0.435562 model2 loss : 0.023961
[11:08:59.275] iteration 10151 : model1 loss : 0.436928 model2 loss : 0.026445
[11:08:59.444] iteration 10152 : model1 loss : 0.431713 model2 loss : 0.021335
[11:08:59.612] iteration 10153 : model1 loss : 0.432995 model2 loss : 0.023327
[11:08:59.783] iteration 10154 : model1 loss : 0.437135 model2 loss : 0.025253
[11:08:59.950] iteration 10155 : model1 loss : 0.438163 model2 loss : 0.021963
[11:09:00.123] iteration 10156 : model1 loss : 0.438174 model2 loss : 0.028745
[11:09:00.291] iteration 10157 : model1 loss : 0.439732 model2 loss : 0.026991
[11:09:00.461] iteration 10158 : model1 loss : 0.435128 model2 loss : 0.027211
[11:09:00.629] iteration 10159 : model1 loss : 0.439551 model2 loss : 0.029536
[11:09:00.799] iteration 10160 : model1 loss : 0.442515 model2 loss : 0.026131
[11:09:00.966] iteration 10161 : model1 loss : 0.440975 model2 loss : 0.031289
[11:09:01.134] iteration 10162 : model1 loss : 0.434769 model2 loss : 0.023972
[11:09:01.302] iteration 10163 : model1 loss : 0.434336 model2 loss : 0.026440
[11:09:01.483] iteration 10164 : model1 loss : 0.435443 model2 loss : 0.025472
[11:09:03.392] iteration 10165 : model1 loss : 0.436196 model2 loss : 0.024177
[11:09:03.561] iteration 10166 : model1 loss : 0.438766 model2 loss : 0.024391
[11:09:03.732] iteration 10167 : model1 loss : 0.440705 model2 loss : 0.028963
[11:09:03.899] iteration 10168 : model1 loss : 0.435401 model2 loss : 0.024919
[11:09:04.067] iteration 10169 : model1 loss : 0.437138 model2 loss : 0.024326
[11:09:04.236] iteration 10170 : model1 loss : 0.434618 model2 loss : 0.025296
[11:09:04.409] iteration 10171 : model1 loss : 0.437110 model2 loss : 0.026566
[11:09:04.577] iteration 10172 : model1 loss : 0.438049 model2 loss : 0.028176
[11:09:04.746] iteration 10173 : model1 loss : 0.435871 model2 loss : 0.025672
[11:09:04.914] iteration 10174 : model1 loss : 0.432613 model2 loss : 0.025444
[11:09:05.082] iteration 10175 : model1 loss : 0.431850 model2 loss : 0.025733
[11:09:05.250] iteration 10176 : model1 loss : 0.440749 model2 loss : 0.038184
[11:09:05.420] iteration 10177 : model1 loss : 0.435869 model2 loss : 0.022665
[11:09:05.589] iteration 10178 : model1 loss : 0.436391 model2 loss : 0.029426
[11:09:05.759] iteration 10179 : model1 loss : 0.428398 model2 loss : 0.024160
[11:09:05.927] iteration 10180 : model1 loss : 0.435574 model2 loss : 0.028197
[11:09:06.095] iteration 10181 : model1 loss : 0.437989 model2 loss : 0.029332
[11:09:06.263] iteration 10182 : model1 loss : 0.440518 model2 loss : 0.043493
[11:09:06.431] iteration 10183 : model1 loss : 0.440645 model2 loss : 0.031339
[11:09:06.597] iteration 10184 : model1 loss : 0.435352 model2 loss : 0.025641
[11:09:06.769] iteration 10185 : model1 loss : 0.437861 model2 loss : 0.037673
[11:09:06.936] iteration 10186 : model1 loss : 0.439402 model2 loss : 0.029106
[11:09:07.103] iteration 10187 : model1 loss : 0.439054 model2 loss : 0.033095
[11:09:07.271] iteration 10188 : model1 loss : 0.435478 model2 loss : 0.023416
[11:09:07.446] iteration 10189 : model1 loss : 0.436032 model2 loss : 0.027410
[11:09:07.615] iteration 10190 : model1 loss : 0.436460 model2 loss : 0.026736
[11:09:07.786] iteration 10191 : model1 loss : 0.436537 model2 loss : 0.025852
[11:09:07.953] iteration 10192 : model1 loss : 0.434590 model2 loss : 0.025290
[11:09:08.123] iteration 10193 : model1 loss : 0.440032 model2 loss : 0.024071
[11:09:08.292] iteration 10194 : model1 loss : 0.440549 model2 loss : 0.025340
[11:09:08.463] iteration 10195 : model1 loss : 0.436444 model2 loss : 0.027159
[11:09:08.629] iteration 10196 : model1 loss : 0.439618 model2 loss : 0.033685
[11:09:08.798] iteration 10197 : model1 loss : 0.439014 model2 loss : 0.029453
[11:09:10.709] iteration 10198 : model1 loss : 0.437230 model2 loss : 0.025267
[11:09:10.879] iteration 10199 : model1 loss : 0.438293 model2 loss : 0.025424
[11:09:11.048] iteration 10200 : model1 loss : 0.437374 model2 loss : 0.027788
[11:09:11.215] iteration 10201 : model1 loss : 0.428485 model2 loss : 0.022730
[11:09:11.384] iteration 10202 : model1 loss : 0.439230 model2 loss : 0.030716
[11:09:11.551] iteration 10203 : model1 loss : 0.442278 model2 loss : 0.030121
[11:09:11.721] iteration 10204 : model1 loss : 0.435643 model2 loss : 0.028511
[11:09:11.888] iteration 10205 : model1 loss : 0.436375 model2 loss : 0.030390
[11:09:12.057] iteration 10206 : model1 loss : 0.440439 model2 loss : 0.027310
[11:09:12.225] iteration 10207 : model1 loss : 0.437433 model2 loss : 0.026915
[11:09:12.401] iteration 10208 : model1 loss : 0.435244 model2 loss : 0.030935
[11:09:12.570] iteration 10209 : model1 loss : 0.434736 model2 loss : 0.027998
[11:09:12.738] iteration 10210 : model1 loss : 0.438350 model2 loss : 0.026414
[11:09:12.909] iteration 10211 : model1 loss : 0.432930 model2 loss : 0.022603
[11:09:13.077] iteration 10212 : model1 loss : 0.438012 model2 loss : 0.027254
[11:09:13.245] iteration 10213 : model1 loss : 0.435089 model2 loss : 0.025277
[11:09:13.414] iteration 10214 : model1 loss : 0.438428 model2 loss : 0.028568
[11:09:13.580] iteration 10215 : model1 loss : 0.440855 model2 loss : 0.030117
[11:09:13.750] iteration 10216 : model1 loss : 0.439469 model2 loss : 0.031998
[11:09:13.919] iteration 10217 : model1 loss : 0.434239 model2 loss : 0.021489
[11:09:14.089] iteration 10218 : model1 loss : 0.435978 model2 loss : 0.026413
[11:09:14.256] iteration 10219 : model1 loss : 0.433131 model2 loss : 0.028293
[11:09:14.425] iteration 10220 : model1 loss : 0.436208 model2 loss : 0.025833
[11:09:14.592] iteration 10221 : model1 loss : 0.442287 model2 loss : 0.031235
[11:09:14.761] iteration 10222 : model1 loss : 0.433343 model2 loss : 0.023866
[11:09:14.930] iteration 10223 : model1 loss : 0.437043 model2 loss : 0.026084
[11:09:15.099] iteration 10224 : model1 loss : 0.437939 model2 loss : 0.027953
[11:09:15.267] iteration 10225 : model1 loss : 0.436326 model2 loss : 0.024542
[11:09:15.435] iteration 10226 : model1 loss : 0.439258 model2 loss : 0.029008
[11:09:15.601] iteration 10227 : model1 loss : 0.438777 model2 loss : 0.026538
[11:09:15.772] iteration 10228 : model1 loss : 0.440077 model2 loss : 0.024698
[11:09:15.939] iteration 10229 : model1 loss : 0.439135 model2 loss : 0.024351
[11:09:16.108] iteration 10230 : model1 loss : 0.434034 model2 loss : 0.024363
[11:09:18.021] iteration 10231 : model1 loss : 0.438120 model2 loss : 0.027545
[11:09:18.192] iteration 10232 : model1 loss : 0.437956 model2 loss : 0.030007
[11:09:18.361] iteration 10233 : model1 loss : 0.435066 model2 loss : 0.028358
[11:09:18.532] iteration 10234 : model1 loss : 0.441555 model2 loss : 0.027739
[11:09:18.700] iteration 10235 : model1 loss : 0.434442 model2 loss : 0.026214
[11:09:18.866] iteration 10236 : model1 loss : 0.435696 model2 loss : 0.024675
[11:09:19.035] iteration 10237 : model1 loss : 0.438087 model2 loss : 0.030488
[11:09:19.203] iteration 10238 : model1 loss : 0.438611 model2 loss : 0.026270
[11:09:19.372] iteration 10239 : model1 loss : 0.436428 model2 loss : 0.025802
[11:09:19.543] iteration 10240 : model1 loss : 0.431954 model2 loss : 0.025103
[11:09:19.712] iteration 10241 : model1 loss : 0.436494 model2 loss : 0.025128
[11:09:19.879] iteration 10242 : model1 loss : 0.436852 model2 loss : 0.027358
[11:09:20.048] iteration 10243 : model1 loss : 0.435891 model2 loss : 0.027061
[11:09:20.214] iteration 10244 : model1 loss : 0.439894 model2 loss : 0.029105
[11:09:20.383] iteration 10245 : model1 loss : 0.434067 model2 loss : 0.026000
[11:09:20.550] iteration 10246 : model1 loss : 0.437701 model2 loss : 0.024781
[11:09:20.719] iteration 10247 : model1 loss : 0.435952 model2 loss : 0.025342
[11:09:20.892] iteration 10248 : model1 loss : 0.441299 model2 loss : 0.030773
[11:09:21.063] iteration 10249 : model1 loss : 0.437202 model2 loss : 0.027467
[11:09:21.231] iteration 10250 : model1 loss : 0.439663 model2 loss : 0.028370
[11:09:21.400] iteration 10251 : model1 loss : 0.435796 model2 loss : 0.026114
[11:09:21.568] iteration 10252 : model1 loss : 0.436202 model2 loss : 0.022189
[11:09:21.737] iteration 10253 : model1 loss : 0.439866 model2 loss : 0.027686
[11:09:21.907] iteration 10254 : model1 loss : 0.438546 model2 loss : 0.026188
[11:09:22.077] iteration 10255 : model1 loss : 0.442959 model2 loss : 0.025872
[11:09:22.244] iteration 10256 : model1 loss : 0.437039 model2 loss : 0.026768
[11:09:22.414] iteration 10257 : model1 loss : 0.438810 model2 loss : 0.030307
[11:09:22.583] iteration 10258 : model1 loss : 0.434731 model2 loss : 0.026763
[11:09:22.752] iteration 10259 : model1 loss : 0.439883 model2 loss : 0.026216
[11:09:22.923] iteration 10260 : model1 loss : 0.433763 model2 loss : 0.029597
[11:09:23.092] iteration 10261 : model1 loss : 0.433371 model2 loss : 0.023777
[11:09:23.260] iteration 10262 : model1 loss : 0.436245 model2 loss : 0.025316
[11:09:23.427] iteration 10263 : model1 loss : 0.437419 model2 loss : 0.027327
[11:09:25.336] iteration 10264 : model1 loss : 0.436293 model2 loss : 0.021960
[11:09:25.503] iteration 10265 : model1 loss : 0.438669 model2 loss : 0.026670
[11:09:25.673] iteration 10266 : model1 loss : 0.436208 model2 loss : 0.023517
[11:09:25.843] iteration 10267 : model1 loss : 0.436500 model2 loss : 0.026065
[11:09:26.014] iteration 10268 : model1 loss : 0.436676 model2 loss : 0.028170
[11:09:26.180] iteration 10269 : model1 loss : 0.439217 model2 loss : 0.027906
[11:09:26.347] iteration 10270 : model1 loss : 0.435647 model2 loss : 0.026068
[11:09:26.516] iteration 10271 : model1 loss : 0.438267 model2 loss : 0.022743
[11:09:26.684] iteration 10272 : model1 loss : 0.434929 model2 loss : 0.026566
[11:09:26.852] iteration 10273 : model1 loss : 0.434496 model2 loss : 0.024508
[11:09:27.023] iteration 10274 : model1 loss : 0.440768 model2 loss : 0.028049
[11:09:27.189] iteration 10275 : model1 loss : 0.432008 model2 loss : 0.021768
[11:09:27.358] iteration 10276 : model1 loss : 0.433972 model2 loss : 0.027314
[11:09:27.527] iteration 10277 : model1 loss : 0.435638 model2 loss : 0.024029
[11:09:27.697] iteration 10278 : model1 loss : 0.435426 model2 loss : 0.025161
[11:09:27.864] iteration 10279 : model1 loss : 0.432966 model2 loss : 0.026645
[11:09:28.032] iteration 10280 : model1 loss : 0.437121 model2 loss : 0.028760
[11:09:28.199] iteration 10281 : model1 loss : 0.436207 model2 loss : 0.024727
[11:09:28.369] iteration 10282 : model1 loss : 0.438146 model2 loss : 0.024668
[11:09:28.537] iteration 10283 : model1 loss : 0.429707 model2 loss : 0.021850
[11:09:28.706] iteration 10284 : model1 loss : 0.439281 model2 loss : 0.024330
[11:09:28.873] iteration 10285 : model1 loss : 0.439181 model2 loss : 0.029350
[11:09:29.043] iteration 10286 : model1 loss : 0.438149 model2 loss : 0.026827
[11:09:29.212] iteration 10287 : model1 loss : 0.435057 model2 loss : 0.022520
[11:09:29.380] iteration 10288 : model1 loss : 0.438992 model2 loss : 0.031115
[11:09:29.547] iteration 10289 : model1 loss : 0.440544 model2 loss : 0.029780
[11:09:29.716] iteration 10290 : model1 loss : 0.437687 model2 loss : 0.027719
[11:09:29.885] iteration 10291 : model1 loss : 0.437372 model2 loss : 0.023559
[11:09:30.053] iteration 10292 : model1 loss : 0.439732 model2 loss : 0.024837
[11:09:30.222] iteration 10293 : model1 loss : 0.439935 model2 loss : 0.046357
[11:09:30.391] iteration 10294 : model1 loss : 0.440653 model2 loss : 0.023813
[11:09:30.557] iteration 10295 : model1 loss : 0.433901 model2 loss : 0.034502
[11:09:30.724] iteration 10296 : model1 loss : 0.440140 model2 loss : 0.027902
[11:09:32.696] iteration 10297 : model1 loss : 0.437312 model2 loss : 0.033290
[11:09:32.867] iteration 10298 : model1 loss : 0.433711 model2 loss : 0.024121
[11:09:33.039] iteration 10299 : model1 loss : 0.440381 model2 loss : 0.027914
[11:09:33.207] iteration 10300 : model1 loss : 0.437055 model2 loss : 0.028756
[11:09:33.376] iteration 10301 : model1 loss : 0.441565 model2 loss : 0.030156
[11:09:33.545] iteration 10302 : model1 loss : 0.439686 model2 loss : 0.025863
[11:09:33.713] iteration 10303 : model1 loss : 0.436577 model2 loss : 0.026462
[11:09:33.879] iteration 10304 : model1 loss : 0.435228 model2 loss : 0.027031
[11:09:34.047] iteration 10305 : model1 loss : 0.435548 model2 loss : 0.024026
[11:09:34.214] iteration 10306 : model1 loss : 0.435110 model2 loss : 0.024607
[11:09:34.385] iteration 10307 : model1 loss : 0.438994 model2 loss : 0.026121
[11:09:34.565] iteration 10308 : model1 loss : 0.437343 model2 loss : 0.027381
[11:09:34.735] iteration 10309 : model1 loss : 0.439349 model2 loss : 0.027119
[11:09:34.905] iteration 10310 : model1 loss : 0.434491 model2 loss : 0.024909
[11:09:35.074] iteration 10311 : model1 loss : 0.438524 model2 loss : 0.023810
[11:09:35.242] iteration 10312 : model1 loss : 0.440584 model2 loss : 0.025952
[11:09:35.411] iteration 10313 : model1 loss : 0.433641 model2 loss : 0.025512
[11:09:35.577] iteration 10314 : model1 loss : 0.438327 model2 loss : 0.027503
[11:09:35.748] iteration 10315 : model1 loss : 0.433889 model2 loss : 0.022436
[11:09:35.917] iteration 10316 : model1 loss : 0.438077 model2 loss : 0.027317
[11:09:36.084] iteration 10317 : model1 loss : 0.435374 model2 loss : 0.028243
[11:09:36.251] iteration 10318 : model1 loss : 0.438732 model2 loss : 0.025419
[11:09:36.421] iteration 10319 : model1 loss : 0.431843 model2 loss : 0.023546
[11:09:36.600] iteration 10320 : model1 loss : 0.437225 model2 loss : 0.029584
[11:09:36.771] iteration 10321 : model1 loss : 0.433552 model2 loss : 0.024411
[11:09:36.940] iteration 10322 : model1 loss : 0.441498 model2 loss : 0.028100
[11:09:37.109] iteration 10323 : model1 loss : 0.438174 model2 loss : 0.029442
[11:09:37.276] iteration 10324 : model1 loss : 0.436479 model2 loss : 0.026120
[11:09:37.445] iteration 10325 : model1 loss : 0.440469 model2 loss : 0.026568
[11:09:37.611] iteration 10326 : model1 loss : 0.440447 model2 loss : 0.025734
[11:09:37.780] iteration 10327 : model1 loss : 0.440091 model2 loss : 0.026467
[11:09:37.949] iteration 10328 : model1 loss : 0.434556 model2 loss : 0.026660
[11:09:38.117] iteration 10329 : model1 loss : 0.437106 model2 loss : 0.025306
[11:09:40.057] iteration 10330 : model1 loss : 0.431774 model2 loss : 0.022520
[11:09:40.225] iteration 10331 : model1 loss : 0.441914 model2 loss : 0.024804
[11:09:40.394] iteration 10332 : model1 loss : 0.435923 model2 loss : 0.025533
[11:09:40.563] iteration 10333 : model1 loss : 0.436600 model2 loss : 0.022412
[11:09:40.734] iteration 10334 : model1 loss : 0.438932 model2 loss : 0.028373
[11:09:40.900] iteration 10335 : model1 loss : 0.437565 model2 loss : 0.027357
[11:09:41.068] iteration 10336 : model1 loss : 0.435418 model2 loss : 0.023709
[11:09:41.234] iteration 10337 : model1 loss : 0.434000 model2 loss : 0.025157
[11:09:41.404] iteration 10338 : model1 loss : 0.437446 model2 loss : 0.026374
[11:09:41.572] iteration 10339 : model1 loss : 0.436887 model2 loss : 0.024745
[11:09:41.740] iteration 10340 : model1 loss : 0.436174 model2 loss : 0.022404
[11:09:41.908] iteration 10341 : model1 loss : 0.435192 model2 loss : 0.025066
[11:09:42.076] iteration 10342 : model1 loss : 0.440166 model2 loss : 0.028391
[11:09:42.245] iteration 10343 : model1 loss : 0.441269 model2 loss : 0.026008
[11:09:42.414] iteration 10344 : model1 loss : 0.438284 model2 loss : 0.027347
[11:09:42.581] iteration 10345 : model1 loss : 0.439335 model2 loss : 0.029006
[11:09:42.750] iteration 10346 : model1 loss : 0.439206 model2 loss : 0.027610
[11:09:42.915] iteration 10347 : model1 loss : 0.439346 model2 loss : 0.025149
[11:09:43.085] iteration 10348 : model1 loss : 0.436521 model2 loss : 0.026322
[11:09:43.253] iteration 10349 : model1 loss : 0.435662 model2 loss : 0.029606
[11:09:43.423] iteration 10350 : model1 loss : 0.435575 model2 loss : 0.027170
[11:09:43.591] iteration 10351 : model1 loss : 0.436552 model2 loss : 0.023750
[11:09:43.760] iteration 10352 : model1 loss : 0.442377 model2 loss : 0.029078
[11:09:43.928] iteration 10353 : model1 loss : 0.435802 model2 loss : 0.025972
[11:09:44.095] iteration 10354 : model1 loss : 0.437388 model2 loss : 0.027941
[11:09:44.263] iteration 10355 : model1 loss : 0.440177 model2 loss : 0.032190
[11:09:44.432] iteration 10356 : model1 loss : 0.434396 model2 loss : 0.025503
[11:09:44.599] iteration 10357 : model1 loss : 0.435416 model2 loss : 0.025041
[11:09:44.769] iteration 10358 : model1 loss : 0.435144 model2 loss : 0.023267
[11:09:44.936] iteration 10359 : model1 loss : 0.434199 model2 loss : 0.026436
[11:09:45.107] iteration 10360 : model1 loss : 0.434784 model2 loss : 0.027374
[11:09:45.272] iteration 10361 : model1 loss : 0.433381 model2 loss : 0.025496
[11:09:45.439] iteration 10362 : model1 loss : 0.434743 model2 loss : 0.024191
[11:09:47.377] iteration 10363 : model1 loss : 0.429047 model2 loss : 0.025127
[11:09:47.551] iteration 10364 : model1 loss : 0.437157 model2 loss : 0.025006
[11:09:47.720] iteration 10365 : model1 loss : 0.434538 model2 loss : 0.026051
[11:09:47.888] iteration 10366 : model1 loss : 0.438695 model2 loss : 0.028566
[11:09:48.056] iteration 10367 : model1 loss : 0.439032 model2 loss : 0.046306
[11:09:48.224] iteration 10368 : model1 loss : 0.432489 model2 loss : 0.025065
[11:09:48.393] iteration 10369 : model1 loss : 0.436314 model2 loss : 0.027081
[11:09:48.561] iteration 10370 : model1 loss : 0.433915 model2 loss : 0.024703
[11:09:48.742] iteration 10371 : model1 loss : 0.439781 model2 loss : 0.026555
[11:09:48.908] iteration 10372 : model1 loss : 0.437373 model2 loss : 0.027351
[11:09:49.081] iteration 10373 : model1 loss : 0.436441 model2 loss : 0.025816
[11:09:49.247] iteration 10374 : model1 loss : 0.439484 model2 loss : 0.025543
[11:09:49.416] iteration 10375 : model1 loss : 0.439319 model2 loss : 0.028092
[11:09:49.584] iteration 10376 : model1 loss : 0.440472 model2 loss : 0.027425
[11:09:49.755] iteration 10377 : model1 loss : 0.436141 model2 loss : 0.028101
[11:09:49.923] iteration 10378 : model1 loss : 0.436828 model2 loss : 0.023163
[11:09:50.093] iteration 10379 : model1 loss : 0.431145 model2 loss : 0.025243
[11:09:50.263] iteration 10380 : model1 loss : 0.439814 model2 loss : 0.024644
[11:09:50.433] iteration 10381 : model1 loss : 0.438265 model2 loss : 0.027209
[11:09:50.601] iteration 10382 : model1 loss : 0.434794 model2 loss : 0.025326
[11:09:50.771] iteration 10383 : model1 loss : 0.439111 model2 loss : 0.026466
[11:09:50.938] iteration 10384 : model1 loss : 0.436687 model2 loss : 0.023934
[11:09:51.106] iteration 10385 : model1 loss : 0.435371 model2 loss : 0.024018
[11:09:51.271] iteration 10386 : model1 loss : 0.437323 model2 loss : 0.026127
[11:09:51.441] iteration 10387 : model1 loss : 0.436470 model2 loss : 0.024158
[11:09:51.608] iteration 10388 : model1 loss : 0.436326 model2 loss : 0.025543
[11:09:51.778] iteration 10389 : model1 loss : 0.435680 model2 loss : 0.026110
[11:09:51.945] iteration 10390 : model1 loss : 0.435587 model2 loss : 0.025330
[11:09:52.113] iteration 10391 : model1 loss : 0.440795 model2 loss : 0.027470
[11:09:52.281] iteration 10392 : model1 loss : 0.434782 model2 loss : 0.026053
[11:09:52.450] iteration 10393 : model1 loss : 0.435823 model2 loss : 0.024782
[11:09:52.614] iteration 10394 : model1 loss : 0.440137 model2 loss : 0.028799
[11:09:52.784] iteration 10395 : model1 loss : 0.435610 model2 loss : 0.024153
[11:09:54.718] iteration 10396 : model1 loss : 0.436702 model2 loss : 0.028925
[11:09:54.884] iteration 10397 : model1 loss : 0.435161 model2 loss : 0.026425
[11:09:55.054] iteration 10398 : model1 loss : 0.433500 model2 loss : 0.022985
[11:09:55.222] iteration 10399 : model1 loss : 0.436968 model2 loss : 0.024977
[11:09:55.390] iteration 10400 : model1 loss : 0.436006 model2 loss : 0.026693
[11:09:55.557] iteration 10401 : model1 loss : 0.438122 model2 loss : 0.028274
[11:09:55.727] iteration 10402 : model1 loss : 0.443255 model2 loss : 0.029519
[11:09:55.898] iteration 10403 : model1 loss : 0.440813 model2 loss : 0.027382
[11:09:56.069] iteration 10404 : model1 loss : 0.436529 model2 loss : 0.025721
[11:09:56.235] iteration 10405 : model1 loss : 0.437465 model2 loss : 0.025719
[11:09:56.405] iteration 10406 : model1 loss : 0.438188 model2 loss : 0.029508
[11:09:56.574] iteration 10407 : model1 loss : 0.437788 model2 loss : 0.028643
[11:09:56.742] iteration 10408 : model1 loss : 0.437899 model2 loss : 0.028324
[11:09:56.910] iteration 10409 : model1 loss : 0.439681 model2 loss : 0.025876
[11:09:57.078] iteration 10410 : model1 loss : 0.437689 model2 loss : 0.025751
[11:09:57.245] iteration 10411 : model1 loss : 0.439100 model2 loss : 0.026481
[11:09:57.415] iteration 10412 : model1 loss : 0.436281 model2 loss : 0.026060
[11:09:57.582] iteration 10413 : model1 loss : 0.439712 model2 loss : 0.028499
[11:09:57.751] iteration 10414 : model1 loss : 0.432944 model2 loss : 0.024700
[11:09:57.917] iteration 10415 : model1 loss : 0.434256 model2 loss : 0.023972
[11:09:58.085] iteration 10416 : model1 loss : 0.437081 model2 loss : 0.028245
[11:09:58.252] iteration 10417 : model1 loss : 0.431700 model2 loss : 0.025266
[11:09:58.421] iteration 10418 : model1 loss : 0.437343 model2 loss : 0.024447
[11:09:58.591] iteration 10419 : model1 loss : 0.437628 model2 loss : 0.026576
[11:09:58.761] iteration 10420 : model1 loss : 0.437447 model2 loss : 0.025336
[11:09:58.929] iteration 10421 : model1 loss : 0.438368 model2 loss : 0.025667
[11:09:59.098] iteration 10422 : model1 loss : 0.435619 model2 loss : 0.028631
[11:09:59.265] iteration 10423 : model1 loss : 0.434893 model2 loss : 0.025209
[11:09:59.433] iteration 10424 : model1 loss : 0.440695 model2 loss : 0.026888
[11:09:59.599] iteration 10425 : model1 loss : 0.433244 model2 loss : 0.023233
[11:09:59.770] iteration 10426 : model1 loss : 0.436537 model2 loss : 0.024965
[11:09:59.935] iteration 10427 : model1 loss : 0.439417 model2 loss : 0.027855
[11:10:00.104] iteration 10428 : model1 loss : 0.434778 model2 loss : 0.024374
[11:10:02.040] iteration 10429 : model1 loss : 0.438152 model2 loss : 0.025713
[11:10:02.213] iteration 10430 : model1 loss : 0.435883 model2 loss : 0.023367
[11:10:02.382] iteration 10431 : model1 loss : 0.440646 model2 loss : 0.023303
[11:10:02.550] iteration 10432 : model1 loss : 0.433488 model2 loss : 0.024178
[11:10:02.717] iteration 10433 : model1 loss : 0.435822 model2 loss : 0.025708
[11:10:02.884] iteration 10434 : model1 loss : 0.438285 model2 loss : 0.026508
[11:10:03.055] iteration 10435 : model1 loss : 0.440751 model2 loss : 0.027988
[11:10:03.222] iteration 10436 : model1 loss : 0.434044 model2 loss : 0.025458
[11:10:03.391] iteration 10437 : model1 loss : 0.437405 model2 loss : 0.027051
[11:10:03.559] iteration 10438 : model1 loss : 0.437790 model2 loss : 0.028662
[11:10:03.728] iteration 10439 : model1 loss : 0.439539 model2 loss : 0.027186
[11:10:03.895] iteration 10440 : model1 loss : 0.439250 model2 loss : 0.029753
[11:10:04.063] iteration 10441 : model1 loss : 0.433824 model2 loss : 0.024339
[11:10:04.232] iteration 10442 : model1 loss : 0.436283 model2 loss : 0.028275
[11:10:04.399] iteration 10443 : model1 loss : 0.437078 model2 loss : 0.021481
[11:10:04.568] iteration 10444 : model1 loss : 0.435187 model2 loss : 0.023574
[11:10:04.737] iteration 10445 : model1 loss : 0.437597 model2 loss : 0.024707
[11:10:04.906] iteration 10446 : model1 loss : 0.430861 model2 loss : 0.023818
[11:10:05.075] iteration 10447 : model1 loss : 0.435934 model2 loss : 0.023214
[11:10:05.244] iteration 10448 : model1 loss : 0.438469 model2 loss : 0.022621
[11:10:05.413] iteration 10449 : model1 loss : 0.433992 model2 loss : 0.022633
[11:10:05.583] iteration 10450 : model1 loss : 0.438511 model2 loss : 0.024289
[11:10:05.753] iteration 10451 : model1 loss : 0.435116 model2 loss : 0.024259
[11:10:05.922] iteration 10452 : model1 loss : 0.431244 model2 loss : 0.025318
[11:10:06.090] iteration 10453 : model1 loss : 0.438419 model2 loss : 0.028149
[11:10:06.256] iteration 10454 : model1 loss : 0.434869 model2 loss : 0.027115
[11:10:06.424] iteration 10455 : model1 loss : 0.442326 model2 loss : 0.031615
[11:10:06.592] iteration 10456 : model1 loss : 0.437394 model2 loss : 0.026348
[11:10:06.763] iteration 10457 : model1 loss : 0.440389 model2 loss : 0.029684
[11:10:06.931] iteration 10458 : model1 loss : 0.437343 model2 loss : 0.023041
[11:10:07.109] iteration 10459 : model1 loss : 0.441467 model2 loss : 0.027510
[11:10:07.276] iteration 10460 : model1 loss : 0.436135 model2 loss : 0.025995
[11:10:07.444] iteration 10461 : model1 loss : 0.435563 model2 loss : 0.028037
[11:10:09.359] iteration 10462 : model1 loss : 0.439860 model2 loss : 0.030770
[11:10:09.528] iteration 10463 : model1 loss : 0.437072 model2 loss : 0.024080
[11:10:09.699] iteration 10464 : model1 loss : 0.435457 model2 loss : 0.024463
[11:10:09.866] iteration 10465 : model1 loss : 0.434347 model2 loss : 0.026269
[11:10:10.036] iteration 10466 : model1 loss : 0.439283 model2 loss : 0.027460
[11:10:10.204] iteration 10467 : model1 loss : 0.437609 model2 loss : 0.021208
[11:10:10.374] iteration 10468 : model1 loss : 0.437086 model2 loss : 0.024093
[11:10:10.542] iteration 10469 : model1 loss : 0.437624 model2 loss : 0.023203
[11:10:10.710] iteration 10470 : model1 loss : 0.432960 model2 loss : 0.023800
[11:10:10.878] iteration 10471 : model1 loss : 0.440509 model2 loss : 0.035482
[11:10:11.047] iteration 10472 : model1 loss : 0.434801 model2 loss : 0.026508
[11:10:11.213] iteration 10473 : model1 loss : 0.434106 model2 loss : 0.026282
[11:10:11.384] iteration 10474 : model1 loss : 0.437282 model2 loss : 0.026424
[11:10:11.553] iteration 10475 : model1 loss : 0.438759 model2 loss : 0.025113
[11:10:11.725] iteration 10476 : model1 loss : 0.439196 model2 loss : 0.027587
[11:10:11.891] iteration 10477 : model1 loss : 0.439023 model2 loss : 0.026733
[11:10:12.061] iteration 10478 : model1 loss : 0.434487 model2 loss : 0.022756
[11:10:12.229] iteration 10479 : model1 loss : 0.434810 model2 loss : 0.025630
[11:10:12.400] iteration 10480 : model1 loss : 0.439048 model2 loss : 0.027590
[11:10:12.568] iteration 10481 : model1 loss : 0.434359 model2 loss : 0.023523
[11:10:12.737] iteration 10482 : model1 loss : 0.437465 model2 loss : 0.024572
[11:10:12.905] iteration 10483 : model1 loss : 0.438804 model2 loss : 0.023736
[11:10:13.085] iteration 10484 : model1 loss : 0.439011 model2 loss : 0.027343
[11:10:13.253] iteration 10485 : model1 loss : 0.431717 model2 loss : 0.023416
[11:10:13.421] iteration 10486 : model1 loss : 0.434987 model2 loss : 0.022138
[11:10:13.588] iteration 10487 : model1 loss : 0.438976 model2 loss : 0.024709
[11:10:13.756] iteration 10488 : model1 loss : 0.435538 model2 loss : 0.026257
[11:10:13.922] iteration 10489 : model1 loss : 0.434335 model2 loss : 0.023460
[11:10:14.092] iteration 10490 : model1 loss : 0.442543 model2 loss : 0.027273
[11:10:14.260] iteration 10491 : model1 loss : 0.441557 model2 loss : 0.026322
[11:10:14.430] iteration 10492 : model1 loss : 0.435087 model2 loss : 0.025159
[11:10:14.596] iteration 10493 : model1 loss : 0.436088 model2 loss : 0.023729
[11:10:14.763] iteration 10494 : model1 loss : 0.432723 model2 loss : 0.024209
[11:10:16.694] iteration 10495 : model1 loss : 0.433078 model2 loss : 0.023929
[11:10:16.861] iteration 10496 : model1 loss : 0.431338 model2 loss : 0.023845
[11:10:17.033] iteration 10497 : model1 loss : 0.434700 model2 loss : 0.024489
[11:10:17.201] iteration 10498 : model1 loss : 0.437595 model2 loss : 0.022925
[11:10:17.370] iteration 10499 : model1 loss : 0.439173 model2 loss : 0.029232
[11:10:17.560] iteration 10500 : model1 loss : 0.439441 model2 loss : 0.025319
[11:10:17.729] iteration 10501 : model1 loss : 0.439577 model2 loss : 0.029276
[11:10:17.898] iteration 10502 : model1 loss : 0.432159 model2 loss : 0.023140
[11:10:18.067] iteration 10503 : model1 loss : 0.436030 model2 loss : 0.022070
[11:10:18.236] iteration 10504 : model1 loss : 0.436717 model2 loss : 0.025631
[11:10:18.403] iteration 10505 : model1 loss : 0.439088 model2 loss : 0.026149
[11:10:18.570] iteration 10506 : model1 loss : 0.439000 model2 loss : 0.025777
[11:10:18.740] iteration 10507 : model1 loss : 0.439600 model2 loss : 0.026945
[11:10:18.907] iteration 10508 : model1 loss : 0.442111 model2 loss : 0.031449
[11:10:19.078] iteration 10509 : model1 loss : 0.439584 model2 loss : 0.026651
[11:10:19.245] iteration 10510 : model1 loss : 0.437637 model2 loss : 0.027726
[11:10:19.414] iteration 10511 : model1 loss : 0.436707 model2 loss : 0.027160
[11:10:19.581] iteration 10512 : model1 loss : 0.439320 model2 loss : 0.024699
[11:10:19.751] iteration 10513 : model1 loss : 0.440176 model2 loss : 0.025816
[11:10:19.919] iteration 10514 : model1 loss : 0.439600 model2 loss : 0.026384
[11:10:20.089] iteration 10515 : model1 loss : 0.433778 model2 loss : 0.024758
[11:10:20.258] iteration 10516 : model1 loss : 0.435670 model2 loss : 0.025329
[11:10:20.427] iteration 10517 : model1 loss : 0.438998 model2 loss : 0.026048
[11:10:20.595] iteration 10518 : model1 loss : 0.438046 model2 loss : 0.024739
[11:10:20.764] iteration 10519 : model1 loss : 0.434293 model2 loss : 0.023154
[11:10:20.933] iteration 10520 : model1 loss : 0.434724 model2 loss : 0.023912
[11:10:21.105] iteration 10521 : model1 loss : 0.435497 model2 loss : 0.024417
[11:10:21.272] iteration 10522 : model1 loss : 0.437788 model2 loss : 0.026765
[11:10:21.442] iteration 10523 : model1 loss : 0.434108 model2 loss : 0.025174
[11:10:21.609] iteration 10524 : model1 loss : 0.434517 model2 loss : 0.023052
[11:10:21.779] iteration 10525 : model1 loss : 0.437132 model2 loss : 0.026449
[11:10:21.966] iteration 10526 : model1 loss : 0.436135 model2 loss : 0.022786
[11:10:22.135] iteration 10527 : model1 loss : 0.437723 model2 loss : 0.026900
[11:10:24.122] iteration 10528 : model1 loss : 0.438561 model2 loss : 0.027348
[11:10:24.289] iteration 10529 : model1 loss : 0.439715 model2 loss : 0.024229
[11:10:24.459] iteration 10530 : model1 loss : 0.433581 model2 loss : 0.025996
[11:10:24.624] iteration 10531 : model1 loss : 0.438248 model2 loss : 0.025736
[11:10:24.793] iteration 10532 : model1 loss : 0.435859 model2 loss : 0.022491
[11:10:24.960] iteration 10533 : model1 loss : 0.436645 model2 loss : 0.028898
[11:10:25.131] iteration 10534 : model1 loss : 0.435935 model2 loss : 0.029934
[11:10:25.299] iteration 10535 : model1 loss : 0.436717 model2 loss : 0.028071
[11:10:25.468] iteration 10536 : model1 loss : 0.439797 model2 loss : 0.023475
[11:10:25.638] iteration 10537 : model1 loss : 0.436222 model2 loss : 0.025996
[11:10:25.806] iteration 10538 : model1 loss : 0.439201 model2 loss : 0.024460
[11:10:25.974] iteration 10539 : model1 loss : 0.441911 model2 loss : 0.030023
[11:10:26.144] iteration 10540 : model1 loss : 0.433657 model2 loss : 0.024711
[11:10:26.311] iteration 10541 : model1 loss : 0.436657 model2 loss : 0.023412
[11:10:26.481] iteration 10542 : model1 loss : 0.435106 model2 loss : 0.030138
[11:10:26.664] iteration 10543 : model1 loss : 0.440786 model2 loss : 0.026162
[11:10:26.834] iteration 10544 : model1 loss : 0.437458 model2 loss : 0.025799
[11:10:27.002] iteration 10545 : model1 loss : 0.435565 model2 loss : 0.023379
[11:10:27.169] iteration 10546 : model1 loss : 0.432372 model2 loss : 0.026136
[11:10:27.336] iteration 10547 : model1 loss : 0.441816 model2 loss : 0.024741
[11:10:27.506] iteration 10548 : model1 loss : 0.438607 model2 loss : 0.027202
[11:10:27.673] iteration 10549 : model1 loss : 0.438605 model2 loss : 0.029922
[11:10:27.842] iteration 10550 : model1 loss : 0.440291 model2 loss : 0.029139
[11:10:28.009] iteration 10551 : model1 loss : 0.434834 model2 loss : 0.022290
[11:10:28.180] iteration 10552 : model1 loss : 0.435354 model2 loss : 0.022618
[11:10:28.347] iteration 10553 : model1 loss : 0.434435 model2 loss : 0.027357
[11:10:28.522] iteration 10554 : model1 loss : 0.432290 model2 loss : 0.023627
[11:10:28.689] iteration 10555 : model1 loss : 0.436146 model2 loss : 0.027954
[11:10:28.860] iteration 10556 : model1 loss : 0.435355 model2 loss : 0.023733
[11:10:29.029] iteration 10557 : model1 loss : 0.437775 model2 loss : 0.027016
[11:10:29.197] iteration 10558 : model1 loss : 0.437758 model2 loss : 0.026432
[11:10:29.365] iteration 10559 : model1 loss : 0.436047 model2 loss : 0.025557
[11:10:29.534] iteration 10560 : model1 loss : 0.441150 model2 loss : 0.032353
[11:10:31.470] iteration 10561 : model1 loss : 0.436529 model2 loss : 0.024133
[11:10:31.637] iteration 10562 : model1 loss : 0.437440 model2 loss : 0.023274
[11:10:31.809] iteration 10563 : model1 loss : 0.439347 model2 loss : 0.026713
[11:10:31.976] iteration 10564 : model1 loss : 0.435062 model2 loss : 0.026115
[11:10:32.146] iteration 10565 : model1 loss : 0.440853 model2 loss : 0.029019
[11:10:32.312] iteration 10566 : model1 loss : 0.436735 model2 loss : 0.022583
[11:10:32.479] iteration 10567 : model1 loss : 0.436323 model2 loss : 0.022834
[11:10:32.647] iteration 10568 : model1 loss : 0.436238 model2 loss : 0.025203
[11:10:32.815] iteration 10569 : model1 loss : 0.438579 model2 loss : 0.024498
[11:10:32.984] iteration 10570 : model1 loss : 0.434833 model2 loss : 0.025982
[11:10:33.153] iteration 10571 : model1 loss : 0.437167 model2 loss : 0.025472
[11:10:33.322] iteration 10572 : model1 loss : 0.439374 model2 loss : 0.027212
[11:10:33.494] iteration 10573 : model1 loss : 0.437415 model2 loss : 0.025572
[11:10:33.660] iteration 10574 : model1 loss : 0.433855 model2 loss : 0.025082
[11:10:33.830] iteration 10575 : model1 loss : 0.436283 model2 loss : 0.028448
[11:10:33.997] iteration 10576 : model1 loss : 0.437420 model2 loss : 0.029668
[11:10:34.167] iteration 10577 : model1 loss : 0.435036 model2 loss : 0.024052
[11:10:34.336] iteration 10578 : model1 loss : 0.435139 model2 loss : 0.025244
[11:10:34.508] iteration 10579 : model1 loss : 0.434418 model2 loss : 0.024457
[11:10:34.676] iteration 10580 : model1 loss : 0.435986 model2 loss : 0.025251
[11:10:34.847] iteration 10581 : model1 loss : 0.435939 model2 loss : 0.025753
[11:10:35.015] iteration 10582 : model1 loss : 0.436850 model2 loss : 0.022976
[11:10:35.185] iteration 10583 : model1 loss : 0.439834 model2 loss : 0.026694
[11:10:35.351] iteration 10584 : model1 loss : 0.434754 model2 loss : 0.027057
[11:10:35.522] iteration 10585 : model1 loss : 0.439280 model2 loss : 0.025483
[11:10:35.689] iteration 10586 : model1 loss : 0.437192 model2 loss : 0.023767
[11:10:35.863] iteration 10587 : model1 loss : 0.438104 model2 loss : 0.023224
[11:10:36.029] iteration 10588 : model1 loss : 0.436558 model2 loss : 0.026035
[11:10:36.200] iteration 10589 : model1 loss : 0.435857 model2 loss : 0.024292
[11:10:36.368] iteration 10590 : model1 loss : 0.439678 model2 loss : 0.027978
[11:10:36.538] iteration 10591 : model1 loss : 0.435001 model2 loss : 0.023285
[11:10:36.705] iteration 10592 : model1 loss : 0.435754 model2 loss : 0.024159
[11:10:36.873] iteration 10593 : model1 loss : 0.438415 model2 loss : 0.023864
[11:10:38.812] iteration 10594 : model1 loss : 0.437177 model2 loss : 0.022101
[11:10:38.978] iteration 10595 : model1 loss : 0.438767 model2 loss : 0.025312
[11:10:39.149] iteration 10596 : model1 loss : 0.440553 model2 loss : 0.028532
[11:10:39.316] iteration 10597 : model1 loss : 0.439302 model2 loss : 0.025720
[11:10:39.484] iteration 10598 : model1 loss : 0.436641 model2 loss : 0.022927
[11:10:39.652] iteration 10599 : model1 loss : 0.439574 model2 loss : 0.026799
[11:10:39.821] iteration 10600 : model1 loss : 0.435230 model2 loss : 0.024758
[11:10:39.988] iteration 10601 : model1 loss : 0.432609 model2 loss : 0.023588
[11:10:40.156] iteration 10602 : model1 loss : 0.435843 model2 loss : 0.022913
[11:10:40.326] iteration 10603 : model1 loss : 0.431314 model2 loss : 0.023999
[11:10:40.496] iteration 10604 : model1 loss : 0.436389 model2 loss : 0.026945
[11:10:40.664] iteration 10605 : model1 loss : 0.434983 model2 loss : 0.028430
[11:10:40.835] iteration 10606 : model1 loss : 0.435318 model2 loss : 0.025228
[11:10:41.001] iteration 10607 : model1 loss : 0.439599 model2 loss : 0.026028
[11:10:41.168] iteration 10608 : model1 loss : 0.438474 model2 loss : 0.026328
[11:10:41.336] iteration 10609 : model1 loss : 0.435102 model2 loss : 0.022534
[11:10:41.509] iteration 10610 : model1 loss : 0.433574 model2 loss : 0.026901
[11:10:41.676] iteration 10611 : model1 loss : 0.437819 model2 loss : 0.023804
[11:10:41.843] iteration 10612 : model1 loss : 0.434368 model2 loss : 0.022694
[11:10:42.012] iteration 10613 : model1 loss : 0.437610 model2 loss : 0.023966
[11:10:42.179] iteration 10614 : model1 loss : 0.433380 model2 loss : 0.021802
[11:10:42.347] iteration 10615 : model1 loss : 0.443079 model2 loss : 0.028539
[11:10:42.521] iteration 10616 : model1 loss : 0.437777 model2 loss : 0.023979
[11:10:42.686] iteration 10617 : model1 loss : 0.439835 model2 loss : 0.028418
[11:10:42.855] iteration 10618 : model1 loss : 0.435837 model2 loss : 0.023672
[11:10:43.021] iteration 10619 : model1 loss : 0.436999 model2 loss : 0.025796
[11:10:43.190] iteration 10620 : model1 loss : 0.435514 model2 loss : 0.024215
[11:10:43.356] iteration 10621 : model1 loss : 0.436782 model2 loss : 0.025336
[11:10:43.526] iteration 10622 : model1 loss : 0.433098 model2 loss : 0.022733
[11:10:43.695] iteration 10623 : model1 loss : 0.438017 model2 loss : 0.024448
[11:10:43.865] iteration 10624 : model1 loss : 0.439524 model2 loss : 0.029698
[11:10:44.031] iteration 10625 : model1 loss : 0.439367 model2 loss : 0.026415
[11:10:44.200] iteration 10626 : model1 loss : 0.436374 model2 loss : 0.026344
[11:10:46.176] iteration 10627 : model1 loss : 0.436018 model2 loss : 0.024338
[11:10:46.345] iteration 10628 : model1 loss : 0.440780 model2 loss : 0.025829
[11:10:46.523] iteration 10629 : model1 loss : 0.439603 model2 loss : 0.028723
[11:10:46.690] iteration 10630 : model1 loss : 0.435379 model2 loss : 0.025121
[11:10:46.861] iteration 10631 : model1 loss : 0.436430 model2 loss : 0.022175
[11:10:47.029] iteration 10632 : model1 loss : 0.441003 model2 loss : 0.025530
[11:10:47.197] iteration 10633 : model1 loss : 0.438884 model2 loss : 0.024885
[11:10:47.363] iteration 10634 : model1 loss : 0.438749 model2 loss : 0.025821
[11:10:47.533] iteration 10635 : model1 loss : 0.437100 model2 loss : 0.025228
[11:10:47.703] iteration 10636 : model1 loss : 0.441107 model2 loss : 0.030576
[11:10:47.874] iteration 10637 : model1 loss : 0.435439 model2 loss : 0.024888
[11:10:48.041] iteration 10638 : model1 loss : 0.434352 model2 loss : 0.026674
[11:10:48.210] iteration 10639 : model1 loss : 0.434131 model2 loss : 0.024718
[11:10:48.377] iteration 10640 : model1 loss : 0.435769 model2 loss : 0.023665
[11:10:48.547] iteration 10641 : model1 loss : 0.432724 model2 loss : 0.025753
[11:10:48.713] iteration 10642 : model1 loss : 0.436850 model2 loss : 0.023242
[11:10:48.883] iteration 10643 : model1 loss : 0.437605 model2 loss : 0.023478
[11:10:49.050] iteration 10644 : model1 loss : 0.440390 model2 loss : 0.027958
[11:10:49.221] iteration 10645 : model1 loss : 0.437782 model2 loss : 0.023010
[11:10:49.387] iteration 10646 : model1 loss : 0.431761 model2 loss : 0.022860
[11:10:49.559] iteration 10647 : model1 loss : 0.439296 model2 loss : 0.023994
[11:10:49.727] iteration 10648 : model1 loss : 0.439937 model2 loss : 0.028550
[11:10:49.896] iteration 10649 : model1 loss : 0.438964 model2 loss : 0.027069
[11:10:50.064] iteration 10650 : model1 loss : 0.437932 model2 loss : 0.025712
[11:10:50.234] iteration 10651 : model1 loss : 0.439742 model2 loss : 0.027232
[11:10:50.400] iteration 10652 : model1 loss : 0.439397 model2 loss : 0.030722
[11:10:50.569] iteration 10653 : model1 loss : 0.433331 model2 loss : 0.024293
[11:10:50.736] iteration 10654 : model1 loss : 0.435049 model2 loss : 0.022685
[11:10:50.910] iteration 10655 : model1 loss : 0.431648 model2 loss : 0.022279
[11:10:51.082] iteration 10656 : model1 loss : 0.433249 model2 loss : 0.024730
[11:10:51.253] iteration 10657 : model1 loss : 0.429996 model2 loss : 0.021291
[11:10:51.419] iteration 10658 : model1 loss : 0.436993 model2 loss : 0.027355
[11:10:51.587] iteration 10659 : model1 loss : 0.435589 model2 loss : 0.024185
[11:10:53.546] iteration 10660 : model1 loss : 0.441178 model2 loss : 0.029746
[11:10:53.718] iteration 10661 : model1 loss : 0.439127 model2 loss : 0.024353
[11:10:53.889] iteration 10662 : model1 loss : 0.435700 model2 loss : 0.024605
[11:10:54.059] iteration 10663 : model1 loss : 0.435401 model2 loss : 0.025592
[11:10:54.227] iteration 10664 : model1 loss : 0.441443 model2 loss : 0.037784
[11:10:54.393] iteration 10665 : model1 loss : 0.434727 model2 loss : 0.025326
[11:10:54.564] iteration 10666 : model1 loss : 0.436120 model2 loss : 0.025915
[11:10:54.731] iteration 10667 : model1 loss : 0.440655 model2 loss : 0.027641
[11:10:54.899] iteration 10668 : model1 loss : 0.441754 model2 loss : 0.024043
[11:10:55.068] iteration 10669 : model1 loss : 0.433845 model2 loss : 0.026673
[11:10:55.237] iteration 10670 : model1 loss : 0.439658 model2 loss : 0.029643
[11:10:55.406] iteration 10671 : model1 loss : 0.432472 model2 loss : 0.027376
[11:10:55.574] iteration 10672 : model1 loss : 0.438311 model2 loss : 0.026228
[11:10:55.742] iteration 10673 : model1 loss : 0.433226 model2 loss : 0.022660
[11:10:55.914] iteration 10674 : model1 loss : 0.438214 model2 loss : 0.029722
[11:10:56.083] iteration 10675 : model1 loss : 0.437787 model2 loss : 0.026314
[11:10:56.252] iteration 10676 : model1 loss : 0.441404 model2 loss : 0.024572
[11:10:56.418] iteration 10677 : model1 loss : 0.436287 model2 loss : 0.025720
[11:10:56.587] iteration 10678 : model1 loss : 0.435138 model2 loss : 0.026614
[11:10:56.752] iteration 10679 : model1 loss : 0.437186 model2 loss : 0.028064
[11:10:56.923] iteration 10680 : model1 loss : 0.437374 model2 loss : 0.025396
[11:10:57.095] iteration 10681 : model1 loss : 0.437876 model2 loss : 0.025209
[11:10:57.265] iteration 10682 : model1 loss : 0.439598 model2 loss : 0.032594
[11:10:57.432] iteration 10683 : model1 loss : 0.431147 model2 loss : 0.023215
[11:10:57.603] iteration 10684 : model1 loss : 0.436408 model2 loss : 0.022174
[11:10:57.774] iteration 10685 : model1 loss : 0.436604 model2 loss : 0.025222
[11:10:57.944] iteration 10686 : model1 loss : 0.436568 model2 loss : 0.025986
[11:10:58.111] iteration 10687 : model1 loss : 0.441531 model2 loss : 0.028843
[11:10:58.282] iteration 10688 : model1 loss : 0.434723 model2 loss : 0.026059
[11:10:58.449] iteration 10689 : model1 loss : 0.434786 model2 loss : 0.021784
[11:10:58.616] iteration 10690 : model1 loss : 0.438607 model2 loss : 0.028820
[11:10:58.783] iteration 10691 : model1 loss : 0.440011 model2 loss : 0.027444
[11:10:58.953] iteration 10692 : model1 loss : 0.435708 model2 loss : 0.026511
[11:11:00.927] iteration 10693 : model1 loss : 0.437432 model2 loss : 0.026531
[11:11:01.096] iteration 10694 : model1 loss : 0.439550 model2 loss : 0.027640
[11:11:01.267] iteration 10695 : model1 loss : 0.439068 model2 loss : 0.025203
[11:11:01.434] iteration 10696 : model1 loss : 0.434382 model2 loss : 0.027980
[11:11:01.606] iteration 10697 : model1 loss : 0.434847 model2 loss : 0.023891
[11:11:01.772] iteration 10698 : model1 loss : 0.435368 model2 loss : 0.026007
[11:11:01.940] iteration 10699 : model1 loss : 0.434564 model2 loss : 0.025833
[11:11:02.111] iteration 10700 : model1 loss : 0.436238 model2 loss : 0.027399
[11:11:02.280] iteration 10701 : model1 loss : 0.442375 model2 loss : 0.026124
[11:11:02.450] iteration 10702 : model1 loss : 0.445595 model2 loss : 0.034000
[11:11:02.618] iteration 10703 : model1 loss : 0.439276 model2 loss : 0.024481
[11:11:02.784] iteration 10704 : model1 loss : 0.434681 model2 loss : 0.024921
[11:11:02.953] iteration 10705 : model1 loss : 0.436180 model2 loss : 0.025331
[11:11:03.122] iteration 10706 : model1 loss : 0.435779 model2 loss : 0.024004
[11:11:03.293] iteration 10707 : model1 loss : 0.433330 model2 loss : 0.024027
[11:11:03.459] iteration 10708 : model1 loss : 0.436021 model2 loss : 0.026504
[11:11:03.630] iteration 10709 : model1 loss : 0.437405 model2 loss : 0.027657
[11:11:03.796] iteration 10710 : model1 loss : 0.434405 model2 loss : 0.026009
[11:11:03.965] iteration 10711 : model1 loss : 0.434608 model2 loss : 0.023039
[11:11:04.134] iteration 10712 : model1 loss : 0.433304 model2 loss : 0.026266
[11:11:04.303] iteration 10713 : model1 loss : 0.437870 model2 loss : 0.029869
[11:11:04.471] iteration 10714 : model1 loss : 0.436744 model2 loss : 0.029583
[11:11:04.642] iteration 10715 : model1 loss : 0.435308 model2 loss : 0.026936
[11:11:04.809] iteration 10716 : model1 loss : 0.434494 model2 loss : 0.024107
[11:11:04.978] iteration 10717 : model1 loss : 0.438653 model2 loss : 0.028124
[11:11:05.146] iteration 10718 : model1 loss : 0.437901 model2 loss : 0.025944
[11:11:05.316] iteration 10719 : model1 loss : 0.436310 model2 loss : 0.027618
[11:11:05.485] iteration 10720 : model1 loss : 0.439327 model2 loss : 0.027926
[11:11:05.655] iteration 10721 : model1 loss : 0.434602 model2 loss : 0.024715
[11:11:05.824] iteration 10722 : model1 loss : 0.442354 model2 loss : 0.031898
[11:11:05.992] iteration 10723 : model1 loss : 0.434840 model2 loss : 0.025134
[11:11:06.158] iteration 10724 : model1 loss : 0.434247 model2 loss : 0.025062
[11:11:06.326] iteration 10725 : model1 loss : 0.438965 model2 loss : 0.022889
[11:11:08.253] iteration 10726 : model1 loss : 0.435270 model2 loss : 0.024157
[11:11:08.423] iteration 10727 : model1 loss : 0.436779 model2 loss : 0.025779
[11:11:08.593] iteration 10728 : model1 loss : 0.436797 model2 loss : 0.026578
[11:11:08.762] iteration 10729 : model1 loss : 0.437194 model2 loss : 0.025956
[11:11:08.932] iteration 10730 : model1 loss : 0.433120 model2 loss : 0.023592
[11:11:09.100] iteration 10731 : model1 loss : 0.435647 model2 loss : 0.027247
[11:11:09.272] iteration 10732 : model1 loss : 0.443198 model2 loss : 0.028653
[11:11:09.442] iteration 10733 : model1 loss : 0.430905 model2 loss : 0.022282
[11:11:09.612] iteration 10734 : model1 loss : 0.436606 model2 loss : 0.021830
[11:11:09.777] iteration 10735 : model1 loss : 0.434577 model2 loss : 0.024917
[11:11:09.948] iteration 10736 : model1 loss : 0.436456 model2 loss : 0.024058
[11:11:10.118] iteration 10737 : model1 loss : 0.436510 model2 loss : 0.025493
[11:11:10.286] iteration 10738 : model1 loss : 0.435746 model2 loss : 0.024414
[11:11:10.455] iteration 10739 : model1 loss : 0.438038 model2 loss : 0.031145
[11:11:10.624] iteration 10740 : model1 loss : 0.439597 model2 loss : 0.026276
[11:11:10.790] iteration 10741 : model1 loss : 0.431263 model2 loss : 0.024231
[11:11:10.960] iteration 10742 : model1 loss : 0.435776 model2 loss : 0.022443
[11:11:11.129] iteration 10743 : model1 loss : 0.433574 model2 loss : 0.025800
[11:11:11.300] iteration 10744 : model1 loss : 0.435217 model2 loss : 0.028931
[11:11:11.467] iteration 10745 : model1 loss : 0.436549 model2 loss : 0.026110
[11:11:11.637] iteration 10746 : model1 loss : 0.441987 model2 loss : 0.031317
[11:11:11.803] iteration 10747 : model1 loss : 0.441505 model2 loss : 0.032850
[11:11:11.973] iteration 10748 : model1 loss : 0.438781 model2 loss : 0.027656
[11:11:12.143] iteration 10749 : model1 loss : 0.437474 model2 loss : 0.027520
[11:11:12.313] iteration 10750 : model1 loss : 0.434463 model2 loss : 0.022865
[11:11:12.481] iteration 10751 : model1 loss : 0.440369 model2 loss : 0.029034
[11:11:12.649] iteration 10752 : model1 loss : 0.433922 model2 loss : 0.025122
[11:11:12.817] iteration 10753 : model1 loss : 0.439850 model2 loss : 0.023905
[11:11:12.987] iteration 10754 : model1 loss : 0.443121 model2 loss : 0.032757
[11:11:13.158] iteration 10755 : model1 loss : 0.441626 model2 loss : 0.028727
[11:11:13.328] iteration 10756 : model1 loss : 0.435998 model2 loss : 0.026863
[11:11:13.493] iteration 10757 : model1 loss : 0.433204 model2 loss : 0.026464
[11:11:13.659] iteration 10758 : model1 loss : 0.434948 model2 loss : 0.024875
[11:11:15.633] iteration 10759 : model1 loss : 0.432451 model2 loss : 0.024528
[11:11:15.805] iteration 10760 : model1 loss : 0.432778 model2 loss : 0.025489
[11:11:15.975] iteration 10761 : model1 loss : 0.437030 model2 loss : 0.030089
[11:11:16.142] iteration 10762 : model1 loss : 0.435815 model2 loss : 0.026011
[11:11:16.334] iteration 10763 : model1 loss : 0.435921 model2 loss : 0.024970
[11:11:16.500] iteration 10764 : model1 loss : 0.437022 model2 loss : 0.027787
[11:11:16.668] iteration 10765 : model1 loss : 0.443406 model2 loss : 0.030518
[11:11:16.835] iteration 10766 : model1 loss : 0.436833 model2 loss : 0.025920
[11:11:17.004] iteration 10767 : model1 loss : 0.440766 model2 loss : 0.029291
[11:11:17.170] iteration 10768 : model1 loss : 0.439462 model2 loss : 0.029364
[11:11:17.340] iteration 10769 : model1 loss : 0.437562 model2 loss : 0.029391
[11:11:17.510] iteration 10770 : model1 loss : 0.436499 model2 loss : 0.027661
[11:11:17.678] iteration 10771 : model1 loss : 0.434011 model2 loss : 0.027506
[11:11:17.856] iteration 10772 : model1 loss : 0.438921 model2 loss : 0.028611
[11:11:18.024] iteration 10773 : model1 loss : 0.441504 model2 loss : 0.030102
[11:11:18.193] iteration 10774 : model1 loss : 0.436361 model2 loss : 0.025309
[11:11:18.362] iteration 10775 : model1 loss : 0.437719 model2 loss : 0.022962
[11:11:18.530] iteration 10776 : model1 loss : 0.437176 model2 loss : 0.027225
[11:11:18.699] iteration 10777 : model1 loss : 0.441685 model2 loss : 0.029133
[11:11:18.866] iteration 10778 : model1 loss : 0.439347 model2 loss : 0.029380
[11:11:19.034] iteration 10779 : model1 loss : 0.434177 model2 loss : 0.024644
[11:11:19.202] iteration 10780 : model1 loss : 0.435830 model2 loss : 0.026274
[11:11:19.383] iteration 10781 : model1 loss : 0.436203 model2 loss : 0.026951
[11:11:19.549] iteration 10782 : model1 loss : 0.441484 model2 loss : 0.025876
[11:11:19.719] iteration 10783 : model1 loss : 0.438420 model2 loss : 0.024156
[11:11:19.885] iteration 10784 : model1 loss : 0.432170 model2 loss : 0.024393
[11:11:20.054] iteration 10785 : model1 loss : 0.438913 model2 loss : 0.028545
[11:11:20.224] iteration 10786 : model1 loss : 0.439617 model2 loss : 0.027079
[11:11:20.395] iteration 10787 : model1 loss : 0.435844 model2 loss : 0.031237
[11:11:20.563] iteration 10788 : model1 loss : 0.437309 model2 loss : 0.024449
[11:11:20.732] iteration 10789 : model1 loss : 0.435735 model2 loss : 0.024840
[11:11:20.898] iteration 10790 : model1 loss : 0.435572 model2 loss : 0.022131
[11:11:21.066] iteration 10791 : model1 loss : 0.437379 model2 loss : 0.021761
[11:11:22.997] iteration 10792 : model1 loss : 0.436051 model2 loss : 0.026317
[11:11:23.164] iteration 10793 : model1 loss : 0.441946 model2 loss : 0.027191
[11:11:23.333] iteration 10794 : model1 loss : 0.437466 model2 loss : 0.026930
[11:11:23.501] iteration 10795 : model1 loss : 0.436575 model2 loss : 0.022964
[11:11:23.669] iteration 10796 : model1 loss : 0.437332 model2 loss : 0.027065
[11:11:23.834] iteration 10797 : model1 loss : 0.433513 model2 loss : 0.022959
[11:11:24.002] iteration 10798 : model1 loss : 0.438146 model2 loss : 0.026084
[11:11:24.170] iteration 10799 : model1 loss : 0.436303 model2 loss : 0.023498
[11:11:24.338] iteration 10800 : model1 loss : 0.438003 model2 loss : 0.025030
[11:11:24.509] iteration 10801 : model1 loss : 0.438811 model2 loss : 0.024134
[11:11:24.678] iteration 10802 : model1 loss : 0.438493 model2 loss : 0.026689
[11:11:24.858] iteration 10803 : model1 loss : 0.433884 model2 loss : 0.026645
[11:11:25.027] iteration 10804 : model1 loss : 0.434413 model2 loss : 0.023839
[11:11:25.193] iteration 10805 : model1 loss : 0.430241 model2 loss : 0.024432
[11:11:25.362] iteration 10806 : model1 loss : 0.435264 model2 loss : 0.023903
[11:11:25.532] iteration 10807 : model1 loss : 0.437970 model2 loss : 0.026002
[11:11:25.700] iteration 10808 : model1 loss : 0.438847 model2 loss : 0.024219
[11:11:25.869] iteration 10809 : model1 loss : 0.437453 model2 loss : 0.028035
[11:11:26.037] iteration 10810 : model1 loss : 0.433475 model2 loss : 0.024421
[11:11:26.204] iteration 10811 : model1 loss : 0.442268 model2 loss : 0.031674
[11:11:26.373] iteration 10812 : model1 loss : 0.439332 model2 loss : 0.025027
[11:11:26.541] iteration 10813 : model1 loss : 0.438781 model2 loss : 0.026091
[11:11:26.710] iteration 10814 : model1 loss : 0.437257 model2 loss : 0.025636
[11:11:26.875] iteration 10815 : model1 loss : 0.437177 model2 loss : 0.023227
[11:11:27.046] iteration 10816 : model1 loss : 0.436959 model2 loss : 0.026131
[11:11:27.215] iteration 10817 : model1 loss : 0.437878 model2 loss : 0.028050
[11:11:27.384] iteration 10818 : model1 loss : 0.437837 model2 loss : 0.026259
[11:11:27.577] iteration 10819 : model1 loss : 0.430779 model2 loss : 0.023012
[11:11:27.745] iteration 10820 : model1 loss : 0.437063 model2 loss : 0.026375
[11:11:27.912] iteration 10821 : model1 loss : 0.444216 model2 loss : 0.029894
[11:11:28.082] iteration 10822 : model1 loss : 0.437097 model2 loss : 0.023108
[11:11:28.247] iteration 10823 : model1 loss : 0.437885 model2 loss : 0.023240
[11:11:28.416] iteration 10824 : model1 loss : 0.428894 model2 loss : 0.023841
[11:11:30.328] iteration 10825 : model1 loss : 0.440115 model2 loss : 0.032229
[11:11:30.502] iteration 10826 : model1 loss : 0.435026 model2 loss : 0.024556
[11:11:30.672] iteration 10827 : model1 loss : 0.439819 model2 loss : 0.021149
[11:11:30.840] iteration 10828 : model1 loss : 0.438370 model2 loss : 0.024190
[11:11:31.009] iteration 10829 : model1 loss : 0.437479 model2 loss : 0.022906
[11:11:31.179] iteration 10830 : model1 loss : 0.435775 model2 loss : 0.027469
[11:11:31.349] iteration 10831 : model1 loss : 0.435134 model2 loss : 0.029778
[11:11:31.520] iteration 10832 : model1 loss : 0.442211 model2 loss : 0.039771
[11:11:31.690] iteration 10833 : model1 loss : 0.433339 model2 loss : 0.022825
[11:11:31.858] iteration 10834 : model1 loss : 0.438555 model2 loss : 0.023834
[11:11:32.026] iteration 10835 : model1 loss : 0.437513 model2 loss : 0.029583
[11:11:32.194] iteration 10836 : model1 loss : 0.433548 model2 loss : 0.024897
[11:11:32.361] iteration 10837 : model1 loss : 0.444075 model2 loss : 0.029396
[11:11:32.530] iteration 10838 : model1 loss : 0.435028 model2 loss : 0.024758
[11:11:32.698] iteration 10839 : model1 loss : 0.434859 model2 loss : 0.027176
[11:11:32.865] iteration 10840 : model1 loss : 0.434050 model2 loss : 0.023387
[11:11:33.047] iteration 10841 : model1 loss : 0.437145 model2 loss : 0.024447
[11:11:33.216] iteration 10842 : model1 loss : 0.433791 model2 loss : 0.026113
[11:11:33.384] iteration 10843 : model1 loss : 0.435708 model2 loss : 0.023106
[11:11:33.551] iteration 10844 : model1 loss : 0.435785 model2 loss : 0.026081
[11:11:33.723] iteration 10845 : model1 loss : 0.440154 model2 loss : 0.026350
[11:11:33.891] iteration 10846 : model1 loss : 0.439084 model2 loss : 0.024145
[11:11:34.062] iteration 10847 : model1 loss : 0.435146 model2 loss : 0.024271
[11:11:34.227] iteration 10848 : model1 loss : 0.436431 model2 loss : 0.026915
[11:11:34.397] iteration 10849 : model1 loss : 0.441009 model2 loss : 0.026685
[11:11:34.564] iteration 10850 : model1 loss : 0.432436 model2 loss : 0.024247
[11:11:34.732] iteration 10851 : model1 loss : 0.437065 model2 loss : 0.027586
[11:11:34.899] iteration 10852 : model1 loss : 0.435625 model2 loss : 0.022532
[11:11:35.069] iteration 10853 : model1 loss : 0.434704 model2 loss : 0.022738
[11:11:35.237] iteration 10854 : model1 loss : 0.438155 model2 loss : 0.024765
[11:11:35.406] iteration 10855 : model1 loss : 0.435016 model2 loss : 0.027018
[11:11:35.573] iteration 10856 : model1 loss : 0.437097 model2 loss : 0.026352
[11:11:35.741] iteration 10857 : model1 loss : 0.439020 model2 loss : 0.027394
[11:11:37.696] iteration 10858 : model1 loss : 0.434223 model2 loss : 0.022516
[11:11:37.863] iteration 10859 : model1 loss : 0.433777 model2 loss : 0.027849
[11:11:38.032] iteration 10860 : model1 loss : 0.436384 model2 loss : 0.025511
[11:11:38.199] iteration 10861 : model1 loss : 0.443317 model2 loss : 0.027605
[11:11:38.367] iteration 10862 : model1 loss : 0.437944 model2 loss : 0.026080
[11:11:38.535] iteration 10863 : model1 loss : 0.434827 model2 loss : 0.020995
[11:11:38.705] iteration 10864 : model1 loss : 0.432239 model2 loss : 0.023143
[11:11:38.872] iteration 10865 : model1 loss : 0.442822 model2 loss : 0.030506
[11:11:39.044] iteration 10866 : model1 loss : 0.435270 model2 loss : 0.019813
[11:11:39.211] iteration 10867 : model1 loss : 0.434965 model2 loss : 0.024672
[11:11:39.381] iteration 10868 : model1 loss : 0.441334 model2 loss : 0.027539
[11:11:39.547] iteration 10869 : model1 loss : 0.437852 model2 loss : 0.025978
[11:11:39.718] iteration 10870 : model1 loss : 0.439003 model2 loss : 0.024727
[11:11:39.886] iteration 10871 : model1 loss : 0.434809 model2 loss : 0.024046
[11:11:40.056] iteration 10872 : model1 loss : 0.436400 model2 loss : 0.024199
[11:11:40.222] iteration 10873 : model1 loss : 0.437958 model2 loss : 0.025125
[11:11:40.391] iteration 10874 : model1 loss : 0.439443 model2 loss : 0.027534
[11:11:40.559] iteration 10875 : model1 loss : 0.434495 model2 loss : 0.026131
[11:11:40.729] iteration 10876 : model1 loss : 0.437276 model2 loss : 0.025486
[11:11:40.902] iteration 10877 : model1 loss : 0.432298 model2 loss : 0.023228
[11:11:41.072] iteration 10878 : model1 loss : 0.438622 model2 loss : 0.025405
[11:11:41.239] iteration 10879 : model1 loss : 0.435393 model2 loss : 0.024371
[11:11:41.411] iteration 10880 : model1 loss : 0.435957 model2 loss : 0.023725
[11:11:41.579] iteration 10881 : model1 loss : 0.435953 model2 loss : 0.023025
[11:11:41.749] iteration 10882 : model1 loss : 0.438208 model2 loss : 0.026823
[11:11:41.917] iteration 10883 : model1 loss : 0.441993 model2 loss : 0.028238
[11:11:42.088] iteration 10884 : model1 loss : 0.435248 model2 loss : 0.025588
[11:11:42.259] iteration 10885 : model1 loss : 0.434464 model2 loss : 0.025450
[11:11:42.430] iteration 10886 : model1 loss : 0.433732 model2 loss : 0.023788
[11:11:42.596] iteration 10887 : model1 loss : 0.435493 model2 loss : 0.024546
[11:11:42.765] iteration 10888 : model1 loss : 0.436922 model2 loss : 0.025905
[11:11:42.933] iteration 10889 : model1 loss : 0.441907 model2 loss : 0.026283
[11:11:43.102] iteration 10890 : model1 loss : 0.435902 model2 loss : 0.026798
[11:11:45.034] iteration 10891 : model1 loss : 0.439368 model2 loss : 0.025245
[11:11:45.204] iteration 10892 : model1 loss : 0.436245 model2 loss : 0.025924
[11:11:45.376] iteration 10893 : model1 loss : 0.435839 model2 loss : 0.025341
[11:11:45.554] iteration 10894 : model1 loss : 0.436803 model2 loss : 0.024997
[11:11:45.724] iteration 10895 : model1 loss : 0.440627 model2 loss : 0.025610
[11:11:45.896] iteration 10896 : model1 loss : 0.437384 model2 loss : 0.023652
[11:11:46.064] iteration 10897 : model1 loss : 0.440053 model2 loss : 0.027349
[11:11:46.230] iteration 10898 : model1 loss : 0.435751 model2 loss : 0.027023
[11:11:46.404] iteration 10899 : model1 loss : 0.435427 model2 loss : 0.024608
[11:11:46.570] iteration 10900 : model1 loss : 0.435947 model2 loss : 0.024487
[11:11:46.737] iteration 10901 : model1 loss : 0.437044 model2 loss : 0.024711
[11:11:46.906] iteration 10902 : model1 loss : 0.434588 model2 loss : 0.025353
[11:11:47.074] iteration 10903 : model1 loss : 0.436117 model2 loss : 0.023901
[11:11:47.243] iteration 10904 : model1 loss : 0.439039 model2 loss : 0.025841
[11:11:47.413] iteration 10905 : model1 loss : 0.436821 model2 loss : 0.024650
[11:11:47.579] iteration 10906 : model1 loss : 0.437123 model2 loss : 0.023759
[11:11:47.767] iteration 10907 : model1 loss : 0.436492 model2 loss : 0.025447
[11:11:47.933] iteration 10908 : model1 loss : 0.441397 model2 loss : 0.029950
[11:11:48.105] iteration 10909 : model1 loss : 0.438163 model2 loss : 0.025116
[11:11:48.274] iteration 10910 : model1 loss : 0.435370 model2 loss : 0.024272
[11:11:48.445] iteration 10911 : model1 loss : 0.434693 model2 loss : 0.022179
[11:11:48.614] iteration 10912 : model1 loss : 0.440129 model2 loss : 0.028913
[11:11:48.785] iteration 10913 : model1 loss : 0.438231 model2 loss : 0.026523
[11:11:48.953] iteration 10914 : model1 loss : 0.432182 model2 loss : 0.020232
[11:11:49.123] iteration 10915 : model1 loss : 0.436560 model2 loss : 0.022894
[11:11:49.293] iteration 10916 : model1 loss : 0.439255 model2 loss : 0.026147
[11:11:49.461] iteration 10917 : model1 loss : 0.438363 model2 loss : 0.026394
[11:11:49.628] iteration 10918 : model1 loss : 0.436115 model2 loss : 0.022472
[11:11:49.797] iteration 10919 : model1 loss : 0.436213 model2 loss : 0.025301
[11:11:49.964] iteration 10920 : model1 loss : 0.432439 model2 loss : 0.022363
[11:11:50.132] iteration 10921 : model1 loss : 0.434871 model2 loss : 0.023550
[11:11:50.300] iteration 10922 : model1 loss : 0.441833 model2 loss : 0.027338
[11:11:50.470] iteration 10923 : model1 loss : 0.440177 model2 loss : 0.024615
[11:11:52.454] iteration 10924 : model1 loss : 0.438036 model2 loss : 0.023985
[11:11:52.627] iteration 10925 : model1 loss : 0.437104 model2 loss : 0.023967
[11:11:52.798] iteration 10926 : model1 loss : 0.446710 model2 loss : 0.022693
[11:11:52.967] iteration 10927 : model1 loss : 0.439926 model2 loss : 0.025104
[11:11:53.136] iteration 10928 : model1 loss : 0.439595 model2 loss : 0.026942
[11:11:53.306] iteration 10929 : model1 loss : 0.436757 model2 loss : 0.026163
[11:11:53.476] iteration 10930 : model1 loss : 0.435742 model2 loss : 0.030561
[11:11:53.643] iteration 10931 : model1 loss : 0.437944 model2 loss : 0.027799
[11:11:53.810] iteration 10932 : model1 loss : 0.437789 model2 loss : 0.023393
[11:11:53.977] iteration 10933 : model1 loss : 0.437536 model2 loss : 0.026663
[11:11:54.147] iteration 10934 : model1 loss : 0.437957 model2 loss : 0.021774
[11:11:54.318] iteration 10935 : model1 loss : 0.433232 model2 loss : 0.022660
[11:11:54.489] iteration 10936 : model1 loss : 0.433506 model2 loss : 0.022332
[11:11:54.655] iteration 10937 : model1 loss : 0.440692 model2 loss : 0.027228
[11:11:54.824] iteration 10938 : model1 loss : 0.444239 model2 loss : 0.031726
[11:11:54.991] iteration 10939 : model1 loss : 0.438028 model2 loss : 0.024198
[11:11:55.160] iteration 10940 : model1 loss : 0.437815 model2 loss : 0.025085
[11:11:55.332] iteration 10941 : model1 loss : 0.438905 model2 loss : 0.025122
[11:11:55.504] iteration 10942 : model1 loss : 0.438856 model2 loss : 0.026274
[11:11:55.671] iteration 10943 : model1 loss : 0.438630 model2 loss : 0.026063
[11:11:55.840] iteration 10944 : model1 loss : 0.431188 model2 loss : 0.024666
[11:11:56.011] iteration 10945 : model1 loss : 0.433830 model2 loss : 0.023482
[11:11:56.178] iteration 10946 : model1 loss : 0.436768 model2 loss : 0.023695
[11:11:56.347] iteration 10947 : model1 loss : 0.432247 model2 loss : 0.022875
[11:11:56.521] iteration 10948 : model1 loss : 0.442059 model2 loss : 0.028419
[11:11:56.689] iteration 10949 : model1 loss : 0.438633 model2 loss : 0.023411
[11:11:56.859] iteration 10950 : model1 loss : 0.440100 model2 loss : 0.025735
[11:11:57.028] iteration 10951 : model1 loss : 0.431500 model2 loss : 0.023650
[11:11:57.196] iteration 10952 : model1 loss : 0.434943 model2 loss : 0.024925
[11:11:57.364] iteration 10953 : model1 loss : 0.437174 model2 loss : 0.028397
[11:11:57.534] iteration 10954 : model1 loss : 0.440019 model2 loss : 0.025275
[11:11:57.701] iteration 10955 : model1 loss : 0.439673 model2 loss : 0.024297
[11:11:57.867] iteration 10956 : model1 loss : 0.437002 model2 loss : 0.024637
[11:11:59.781] iteration 10957 : model1 loss : 0.437121 model2 loss : 0.023574
[11:11:59.949] iteration 10958 : model1 loss : 0.438701 model2 loss : 0.025358
[11:12:00.123] iteration 10959 : model1 loss : 0.440262 model2 loss : 0.033221
[11:12:00.290] iteration 10960 : model1 loss : 0.438202 model2 loss : 0.026211
[11:12:00.459] iteration 10961 : model1 loss : 0.435893 model2 loss : 0.028827
[11:12:00.628] iteration 10962 : model1 loss : 0.436601 model2 loss : 0.025014
[11:12:00.799] iteration 10963 : model1 loss : 0.435775 model2 loss : 0.026536
[11:12:00.968] iteration 10964 : model1 loss : 0.439280 model2 loss : 0.024649
[11:12:01.137] iteration 10965 : model1 loss : 0.435304 model2 loss : 0.023744
[11:12:01.308] iteration 10966 : model1 loss : 0.438021 model2 loss : 0.022708
[11:12:01.476] iteration 10967 : model1 loss : 0.437146 model2 loss : 0.024028
[11:12:01.643] iteration 10968 : model1 loss : 0.440128 model2 loss : 0.028452
[11:12:01.820] iteration 10969 : model1 loss : 0.434780 model2 loss : 0.025147
[11:12:01.988] iteration 10970 : model1 loss : 0.435987 model2 loss : 0.023355
[11:12:02.157] iteration 10971 : model1 loss : 0.437305 model2 loss : 0.027016
[11:12:02.328] iteration 10972 : model1 loss : 0.435799 model2 loss : 0.027589
[11:12:02.500] iteration 10973 : model1 loss : 0.435569 model2 loss : 0.024250
[11:12:02.667] iteration 10974 : model1 loss : 0.442401 model2 loss : 0.031326
[11:12:02.838] iteration 10975 : model1 loss : 0.434636 model2 loss : 0.023650
[11:12:03.005] iteration 10976 : model1 loss : 0.436359 model2 loss : 0.024031
[11:12:03.194] iteration 10977 : model1 loss : 0.433704 model2 loss : 0.023829
[11:12:03.361] iteration 10978 : model1 loss : 0.435813 model2 loss : 0.023138
[11:12:03.531] iteration 10979 : model1 loss : 0.436556 model2 loss : 0.026451
[11:12:03.701] iteration 10980 : model1 loss : 0.437492 model2 loss : 0.027987
[11:12:03.872] iteration 10981 : model1 loss : 0.437917 model2 loss : 0.024427
[11:12:04.041] iteration 10982 : model1 loss : 0.437390 model2 loss : 0.022726
[11:12:04.207] iteration 10983 : model1 loss : 0.434058 model2 loss : 0.022119
[11:12:04.375] iteration 10984 : model1 loss : 0.439718 model2 loss : 0.024536
[11:12:04.545] iteration 10985 : model1 loss : 0.437072 model2 loss : 0.027176
[11:12:04.715] iteration 10986 : model1 loss : 0.440115 model2 loss : 0.027776
[11:12:04.884] iteration 10987 : model1 loss : 0.440366 model2 loss : 0.025792
[11:12:05.051] iteration 10988 : model1 loss : 0.430577 model2 loss : 0.022655
[11:12:05.220] iteration 10989 : model1 loss : 0.440244 model2 loss : 0.025233
[11:12:07.190] iteration 10990 : model1 loss : 0.434734 model2 loss : 0.022249
[11:12:07.358] iteration 10991 : model1 loss : 0.434209 model2 loss : 0.023886
[11:12:07.530] iteration 10992 : model1 loss : 0.438348 model2 loss : 0.024204
[11:12:07.711] iteration 10993 : model1 loss : 0.438595 model2 loss : 0.025633
[11:12:07.880] iteration 10994 : model1 loss : 0.435556 model2 loss : 0.026155
[11:12:08.048] iteration 10995 : model1 loss : 0.437389 model2 loss : 0.026202
[11:12:08.218] iteration 10996 : model1 loss : 0.434129 model2 loss : 0.025311
[11:12:08.386] iteration 10997 : model1 loss : 0.437768 model2 loss : 0.025951
[11:12:08.554] iteration 10998 : model1 loss : 0.434311 model2 loss : 0.023618
[11:12:08.721] iteration 10999 : model1 loss : 0.439190 model2 loss : 0.027773
[11:12:08.890] iteration 11000 : model1 loss : 0.429567 model2 loss : 0.024425
[11:12:17.197] iteration 11000 : model1_mean_dice : 0.880723 model1_mean_hd95 : 4.393526
[11:12:25.529] iteration 11000 : model2_mean_dice : 0.888136 model2_mean_hd95 : 5.048075
[11:12:25.703] iteration 11001 : model1 loss : 0.440157 model2 loss : 0.027990
[11:12:25.877] iteration 11002 : model1 loss : 0.438411 model2 loss : 0.026303
[11:12:26.042] iteration 11003 : model1 loss : 0.439981 model2 loss : 0.027602
[11:12:26.210] iteration 11004 : model1 loss : 0.441209 model2 loss : 0.028455
[11:12:26.379] iteration 11005 : model1 loss : 0.436044 model2 loss : 0.023742
[11:12:26.549] iteration 11006 : model1 loss : 0.434409 model2 loss : 0.022760
[11:12:26.714] iteration 11007 : model1 loss : 0.435466 model2 loss : 0.022070
[11:12:26.882] iteration 11008 : model1 loss : 0.442090 model2 loss : 0.028669
[11:12:27.047] iteration 11009 : model1 loss : 0.434563 model2 loss : 0.023469
[11:12:27.214] iteration 11010 : model1 loss : 0.439109 model2 loss : 0.026940
[11:12:27.382] iteration 11011 : model1 loss : 0.435536 model2 loss : 0.025545
[11:12:27.550] iteration 11012 : model1 loss : 0.438555 model2 loss : 0.025408
[11:12:27.715] iteration 11013 : model1 loss : 0.435861 model2 loss : 0.023980
[11:12:27.883] iteration 11014 : model1 loss : 0.435500 model2 loss : 0.025353
[11:12:28.050] iteration 11015 : model1 loss : 0.434200 model2 loss : 0.025133
[11:12:28.216] iteration 11016 : model1 loss : 0.438185 model2 loss : 0.026835
[11:12:28.384] iteration 11017 : model1 loss : 0.439448 model2 loss : 0.028458
[11:12:28.550] iteration 11018 : model1 loss : 0.440103 model2 loss : 0.027985
[11:12:28.717] iteration 11019 : model1 loss : 0.441260 model2 loss : 0.030021
[11:12:28.884] iteration 11020 : model1 loss : 0.439307 model2 loss : 0.028869
[11:12:29.051] iteration 11021 : model1 loss : 0.439192 model2 loss : 0.026012
[11:12:29.217] iteration 11022 : model1 loss : 0.437321 model2 loss : 0.022510
[11:12:31.173] iteration 11023 : model1 loss : 0.436256 model2 loss : 0.024476
[11:12:31.341] iteration 11024 : model1 loss : 0.437824 model2 loss : 0.025785
[11:12:31.515] iteration 11025 : model1 loss : 0.438773 model2 loss : 0.024386
[11:12:31.694] iteration 11026 : model1 loss : 0.433626 model2 loss : 0.023361
[11:12:31.861] iteration 11027 : model1 loss : 0.437913 model2 loss : 0.027862
[11:12:32.028] iteration 11028 : model1 loss : 0.435834 model2 loss : 0.024158
[11:12:32.195] iteration 11029 : model1 loss : 0.433569 model2 loss : 0.023671
[11:12:32.361] iteration 11030 : model1 loss : 0.436807 model2 loss : 0.025543
[11:12:32.530] iteration 11031 : model1 loss : 0.439918 model2 loss : 0.023296
[11:12:32.696] iteration 11032 : model1 loss : 0.436092 model2 loss : 0.027986
[11:12:32.864] iteration 11033 : model1 loss : 0.437004 model2 loss : 0.023897
[11:12:33.032] iteration 11034 : model1 loss : 0.437333 model2 loss : 0.027210
[11:12:33.200] iteration 11035 : model1 loss : 0.439589 model2 loss : 0.025002
[11:12:33.367] iteration 11036 : model1 loss : 0.439783 model2 loss : 0.026073
[11:12:33.540] iteration 11037 : model1 loss : 0.432613 model2 loss : 0.020704
[11:12:33.707] iteration 11038 : model1 loss : 0.436697 model2 loss : 0.022068
[11:12:33.876] iteration 11039 : model1 loss : 0.440582 model2 loss : 0.025854
[11:12:34.040] iteration 11040 : model1 loss : 0.434776 model2 loss : 0.025373
[11:12:34.208] iteration 11041 : model1 loss : 0.435638 model2 loss : 0.024984
[11:12:34.373] iteration 11042 : model1 loss : 0.435735 model2 loss : 0.025409
[11:12:34.545] iteration 11043 : model1 loss : 0.435815 model2 loss : 0.022033
[11:12:34.710] iteration 11044 : model1 loss : 0.432654 model2 loss : 0.022950
[11:12:34.881] iteration 11045 : model1 loss : 0.439838 model2 loss : 0.021830
[11:12:35.048] iteration 11046 : model1 loss : 0.437345 model2 loss : 0.024907
[11:12:35.214] iteration 11047 : model1 loss : 0.438214 model2 loss : 0.027739
[11:12:35.381] iteration 11048 : model1 loss : 0.437629 model2 loss : 0.024906
[11:12:35.555] iteration 11049 : model1 loss : 0.438335 model2 loss : 0.026018
[11:12:35.722] iteration 11050 : model1 loss : 0.433866 model2 loss : 0.022525
[11:12:35.893] iteration 11051 : model1 loss : 0.436298 model2 loss : 0.024784
[11:12:36.059] iteration 11052 : model1 loss : 0.434498 model2 loss : 0.026216
[11:12:36.231] iteration 11053 : model1 loss : 0.439289 model2 loss : 0.023925
[11:12:36.397] iteration 11054 : model1 loss : 0.439358 model2 loss : 0.026830
[11:12:36.563] iteration 11055 : model1 loss : 0.437849 model2 loss : 0.023445
[11:12:38.462] iteration 11056 : model1 loss : 0.440865 model2 loss : 0.024262
[11:12:38.627] iteration 11057 : model1 loss : 0.434793 model2 loss : 0.021356
[11:12:38.795] iteration 11058 : model1 loss : 0.437540 model2 loss : 0.023916
[11:12:38.961] iteration 11059 : model1 loss : 0.436184 model2 loss : 0.025050
[11:12:39.131] iteration 11060 : model1 loss : 0.436474 model2 loss : 0.024314
[11:12:39.296] iteration 11061 : model1 loss : 0.439343 model2 loss : 0.030027
[11:12:39.468] iteration 11062 : model1 loss : 0.437593 model2 loss : 0.022743
[11:12:39.634] iteration 11063 : model1 loss : 0.436817 model2 loss : 0.021438
[11:12:39.801] iteration 11064 : model1 loss : 0.441263 model2 loss : 0.025862
[11:12:39.967] iteration 11065 : model1 loss : 0.434900 model2 loss : 0.022525
[11:12:40.134] iteration 11066 : model1 loss : 0.432489 model2 loss : 0.023886
[11:12:40.300] iteration 11067 : model1 loss : 0.435632 model2 loss : 0.026762
[11:12:40.470] iteration 11068 : model1 loss : 0.437953 model2 loss : 0.023689
[11:12:40.637] iteration 11069 : model1 loss : 0.436823 model2 loss : 0.023428
[11:12:40.802] iteration 11070 : model1 loss : 0.434861 model2 loss : 0.036356
[11:12:40.969] iteration 11071 : model1 loss : 0.438872 model2 loss : 0.025251
[11:12:41.135] iteration 11072 : model1 loss : 0.438613 model2 loss : 0.023902
[11:12:41.302] iteration 11073 : model1 loss : 0.431222 model2 loss : 0.022145
[11:12:41.473] iteration 11074 : model1 loss : 0.434165 model2 loss : 0.021243
[11:12:41.639] iteration 11075 : model1 loss : 0.439204 model2 loss : 0.023403
[11:12:41.808] iteration 11076 : model1 loss : 0.436559 model2 loss : 0.028143
[11:12:41.975] iteration 11077 : model1 loss : 0.441117 model2 loss : 0.029964
[11:12:42.142] iteration 11078 : model1 loss : 0.435209 model2 loss : 0.023556
[11:12:42.307] iteration 11079 : model1 loss : 0.437199 model2 loss : 0.025817
[11:12:42.475] iteration 11080 : model1 loss : 0.435859 model2 loss : 0.024245
[11:12:42.640] iteration 11081 : model1 loss : 0.437484 model2 loss : 0.025469
[11:12:42.808] iteration 11082 : model1 loss : 0.437943 model2 loss : 0.028326
[11:12:42.974] iteration 11083 : model1 loss : 0.437515 model2 loss : 0.026264
[11:12:43.142] iteration 11084 : model1 loss : 0.433157 model2 loss : 0.024401
[11:12:43.308] iteration 11085 : model1 loss : 0.437854 model2 loss : 0.027846
[11:12:43.479] iteration 11086 : model1 loss : 0.438155 model2 loss : 0.027442
[11:12:43.645] iteration 11087 : model1 loss : 0.431822 model2 loss : 0.020436
[11:12:43.810] iteration 11088 : model1 loss : 0.443699 model2 loss : 0.032143
[11:12:45.730] iteration 11089 : model1 loss : 0.436641 model2 loss : 0.024748
[11:12:45.908] iteration 11090 : model1 loss : 0.437586 model2 loss : 0.023808
[11:12:46.078] iteration 11091 : model1 loss : 0.438460 model2 loss : 0.024361
[11:12:46.246] iteration 11092 : model1 loss : 0.437033 model2 loss : 0.025603
[11:12:46.413] iteration 11093 : model1 loss : 0.440076 model2 loss : 0.025306
[11:12:46.578] iteration 11094 : model1 loss : 0.437365 model2 loss : 0.022599
[11:12:46.746] iteration 11095 : model1 loss : 0.435850 model2 loss : 0.025519
[11:12:46.912] iteration 11096 : model1 loss : 0.436407 model2 loss : 0.023304
[11:12:47.081] iteration 11097 : model1 loss : 0.440510 model2 loss : 0.026984
[11:12:47.245] iteration 11098 : model1 loss : 0.435506 model2 loss : 0.023063
[11:12:47.414] iteration 11099 : model1 loss : 0.435898 model2 loss : 0.024821
[11:12:47.584] iteration 11100 : model1 loss : 0.437836 model2 loss : 0.024329
[11:12:47.750] iteration 11101 : model1 loss : 0.438158 model2 loss : 0.027447
[11:12:47.916] iteration 11102 : model1 loss : 0.435497 model2 loss : 0.024022
[11:12:48.083] iteration 11103 : model1 loss : 0.437567 model2 loss : 0.023854
[11:12:48.248] iteration 11104 : model1 loss : 0.437910 model2 loss : 0.026985
[11:12:48.417] iteration 11105 : model1 loss : 0.437955 model2 loss : 0.023082
[11:12:48.583] iteration 11106 : model1 loss : 0.440113 model2 loss : 0.027351
[11:12:48.757] iteration 11107 : model1 loss : 0.437615 model2 loss : 0.024100
[11:12:48.923] iteration 11108 : model1 loss : 0.435209 model2 loss : 0.026878
[11:12:49.094] iteration 11109 : model1 loss : 0.436422 model2 loss : 0.026584
[11:12:49.260] iteration 11110 : model1 loss : 0.436897 model2 loss : 0.024590
[11:12:49.430] iteration 11111 : model1 loss : 0.435664 model2 loss : 0.025868
[11:12:49.595] iteration 11112 : model1 loss : 0.432015 model2 loss : 0.022644
[11:12:49.765] iteration 11113 : model1 loss : 0.439649 model2 loss : 0.026208
[11:12:49.931] iteration 11114 : model1 loss : 0.430929 model2 loss : 0.021742
[11:12:50.100] iteration 11115 : model1 loss : 0.437500 model2 loss : 0.025815
[11:12:50.267] iteration 11116 : model1 loss : 0.435301 model2 loss : 0.024663
[11:12:50.438] iteration 11117 : model1 loss : 0.436122 model2 loss : 0.025186
[11:12:50.604] iteration 11118 : model1 loss : 0.435063 model2 loss : 0.025928
[11:12:50.774] iteration 11119 : model1 loss : 0.442903 model2 loss : 0.024755
[11:12:50.939] iteration 11120 : model1 loss : 0.438981 model2 loss : 0.026649
[11:12:51.105] iteration 11121 : model1 loss : 0.434174 model2 loss : 0.024364
[11:12:53.002] iteration 11122 : model1 loss : 0.439222 model2 loss : 0.025847
[11:12:53.168] iteration 11123 : model1 loss : 0.437908 model2 loss : 0.025624
[11:12:53.342] iteration 11124 : model1 loss : 0.438752 model2 loss : 0.025773
[11:12:53.512] iteration 11125 : model1 loss : 0.437079 model2 loss : 0.025183
[11:12:53.680] iteration 11126 : model1 loss : 0.431478 model2 loss : 0.023248
[11:12:53.856] iteration 11127 : model1 loss : 0.436120 model2 loss : 0.023119
[11:12:54.025] iteration 11128 : model1 loss : 0.435685 model2 loss : 0.023639
[11:12:54.190] iteration 11129 : model1 loss : 0.437584 model2 loss : 0.023168
[11:12:54.359] iteration 11130 : model1 loss : 0.438253 model2 loss : 0.024196
[11:12:54.526] iteration 11131 : model1 loss : 0.438339 model2 loss : 0.025225
[11:12:54.693] iteration 11132 : model1 loss : 0.436473 model2 loss : 0.025179
[11:12:54.860] iteration 11133 : model1 loss : 0.433196 model2 loss : 0.022893
[11:12:55.028] iteration 11134 : model1 loss : 0.440584 model2 loss : 0.028067
[11:12:55.194] iteration 11135 : model1 loss : 0.436283 model2 loss : 0.023855
[11:12:55.363] iteration 11136 : model1 loss : 0.438845 model2 loss : 0.027031
[11:12:55.531] iteration 11137 : model1 loss : 0.437202 model2 loss : 0.023239
[11:12:55.701] iteration 11138 : model1 loss : 0.437212 model2 loss : 0.024525
[11:12:55.868] iteration 11139 : model1 loss : 0.435576 model2 loss : 0.026792
[11:12:56.036] iteration 11140 : model1 loss : 0.433526 model2 loss : 0.023137
[11:12:56.204] iteration 11141 : model1 loss : 0.436691 model2 loss : 0.023572
[11:12:56.371] iteration 11142 : model1 loss : 0.438647 model2 loss : 0.026333
[11:12:56.538] iteration 11143 : model1 loss : 0.432345 model2 loss : 0.024660
[11:12:56.711] iteration 11144 : model1 loss : 0.438038 model2 loss : 0.029654
[11:12:56.878] iteration 11145 : model1 loss : 0.436377 model2 loss : 0.026279
[11:12:57.047] iteration 11146 : model1 loss : 0.435042 model2 loss : 0.025436
[11:12:57.213] iteration 11147 : model1 loss : 0.435069 model2 loss : 0.021634
[11:12:57.385] iteration 11148 : model1 loss : 0.436058 model2 loss : 0.025310
[11:12:57.550] iteration 11149 : model1 loss : 0.443015 model2 loss : 0.028424
[11:12:57.717] iteration 11150 : model1 loss : 0.437389 model2 loss : 0.027362
[11:12:57.883] iteration 11151 : model1 loss : 0.437739 model2 loss : 0.026532
[11:12:58.052] iteration 11152 : model1 loss : 0.436138 model2 loss : 0.025077
[11:12:58.218] iteration 11153 : model1 loss : 0.442749 model2 loss : 0.031036
[11:12:58.386] iteration 11154 : model1 loss : 0.435964 model2 loss : 0.021564
[11:13:00.322] iteration 11155 : model1 loss : 0.436023 model2 loss : 0.025917
[11:13:00.491] iteration 11156 : model1 loss : 0.438580 model2 loss : 0.026375
[11:13:00.662] iteration 11157 : model1 loss : 0.434994 model2 loss : 0.022441
[11:13:00.830] iteration 11158 : model1 loss : 0.438100 model2 loss : 0.023402
[11:13:01.001] iteration 11159 : model1 loss : 0.437739 model2 loss : 0.022896
[11:13:01.167] iteration 11160 : model1 loss : 0.433624 model2 loss : 0.022183
[11:13:01.335] iteration 11161 : model1 loss : 0.436153 model2 loss : 0.025004
[11:13:01.508] iteration 11162 : model1 loss : 0.437140 model2 loss : 0.024177
[11:13:01.676] iteration 11163 : model1 loss : 0.431394 model2 loss : 0.021278
[11:13:01.841] iteration 11164 : model1 loss : 0.438461 model2 loss : 0.023129
[11:13:02.009] iteration 11165 : model1 loss : 0.440602 model2 loss : 0.024413
[11:13:02.174] iteration 11166 : model1 loss : 0.434968 model2 loss : 0.022594
[11:13:02.343] iteration 11167 : model1 loss : 0.437717 model2 loss : 0.022763
[11:13:02.512] iteration 11168 : model1 loss : 0.433583 model2 loss : 0.023199
[11:13:02.681] iteration 11169 : model1 loss : 0.434628 model2 loss : 0.022224
[11:13:02.849] iteration 11170 : model1 loss : 0.435058 model2 loss : 0.024846
[11:13:03.015] iteration 11171 : model1 loss : 0.437270 model2 loss : 0.028008
[11:13:03.183] iteration 11172 : model1 loss : 0.433436 model2 loss : 0.025430
[11:13:03.352] iteration 11173 : model1 loss : 0.437482 model2 loss : 0.027238
[11:13:03.523] iteration 11174 : model1 loss : 0.441782 model2 loss : 0.028481
[11:13:03.691] iteration 11175 : model1 loss : 0.438562 model2 loss : 0.027942
[11:13:03.858] iteration 11176 : model1 loss : 0.444908 model2 loss : 0.034723
[11:13:04.027] iteration 11177 : model1 loss : 0.430895 model2 loss : 0.026013
[11:13:04.195] iteration 11178 : model1 loss : 0.439420 model2 loss : 0.030908
[11:13:04.363] iteration 11179 : model1 loss : 0.439174 model2 loss : 0.027732
[11:13:04.532] iteration 11180 : model1 loss : 0.436303 model2 loss : 0.026428
[11:13:04.702] iteration 11181 : model1 loss : 0.439978 model2 loss : 0.023441
[11:13:04.869] iteration 11182 : model1 loss : 0.437655 model2 loss : 0.024443
[11:13:05.035] iteration 11183 : model1 loss : 0.437350 model2 loss : 0.024950
[11:13:05.205] iteration 11184 : model1 loss : 0.433559 model2 loss : 0.025157
[11:13:05.373] iteration 11185 : model1 loss : 0.438907 model2 loss : 0.025876
[11:13:05.541] iteration 11186 : model1 loss : 0.433877 model2 loss : 0.025518
[11:13:05.708] iteration 11187 : model1 loss : 0.436752 model2 loss : 0.023260
[11:13:07.637] iteration 11188 : model1 loss : 0.441596 model2 loss : 0.027911
[11:13:07.809] iteration 11189 : model1 loss : 0.435798 model2 loss : 0.024944
[11:13:07.981] iteration 11190 : model1 loss : 0.441625 model2 loss : 0.030390
[11:13:08.149] iteration 11191 : model1 loss : 0.432897 model2 loss : 0.024631
[11:13:08.318] iteration 11192 : model1 loss : 0.437524 model2 loss : 0.025929
[11:13:08.486] iteration 11193 : model1 loss : 0.437411 model2 loss : 0.025304
[11:13:08.655] iteration 11194 : model1 loss : 0.437913 model2 loss : 0.024869
[11:13:08.822] iteration 11195 : model1 loss : 0.436586 model2 loss : 0.023587
[11:13:08.993] iteration 11196 : model1 loss : 0.434074 model2 loss : 0.022939
[11:13:09.160] iteration 11197 : model1 loss : 0.434756 model2 loss : 0.025629
[11:13:09.330] iteration 11198 : model1 loss : 0.441329 model2 loss : 0.026298
[11:13:09.503] iteration 11199 : model1 loss : 0.433182 model2 loss : 0.022667
[11:13:09.672] iteration 11200 : model1 loss : 0.439115 model2 loss : 0.024333
[11:13:09.840] iteration 11201 : model1 loss : 0.437775 model2 loss : 0.027482
[11:13:10.023] iteration 11202 : model1 loss : 0.434960 model2 loss : 0.025314
[11:13:10.192] iteration 11203 : model1 loss : 0.438019 model2 loss : 0.022426
[11:13:10.360] iteration 11204 : model1 loss : 0.436849 model2 loss : 0.023320
[11:13:10.529] iteration 11205 : model1 loss : 0.439953 model2 loss : 0.024689
[11:13:10.697] iteration 11206 : model1 loss : 0.441140 model2 loss : 0.027075
[11:13:10.866] iteration 11207 : model1 loss : 0.437380 model2 loss : 0.025114
[11:13:11.036] iteration 11208 : model1 loss : 0.437903 model2 loss : 0.024196
[11:13:11.205] iteration 11209 : model1 loss : 0.437379 model2 loss : 0.026064
[11:13:11.376] iteration 11210 : model1 loss : 0.431746 model2 loss : 0.021376
[11:13:11.547] iteration 11211 : model1 loss : 0.434142 model2 loss : 0.026502
[11:13:11.716] iteration 11212 : model1 loss : 0.434326 model2 loss : 0.022211
[11:13:11.884] iteration 11213 : model1 loss : 0.438232 model2 loss : 0.026090
[11:13:12.054] iteration 11214 : model1 loss : 0.438151 model2 loss : 0.026168
[11:13:12.221] iteration 11215 : model1 loss : 0.432198 model2 loss : 0.024217
[11:13:12.389] iteration 11216 : model1 loss : 0.434006 model2 loss : 0.025858
[11:13:12.557] iteration 11217 : model1 loss : 0.438608 model2 loss : 0.027798
[11:13:12.724] iteration 11218 : model1 loss : 0.433200 model2 loss : 0.021548
[11:13:12.889] iteration 11219 : model1 loss : 0.438158 model2 loss : 0.024755
[11:13:13.056] iteration 11220 : model1 loss : 0.436413 model2 loss : 0.026335
[11:13:15.009] iteration 11221 : model1 loss : 0.434797 model2 loss : 0.024351
[11:13:15.174] iteration 11222 : model1 loss : 0.436125 model2 loss : 0.025093
[11:13:15.345] iteration 11223 : model1 loss : 0.434720 model2 loss : 0.025638
[11:13:15.515] iteration 11224 : model1 loss : 0.436276 model2 loss : 0.024796
[11:13:15.684] iteration 11225 : model1 loss : 0.441086 model2 loss : 0.028346
[11:13:15.851] iteration 11226 : model1 loss : 0.441590 model2 loss : 0.024602
[11:13:16.020] iteration 11227 : model1 loss : 0.438859 model2 loss : 0.025832
[11:13:16.188] iteration 11228 : model1 loss : 0.434736 model2 loss : 0.024012
[11:13:16.357] iteration 11229 : model1 loss : 0.435770 model2 loss : 0.025950
[11:13:16.531] iteration 11230 : model1 loss : 0.435566 model2 loss : 0.026302
[11:13:16.700] iteration 11231 : model1 loss : 0.438186 model2 loss : 0.027307
[11:13:16.868] iteration 11232 : model1 loss : 0.434736 model2 loss : 0.024463
[11:13:17.036] iteration 11233 : model1 loss : 0.437446 model2 loss : 0.027618
[11:13:17.204] iteration 11234 : model1 loss : 0.435603 model2 loss : 0.025812
[11:13:17.372] iteration 11235 : model1 loss : 0.433544 model2 loss : 0.025466
[11:13:17.542] iteration 11236 : model1 loss : 0.435497 model2 loss : 0.027379
[11:13:17.713] iteration 11237 : model1 loss : 0.436943 model2 loss : 0.024980
[11:13:17.885] iteration 11238 : model1 loss : 0.437504 model2 loss : 0.025870
[11:13:18.054] iteration 11239 : model1 loss : 0.439839 model2 loss : 0.026670
[11:13:18.222] iteration 11240 : model1 loss : 0.435695 model2 loss : 0.024929
[11:13:18.392] iteration 11241 : model1 loss : 0.433867 model2 loss : 0.022300
[11:13:18.562] iteration 11242 : model1 loss : 0.437709 model2 loss : 0.026249
[11:13:18.731] iteration 11243 : model1 loss : 0.436134 model2 loss : 0.022596
[11:13:18.900] iteration 11244 : model1 loss : 0.437511 model2 loss : 0.027507
[11:13:19.067] iteration 11245 : model1 loss : 0.438043 model2 loss : 0.026228
[11:13:19.235] iteration 11246 : model1 loss : 0.440031 model2 loss : 0.027873
[11:13:19.405] iteration 11247 : model1 loss : 0.435672 model2 loss : 0.023259
[11:13:19.570] iteration 11248 : model1 loss : 0.440881 model2 loss : 0.028118
[11:13:19.740] iteration 11249 : model1 loss : 0.439087 model2 loss : 0.029323
[11:13:19.906] iteration 11250 : model1 loss : 0.436912 model2 loss : 0.024235
[11:13:20.077] iteration 11251 : model1 loss : 0.437454 model2 loss : 0.026983
[11:13:20.244] iteration 11252 : model1 loss : 0.431046 model2 loss : 0.023902
[11:13:20.411] iteration 11253 : model1 loss : 0.440282 model2 loss : 0.027438
[11:13:22.342] iteration 11254 : model1 loss : 0.439022 model2 loss : 0.024982
[11:13:22.519] iteration 11255 : model1 loss : 0.438739 model2 loss : 0.027530
[11:13:22.688] iteration 11256 : model1 loss : 0.431820 model2 loss : 0.026360
[11:13:22.854] iteration 11257 : model1 loss : 0.434956 model2 loss : 0.026643
[11:13:23.026] iteration 11258 : model1 loss : 0.440262 model2 loss : 0.025068
[11:13:23.194] iteration 11259 : model1 loss : 0.439016 model2 loss : 0.024919
[11:13:23.362] iteration 11260 : model1 loss : 0.438674 model2 loss : 0.031312
[11:13:23.533] iteration 11261 : model1 loss : 0.433594 model2 loss : 0.023613
[11:13:23.701] iteration 11262 : model1 loss : 0.434705 model2 loss : 0.025437
[11:13:23.866] iteration 11263 : model1 loss : 0.436299 model2 loss : 0.025974
[11:13:24.035] iteration 11264 : model1 loss : 0.437799 model2 loss : 0.023502
[11:13:24.203] iteration 11265 : model1 loss : 0.440714 model2 loss : 0.025795
[11:13:24.372] iteration 11266 : model1 loss : 0.440245 model2 loss : 0.026238
[11:13:24.542] iteration 11267 : model1 loss : 0.441163 model2 loss : 0.024881
[11:13:24.711] iteration 11268 : model1 loss : 0.439734 model2 loss : 0.026121
[11:13:24.879] iteration 11269 : model1 loss : 0.430748 model2 loss : 0.021536
[11:13:25.048] iteration 11270 : model1 loss : 0.432651 model2 loss : 0.022089
[11:13:25.216] iteration 11271 : model1 loss : 0.435141 model2 loss : 0.026955
[11:13:25.385] iteration 11272 : model1 loss : 0.440253 model2 loss : 0.034082
[11:13:25.557] iteration 11273 : model1 loss : 0.441542 model2 loss : 0.028696
[11:13:25.725] iteration 11274 : model1 loss : 0.438953 model2 loss : 0.029882
[11:13:25.896] iteration 11275 : model1 loss : 0.432479 model2 loss : 0.025237
[11:13:26.065] iteration 11276 : model1 loss : 0.431719 model2 loss : 0.021302
[11:13:26.233] iteration 11277 : model1 loss : 0.433630 model2 loss : 0.023543
[11:13:26.402] iteration 11278 : model1 loss : 0.441010 model2 loss : 0.024204
[11:13:26.574] iteration 11279 : model1 loss : 0.438227 model2 loss : 0.024101
[11:13:26.745] iteration 11280 : model1 loss : 0.436034 model2 loss : 0.027522
[11:13:26.913] iteration 11281 : model1 loss : 0.435804 model2 loss : 0.026750
[11:13:27.083] iteration 11282 : model1 loss : 0.438436 model2 loss : 0.026050
[11:13:27.250] iteration 11283 : model1 loss : 0.440173 model2 loss : 0.026025
[11:13:27.420] iteration 11284 : model1 loss : 0.435641 model2 loss : 0.026930
[11:13:27.586] iteration 11285 : model1 loss : 0.442594 model2 loss : 0.027663
[11:13:27.754] iteration 11286 : model1 loss : 0.441302 model2 loss : 0.028928
[11:13:29.718] iteration 11287 : model1 loss : 0.434569 model2 loss : 0.026367
[11:13:29.884] iteration 11288 : model1 loss : 0.437534 model2 loss : 0.020608
[11:13:30.055] iteration 11289 : model1 loss : 0.433396 model2 loss : 0.023719
[11:13:30.222] iteration 11290 : model1 loss : 0.438989 model2 loss : 0.024980
[11:13:30.391] iteration 11291 : model1 loss : 0.439993 model2 loss : 0.024899
[11:13:30.561] iteration 11292 : model1 loss : 0.432366 model2 loss : 0.026388
[11:13:30.729] iteration 11293 : model1 loss : 0.441725 model2 loss : 0.028013
[11:13:30.899] iteration 11294 : model1 loss : 0.435323 model2 loss : 0.024988
[11:13:31.069] iteration 11295 : model1 loss : 0.436723 model2 loss : 0.021724
[11:13:31.234] iteration 11296 : model1 loss : 0.434910 model2 loss : 0.022342
[11:13:31.405] iteration 11297 : model1 loss : 0.436237 model2 loss : 0.025510
[11:13:31.576] iteration 11298 : model1 loss : 0.439657 model2 loss : 0.025194
[11:13:31.744] iteration 11299 : model1 loss : 0.441810 model2 loss : 0.028207
[11:13:31.911] iteration 11300 : model1 loss : 0.441190 model2 loss : 0.026187
[11:13:32.080] iteration 11301 : model1 loss : 0.438692 model2 loss : 0.028431
[11:13:32.245] iteration 11302 : model1 loss : 0.438672 model2 loss : 0.023291
[11:13:32.415] iteration 11303 : model1 loss : 0.435639 model2 loss : 0.023870
[11:13:32.586] iteration 11304 : model1 loss : 0.440952 model2 loss : 0.026695
[11:13:32.753] iteration 11305 : model1 loss : 0.436459 model2 loss : 0.024576
[11:13:32.918] iteration 11306 : model1 loss : 0.437074 model2 loss : 0.023198
[11:13:33.087] iteration 11307 : model1 loss : 0.438244 model2 loss : 0.026012
[11:13:33.253] iteration 11308 : model1 loss : 0.432649 model2 loss : 0.023893
[11:13:33.421] iteration 11309 : model1 loss : 0.437906 model2 loss : 0.023851
[11:13:33.591] iteration 11310 : model1 loss : 0.435828 model2 loss : 0.028260
[11:13:33.759] iteration 11311 : model1 loss : 0.431226 model2 loss : 0.022263
[11:13:33.928] iteration 11312 : model1 loss : 0.444213 model2 loss : 0.029327
[11:13:34.098] iteration 11313 : model1 loss : 0.436751 model2 loss : 0.024075
[11:13:34.265] iteration 11314 : model1 loss : 0.435165 model2 loss : 0.021587
[11:13:34.433] iteration 11315 : model1 loss : 0.434007 model2 loss : 0.027630
[11:13:34.599] iteration 11316 : model1 loss : 0.440270 model2 loss : 0.027314
[11:13:34.768] iteration 11317 : model1 loss : 0.436458 model2 loss : 0.028731
[11:13:34.933] iteration 11318 : model1 loss : 0.434239 model2 loss : 0.023299
[11:13:35.101] iteration 11319 : model1 loss : 0.439027 model2 loss : 0.031784
[11:13:37.018] iteration 11320 : model1 loss : 0.437354 model2 loss : 0.026167
[11:13:37.190] iteration 11321 : model1 loss : 0.437834 model2 loss : 0.022030
[11:13:37.361] iteration 11322 : model1 loss : 0.431719 model2 loss : 0.024414
[11:13:37.529] iteration 11323 : model1 loss : 0.443659 model2 loss : 0.035580
[11:13:37.700] iteration 11324 : model1 loss : 0.436238 model2 loss : 0.025070
[11:13:37.867] iteration 11325 : model1 loss : 0.443003 model2 loss : 0.030656
[11:13:38.039] iteration 11326 : model1 loss : 0.438734 model2 loss : 0.029315
[11:13:38.204] iteration 11327 : model1 loss : 0.438705 model2 loss : 0.027665
[11:13:38.374] iteration 11328 : model1 loss : 0.434231 model2 loss : 0.025107
[11:13:38.543] iteration 11329 : model1 loss : 0.439050 model2 loss : 0.025055
[11:13:38.714] iteration 11330 : model1 loss : 0.437138 model2 loss : 0.023242
[11:13:38.880] iteration 11331 : model1 loss : 0.437052 model2 loss : 0.023817
[11:13:39.049] iteration 11332 : model1 loss : 0.434007 model2 loss : 0.022122
[11:13:39.216] iteration 11333 : model1 loss : 0.435534 model2 loss : 0.024618
[11:13:39.385] iteration 11334 : model1 loss : 0.436218 model2 loss : 0.024893
[11:13:39.553] iteration 11335 : model1 loss : 0.436255 model2 loss : 0.023058
[11:13:39.722] iteration 11336 : model1 loss : 0.436760 model2 loss : 0.023356
[11:13:39.890] iteration 11337 : model1 loss : 0.442656 model2 loss : 0.032539
[11:13:40.057] iteration 11338 : model1 loss : 0.436925 model2 loss : 0.028041
[11:13:40.224] iteration 11339 : model1 loss : 0.437774 model2 loss : 0.023130
[11:13:40.394] iteration 11340 : model1 loss : 0.433687 model2 loss : 0.021812
[11:13:40.570] iteration 11341 : model1 loss : 0.437868 model2 loss : 0.024729
[11:13:40.737] iteration 11342 : model1 loss : 0.439246 model2 loss : 0.024846
[11:13:40.904] iteration 11343 : model1 loss : 0.436249 model2 loss : 0.024486
[11:13:41.072] iteration 11344 : model1 loss : 0.433497 model2 loss : 0.021791
[11:13:41.239] iteration 11345 : model1 loss : 0.435730 model2 loss : 0.024992
[11:13:41.407] iteration 11346 : model1 loss : 0.441018 model2 loss : 0.027281
[11:13:41.579] iteration 11347 : model1 loss : 0.433918 model2 loss : 0.024740
[11:13:41.748] iteration 11348 : model1 loss : 0.437374 model2 loss : 0.024442
[11:13:41.916] iteration 11349 : model1 loss : 0.435062 model2 loss : 0.027296
[11:13:42.084] iteration 11350 : model1 loss : 0.436253 model2 loss : 0.023433
[11:13:42.249] iteration 11351 : model1 loss : 0.435295 model2 loss : 0.025550
[11:13:42.415] iteration 11352 : model1 loss : 0.434445 model2 loss : 0.025151
[11:13:44.325] iteration 11353 : model1 loss : 0.439493 model2 loss : 0.021457
[11:13:44.493] iteration 11354 : model1 loss : 0.442765 model2 loss : 0.031160
[11:13:44.662] iteration 11355 : model1 loss : 0.436605 model2 loss : 0.026143
[11:13:44.828] iteration 11356 : model1 loss : 0.439434 model2 loss : 0.031573
[11:13:44.996] iteration 11357 : model1 loss : 0.439688 model2 loss : 0.024326
[11:13:45.161] iteration 11358 : model1 loss : 0.437607 model2 loss : 0.024811
[11:13:45.328] iteration 11359 : model1 loss : 0.433335 model2 loss : 0.023022
[11:13:45.495] iteration 11360 : model1 loss : 0.437711 model2 loss : 0.025424
[11:13:45.663] iteration 11361 : model1 loss : 0.436010 model2 loss : 0.022035
[11:13:45.833] iteration 11362 : model1 loss : 0.438794 model2 loss : 0.024439
[11:13:46.002] iteration 11363 : model1 loss : 0.432144 model2 loss : 0.020073
[11:13:46.170] iteration 11364 : model1 loss : 0.437806 model2 loss : 0.025468
[11:13:46.338] iteration 11365 : model1 loss : 0.434889 model2 loss : 0.022555
[11:13:46.506] iteration 11366 : model1 loss : 0.437225 model2 loss : 0.022172
[11:13:46.674] iteration 11367 : model1 loss : 0.438569 model2 loss : 0.029951
[11:13:46.841] iteration 11368 : model1 loss : 0.437535 model2 loss : 0.026113
[11:13:47.012] iteration 11369 : model1 loss : 0.435653 model2 loss : 0.023566
[11:13:47.177] iteration 11370 : model1 loss : 0.435507 model2 loss : 0.022351
[11:13:47.346] iteration 11371 : model1 loss : 0.438011 model2 loss : 0.023959
[11:13:47.516] iteration 11372 : model1 loss : 0.434411 model2 loss : 0.027184
[11:13:47.686] iteration 11373 : model1 loss : 0.436278 model2 loss : 0.024116
[11:13:47.851] iteration 11374 : model1 loss : 0.437553 model2 loss : 0.025479
[11:13:48.020] iteration 11375 : model1 loss : 0.437559 model2 loss : 0.021606
[11:13:48.188] iteration 11376 : model1 loss : 0.433361 model2 loss : 0.024730
[11:13:48.357] iteration 11377 : model1 loss : 0.437143 model2 loss : 0.027963
[11:13:48.528] iteration 11378 : model1 loss : 0.436353 model2 loss : 0.022433
[11:13:48.696] iteration 11379 : model1 loss : 0.433804 model2 loss : 0.022998
[11:13:48.863] iteration 11380 : model1 loss : 0.435255 model2 loss : 0.024925
[11:13:49.030] iteration 11381 : model1 loss : 0.437173 model2 loss : 0.028031
[11:13:49.198] iteration 11382 : model1 loss : 0.436258 model2 loss : 0.024176
[11:13:49.365] iteration 11383 : model1 loss : 0.436653 model2 loss : 0.024980
[11:13:49.533] iteration 11384 : model1 loss : 0.433255 model2 loss : 0.022274
[11:13:49.700] iteration 11385 : model1 loss : 0.436698 model2 loss : 0.024750
[11:13:51.635] iteration 11386 : model1 loss : 0.433807 model2 loss : 0.025075
[11:13:51.801] iteration 11387 : model1 loss : 0.438756 model2 loss : 0.026636
[11:13:51.972] iteration 11388 : model1 loss : 0.440799 model2 loss : 0.028232
[11:13:52.139] iteration 11389 : model1 loss : 0.437523 model2 loss : 0.027834
[11:13:52.306] iteration 11390 : model1 loss : 0.434605 model2 loss : 0.023654
[11:13:52.474] iteration 11391 : model1 loss : 0.437840 model2 loss : 0.025518
[11:13:52.641] iteration 11392 : model1 loss : 0.439678 model2 loss : 0.027931
[11:13:52.808] iteration 11393 : model1 loss : 0.429755 model2 loss : 0.022452
[11:13:52.977] iteration 11394 : model1 loss : 0.437828 model2 loss : 0.026047
[11:13:53.144] iteration 11395 : model1 loss : 0.436767 model2 loss : 0.022092
[11:13:53.314] iteration 11396 : model1 loss : 0.439717 model2 loss : 0.024673
[11:13:53.480] iteration 11397 : model1 loss : 0.437221 model2 loss : 0.022073
[11:13:53.649] iteration 11398 : model1 loss : 0.436334 model2 loss : 0.027339
[11:13:53.817] iteration 11399 : model1 loss : 0.436628 model2 loss : 0.023350
[11:13:53.987] iteration 11400 : model1 loss : 0.432343 model2 loss : 0.023255
[11:13:54.154] iteration 11401 : model1 loss : 0.437390 model2 loss : 0.021636
[11:13:54.324] iteration 11402 : model1 loss : 0.437325 model2 loss : 0.025573
[11:13:54.491] iteration 11403 : model1 loss : 0.432869 model2 loss : 0.021761
[11:13:54.661] iteration 11404 : model1 loss : 0.441716 model2 loss : 0.031113
[11:13:54.827] iteration 11405 : model1 loss : 0.435061 model2 loss : 0.024466
[11:13:54.996] iteration 11406 : model1 loss : 0.438667 model2 loss : 0.025162
[11:13:55.163] iteration 11407 : model1 loss : 0.437134 model2 loss : 0.026656
[11:13:55.334] iteration 11408 : model1 loss : 0.439942 model2 loss : 0.028159
[11:13:55.502] iteration 11409 : model1 loss : 0.437668 model2 loss : 0.024305
[11:13:55.670] iteration 11410 : model1 loss : 0.433433 model2 loss : 0.023634
[11:13:55.840] iteration 11411 : model1 loss : 0.438194 model2 loss : 0.025571
[11:13:56.010] iteration 11412 : model1 loss : 0.431856 model2 loss : 0.024950
[11:13:56.177] iteration 11413 : model1 loss : 0.439365 model2 loss : 0.023083
[11:13:56.347] iteration 11414 : model1 loss : 0.436868 model2 loss : 0.022423
[11:13:56.518] iteration 11415 : model1 loss : 0.435508 model2 loss : 0.022736
[11:13:56.686] iteration 11416 : model1 loss : 0.437191 model2 loss : 0.022608
[11:13:56.852] iteration 11417 : model1 loss : 0.441547 model2 loss : 0.029386
[11:13:57.022] iteration 11418 : model1 loss : 0.432549 model2 loss : 0.021944
[11:13:58.922] iteration 11419 : model1 loss : 0.431067 model2 loss : 0.024953
[11:13:59.094] iteration 11420 : model1 loss : 0.438186 model2 loss : 0.025777
[11:13:59.264] iteration 11421 : model1 loss : 0.435531 model2 loss : 0.024129
[11:13:59.432] iteration 11422 : model1 loss : 0.432759 model2 loss : 0.021764
[11:13:59.606] iteration 11423 : model1 loss : 0.436700 model2 loss : 0.022912
[11:13:59.772] iteration 11424 : model1 loss : 0.439764 model2 loss : 0.025921
[11:13:59.941] iteration 11425 : model1 loss : 0.434481 model2 loss : 0.025067
[11:14:00.109] iteration 11426 : model1 loss : 0.443586 model2 loss : 0.028805
[11:14:00.276] iteration 11427 : model1 loss : 0.436245 model2 loss : 0.025513
[11:14:00.443] iteration 11428 : model1 loss : 0.436499 model2 loss : 0.025879
[11:14:00.616] iteration 11429 : model1 loss : 0.434221 model2 loss : 0.025207
[11:14:00.783] iteration 11430 : model1 loss : 0.432819 model2 loss : 0.023729
[11:14:00.953] iteration 11431 : model1 loss : 0.439233 model2 loss : 0.024204
[11:14:01.120] iteration 11432 : model1 loss : 0.433096 model2 loss : 0.024038
[11:14:01.290] iteration 11433 : model1 loss : 0.443620 model2 loss : 0.030323
[11:14:01.457] iteration 11434 : model1 loss : 0.438015 model2 loss : 0.023051
[11:14:01.633] iteration 11435 : model1 loss : 0.442227 model2 loss : 0.026716
[11:14:01.800] iteration 11436 : model1 loss : 0.438964 model2 loss : 0.025034
[11:14:01.968] iteration 11437 : model1 loss : 0.435841 model2 loss : 0.027219
[11:14:02.136] iteration 11438 : model1 loss : 0.436065 model2 loss : 0.023168
[11:14:02.305] iteration 11439 : model1 loss : 0.438250 model2 loss : 0.027251
[11:14:02.473] iteration 11440 : model1 loss : 0.438676 model2 loss : 0.028674
[11:14:02.641] iteration 11441 : model1 loss : 0.443916 model2 loss : 0.034718
[11:14:02.806] iteration 11442 : model1 loss : 0.435670 model2 loss : 0.025040
[11:14:02.977] iteration 11443 : model1 loss : 0.437578 model2 loss : 0.025449
[11:14:03.145] iteration 11444 : model1 loss : 0.436370 model2 loss : 0.023734
[11:14:03.313] iteration 11445 : model1 loss : 0.434372 model2 loss : 0.025737
[11:14:03.480] iteration 11446 : model1 loss : 0.437492 model2 loss : 0.023165
[11:14:03.649] iteration 11447 : model1 loss : 0.442262 model2 loss : 0.026000
[11:14:03.815] iteration 11448 : model1 loss : 0.443022 model2 loss : 0.025536
[11:14:03.983] iteration 11449 : model1 loss : 0.438226 model2 loss : 0.025890
[11:14:04.149] iteration 11450 : model1 loss : 0.435263 model2 loss : 0.024272
[11:14:04.332] iteration 11451 : model1 loss : 0.437527 model2 loss : 0.026640
[11:14:06.270] iteration 11452 : model1 loss : 0.440887 model2 loss : 0.027347
[11:14:06.438] iteration 11453 : model1 loss : 0.431870 model2 loss : 0.024083
[11:14:06.609] iteration 11454 : model1 loss : 0.439950 model2 loss : 0.026525
[11:14:06.776] iteration 11455 : model1 loss : 0.441891 model2 loss : 0.026465
[11:14:06.945] iteration 11456 : model1 loss : 0.436788 model2 loss : 0.026868
[11:14:07.113] iteration 11457 : model1 loss : 0.437044 model2 loss : 0.027486
[11:14:07.282] iteration 11458 : model1 loss : 0.438753 model2 loss : 0.026690
[11:14:07.448] iteration 11459 : model1 loss : 0.443214 model2 loss : 0.033232
[11:14:07.621] iteration 11460 : model1 loss : 0.437097 model2 loss : 0.023925
[11:14:07.785] iteration 11461 : model1 loss : 0.436382 model2 loss : 0.020968
[11:14:07.955] iteration 11462 : model1 loss : 0.439637 model2 loss : 0.023472
[11:14:08.124] iteration 11463 : model1 loss : 0.436039 model2 loss : 0.028608
[11:14:08.294] iteration 11464 : model1 loss : 0.432680 model2 loss : 0.026122
[11:14:08.463] iteration 11465 : model1 loss : 0.436137 model2 loss : 0.024390
[11:14:08.647] iteration 11466 : model1 loss : 0.439739 model2 loss : 0.026991
[11:14:08.814] iteration 11467 : model1 loss : 0.439425 model2 loss : 0.025671
[11:14:08.983] iteration 11468 : model1 loss : 0.441287 model2 loss : 0.026023
[11:14:09.150] iteration 11469 : model1 loss : 0.432747 model2 loss : 0.027921
[11:14:09.318] iteration 11470 : model1 loss : 0.434306 model2 loss : 0.023124
[11:14:09.486] iteration 11471 : model1 loss : 0.437688 model2 loss : 0.027386
[11:14:09.656] iteration 11472 : model1 loss : 0.434390 model2 loss : 0.025750
[11:14:09.824] iteration 11473 : model1 loss : 0.438191 model2 loss : 0.026829
[11:14:09.992] iteration 11474 : model1 loss : 0.434483 model2 loss : 0.021949
[11:14:10.158] iteration 11475 : model1 loss : 0.439072 model2 loss : 0.024357
[11:14:10.328] iteration 11476 : model1 loss : 0.439658 model2 loss : 0.028446
[11:14:10.494] iteration 11477 : model1 loss : 0.433802 model2 loss : 0.022864
[11:14:10.662] iteration 11478 : model1 loss : 0.435225 model2 loss : 0.025863
[11:14:10.831] iteration 11479 : model1 loss : 0.433871 model2 loss : 0.023960
[11:14:11.001] iteration 11480 : model1 loss : 0.439478 model2 loss : 0.022452
[11:14:11.168] iteration 11481 : model1 loss : 0.435338 model2 loss : 0.023990
[11:14:11.337] iteration 11482 : model1 loss : 0.434659 model2 loss : 0.022715
[11:14:11.506] iteration 11483 : model1 loss : 0.437302 model2 loss : 0.025779
[11:14:11.675] iteration 11484 : model1 loss : 0.436624 model2 loss : 0.029030
[11:14:13.618] iteration 11485 : model1 loss : 0.438863 model2 loss : 0.025821
[11:14:13.789] iteration 11486 : model1 loss : 0.434954 model2 loss : 0.021974
[11:14:13.959] iteration 11487 : model1 loss : 0.437156 model2 loss : 0.022393
[11:14:14.125] iteration 11488 : model1 loss : 0.431137 model2 loss : 0.021291
[11:14:14.293] iteration 11489 : model1 loss : 0.437978 model2 loss : 0.021441
[11:14:14.460] iteration 11490 : model1 loss : 0.437667 model2 loss : 0.025507
[11:14:14.632] iteration 11491 : model1 loss : 0.437313 model2 loss : 0.022417
[11:14:14.800] iteration 11492 : model1 loss : 0.439615 model2 loss : 0.029770
[11:14:14.969] iteration 11493 : model1 loss : 0.436268 model2 loss : 0.024594
[11:14:15.136] iteration 11494 : model1 loss : 0.437402 model2 loss : 0.024825
[11:14:15.304] iteration 11495 : model1 loss : 0.433740 model2 loss : 0.022853
[11:14:15.470] iteration 11496 : model1 loss : 0.439335 model2 loss : 0.026324
[11:14:15.643] iteration 11497 : model1 loss : 0.441465 model2 loss : 0.028072
[11:14:15.809] iteration 11498 : model1 loss : 0.439075 model2 loss : 0.025701
[11:14:15.977] iteration 11499 : model1 loss : 0.432460 model2 loss : 0.023525
[11:14:16.145] iteration 11500 : model1 loss : 0.438220 model2 loss : 0.020867
[11:14:16.313] iteration 11501 : model1 loss : 0.440583 model2 loss : 0.025214
[11:14:16.481] iteration 11502 : model1 loss : 0.435731 model2 loss : 0.025980
[11:14:16.653] iteration 11503 : model1 loss : 0.438015 model2 loss : 0.025128
[11:14:16.820] iteration 11504 : model1 loss : 0.438135 model2 loss : 0.026075
[11:14:16.989] iteration 11505 : model1 loss : 0.435420 model2 loss : 0.025353
[11:14:17.156] iteration 11506 : model1 loss : 0.434755 model2 loss : 0.023498
[11:14:17.324] iteration 11507 : model1 loss : 0.435713 model2 loss : 0.021798
[11:14:17.493] iteration 11508 : model1 loss : 0.433903 model2 loss : 0.022496
[11:14:17.665] iteration 11509 : model1 loss : 0.439284 model2 loss : 0.026176
[11:14:17.832] iteration 11510 : model1 loss : 0.436148 model2 loss : 0.024319
[11:14:18.002] iteration 11511 : model1 loss : 0.434832 model2 loss : 0.023418
[11:14:18.171] iteration 11512 : model1 loss : 0.438183 model2 loss : 0.027253
[11:14:18.340] iteration 11513 : model1 loss : 0.438662 model2 loss : 0.024670
[11:14:18.510] iteration 11514 : model1 loss : 0.435976 model2 loss : 0.025064
[11:14:18.678] iteration 11515 : model1 loss : 0.436958 model2 loss : 0.023386
[11:14:18.844] iteration 11516 : model1 loss : 0.431896 model2 loss : 0.022939
[11:14:19.012] iteration 11517 : model1 loss : 0.438810 model2 loss : 0.024432
[11:14:20.952] iteration 11518 : model1 loss : 0.438367 model2 loss : 0.024025
[11:14:21.118] iteration 11519 : model1 loss : 0.435591 model2 loss : 0.022937
[11:14:21.288] iteration 11520 : model1 loss : 0.438536 model2 loss : 0.023975
[11:14:21.454] iteration 11521 : model1 loss : 0.438224 model2 loss : 0.024512
[11:14:21.624] iteration 11522 : model1 loss : 0.441709 model2 loss : 0.026800
[11:14:21.792] iteration 11523 : model1 loss : 0.440766 model2 loss : 0.029148
[11:14:21.962] iteration 11524 : model1 loss : 0.437269 model2 loss : 0.024870
[11:14:22.129] iteration 11525 : model1 loss : 0.436864 model2 loss : 0.021912
[11:14:22.299] iteration 11526 : model1 loss : 0.436537 model2 loss : 0.025250
[11:14:22.465] iteration 11527 : model1 loss : 0.431540 model2 loss : 0.023810
[11:14:22.632] iteration 11528 : model1 loss : 0.432077 model2 loss : 0.021466
[11:14:22.800] iteration 11529 : model1 loss : 0.434224 model2 loss : 0.023970
[11:14:22.968] iteration 11530 : model1 loss : 0.436987 model2 loss : 0.025238
[11:14:23.136] iteration 11531 : model1 loss : 0.442288 model2 loss : 0.029397
[11:14:23.306] iteration 11532 : model1 loss : 0.439571 model2 loss : 0.026349
[11:14:23.473] iteration 11533 : model1 loss : 0.440278 model2 loss : 0.026721
[11:14:23.644] iteration 11534 : model1 loss : 0.432466 model2 loss : 0.023838
[11:14:23.810] iteration 11535 : model1 loss : 0.437967 model2 loss : 0.026434
[11:14:23.978] iteration 11536 : model1 loss : 0.432677 model2 loss : 0.024503
[11:14:24.147] iteration 11537 : model1 loss : 0.432012 model2 loss : 0.024189
[11:14:24.317] iteration 11538 : model1 loss : 0.434513 model2 loss : 0.023874
[11:14:24.485] iteration 11539 : model1 loss : 0.444340 model2 loss : 0.028350
[11:14:24.657] iteration 11540 : model1 loss : 0.435059 model2 loss : 0.025676
[11:14:24.823] iteration 11541 : model1 loss : 0.436879 model2 loss : 0.021165
[11:14:24.992] iteration 11542 : model1 loss : 0.434905 model2 loss : 0.027181
[11:14:25.159] iteration 11543 : model1 loss : 0.438484 model2 loss : 0.024998
[11:14:25.328] iteration 11544 : model1 loss : 0.437724 model2 loss : 0.024995
[11:14:25.496] iteration 11545 : model1 loss : 0.440665 model2 loss : 0.026524
[11:14:25.669] iteration 11546 : model1 loss : 0.436964 model2 loss : 0.024480
[11:14:25.838] iteration 11547 : model1 loss : 0.439661 model2 loss : 0.025375
[11:14:26.009] iteration 11548 : model1 loss : 0.437048 model2 loss : 0.026398
[11:14:26.175] iteration 11549 : model1 loss : 0.436282 model2 loss : 0.026123
[11:14:26.344] iteration 11550 : model1 loss : 0.436961 model2 loss : 0.025669
[11:14:28.276] iteration 11551 : model1 loss : 0.437585 model2 loss : 0.024640
[11:14:28.449] iteration 11552 : model1 loss : 0.436219 model2 loss : 0.022942
[11:14:28.620] iteration 11553 : model1 loss : 0.438669 model2 loss : 0.022710
[11:14:28.787] iteration 11554 : model1 loss : 0.436201 model2 loss : 0.025644
[11:14:28.959] iteration 11555 : model1 loss : 0.436334 model2 loss : 0.022001
[11:14:29.125] iteration 11556 : model1 loss : 0.435370 model2 loss : 0.021987
[11:14:29.294] iteration 11557 : model1 loss : 0.439085 model2 loss : 0.029719
[11:14:29.460] iteration 11558 : model1 loss : 0.435694 model2 loss : 0.028363
[11:14:29.628] iteration 11559 : model1 loss : 0.434461 model2 loss : 0.023757
[11:14:29.795] iteration 11560 : model1 loss : 0.439368 model2 loss : 0.026876
[11:14:29.964] iteration 11561 : model1 loss : 0.435805 model2 loss : 0.025866
[11:14:30.133] iteration 11562 : model1 loss : 0.439882 model2 loss : 0.027174
[11:14:30.300] iteration 11563 : model1 loss : 0.436204 model2 loss : 0.025324
[11:14:30.469] iteration 11564 : model1 loss : 0.437405 model2 loss : 0.022894
[11:14:30.638] iteration 11565 : model1 loss : 0.441627 model2 loss : 0.025757
[11:14:30.805] iteration 11566 : model1 loss : 0.434603 model2 loss : 0.022604
[11:14:30.975] iteration 11567 : model1 loss : 0.441059 model2 loss : 0.023382
[11:14:31.141] iteration 11568 : model1 loss : 0.435385 model2 loss : 0.024826
[11:14:31.311] iteration 11569 : model1 loss : 0.434643 model2 loss : 0.023996
[11:14:31.478] iteration 11570 : model1 loss : 0.432768 model2 loss : 0.021767
[11:14:31.648] iteration 11571 : model1 loss : 0.434094 model2 loss : 0.021588
[11:14:31.815] iteration 11572 : model1 loss : 0.436855 model2 loss : 0.024775
[11:14:31.983] iteration 11573 : model1 loss : 0.436985 model2 loss : 0.026610
[11:14:32.150] iteration 11574 : model1 loss : 0.433320 model2 loss : 0.023431
[11:14:32.320] iteration 11575 : model1 loss : 0.433387 model2 loss : 0.024880
[11:14:32.489] iteration 11576 : model1 loss : 0.443524 model2 loss : 0.035738
[11:14:32.659] iteration 11577 : model1 loss : 0.438630 model2 loss : 0.024502
[11:14:32.825] iteration 11578 : model1 loss : 0.439585 model2 loss : 0.024745
[11:14:32.995] iteration 11579 : model1 loss : 0.439194 model2 loss : 0.024820
[11:14:33.162] iteration 11580 : model1 loss : 0.442664 model2 loss : 0.027039
[11:14:33.332] iteration 11581 : model1 loss : 0.435135 model2 loss : 0.023945
[11:14:33.500] iteration 11582 : model1 loss : 0.437216 model2 loss : 0.023444
[11:14:33.667] iteration 11583 : model1 loss : 0.434698 model2 loss : 0.025508
[11:14:35.562] iteration 11584 : model1 loss : 0.436318 model2 loss : 0.021785
[11:14:35.727] iteration 11585 : model1 loss : 0.440524 model2 loss : 0.022635
[11:14:35.901] iteration 11586 : model1 loss : 0.434608 model2 loss : 0.021532
[11:14:36.068] iteration 11587 : model1 loss : 0.439766 model2 loss : 0.025040
[11:14:36.237] iteration 11588 : model1 loss : 0.436620 model2 loss : 0.022488
[11:14:36.403] iteration 11589 : model1 loss : 0.434917 model2 loss : 0.022272
[11:14:36.575] iteration 11590 : model1 loss : 0.435952 model2 loss : 0.027356
[11:14:36.742] iteration 11591 : model1 loss : 0.441922 model2 loss : 0.025752
[11:14:36.911] iteration 11592 : model1 loss : 0.436500 model2 loss : 0.029234
[11:14:37.077] iteration 11593 : model1 loss : 0.435620 model2 loss : 0.026764
[11:14:37.248] iteration 11594 : model1 loss : 0.440636 model2 loss : 0.025368
[11:14:37.414] iteration 11595 : model1 loss : 0.435098 model2 loss : 0.022962
[11:14:37.585] iteration 11596 : model1 loss : 0.440421 model2 loss : 0.020852
[11:14:37.752] iteration 11597 : model1 loss : 0.438178 model2 loss : 0.026512
[11:14:37.920] iteration 11598 : model1 loss : 0.432184 model2 loss : 0.022339
[11:14:38.085] iteration 11599 : model1 loss : 0.434821 model2 loss : 0.025671
[11:14:38.256] iteration 11600 : model1 loss : 0.438309 model2 loss : 0.025134
[11:14:38.422] iteration 11601 : model1 loss : 0.435300 model2 loss : 0.022065
[11:14:38.591] iteration 11602 : model1 loss : 0.439902 model2 loss : 0.027658
[11:14:38.758] iteration 11603 : model1 loss : 0.436058 model2 loss : 0.026545
[11:14:38.928] iteration 11604 : model1 loss : 0.437999 model2 loss : 0.027167
[11:14:39.095] iteration 11605 : model1 loss : 0.439091 model2 loss : 0.025737
[11:14:39.264] iteration 11606 : model1 loss : 0.438131 model2 loss : 0.023663
[11:14:39.431] iteration 11607 : model1 loss : 0.435416 model2 loss : 0.023886
[11:14:39.601] iteration 11608 : model1 loss : 0.445780 model2 loss : 0.032019
[11:14:39.767] iteration 11609 : model1 loss : 0.438282 model2 loss : 0.025376
[11:14:39.937] iteration 11610 : model1 loss : 0.433788 model2 loss : 0.024210
[11:14:40.104] iteration 11611 : model1 loss : 0.433386 model2 loss : 0.024200
[11:14:40.274] iteration 11612 : model1 loss : 0.437923 model2 loss : 0.025161
[11:14:40.442] iteration 11613 : model1 loss : 0.435674 model2 loss : 0.021570
[11:14:40.609] iteration 11614 : model1 loss : 0.431870 model2 loss : 0.023121
[11:14:40.776] iteration 11615 : model1 loss : 0.434630 model2 loss : 0.024597
[11:14:40.946] iteration 11616 : model1 loss : 0.437624 model2 loss : 0.021683
[11:14:42.846] iteration 11617 : model1 loss : 0.442405 model2 loss : 0.030413
[11:14:43.015] iteration 11618 : model1 loss : 0.436802 model2 loss : 0.024048
[11:14:43.185] iteration 11619 : model1 loss : 0.434092 model2 loss : 0.026364
[11:14:43.353] iteration 11620 : model1 loss : 0.433274 model2 loss : 0.022531
[11:14:43.526] iteration 11621 : model1 loss : 0.438832 model2 loss : 0.026354
[11:14:43.693] iteration 11622 : model1 loss : 0.431447 model2 loss : 0.023055
[11:14:43.862] iteration 11623 : model1 loss : 0.436327 model2 loss : 0.021652
[11:14:44.029] iteration 11624 : model1 loss : 0.436408 model2 loss : 0.024914
[11:14:44.199] iteration 11625 : model1 loss : 0.435625 model2 loss : 0.024183
[11:14:44.367] iteration 11626 : model1 loss : 0.440317 model2 loss : 0.024773
[11:14:44.537] iteration 11627 : model1 loss : 0.434276 model2 loss : 0.024135
[11:14:44.707] iteration 11628 : model1 loss : 0.440948 model2 loss : 0.026262
[11:14:44.877] iteration 11629 : model1 loss : 0.437196 model2 loss : 0.026463
[11:14:45.043] iteration 11630 : model1 loss : 0.435029 model2 loss : 0.021955
[11:14:45.213] iteration 11631 : model1 loss : 0.438485 model2 loss : 0.023752
[11:14:45.380] iteration 11632 : model1 loss : 0.441398 model2 loss : 0.027041
[11:14:45.549] iteration 11633 : model1 loss : 0.441003 model2 loss : 0.025065
[11:14:45.718] iteration 11634 : model1 loss : 0.437196 model2 loss : 0.023585
[11:14:45.889] iteration 11635 : model1 loss : 0.433684 model2 loss : 0.021720
[11:14:46.056] iteration 11636 : model1 loss : 0.438464 model2 loss : 0.024927
[11:14:46.224] iteration 11637 : model1 loss : 0.439060 model2 loss : 0.023919
[11:14:46.391] iteration 11638 : model1 loss : 0.435199 model2 loss : 0.026632
[11:14:46.562] iteration 11639 : model1 loss : 0.438881 model2 loss : 0.024265
[11:14:46.732] iteration 11640 : model1 loss : 0.435941 model2 loss : 0.023665
[11:14:46.903] iteration 11641 : model1 loss : 0.434733 model2 loss : 0.020549
[11:14:47.070] iteration 11642 : model1 loss : 0.439437 model2 loss : 0.023892
[11:14:47.240] iteration 11643 : model1 loss : 0.434436 model2 loss : 0.023429
[11:14:47.408] iteration 11644 : model1 loss : 0.435324 model2 loss : 0.025411
[11:14:47.577] iteration 11645 : model1 loss : 0.436712 model2 loss : 0.023836
[11:14:47.746] iteration 11646 : model1 loss : 0.433494 model2 loss : 0.022628
[11:14:47.916] iteration 11647 : model1 loss : 0.438042 model2 loss : 0.024772
[11:14:48.082] iteration 11648 : model1 loss : 0.437022 model2 loss : 0.025875
[11:14:48.250] iteration 11649 : model1 loss : 0.441016 model2 loss : 0.025622
[11:14:50.138] iteration 11650 : model1 loss : 0.437731 model2 loss : 0.021495
[11:14:50.306] iteration 11651 : model1 loss : 0.437307 model2 loss : 0.023198
[11:14:50.476] iteration 11652 : model1 loss : 0.438620 model2 loss : 0.025954
[11:14:50.641] iteration 11653 : model1 loss : 0.438142 model2 loss : 0.026032
[11:14:50.813] iteration 11654 : model1 loss : 0.433265 model2 loss : 0.021537
[11:14:50.980] iteration 11655 : model1 loss : 0.438946 model2 loss : 0.025504
[11:14:51.164] iteration 11656 : model1 loss : 0.433153 model2 loss : 0.019602
[11:14:51.329] iteration 11657 : model1 loss : 0.435513 model2 loss : 0.026153
[11:14:51.500] iteration 11658 : model1 loss : 0.436719 model2 loss : 0.025041
[11:14:51.669] iteration 11659 : model1 loss : 0.441811 model2 loss : 0.026921
[11:14:51.838] iteration 11660 : model1 loss : 0.435990 model2 loss : 0.022885
[11:14:52.005] iteration 11661 : model1 loss : 0.437670 model2 loss : 0.023355
[11:14:52.175] iteration 11662 : model1 loss : 0.437057 model2 loss : 0.022466
[11:14:52.342] iteration 11663 : model1 loss : 0.436456 model2 loss : 0.024029
[11:14:52.514] iteration 11664 : model1 loss : 0.434571 model2 loss : 0.023645
[11:14:52.681] iteration 11665 : model1 loss : 0.432917 model2 loss : 0.024406
[11:14:52.850] iteration 11666 : model1 loss : 0.437418 model2 loss : 0.023424
[11:14:53.017] iteration 11667 : model1 loss : 0.441599 model2 loss : 0.026081
[11:14:53.184] iteration 11668 : model1 loss : 0.432849 model2 loss : 0.024086
[11:14:53.352] iteration 11669 : model1 loss : 0.441305 model2 loss : 0.026683
[11:14:53.524] iteration 11670 : model1 loss : 0.436889 model2 loss : 0.022297
[11:14:53.691] iteration 11671 : model1 loss : 0.436746 model2 loss : 0.025216
[11:14:53.861] iteration 11672 : model1 loss : 0.437324 model2 loss : 0.026908
[11:14:54.028] iteration 11673 : model1 loss : 0.434545 model2 loss : 0.022677
[11:14:54.198] iteration 11674 : model1 loss : 0.441625 model2 loss : 0.029122
[11:14:54.365] iteration 11675 : model1 loss : 0.435355 model2 loss : 0.024275
[11:14:54.537] iteration 11676 : model1 loss : 0.435739 model2 loss : 0.023390
[11:14:54.705] iteration 11677 : model1 loss : 0.437554 model2 loss : 0.021766
[11:14:54.873] iteration 11678 : model1 loss : 0.436555 model2 loss : 0.024763
[11:14:55.042] iteration 11679 : model1 loss : 0.433186 model2 loss : 0.024791
[11:14:55.211] iteration 11680 : model1 loss : 0.434295 model2 loss : 0.021732
[11:14:55.378] iteration 11681 : model1 loss : 0.435940 model2 loss : 0.025723
[11:14:55.546] iteration 11682 : model1 loss : 0.437772 model2 loss : 0.023742
[11:14:57.487] iteration 11683 : model1 loss : 0.437073 model2 loss : 0.027476
[11:14:57.658] iteration 11684 : model1 loss : 0.435687 model2 loss : 0.023999
[11:14:57.829] iteration 11685 : model1 loss : 0.440506 model2 loss : 0.027098
[11:14:57.997] iteration 11686 : model1 loss : 0.435967 model2 loss : 0.024287
[11:14:58.166] iteration 11687 : model1 loss : 0.435878 model2 loss : 0.022764
[11:14:58.334] iteration 11688 : model1 loss : 0.436132 model2 loss : 0.023692
[11:14:58.504] iteration 11689 : model1 loss : 0.437738 model2 loss : 0.024070
[11:14:58.672] iteration 11690 : model1 loss : 0.438772 model2 loss : 0.028282
[11:14:58.842] iteration 11691 : model1 loss : 0.434374 model2 loss : 0.022385
[11:14:59.010] iteration 11692 : model1 loss : 0.438621 model2 loss : 0.026340
[11:14:59.178] iteration 11693 : model1 loss : 0.435671 model2 loss : 0.027040
[11:14:59.345] iteration 11694 : model1 loss : 0.436565 model2 loss : 0.027598
[11:14:59.515] iteration 11695 : model1 loss : 0.436618 model2 loss : 0.025565
[11:14:59.683] iteration 11696 : model1 loss : 0.437592 model2 loss : 0.024117
[11:14:59.852] iteration 11697 : model1 loss : 0.436551 model2 loss : 0.024445
[11:15:00.018] iteration 11698 : model1 loss : 0.438172 model2 loss : 0.023928
[11:15:00.189] iteration 11699 : model1 loss : 0.436111 model2 loss : 0.024113
[11:15:00.357] iteration 11700 : model1 loss : 0.435555 model2 loss : 0.024921
[11:15:00.529] iteration 11701 : model1 loss : 0.432735 model2 loss : 0.024295
[11:15:00.697] iteration 11702 : model1 loss : 0.435760 model2 loss : 0.022938
[11:15:00.869] iteration 11703 : model1 loss : 0.432757 model2 loss : 0.022706
[11:15:01.037] iteration 11704 : model1 loss : 0.435782 model2 loss : 0.022149
[11:15:01.204] iteration 11705 : model1 loss : 0.438393 model2 loss : 0.028045
[11:15:01.371] iteration 11706 : model1 loss : 0.440753 model2 loss : 0.024429
[11:15:01.542] iteration 11707 : model1 loss : 0.437601 model2 loss : 0.022688
[11:15:01.709] iteration 11708 : model1 loss : 0.433630 model2 loss : 0.022575
[11:15:01.879] iteration 11709 : model1 loss : 0.437765 model2 loss : 0.028104
[11:15:02.047] iteration 11710 : model1 loss : 0.438163 model2 loss : 0.024528
[11:15:02.217] iteration 11711 : model1 loss : 0.439206 model2 loss : 0.024495
[11:15:02.384] iteration 11712 : model1 loss : 0.436841 model2 loss : 0.024360
[11:15:02.553] iteration 11713 : model1 loss : 0.436864 model2 loss : 0.025777
[11:15:02.719] iteration 11714 : model1 loss : 0.439498 model2 loss : 0.024754
[11:15:02.887] iteration 11715 : model1 loss : 0.435622 model2 loss : 0.023470
[11:15:04.807] iteration 11716 : model1 loss : 0.436074 model2 loss : 0.024621
[11:15:04.975] iteration 11717 : model1 loss : 0.434181 model2 loss : 0.022531
[11:15:05.147] iteration 11718 : model1 loss : 0.434613 model2 loss : 0.025941
[11:15:05.314] iteration 11719 : model1 loss : 0.438979 model2 loss : 0.025325
[11:15:05.482] iteration 11720 : model1 loss : 0.436494 model2 loss : 0.024534
[11:15:05.649] iteration 11721 : model1 loss : 0.439652 model2 loss : 0.025270
[11:15:05.819] iteration 11722 : model1 loss : 0.436031 model2 loss : 0.025172
[11:15:05.985] iteration 11723 : model1 loss : 0.435611 model2 loss : 0.024736
[11:15:06.154] iteration 11724 : model1 loss : 0.434819 model2 loss : 0.023621
[11:15:06.320] iteration 11725 : model1 loss : 0.437881 model2 loss : 0.025506
[11:15:06.492] iteration 11726 : model1 loss : 0.438661 model2 loss : 0.024254
[11:15:06.659] iteration 11727 : model1 loss : 0.444661 model2 loss : 0.029238
[11:15:06.829] iteration 11728 : model1 loss : 0.432184 model2 loss : 0.022964
[11:15:06.996] iteration 11729 : model1 loss : 0.436684 model2 loss : 0.022748
[11:15:07.164] iteration 11730 : model1 loss : 0.435256 model2 loss : 0.025583
[11:15:07.332] iteration 11731 : model1 loss : 0.435889 model2 loss : 0.023299
[11:15:07.501] iteration 11732 : model1 loss : 0.438939 model2 loss : 0.022358
[11:15:07.669] iteration 11733 : model1 loss : 0.438564 model2 loss : 0.025145
[11:15:07.851] iteration 11734 : model1 loss : 0.438026 model2 loss : 0.023608
[11:15:08.018] iteration 11735 : model1 loss : 0.436794 model2 loss : 0.023315
[11:15:08.190] iteration 11736 : model1 loss : 0.437017 model2 loss : 0.024476
[11:15:08.357] iteration 11737 : model1 loss : 0.433912 model2 loss : 0.026012
[11:15:08.532] iteration 11738 : model1 loss : 0.434754 model2 loss : 0.022464
[11:15:08.699] iteration 11739 : model1 loss : 0.436746 model2 loss : 0.023397
[11:15:08.866] iteration 11740 : model1 loss : 0.437547 model2 loss : 0.023555
[11:15:09.035] iteration 11741 : model1 loss : 0.441379 model2 loss : 0.029053
[11:15:09.203] iteration 11742 : model1 loss : 0.434933 model2 loss : 0.022712
[11:15:09.371] iteration 11743 : model1 loss : 0.439866 model2 loss : 0.027998
[11:15:09.541] iteration 11744 : model1 loss : 0.436836 model2 loss : 0.022321
[11:15:09.709] iteration 11745 : model1 loss : 0.434806 model2 loss : 0.023644
[11:15:09.880] iteration 11746 : model1 loss : 0.434736 model2 loss : 0.025324
[11:15:10.045] iteration 11747 : model1 loss : 0.438851 model2 loss : 0.030509
[11:15:10.213] iteration 11748 : model1 loss : 0.434144 model2 loss : 0.023532
[11:15:12.195] iteration 11749 : model1 loss : 0.436193 model2 loss : 0.027628
[11:15:12.366] iteration 11750 : model1 loss : 0.439038 model2 loss : 0.025542
[11:15:12.538] iteration 11751 : model1 loss : 0.439562 model2 loss : 0.020801
[11:15:12.705] iteration 11752 : model1 loss : 0.436545 model2 loss : 0.024547
[11:15:12.878] iteration 11753 : model1 loss : 0.437516 model2 loss : 0.023943
[11:15:13.044] iteration 11754 : model1 loss : 0.433316 model2 loss : 0.024914
[11:15:13.211] iteration 11755 : model1 loss : 0.436318 model2 loss : 0.023958
[11:15:13.379] iteration 11756 : model1 loss : 0.439257 model2 loss : 0.024376
[11:15:13.546] iteration 11757 : model1 loss : 0.434028 model2 loss : 0.022511
[11:15:13.713] iteration 11758 : model1 loss : 0.433387 model2 loss : 0.022592
[11:15:13.884] iteration 11759 : model1 loss : 0.435124 model2 loss : 0.023583
[11:15:14.050] iteration 11760 : model1 loss : 0.436808 model2 loss : 0.024482
[11:15:14.219] iteration 11761 : model1 loss : 0.437487 model2 loss : 0.027442
[11:15:14.385] iteration 11762 : model1 loss : 0.435672 model2 loss : 0.023009
[11:15:14.556] iteration 11763 : model1 loss : 0.437560 model2 loss : 0.025550
[11:15:14.724] iteration 11764 : model1 loss : 0.432067 model2 loss : 0.025068
[11:15:14.892] iteration 11765 : model1 loss : 0.436051 model2 loss : 0.025500
[11:15:15.058] iteration 11766 : model1 loss : 0.439126 model2 loss : 0.025713
[11:15:15.227] iteration 11767 : model1 loss : 0.438074 model2 loss : 0.023805
[11:15:15.395] iteration 11768 : model1 loss : 0.441896 model2 loss : 0.025528
[11:15:15.563] iteration 11769 : model1 loss : 0.439169 model2 loss : 0.025202
[11:15:15.730] iteration 11770 : model1 loss : 0.444601 model2 loss : 0.030178
[11:15:15.901] iteration 11771 : model1 loss : 0.435300 model2 loss : 0.025813
[11:15:16.069] iteration 11772 : model1 loss : 0.432427 model2 loss : 0.026354
[11:15:16.238] iteration 11773 : model1 loss : 0.438488 model2 loss : 0.028713
[11:15:16.405] iteration 11774 : model1 loss : 0.435518 model2 loss : 0.023363
[11:15:16.573] iteration 11775 : model1 loss : 0.435624 model2 loss : 0.023546
[11:15:16.739] iteration 11776 : model1 loss : 0.440088 model2 loss : 0.028819
[11:15:16.909] iteration 11777 : model1 loss : 0.434448 model2 loss : 0.026523
[11:15:17.077] iteration 11778 : model1 loss : 0.436089 model2 loss : 0.024331
[11:15:17.247] iteration 11779 : model1 loss : 0.440430 model2 loss : 0.030329
[11:15:17.414] iteration 11780 : model1 loss : 0.436401 model2 loss : 0.022511
[11:15:17.582] iteration 11781 : model1 loss : 0.436541 model2 loss : 0.026703
[11:15:19.567] iteration 11782 : model1 loss : 0.437328 model2 loss : 0.026176
[11:15:19.739] iteration 11783 : model1 loss : 0.438430 model2 loss : 0.027461
[11:15:19.910] iteration 11784 : model1 loss : 0.434518 model2 loss : 0.026672
[11:15:20.078] iteration 11785 : model1 loss : 0.436500 model2 loss : 0.023341
[11:15:20.246] iteration 11786 : model1 loss : 0.441605 model2 loss : 0.028652
[11:15:20.413] iteration 11787 : model1 loss : 0.441267 model2 loss : 0.028858
[11:15:20.585] iteration 11788 : model1 loss : 0.438949 model2 loss : 0.027015
[11:15:20.753] iteration 11789 : model1 loss : 0.435268 model2 loss : 0.023049
[11:15:20.925] iteration 11790 : model1 loss : 0.438299 model2 loss : 0.026942
[11:15:21.094] iteration 11791 : model1 loss : 0.437526 model2 loss : 0.024737
[11:15:21.263] iteration 11792 : model1 loss : 0.434899 model2 loss : 0.022815
[11:15:21.429] iteration 11793 : model1 loss : 0.439567 model2 loss : 0.027130
[11:15:21.597] iteration 11794 : model1 loss : 0.433889 model2 loss : 0.022173
[11:15:21.765] iteration 11795 : model1 loss : 0.439468 model2 loss : 0.024079
[11:15:21.937] iteration 11796 : model1 loss : 0.435944 model2 loss : 0.025420
[11:15:22.104] iteration 11797 : model1 loss : 0.436967 model2 loss : 0.025725
[11:15:22.274] iteration 11798 : model1 loss : 0.437254 model2 loss : 0.023699
[11:15:22.444] iteration 11799 : model1 loss : 0.435622 model2 loss : 0.023950
[11:15:22.613] iteration 11800 : model1 loss : 0.431984 model2 loss : 0.022146
[11:15:22.780] iteration 11801 : model1 loss : 0.439384 model2 loss : 0.022884
[11:15:22.951] iteration 11802 : model1 loss : 0.436122 model2 loss : 0.022990
[11:15:23.118] iteration 11803 : model1 loss : 0.440144 model2 loss : 0.025267
[11:15:23.288] iteration 11804 : model1 loss : 0.434331 model2 loss : 0.020784
[11:15:23.455] iteration 11805 : model1 loss : 0.434792 model2 loss : 0.022219
[11:15:23.624] iteration 11806 : model1 loss : 0.433536 model2 loss : 0.022316
[11:15:23.789] iteration 11807 : model1 loss : 0.435633 model2 loss : 0.024227
[11:15:23.961] iteration 11808 : model1 loss : 0.435720 model2 loss : 0.023780
[11:15:24.129] iteration 11809 : model1 loss : 0.434253 model2 loss : 0.021360
[11:15:24.298] iteration 11810 : model1 loss : 0.438679 model2 loss : 0.026801
[11:15:24.481] iteration 11811 : model1 loss : 0.437009 model2 loss : 0.025214
[11:15:24.650] iteration 11812 : model1 loss : 0.438883 model2 loss : 0.024803
[11:15:24.815] iteration 11813 : model1 loss : 0.433970 model2 loss : 0.024073
[11:15:24.981] iteration 11814 : model1 loss : 0.439949 model2 loss : 0.025168
[11:15:26.933] iteration 11815 : model1 loss : 0.436847 model2 loss : 0.025353
[11:15:27.100] iteration 11816 : model1 loss : 0.438813 model2 loss : 0.026756
[11:15:27.271] iteration 11817 : model1 loss : 0.437315 model2 loss : 0.023867
[11:15:27.438] iteration 11818 : model1 loss : 0.434501 model2 loss : 0.022081
[11:15:27.607] iteration 11819 : model1 loss : 0.436200 model2 loss : 0.023496
[11:15:27.775] iteration 11820 : model1 loss : 0.435149 model2 loss : 0.020563
[11:15:27.943] iteration 11821 : model1 loss : 0.438120 model2 loss : 0.022454
[11:15:28.111] iteration 11822 : model1 loss : 0.437735 model2 loss : 0.027176
[11:15:28.280] iteration 11823 : model1 loss : 0.436628 model2 loss : 0.023890
[11:15:28.449] iteration 11824 : model1 loss : 0.434479 model2 loss : 0.023534
[11:15:28.618] iteration 11825 : model1 loss : 0.432949 model2 loss : 0.021357
[11:15:28.787] iteration 11826 : model1 loss : 0.435445 model2 loss : 0.023547
[11:15:28.955] iteration 11827 : model1 loss : 0.438402 model2 loss : 0.026759
[11:15:29.123] iteration 11828 : model1 loss : 0.436084 model2 loss : 0.023231
[11:15:29.291] iteration 11829 : model1 loss : 0.442171 model2 loss : 0.026851
[11:15:29.458] iteration 11830 : model1 loss : 0.435974 model2 loss : 0.026924
[11:15:29.629] iteration 11831 : model1 loss : 0.436240 model2 loss : 0.022812
[11:15:29.796] iteration 11832 : model1 loss : 0.433640 model2 loss : 0.022987
[11:15:29.965] iteration 11833 : model1 loss : 0.437786 model2 loss : 0.022308
[11:15:30.132] iteration 11834 : model1 loss : 0.435793 model2 loss : 0.022988
[11:15:30.300] iteration 11835 : model1 loss : 0.434738 model2 loss : 0.022159
[11:15:30.467] iteration 11836 : model1 loss : 0.438541 model2 loss : 0.027858
[11:15:30.636] iteration 11837 : model1 loss : 0.438498 model2 loss : 0.027095
[11:15:30.803] iteration 11838 : model1 loss : 0.435589 model2 loss : 0.024090
[11:15:30.974] iteration 11839 : model1 loss : 0.438265 model2 loss : 0.024070
[11:15:31.141] iteration 11840 : model1 loss : 0.439697 model2 loss : 0.025193
[11:15:31.309] iteration 11841 : model1 loss : 0.436533 model2 loss : 0.023711
[11:15:31.476] iteration 11842 : model1 loss : 0.439268 model2 loss : 0.023934
[11:15:31.644] iteration 11843 : model1 loss : 0.438235 model2 loss : 0.026492
[11:15:31.813] iteration 11844 : model1 loss : 0.437979 model2 loss : 0.025600
[11:15:31.984] iteration 11845 : model1 loss : 0.434620 model2 loss : 0.024262
[11:15:32.151] iteration 11846 : model1 loss : 0.437501 model2 loss : 0.023258
[11:15:32.320] iteration 11847 : model1 loss : 0.435458 model2 loss : 0.024524
[11:15:34.221] iteration 11848 : model1 loss : 0.435662 model2 loss : 0.027194
[11:15:34.392] iteration 11849 : model1 loss : 0.438590 model2 loss : 0.024016
[11:15:34.562] iteration 11850 : model1 loss : 0.440578 model2 loss : 0.024537
[11:15:34.730] iteration 11851 : model1 loss : 0.432185 model2 loss : 0.024943
[11:15:34.899] iteration 11852 : model1 loss : 0.436263 model2 loss : 0.026506
[11:15:35.067] iteration 11853 : model1 loss : 0.435147 model2 loss : 0.022736
[11:15:35.235] iteration 11854 : model1 loss : 0.436200 model2 loss : 0.024268
[11:15:35.403] iteration 11855 : model1 loss : 0.434295 model2 loss : 0.025031
[11:15:35.571] iteration 11856 : model1 loss : 0.440801 model2 loss : 0.028611
[11:15:35.739] iteration 11857 : model1 loss : 0.437138 model2 loss : 0.022511
[11:15:35.916] iteration 11858 : model1 loss : 0.433684 model2 loss : 0.023492
[11:15:36.082] iteration 11859 : model1 loss : 0.436297 model2 loss : 0.023582
[11:15:36.252] iteration 11860 : model1 loss : 0.435299 model2 loss : 0.025269
[11:15:36.419] iteration 11861 : model1 loss : 0.442632 model2 loss : 0.027343
[11:15:36.588] iteration 11862 : model1 loss : 0.438077 model2 loss : 0.025150
[11:15:36.756] iteration 11863 : model1 loss : 0.436163 model2 loss : 0.024052
[11:15:36.926] iteration 11864 : model1 loss : 0.439287 model2 loss : 0.024094
[11:15:37.095] iteration 11865 : model1 loss : 0.438414 model2 loss : 0.023225
[11:15:37.263] iteration 11866 : model1 loss : 0.435197 model2 loss : 0.023976
[11:15:37.431] iteration 11867 : model1 loss : 0.436930 model2 loss : 0.029015
[11:15:37.603] iteration 11868 : model1 loss : 0.437906 model2 loss : 0.027096
[11:15:37.771] iteration 11869 : model1 loss : 0.439140 model2 loss : 0.027759
[11:15:37.941] iteration 11870 : model1 loss : 0.435481 model2 loss : 0.021458
[11:15:38.109] iteration 11871 : model1 loss : 0.435866 model2 loss : 0.024127
[11:15:38.277] iteration 11872 : model1 loss : 0.436474 model2 loss : 0.020264
[11:15:38.444] iteration 11873 : model1 loss : 0.436492 model2 loss : 0.026562
[11:15:38.612] iteration 11874 : model1 loss : 0.433739 model2 loss : 0.020945
[11:15:38.780] iteration 11875 : model1 loss : 0.438562 model2 loss : 0.021209
[11:15:38.950] iteration 11876 : model1 loss : 0.440905 model2 loss : 0.026155
[11:15:39.120] iteration 11877 : model1 loss : 0.436476 model2 loss : 0.026406
[11:15:39.289] iteration 11878 : model1 loss : 0.437054 model2 loss : 0.021736
[11:15:39.457] iteration 11879 : model1 loss : 0.438661 model2 loss : 0.024209
[11:15:39.624] iteration 11880 : model1 loss : 0.431606 model2 loss : 0.023107
[11:15:41.581] iteration 11881 : model1 loss : 0.432287 model2 loss : 0.021358
[11:15:41.749] iteration 11882 : model1 loss : 0.436926 model2 loss : 0.026582
[11:15:41.920] iteration 11883 : model1 loss : 0.436933 model2 loss : 0.022625
[11:15:42.087] iteration 11884 : model1 loss : 0.432831 model2 loss : 0.028312
[11:15:42.255] iteration 11885 : model1 loss : 0.429399 model2 loss : 0.022377
[11:15:42.424] iteration 11886 : model1 loss : 0.436465 model2 loss : 0.023544
[11:15:42.594] iteration 11887 : model1 loss : 0.435404 model2 loss : 0.023367
[11:15:42.760] iteration 11888 : model1 loss : 0.440566 model2 loss : 0.026352
[11:15:42.928] iteration 11889 : model1 loss : 0.433940 model2 loss : 0.022600
[11:15:43.099] iteration 11890 : model1 loss : 0.436390 model2 loss : 0.026131
[11:15:43.268] iteration 11891 : model1 loss : 0.438604 model2 loss : 0.025418
[11:15:43.437] iteration 11892 : model1 loss : 0.435453 model2 loss : 0.025260
[11:15:43.608] iteration 11893 : model1 loss : 0.435327 model2 loss : 0.022939
[11:15:43.775] iteration 11894 : model1 loss : 0.434598 model2 loss : 0.023896
[11:15:43.943] iteration 11895 : model1 loss : 0.430116 model2 loss : 0.022768
[11:15:44.110] iteration 11896 : model1 loss : 0.437398 model2 loss : 0.026170
[11:15:44.280] iteration 11897 : model1 loss : 0.437767 model2 loss : 0.027021
[11:15:44.447] iteration 11898 : model1 loss : 0.436666 model2 loss : 0.025543
[11:15:44.617] iteration 11899 : model1 loss : 0.435381 model2 loss : 0.025327
[11:15:44.785] iteration 11900 : model1 loss : 0.435128 model2 loss : 0.024039
[11:15:44.953] iteration 11901 : model1 loss : 0.437616 model2 loss : 0.025327
[11:15:45.121] iteration 11902 : model1 loss : 0.437599 model2 loss : 0.025553
[11:15:45.291] iteration 11903 : model1 loss : 0.439426 model2 loss : 0.023550
[11:15:45.459] iteration 11904 : model1 loss : 0.441528 model2 loss : 0.034470
[11:15:45.630] iteration 11905 : model1 loss : 0.440501 model2 loss : 0.026619
[11:15:45.797] iteration 11906 : model1 loss : 0.433535 model2 loss : 0.025036
[11:15:45.966] iteration 11907 : model1 loss : 0.438422 model2 loss : 0.027238
[11:15:46.132] iteration 11908 : model1 loss : 0.435635 model2 loss : 0.021911
[11:15:46.301] iteration 11909 : model1 loss : 0.440408 model2 loss : 0.038077
[11:15:46.469] iteration 11910 : model1 loss : 0.440502 model2 loss : 0.028658
[11:15:46.637] iteration 11911 : model1 loss : 0.439218 model2 loss : 0.025630
[11:15:46.806] iteration 11912 : model1 loss : 0.440945 model2 loss : 0.025259
[11:15:46.975] iteration 11913 : model1 loss : 0.438296 model2 loss : 0.025715
[11:15:48.916] iteration 11914 : model1 loss : 0.431402 model2 loss : 0.025284
[11:15:49.087] iteration 11915 : model1 loss : 0.438772 model2 loss : 0.025808
[11:15:49.256] iteration 11916 : model1 loss : 0.437771 model2 loss : 0.023817
[11:15:49.423] iteration 11917 : model1 loss : 0.436005 model2 loss : 0.025456
[11:15:49.594] iteration 11918 : model1 loss : 0.436646 model2 loss : 0.028799
[11:15:49.762] iteration 11919 : model1 loss : 0.433481 model2 loss : 0.025909
[11:15:49.933] iteration 11920 : model1 loss : 0.437332 model2 loss : 0.021817
[11:15:50.102] iteration 11921 : model1 loss : 0.436011 model2 loss : 0.023389
[11:15:50.272] iteration 11922 : model1 loss : 0.435978 model2 loss : 0.024521
[11:15:50.442] iteration 11923 : model1 loss : 0.436209 model2 loss : 0.026362
[11:15:50.612] iteration 11924 : model1 loss : 0.432871 model2 loss : 0.024335
[11:15:50.780] iteration 11925 : model1 loss : 0.436511 model2 loss : 0.024622
[11:15:50.951] iteration 11926 : model1 loss : 0.439955 model2 loss : 0.025243
[11:15:51.118] iteration 11927 : model1 loss : 0.436122 model2 loss : 0.028402
[11:15:51.287] iteration 11928 : model1 loss : 0.440517 model2 loss : 0.036811
[11:15:51.455] iteration 11929 : model1 loss : 0.440807 model2 loss : 0.032123
[11:15:51.624] iteration 11930 : model1 loss : 0.434454 model2 loss : 0.024919
[11:15:51.792] iteration 11931 : model1 loss : 0.436417 model2 loss : 0.022729
[11:15:51.960] iteration 11932 : model1 loss : 0.437331 model2 loss : 0.024383
[11:15:52.128] iteration 11933 : model1 loss : 0.436780 model2 loss : 0.026128
[11:15:52.296] iteration 11934 : model1 loss : 0.440387 model2 loss : 0.031423
[11:15:52.465] iteration 11935 : model1 loss : 0.435654 model2 loss : 0.031638
[11:15:52.634] iteration 11936 : model1 loss : 0.435320 model2 loss : 0.028378
[11:15:52.803] iteration 11937 : model1 loss : 0.438078 model2 loss : 0.026230
[11:15:52.975] iteration 11938 : model1 loss : 0.439837 model2 loss : 0.026496
[11:15:53.142] iteration 11939 : model1 loss : 0.435521 model2 loss : 0.023595
[11:15:53.313] iteration 11940 : model1 loss : 0.433999 model2 loss : 0.025453
[11:15:53.480] iteration 11941 : model1 loss : 0.437135 model2 loss : 0.022491
[11:15:53.651] iteration 11942 : model1 loss : 0.437719 model2 loss : 0.024012
[11:15:53.820] iteration 11943 : model1 loss : 0.436915 model2 loss : 0.024165
[11:15:53.987] iteration 11944 : model1 loss : 0.437924 model2 loss : 0.027971
[11:15:54.151] iteration 11945 : model1 loss : 0.437485 model2 loss : 0.042841
[11:15:54.322] iteration 11946 : model1 loss : 0.434493 model2 loss : 0.026854
[11:15:56.248] iteration 11947 : model1 loss : 0.430437 model2 loss : 0.021398
[11:15:56.426] iteration 11948 : model1 loss : 0.437720 model2 loss : 0.025857
[11:15:56.597] iteration 11949 : model1 loss : 0.439518 model2 loss : 0.025391
[11:15:56.763] iteration 11950 : model1 loss : 0.434379 model2 loss : 0.026229
[11:15:56.933] iteration 11951 : model1 loss : 0.441071 model2 loss : 0.027686
[11:15:57.102] iteration 11952 : model1 loss : 0.434191 model2 loss : 0.024054
[11:15:57.271] iteration 11953 : model1 loss : 0.438562 model2 loss : 0.025830
[11:15:57.438] iteration 11954 : model1 loss : 0.440988 model2 loss : 0.028250
[11:15:57.606] iteration 11955 : model1 loss : 0.437539 model2 loss : 0.026642
[11:15:57.774] iteration 11956 : model1 loss : 0.438561 model2 loss : 0.023086
[11:15:57.944] iteration 11957 : model1 loss : 0.438455 model2 loss : 0.024942
[11:15:58.111] iteration 11958 : model1 loss : 0.439118 model2 loss : 0.031673
[11:15:58.281] iteration 11959 : model1 loss : 0.433161 model2 loss : 0.026914
[11:15:58.447] iteration 11960 : model1 loss : 0.435504 model2 loss : 0.028885
[11:15:58.616] iteration 11961 : model1 loss : 0.436602 model2 loss : 0.025893
[11:15:58.782] iteration 11962 : model1 loss : 0.435098 model2 loss : 0.027212
[11:15:58.953] iteration 11963 : model1 loss : 0.428968 model2 loss : 0.023104
[11:15:59.119] iteration 11964 : model1 loss : 0.438096 model2 loss : 0.026842
[11:15:59.288] iteration 11965 : model1 loss : 0.441122 model2 loss : 0.031816
[11:15:59.457] iteration 11966 : model1 loss : 0.438141 model2 loss : 0.026233
[11:15:59.626] iteration 11967 : model1 loss : 0.438595 model2 loss : 0.028460
[11:15:59.792] iteration 11968 : model1 loss : 0.442146 model2 loss : 0.027813
[11:15:59.962] iteration 11969 : model1 loss : 0.438703 model2 loss : 0.030587
[11:16:00.130] iteration 11970 : model1 loss : 0.437981 model2 loss : 0.025958
[11:16:00.301] iteration 11971 : model1 loss : 0.437580 model2 loss : 0.031673
[11:16:00.469] iteration 11972 : model1 loss : 0.433223 model2 loss : 0.024159
[11:16:00.641] iteration 11973 : model1 loss : 0.435014 model2 loss : 0.028301
[11:16:00.808] iteration 11974 : model1 loss : 0.437041 model2 loss : 0.027051
[11:16:00.976] iteration 11975 : model1 loss : 0.437425 model2 loss : 0.025844
[11:16:01.144] iteration 11976 : model1 loss : 0.437338 model2 loss : 0.023653
[11:16:01.312] iteration 11977 : model1 loss : 0.434186 model2 loss : 0.027594
[11:16:01.477] iteration 11978 : model1 loss : 0.437257 model2 loss : 0.027527
[11:16:01.645] iteration 11979 : model1 loss : 0.431993 model2 loss : 0.024273
[11:16:03.536] iteration 11980 : model1 loss : 0.434686 model2 loss : 0.026537
[11:16:03.702] iteration 11981 : model1 loss : 0.435459 model2 loss : 0.021779
[11:16:03.874] iteration 11982 : model1 loss : 0.437736 model2 loss : 0.023957
[11:16:04.042] iteration 11983 : model1 loss : 0.438598 model2 loss : 0.028561
[11:16:04.211] iteration 11984 : model1 loss : 0.439270 model2 loss : 0.028747
[11:16:04.378] iteration 11985 : model1 loss : 0.439243 model2 loss : 0.026743
[11:16:04.547] iteration 11986 : model1 loss : 0.435627 model2 loss : 0.026519
[11:16:04.714] iteration 11987 : model1 loss : 0.438369 model2 loss : 0.024540
[11:16:04.885] iteration 11988 : model1 loss : 0.438063 model2 loss : 0.026150
[11:16:05.051] iteration 11989 : model1 loss : 0.438511 model2 loss : 0.029827
[11:16:05.220] iteration 11990 : model1 loss : 0.437689 model2 loss : 0.025296
[11:16:05.387] iteration 11991 : model1 loss : 0.437531 model2 loss : 0.024110
[11:16:05.558] iteration 11992 : model1 loss : 0.439923 model2 loss : 0.026917
[11:16:05.725] iteration 11993 : model1 loss : 0.431944 model2 loss : 0.022330
[11:16:05.898] iteration 11994 : model1 loss : 0.434363 model2 loss : 0.025276
[11:16:06.066] iteration 11995 : model1 loss : 0.437084 model2 loss : 0.025721
[11:16:06.235] iteration 11996 : model1 loss : 0.435841 model2 loss : 0.021713
[11:16:06.404] iteration 11997 : model1 loss : 0.437736 model2 loss : 0.026445
[11:16:06.573] iteration 11998 : model1 loss : 0.434665 model2 loss : 0.024179
[11:16:06.742] iteration 11999 : model1 loss : 0.441801 model2 loss : 0.027686
[11:16:06.925] iteration 12000 : model1 loss : 0.428855 model2 loss : 0.020376
[11:16:15.193] iteration 12000 : model1_mean_dice : 0.866568 model1_mean_hd95 : 8.444215
[11:16:23.483] iteration 12000 : model2_mean_dice : 0.875159 model2_mean_hd95 : 6.562632
[11:16:23.504] save model1 to ../model/ACDC/EVILv1_kl0.5_tau0.25_21_1337/unet\model1_iter_12000.pth
[11:16:23.523] save model2 to ../model/ACDC/EVILv1_kl0.5_tau0.25_21_1337/unet\model2_iter_12000.pth
[11:16:23.698] iteration 12001 : model1 loss : 0.435067 model2 loss : 0.024601
[11:16:23.870] iteration 12002 : model1 loss : 0.440238 model2 loss : 0.026913
[11:16:24.041] iteration 12003 : model1 loss : 0.434896 model2 loss : 0.023227
[11:16:24.207] iteration 12004 : model1 loss : 0.439392 model2 loss : 0.024941
[11:16:24.375] iteration 12005 : model1 loss : 0.436249 model2 loss : 0.024616
[11:16:24.540] iteration 12006 : model1 loss : 0.435561 model2 loss : 0.025547
[11:16:24.709] iteration 12007 : model1 loss : 0.437190 model2 loss : 0.024113
[11:16:24.877] iteration 12008 : model1 loss : 0.436439 model2 loss : 0.022486
[11:16:25.045] iteration 12009 : model1 loss : 0.437901 model2 loss : 0.025856
[11:16:25.212] iteration 12010 : model1 loss : 0.437927 model2 loss : 0.022686
[11:16:25.380] iteration 12011 : model1 loss : 0.437196 model2 loss : 0.023981
[11:16:25.545] iteration 12012 : model1 loss : 0.437252 model2 loss : 0.022523
[11:16:27.498] iteration 12013 : model1 loss : 0.440926 model2 loss : 0.025960
[11:16:27.664] iteration 12014 : model1 loss : 0.436330 model2 loss : 0.023496
[11:16:27.831] iteration 12015 : model1 loss : 0.435981 model2 loss : 0.025673
[11:16:28.004] iteration 12016 : model1 loss : 0.437062 model2 loss : 0.023080
[11:16:28.173] iteration 12017 : model1 loss : 0.438634 model2 loss : 0.024196
[11:16:28.341] iteration 12018 : model1 loss : 0.439818 model2 loss : 0.026867
[11:16:28.511] iteration 12019 : model1 loss : 0.437142 model2 loss : 0.021856
[11:16:28.677] iteration 12020 : model1 loss : 0.438932 model2 loss : 0.023340
[11:16:28.845] iteration 12021 : model1 loss : 0.435952 model2 loss : 0.023567
[11:16:29.011] iteration 12022 : model1 loss : 0.435377 model2 loss : 0.023914
[11:16:29.181] iteration 12023 : model1 loss : 0.438016 model2 loss : 0.027537
[11:16:29.349] iteration 12024 : model1 loss : 0.437650 model2 loss : 0.025637
[11:16:29.519] iteration 12025 : model1 loss : 0.434385 model2 loss : 0.022230
[11:16:29.686] iteration 12026 : model1 loss : 0.433291 model2 loss : 0.021480
[11:16:29.854] iteration 12027 : model1 loss : 0.437601 model2 loss : 0.028139
[11:16:30.021] iteration 12028 : model1 loss : 0.435866 model2 loss : 0.024126
[11:16:30.189] iteration 12029 : model1 loss : 0.435917 model2 loss : 0.024706
[11:16:30.355] iteration 12030 : model1 loss : 0.438871 model2 loss : 0.026838
[11:16:30.526] iteration 12031 : model1 loss : 0.433277 model2 loss : 0.025611
[11:16:30.693] iteration 12032 : model1 loss : 0.436096 model2 loss : 0.021779
[11:16:30.865] iteration 12033 : model1 loss : 0.436701 model2 loss : 0.023824
[11:16:31.032] iteration 12034 : model1 loss : 0.432211 model2 loss : 0.024876
[11:16:31.201] iteration 12035 : model1 loss : 0.436821 model2 loss : 0.025818
[11:16:31.366] iteration 12036 : model1 loss : 0.435888 model2 loss : 0.025835
[11:16:31.538] iteration 12037 : model1 loss : 0.436704 model2 loss : 0.023380
[11:16:31.708] iteration 12038 : model1 loss : 0.438586 model2 loss : 0.026473
[11:16:31.878] iteration 12039 : model1 loss : 0.438063 model2 loss : 0.026865
[11:16:32.047] iteration 12040 : model1 loss : 0.437245 model2 loss : 0.022651
[11:16:32.213] iteration 12041 : model1 loss : 0.435803 model2 loss : 0.022190
[11:16:32.381] iteration 12042 : model1 loss : 0.433864 model2 loss : 0.022394
[11:16:32.547] iteration 12043 : model1 loss : 0.435027 model2 loss : 0.024724
[11:16:32.712] iteration 12044 : model1 loss : 0.436590 model2 loss : 0.025135
[11:16:32.880] iteration 12045 : model1 loss : 0.444444 model2 loss : 0.027977
[11:16:34.793] iteration 12046 : model1 loss : 0.439318 model2 loss : 0.024810
[11:16:34.964] iteration 12047 : model1 loss : 0.434382 model2 loss : 0.024042
[11:16:35.137] iteration 12048 : model1 loss : 0.436081 model2 loss : 0.023004
[11:16:35.304] iteration 12049 : model1 loss : 0.432256 model2 loss : 0.021179
[11:16:35.473] iteration 12050 : model1 loss : 0.436934 model2 loss : 0.021284
[11:16:35.641] iteration 12051 : model1 loss : 0.435317 model2 loss : 0.023772
[11:16:35.808] iteration 12052 : model1 loss : 0.436003 model2 loss : 0.022772
[11:16:35.978] iteration 12053 : model1 loss : 0.440759 model2 loss : 0.023865
[11:16:36.146] iteration 12054 : model1 loss : 0.433757 model2 loss : 0.024625
[11:16:36.315] iteration 12055 : model1 loss : 0.440511 model2 loss : 0.029557
[11:16:36.483] iteration 12056 : model1 loss : 0.436777 model2 loss : 0.024582
[11:16:36.653] iteration 12057 : model1 loss : 0.439369 model2 loss : 0.027853
[11:16:36.821] iteration 12058 : model1 loss : 0.439232 model2 loss : 0.029307
[11:16:36.990] iteration 12059 : model1 loss : 0.433853 model2 loss : 0.024736
[11:16:37.158] iteration 12060 : model1 loss : 0.436664 model2 loss : 0.026345
[11:16:37.322] iteration 12061 : model1 loss : 0.442511 model2 loss : 0.025424
[11:16:37.494] iteration 12062 : model1 loss : 0.434431 model2 loss : 0.023884
[11:16:37.661] iteration 12063 : model1 loss : 0.438415 model2 loss : 0.028724
[11:16:37.832] iteration 12064 : model1 loss : 0.440050 model2 loss : 0.026444
[11:16:38.002] iteration 12065 : model1 loss : 0.434381 model2 loss : 0.028023
[11:16:38.170] iteration 12066 : model1 loss : 0.434563 model2 loss : 0.023477
[11:16:38.336] iteration 12067 : model1 loss : 0.433775 model2 loss : 0.024380
[11:16:38.511] iteration 12068 : model1 loss : 0.435891 model2 loss : 0.025138
[11:16:38.678] iteration 12069 : model1 loss : 0.437682 model2 loss : 0.024902
[11:16:38.846] iteration 12070 : model1 loss : 0.435008 model2 loss : 0.025442
[11:16:39.014] iteration 12071 : model1 loss : 0.438205 model2 loss : 0.024367
[11:16:39.183] iteration 12072 : model1 loss : 0.435214 model2 loss : 0.022758
[11:16:39.348] iteration 12073 : model1 loss : 0.438115 model2 loss : 0.024657
[11:16:39.520] iteration 12074 : model1 loss : 0.440310 model2 loss : 0.027294
[11:16:39.688] iteration 12075 : model1 loss : 0.438692 model2 loss : 0.025010
[11:16:39.857] iteration 12076 : model1 loss : 0.438712 model2 loss : 0.023873
[11:16:40.022] iteration 12077 : model1 loss : 0.437668 model2 loss : 0.026726
[11:16:40.189] iteration 12078 : model1 loss : 0.433472 model2 loss : 0.023379
[11:16:42.122] iteration 12079 : model1 loss : 0.439536 model2 loss : 0.021466
[11:16:42.289] iteration 12080 : model1 loss : 0.431265 model2 loss : 0.023236
[11:16:42.459] iteration 12081 : model1 loss : 0.433449 model2 loss : 0.023590
[11:16:42.626] iteration 12082 : model1 loss : 0.436058 model2 loss : 0.022677
[11:16:42.796] iteration 12083 : model1 loss : 0.438087 model2 loss : 0.025441
[11:16:42.962] iteration 12084 : model1 loss : 0.435874 model2 loss : 0.027560
[11:16:43.154] iteration 12085 : model1 loss : 0.437995 model2 loss : 0.021762
[11:16:43.321] iteration 12086 : model1 loss : 0.443065 model2 loss : 0.027381
[11:16:43.492] iteration 12087 : model1 loss : 0.436945 model2 loss : 0.022155
[11:16:43.659] iteration 12088 : model1 loss : 0.432466 model2 loss : 0.024006
[11:16:43.829] iteration 12089 : model1 loss : 0.435575 model2 loss : 0.026974
[11:16:43.997] iteration 12090 : model1 loss : 0.437177 model2 loss : 0.026734
[11:16:44.169] iteration 12091 : model1 loss : 0.434277 model2 loss : 0.020553
[11:16:44.335] iteration 12092 : model1 loss : 0.436009 model2 loss : 0.024897
[11:16:44.508] iteration 12093 : model1 loss : 0.432095 model2 loss : 0.023417
[11:16:44.679] iteration 12094 : model1 loss : 0.434525 model2 loss : 0.021705
[11:16:44.847] iteration 12095 : model1 loss : 0.436108 model2 loss : 0.024259
[11:16:45.015] iteration 12096 : model1 loss : 0.439045 model2 loss : 0.024014
[11:16:45.183] iteration 12097 : model1 loss : 0.436221 model2 loss : 0.025362
[11:16:45.352] iteration 12098 : model1 loss : 0.435187 model2 loss : 0.021849
[11:16:45.522] iteration 12099 : model1 loss : 0.440256 model2 loss : 0.025124
[11:16:45.692] iteration 12100 : model1 loss : 0.438588 model2 loss : 0.026072
[11:16:45.863] iteration 12101 : model1 loss : 0.436235 model2 loss : 0.023061
[11:16:46.032] iteration 12102 : model1 loss : 0.440546 model2 loss : 0.024485
[11:16:46.205] iteration 12103 : model1 loss : 0.437090 model2 loss : 0.024952
[11:16:46.374] iteration 12104 : model1 loss : 0.434462 model2 loss : 0.023515
[11:16:46.543] iteration 12105 : model1 loss : 0.439660 model2 loss : 0.025451
[11:16:46.710] iteration 12106 : model1 loss : 0.439067 model2 loss : 0.025967
[11:16:46.879] iteration 12107 : model1 loss : 0.440980 model2 loss : 0.030240
[11:16:47.046] iteration 12108 : model1 loss : 0.433558 model2 loss : 0.025065
[11:16:47.219] iteration 12109 : model1 loss : 0.436204 model2 loss : 0.021758
[11:16:47.385] iteration 12110 : model1 loss : 0.435574 model2 loss : 0.022467
[11:16:47.551] iteration 12111 : model1 loss : 0.437311 model2 loss : 0.026319
[11:16:49.485] iteration 12112 : model1 loss : 0.437961 model2 loss : 0.024377
[11:16:49.654] iteration 12113 : model1 loss : 0.435096 model2 loss : 0.025333
[11:16:49.824] iteration 12114 : model1 loss : 0.439472 model2 loss : 0.026453
[11:16:49.991] iteration 12115 : model1 loss : 0.434904 model2 loss : 0.022345
[11:16:50.159] iteration 12116 : model1 loss : 0.433106 model2 loss : 0.024977
[11:16:50.327] iteration 12117 : model1 loss : 0.435618 model2 loss : 0.027627
[11:16:50.496] iteration 12118 : model1 loss : 0.437719 model2 loss : 0.024678
[11:16:50.664] iteration 12119 : model1 loss : 0.434950 model2 loss : 0.027898
[11:16:50.836] iteration 12120 : model1 loss : 0.441956 model2 loss : 0.025087
[11:16:51.003] iteration 12121 : model1 loss : 0.438574 model2 loss : 0.026112
[11:16:51.173] iteration 12122 : model1 loss : 0.440020 model2 loss : 0.025619
[11:16:51.337] iteration 12123 : model1 loss : 0.436762 model2 loss : 0.023614
[11:16:51.512] iteration 12124 : model1 loss : 0.431961 model2 loss : 0.023048
[11:16:51.681] iteration 12125 : model1 loss : 0.435428 model2 loss : 0.023848
[11:16:51.850] iteration 12126 : model1 loss : 0.431207 model2 loss : 0.019999
[11:16:52.018] iteration 12127 : model1 loss : 0.434701 model2 loss : 0.023302
[11:16:52.187] iteration 12128 : model1 loss : 0.438890 model2 loss : 0.029157
[11:16:52.355] iteration 12129 : model1 loss : 0.436300 model2 loss : 0.026684
[11:16:52.525] iteration 12130 : model1 loss : 0.439704 model2 loss : 0.024920
[11:16:52.694] iteration 12131 : model1 loss : 0.434998 model2 loss : 0.023327
[11:16:52.863] iteration 12132 : model1 loss : 0.441501 model2 loss : 0.027716
[11:16:53.032] iteration 12133 : model1 loss : 0.438031 model2 loss : 0.023999
[11:16:53.201] iteration 12134 : model1 loss : 0.433453 model2 loss : 0.024454
[11:16:53.369] iteration 12135 : model1 loss : 0.439278 model2 loss : 0.026717
[11:16:53.540] iteration 12136 : model1 loss : 0.440846 model2 loss : 0.023714
[11:16:53.708] iteration 12137 : model1 loss : 0.437071 model2 loss : 0.025014
[11:16:53.878] iteration 12138 : model1 loss : 0.431885 model2 loss : 0.020809
[11:16:54.046] iteration 12139 : model1 loss : 0.438105 model2 loss : 0.024872
[11:16:54.214] iteration 12140 : model1 loss : 0.437404 model2 loss : 0.025349
[11:16:54.381] iteration 12141 : model1 loss : 0.436279 model2 loss : 0.026656
[11:16:54.550] iteration 12142 : model1 loss : 0.437423 model2 loss : 0.024495
[11:16:54.715] iteration 12143 : model1 loss : 0.438546 model2 loss : 0.022645
[11:16:54.883] iteration 12144 : model1 loss : 0.439646 model2 loss : 0.024798
[11:16:56.864] iteration 12145 : model1 loss : 0.432387 model2 loss : 0.024421
[11:16:57.033] iteration 12146 : model1 loss : 0.441637 model2 loss : 0.026824
[11:16:57.205] iteration 12147 : model1 loss : 0.433481 model2 loss : 0.024008
[11:16:57.371] iteration 12148 : model1 loss : 0.435747 model2 loss : 0.023010
[11:16:57.542] iteration 12149 : model1 loss : 0.441741 model2 loss : 0.030454
[11:16:57.709] iteration 12150 : model1 loss : 0.440266 model2 loss : 0.025247
[11:16:57.877] iteration 12151 : model1 loss : 0.436961 model2 loss : 0.022061
[11:16:58.047] iteration 12152 : model1 loss : 0.437246 model2 loss : 0.021699
[11:16:58.214] iteration 12153 : model1 loss : 0.439034 model2 loss : 0.025455
[11:16:58.382] iteration 12154 : model1 loss : 0.437244 model2 loss : 0.025469
[11:16:58.551] iteration 12155 : model1 loss : 0.433915 model2 loss : 0.022151
[11:16:58.717] iteration 12156 : model1 loss : 0.436746 model2 loss : 0.024095
[11:16:58.886] iteration 12157 : model1 loss : 0.435538 model2 loss : 0.024741
[11:16:59.054] iteration 12158 : model1 loss : 0.438952 model2 loss : 0.026582
[11:16:59.222] iteration 12159 : model1 loss : 0.435928 model2 loss : 0.028970
[11:16:59.388] iteration 12160 : model1 loss : 0.435823 model2 loss : 0.026119
[11:16:59.558] iteration 12161 : model1 loss : 0.434100 model2 loss : 0.025952
[11:16:59.727] iteration 12162 : model1 loss : 0.437254 model2 loss : 0.026274
[11:16:59.895] iteration 12163 : model1 loss : 0.440415 model2 loss : 0.030578
[11:17:00.062] iteration 12164 : model1 loss : 0.432757 model2 loss : 0.019503
[11:17:00.231] iteration 12165 : model1 loss : 0.441915 model2 loss : 0.023847
[11:17:00.398] iteration 12166 : model1 loss : 0.439658 model2 loss : 0.023640
[11:17:00.571] iteration 12167 : model1 loss : 0.438422 model2 loss : 0.024727
[11:17:00.739] iteration 12168 : model1 loss : 0.439690 model2 loss : 0.025685
[11:17:00.911] iteration 12169 : model1 loss : 0.434450 model2 loss : 0.025530
[11:17:01.078] iteration 12170 : model1 loss : 0.435972 model2 loss : 0.023605
[11:17:01.250] iteration 12171 : model1 loss : 0.436081 model2 loss : 0.023931
[11:17:01.416] iteration 12172 : model1 loss : 0.434202 model2 loss : 0.021453
[11:17:01.589] iteration 12173 : model1 loss : 0.431710 model2 loss : 0.023448
[11:17:01.755] iteration 12174 : model1 loss : 0.436277 model2 loss : 0.026658
[11:17:01.923] iteration 12175 : model1 loss : 0.438613 model2 loss : 0.026055
[11:17:02.089] iteration 12176 : model1 loss : 0.434391 model2 loss : 0.025346
[11:17:02.255] iteration 12177 : model1 loss : 0.440395 model2 loss : 0.026819
[11:17:04.201] iteration 12178 : model1 loss : 0.437069 model2 loss : 0.025827
[11:17:04.370] iteration 12179 : model1 loss : 0.433977 model2 loss : 0.024224
[11:17:04.539] iteration 12180 : model1 loss : 0.439857 model2 loss : 0.028953
[11:17:04.706] iteration 12181 : model1 loss : 0.442513 model2 loss : 0.029426
[11:17:04.876] iteration 12182 : model1 loss : 0.440195 model2 loss : 0.025274
[11:17:05.043] iteration 12183 : model1 loss : 0.437514 model2 loss : 0.025912
[11:17:05.213] iteration 12184 : model1 loss : 0.435647 model2 loss : 0.023764
[11:17:05.379] iteration 12185 : model1 loss : 0.437566 model2 loss : 0.026429
[11:17:05.550] iteration 12186 : model1 loss : 0.435245 model2 loss : 0.028621
[11:17:05.716] iteration 12187 : model1 loss : 0.435186 model2 loss : 0.024965
[11:17:05.889] iteration 12188 : model1 loss : 0.433844 model2 loss : 0.027210
[11:17:06.060] iteration 12189 : model1 loss : 0.435998 model2 loss : 0.022246
[11:17:06.228] iteration 12190 : model1 loss : 0.433863 model2 loss : 0.025325
[11:17:06.393] iteration 12191 : model1 loss : 0.438694 model2 loss : 0.023655
[11:17:06.563] iteration 12192 : model1 loss : 0.439639 model2 loss : 0.024485
[11:17:06.730] iteration 12193 : model1 loss : 0.438353 model2 loss : 0.027365
[11:17:06.899] iteration 12194 : model1 loss : 0.437333 model2 loss : 0.027927
[11:17:07.067] iteration 12195 : model1 loss : 0.433891 model2 loss : 0.023429
[11:17:07.236] iteration 12196 : model1 loss : 0.441467 model2 loss : 0.024754
[11:17:07.403] iteration 12197 : model1 loss : 0.433648 model2 loss : 0.022687
[11:17:07.571] iteration 12198 : model1 loss : 0.433932 model2 loss : 0.020877
[11:17:07.737] iteration 12199 : model1 loss : 0.440407 model2 loss : 0.027663
[11:17:07.907] iteration 12200 : model1 loss : 0.435822 model2 loss : 0.023696
[11:17:08.076] iteration 12201 : model1 loss : 0.434113 model2 loss : 0.025385
[11:17:08.246] iteration 12202 : model1 loss : 0.435996 model2 loss : 0.023357
[11:17:08.413] iteration 12203 : model1 loss : 0.435006 model2 loss : 0.024283
[11:17:08.583] iteration 12204 : model1 loss : 0.440802 model2 loss : 0.027513
[11:17:08.750] iteration 12205 : model1 loss : 0.437649 model2 loss : 0.024203
[11:17:08.918] iteration 12206 : model1 loss : 0.438584 model2 loss : 0.025914
[11:17:09.086] iteration 12207 : model1 loss : 0.434178 model2 loss : 0.023915
[11:17:09.256] iteration 12208 : model1 loss : 0.432416 model2 loss : 0.023695
[11:17:09.423] iteration 12209 : model1 loss : 0.438033 model2 loss : 0.029334
[11:17:09.590] iteration 12210 : model1 loss : 0.439514 model2 loss : 0.025645
[11:17:11.534] iteration 12211 : model1 loss : 0.433255 model2 loss : 0.022744
[11:17:11.700] iteration 12212 : model1 loss : 0.440085 model2 loss : 0.025253
[11:17:11.870] iteration 12213 : model1 loss : 0.433185 model2 loss : 0.022374
[11:17:12.037] iteration 12214 : model1 loss : 0.445527 model2 loss : 0.029919
[11:17:12.207] iteration 12215 : model1 loss : 0.436804 model2 loss : 0.027108
[11:17:12.384] iteration 12216 : model1 loss : 0.440559 model2 loss : 0.023640
[11:17:12.554] iteration 12217 : model1 loss : 0.436492 model2 loss : 0.025460
[11:17:12.721] iteration 12218 : model1 loss : 0.436833 model2 loss : 0.018804
[11:17:12.889] iteration 12219 : model1 loss : 0.441479 model2 loss : 0.027279
[11:17:13.057] iteration 12220 : model1 loss : 0.440327 model2 loss : 0.024196
[11:17:13.227] iteration 12221 : model1 loss : 0.439361 model2 loss : 0.023246
[11:17:13.396] iteration 12222 : model1 loss : 0.435823 model2 loss : 0.023601
[11:17:13.566] iteration 12223 : model1 loss : 0.433686 model2 loss : 0.021886
[11:17:13.734] iteration 12224 : model1 loss : 0.441094 model2 loss : 0.028133
[11:17:13.904] iteration 12225 : model1 loss : 0.436722 model2 loss : 0.021605
[11:17:14.071] iteration 12226 : model1 loss : 0.435150 model2 loss : 0.024169
[11:17:14.242] iteration 12227 : model1 loss : 0.437441 model2 loss : 0.024839
[11:17:14.413] iteration 12228 : model1 loss : 0.436683 model2 loss : 0.023792
[11:17:14.582] iteration 12229 : model1 loss : 0.435001 model2 loss : 0.024966
[11:17:14.750] iteration 12230 : model1 loss : 0.437331 model2 loss : 0.024630
[11:17:14.920] iteration 12231 : model1 loss : 0.438742 model2 loss : 0.025204
[11:17:15.089] iteration 12232 : model1 loss : 0.442088 model2 loss : 0.028437
[11:17:15.259] iteration 12233 : model1 loss : 0.438006 model2 loss : 0.025783
[11:17:15.426] iteration 12234 : model1 loss : 0.430026 model2 loss : 0.023177
[11:17:15.595] iteration 12235 : model1 loss : 0.436372 model2 loss : 0.026249
[11:17:15.762] iteration 12236 : model1 loss : 0.438771 model2 loss : 0.023939
[11:17:15.929] iteration 12237 : model1 loss : 0.434463 model2 loss : 0.025291
[11:17:16.101] iteration 12238 : model1 loss : 0.439678 model2 loss : 0.024963
[11:17:16.271] iteration 12239 : model1 loss : 0.433658 model2 loss : 0.022313
[11:17:16.438] iteration 12240 : model1 loss : 0.439253 model2 loss : 0.027638
[11:17:16.607] iteration 12241 : model1 loss : 0.433734 model2 loss : 0.024632
[11:17:16.772] iteration 12242 : model1 loss : 0.435964 model2 loss : 0.024234
[11:17:16.940] iteration 12243 : model1 loss : 0.437909 model2 loss : 0.026196
[11:17:18.879] iteration 12244 : model1 loss : 0.440929 model2 loss : 0.030042
[11:17:19.045] iteration 12245 : model1 loss : 0.434262 model2 loss : 0.022195
[11:17:19.214] iteration 12246 : model1 loss : 0.436845 model2 loss : 0.024372
[11:17:19.381] iteration 12247 : model1 loss : 0.438322 model2 loss : 0.025907
[11:17:19.551] iteration 12248 : model1 loss : 0.432826 model2 loss : 0.021785
[11:17:19.718] iteration 12249 : model1 loss : 0.438559 model2 loss : 0.028207
[11:17:19.887] iteration 12250 : model1 loss : 0.442039 model2 loss : 0.026503
[11:17:20.053] iteration 12251 : model1 loss : 0.435633 model2 loss : 0.022552
[11:17:20.222] iteration 12252 : model1 loss : 0.435723 model2 loss : 0.024020
[11:17:20.389] iteration 12253 : model1 loss : 0.436706 model2 loss : 0.026706
[11:17:20.559] iteration 12254 : model1 loss : 0.436587 model2 loss : 0.025136
[11:17:20.727] iteration 12255 : model1 loss : 0.435678 model2 loss : 0.022234
[11:17:20.899] iteration 12256 : model1 loss : 0.436800 model2 loss : 0.023989
[11:17:21.067] iteration 12257 : model1 loss : 0.438171 model2 loss : 0.024107
[11:17:21.236] iteration 12258 : model1 loss : 0.438744 model2 loss : 0.025376
[11:17:21.404] iteration 12259 : model1 loss : 0.433792 model2 loss : 0.024680
[11:17:21.571] iteration 12260 : model1 loss : 0.433388 model2 loss : 0.024319
[11:17:21.740] iteration 12261 : model1 loss : 0.436679 model2 loss : 0.025495
[11:17:21.911] iteration 12262 : model1 loss : 0.439614 model2 loss : 0.030007
[11:17:22.077] iteration 12263 : model1 loss : 0.438736 model2 loss : 0.021716
[11:17:22.259] iteration 12264 : model1 loss : 0.438677 model2 loss : 0.026119
[11:17:22.426] iteration 12265 : model1 loss : 0.439374 model2 loss : 0.023896
[11:17:22.596] iteration 12266 : model1 loss : 0.440419 model2 loss : 0.025542
[11:17:22.770] iteration 12267 : model1 loss : 0.434288 model2 loss : 0.022917
[11:17:22.939] iteration 12268 : model1 loss : 0.438585 model2 loss : 0.031015
[11:17:23.111] iteration 12269 : model1 loss : 0.438955 model2 loss : 0.025649
[11:17:23.282] iteration 12270 : model1 loss : 0.436402 model2 loss : 0.025156
[11:17:23.448] iteration 12271 : model1 loss : 0.434785 model2 loss : 0.023205
[11:17:23.619] iteration 12272 : model1 loss : 0.439598 model2 loss : 0.028672
[11:17:23.787] iteration 12273 : model1 loss : 0.435593 model2 loss : 0.024397
[11:17:23.956] iteration 12274 : model1 loss : 0.431157 model2 loss : 0.024378
[11:17:24.125] iteration 12275 : model1 loss : 0.436575 model2 loss : 0.026050
[11:17:24.295] iteration 12276 : model1 loss : 0.438717 model2 loss : 0.024684
[11:17:26.241] iteration 12277 : model1 loss : 0.444928 model2 loss : 0.036247
[11:17:26.417] iteration 12278 : model1 loss : 0.431059 model2 loss : 0.023260
[11:17:26.587] iteration 12279 : model1 loss : 0.436499 model2 loss : 0.023198
[11:17:26.754] iteration 12280 : model1 loss : 0.436535 model2 loss : 0.022494
[11:17:26.924] iteration 12281 : model1 loss : 0.434611 model2 loss : 0.024373
[11:17:27.096] iteration 12282 : model1 loss : 0.434543 model2 loss : 0.027478
[11:17:27.266] iteration 12283 : model1 loss : 0.433895 model2 loss : 0.023703
[11:17:27.432] iteration 12284 : model1 loss : 0.434815 model2 loss : 0.025151
[11:17:27.600] iteration 12285 : model1 loss : 0.435821 model2 loss : 0.025817
[11:17:27.767] iteration 12286 : model1 loss : 0.440169 model2 loss : 0.025733
[11:17:27.934] iteration 12287 : model1 loss : 0.439401 model2 loss : 0.022090
[11:17:28.106] iteration 12288 : model1 loss : 0.441715 model2 loss : 0.034464
[11:17:28.277] iteration 12289 : model1 loss : 0.437255 model2 loss : 0.027296
[11:17:28.444] iteration 12290 : model1 loss : 0.437533 model2 loss : 0.026824
[11:17:28.613] iteration 12291 : model1 loss : 0.437933 model2 loss : 0.029026
[11:17:28.779] iteration 12292 : model1 loss : 0.438552 model2 loss : 0.025526
[11:17:28.949] iteration 12293 : model1 loss : 0.433479 model2 loss : 0.024880
[11:17:29.121] iteration 12294 : model1 loss : 0.431802 model2 loss : 0.024001
[11:17:29.289] iteration 12295 : model1 loss : 0.438653 model2 loss : 0.031218
[11:17:29.458] iteration 12296 : model1 loss : 0.432507 model2 loss : 0.024518
[11:17:29.628] iteration 12297 : model1 loss : 0.434324 model2 loss : 0.025870
[11:17:29.795] iteration 12298 : model1 loss : 0.442666 model2 loss : 0.028294
[11:17:29.965] iteration 12299 : model1 loss : 0.438544 model2 loss : 0.028340
[11:17:30.135] iteration 12300 : model1 loss : 0.439839 model2 loss : 0.030279
[11:17:30.306] iteration 12301 : model1 loss : 0.434497 model2 loss : 0.023556
[11:17:30.474] iteration 12302 : model1 loss : 0.436125 model2 loss : 0.026437
[11:17:30.642] iteration 12303 : model1 loss : 0.438289 model2 loss : 0.027540
[11:17:30.810] iteration 12304 : model1 loss : 0.435552 model2 loss : 0.024947
[11:17:30.978] iteration 12305 : model1 loss : 0.436396 model2 loss : 0.024215
[11:17:31.147] iteration 12306 : model1 loss : 0.437534 model2 loss : 0.024918
[11:17:31.315] iteration 12307 : model1 loss : 0.438734 model2 loss : 0.025774
[11:17:31.480] iteration 12308 : model1 loss : 0.437075 model2 loss : 0.024617
[11:17:31.649] iteration 12309 : model1 loss : 0.438493 model2 loss : 0.025860
[11:17:33.557] iteration 12310 : model1 loss : 0.440560 model2 loss : 0.023098
[11:17:33.724] iteration 12311 : model1 loss : 0.437036 model2 loss : 0.021390
[11:17:33.896] iteration 12312 : model1 loss : 0.438773 model2 loss : 0.027153
[11:17:34.062] iteration 12313 : model1 loss : 0.437258 model2 loss : 0.025501
[11:17:34.248] iteration 12314 : model1 loss : 0.434636 model2 loss : 0.027176
[11:17:34.416] iteration 12315 : model1 loss : 0.439933 model2 loss : 0.026161
[11:17:34.586] iteration 12316 : model1 loss : 0.437431 model2 loss : 0.024477
[11:17:34.752] iteration 12317 : model1 loss : 0.438387 model2 loss : 0.024419
[11:17:34.923] iteration 12318 : model1 loss : 0.439705 model2 loss : 0.027015
[11:17:35.089] iteration 12319 : model1 loss : 0.435781 model2 loss : 0.019462
[11:17:35.260] iteration 12320 : model1 loss : 0.440708 model2 loss : 0.026590
[11:17:35.428] iteration 12321 : model1 loss : 0.437430 model2 loss : 0.023829
[11:17:35.597] iteration 12322 : model1 loss : 0.434310 model2 loss : 0.023810
[11:17:35.764] iteration 12323 : model1 loss : 0.438398 model2 loss : 0.025448
[11:17:35.935] iteration 12324 : model1 loss : 0.435698 model2 loss : 0.024461
[11:17:36.102] iteration 12325 : model1 loss : 0.435307 model2 loss : 0.024730
[11:17:36.271] iteration 12326 : model1 loss : 0.441325 model2 loss : 0.022204
[11:17:36.436] iteration 12327 : model1 loss : 0.437201 model2 loss : 0.026948
[11:17:36.605] iteration 12328 : model1 loss : 0.436678 model2 loss : 0.022686
[11:17:36.772] iteration 12329 : model1 loss : 0.435444 model2 loss : 0.023045
[11:17:36.943] iteration 12330 : model1 loss : 0.427690 model2 loss : 0.023581
[11:17:37.111] iteration 12331 : model1 loss : 0.436211 model2 loss : 0.026058
[11:17:37.279] iteration 12332 : model1 loss : 0.438726 model2 loss : 0.027810
[11:17:37.446] iteration 12333 : model1 loss : 0.440506 model2 loss : 0.033776
[11:17:37.614] iteration 12334 : model1 loss : 0.436108 model2 loss : 0.021877
[11:17:37.781] iteration 12335 : model1 loss : 0.438347 model2 loss : 0.025743
[11:17:37.949] iteration 12336 : model1 loss : 0.436930 model2 loss : 0.022371
[11:17:38.116] iteration 12337 : model1 loss : 0.436096 model2 loss : 0.024060
[11:17:38.283] iteration 12338 : model1 loss : 0.435775 model2 loss : 0.022742
[11:17:38.453] iteration 12339 : model1 loss : 0.437168 model2 loss : 0.023658
[11:17:38.622] iteration 12340 : model1 loss : 0.434328 model2 loss : 0.023500
[11:17:38.786] iteration 12341 : model1 loss : 0.437853 model2 loss : 0.024614
[11:17:38.955] iteration 12342 : model1 loss : 0.435396 model2 loss : 0.025795
[11:17:40.899] iteration 12343 : model1 loss : 0.443151 model2 loss : 0.026160
[11:17:41.066] iteration 12344 : model1 loss : 0.439119 model2 loss : 0.031035
[11:17:41.236] iteration 12345 : model1 loss : 0.430487 model2 loss : 0.021705
[11:17:41.401] iteration 12346 : model1 loss : 0.433758 model2 loss : 0.023603
[11:17:41.576] iteration 12347 : model1 loss : 0.432193 model2 loss : 0.023758
[11:17:41.744] iteration 12348 : model1 loss : 0.437934 model2 loss : 0.027393
[11:17:41.915] iteration 12349 : model1 loss : 0.438499 model2 loss : 0.022195
[11:17:42.084] iteration 12350 : model1 loss : 0.439423 model2 loss : 0.024661
[11:17:42.251] iteration 12351 : model1 loss : 0.438593 model2 loss : 0.024192
[11:17:42.417] iteration 12352 : model1 loss : 0.439886 model2 loss : 0.024919
[11:17:42.587] iteration 12353 : model1 loss : 0.433134 model2 loss : 0.023242
[11:17:42.755] iteration 12354 : model1 loss : 0.432298 model2 loss : 0.022972
[11:17:42.926] iteration 12355 : model1 loss : 0.440168 model2 loss : 0.029186
[11:17:43.094] iteration 12356 : model1 loss : 0.434449 model2 loss : 0.024532
[11:17:43.262] iteration 12357 : model1 loss : 0.439366 model2 loss : 0.027606
[11:17:43.428] iteration 12358 : model1 loss : 0.438722 model2 loss : 0.024062
[11:17:43.598] iteration 12359 : model1 loss : 0.438812 model2 loss : 0.026599
[11:17:43.766] iteration 12360 : model1 loss : 0.438783 model2 loss : 0.024671
[11:17:43.934] iteration 12361 : model1 loss : 0.436961 model2 loss : 0.025788
[11:17:44.102] iteration 12362 : model1 loss : 0.442644 model2 loss : 0.030152
[11:17:44.270] iteration 12363 : model1 loss : 0.436842 model2 loss : 0.026438
[11:17:44.439] iteration 12364 : model1 loss : 0.442916 model2 loss : 0.028884
[11:17:44.618] iteration 12365 : model1 loss : 0.439103 model2 loss : 0.024502
[11:17:44.787] iteration 12366 : model1 loss : 0.431524 model2 loss : 0.029493
[11:17:44.955] iteration 12367 : model1 loss : 0.438405 model2 loss : 0.022757
[11:17:45.123] iteration 12368 : model1 loss : 0.438711 model2 loss : 0.028882
[11:17:45.291] iteration 12369 : model1 loss : 0.436740 model2 loss : 0.024973
[11:17:45.461] iteration 12370 : model1 loss : 0.439126 model2 loss : 0.020766
[11:17:45.630] iteration 12371 : model1 loss : 0.437599 model2 loss : 0.025659
[11:17:45.798] iteration 12372 : model1 loss : 0.435795 model2 loss : 0.023220
[11:17:45.968] iteration 12373 : model1 loss : 0.441507 model2 loss : 0.025906
[11:17:46.136] iteration 12374 : model1 loss : 0.439935 model2 loss : 0.028440
[11:17:46.304] iteration 12375 : model1 loss : 0.436645 model2 loss : 0.023226
[11:17:48.266] iteration 12376 : model1 loss : 0.435873 model2 loss : 0.023588
[11:17:48.433] iteration 12377 : model1 loss : 0.434548 model2 loss : 0.024399
[11:17:48.605] iteration 12378 : model1 loss : 0.435710 model2 loss : 0.023674
[11:17:48.770] iteration 12379 : model1 loss : 0.435418 model2 loss : 0.025554
[11:17:48.939] iteration 12380 : model1 loss : 0.442954 model2 loss : 0.028315
[11:17:49.105] iteration 12381 : model1 loss : 0.438305 model2 loss : 0.026607
[11:17:49.277] iteration 12382 : model1 loss : 0.435901 model2 loss : 0.022360
[11:17:49.445] iteration 12383 : model1 loss : 0.441004 model2 loss : 0.026907
[11:17:49.612] iteration 12384 : model1 loss : 0.435063 model2 loss : 0.020195
[11:17:49.780] iteration 12385 : model1 loss : 0.438501 model2 loss : 0.025169
[11:17:49.948] iteration 12386 : model1 loss : 0.438532 model2 loss : 0.025810
[11:17:50.114] iteration 12387 : model1 loss : 0.437686 model2 loss : 0.026404
[11:17:50.284] iteration 12388 : model1 loss : 0.437543 model2 loss : 0.020617
[11:17:50.451] iteration 12389 : model1 loss : 0.438141 model2 loss : 0.029887
[11:17:50.619] iteration 12390 : model1 loss : 0.436267 model2 loss : 0.023545
[11:17:50.785] iteration 12391 : model1 loss : 0.437023 model2 loss : 0.023662
[11:17:50.954] iteration 12392 : model1 loss : 0.435495 model2 loss : 0.023843
[11:17:51.120] iteration 12393 : model1 loss : 0.438018 model2 loss : 0.023122
[11:17:51.291] iteration 12394 : model1 loss : 0.433640 model2 loss : 0.024650
[11:17:51.458] iteration 12395 : model1 loss : 0.439523 model2 loss : 0.025898
[11:17:51.629] iteration 12396 : model1 loss : 0.436026 model2 loss : 0.022624
[11:17:51.796] iteration 12397 : model1 loss : 0.433674 model2 loss : 0.020876
[11:17:51.967] iteration 12398 : model1 loss : 0.433074 model2 loss : 0.022622
[11:17:52.132] iteration 12399 : model1 loss : 0.439260 model2 loss : 0.028950
[11:17:52.301] iteration 12400 : model1 loss : 0.433015 model2 loss : 0.023767
[11:17:52.466] iteration 12401 : model1 loss : 0.435745 model2 loss : 0.024804
[11:17:52.641] iteration 12402 : model1 loss : 0.435410 model2 loss : 0.024971
[11:17:52.807] iteration 12403 : model1 loss : 0.434328 model2 loss : 0.024664
[11:17:52.977] iteration 12404 : model1 loss : 0.439529 model2 loss : 0.024555
[11:17:53.147] iteration 12405 : model1 loss : 0.439690 model2 loss : 0.030848
[11:17:53.317] iteration 12406 : model1 loss : 0.440465 model2 loss : 0.024380
[11:17:53.484] iteration 12407 : model1 loss : 0.438193 model2 loss : 0.025230
[11:17:53.655] iteration 12408 : model1 loss : 0.435457 model2 loss : 0.022816
[11:17:55.651] iteration 12409 : model1 loss : 0.434581 model2 loss : 0.024226
[11:17:55.820] iteration 12410 : model1 loss : 0.439501 model2 loss : 0.022859
[11:17:55.989] iteration 12411 : model1 loss : 0.437074 model2 loss : 0.027382
[11:17:56.157] iteration 12412 : model1 loss : 0.439259 model2 loss : 0.024955
[11:17:56.327] iteration 12413 : model1 loss : 0.434141 model2 loss : 0.022922
[11:17:56.495] iteration 12414 : model1 loss : 0.442980 model2 loss : 0.029826
[11:17:56.663] iteration 12415 : model1 loss : 0.437391 model2 loss : 0.025951
[11:17:56.830] iteration 12416 : model1 loss : 0.439513 model2 loss : 0.024432
[11:17:57.000] iteration 12417 : model1 loss : 0.438835 model2 loss : 0.025708
[11:17:57.171] iteration 12418 : model1 loss : 0.433632 model2 loss : 0.024611
[11:17:57.338] iteration 12419 : model1 loss : 0.439661 model2 loss : 0.026895
[11:17:57.507] iteration 12420 : model1 loss : 0.436465 model2 loss : 0.025590
[11:17:57.677] iteration 12421 : model1 loss : 0.434485 model2 loss : 0.025182
[11:17:57.855] iteration 12422 : model1 loss : 0.439600 model2 loss : 0.025990
[11:17:58.035] iteration 12423 : model1 loss : 0.439720 model2 loss : 0.026368
[11:17:58.213] iteration 12424 : model1 loss : 0.436481 model2 loss : 0.027287
[11:17:58.401] iteration 12425 : model1 loss : 0.435488 model2 loss : 0.022493
[11:17:58.581] iteration 12426 : model1 loss : 0.434150 model2 loss : 0.024904
[11:17:58.764] iteration 12427 : model1 loss : 0.437319 model2 loss : 0.021942
[11:17:58.944] iteration 12428 : model1 loss : 0.433142 model2 loss : 0.025509
[11:17:59.124] iteration 12429 : model1 loss : 0.434110 model2 loss : 0.023839
[11:17:59.304] iteration 12430 : model1 loss : 0.442061 model2 loss : 0.027695
[11:17:59.486] iteration 12431 : model1 loss : 0.433700 model2 loss : 0.025346
[11:17:59.665] iteration 12432 : model1 loss : 0.439343 model2 loss : 0.027089
[11:17:59.842] iteration 12433 : model1 loss : 0.435307 model2 loss : 0.023172
[11:18:00.010] iteration 12434 : model1 loss : 0.435192 model2 loss : 0.028750
[11:18:00.182] iteration 12435 : model1 loss : 0.440255 model2 loss : 0.026546
[11:18:00.350] iteration 12436 : model1 loss : 0.431738 model2 loss : 0.022880
[11:18:00.523] iteration 12437 : model1 loss : 0.432337 model2 loss : 0.024298
[11:18:00.690] iteration 12438 : model1 loss : 0.436850 model2 loss : 0.026911
[11:18:00.864] iteration 12439 : model1 loss : 0.437206 model2 loss : 0.023739
[11:18:01.029] iteration 12440 : model1 loss : 0.435830 model2 loss : 0.025439
[11:18:01.200] iteration 12441 : model1 loss : 0.441123 model2 loss : 0.027269
[11:18:03.196] iteration 12442 : model1 loss : 0.436181 model2 loss : 0.022154
[11:18:03.365] iteration 12443 : model1 loss : 0.443294 model2 loss : 0.028037
[11:18:03.534] iteration 12444 : model1 loss : 0.439259 model2 loss : 0.024277
[11:18:03.701] iteration 12445 : model1 loss : 0.438165 model2 loss : 0.028176
[11:18:03.874] iteration 12446 : model1 loss : 0.437811 model2 loss : 0.024201
[11:18:04.040] iteration 12447 : model1 loss : 0.436661 model2 loss : 0.024369
[11:18:04.210] iteration 12448 : model1 loss : 0.436805 model2 loss : 0.024325
[11:18:04.378] iteration 12449 : model1 loss : 0.438295 model2 loss : 0.024881
[11:18:04.547] iteration 12450 : model1 loss : 0.435248 model2 loss : 0.023800
[11:18:04.714] iteration 12451 : model1 loss : 0.434664 model2 loss : 0.024049
[11:18:04.887] iteration 12452 : model1 loss : 0.438483 model2 loss : 0.026886
[11:18:05.054] iteration 12453 : model1 loss : 0.436729 model2 loss : 0.024055
[11:18:05.223] iteration 12454 : model1 loss : 0.438669 model2 loss : 0.026165
[11:18:05.392] iteration 12455 : model1 loss : 0.434338 model2 loss : 0.025076
[11:18:05.561] iteration 12456 : model1 loss : 0.435474 model2 loss : 0.027484
[11:18:05.728] iteration 12457 : model1 loss : 0.438095 model2 loss : 0.025670
[11:18:05.903] iteration 12458 : model1 loss : 0.434416 model2 loss : 0.021906
[11:18:06.070] iteration 12459 : model1 loss : 0.440228 model2 loss : 0.025224
[11:18:06.240] iteration 12460 : model1 loss : 0.442185 model2 loss : 0.035050
[11:18:06.408] iteration 12461 : model1 loss : 0.436769 model2 loss : 0.025687
[11:18:06.578] iteration 12462 : model1 loss : 0.433110 model2 loss : 0.021675
[11:18:06.745] iteration 12463 : model1 loss : 0.438593 model2 loss : 0.025965
[11:18:06.915] iteration 12464 : model1 loss : 0.439222 model2 loss : 0.024460
[11:18:07.080] iteration 12465 : model1 loss : 0.434498 model2 loss : 0.025934
[11:18:07.253] iteration 12466 : model1 loss : 0.433375 model2 loss : 0.024861
[11:18:07.421] iteration 12467 : model1 loss : 0.433062 model2 loss : 0.020510
[11:18:07.588] iteration 12468 : model1 loss : 0.435247 model2 loss : 0.026332
[11:18:07.756] iteration 12469 : model1 loss : 0.440132 model2 loss : 0.024992
[11:18:07.923] iteration 12470 : model1 loss : 0.438898 model2 loss : 0.024649
[11:18:08.090] iteration 12471 : model1 loss : 0.436554 model2 loss : 0.023949
[11:18:08.262] iteration 12472 : model1 loss : 0.434611 model2 loss : 0.028084
[11:18:08.427] iteration 12473 : model1 loss : 0.432789 model2 loss : 0.022699
[11:18:08.595] iteration 12474 : model1 loss : 0.438551 model2 loss : 0.022651
[11:18:10.516] iteration 12475 : model1 loss : 0.435987 model2 loss : 0.024108
[11:18:10.685] iteration 12476 : model1 loss : 0.435921 model2 loss : 0.024961
[11:18:10.856] iteration 12477 : model1 loss : 0.435701 model2 loss : 0.021594
[11:18:11.022] iteration 12478 : model1 loss : 0.434766 model2 loss : 0.021642
[11:18:11.192] iteration 12479 : model1 loss : 0.437743 model2 loss : 0.026754
[11:18:11.359] iteration 12480 : model1 loss : 0.439894 model2 loss : 0.024512
[11:18:11.533] iteration 12481 : model1 loss : 0.437336 model2 loss : 0.023431
[11:18:11.697] iteration 12482 : model1 loss : 0.437454 model2 loss : 0.026978
[11:18:11.867] iteration 12483 : model1 loss : 0.431407 model2 loss : 0.025172
[11:18:12.036] iteration 12484 : model1 loss : 0.438089 model2 loss : 0.021533
[11:18:12.205] iteration 12485 : model1 loss : 0.438223 model2 loss : 0.025751
[11:18:12.371] iteration 12486 : model1 loss : 0.435131 model2 loss : 0.019156
[11:18:12.542] iteration 12487 : model1 loss : 0.432175 model2 loss : 0.023057
[11:18:12.708] iteration 12488 : model1 loss : 0.438466 model2 loss : 0.026445
[11:18:12.877] iteration 12489 : model1 loss : 0.439744 model2 loss : 0.026645
[11:18:13.044] iteration 12490 : model1 loss : 0.438499 model2 loss : 0.023543
[11:18:13.214] iteration 12491 : model1 loss : 0.440771 model2 loss : 0.024093
[11:18:13.380] iteration 12492 : model1 loss : 0.436865 model2 loss : 0.024854
[11:18:13.549] iteration 12493 : model1 loss : 0.436268 model2 loss : 0.024115
[11:18:13.717] iteration 12494 : model1 loss : 0.437369 model2 loss : 0.026452
[11:18:13.886] iteration 12495 : model1 loss : 0.437899 model2 loss : 0.025849
[11:18:14.054] iteration 12496 : model1 loss : 0.439825 model2 loss : 0.027793
[11:18:14.224] iteration 12497 : model1 loss : 0.436284 model2 loss : 0.023704
[11:18:14.391] iteration 12498 : model1 loss : 0.434446 model2 loss : 0.025032
[11:18:14.561] iteration 12499 : model1 loss : 0.435537 model2 loss : 0.025016
[11:18:14.729] iteration 12500 : model1 loss : 0.437869 model2 loss : 0.027098
[11:18:14.898] iteration 12501 : model1 loss : 0.435756 model2 loss : 0.024247
[11:18:15.066] iteration 12502 : model1 loss : 0.435664 model2 loss : 0.026086
[11:18:15.235] iteration 12503 : model1 loss : 0.437216 model2 loss : 0.022623
[11:18:15.402] iteration 12504 : model1 loss : 0.441706 model2 loss : 0.026018
[11:18:15.573] iteration 12505 : model1 loss : 0.436996 model2 loss : 0.025501
[11:18:15.739] iteration 12506 : model1 loss : 0.437459 model2 loss : 0.028027
[11:18:15.909] iteration 12507 : model1 loss : 0.432920 model2 loss : 0.021696
[11:18:17.815] iteration 12508 : model1 loss : 0.436631 model2 loss : 0.022870
[11:18:17.981] iteration 12509 : model1 loss : 0.433974 model2 loss : 0.022303
[11:18:18.153] iteration 12510 : model1 loss : 0.436736 model2 loss : 0.023571
[11:18:18.323] iteration 12511 : model1 loss : 0.433756 model2 loss : 0.022220
[11:18:18.495] iteration 12512 : model1 loss : 0.437769 model2 loss : 0.022788
[11:18:18.660] iteration 12513 : model1 loss : 0.434730 model2 loss : 0.020579
[11:18:18.837] iteration 12514 : model1 loss : 0.444435 model2 loss : 0.026461
[11:18:19.004] iteration 12515 : model1 loss : 0.435912 model2 loss : 0.023895
[11:18:19.174] iteration 12516 : model1 loss : 0.435630 model2 loss : 0.028554
[11:18:19.339] iteration 12517 : model1 loss : 0.439263 model2 loss : 0.026564
[11:18:19.510] iteration 12518 : model1 loss : 0.431018 model2 loss : 0.022996
[11:18:19.678] iteration 12519 : model1 loss : 0.433834 model2 loss : 0.021019
[11:18:19.846] iteration 12520 : model1 loss : 0.437687 model2 loss : 0.025269
[11:18:20.015] iteration 12521 : model1 loss : 0.436790 model2 loss : 0.025763
[11:18:20.183] iteration 12522 : model1 loss : 0.435822 model2 loss : 0.023183
[11:18:20.353] iteration 12523 : model1 loss : 0.436412 model2 loss : 0.021363
[11:18:20.525] iteration 12524 : model1 loss : 0.435866 model2 loss : 0.023022
[11:18:20.691] iteration 12525 : model1 loss : 0.438630 model2 loss : 0.025586
[11:18:20.862] iteration 12526 : model1 loss : 0.434681 model2 loss : 0.024009
[11:18:21.029] iteration 12527 : model1 loss : 0.436625 model2 loss : 0.025230
[11:18:21.199] iteration 12528 : model1 loss : 0.441985 model2 loss : 0.029669
[11:18:21.366] iteration 12529 : model1 loss : 0.439431 model2 loss : 0.025671
[11:18:21.536] iteration 12530 : model1 loss : 0.434213 model2 loss : 0.023737
[11:18:21.702] iteration 12531 : model1 loss : 0.439497 model2 loss : 0.026240
[11:18:21.873] iteration 12532 : model1 loss : 0.434916 model2 loss : 0.025255
[11:18:22.040] iteration 12533 : model1 loss : 0.437700 model2 loss : 0.026174
[11:18:22.208] iteration 12534 : model1 loss : 0.437310 model2 loss : 0.024865
[11:18:22.375] iteration 12535 : model1 loss : 0.433068 model2 loss : 0.023608
[11:18:22.546] iteration 12536 : model1 loss : 0.438505 model2 loss : 0.024777
[11:18:22.713] iteration 12537 : model1 loss : 0.434369 model2 loss : 0.023347
[11:18:22.882] iteration 12538 : model1 loss : 0.436757 model2 loss : 0.026397
[11:18:23.049] iteration 12539 : model1 loss : 0.442008 model2 loss : 0.026317
[11:18:23.216] iteration 12540 : model1 loss : 0.439081 model2 loss : 0.024670
[11:18:25.105] iteration 12541 : model1 loss : 0.439123 model2 loss : 0.024642
[11:18:25.271] iteration 12542 : model1 loss : 0.437123 model2 loss : 0.023004
[11:18:25.440] iteration 12543 : model1 loss : 0.436521 model2 loss : 0.023927
[11:18:25.607] iteration 12544 : model1 loss : 0.435534 model2 loss : 0.023892
[11:18:25.775] iteration 12545 : model1 loss : 0.433642 model2 loss : 0.022161
[11:18:25.943] iteration 12546 : model1 loss : 0.435275 model2 loss : 0.023143
[11:18:26.112] iteration 12547 : model1 loss : 0.437219 model2 loss : 0.026380
[11:18:26.277] iteration 12548 : model1 loss : 0.435570 model2 loss : 0.023094
[11:18:26.445] iteration 12549 : model1 loss : 0.442088 model2 loss : 0.025828
[11:18:26.613] iteration 12550 : model1 loss : 0.437320 model2 loss : 0.022217
[11:18:26.784] iteration 12551 : model1 loss : 0.434695 model2 loss : 0.024735
[11:18:26.952] iteration 12552 : model1 loss : 0.436979 model2 loss : 0.022776
[11:18:27.122] iteration 12553 : model1 loss : 0.438912 model2 loss : 0.025573
[11:18:27.289] iteration 12554 : model1 loss : 0.439862 model2 loss : 0.025260
[11:18:27.456] iteration 12555 : model1 loss : 0.432862 model2 loss : 0.023456
[11:18:27.622] iteration 12556 : model1 loss : 0.436298 model2 loss : 0.022303
[11:18:27.790] iteration 12557 : model1 loss : 0.435935 model2 loss : 0.023095
[11:18:27.957] iteration 12558 : model1 loss : 0.433237 model2 loss : 0.022659
[11:18:28.125] iteration 12559 : model1 loss : 0.437616 model2 loss : 0.022845
[11:18:28.294] iteration 12560 : model1 loss : 0.436452 model2 loss : 0.023563
[11:18:28.463] iteration 12561 : model1 loss : 0.437927 model2 loss : 0.024697
[11:18:28.630] iteration 12562 : model1 loss : 0.435101 model2 loss : 0.025171
[11:18:28.798] iteration 12563 : model1 loss : 0.433390 model2 loss : 0.027664
[11:18:28.964] iteration 12564 : model1 loss : 0.435600 model2 loss : 0.024324
[11:18:29.132] iteration 12565 : model1 loss : 0.438835 model2 loss : 0.022643
[11:18:29.298] iteration 12566 : model1 loss : 0.439202 model2 loss : 0.026187
[11:18:29.467] iteration 12567 : model1 loss : 0.439648 model2 loss : 0.026969
[11:18:29.634] iteration 12568 : model1 loss : 0.435308 model2 loss : 0.024977
[11:18:29.802] iteration 12569 : model1 loss : 0.433913 model2 loss : 0.024474
[11:18:29.970] iteration 12570 : model1 loss : 0.440466 model2 loss : 0.025451
[11:18:30.137] iteration 12571 : model1 loss : 0.438775 model2 loss : 0.025682
[11:18:30.303] iteration 12572 : model1 loss : 0.438479 model2 loss : 0.024036
[11:18:30.472] iteration 12573 : model1 loss : 0.434373 model2 loss : 0.026459
[11:18:32.400] iteration 12574 : model1 loss : 0.438706 model2 loss : 0.027984
[11:18:32.572] iteration 12575 : model1 loss : 0.437341 model2 loss : 0.022266
[11:18:32.744] iteration 12576 : model1 loss : 0.438984 model2 loss : 0.022443
[11:18:32.910] iteration 12577 : model1 loss : 0.437244 model2 loss : 0.025016
[11:18:33.082] iteration 12578 : model1 loss : 0.436439 model2 loss : 0.025658
[11:18:33.250] iteration 12579 : model1 loss : 0.434662 model2 loss : 0.023793
[11:18:33.419] iteration 12580 : model1 loss : 0.437507 model2 loss : 0.025885
[11:18:33.586] iteration 12581 : model1 loss : 0.434382 model2 loss : 0.022751
[11:18:33.755] iteration 12582 : model1 loss : 0.440725 model2 loss : 0.028222
[11:18:33.923] iteration 12583 : model1 loss : 0.440795 model2 loss : 0.025025
[11:18:34.092] iteration 12584 : model1 loss : 0.436370 model2 loss : 0.022400
[11:18:34.260] iteration 12585 : model1 loss : 0.435161 model2 loss : 0.026196
[11:18:34.432] iteration 12586 : model1 loss : 0.435458 model2 loss : 0.021753
[11:18:34.598] iteration 12587 : model1 loss : 0.432420 model2 loss : 0.024344
[11:18:34.769] iteration 12588 : model1 loss : 0.438679 model2 loss : 0.024164
[11:18:34.936] iteration 12589 : model1 loss : 0.433906 model2 loss : 0.023318
[11:18:35.106] iteration 12590 : model1 loss : 0.436898 model2 loss : 0.022694
[11:18:35.273] iteration 12591 : model1 loss : 0.437246 model2 loss : 0.024387
[11:18:35.442] iteration 12592 : model1 loss : 0.436436 model2 loss : 0.023785
[11:18:35.610] iteration 12593 : model1 loss : 0.435906 model2 loss : 0.025222
[11:18:35.781] iteration 12594 : model1 loss : 0.434758 model2 loss : 0.023728
[11:18:35.951] iteration 12595 : model1 loss : 0.441465 model2 loss : 0.026451
[11:18:36.121] iteration 12596 : model1 loss : 0.434738 model2 loss : 0.024007
[11:18:36.288] iteration 12597 : model1 loss : 0.435570 model2 loss : 0.022117
[11:18:36.458] iteration 12598 : model1 loss : 0.436145 model2 loss : 0.024114
[11:18:36.625] iteration 12599 : model1 loss : 0.435968 model2 loss : 0.025428
[11:18:36.794] iteration 12600 : model1 loss : 0.434431 model2 loss : 0.023141
[11:18:36.962] iteration 12601 : model1 loss : 0.437734 model2 loss : 0.025050
[11:18:37.130] iteration 12602 : model1 loss : 0.431718 model2 loss : 0.022257
[11:18:37.298] iteration 12603 : model1 loss : 0.442579 model2 loss : 0.026952
[11:18:37.469] iteration 12604 : model1 loss : 0.435110 model2 loss : 0.020013
[11:18:37.634] iteration 12605 : model1 loss : 0.438578 model2 loss : 0.024514
[11:18:37.802] iteration 12606 : model1 loss : 0.438124 model2 loss : 0.024507
[11:18:39.771] iteration 12607 : model1 loss : 0.435428 model2 loss : 0.023959
[11:18:39.939] iteration 12608 : model1 loss : 0.439791 model2 loss : 0.025519
[11:18:40.106] iteration 12609 : model1 loss : 0.433164 model2 loss : 0.025315
[11:18:40.273] iteration 12610 : model1 loss : 0.435453 model2 loss : 0.027428
[11:18:40.443] iteration 12611 : model1 loss : 0.435342 model2 loss : 0.024878
[11:18:40.611] iteration 12612 : model1 loss : 0.438181 model2 loss : 0.023057
[11:18:40.781] iteration 12613 : model1 loss : 0.439269 model2 loss : 0.022657
[11:18:40.947] iteration 12614 : model1 loss : 0.440002 model2 loss : 0.024578
[11:18:41.116] iteration 12615 : model1 loss : 0.435575 model2 loss : 0.022660
[11:18:41.282] iteration 12616 : model1 loss : 0.430162 model2 loss : 0.023773
[11:18:41.451] iteration 12617 : model1 loss : 0.433749 model2 loss : 0.022150
[11:18:41.618] iteration 12618 : model1 loss : 0.434421 model2 loss : 0.025743
[11:18:41.790] iteration 12619 : model1 loss : 0.438556 model2 loss : 0.025409
[11:18:41.958] iteration 12620 : model1 loss : 0.437836 model2 loss : 0.023563
[11:18:42.128] iteration 12621 : model1 loss : 0.437825 model2 loss : 0.027011
[11:18:42.295] iteration 12622 : model1 loss : 0.440440 model2 loss : 0.034716
[11:18:42.464] iteration 12623 : model1 loss : 0.438374 model2 loss : 0.021873
[11:18:42.631] iteration 12624 : model1 loss : 0.435406 model2 loss : 0.025494
[11:18:42.801] iteration 12625 : model1 loss : 0.439298 model2 loss : 0.027179
[11:18:42.967] iteration 12626 : model1 loss : 0.438284 model2 loss : 0.023586
[11:18:43.136] iteration 12627 : model1 loss : 0.439396 model2 loss : 0.023117
[11:18:43.302] iteration 12628 : model1 loss : 0.434648 model2 loss : 0.022519
[11:18:43.473] iteration 12629 : model1 loss : 0.436882 model2 loss : 0.025390
[11:18:43.640] iteration 12630 : model1 loss : 0.437631 model2 loss : 0.025900
[11:18:43.810] iteration 12631 : model1 loss : 0.434650 model2 loss : 0.028237
[11:18:43.977] iteration 12632 : model1 loss : 0.439299 model2 loss : 0.027549
[11:18:44.148] iteration 12633 : model1 loss : 0.436310 model2 loss : 0.021969
[11:18:44.316] iteration 12634 : model1 loss : 0.434195 model2 loss : 0.023346
[11:18:44.488] iteration 12635 : model1 loss : 0.436730 model2 loss : 0.024042
[11:18:44.655] iteration 12636 : model1 loss : 0.435841 model2 loss : 0.022735
[11:18:44.823] iteration 12637 : model1 loss : 0.437452 model2 loss : 0.025563
[11:18:44.989] iteration 12638 : model1 loss : 0.444135 model2 loss : 0.030590
[11:18:45.156] iteration 12639 : model1 loss : 0.433459 model2 loss : 0.023452
[11:18:47.069] iteration 12640 : model1 loss : 0.430162 model2 loss : 0.022509
[11:18:47.237] iteration 12641 : model1 loss : 0.434441 model2 loss : 0.025654
[11:18:47.408] iteration 12642 : model1 loss : 0.438206 model2 loss : 0.021292
[11:18:47.577] iteration 12643 : model1 loss : 0.441939 model2 loss : 0.029346
[11:18:47.747] iteration 12644 : model1 loss : 0.434350 model2 loss : 0.023397
[11:18:47.917] iteration 12645 : model1 loss : 0.440640 model2 loss : 0.022128
[11:18:48.086] iteration 12646 : model1 loss : 0.436105 model2 loss : 0.022544
[11:18:48.254] iteration 12647 : model1 loss : 0.435217 model2 loss : 0.025121
[11:18:48.424] iteration 12648 : model1 loss : 0.435510 model2 loss : 0.022988
[11:18:48.600] iteration 12649 : model1 loss : 0.438148 model2 loss : 0.026550
[11:18:48.773] iteration 12650 : model1 loss : 0.437278 model2 loss : 0.027670
[11:18:48.940] iteration 12651 : model1 loss : 0.439409 model2 loss : 0.026477
[11:18:49.110] iteration 12652 : model1 loss : 0.440002 model2 loss : 0.023540
[11:18:49.277] iteration 12653 : model1 loss : 0.441285 model2 loss : 0.026325
[11:18:49.447] iteration 12654 : model1 loss : 0.439752 model2 loss : 0.026707
[11:18:49.617] iteration 12655 : model1 loss : 0.432705 model2 loss : 0.022956
[11:18:49.787] iteration 12656 : model1 loss : 0.437903 model2 loss : 0.033154
[11:18:49.956] iteration 12657 : model1 loss : 0.437546 model2 loss : 0.027280
[11:18:50.127] iteration 12658 : model1 loss : 0.435949 model2 loss : 0.023600
[11:18:50.294] iteration 12659 : model1 loss : 0.436354 model2 loss : 0.033531
[11:18:50.463] iteration 12660 : model1 loss : 0.436396 model2 loss : 0.028138
[11:18:50.629] iteration 12661 : model1 loss : 0.442192 model2 loss : 0.031987
[11:18:50.799] iteration 12662 : model1 loss : 0.434224 model2 loss : 0.023218
[11:18:50.967] iteration 12663 : model1 loss : 0.442034 model2 loss : 0.036774
[11:18:51.136] iteration 12664 : model1 loss : 0.438481 model2 loss : 0.025760
[11:18:51.305] iteration 12665 : model1 loss : 0.441304 model2 loss : 0.028901
[11:18:51.474] iteration 12666 : model1 loss : 0.438683 model2 loss : 0.029598
[11:18:51.640] iteration 12667 : model1 loss : 0.437703 model2 loss : 0.028886
[11:18:51.810] iteration 12668 : model1 loss : 0.431972 model2 loss : 0.035638
[11:18:51.976] iteration 12669 : model1 loss : 0.439503 model2 loss : 0.030032
[11:18:52.145] iteration 12670 : model1 loss : 0.438915 model2 loss : 0.026269
[11:18:52.311] iteration 12671 : model1 loss : 0.439376 model2 loss : 0.024469
[11:18:52.480] iteration 12672 : model1 loss : 0.434660 model2 loss : 0.025478
[11:18:54.417] iteration 12673 : model1 loss : 0.434708 model2 loss : 0.027442
[11:18:54.584] iteration 12674 : model1 loss : 0.437469 model2 loss : 0.027593
[11:18:54.754] iteration 12675 : model1 loss : 0.440634 model2 loss : 0.030462
[11:18:54.921] iteration 12676 : model1 loss : 0.439591 model2 loss : 0.027230
[11:18:55.089] iteration 12677 : model1 loss : 0.436763 model2 loss : 0.024771
[11:18:55.257] iteration 12678 : model1 loss : 0.437365 model2 loss : 0.026722
[11:18:55.424] iteration 12679 : model1 loss : 0.438426 model2 loss : 0.033951
[11:18:55.591] iteration 12680 : model1 loss : 0.438088 model2 loss : 0.024773
[11:18:55.760] iteration 12681 : model1 loss : 0.440820 model2 loss : 0.030115
[11:18:55.928] iteration 12682 : model1 loss : 0.434938 model2 loss : 0.023658
[11:18:56.098] iteration 12683 : model1 loss : 0.437989 model2 loss : 0.026553
[11:18:56.265] iteration 12684 : model1 loss : 0.439548 model2 loss : 0.031744
[11:18:56.434] iteration 12685 : model1 loss : 0.440281 model2 loss : 0.028047
[11:18:56.601] iteration 12686 : model1 loss : 0.436720 model2 loss : 0.023574
[11:18:56.771] iteration 12687 : model1 loss : 0.444953 model2 loss : 0.026566
[11:18:56.939] iteration 12688 : model1 loss : 0.441794 model2 loss : 0.031775
[11:18:57.106] iteration 12689 : model1 loss : 0.442833 model2 loss : 0.033781
[11:18:57.274] iteration 12690 : model1 loss : 0.441583 model2 loss : 0.028459
[11:18:57.444] iteration 12691 : model1 loss : 0.439530 model2 loss : 0.032102
[11:18:57.612] iteration 12692 : model1 loss : 0.436485 model2 loss : 0.027366
[11:18:57.783] iteration 12693 : model1 loss : 0.440116 model2 loss : 0.025649
[11:18:57.949] iteration 12694 : model1 loss : 0.434498 model2 loss : 0.027636
[11:18:58.121] iteration 12695 : model1 loss : 0.439223 model2 loss : 0.030822
[11:18:58.288] iteration 12696 : model1 loss : 0.434324 model2 loss : 0.025057
[11:18:58.458] iteration 12697 : model1 loss : 0.434868 model2 loss : 0.038909
[11:18:58.625] iteration 12698 : model1 loss : 0.441083 model2 loss : 0.030522
[11:18:58.818] iteration 12699 : model1 loss : 0.435494 model2 loss : 0.026018
[11:18:58.985] iteration 12700 : model1 loss : 0.443968 model2 loss : 0.032582
[11:18:59.154] iteration 12701 : model1 loss : 0.437057 model2 loss : 0.023540
[11:18:59.323] iteration 12702 : model1 loss : 0.435051 model2 loss : 0.023982
[11:18:59.494] iteration 12703 : model1 loss : 0.436433 model2 loss : 0.031479
[11:18:59.660] iteration 12704 : model1 loss : 0.433092 model2 loss : 0.025825
[11:18:59.828] iteration 12705 : model1 loss : 0.438691 model2 loss : 0.033850
[11:19:01.770] iteration 12706 : model1 loss : 0.437225 model2 loss : 0.030161
[11:19:01.942] iteration 12707 : model1 loss : 0.436652 model2 loss : 0.027916
[11:19:02.112] iteration 12708 : model1 loss : 0.438840 model2 loss : 0.028768
[11:19:02.281] iteration 12709 : model1 loss : 0.435612 model2 loss : 0.025543
[11:19:02.451] iteration 12710 : model1 loss : 0.433162 model2 loss : 0.023295
[11:19:02.620] iteration 12711 : model1 loss : 0.437951 model2 loss : 0.024037
[11:19:02.791] iteration 12712 : model1 loss : 0.436182 model2 loss : 0.029516
[11:19:02.958] iteration 12713 : model1 loss : 0.438492 model2 loss : 0.026848
[11:19:03.130] iteration 12714 : model1 loss : 0.433476 model2 loss : 0.023493
[11:19:03.297] iteration 12715 : model1 loss : 0.443370 model2 loss : 0.026420
[11:19:03.469] iteration 12716 : model1 loss : 0.435968 model2 loss : 0.024893
[11:19:03.636] iteration 12717 : model1 loss : 0.440410 model2 loss : 0.028254
[11:19:03.825] iteration 12718 : model1 loss : 0.434422 model2 loss : 0.025507
[11:19:03.993] iteration 12719 : model1 loss : 0.436707 model2 loss : 0.031994
[11:19:04.163] iteration 12720 : model1 loss : 0.439225 model2 loss : 0.027364
[11:19:04.330] iteration 12721 : model1 loss : 0.437598 model2 loss : 0.028500
[11:19:04.501] iteration 12722 : model1 loss : 0.443501 model2 loss : 0.031557
[11:19:04.668] iteration 12723 : model1 loss : 0.438068 model2 loss : 0.028653
[11:19:04.838] iteration 12724 : model1 loss : 0.433982 model2 loss : 0.029109
[11:19:05.005] iteration 12725 : model1 loss : 0.439714 model2 loss : 0.027897
[11:19:05.172] iteration 12726 : model1 loss : 0.439522 model2 loss : 0.025952
[11:19:05.342] iteration 12727 : model1 loss : 0.439864 model2 loss : 0.024100
[11:19:05.516] iteration 12728 : model1 loss : 0.436772 model2 loss : 0.027156
[11:19:05.682] iteration 12729 : model1 loss : 0.433574 model2 loss : 0.019881
[11:19:05.852] iteration 12730 : model1 loss : 0.435401 model2 loss : 0.028018
[11:19:06.022] iteration 12731 : model1 loss : 0.432461 model2 loss : 0.021990
[11:19:06.190] iteration 12732 : model1 loss : 0.441478 model2 loss : 0.029739
[11:19:06.359] iteration 12733 : model1 loss : 0.438145 model2 loss : 0.026037
[11:19:06.530] iteration 12734 : model1 loss : 0.437445 model2 loss : 0.022519
[11:19:06.697] iteration 12735 : model1 loss : 0.433178 model2 loss : 0.024346
[11:19:06.865] iteration 12736 : model1 loss : 0.441284 model2 loss : 0.030925
[11:19:07.032] iteration 12737 : model1 loss : 0.437949 model2 loss : 0.024842
[11:19:07.201] iteration 12738 : model1 loss : 0.442195 model2 loss : 0.028869
[11:19:09.175] iteration 12739 : model1 loss : 0.438085 model2 loss : 0.025757
[11:19:09.343] iteration 12740 : model1 loss : 0.434857 model2 loss : 0.025164
[11:19:09.516] iteration 12741 : model1 loss : 0.435261 model2 loss : 0.026577
[11:19:09.683] iteration 12742 : model1 loss : 0.437968 model2 loss : 0.023725
[11:19:09.855] iteration 12743 : model1 loss : 0.435374 model2 loss : 0.023609
[11:19:10.023] iteration 12744 : model1 loss : 0.440056 model2 loss : 0.031473
[11:19:10.209] iteration 12745 : model1 loss : 0.439629 model2 loss : 0.025793
[11:19:10.380] iteration 12746 : model1 loss : 0.438723 model2 loss : 0.024397
[11:19:10.548] iteration 12747 : model1 loss : 0.442167 model2 loss : 0.027076
[11:19:10.718] iteration 12748 : model1 loss : 0.438167 model2 loss : 0.026211
[11:19:10.891] iteration 12749 : model1 loss : 0.435426 model2 loss : 0.023503
[11:19:11.059] iteration 12750 : model1 loss : 0.435419 model2 loss : 0.023960
[11:19:11.229] iteration 12751 : model1 loss : 0.441888 model2 loss : 0.023502
[11:19:11.398] iteration 12752 : model1 loss : 0.433141 model2 loss : 0.024669
[11:19:11.569] iteration 12753 : model1 loss : 0.437207 model2 loss : 0.025259
[11:19:11.736] iteration 12754 : model1 loss : 0.439546 model2 loss : 0.023689
[11:19:11.905] iteration 12755 : model1 loss : 0.436107 model2 loss : 0.027767
[11:19:12.070] iteration 12756 : model1 loss : 0.430897 model2 loss : 0.022368
[11:19:12.239] iteration 12757 : model1 loss : 0.433434 model2 loss : 0.023861
[11:19:12.409] iteration 12758 : model1 loss : 0.436965 model2 loss : 0.026184
[11:19:12.580] iteration 12759 : model1 loss : 0.438275 model2 loss : 0.026209
[11:19:12.748] iteration 12760 : model1 loss : 0.437504 model2 loss : 0.023215
[11:19:12.916] iteration 12761 : model1 loss : 0.436592 model2 loss : 0.027542
[11:19:13.084] iteration 12762 : model1 loss : 0.431943 model2 loss : 0.023590
[11:19:13.255] iteration 12763 : model1 loss : 0.438510 model2 loss : 0.023236
[11:19:13.424] iteration 12764 : model1 loss : 0.439141 model2 loss : 0.022189
[11:19:13.594] iteration 12765 : model1 loss : 0.437287 model2 loss : 0.023005
[11:19:13.761] iteration 12766 : model1 loss : 0.430549 model2 loss : 0.020971
[11:19:13.930] iteration 12767 : model1 loss : 0.434448 model2 loss : 0.024023
[11:19:14.098] iteration 12768 : model1 loss : 0.434227 model2 loss : 0.026881
[11:19:14.267] iteration 12769 : model1 loss : 0.436897 model2 loss : 0.022572
[11:19:14.433] iteration 12770 : model1 loss : 0.441972 model2 loss : 0.028769
[11:19:14.602] iteration 12771 : model1 loss : 0.444835 model2 loss : 0.033502
[11:19:16.511] iteration 12772 : model1 loss : 0.443112 model2 loss : 0.024730
[11:19:16.679] iteration 12773 : model1 loss : 0.435104 model2 loss : 0.025350
[11:19:16.849] iteration 12774 : model1 loss : 0.439815 model2 loss : 0.024481
[11:19:17.016] iteration 12775 : model1 loss : 0.432617 model2 loss : 0.024993
[11:19:17.186] iteration 12776 : model1 loss : 0.433413 model2 loss : 0.026300
[11:19:17.352] iteration 12777 : model1 loss : 0.434736 model2 loss : 0.025214
[11:19:17.524] iteration 12778 : model1 loss : 0.436494 model2 loss : 0.023349
[11:19:17.692] iteration 12779 : model1 loss : 0.435178 model2 loss : 0.022879
[11:19:17.861] iteration 12780 : model1 loss : 0.435655 model2 loss : 0.024538
[11:19:18.027] iteration 12781 : model1 loss : 0.438084 model2 loss : 0.025087
[11:19:18.196] iteration 12782 : model1 loss : 0.436139 model2 loss : 0.026221
[11:19:18.363] iteration 12783 : model1 loss : 0.439952 model2 loss : 0.027895
[11:19:18.536] iteration 12784 : model1 loss : 0.437301 model2 loss : 0.023160
[11:19:18.702] iteration 12785 : model1 loss : 0.439461 model2 loss : 0.025503
[11:19:18.871] iteration 12786 : model1 loss : 0.438069 model2 loss : 0.022334
[11:19:19.038] iteration 12787 : model1 loss : 0.435802 model2 loss : 0.022782
[11:19:19.210] iteration 12788 : model1 loss : 0.443722 model2 loss : 0.034894
[11:19:19.379] iteration 12789 : model1 loss : 0.438368 model2 loss : 0.026648
[11:19:19.551] iteration 12790 : model1 loss : 0.437513 model2 loss : 0.026623
[11:19:19.716] iteration 12791 : model1 loss : 0.432968 model2 loss : 0.023349
[11:19:19.887] iteration 12792 : model1 loss : 0.439795 model2 loss : 0.027569
[11:19:20.055] iteration 12793 : model1 loss : 0.439589 model2 loss : 0.028380
[11:19:20.225] iteration 12794 : model1 loss : 0.436589 model2 loss : 0.024185
[11:19:20.394] iteration 12795 : model1 loss : 0.435456 model2 loss : 0.021786
[11:19:20.565] iteration 12796 : model1 loss : 0.438298 model2 loss : 0.022530
[11:19:20.731] iteration 12797 : model1 loss : 0.435031 model2 loss : 0.023773
[11:19:20.902] iteration 12798 : model1 loss : 0.437101 model2 loss : 0.022412
[11:19:21.074] iteration 12799 : model1 loss : 0.434218 model2 loss : 0.025000
[11:19:21.244] iteration 12800 : model1 loss : 0.433570 model2 loss : 0.024646
[11:19:21.414] iteration 12801 : model1 loss : 0.437742 model2 loss : 0.025636
[11:19:21.582] iteration 12802 : model1 loss : 0.439380 model2 loss : 0.037026
[11:19:21.748] iteration 12803 : model1 loss : 0.432810 model2 loss : 0.020771
[11:19:21.916] iteration 12804 : model1 loss : 0.434222 model2 loss : 0.023531
[11:19:23.832] iteration 12805 : model1 loss : 0.435597 model2 loss : 0.025791
[11:19:24.001] iteration 12806 : model1 loss : 0.434621 model2 loss : 0.023381
[11:19:24.170] iteration 12807 : model1 loss : 0.436672 model2 loss : 0.023478
[11:19:24.339] iteration 12808 : model1 loss : 0.438085 model2 loss : 0.022185
[11:19:24.508] iteration 12809 : model1 loss : 0.439367 model2 loss : 0.025100
[11:19:24.677] iteration 12810 : model1 loss : 0.440184 model2 loss : 0.028021
[11:19:24.847] iteration 12811 : model1 loss : 0.439087 model2 loss : 0.026649
[11:19:25.014] iteration 12812 : model1 loss : 0.433438 model2 loss : 0.022603
[11:19:25.184] iteration 12813 : model1 loss : 0.434406 model2 loss : 0.024787
[11:19:25.353] iteration 12814 : model1 loss : 0.437995 model2 loss : 0.025096
[11:19:25.524] iteration 12815 : model1 loss : 0.434985 model2 loss : 0.024676
[11:19:25.691] iteration 12816 : model1 loss : 0.434372 model2 loss : 0.021947
[11:19:25.861] iteration 12817 : model1 loss : 0.436183 model2 loss : 0.022993
[11:19:26.029] iteration 12818 : model1 loss : 0.435488 model2 loss : 0.021866
[11:19:26.199] iteration 12819 : model1 loss : 0.441042 model2 loss : 0.025106
[11:19:26.368] iteration 12820 : model1 loss : 0.435427 model2 loss : 0.024431
[11:19:26.537] iteration 12821 : model1 loss : 0.437485 model2 loss : 0.026413
[11:19:26.704] iteration 12822 : model1 loss : 0.436472 model2 loss : 0.024039
[11:19:26.873] iteration 12823 : model1 loss : 0.434003 model2 loss : 0.023273
[11:19:27.038] iteration 12824 : model1 loss : 0.435469 model2 loss : 0.024100
[11:19:27.208] iteration 12825 : model1 loss : 0.438466 model2 loss : 0.024958
[11:19:27.374] iteration 12826 : model1 loss : 0.437214 model2 loss : 0.023626
[11:19:27.548] iteration 12827 : model1 loss : 0.439529 model2 loss : 0.029017
[11:19:27.716] iteration 12828 : model1 loss : 0.438679 model2 loss : 0.027251
[11:19:27.886] iteration 12829 : model1 loss : 0.437787 model2 loss : 0.028791
[11:19:28.053] iteration 12830 : model1 loss : 0.436025 model2 loss : 0.026452
[11:19:28.222] iteration 12831 : model1 loss : 0.436829 model2 loss : 0.026723
[11:19:28.392] iteration 12832 : model1 loss : 0.435931 model2 loss : 0.020980
[11:19:28.563] iteration 12833 : model1 loss : 0.436908 model2 loss : 0.022629
[11:19:28.742] iteration 12834 : model1 loss : 0.434169 model2 loss : 0.023396
[11:19:28.914] iteration 12835 : model1 loss : 0.440244 model2 loss : 0.026344
[11:19:29.080] iteration 12836 : model1 loss : 0.437235 model2 loss : 0.024559
[11:19:29.248] iteration 12837 : model1 loss : 0.434491 model2 loss : 0.022326
[11:19:31.190] iteration 12838 : model1 loss : 0.437556 model2 loss : 0.022950
[11:19:31.359] iteration 12839 : model1 loss : 0.436505 model2 loss : 0.023998
[11:19:31.531] iteration 12840 : model1 loss : 0.435107 model2 loss : 0.024242
[11:19:31.700] iteration 12841 : model1 loss : 0.437802 model2 loss : 0.020895
[11:19:31.869] iteration 12842 : model1 loss : 0.435868 model2 loss : 0.024874
[11:19:32.034] iteration 12843 : model1 loss : 0.441682 model2 loss : 0.034256
[11:19:32.205] iteration 12844 : model1 loss : 0.433438 model2 loss : 0.025092
[11:19:32.373] iteration 12845 : model1 loss : 0.437379 model2 loss : 0.027309
[11:19:32.544] iteration 12846 : model1 loss : 0.431726 model2 loss : 0.023717
[11:19:32.711] iteration 12847 : model1 loss : 0.438470 model2 loss : 0.022046
[11:19:32.882] iteration 12848 : model1 loss : 0.434610 model2 loss : 0.026529
[11:19:33.049] iteration 12849 : model1 loss : 0.436142 model2 loss : 0.021813
[11:19:33.219] iteration 12850 : model1 loss : 0.436644 model2 loss : 0.023743
[11:19:33.387] iteration 12851 : model1 loss : 0.439686 model2 loss : 0.031653
[11:19:33.559] iteration 12852 : model1 loss : 0.435522 model2 loss : 0.023760
[11:19:33.725] iteration 12853 : model1 loss : 0.441146 model2 loss : 0.024051
[11:19:33.895] iteration 12854 : model1 loss : 0.436170 model2 loss : 0.022352
[11:19:34.064] iteration 12855 : model1 loss : 0.437082 model2 loss : 0.024786
[11:19:34.233] iteration 12856 : model1 loss : 0.439173 model2 loss : 0.027083
[11:19:34.401] iteration 12857 : model1 loss : 0.438309 model2 loss : 0.025169
[11:19:34.570] iteration 12858 : model1 loss : 0.439618 model2 loss : 0.026091
[11:19:34.736] iteration 12859 : model1 loss : 0.440298 model2 loss : 0.027088
[11:19:34.906] iteration 12860 : model1 loss : 0.439353 model2 loss : 0.028327
[11:19:35.073] iteration 12861 : model1 loss : 0.438065 model2 loss : 0.023986
[11:19:35.243] iteration 12862 : model1 loss : 0.439145 model2 loss : 0.026319
[11:19:35.412] iteration 12863 : model1 loss : 0.441165 model2 loss : 0.028224
[11:19:35.579] iteration 12864 : model1 loss : 0.434165 model2 loss : 0.025148
[11:19:35.748] iteration 12865 : model1 loss : 0.432709 model2 loss : 0.025408
[11:19:35.917] iteration 12866 : model1 loss : 0.435781 model2 loss : 0.025224
[11:19:36.086] iteration 12867 : model1 loss : 0.435869 model2 loss : 0.024506
[11:19:36.254] iteration 12868 : model1 loss : 0.434963 model2 loss : 0.024606
[11:19:36.422] iteration 12869 : model1 loss : 0.434130 model2 loss : 0.025513
[11:19:36.590] iteration 12870 : model1 loss : 0.436218 model2 loss : 0.024399
[11:19:38.495] iteration 12871 : model1 loss : 0.433790 model2 loss : 0.024927
[11:19:38.663] iteration 12872 : model1 loss : 0.439789 model2 loss : 0.028889
[11:19:38.832] iteration 12873 : model1 loss : 0.433724 model2 loss : 0.025026
[11:19:38.999] iteration 12874 : model1 loss : 0.431728 model2 loss : 0.023018
[11:19:39.169] iteration 12875 : model1 loss : 0.434814 model2 loss : 0.023309
[11:19:39.336] iteration 12876 : model1 loss : 0.443106 model2 loss : 0.029475
[11:19:39.508] iteration 12877 : model1 loss : 0.436842 model2 loss : 0.024847
[11:19:39.675] iteration 12878 : model1 loss : 0.437176 model2 loss : 0.024828
[11:19:39.846] iteration 12879 : model1 loss : 0.435376 model2 loss : 0.021707
[11:19:40.016] iteration 12880 : model1 loss : 0.435269 model2 loss : 0.025436
[11:19:40.185] iteration 12881 : model1 loss : 0.433640 model2 loss : 0.021254
[11:19:40.354] iteration 12882 : model1 loss : 0.437614 model2 loss : 0.024428
[11:19:40.526] iteration 12883 : model1 loss : 0.439161 model2 loss : 0.023554
[11:19:40.694] iteration 12884 : model1 loss : 0.437382 model2 loss : 0.024341
[11:19:40.865] iteration 12885 : model1 loss : 0.439068 model2 loss : 0.039028
[11:19:41.033] iteration 12886 : model1 loss : 0.436584 model2 loss : 0.023546
[11:19:41.204] iteration 12887 : model1 loss : 0.437369 model2 loss : 0.025387
[11:19:41.371] iteration 12888 : model1 loss : 0.433943 model2 loss : 0.023215
[11:19:41.542] iteration 12889 : model1 loss : 0.438093 model2 loss : 0.021753
[11:19:41.712] iteration 12890 : model1 loss : 0.439395 model2 loss : 0.023130
[11:19:41.882] iteration 12891 : model1 loss : 0.440336 model2 loss : 0.024581
[11:19:42.049] iteration 12892 : model1 loss : 0.434919 model2 loss : 0.025023
[11:19:42.218] iteration 12893 : model1 loss : 0.433853 model2 loss : 0.022917
[11:19:42.385] iteration 12894 : model1 loss : 0.437299 model2 loss : 0.026072
[11:19:42.555] iteration 12895 : model1 loss : 0.438092 model2 loss : 0.022633
[11:19:42.724] iteration 12896 : model1 loss : 0.437939 model2 loss : 0.027051
[11:19:42.893] iteration 12897 : model1 loss : 0.434650 model2 loss : 0.022522
[11:19:43.062] iteration 12898 : model1 loss : 0.437298 model2 loss : 0.026565
[11:19:43.231] iteration 12899 : model1 loss : 0.439765 model2 loss : 0.038732
[11:19:43.398] iteration 12900 : model1 loss : 0.439485 model2 loss : 0.026221
[11:19:43.568] iteration 12901 : model1 loss : 0.435963 model2 loss : 0.024754
[11:19:43.734] iteration 12902 : model1 loss : 0.441865 model2 loss : 0.048195
[11:19:43.901] iteration 12903 : model1 loss : 0.434662 model2 loss : 0.028593
[11:19:45.827] iteration 12904 : model1 loss : 0.437097 model2 loss : 0.036590
[11:19:45.996] iteration 12905 : model1 loss : 0.436583 model2 loss : 0.025017
[11:19:46.168] iteration 12906 : model1 loss : 0.436906 model2 loss : 0.023183
[11:19:46.336] iteration 12907 : model1 loss : 0.436117 model2 loss : 0.025181
[11:19:46.505] iteration 12908 : model1 loss : 0.436347 model2 loss : 0.026295
[11:19:46.671] iteration 12909 : model1 loss : 0.434167 model2 loss : 0.024883
[11:19:46.841] iteration 12910 : model1 loss : 0.437746 model2 loss : 0.024526
[11:19:47.008] iteration 12911 : model1 loss : 0.437774 model2 loss : 0.027626
[11:19:47.177] iteration 12912 : model1 loss : 0.441801 model2 loss : 0.033305
[11:19:47.347] iteration 12913 : model1 loss : 0.435390 model2 loss : 0.023167
[11:19:47.520] iteration 12914 : model1 loss : 0.437791 model2 loss : 0.028594
[11:19:47.689] iteration 12915 : model1 loss : 0.436562 model2 loss : 0.024871
[11:19:47.859] iteration 12916 : model1 loss : 0.435763 model2 loss : 0.029978
[11:19:48.027] iteration 12917 : model1 loss : 0.437021 model2 loss : 0.024457
[11:19:48.198] iteration 12918 : model1 loss : 0.432759 model2 loss : 0.023141
[11:19:48.366] iteration 12919 : model1 loss : 0.433781 model2 loss : 0.030944
[11:19:48.537] iteration 12920 : model1 loss : 0.438727 model2 loss : 0.028209
[11:19:48.703] iteration 12921 : model1 loss : 0.436819 model2 loss : 0.026093
[11:19:48.871] iteration 12922 : model1 loss : 0.434503 model2 loss : 0.025829
[11:19:49.038] iteration 12923 : model1 loss : 0.436375 model2 loss : 0.023728
[11:19:49.208] iteration 12924 : model1 loss : 0.434962 model2 loss : 0.024987
[11:19:49.375] iteration 12925 : model1 loss : 0.438174 model2 loss : 0.035039
[11:19:49.546] iteration 12926 : model1 loss : 0.435049 model2 loss : 0.025518
[11:19:49.713] iteration 12927 : model1 loss : 0.437752 model2 loss : 0.027054
[11:19:49.884] iteration 12928 : model1 loss : 0.434304 model2 loss : 0.026714
[11:19:50.051] iteration 12929 : model1 loss : 0.435643 model2 loss : 0.025456
[11:19:50.219] iteration 12930 : model1 loss : 0.439881 model2 loss : 0.027398
[11:19:50.386] iteration 12931 : model1 loss : 0.436847 model2 loss : 0.030797
[11:19:50.555] iteration 12932 : model1 loss : 0.439953 model2 loss : 0.034998
[11:19:50.722] iteration 12933 : model1 loss : 0.434396 model2 loss : 0.024887
[11:19:50.895] iteration 12934 : model1 loss : 0.439155 model2 loss : 0.029519
[11:19:51.059] iteration 12935 : model1 loss : 0.440129 model2 loss : 0.024945
[11:19:51.228] iteration 12936 : model1 loss : 0.440774 model2 loss : 0.027411
[11:19:53.143] iteration 12937 : model1 loss : 0.436462 model2 loss : 0.024231
[11:19:53.311] iteration 12938 : model1 loss : 0.437355 model2 loss : 0.021393
[11:19:53.482] iteration 12939 : model1 loss : 0.436334 model2 loss : 0.021858
[11:19:53.648] iteration 12940 : model1 loss : 0.436857 model2 loss : 0.023749
[11:19:53.815] iteration 12941 : model1 loss : 0.436328 model2 loss : 0.029548
[11:19:53.985] iteration 12942 : model1 loss : 0.438601 model2 loss : 0.030407
[11:19:54.153] iteration 12943 : model1 loss : 0.435458 model2 loss : 0.025750
[11:19:54.322] iteration 12944 : model1 loss : 0.431722 model2 loss : 0.024441
[11:19:54.493] iteration 12945 : model1 loss : 0.439736 model2 loss : 0.026758
[11:19:54.662] iteration 12946 : model1 loss : 0.437618 model2 loss : 0.028433
[11:19:54.830] iteration 12947 : model1 loss : 0.437266 model2 loss : 0.027139
[11:19:54.997] iteration 12948 : model1 loss : 0.435662 model2 loss : 0.025622
[11:19:55.168] iteration 12949 : model1 loss : 0.437898 model2 loss : 0.025922
[11:19:55.334] iteration 12950 : model1 loss : 0.436894 model2 loss : 0.027108
[11:19:55.508] iteration 12951 : model1 loss : 0.433549 model2 loss : 0.025300
[11:19:55.674] iteration 12952 : model1 loss : 0.432921 model2 loss : 0.027724
[11:19:55.845] iteration 12953 : model1 loss : 0.433452 model2 loss : 0.023158
[11:19:56.032] iteration 12954 : model1 loss : 0.435269 model2 loss : 0.027913
[11:19:56.202] iteration 12955 : model1 loss : 0.437637 model2 loss : 0.027099
[11:19:56.370] iteration 12956 : model1 loss : 0.438371 model2 loss : 0.025787
[11:19:56.544] iteration 12957 : model1 loss : 0.439681 model2 loss : 0.033662
[11:19:56.713] iteration 12958 : model1 loss : 0.442581 model2 loss : 0.036191
[11:19:56.883] iteration 12959 : model1 loss : 0.438592 model2 loss : 0.025794
[11:19:57.052] iteration 12960 : model1 loss : 0.440556 model2 loss : 0.031457
[11:19:57.222] iteration 12961 : model1 loss : 0.432890 model2 loss : 0.022130
[11:19:57.388] iteration 12962 : model1 loss : 0.444920 model2 loss : 0.032323
[11:19:57.555] iteration 12963 : model1 loss : 0.436499 model2 loss : 0.026175
[11:19:57.724] iteration 12964 : model1 loss : 0.437233 model2 loss : 0.026310
[11:19:57.895] iteration 12965 : model1 loss : 0.437300 model2 loss : 0.027269
[11:19:58.061] iteration 12966 : model1 loss : 0.439535 model2 loss : 0.027088
[11:19:58.242] iteration 12967 : model1 loss : 0.432789 model2 loss : 0.024292
[11:19:58.408] iteration 12968 : model1 loss : 0.438772 model2 loss : 0.023706
[11:19:58.576] iteration 12969 : model1 loss : 0.437748 model2 loss : 0.029341
[11:20:00.505] iteration 12970 : model1 loss : 0.431930 model2 loss : 0.023140
[11:20:00.676] iteration 12971 : model1 loss : 0.439774 model2 loss : 0.024358
[11:20:00.850] iteration 12972 : model1 loss : 0.435191 model2 loss : 0.024231
[11:20:01.017] iteration 12973 : model1 loss : 0.438736 model2 loss : 0.024843
[11:20:01.189] iteration 12974 : model1 loss : 0.435886 model2 loss : 0.026303
[11:20:01.357] iteration 12975 : model1 loss : 0.437323 model2 loss : 0.024117
[11:20:01.531] iteration 12976 : model1 loss : 0.436382 model2 loss : 0.025290
[11:20:01.699] iteration 12977 : model1 loss : 0.437956 model2 loss : 0.028715
[11:20:01.867] iteration 12978 : model1 loss : 0.437347 model2 loss : 0.026658
[11:20:02.034] iteration 12979 : model1 loss : 0.437451 model2 loss : 0.025496
[11:20:02.202] iteration 12980 : model1 loss : 0.437048 model2 loss : 0.022048
[11:20:02.369] iteration 12981 : model1 loss : 0.434610 model2 loss : 0.024389
[11:20:02.545] iteration 12982 : model1 loss : 0.435339 model2 loss : 0.024814
[11:20:02.713] iteration 12983 : model1 loss : 0.435157 model2 loss : 0.022349
[11:20:02.881] iteration 12984 : model1 loss : 0.441696 model2 loss : 0.026019
[11:20:03.047] iteration 12985 : model1 loss : 0.436016 model2 loss : 0.024588
[11:20:03.215] iteration 12986 : model1 loss : 0.434226 model2 loss : 0.022513
[11:20:03.382] iteration 12987 : model1 loss : 0.435022 model2 loss : 0.023808
[11:20:03.552] iteration 12988 : model1 loss : 0.435405 model2 loss : 0.025784
[11:20:03.719] iteration 12989 : model1 loss : 0.442214 model2 loss : 0.025641
[11:20:03.890] iteration 12990 : model1 loss : 0.439560 model2 loss : 0.024768
[11:20:04.057] iteration 12991 : model1 loss : 0.431101 model2 loss : 0.022200
[11:20:04.227] iteration 12992 : model1 loss : 0.440952 model2 loss : 0.025690
[11:20:04.394] iteration 12993 : model1 loss : 0.438464 model2 loss : 0.025777
[11:20:04.568] iteration 12994 : model1 loss : 0.442266 model2 loss : 0.031382
[11:20:04.735] iteration 12995 : model1 loss : 0.433495 model2 loss : 0.023225
[11:20:04.905] iteration 12996 : model1 loss : 0.435313 model2 loss : 0.022403
[11:20:05.073] iteration 12997 : model1 loss : 0.434778 model2 loss : 0.022784
[11:20:05.242] iteration 12998 : model1 loss : 0.438380 model2 loss : 0.024535
[11:20:05.410] iteration 12999 : model1 loss : 0.436975 model2 loss : 0.023436
[11:20:05.579] iteration 13000 : model1 loss : 0.437240 model2 loss : 0.027291
[11:20:13.887] iteration 13000 : model1_mean_dice : 0.891333 model1_mean_hd95 : 4.475880
[11:20:22.164] iteration 13000 : model2_mean_dice : 0.897187 model2_mean_hd95 : 1.758522
[11:20:22.337] iteration 13001 : model1 loss : 0.438252 model2 loss : 0.026609
[11:20:22.517] iteration 13002 : model1 loss : 0.436271 model2 loss : 0.029531
[11:20:24.423] iteration 13003 : model1 loss : 0.436692 model2 loss : 0.021544
[11:20:24.596] iteration 13004 : model1 loss : 0.433551 model2 loss : 0.025228
[11:20:24.764] iteration 13005 : model1 loss : 0.434225 model2 loss : 0.023815
[11:20:24.930] iteration 13006 : model1 loss : 0.434427 model2 loss : 0.024560
[11:20:25.099] iteration 13007 : model1 loss : 0.431250 model2 loss : 0.024374
[11:20:25.264] iteration 13008 : model1 loss : 0.436577 model2 loss : 0.027085
[11:20:25.433] iteration 13009 : model1 loss : 0.433041 model2 loss : 0.026404
[11:20:25.602] iteration 13010 : model1 loss : 0.436185 model2 loss : 0.024407
[11:20:25.771] iteration 13011 : model1 loss : 0.435501 model2 loss : 0.024468
[11:20:25.938] iteration 13012 : model1 loss : 0.444430 model2 loss : 0.037315
[11:20:26.107] iteration 13013 : model1 loss : 0.437359 model2 loss : 0.023039
[11:20:26.280] iteration 13014 : model1 loss : 0.439076 model2 loss : 0.031168
[11:20:26.448] iteration 13015 : model1 loss : 0.438288 model2 loss : 0.028189
[11:20:26.615] iteration 13016 : model1 loss : 0.438497 model2 loss : 0.025938
[11:20:26.783] iteration 13017 : model1 loss : 0.433483 model2 loss : 0.025577
[11:20:26.948] iteration 13018 : model1 loss : 0.435336 model2 loss : 0.024766
[11:20:27.116] iteration 13019 : model1 loss : 0.437048 model2 loss : 0.027355
[11:20:27.284] iteration 13020 : model1 loss : 0.438970 model2 loss : 0.023004
[11:20:27.453] iteration 13021 : model1 loss : 0.437076 model2 loss : 0.026334
[11:20:27.619] iteration 13022 : model1 loss : 0.430455 model2 loss : 0.025007
[11:20:27.788] iteration 13023 : model1 loss : 0.439202 model2 loss : 0.026297
[11:20:27.956] iteration 13024 : model1 loss : 0.439972 model2 loss : 0.027242
[11:20:28.125] iteration 13025 : model1 loss : 0.440420 model2 loss : 0.025701
[11:20:28.292] iteration 13026 : model1 loss : 0.441766 model2 loss : 0.028047
[11:20:28.458] iteration 13027 : model1 loss : 0.441559 model2 loss : 0.027495
[11:20:28.625] iteration 13028 : model1 loss : 0.438608 model2 loss : 0.026280
[11:20:28.793] iteration 13029 : model1 loss : 0.440306 model2 loss : 0.026204
[11:20:28.960] iteration 13030 : model1 loss : 0.438389 model2 loss : 0.026934
[11:20:29.128] iteration 13031 : model1 loss : 0.440073 model2 loss : 0.028686
[11:20:29.296] iteration 13032 : model1 loss : 0.434683 model2 loss : 0.022436
[11:20:29.465] iteration 13033 : model1 loss : 0.432962 model2 loss : 0.026600
[11:20:29.631] iteration 13034 : model1 loss : 0.439379 model2 loss : 0.028884
[11:20:29.798] iteration 13035 : model1 loss : 0.436459 model2 loss : 0.022263
[11:20:31.747] iteration 13036 : model1 loss : 0.438404 model2 loss : 0.027198
[11:20:31.916] iteration 13037 : model1 loss : 0.436944 model2 loss : 0.025907
[11:20:32.086] iteration 13038 : model1 loss : 0.435625 model2 loss : 0.024053
[11:20:32.252] iteration 13039 : model1 loss : 0.438958 model2 loss : 0.029340
[11:20:32.422] iteration 13040 : model1 loss : 0.437887 model2 loss : 0.023144
[11:20:32.590] iteration 13041 : model1 loss : 0.436566 model2 loss : 0.024387
[11:20:32.759] iteration 13042 : model1 loss : 0.439079 model2 loss : 0.026124
[11:20:32.928] iteration 13043 : model1 loss : 0.438308 model2 loss : 0.022280
[11:20:33.097] iteration 13044 : model1 loss : 0.436320 model2 loss : 0.024562
[11:20:33.264] iteration 13045 : model1 loss : 0.438887 model2 loss : 0.026484
[11:20:33.433] iteration 13046 : model1 loss : 0.438576 model2 loss : 0.024178
[11:20:33.597] iteration 13047 : model1 loss : 0.433981 model2 loss : 0.022006
[11:20:33.765] iteration 13048 : model1 loss : 0.436703 model2 loss : 0.023942
[11:20:33.933] iteration 13049 : model1 loss : 0.436487 model2 loss : 0.023421
[11:20:34.102] iteration 13050 : model1 loss : 0.436650 model2 loss : 0.023731
[11:20:34.269] iteration 13051 : model1 loss : 0.442904 model2 loss : 0.028458
[11:20:34.437] iteration 13052 : model1 loss : 0.439803 model2 loss : 0.025656
[11:20:34.604] iteration 13053 : model1 loss : 0.433609 model2 loss : 0.025641
[11:20:34.772] iteration 13054 : model1 loss : 0.434109 model2 loss : 0.022554
[11:20:34.940] iteration 13055 : model1 loss : 0.433963 model2 loss : 0.024167
[11:20:35.108] iteration 13056 : model1 loss : 0.437318 model2 loss : 0.025331
[11:20:35.275] iteration 13057 : model1 loss : 0.437301 model2 loss : 0.025348
[11:20:35.451] iteration 13058 : model1 loss : 0.436201 model2 loss : 0.022147
[11:20:35.618] iteration 13059 : model1 loss : 0.440479 model2 loss : 0.026218
[11:20:35.784] iteration 13060 : model1 loss : 0.438888 model2 loss : 0.023522
[11:20:35.951] iteration 13061 : model1 loss : 0.442376 model2 loss : 0.028180
[11:20:36.120] iteration 13062 : model1 loss : 0.437299 model2 loss : 0.022478
[11:20:36.287] iteration 13063 : model1 loss : 0.439126 model2 loss : 0.027429
[11:20:36.454] iteration 13064 : model1 loss : 0.435250 model2 loss : 0.026751
[11:20:36.621] iteration 13065 : model1 loss : 0.433439 model2 loss : 0.022266
[11:20:36.788] iteration 13066 : model1 loss : 0.432520 model2 loss : 0.024859
[11:20:36.954] iteration 13067 : model1 loss : 0.434189 model2 loss : 0.023354
[11:20:37.119] iteration 13068 : model1 loss : 0.432449 model2 loss : 0.022270
[11:20:39.030] iteration 13069 : model1 loss : 0.439093 model2 loss : 0.029413
[11:20:39.197] iteration 13070 : model1 loss : 0.437558 model2 loss : 0.020648
[11:20:39.366] iteration 13071 : model1 loss : 0.439231 model2 loss : 0.024783
[11:20:39.536] iteration 13072 : model1 loss : 0.435297 model2 loss : 0.023603
[11:20:39.703] iteration 13073 : model1 loss : 0.438373 model2 loss : 0.022783
[11:20:39.869] iteration 13074 : model1 loss : 0.434375 model2 loss : 0.024005
[11:20:40.041] iteration 13075 : model1 loss : 0.441140 model2 loss : 0.024795
[11:20:40.206] iteration 13076 : model1 loss : 0.439812 model2 loss : 0.025607
[11:20:40.377] iteration 13077 : model1 loss : 0.433476 model2 loss : 0.020909
[11:20:40.544] iteration 13078 : model1 loss : 0.432664 model2 loss : 0.024873
[11:20:40.713] iteration 13079 : model1 loss : 0.437862 model2 loss : 0.026686
[11:20:40.884] iteration 13080 : model1 loss : 0.434278 model2 loss : 0.024141
[11:20:41.053] iteration 13081 : model1 loss : 0.442168 model2 loss : 0.026655
[11:20:41.220] iteration 13082 : model1 loss : 0.432974 model2 loss : 0.021535
[11:20:41.390] iteration 13083 : model1 loss : 0.436253 model2 loss : 0.024841
[11:20:41.558] iteration 13084 : model1 loss : 0.439877 model2 loss : 0.025821
[11:20:41.727] iteration 13085 : model1 loss : 0.436832 model2 loss : 0.025612
[11:20:41.893] iteration 13086 : model1 loss : 0.438258 model2 loss : 0.024434
[11:20:42.063] iteration 13087 : model1 loss : 0.432823 model2 loss : 0.022251
[11:20:42.232] iteration 13088 : model1 loss : 0.433891 model2 loss : 0.024107
[11:20:42.411] iteration 13089 : model1 loss : 0.435297 model2 loss : 0.024972
[11:20:42.580] iteration 13090 : model1 loss : 0.437964 model2 loss : 0.026018
[11:20:42.748] iteration 13091 : model1 loss : 0.439934 model2 loss : 0.029828
[11:20:42.913] iteration 13092 : model1 loss : 0.431446 model2 loss : 0.022694
[11:20:43.081] iteration 13093 : model1 loss : 0.436276 model2 loss : 0.022574
[11:20:43.249] iteration 13094 : model1 loss : 0.440603 model2 loss : 0.023359
[11:20:43.418] iteration 13095 : model1 loss : 0.439178 model2 loss : 0.029031
[11:20:43.587] iteration 13096 : model1 loss : 0.436744 model2 loss : 0.023106
[11:20:43.756] iteration 13097 : model1 loss : 0.437590 model2 loss : 0.021721
[11:20:43.923] iteration 13098 : model1 loss : 0.436323 model2 loss : 0.024344
[11:20:44.091] iteration 13099 : model1 loss : 0.434459 model2 loss : 0.024084
[11:20:44.257] iteration 13100 : model1 loss : 0.439728 model2 loss : 0.027446
[11:20:44.424] iteration 13101 : model1 loss : 0.438902 model2 loss : 0.023103
[11:20:46.401] iteration 13102 : model1 loss : 0.437072 model2 loss : 0.027367
[11:20:46.570] iteration 13103 : model1 loss : 0.434906 model2 loss : 0.025331
[11:20:46.739] iteration 13104 : model1 loss : 0.436409 model2 loss : 0.023772
[11:20:46.909] iteration 13105 : model1 loss : 0.433350 model2 loss : 0.021550
[11:20:47.078] iteration 13106 : model1 loss : 0.435105 model2 loss : 0.025216
[11:20:47.245] iteration 13107 : model1 loss : 0.438073 model2 loss : 0.027745
[11:20:47.411] iteration 13108 : model1 loss : 0.440571 model2 loss : 0.025278
[11:20:47.577] iteration 13109 : model1 loss : 0.436880 model2 loss : 0.024038
[11:20:47.746] iteration 13110 : model1 loss : 0.439219 model2 loss : 0.025437
[11:20:47.914] iteration 13111 : model1 loss : 0.438931 model2 loss : 0.026348
[11:20:48.083] iteration 13112 : model1 loss : 0.438712 model2 loss : 0.024105
[11:20:48.250] iteration 13113 : model1 loss : 0.441454 model2 loss : 0.027173
[11:20:48.419] iteration 13114 : model1 loss : 0.440297 model2 loss : 0.026863
[11:20:48.585] iteration 13115 : model1 loss : 0.439041 model2 loss : 0.025337
[11:20:48.755] iteration 13116 : model1 loss : 0.439302 model2 loss : 0.022874
[11:20:48.922] iteration 13117 : model1 loss : 0.430466 model2 loss : 0.023755
[11:20:49.091] iteration 13118 : model1 loss : 0.440698 model2 loss : 0.026899
[11:20:49.258] iteration 13119 : model1 loss : 0.434764 model2 loss : 0.023193
[11:20:49.427] iteration 13120 : model1 loss : 0.432765 model2 loss : 0.022478
[11:20:49.594] iteration 13121 : model1 loss : 0.441110 model2 loss : 0.026573
[11:20:49.760] iteration 13122 : model1 loss : 0.431575 model2 loss : 0.022666
[11:20:49.929] iteration 13123 : model1 loss : 0.437170 model2 loss : 0.022471
[11:20:50.100] iteration 13124 : model1 loss : 0.438935 model2 loss : 0.024242
[11:20:50.266] iteration 13125 : model1 loss : 0.434545 model2 loss : 0.023434
[11:20:50.435] iteration 13126 : model1 loss : 0.438434 model2 loss : 0.021694
[11:20:50.603] iteration 13127 : model1 loss : 0.439985 model2 loss : 0.027139
[11:20:50.772] iteration 13128 : model1 loss : 0.435051 model2 loss : 0.026018
[11:20:50.949] iteration 13129 : model1 loss : 0.439920 model2 loss : 0.024574
[11:20:51.118] iteration 13130 : model1 loss : 0.429599 model2 loss : 0.021055
[11:20:51.286] iteration 13131 : model1 loss : 0.437543 model2 loss : 0.023753
[11:20:51.456] iteration 13132 : model1 loss : 0.437073 model2 loss : 0.025908
[11:20:51.622] iteration 13133 : model1 loss : 0.435959 model2 loss : 0.022832
[11:20:51.791] iteration 13134 : model1 loss : 0.437901 model2 loss : 0.030055
[11:20:53.738] iteration 13135 : model1 loss : 0.434193 model2 loss : 0.024323
[11:20:53.904] iteration 13136 : model1 loss : 0.434331 model2 loss : 0.021969
[11:20:54.074] iteration 13137 : model1 loss : 0.436665 model2 loss : 0.024021
[11:20:54.239] iteration 13138 : model1 loss : 0.438468 model2 loss : 0.024097
[11:20:54.407] iteration 13139 : model1 loss : 0.439267 model2 loss : 0.024195
[11:20:54.574] iteration 13140 : model1 loss : 0.438062 model2 loss : 0.026305
[11:20:54.742] iteration 13141 : model1 loss : 0.436899 model2 loss : 0.024392
[11:20:54.909] iteration 13142 : model1 loss : 0.437579 model2 loss : 0.026283
[11:20:55.077] iteration 13143 : model1 loss : 0.436430 model2 loss : 0.026143
[11:20:55.243] iteration 13144 : model1 loss : 0.437986 model2 loss : 0.022872
[11:20:55.412] iteration 13145 : model1 loss : 0.443876 model2 loss : 0.034293
[11:20:55.579] iteration 13146 : model1 loss : 0.439051 model2 loss : 0.025485
[11:20:55.746] iteration 13147 : model1 loss : 0.434860 model2 loss : 0.024857
[11:20:55.912] iteration 13148 : model1 loss : 0.440561 model2 loss : 0.026761
[11:20:56.080] iteration 13149 : model1 loss : 0.436570 model2 loss : 0.025766
[11:20:56.247] iteration 13150 : model1 loss : 0.436995 model2 loss : 0.025383
[11:20:56.417] iteration 13151 : model1 loss : 0.431735 model2 loss : 0.024205
[11:20:56.585] iteration 13152 : model1 loss : 0.435378 model2 loss : 0.022069
[11:20:56.752] iteration 13153 : model1 loss : 0.436366 model2 loss : 0.021529
[11:20:56.919] iteration 13154 : model1 loss : 0.434102 model2 loss : 0.022112
[11:20:57.087] iteration 13155 : model1 loss : 0.436474 model2 loss : 0.019829
[11:20:57.255] iteration 13156 : model1 loss : 0.435303 model2 loss : 0.025054
[11:20:57.423] iteration 13157 : model1 loss : 0.436100 model2 loss : 0.025147
[11:20:57.591] iteration 13158 : model1 loss : 0.433833 model2 loss : 0.023707
[11:20:57.760] iteration 13159 : model1 loss : 0.434823 model2 loss : 0.023374
[11:20:57.927] iteration 13160 : model1 loss : 0.436744 model2 loss : 0.026688
[11:20:58.096] iteration 13161 : model1 loss : 0.436096 model2 loss : 0.022970
[11:20:58.262] iteration 13162 : model1 loss : 0.435650 model2 loss : 0.025176
[11:20:58.430] iteration 13163 : model1 loss : 0.437629 model2 loss : 0.025137
[11:20:58.597] iteration 13164 : model1 loss : 0.438228 model2 loss : 0.024626
[11:20:58.766] iteration 13165 : model1 loss : 0.434837 model2 loss : 0.022192
[11:20:58.931] iteration 13166 : model1 loss : 0.441379 model2 loss : 0.025828
[11:20:59.098] iteration 13167 : model1 loss : 0.437687 model2 loss : 0.025051
[11:21:01.079] iteration 13168 : model1 loss : 0.435277 model2 loss : 0.023701
[11:21:01.248] iteration 13169 : model1 loss : 0.437091 model2 loss : 0.030082
[11:21:01.418] iteration 13170 : model1 loss : 0.435601 model2 loss : 0.025916
[11:21:01.584] iteration 13171 : model1 loss : 0.439033 model2 loss : 0.027448
[11:21:01.752] iteration 13172 : model1 loss : 0.438032 model2 loss : 0.025947
[11:21:01.920] iteration 13173 : model1 loss : 0.442954 model2 loss : 0.027315
[11:21:02.088] iteration 13174 : model1 loss : 0.441293 model2 loss : 0.029179
[11:21:02.256] iteration 13175 : model1 loss : 0.440777 model2 loss : 0.020990
[11:21:02.423] iteration 13176 : model1 loss : 0.441739 model2 loss : 0.025360
[11:21:02.590] iteration 13177 : model1 loss : 0.436430 model2 loss : 0.023813
[11:21:02.759] iteration 13178 : model1 loss : 0.433940 model2 loss : 0.025933
[11:21:02.925] iteration 13179 : model1 loss : 0.437056 model2 loss : 0.023314
[11:21:03.094] iteration 13180 : model1 loss : 0.437411 model2 loss : 0.025478
[11:21:03.260] iteration 13181 : model1 loss : 0.435306 model2 loss : 0.022822
[11:21:03.429] iteration 13182 : model1 loss : 0.441999 model2 loss : 0.026225
[11:21:03.595] iteration 13183 : model1 loss : 0.432870 model2 loss : 0.025218
[11:21:03.764] iteration 13184 : model1 loss : 0.431830 model2 loss : 0.023034
[11:21:03.929] iteration 13185 : model1 loss : 0.437840 model2 loss : 0.023942
[11:21:04.099] iteration 13186 : model1 loss : 0.436827 model2 loss : 0.026268
[11:21:04.265] iteration 13187 : model1 loss : 0.442301 model2 loss : 0.028196
[11:21:04.435] iteration 13188 : model1 loss : 0.435480 model2 loss : 0.024483
[11:21:04.602] iteration 13189 : model1 loss : 0.435352 model2 loss : 0.022458
[11:21:04.771] iteration 13190 : model1 loss : 0.431817 model2 loss : 0.022079
[11:21:04.939] iteration 13191 : model1 loss : 0.439004 model2 loss : 0.024927
[11:21:05.107] iteration 13192 : model1 loss : 0.431053 model2 loss : 0.023137
[11:21:05.275] iteration 13193 : model1 loss : 0.431751 model2 loss : 0.025893
[11:21:05.451] iteration 13194 : model1 loss : 0.437627 model2 loss : 0.024455
[11:21:05.617] iteration 13195 : model1 loss : 0.440248 model2 loss : 0.021670
[11:21:05.785] iteration 13196 : model1 loss : 0.441624 model2 loss : 0.027061
[11:21:05.961] iteration 13197 : model1 loss : 0.435625 model2 loss : 0.026231
[11:21:06.132] iteration 13198 : model1 loss : 0.437138 model2 loss : 0.027493
[11:21:06.298] iteration 13199 : model1 loss : 0.438940 model2 loss : 0.024523
[11:21:06.467] iteration 13200 : model1 loss : 0.438320 model2 loss : 0.022875
[11:21:08.386] iteration 13201 : model1 loss : 0.438617 model2 loss : 0.026179
[11:21:08.553] iteration 13202 : model1 loss : 0.438196 model2 loss : 0.029954
[11:21:08.724] iteration 13203 : model1 loss : 0.433415 model2 loss : 0.021130
[11:21:08.891] iteration 13204 : model1 loss : 0.437298 model2 loss : 0.022325
[11:21:09.059] iteration 13205 : model1 loss : 0.433156 model2 loss : 0.022818
[11:21:09.226] iteration 13206 : model1 loss : 0.434139 model2 loss : 0.024819
[11:21:09.394] iteration 13207 : model1 loss : 0.438705 model2 loss : 0.029339
[11:21:09.560] iteration 13208 : model1 loss : 0.436857 model2 loss : 0.025660
[11:21:09.731] iteration 13209 : model1 loss : 0.439658 model2 loss : 0.023985
[11:21:09.899] iteration 13210 : model1 loss : 0.437270 model2 loss : 0.026460
[11:21:10.069] iteration 13211 : model1 loss : 0.436973 model2 loss : 0.024922
[11:21:10.236] iteration 13212 : model1 loss : 0.439445 model2 loss : 0.025694
[11:21:10.404] iteration 13213 : model1 loss : 0.437843 model2 loss : 0.026550
[11:21:10.572] iteration 13214 : model1 loss : 0.433954 model2 loss : 0.022470
[11:21:10.744] iteration 13215 : model1 loss : 0.436459 model2 loss : 0.020553
[11:21:10.912] iteration 13216 : model1 loss : 0.437598 model2 loss : 0.023563
[11:21:11.083] iteration 13217 : model1 loss : 0.437517 model2 loss : 0.026653
[11:21:11.251] iteration 13218 : model1 loss : 0.435565 model2 loss : 0.022869
[11:21:11.418] iteration 13219 : model1 loss : 0.434616 model2 loss : 0.024484
[11:21:11.585] iteration 13220 : model1 loss : 0.438748 model2 loss : 0.025328
[11:21:11.754] iteration 13221 : model1 loss : 0.434083 model2 loss : 0.026500
[11:21:11.921] iteration 13222 : model1 loss : 0.439916 model2 loss : 0.025247
[11:21:12.091] iteration 13223 : model1 loss : 0.437536 model2 loss : 0.023034
[11:21:12.258] iteration 13224 : model1 loss : 0.442021 model2 loss : 0.024727
[11:21:12.427] iteration 13225 : model1 loss : 0.436259 model2 loss : 0.021779
[11:21:12.595] iteration 13226 : model1 loss : 0.442468 model2 loss : 0.033412
[11:21:12.764] iteration 13227 : model1 loss : 0.436528 model2 loss : 0.023790
[11:21:12.929] iteration 13228 : model1 loss : 0.435753 model2 loss : 0.023768
[11:21:13.099] iteration 13229 : model1 loss : 0.433345 model2 loss : 0.021080
[11:21:13.267] iteration 13230 : model1 loss : 0.439169 model2 loss : 0.027166
[11:21:13.434] iteration 13231 : model1 loss : 0.438547 model2 loss : 0.034905
[11:21:13.600] iteration 13232 : model1 loss : 0.440056 model2 loss : 0.026042
[11:21:13.769] iteration 13233 : model1 loss : 0.438710 model2 loss : 0.027746
[11:21:15.687] iteration 13234 : model1 loss : 0.434363 model2 loss : 0.031211
[11:21:15.860] iteration 13235 : model1 loss : 0.441799 model2 loss : 0.035384
[11:21:16.030] iteration 13236 : model1 loss : 0.438818 model2 loss : 0.044301
[11:21:16.197] iteration 13237 : model1 loss : 0.434150 model2 loss : 0.025577
[11:21:16.367] iteration 13238 : model1 loss : 0.437670 model2 loss : 0.027498
[11:21:16.535] iteration 13239 : model1 loss : 0.436576 model2 loss : 0.031957
[11:21:16.705] iteration 13240 : model1 loss : 0.440789 model2 loss : 0.028047
[11:21:16.871] iteration 13241 : model1 loss : 0.444301 model2 loss : 0.032701
[11:21:17.039] iteration 13242 : model1 loss : 0.437468 model2 loss : 0.031634
[11:21:17.205] iteration 13243 : model1 loss : 0.441561 model2 loss : 0.030835
[11:21:17.374] iteration 13244 : model1 loss : 0.439270 model2 loss : 0.031839
[11:21:17.542] iteration 13245 : model1 loss : 0.436693 model2 loss : 0.034911
[11:21:17.710] iteration 13246 : model1 loss : 0.439703 model2 loss : 0.036459
[11:21:17.877] iteration 13247 : model1 loss : 0.440617 model2 loss : 0.026009
[11:21:18.045] iteration 13248 : model1 loss : 0.437675 model2 loss : 0.036584
[11:21:18.213] iteration 13249 : model1 loss : 0.441891 model2 loss : 0.034220
[11:21:18.380] iteration 13250 : model1 loss : 0.436212 model2 loss : 0.029015
[11:21:18.549] iteration 13251 : model1 loss : 0.438201 model2 loss : 0.026080
[11:21:18.719] iteration 13252 : model1 loss : 0.438929 model2 loss : 0.037306
[11:21:18.885] iteration 13253 : model1 loss : 0.438259 model2 loss : 0.026791
[11:21:19.055] iteration 13254 : model1 loss : 0.435159 model2 loss : 0.027755
[11:21:19.222] iteration 13255 : model1 loss : 0.436125 model2 loss : 0.029916
[11:21:19.390] iteration 13256 : model1 loss : 0.436965 model2 loss : 0.028341
[11:21:19.558] iteration 13257 : model1 loss : 0.438869 model2 loss : 0.037957
[11:21:19.745] iteration 13258 : model1 loss : 0.435243 model2 loss : 0.026574
[11:21:19.911] iteration 13259 : model1 loss : 0.436524 model2 loss : 0.028337
[11:21:20.080] iteration 13260 : model1 loss : 0.440167 model2 loss : 0.040456
[11:21:20.247] iteration 13261 : model1 loss : 0.441184 model2 loss : 0.034516
[11:21:20.416] iteration 13262 : model1 loss : 0.436853 model2 loss : 0.031237
[11:21:20.584] iteration 13263 : model1 loss : 0.434720 model2 loss : 0.025972
[11:21:20.754] iteration 13264 : model1 loss : 0.439599 model2 loss : 0.034571
[11:21:20.922] iteration 13265 : model1 loss : 0.434202 model2 loss : 0.031102
[11:21:21.101] iteration 13266 : model1 loss : 0.437723 model2 loss : 0.025334
[11:21:23.009] iteration 13267 : model1 loss : 0.438119 model2 loss : 0.028042
[11:21:23.177] iteration 13268 : model1 loss : 0.436177 model2 loss : 0.026745
[11:21:23.346] iteration 13269 : model1 loss : 0.433108 model2 loss : 0.028012
[11:21:23.516] iteration 13270 : model1 loss : 0.442667 model2 loss : 0.039051
[11:21:23.685] iteration 13271 : model1 loss : 0.434022 model2 loss : 0.025524
[11:21:23.854] iteration 13272 : model1 loss : 0.439395 model2 loss : 0.034837
[11:21:24.021] iteration 13273 : model1 loss : 0.437275 model2 loss : 0.031321
[11:21:24.191] iteration 13274 : model1 loss : 0.437307 model2 loss : 0.032690
[11:21:24.359] iteration 13275 : model1 loss : 0.440506 model2 loss : 0.029060
[11:21:24.527] iteration 13276 : model1 loss : 0.436926 model2 loss : 0.033795
[11:21:24.695] iteration 13277 : model1 loss : 0.430796 model2 loss : 0.025866
[11:21:24.861] iteration 13278 : model1 loss : 0.436732 model2 loss : 0.036187
[11:21:25.029] iteration 13279 : model1 loss : 0.436176 model2 loss : 0.034945
[11:21:25.195] iteration 13280 : model1 loss : 0.437718 model2 loss : 0.030394
[11:21:25.364] iteration 13281 : model1 loss : 0.434872 model2 loss : 0.027482
[11:21:25.533] iteration 13282 : model1 loss : 0.433348 model2 loss : 0.027769
[11:21:25.702] iteration 13283 : model1 loss : 0.442824 model2 loss : 0.031901
[11:21:25.873] iteration 13284 : model1 loss : 0.437504 model2 loss : 0.027041
[11:21:26.040] iteration 13285 : model1 loss : 0.439702 model2 loss : 0.026751
[11:21:26.208] iteration 13286 : model1 loss : 0.437822 model2 loss : 0.028992
[11:21:26.376] iteration 13287 : model1 loss : 0.439243 model2 loss : 0.026997
[11:21:26.545] iteration 13288 : model1 loss : 0.436995 model2 loss : 0.027687
[11:21:26.716] iteration 13289 : model1 loss : 0.439004 model2 loss : 0.031306
[11:21:26.882] iteration 13290 : model1 loss : 0.439250 model2 loss : 0.028556
[11:21:27.050] iteration 13291 : model1 loss : 0.437702 model2 loss : 0.033031
[11:21:27.216] iteration 13292 : model1 loss : 0.432697 model2 loss : 0.026221
[11:21:27.386] iteration 13293 : model1 loss : 0.439408 model2 loss : 0.032288
[11:21:27.556] iteration 13294 : model1 loss : 0.434454 model2 loss : 0.029953
[11:21:27.726] iteration 13295 : model1 loss : 0.434874 model2 loss : 0.024838
[11:21:27.894] iteration 13296 : model1 loss : 0.439606 model2 loss : 0.029734
[11:21:28.061] iteration 13297 : model1 loss : 0.439260 model2 loss : 0.026976
[11:21:28.227] iteration 13298 : model1 loss : 0.434050 model2 loss : 0.024774
[11:21:28.395] iteration 13299 : model1 loss : 0.438585 model2 loss : 0.028811
[11:21:30.312] iteration 13300 : model1 loss : 0.435559 model2 loss : 0.028608
[11:21:30.477] iteration 13301 : model1 loss : 0.440127 model2 loss : 0.028699
[11:21:30.650] iteration 13302 : model1 loss : 0.434892 model2 loss : 0.024239
[11:21:30.819] iteration 13303 : model1 loss : 0.439691 model2 loss : 0.031614
[11:21:30.990] iteration 13304 : model1 loss : 0.432834 model2 loss : 0.023974
[11:21:31.157] iteration 13305 : model1 loss : 0.433827 model2 loss : 0.026445
[11:21:31.325] iteration 13306 : model1 loss : 0.437467 model2 loss : 0.027770
[11:21:31.493] iteration 13307 : model1 loss : 0.434963 model2 loss : 0.023138
[11:21:31.660] iteration 13308 : model1 loss : 0.442235 model2 loss : 0.030191
[11:21:31.829] iteration 13309 : model1 loss : 0.437621 model2 loss : 0.025182
[11:21:31.998] iteration 13310 : model1 loss : 0.430660 model2 loss : 0.024790
[11:21:32.167] iteration 13311 : model1 loss : 0.435766 model2 loss : 0.026510
[11:21:32.336] iteration 13312 : model1 loss : 0.439786 model2 loss : 0.024615
[11:21:32.503] iteration 13313 : model1 loss : 0.440202 model2 loss : 0.027943
[11:21:32.670] iteration 13314 : model1 loss : 0.442331 model2 loss : 0.037964
[11:21:32.838] iteration 13315 : model1 loss : 0.432625 model2 loss : 0.023962
[11:21:33.007] iteration 13316 : model1 loss : 0.433713 model2 loss : 0.025069
[11:21:33.173] iteration 13317 : model1 loss : 0.435326 model2 loss : 0.023712
[11:21:33.340] iteration 13318 : model1 loss : 0.432183 model2 loss : 0.024170
[11:21:33.509] iteration 13319 : model1 loss : 0.434477 model2 loss : 0.023572
[11:21:33.678] iteration 13320 : model1 loss : 0.439038 model2 loss : 0.026249
[11:21:33.846] iteration 13321 : model1 loss : 0.434714 model2 loss : 0.025653
[11:21:34.015] iteration 13322 : model1 loss : 0.438453 model2 loss : 0.027524
[11:21:34.180] iteration 13323 : model1 loss : 0.434049 model2 loss : 0.024507
[11:21:34.349] iteration 13324 : model1 loss : 0.441557 model2 loss : 0.028668
[11:21:34.519] iteration 13325 : model1 loss : 0.438549 model2 loss : 0.027271
[11:21:34.688] iteration 13326 : model1 loss : 0.441135 model2 loss : 0.028561
[11:21:34.857] iteration 13327 : model1 loss : 0.440309 model2 loss : 0.027752
[11:21:35.024] iteration 13328 : model1 loss : 0.437849 model2 loss : 0.029482
[11:21:35.192] iteration 13329 : model1 loss : 0.439728 model2 loss : 0.028064
[11:21:35.361] iteration 13330 : model1 loss : 0.441656 model2 loss : 0.028643
[11:21:35.527] iteration 13331 : model1 loss : 0.434550 model2 loss : 0.024747
[11:21:35.697] iteration 13332 : model1 loss : 0.441031 model2 loss : 0.037809
[11:21:37.640] iteration 13333 : model1 loss : 0.442714 model2 loss : 0.030740
[11:21:37.812] iteration 13334 : model1 loss : 0.440230 model2 loss : 0.027693
[11:21:37.983] iteration 13335 : model1 loss : 0.436845 model2 loss : 0.029623
[11:21:38.151] iteration 13336 : model1 loss : 0.435271 model2 loss : 0.024614
[11:21:38.320] iteration 13337 : model1 loss : 0.437705 model2 loss : 0.024057
[11:21:38.487] iteration 13338 : model1 loss : 0.440332 model2 loss : 0.031287
[11:21:38.658] iteration 13339 : model1 loss : 0.437385 model2 loss : 0.028111
[11:21:38.824] iteration 13340 : model1 loss : 0.435046 model2 loss : 0.025344
[11:21:38.992] iteration 13341 : model1 loss : 0.431837 model2 loss : 0.023942
[11:21:39.158] iteration 13342 : model1 loss : 0.440228 model2 loss : 0.027463
[11:21:39.326] iteration 13343 : model1 loss : 0.438188 model2 loss : 0.027290
[11:21:39.493] iteration 13344 : model1 loss : 0.441811 model2 loss : 0.026385
[11:21:39.662] iteration 13345 : model1 loss : 0.434990 model2 loss : 0.025037
[11:21:39.834] iteration 13346 : model1 loss : 0.435830 model2 loss : 0.024691
[11:21:40.012] iteration 13347 : model1 loss : 0.435078 model2 loss : 0.024756
[11:21:40.179] iteration 13348 : model1 loss : 0.440493 model2 loss : 0.033455
[11:21:40.349] iteration 13349 : model1 loss : 0.437750 model2 loss : 0.027923
[11:21:40.520] iteration 13350 : model1 loss : 0.442365 model2 loss : 0.027685
[11:21:40.689] iteration 13351 : model1 loss : 0.435371 model2 loss : 0.027413
[11:21:40.858] iteration 13352 : model1 loss : 0.433252 model2 loss : 0.022576
[11:21:41.028] iteration 13353 : model1 loss : 0.439120 model2 loss : 0.029912
[11:21:41.194] iteration 13354 : model1 loss : 0.434530 model2 loss : 0.025871
[11:21:41.364] iteration 13355 : model1 loss : 0.438753 model2 loss : 0.026391
[11:21:41.534] iteration 13356 : model1 loss : 0.437700 model2 loss : 0.027867
[11:21:41.703] iteration 13357 : model1 loss : 0.434608 model2 loss : 0.026010
[11:21:41.871] iteration 13358 : model1 loss : 0.436599 model2 loss : 0.023954
[11:21:42.042] iteration 13359 : model1 loss : 0.439069 model2 loss : 0.027814
[11:21:42.210] iteration 13360 : model1 loss : 0.433247 model2 loss : 0.025243
[11:21:42.379] iteration 13361 : model1 loss : 0.435625 model2 loss : 0.021758
[11:21:42.551] iteration 13362 : model1 loss : 0.436584 model2 loss : 0.025641
[11:21:42.720] iteration 13363 : model1 loss : 0.438639 model2 loss : 0.028769
[11:21:42.884] iteration 13364 : model1 loss : 0.437837 model2 loss : 0.026358
[11:21:43.053] iteration 13365 : model1 loss : 0.436546 model2 loss : 0.027142
[11:21:44.973] iteration 13366 : model1 loss : 0.436850 model2 loss : 0.024434
[11:21:45.140] iteration 13367 : model1 loss : 0.435507 model2 loss : 0.026968
[11:21:45.312] iteration 13368 : model1 loss : 0.432404 model2 loss : 0.024743
[11:21:45.480] iteration 13369 : model1 loss : 0.437331 model2 loss : 0.030012
[11:21:45.650] iteration 13370 : model1 loss : 0.433419 model2 loss : 0.023329
[11:21:45.819] iteration 13371 : model1 loss : 0.438048 model2 loss : 0.025429
[11:21:45.989] iteration 13372 : model1 loss : 0.440434 model2 loss : 0.023519
[11:21:46.160] iteration 13373 : model1 loss : 0.437500 model2 loss : 0.025475
[11:21:46.331] iteration 13374 : model1 loss : 0.439301 model2 loss : 0.026150
[11:21:46.517] iteration 13375 : model1 loss : 0.437180 model2 loss : 0.024625
[11:21:46.684] iteration 13376 : model1 loss : 0.440236 model2 loss : 0.035969
[11:21:46.855] iteration 13377 : model1 loss : 0.432996 model2 loss : 0.026096
[11:21:47.025] iteration 13378 : model1 loss : 0.440351 model2 loss : 0.029285
[11:21:47.195] iteration 13379 : model1 loss : 0.432709 model2 loss : 0.020285
[11:21:47.365] iteration 13380 : model1 loss : 0.440537 model2 loss : 0.026184
[11:21:47.534] iteration 13381 : model1 loss : 0.436505 model2 loss : 0.025520
[11:21:47.702] iteration 13382 : model1 loss : 0.438418 model2 loss : 0.026282
[11:21:47.871] iteration 13383 : model1 loss : 0.441271 model2 loss : 0.028717
[11:21:48.041] iteration 13384 : model1 loss : 0.437780 model2 loss : 0.028203
[11:21:48.207] iteration 13385 : model1 loss : 0.436556 model2 loss : 0.025492
[11:21:48.378] iteration 13386 : model1 loss : 0.439081 model2 loss : 0.025375
[11:21:48.545] iteration 13387 : model1 loss : 0.435388 model2 loss : 0.029285
[11:21:48.715] iteration 13388 : model1 loss : 0.438713 model2 loss : 0.023651
[11:21:48.881] iteration 13389 : model1 loss : 0.435654 model2 loss : 0.024868
[11:21:49.060] iteration 13390 : model1 loss : 0.438310 model2 loss : 0.023479
[11:21:49.226] iteration 13391 : model1 loss : 0.446416 model2 loss : 0.031853
[11:21:49.396] iteration 13392 : model1 loss : 0.440685 model2 loss : 0.026500
[11:21:49.564] iteration 13393 : model1 loss : 0.438884 model2 loss : 0.025886
[11:21:49.732] iteration 13394 : model1 loss : 0.432275 model2 loss : 0.023403
[11:21:49.901] iteration 13395 : model1 loss : 0.439191 model2 loss : 0.025676
[11:21:50.071] iteration 13396 : model1 loss : 0.436274 model2 loss : 0.026528
[11:21:50.238] iteration 13397 : model1 loss : 0.438264 model2 loss : 0.026077
[11:21:50.406] iteration 13398 : model1 loss : 0.440929 model2 loss : 0.028894
[11:21:52.385] iteration 13399 : model1 loss : 0.437991 model2 loss : 0.024128
[11:21:52.554] iteration 13400 : model1 loss : 0.437979 model2 loss : 0.021965
[11:21:52.722] iteration 13401 : model1 loss : 0.439670 model2 loss : 0.029916
[11:21:52.889] iteration 13402 : model1 loss : 0.433509 model2 loss : 0.024903
[11:21:53.056] iteration 13403 : model1 loss : 0.437092 model2 loss : 0.026938
[11:21:53.224] iteration 13404 : model1 loss : 0.436980 model2 loss : 0.022780
[11:21:53.394] iteration 13405 : model1 loss : 0.441720 model2 loss : 0.028486
[11:21:53.563] iteration 13406 : model1 loss : 0.438534 model2 loss : 0.029913
[11:21:53.740] iteration 13407 : model1 loss : 0.432508 model2 loss : 0.024669
[11:21:53.908] iteration 13408 : model1 loss : 0.438232 model2 loss : 0.024528
[11:21:54.079] iteration 13409 : model1 loss : 0.436360 model2 loss : 0.022503
[11:21:54.246] iteration 13410 : model1 loss : 0.436122 model2 loss : 0.024801
[11:21:54.414] iteration 13411 : model1 loss : 0.435070 model2 loss : 0.021110
[11:21:54.581] iteration 13412 : model1 loss : 0.438679 model2 loss : 0.026914
[11:21:54.753] iteration 13413 : model1 loss : 0.432682 model2 loss : 0.021924
[11:21:54.920] iteration 13414 : model1 loss : 0.435136 model2 loss : 0.024817
[11:21:55.090] iteration 13415 : model1 loss : 0.436229 model2 loss : 0.023481
[11:21:55.256] iteration 13416 : model1 loss : 0.437849 model2 loss : 0.034528
[11:21:55.426] iteration 13417 : model1 loss : 0.443066 model2 loss : 0.029303
[11:21:55.592] iteration 13418 : model1 loss : 0.436659 model2 loss : 0.024927
[11:21:55.762] iteration 13419 : model1 loss : 0.435123 model2 loss : 0.025152
[11:21:55.931] iteration 13420 : model1 loss : 0.439787 model2 loss : 0.028952
[11:21:56.101] iteration 13421 : model1 loss : 0.437810 model2 loss : 0.021671
[11:21:56.269] iteration 13422 : model1 loss : 0.435756 model2 loss : 0.024271
[11:21:56.437] iteration 13423 : model1 loss : 0.438418 model2 loss : 0.025067
[11:21:56.607] iteration 13424 : model1 loss : 0.436562 model2 loss : 0.028967
[11:21:56.777] iteration 13425 : model1 loss : 0.437833 model2 loss : 0.023752
[11:21:56.943] iteration 13426 : model1 loss : 0.433574 model2 loss : 0.026188
[11:21:57.114] iteration 13427 : model1 loss : 0.434042 model2 loss : 0.025635
[11:21:57.281] iteration 13428 : model1 loss : 0.436834 model2 loss : 0.026026
[11:21:57.452] iteration 13429 : model1 loss : 0.441194 model2 loss : 0.028128
[11:21:57.616] iteration 13430 : model1 loss : 0.436016 model2 loss : 0.025429
[11:21:57.783] iteration 13431 : model1 loss : 0.437582 model2 loss : 0.024035
[11:21:59.738] iteration 13432 : model1 loss : 0.436238 model2 loss : 0.023902
[11:21:59.910] iteration 13433 : model1 loss : 0.433491 model2 loss : 0.021688
[11:22:00.082] iteration 13434 : model1 loss : 0.436572 model2 loss : 0.028331
[11:22:00.248] iteration 13435 : model1 loss : 0.439654 model2 loss : 0.029480
[11:22:00.417] iteration 13436 : model1 loss : 0.437946 model2 loss : 0.027311
[11:22:00.584] iteration 13437 : model1 loss : 0.436777 model2 loss : 0.028458
[11:22:00.753] iteration 13438 : model1 loss : 0.434583 model2 loss : 0.022942
[11:22:00.927] iteration 13439 : model1 loss : 0.440075 model2 loss : 0.024427
[11:22:01.098] iteration 13440 : model1 loss : 0.438596 model2 loss : 0.029287
[11:22:01.265] iteration 13441 : model1 loss : 0.434494 model2 loss : 0.022929
[11:22:01.433] iteration 13442 : model1 loss : 0.434004 model2 loss : 0.024762
[11:22:01.600] iteration 13443 : model1 loss : 0.433696 model2 loss : 0.021639
[11:22:01.769] iteration 13444 : model1 loss : 0.433556 model2 loss : 0.028441
[11:22:01.935] iteration 13445 : model1 loss : 0.438187 model2 loss : 0.026277
[11:22:02.104] iteration 13446 : model1 loss : 0.435183 model2 loss : 0.027921
[11:22:02.271] iteration 13447 : model1 loss : 0.440972 model2 loss : 0.029347
[11:22:02.439] iteration 13448 : model1 loss : 0.436321 model2 loss : 0.022927
[11:22:02.606] iteration 13449 : model1 loss : 0.438703 model2 loss : 0.025711
[11:22:02.777] iteration 13450 : model1 loss : 0.437122 model2 loss : 0.024545
[11:22:02.945] iteration 13451 : model1 loss : 0.444057 model2 loss : 0.029886
[11:22:03.115] iteration 13452 : model1 loss : 0.440588 model2 loss : 0.028027
[11:22:03.281] iteration 13453 : model1 loss : 0.434698 model2 loss : 0.023154
[11:22:03.450] iteration 13454 : model1 loss : 0.437691 model2 loss : 0.022602
[11:22:03.616] iteration 13455 : model1 loss : 0.436550 model2 loss : 0.026469
[11:22:03.786] iteration 13456 : model1 loss : 0.433801 model2 loss : 0.022239
[11:22:03.955] iteration 13457 : model1 loss : 0.438215 model2 loss : 0.026687
[11:22:04.124] iteration 13458 : model1 loss : 0.435683 model2 loss : 0.023886
[11:22:04.292] iteration 13459 : model1 loss : 0.436296 model2 loss : 0.035699
[11:22:04.461] iteration 13460 : model1 loss : 0.439120 model2 loss : 0.027065
[11:22:04.629] iteration 13461 : model1 loss : 0.439755 model2 loss : 0.026073
[11:22:04.798] iteration 13462 : model1 loss : 0.441967 model2 loss : 0.026729
[11:22:04.963] iteration 13463 : model1 loss : 0.435578 model2 loss : 0.023302
[11:22:05.132] iteration 13464 : model1 loss : 0.433421 model2 loss : 0.024490
[11:22:07.120] iteration 13465 : model1 loss : 0.439116 model2 loss : 0.026648
[11:22:07.288] iteration 13466 : model1 loss : 0.434165 model2 loss : 0.029086
[11:22:07.457] iteration 13467 : model1 loss : 0.435099 model2 loss : 0.034184
[11:22:07.626] iteration 13468 : model1 loss : 0.435702 model2 loss : 0.028100
[11:22:07.793] iteration 13469 : model1 loss : 0.441924 model2 loss : 0.031705
[11:22:07.961] iteration 13470 : model1 loss : 0.428920 model2 loss : 0.024049
[11:22:08.132] iteration 13471 : model1 loss : 0.436188 model2 loss : 0.024975
[11:22:08.298] iteration 13472 : model1 loss : 0.440955 model2 loss : 0.035292
[11:22:08.466] iteration 13473 : model1 loss : 0.435109 model2 loss : 0.023907
[11:22:08.634] iteration 13474 : model1 loss : 0.439819 model2 loss : 0.024457
[11:22:08.802] iteration 13475 : model1 loss : 0.436486 model2 loss : 0.026045
[11:22:08.970] iteration 13476 : model1 loss : 0.436278 model2 loss : 0.025174
[11:22:09.138] iteration 13477 : model1 loss : 0.446067 model2 loss : 0.030098
[11:22:09.307] iteration 13478 : model1 loss : 0.436717 model2 loss : 0.027637
[11:22:09.478] iteration 13479 : model1 loss : 0.440584 model2 loss : 0.027266
[11:22:09.648] iteration 13480 : model1 loss : 0.436912 model2 loss : 0.023427
[11:22:09.819] iteration 13481 : model1 loss : 0.440740 model2 loss : 0.038785
[11:22:09.986] iteration 13482 : model1 loss : 0.435225 model2 loss : 0.025341
[11:22:10.155] iteration 13483 : model1 loss : 0.437409 model2 loss : 0.026256
[11:22:10.325] iteration 13484 : model1 loss : 0.435516 model2 loss : 0.029348
[11:22:10.496] iteration 13485 : model1 loss : 0.439138 model2 loss : 0.022491
[11:22:10.664] iteration 13486 : model1 loss : 0.434250 model2 loss : 0.030611
[11:22:10.836] iteration 13487 : model1 loss : 0.439715 model2 loss : 0.027918
[11:22:11.006] iteration 13488 : model1 loss : 0.436150 model2 loss : 0.025815
[11:22:11.176] iteration 13489 : model1 loss : 0.434443 model2 loss : 0.029196
[11:22:11.343] iteration 13490 : model1 loss : 0.436392 model2 loss : 0.025529
[11:22:11.519] iteration 13491 : model1 loss : 0.441642 model2 loss : 0.030322
[11:22:11.688] iteration 13492 : model1 loss : 0.436445 model2 loss : 0.025130
[11:22:11.859] iteration 13493 : model1 loss : 0.441865 model2 loss : 0.032440
[11:22:12.028] iteration 13494 : model1 loss : 0.436054 model2 loss : 0.030549
[11:22:12.211] iteration 13495 : model1 loss : 0.439798 model2 loss : 0.026734
[11:22:12.377] iteration 13496 : model1 loss : 0.434581 model2 loss : 0.023618
[11:22:12.547] iteration 13497 : model1 loss : 0.433298 model2 loss : 0.023992
[11:22:14.495] iteration 13498 : model1 loss : 0.433216 model2 loss : 0.024343
[11:22:14.663] iteration 13499 : model1 loss : 0.434517 model2 loss : 0.023643
[11:22:14.835] iteration 13500 : model1 loss : 0.435968 model2 loss : 0.027016
[11:22:15.003] iteration 13501 : model1 loss : 0.436584 model2 loss : 0.041113
[11:22:15.172] iteration 13502 : model1 loss : 0.437468 model2 loss : 0.025177
[11:22:15.339] iteration 13503 : model1 loss : 0.435569 model2 loss : 0.022240
[11:22:15.510] iteration 13504 : model1 loss : 0.437616 model2 loss : 0.027282
[11:22:15.678] iteration 13505 : model1 loss : 0.439883 model2 loss : 0.025900
[11:22:15.850] iteration 13506 : model1 loss : 0.438130 model2 loss : 0.025466
[11:22:16.021] iteration 13507 : model1 loss : 0.442444 model2 loss : 0.029490
[11:22:16.190] iteration 13508 : model1 loss : 0.434728 model2 loss : 0.026314
[11:22:16.359] iteration 13509 : model1 loss : 0.433013 model2 loss : 0.021814
[11:22:16.531] iteration 13510 : model1 loss : 0.438723 model2 loss : 0.029001
[11:22:16.696] iteration 13511 : model1 loss : 0.437073 model2 loss : 0.027142
[11:22:16.866] iteration 13512 : model1 loss : 0.440202 model2 loss : 0.027513
[11:22:17.035] iteration 13513 : model1 loss : 0.437213 model2 loss : 0.023785
[11:22:17.203] iteration 13514 : model1 loss : 0.439637 model2 loss : 0.027478
[11:22:17.373] iteration 13515 : model1 loss : 0.436056 model2 loss : 0.023724
[11:22:17.545] iteration 13516 : model1 loss : 0.433724 model2 loss : 0.021498
[11:22:17.712] iteration 13517 : model1 loss : 0.440164 model2 loss : 0.026642
[11:22:17.882] iteration 13518 : model1 loss : 0.433640 model2 loss : 0.024582
[11:22:18.048] iteration 13519 : model1 loss : 0.431823 model2 loss : 0.023698
[11:22:18.218] iteration 13520 : model1 loss : 0.435576 model2 loss : 0.024308
[11:22:18.385] iteration 13521 : model1 loss : 0.441400 model2 loss : 0.025746
[11:22:18.556] iteration 13522 : model1 loss : 0.436798 model2 loss : 0.027032
[11:22:18.723] iteration 13523 : model1 loss : 0.437000 model2 loss : 0.028140
[11:22:18.892] iteration 13524 : model1 loss : 0.438220 model2 loss : 0.022726
[11:22:19.061] iteration 13525 : model1 loss : 0.439092 model2 loss : 0.026470
[11:22:19.230] iteration 13526 : model1 loss : 0.435342 model2 loss : 0.024624
[11:22:19.397] iteration 13527 : model1 loss : 0.437246 model2 loss : 0.022833
[11:22:19.566] iteration 13528 : model1 loss : 0.438045 model2 loss : 0.030490
[11:22:19.731] iteration 13529 : model1 loss : 0.439194 model2 loss : 0.025896
[11:22:19.899] iteration 13530 : model1 loss : 0.439253 model2 loss : 0.029992
[11:22:21.878] iteration 13531 : model1 loss : 0.438296 model2 loss : 0.023764
[11:22:22.048] iteration 13532 : model1 loss : 0.435092 model2 loss : 0.023080
[11:22:22.218] iteration 13533 : model1 loss : 0.436968 model2 loss : 0.029491
[11:22:22.384] iteration 13534 : model1 loss : 0.434343 model2 loss : 0.020983
[11:22:22.555] iteration 13535 : model1 loss : 0.438433 model2 loss : 0.024835
[11:22:22.723] iteration 13536 : model1 loss : 0.438333 model2 loss : 0.024372
[11:22:22.893] iteration 13537 : model1 loss : 0.433652 model2 loss : 0.023075
[11:22:23.061] iteration 13538 : model1 loss : 0.443069 model2 loss : 0.029748
[11:22:23.231] iteration 13539 : model1 loss : 0.435885 model2 loss : 0.024739
[11:22:23.399] iteration 13540 : model1 loss : 0.436683 model2 loss : 0.030064
[11:22:23.570] iteration 13541 : model1 loss : 0.437979 model2 loss : 0.023296
[11:22:23.738] iteration 13542 : model1 loss : 0.435048 model2 loss : 0.026177
[11:22:23.916] iteration 13543 : model1 loss : 0.435465 model2 loss : 0.025029
[11:22:24.086] iteration 13544 : model1 loss : 0.437727 model2 loss : 0.026559
[11:22:24.255] iteration 13545 : model1 loss : 0.438767 model2 loss : 0.023432
[11:22:24.422] iteration 13546 : model1 loss : 0.441850 model2 loss : 0.031865
[11:22:24.592] iteration 13547 : model1 loss : 0.435335 model2 loss : 0.023363
[11:22:24.759] iteration 13548 : model1 loss : 0.438166 model2 loss : 0.024896
[11:22:24.930] iteration 13549 : model1 loss : 0.437438 model2 loss : 0.027876
[11:22:25.096] iteration 13550 : model1 loss : 0.437458 model2 loss : 0.026215
[11:22:25.267] iteration 13551 : model1 loss : 0.435417 model2 loss : 0.024210
[11:22:25.434] iteration 13552 : model1 loss : 0.434379 model2 loss : 0.025787
[11:22:25.603] iteration 13553 : model1 loss : 0.439582 model2 loss : 0.025470
[11:22:25.772] iteration 13554 : model1 loss : 0.436089 model2 loss : 0.027094
[11:22:25.940] iteration 13555 : model1 loss : 0.438629 model2 loss : 0.024938
[11:22:26.110] iteration 13556 : model1 loss : 0.437010 model2 loss : 0.026864
[11:22:26.279] iteration 13557 : model1 loss : 0.435686 model2 loss : 0.024476
[11:22:26.445] iteration 13558 : model1 loss : 0.436473 model2 loss : 0.025239
[11:22:26.614] iteration 13559 : model1 loss : 0.438796 model2 loss : 0.023429
[11:22:26.782] iteration 13560 : model1 loss : 0.434065 model2 loss : 0.025888
[11:22:26.952] iteration 13561 : model1 loss : 0.438395 model2 loss : 0.024514
[11:22:27.119] iteration 13562 : model1 loss : 0.436194 model2 loss : 0.024058
[11:22:27.288] iteration 13563 : model1 loss : 0.431022 model2 loss : 0.020922
[11:22:29.213] iteration 13564 : model1 loss : 0.441030 model2 loss : 0.026575
[11:22:29.382] iteration 13565 : model1 loss : 0.436314 model2 loss : 0.023329
[11:22:29.554] iteration 13566 : model1 loss : 0.437429 model2 loss : 0.024950
[11:22:29.722] iteration 13567 : model1 loss : 0.436864 model2 loss : 0.022964
[11:22:29.891] iteration 13568 : model1 loss : 0.439132 model2 loss : 0.027185
[11:22:30.062] iteration 13569 : model1 loss : 0.436747 model2 loss : 0.022096
[11:22:30.230] iteration 13570 : model1 loss : 0.437237 model2 loss : 0.026407
[11:22:30.396] iteration 13571 : model1 loss : 0.437887 model2 loss : 0.025303
[11:22:30.566] iteration 13572 : model1 loss : 0.438496 model2 loss : 0.024589
[11:22:30.732] iteration 13573 : model1 loss : 0.435977 model2 loss : 0.022247
[11:22:30.903] iteration 13574 : model1 loss : 0.433634 model2 loss : 0.023206
[11:22:31.074] iteration 13575 : model1 loss : 0.435676 model2 loss : 0.027488
[11:22:31.242] iteration 13576 : model1 loss : 0.434328 model2 loss : 0.021949
[11:22:31.410] iteration 13577 : model1 loss : 0.437788 model2 loss : 0.026295
[11:22:31.579] iteration 13578 : model1 loss : 0.436739 model2 loss : 0.026145
[11:22:31.745] iteration 13579 : model1 loss : 0.435632 model2 loss : 0.023675
[11:22:31.917] iteration 13580 : model1 loss : 0.433738 model2 loss : 0.022082
[11:22:32.085] iteration 13581 : model1 loss : 0.438657 model2 loss : 0.027119
[11:22:32.255] iteration 13582 : model1 loss : 0.438155 model2 loss : 0.022914
[11:22:32.422] iteration 13583 : model1 loss : 0.439607 model2 loss : 0.029839
[11:22:32.592] iteration 13584 : model1 loss : 0.431798 model2 loss : 0.024326
[11:22:32.759] iteration 13585 : model1 loss : 0.434503 model2 loss : 0.024996
[11:22:32.929] iteration 13586 : model1 loss : 0.444057 model2 loss : 0.032732
[11:22:33.098] iteration 13587 : model1 loss : 0.437309 model2 loss : 0.028986
[11:22:33.267] iteration 13588 : model1 loss : 0.433552 model2 loss : 0.024212
[11:22:33.434] iteration 13589 : model1 loss : 0.434845 model2 loss : 0.022872
[11:22:33.602] iteration 13590 : model1 loss : 0.437765 model2 loss : 0.025214
[11:22:33.767] iteration 13591 : model1 loss : 0.434812 model2 loss : 0.024017
[11:22:33.936] iteration 13592 : model1 loss : 0.440120 model2 loss : 0.027498
[11:22:34.105] iteration 13593 : model1 loss : 0.431850 model2 loss : 0.022423
[11:22:34.275] iteration 13594 : model1 loss : 0.440307 model2 loss : 0.029043
[11:22:34.440] iteration 13595 : model1 loss : 0.439012 model2 loss : 0.025154
[11:22:34.610] iteration 13596 : model1 loss : 0.436874 model2 loss : 0.024385
[11:22:36.582] iteration 13597 : model1 loss : 0.437706 model2 loss : 0.027491
[11:22:36.752] iteration 13598 : model1 loss : 0.433056 model2 loss : 0.022987
[11:22:36.922] iteration 13599 : model1 loss : 0.436581 model2 loss : 0.024716
[11:22:37.090] iteration 13600 : model1 loss : 0.436768 model2 loss : 0.023955
[11:22:37.259] iteration 13601 : model1 loss : 0.436292 model2 loss : 0.025077
[11:22:37.424] iteration 13602 : model1 loss : 0.435035 model2 loss : 0.026364
[11:22:37.594] iteration 13603 : model1 loss : 0.435627 model2 loss : 0.022273
[11:22:37.760] iteration 13604 : model1 loss : 0.435819 model2 loss : 0.025182
[11:22:37.931] iteration 13605 : model1 loss : 0.437371 model2 loss : 0.025000
[11:22:38.100] iteration 13606 : model1 loss : 0.435857 model2 loss : 0.022398
[11:22:38.272] iteration 13607 : model1 loss : 0.442718 model2 loss : 0.032025
[11:22:38.439] iteration 13608 : model1 loss : 0.437496 model2 loss : 0.026890
[11:22:38.610] iteration 13609 : model1 loss : 0.436119 model2 loss : 0.023503
[11:22:38.776] iteration 13610 : model1 loss : 0.436936 model2 loss : 0.026683
[11:22:38.944] iteration 13611 : model1 loss : 0.436857 model2 loss : 0.025116
[11:22:39.113] iteration 13612 : model1 loss : 0.437075 model2 loss : 0.024999
[11:22:39.283] iteration 13613 : model1 loss : 0.438177 model2 loss : 0.026899
[11:22:39.451] iteration 13614 : model1 loss : 0.437673 model2 loss : 0.025727
[11:22:39.619] iteration 13615 : model1 loss : 0.437738 model2 loss : 0.027077
[11:22:39.786] iteration 13616 : model1 loss : 0.439771 model2 loss : 0.025075
[11:22:39.956] iteration 13617 : model1 loss : 0.437890 model2 loss : 0.025104
[11:22:40.126] iteration 13618 : model1 loss : 0.437079 model2 loss : 0.024944
[11:22:40.296] iteration 13619 : model1 loss : 0.438542 model2 loss : 0.020825
[11:22:40.465] iteration 13620 : model1 loss : 0.436964 model2 loss : 0.024884
[11:22:40.634] iteration 13621 : model1 loss : 0.435804 model2 loss : 0.025143
[11:22:40.801] iteration 13622 : model1 loss : 0.437034 model2 loss : 0.022391
[11:22:40.970] iteration 13623 : model1 loss : 0.434415 model2 loss : 0.024843
[11:22:41.138] iteration 13624 : model1 loss : 0.438771 model2 loss : 0.025268
[11:22:41.308] iteration 13625 : model1 loss : 0.437169 model2 loss : 0.024029
[11:22:41.476] iteration 13626 : model1 loss : 0.439258 model2 loss : 0.027029
[11:22:41.644] iteration 13627 : model1 loss : 0.434514 model2 loss : 0.020650
[11:22:41.808] iteration 13628 : model1 loss : 0.438093 model2 loss : 0.025117
[11:22:41.975] iteration 13629 : model1 loss : 0.438054 model2 loss : 0.024674
[11:22:43.912] iteration 13630 : model1 loss : 0.434363 model2 loss : 0.022852
[11:22:44.079] iteration 13631 : model1 loss : 0.432954 model2 loss : 0.022136
[11:22:44.247] iteration 13632 : model1 loss : 0.438770 model2 loss : 0.025355
[11:22:44.424] iteration 13633 : model1 loss : 0.437232 model2 loss : 0.022577
[11:22:44.595] iteration 13634 : model1 loss : 0.433643 model2 loss : 0.020493
[11:22:44.763] iteration 13635 : model1 loss : 0.439785 model2 loss : 0.031276
[11:22:44.931] iteration 13636 : model1 loss : 0.436454 model2 loss : 0.022703
[11:22:45.103] iteration 13637 : model1 loss : 0.437787 model2 loss : 0.025390
[11:22:45.274] iteration 13638 : model1 loss : 0.433749 model2 loss : 0.021878
[11:22:45.439] iteration 13639 : model1 loss : 0.431289 model2 loss : 0.023218
[11:22:45.609] iteration 13640 : model1 loss : 0.437774 model2 loss : 0.023929
[11:22:45.776] iteration 13641 : model1 loss : 0.432904 model2 loss : 0.023160
[11:22:45.948] iteration 13642 : model1 loss : 0.439364 model2 loss : 0.024112
[11:22:46.117] iteration 13643 : model1 loss : 0.436404 model2 loss : 0.024309
[11:22:46.286] iteration 13644 : model1 loss : 0.438256 model2 loss : 0.026177
[11:22:46.454] iteration 13645 : model1 loss : 0.438254 model2 loss : 0.023987
[11:22:46.623] iteration 13646 : model1 loss : 0.439744 model2 loss : 0.026577
[11:22:46.790] iteration 13647 : model1 loss : 0.438117 model2 loss : 0.026106
[11:22:46.960] iteration 13648 : model1 loss : 0.434559 model2 loss : 0.021113
[11:22:47.132] iteration 13649 : model1 loss : 0.437495 model2 loss : 0.026385
[11:22:47.301] iteration 13650 : model1 loss : 0.435399 model2 loss : 0.024787
[11:22:47.469] iteration 13651 : model1 loss : 0.441307 model2 loss : 0.026138
[11:22:47.654] iteration 13652 : model1 loss : 0.440062 model2 loss : 0.021609
[11:22:47.823] iteration 13653 : model1 loss : 0.434839 model2 loss : 0.025551
[11:22:47.993] iteration 13654 : model1 loss : 0.442644 model2 loss : 0.030254
[11:22:48.161] iteration 13655 : model1 loss : 0.434582 model2 loss : 0.023051
[11:22:48.330] iteration 13656 : model1 loss : 0.436248 model2 loss : 0.023200
[11:22:48.499] iteration 13657 : model1 loss : 0.441776 model2 loss : 0.029554
[11:22:48.668] iteration 13658 : model1 loss : 0.434707 model2 loss : 0.021950
[11:22:48.836] iteration 13659 : model1 loss : 0.440385 model2 loss : 0.024123
[11:22:49.005] iteration 13660 : model1 loss : 0.435777 model2 loss : 0.023898
[11:22:49.171] iteration 13661 : model1 loss : 0.435432 model2 loss : 0.021717
[11:22:49.339] iteration 13662 : model1 loss : 0.438016 model2 loss : 0.022921
[11:22:51.270] iteration 13663 : model1 loss : 0.439035 model2 loss : 0.022774
[11:22:51.438] iteration 13664 : model1 loss : 0.432407 model2 loss : 0.021943
[11:22:51.609] iteration 13665 : model1 loss : 0.436155 model2 loss : 0.022096
[11:22:51.776] iteration 13666 : model1 loss : 0.435646 model2 loss : 0.022348
[11:22:51.944] iteration 13667 : model1 loss : 0.434953 model2 loss : 0.024468
[11:22:52.114] iteration 13668 : model1 loss : 0.438315 model2 loss : 0.027854
[11:22:52.285] iteration 13669 : model1 loss : 0.436396 model2 loss : 0.026458
[11:22:52.452] iteration 13670 : model1 loss : 0.437224 model2 loss : 0.023013
[11:22:52.622] iteration 13671 : model1 loss : 0.433982 model2 loss : 0.024273
[11:22:52.789] iteration 13672 : model1 loss : 0.436949 model2 loss : 0.023176
[11:22:52.960] iteration 13673 : model1 loss : 0.435911 model2 loss : 0.024605
[11:22:53.131] iteration 13674 : model1 loss : 0.438439 model2 loss : 0.022780
[11:22:53.301] iteration 13675 : model1 loss : 0.440945 model2 loss : 0.026849
[11:22:53.468] iteration 13676 : model1 loss : 0.436465 model2 loss : 0.020515
[11:22:53.638] iteration 13677 : model1 loss : 0.435415 model2 loss : 0.022834
[11:22:53.808] iteration 13678 : model1 loss : 0.438521 model2 loss : 0.023867
[11:22:53.974] iteration 13679 : model1 loss : 0.439164 model2 loss : 0.023031
[11:22:54.143] iteration 13680 : model1 loss : 0.434552 model2 loss : 0.023423
[11:22:54.312] iteration 13681 : model1 loss : 0.432514 model2 loss : 0.022995
[11:22:54.479] iteration 13682 : model1 loss : 0.437028 model2 loss : 0.022747
[11:22:54.647] iteration 13683 : model1 loss : 0.436538 model2 loss : 0.025857
[11:22:54.815] iteration 13684 : model1 loss : 0.442407 model2 loss : 0.027052
[11:22:54.984] iteration 13685 : model1 loss : 0.438182 model2 loss : 0.025027
[11:22:55.152] iteration 13686 : model1 loss : 0.434886 model2 loss : 0.022048
[11:22:55.324] iteration 13687 : model1 loss : 0.436076 model2 loss : 0.025354
[11:22:55.490] iteration 13688 : model1 loss : 0.440249 model2 loss : 0.026953
[11:22:55.658] iteration 13689 : model1 loss : 0.441197 model2 loss : 0.029091
[11:22:55.824] iteration 13690 : model1 loss : 0.438998 model2 loss : 0.026161
[11:22:55.994] iteration 13691 : model1 loss : 0.434666 model2 loss : 0.022568
[11:22:56.163] iteration 13692 : model1 loss : 0.435858 model2 loss : 0.023734
[11:22:56.333] iteration 13693 : model1 loss : 0.436227 model2 loss : 0.021464
[11:22:56.500] iteration 13694 : model1 loss : 0.436601 model2 loss : 0.024145
[11:22:56.667] iteration 13695 : model1 loss : 0.438076 model2 loss : 0.020560
[11:22:58.608] iteration 13696 : model1 loss : 0.435048 model2 loss : 0.022707
[11:22:58.778] iteration 13697 : model1 loss : 0.437628 model2 loss : 0.022659
[11:22:58.947] iteration 13698 : model1 loss : 0.438018 model2 loss : 0.023715
[11:22:59.115] iteration 13699 : model1 loss : 0.441634 model2 loss : 0.031319
[11:22:59.285] iteration 13700 : model1 loss : 0.437021 model2 loss : 0.023883
[11:22:59.454] iteration 13701 : model1 loss : 0.435992 model2 loss : 0.025981
[11:22:59.621] iteration 13702 : model1 loss : 0.439583 model2 loss : 0.027294
[11:22:59.788] iteration 13703 : model1 loss : 0.435928 model2 loss : 0.023984
[11:22:59.958] iteration 13704 : model1 loss : 0.432835 model2 loss : 0.019902
[11:23:00.133] iteration 13705 : model1 loss : 0.438371 model2 loss : 0.024407
[11:23:00.300] iteration 13706 : model1 loss : 0.435804 model2 loss : 0.022995
[11:23:00.469] iteration 13707 : model1 loss : 0.438497 model2 loss : 0.026889
[11:23:00.639] iteration 13708 : model1 loss : 0.437957 model2 loss : 0.034500
[11:23:00.808] iteration 13709 : model1 loss : 0.439482 model2 loss : 0.028426
[11:23:00.990] iteration 13710 : model1 loss : 0.438251 model2 loss : 0.026161
[11:23:01.156] iteration 13711 : model1 loss : 0.435204 model2 loss : 0.024302
[11:23:01.325] iteration 13712 : model1 loss : 0.435041 model2 loss : 0.022862
[11:23:01.494] iteration 13713 : model1 loss : 0.435743 model2 loss : 0.022743
[11:23:01.662] iteration 13714 : model1 loss : 0.433919 model2 loss : 0.024462
[11:23:01.830] iteration 13715 : model1 loss : 0.443324 model2 loss : 0.031645
[11:23:01.999] iteration 13716 : model1 loss : 0.441831 model2 loss : 0.026560
[11:23:02.168] iteration 13717 : model1 loss : 0.442174 model2 loss : 0.028669
[11:23:02.337] iteration 13718 : model1 loss : 0.435645 model2 loss : 0.022887
[11:23:02.505] iteration 13719 : model1 loss : 0.429853 model2 loss : 0.022585
[11:23:02.675] iteration 13720 : model1 loss : 0.436844 model2 loss : 0.023946
[11:23:02.842] iteration 13721 : model1 loss : 0.431327 model2 loss : 0.024111
[11:23:03.011] iteration 13722 : model1 loss : 0.434846 model2 loss : 0.022508
[11:23:03.179] iteration 13723 : model1 loss : 0.435955 model2 loss : 0.028832
[11:23:03.350] iteration 13724 : model1 loss : 0.441701 model2 loss : 0.028774
[11:23:03.518] iteration 13725 : model1 loss : 0.435957 model2 loss : 0.023733
[11:23:03.688] iteration 13726 : model1 loss : 0.433911 model2 loss : 0.021680
[11:23:03.854] iteration 13727 : model1 loss : 0.439105 model2 loss : 0.027316
[11:23:04.024] iteration 13728 : model1 loss : 0.435520 model2 loss : 0.027142
[11:23:05.936] iteration 13729 : model1 loss : 0.438133 model2 loss : 0.026119
[11:23:06.102] iteration 13730 : model1 loss : 0.435402 model2 loss : 0.027853
[11:23:06.273] iteration 13731 : model1 loss : 0.441465 model2 loss : 0.024191
[11:23:06.440] iteration 13732 : model1 loss : 0.436812 model2 loss : 0.025432
[11:23:06.609] iteration 13733 : model1 loss : 0.438888 model2 loss : 0.024337
[11:23:06.778] iteration 13734 : model1 loss : 0.434488 model2 loss : 0.027078
[11:23:06.948] iteration 13735 : model1 loss : 0.438691 model2 loss : 0.026050
[11:23:07.118] iteration 13736 : model1 loss : 0.436288 model2 loss : 0.024264
[11:23:07.287] iteration 13737 : model1 loss : 0.435463 model2 loss : 0.021970
[11:23:07.455] iteration 13738 : model1 loss : 0.430581 model2 loss : 0.023273
[11:23:07.623] iteration 13739 : model1 loss : 0.437711 model2 loss : 0.024287
[11:23:07.791] iteration 13740 : model1 loss : 0.439285 model2 loss : 0.025948
[11:23:07.961] iteration 13741 : model1 loss : 0.431709 model2 loss : 0.023555
[11:23:08.129] iteration 13742 : model1 loss : 0.438710 model2 loss : 0.030984
[11:23:08.298] iteration 13743 : model1 loss : 0.433964 model2 loss : 0.027255
[11:23:08.467] iteration 13744 : model1 loss : 0.437201 model2 loss : 0.024510
[11:23:08.634] iteration 13745 : model1 loss : 0.438424 model2 loss : 0.025326
[11:23:08.801] iteration 13746 : model1 loss : 0.437181 model2 loss : 0.023622
[11:23:08.984] iteration 13747 : model1 loss : 0.438538 model2 loss : 0.027273
[11:23:09.151] iteration 13748 : model1 loss : 0.439237 model2 loss : 0.027390
[11:23:09.321] iteration 13749 : model1 loss : 0.435872 model2 loss : 0.023553
[11:23:09.487] iteration 13750 : model1 loss : 0.437994 model2 loss : 0.024097
[11:23:09.657] iteration 13751 : model1 loss : 0.432344 model2 loss : 0.020757
[11:23:09.824] iteration 13752 : model1 loss : 0.438290 model2 loss : 0.023116
[11:23:09.994] iteration 13753 : model1 loss : 0.440431 model2 loss : 0.031006
[11:23:10.161] iteration 13754 : model1 loss : 0.441261 model2 loss : 0.030778
[11:23:10.331] iteration 13755 : model1 loss : 0.444809 model2 loss : 0.040696
[11:23:10.499] iteration 13756 : model1 loss : 0.434141 model2 loss : 0.027915
[11:23:10.667] iteration 13757 : model1 loss : 0.433482 model2 loss : 0.031901
[11:23:10.837] iteration 13758 : model1 loss : 0.438064 model2 loss : 0.043477
[11:23:11.007] iteration 13759 : model1 loss : 0.441292 model2 loss : 0.040927
[11:23:11.172] iteration 13760 : model1 loss : 0.440086 model2 loss : 0.030668
[11:23:11.341] iteration 13761 : model1 loss : 0.437139 model2 loss : 0.036264
[11:23:13.323] iteration 13762 : model1 loss : 0.434153 model2 loss : 0.028780
[11:23:13.495] iteration 13763 : model1 loss : 0.435827 model2 loss : 0.043059
[11:23:13.667] iteration 13764 : model1 loss : 0.440245 model2 loss : 0.053105
[11:23:13.833] iteration 13765 : model1 loss : 0.436981 model2 loss : 0.032330
[11:23:14.002] iteration 13766 : model1 loss : 0.443255 model2 loss : 0.044528
[11:23:14.173] iteration 13767 : model1 loss : 0.436321 model2 loss : 0.034951
[11:23:14.343] iteration 13768 : model1 loss : 0.439464 model2 loss : 0.051583
[11:23:14.512] iteration 13769 : model1 loss : 0.438567 model2 loss : 0.048772
[11:23:14.682] iteration 13770 : model1 loss : 0.438380 model2 loss : 0.037523
[11:23:14.852] iteration 13771 : model1 loss : 0.435825 model2 loss : 0.040200
[11:23:15.020] iteration 13772 : model1 loss : 0.434089 model2 loss : 0.030472
[11:23:15.190] iteration 13773 : model1 loss : 0.436034 model2 loss : 0.044958
[11:23:15.355] iteration 13774 : model1 loss : 0.439356 model2 loss : 0.039501
[11:23:15.523] iteration 13775 : model1 loss : 0.437923 model2 loss : 0.038117
[11:23:15.692] iteration 13776 : model1 loss : 0.434555 model2 loss : 0.036799
[11:23:15.863] iteration 13777 : model1 loss : 0.439667 model2 loss : 0.050697
[11:23:16.032] iteration 13778 : model1 loss : 0.436565 model2 loss : 0.040941
[11:23:16.199] iteration 13779 : model1 loss : 0.435336 model2 loss : 0.040868
[11:23:16.368] iteration 13780 : model1 loss : 0.432919 model2 loss : 0.031707
[11:23:16.539] iteration 13781 : model1 loss : 0.441733 model2 loss : 0.047399
[11:23:16.710] iteration 13782 : model1 loss : 0.436030 model2 loss : 0.035184
[11:23:16.878] iteration 13783 : model1 loss : 0.438695 model2 loss : 0.047374
[11:23:17.048] iteration 13784 : model1 loss : 0.442335 model2 loss : 0.045255
[11:23:17.214] iteration 13785 : model1 loss : 0.434729 model2 loss : 0.035281
[11:23:17.382] iteration 13786 : model1 loss : 0.437929 model2 loss : 0.035212
[11:23:17.549] iteration 13787 : model1 loss : 0.438449 model2 loss : 0.038468
[11:23:17.715] iteration 13788 : model1 loss : 0.438799 model2 loss : 0.033893
[11:23:17.882] iteration 13789 : model1 loss : 0.435766 model2 loss : 0.026918
[11:23:18.050] iteration 13790 : model1 loss : 0.434374 model2 loss : 0.035377
[11:23:18.218] iteration 13791 : model1 loss : 0.438771 model2 loss : 0.054929
[11:23:18.390] iteration 13792 : model1 loss : 0.432366 model2 loss : 0.035980
[11:23:18.557] iteration 13793 : model1 loss : 0.436530 model2 loss : 0.029551
[11:23:18.726] iteration 13794 : model1 loss : 0.437986 model2 loss : 0.032281
[11:23:20.638] iteration 13795 : model1 loss : 0.442324 model2 loss : 0.036344
[11:23:20.806] iteration 13796 : model1 loss : 0.440271 model2 loss : 0.045837
[11:23:20.977] iteration 13797 : model1 loss : 0.439451 model2 loss : 0.045113
[11:23:21.143] iteration 13798 : model1 loss : 0.437169 model2 loss : 0.033721
[11:23:21.314] iteration 13799 : model1 loss : 0.440376 model2 loss : 0.034282
[11:23:21.480] iteration 13800 : model1 loss : 0.437986 model2 loss : 0.046667
[11:23:21.652] iteration 13801 : model1 loss : 0.436176 model2 loss : 0.040081
[11:23:21.820] iteration 13802 : model1 loss : 0.434869 model2 loss : 0.027346
[11:23:21.988] iteration 13803 : model1 loss : 0.441130 model2 loss : 0.029672
[11:23:22.155] iteration 13804 : model1 loss : 0.436842 model2 loss : 0.032353
[11:23:22.322] iteration 13805 : model1 loss : 0.436415 model2 loss : 0.046366
[11:23:22.490] iteration 13806 : model1 loss : 0.437351 model2 loss : 0.039466
[11:23:22.660] iteration 13807 : model1 loss : 0.436329 model2 loss : 0.032088
[11:23:22.827] iteration 13808 : model1 loss : 0.445313 model2 loss : 0.049779
[11:23:22.996] iteration 13809 : model1 loss : 0.433070 model2 loss : 0.033455
[11:23:23.165] iteration 13810 : model1 loss : 0.435302 model2 loss : 0.030964
[11:23:23.333] iteration 13811 : model1 loss : 0.434274 model2 loss : 0.033659
[11:23:23.503] iteration 13812 : model1 loss : 0.437842 model2 loss : 0.029462
[11:23:23.672] iteration 13813 : model1 loss : 0.434351 model2 loss : 0.025760
[11:23:23.840] iteration 13814 : model1 loss : 0.438709 model2 loss : 0.031832
[11:23:24.008] iteration 13815 : model1 loss : 0.435491 model2 loss : 0.031729
[11:23:24.178] iteration 13816 : model1 loss : 0.438774 model2 loss : 0.031701
[11:23:24.346] iteration 13817 : model1 loss : 0.438650 model2 loss : 0.032364
[11:23:24.516] iteration 13818 : model1 loss : 0.437672 model2 loss : 0.028849
[11:23:24.686] iteration 13819 : model1 loss : 0.439520 model2 loss : 0.030447
[11:23:24.852] iteration 13820 : model1 loss : 0.437954 model2 loss : 0.029462
[11:23:25.022] iteration 13821 : model1 loss : 0.432727 model2 loss : 0.030543
[11:23:25.189] iteration 13822 : model1 loss : 0.433672 model2 loss : 0.035248
[11:23:25.357] iteration 13823 : model1 loss : 0.438791 model2 loss : 0.028045
[11:23:25.526] iteration 13824 : model1 loss : 0.432179 model2 loss : 0.031838
[11:23:25.695] iteration 13825 : model1 loss : 0.432705 model2 loss : 0.028359
[11:23:25.861] iteration 13826 : model1 loss : 0.436292 model2 loss : 0.033527
[11:23:26.029] iteration 13827 : model1 loss : 0.437467 model2 loss : 0.028289
[11:23:27.943] iteration 13828 : model1 loss : 0.437563 model2 loss : 0.026187
[11:23:28.110] iteration 13829 : model1 loss : 0.435200 model2 loss : 0.025315
[11:23:28.279] iteration 13830 : model1 loss : 0.438366 model2 loss : 0.027722
[11:23:28.446] iteration 13831 : model1 loss : 0.439563 model2 loss : 0.027192
[11:23:28.615] iteration 13832 : model1 loss : 0.436116 model2 loss : 0.031552
[11:23:28.781] iteration 13833 : model1 loss : 0.434587 model2 loss : 0.025622
[11:23:28.950] iteration 13834 : model1 loss : 0.432448 model2 loss : 0.026976
[11:23:29.118] iteration 13835 : model1 loss : 0.436888 model2 loss : 0.037415
[11:23:29.291] iteration 13836 : model1 loss : 0.438521 model2 loss : 0.028606
[11:23:29.459] iteration 13837 : model1 loss : 0.437701 model2 loss : 0.029555
[11:23:29.628] iteration 13838 : model1 loss : 0.444083 model2 loss : 0.054099
[11:23:29.795] iteration 13839 : model1 loss : 0.438237 model2 loss : 0.038138
[11:23:29.965] iteration 13840 : model1 loss : 0.437652 model2 loss : 0.027241
[11:23:30.131] iteration 13841 : model1 loss : 0.435306 model2 loss : 0.036872
[11:23:30.300] iteration 13842 : model1 loss : 0.440182 model2 loss : 0.033236
[11:23:30.466] iteration 13843 : model1 loss : 0.437059 model2 loss : 0.031627
[11:23:30.634] iteration 13844 : model1 loss : 0.436126 model2 loss : 0.026304
[11:23:30.800] iteration 13845 : model1 loss : 0.435666 model2 loss : 0.028486
[11:23:30.967] iteration 13846 : model1 loss : 0.437864 model2 loss : 0.028606
[11:23:31.134] iteration 13847 : model1 loss : 0.441021 model2 loss : 0.032472
[11:23:31.304] iteration 13848 : model1 loss : 0.436380 model2 loss : 0.029771
[11:23:31.472] iteration 13849 : model1 loss : 0.439578 model2 loss : 0.028690
[11:23:31.643] iteration 13850 : model1 loss : 0.440385 model2 loss : 0.028312
[11:23:31.809] iteration 13851 : model1 loss : 0.435509 model2 loss : 0.025775
[11:23:31.981] iteration 13852 : model1 loss : 0.436165 model2 loss : 0.025996
[11:23:32.149] iteration 13853 : model1 loss : 0.439443 model2 loss : 0.028482
[11:23:32.319] iteration 13854 : model1 loss : 0.434033 model2 loss : 0.030847
[11:23:32.485] iteration 13855 : model1 loss : 0.435759 model2 loss : 0.029406
[11:23:32.654] iteration 13856 : model1 loss : 0.440622 model2 loss : 0.030196
[11:23:32.822] iteration 13857 : model1 loss : 0.436881 model2 loss : 0.026531
[11:23:32.990] iteration 13858 : model1 loss : 0.439234 model2 loss : 0.030331
[11:23:33.156] iteration 13859 : model1 loss : 0.438969 model2 loss : 0.029790
[11:23:33.325] iteration 13860 : model1 loss : 0.430637 model2 loss : 0.024405
[11:23:35.246] iteration 13861 : model1 loss : 0.436466 model2 loss : 0.027677
[11:23:35.416] iteration 13862 : model1 loss : 0.438327 model2 loss : 0.034384
[11:23:35.588] iteration 13863 : model1 loss : 0.438109 model2 loss : 0.029169
[11:23:35.757] iteration 13864 : model1 loss : 0.436429 model2 loss : 0.026200
[11:23:35.927] iteration 13865 : model1 loss : 0.438739 model2 loss : 0.026684
[11:23:36.094] iteration 13866 : model1 loss : 0.439605 model2 loss : 0.027630
[11:23:36.266] iteration 13867 : model1 loss : 0.437465 model2 loss : 0.026424
[11:23:36.432] iteration 13868 : model1 loss : 0.435409 model2 loss : 0.031230
[11:23:36.601] iteration 13869 : model1 loss : 0.438017 model2 loss : 0.026825
[11:23:36.768] iteration 13870 : model1 loss : 0.440638 model2 loss : 0.041334
[11:23:36.938] iteration 13871 : model1 loss : 0.438579 model2 loss : 0.027997
[11:23:37.106] iteration 13872 : model1 loss : 0.440114 model2 loss : 0.030685
[11:23:37.275] iteration 13873 : model1 loss : 0.439402 model2 loss : 0.025852
[11:23:37.442] iteration 13874 : model1 loss : 0.433863 model2 loss : 0.027344
[11:23:37.611] iteration 13875 : model1 loss : 0.431942 model2 loss : 0.026890
[11:23:37.779] iteration 13876 : model1 loss : 0.436295 model2 loss : 0.034400
[11:23:37.949] iteration 13877 : model1 loss : 0.435270 model2 loss : 0.028530
[11:23:38.116] iteration 13878 : model1 loss : 0.434722 model2 loss : 0.031570
[11:23:38.286] iteration 13879 : model1 loss : 0.434898 model2 loss : 0.023269
[11:23:38.453] iteration 13880 : model1 loss : 0.437297 model2 loss : 0.035171
[11:23:38.620] iteration 13881 : model1 loss : 0.443019 model2 loss : 0.034820
[11:23:38.788] iteration 13882 : model1 loss : 0.437052 model2 loss : 0.027820
[11:23:38.958] iteration 13883 : model1 loss : 0.432183 model2 loss : 0.025799
[11:23:39.126] iteration 13884 : model1 loss : 0.435396 model2 loss : 0.030569
[11:23:39.295] iteration 13885 : model1 loss : 0.438706 model2 loss : 0.035397
[11:23:39.463] iteration 13886 : model1 loss : 0.434396 model2 loss : 0.025752
[11:23:39.631] iteration 13887 : model1 loss : 0.435521 model2 loss : 0.027245
[11:23:39.802] iteration 13888 : model1 loss : 0.438304 model2 loss : 0.029293
[11:23:39.971] iteration 13889 : model1 loss : 0.439899 model2 loss : 0.039796
[11:23:40.139] iteration 13890 : model1 loss : 0.437814 model2 loss : 0.036299
[11:23:40.307] iteration 13891 : model1 loss : 0.437417 model2 loss : 0.032533
[11:23:40.473] iteration 13892 : model1 loss : 0.438166 model2 loss : 0.027943
[11:23:40.642] iteration 13893 : model1 loss : 0.436352 model2 loss : 0.030579
[11:23:42.573] iteration 13894 : model1 loss : 0.437207 model2 loss : 0.026240
[11:23:42.740] iteration 13895 : model1 loss : 0.438291 model2 loss : 0.027260
[11:23:42.909] iteration 13896 : model1 loss : 0.444015 model2 loss : 0.033380
[11:23:43.077] iteration 13897 : model1 loss : 0.435878 model2 loss : 0.032925
[11:23:43.245] iteration 13898 : model1 loss : 0.441720 model2 loss : 0.029938
[11:23:43.415] iteration 13899 : model1 loss : 0.437999 model2 loss : 0.030609
[11:23:43.584] iteration 13900 : model1 loss : 0.438427 model2 loss : 0.029431
[11:23:43.753] iteration 13901 : model1 loss : 0.435011 model2 loss : 0.023738
[11:23:43.924] iteration 13902 : model1 loss : 0.434737 model2 loss : 0.028145
[11:23:44.091] iteration 13903 : model1 loss : 0.438226 model2 loss : 0.027103
[11:23:44.261] iteration 13904 : model1 loss : 0.435446 model2 loss : 0.031063
[11:23:44.428] iteration 13905 : model1 loss : 0.433742 model2 loss : 0.024840
[11:23:44.597] iteration 13906 : model1 loss : 0.439406 model2 loss : 0.031836
[11:23:44.766] iteration 13907 : model1 loss : 0.436992 model2 loss : 0.027821
[11:23:44.935] iteration 13908 : model1 loss : 0.437819 model2 loss : 0.029089
[11:23:45.104] iteration 13909 : model1 loss : 0.432352 model2 loss : 0.024907
[11:23:45.270] iteration 13910 : model1 loss : 0.441700 model2 loss : 0.033644
[11:23:45.441] iteration 13911 : model1 loss : 0.435941 model2 loss : 0.026800
[11:23:45.609] iteration 13912 : model1 loss : 0.435170 model2 loss : 0.026887
[11:23:45.777] iteration 13913 : model1 loss : 0.438353 model2 loss : 0.028474
[11:23:45.947] iteration 13914 : model1 loss : 0.436094 model2 loss : 0.024063
[11:23:46.115] iteration 13915 : model1 loss : 0.435502 model2 loss : 0.027520
[11:23:46.285] iteration 13916 : model1 loss : 0.433533 model2 loss : 0.024005
[11:23:46.457] iteration 13917 : model1 loss : 0.438300 model2 loss : 0.022609
[11:23:46.626] iteration 13918 : model1 loss : 0.440269 model2 loss : 0.027028
[11:23:46.794] iteration 13919 : model1 loss : 0.439549 model2 loss : 0.028570
[11:23:46.966] iteration 13920 : model1 loss : 0.436038 model2 loss : 0.027518
[11:23:47.133] iteration 13921 : model1 loss : 0.437658 model2 loss : 0.025575
[11:23:47.303] iteration 13922 : model1 loss : 0.435611 model2 loss : 0.026999
[11:23:47.471] iteration 13923 : model1 loss : 0.434560 model2 loss : 0.022900
[11:23:47.641] iteration 13924 : model1 loss : 0.436854 model2 loss : 0.026517
[11:23:47.807] iteration 13925 : model1 loss : 0.434826 model2 loss : 0.025228
[11:23:47.976] iteration 13926 : model1 loss : 0.439543 model2 loss : 0.027078
[11:23:49.911] iteration 13927 : model1 loss : 0.433998 model2 loss : 0.024795
[11:23:50.083] iteration 13928 : model1 loss : 0.436084 model2 loss : 0.028356
[11:23:50.254] iteration 13929 : model1 loss : 0.437270 model2 loss : 0.026567
[11:23:50.423] iteration 13930 : model1 loss : 0.438546 model2 loss : 0.024328
[11:23:50.602] iteration 13931 : model1 loss : 0.441231 model2 loss : 0.027211
[11:23:50.769] iteration 13932 : model1 loss : 0.438054 model2 loss : 0.027880
[11:23:50.941] iteration 13933 : model1 loss : 0.437711 model2 loss : 0.024065
[11:23:51.107] iteration 13934 : model1 loss : 0.435631 model2 loss : 0.023709
[11:23:51.276] iteration 13935 : model1 loss : 0.440532 model2 loss : 0.025778
[11:23:51.444] iteration 13936 : model1 loss : 0.437607 model2 loss : 0.025959
[11:23:51.615] iteration 13937 : model1 loss : 0.433464 model2 loss : 0.022471
[11:23:51.781] iteration 13938 : model1 loss : 0.438251 model2 loss : 0.024770
[11:23:51.949] iteration 13939 : model1 loss : 0.441110 model2 loss : 0.025455
[11:23:52.117] iteration 13940 : model1 loss : 0.434006 model2 loss : 0.026393
[11:23:52.288] iteration 13941 : model1 loss : 0.436431 model2 loss : 0.024981
[11:23:52.455] iteration 13942 : model1 loss : 0.438506 model2 loss : 0.023236
[11:23:52.625] iteration 13943 : model1 loss : 0.436891 model2 loss : 0.028743
[11:23:52.793] iteration 13944 : model1 loss : 0.441311 model2 loss : 0.026241
[11:23:52.962] iteration 13945 : model1 loss : 0.435729 model2 loss : 0.025952
[11:23:53.130] iteration 13946 : model1 loss : 0.437256 model2 loss : 0.024660
[11:23:53.300] iteration 13947 : model1 loss : 0.439839 model2 loss : 0.026686
[11:23:53.475] iteration 13948 : model1 loss : 0.434966 model2 loss : 0.027770
[11:23:53.644] iteration 13949 : model1 loss : 0.438174 model2 loss : 0.027107
[11:23:53.812] iteration 13950 : model1 loss : 0.433345 model2 loss : 0.021957
[11:23:53.980] iteration 13951 : model1 loss : 0.434626 model2 loss : 0.030029
[11:23:54.151] iteration 13952 : model1 loss : 0.435178 model2 loss : 0.024393
[11:23:54.321] iteration 13953 : model1 loss : 0.435699 model2 loss : 0.024395
[11:23:54.488] iteration 13954 : model1 loss : 0.433992 model2 loss : 0.023404
[11:23:54.657] iteration 13955 : model1 loss : 0.437907 model2 loss : 0.028793
[11:23:54.825] iteration 13956 : model1 loss : 0.432651 model2 loss : 0.022994
[11:23:54.995] iteration 13957 : model1 loss : 0.434923 model2 loss : 0.023606
[11:23:55.160] iteration 13958 : model1 loss : 0.436161 model2 loss : 0.026673
[11:23:55.329] iteration 13959 : model1 loss : 0.436598 model2 loss : 0.027427
[11:23:57.292] iteration 13960 : model1 loss : 0.436967 model2 loss : 0.026202
[11:23:57.460] iteration 13961 : model1 loss : 0.437292 model2 loss : 0.025160
[11:23:57.630] iteration 13962 : model1 loss : 0.439868 model2 loss : 0.028913
[11:23:57.798] iteration 13963 : model1 loss : 0.434602 model2 loss : 0.022276
[11:23:57.967] iteration 13964 : model1 loss : 0.438073 model2 loss : 0.027573
[11:23:58.130] iteration 13965 : model1 loss : 0.438057 model2 loss : 0.025835
[11:23:58.302] iteration 13966 : model1 loss : 0.434690 model2 loss : 0.020959
[11:23:58.468] iteration 13967 : model1 loss : 0.436934 model2 loss : 0.027692
[11:23:58.638] iteration 13968 : model1 loss : 0.439340 model2 loss : 0.028859
[11:23:58.804] iteration 13969 : model1 loss : 0.435460 model2 loss : 0.024756
[11:23:58.974] iteration 13970 : model1 loss : 0.441329 model2 loss : 0.027615
[11:23:59.143] iteration 13971 : model1 loss : 0.436962 model2 loss : 0.022581
[11:23:59.311] iteration 13972 : model1 loss : 0.439112 model2 loss : 0.024773
[11:23:59.478] iteration 13973 : model1 loss : 0.432991 model2 loss : 0.023803
[11:23:59.648] iteration 13974 : model1 loss : 0.437154 model2 loss : 0.025635
[11:23:59.816] iteration 13975 : model1 loss : 0.438874 model2 loss : 0.026050
[11:23:59.986] iteration 13976 : model1 loss : 0.435903 model2 loss : 0.024209
[11:24:00.156] iteration 13977 : model1 loss : 0.438820 model2 loss : 0.028423
[11:24:00.325] iteration 13978 : model1 loss : 0.436134 model2 loss : 0.024569
[11:24:00.492] iteration 13979 : model1 loss : 0.434309 model2 loss : 0.024815
[11:24:00.662] iteration 13980 : model1 loss : 0.434937 model2 loss : 0.022720
[11:24:00.831] iteration 13981 : model1 loss : 0.441198 model2 loss : 0.029320
[11:24:01.001] iteration 13982 : model1 loss : 0.438369 model2 loss : 0.029042
[11:24:01.171] iteration 13983 : model1 loss : 0.438816 model2 loss : 0.035716
[11:24:01.343] iteration 13984 : model1 loss : 0.437200 model2 loss : 0.024268
[11:24:01.514] iteration 13985 : model1 loss : 0.436023 model2 loss : 0.026937
[11:24:01.684] iteration 13986 : model1 loss : 0.434733 model2 loss : 0.025380
[11:24:01.853] iteration 13987 : model1 loss : 0.442247 model2 loss : 0.031839
[11:24:02.024] iteration 13988 : model1 loss : 0.433472 model2 loss : 0.024976
[11:24:02.191] iteration 13989 : model1 loss : 0.438170 model2 loss : 0.021780
[11:24:02.360] iteration 13990 : model1 loss : 0.436543 model2 loss : 0.026376
[11:24:02.527] iteration 13991 : model1 loss : 0.432181 model2 loss : 0.024148
[11:24:02.695] iteration 13992 : model1 loss : 0.434296 model2 loss : 0.026607
[11:24:04.670] iteration 13993 : model1 loss : 0.435900 model2 loss : 0.023704
[11:24:04.837] iteration 13994 : model1 loss : 0.432624 model2 loss : 0.024211
[11:24:05.009] iteration 13995 : model1 loss : 0.437310 model2 loss : 0.028556
[11:24:05.176] iteration 13996 : model1 loss : 0.435215 model2 loss : 0.023359
[11:24:05.346] iteration 13997 : model1 loss : 0.440284 model2 loss : 0.026069
[11:24:05.516] iteration 13998 : model1 loss : 0.436860 model2 loss : 0.023931
[11:24:05.685] iteration 13999 : model1 loss : 0.435478 model2 loss : 0.024688
[11:24:05.854] iteration 14000 : model1 loss : 0.436458 model2 loss : 0.025550
[11:24:14.150] iteration 14000 : model1_mean_dice : 0.894632 model1_mean_hd95 : 3.750001
[11:24:22.460] iteration 14000 : model2_mean_dice : 0.892707 model2_mean_hd95 : 1.944001
[11:24:22.635] iteration 14001 : model1 loss : 0.436594 model2 loss : 0.026572
[11:24:22.802] iteration 14002 : model1 loss : 0.439454 model2 loss : 0.029431
[11:24:22.972] iteration 14003 : model1 loss : 0.437891 model2 loss : 0.025850
[11:24:23.143] iteration 14004 : model1 loss : 0.438031 model2 loss : 0.025496
[11:24:23.309] iteration 14005 : model1 loss : 0.437461 model2 loss : 0.024227
[11:24:23.476] iteration 14006 : model1 loss : 0.438140 model2 loss : 0.026401
[11:24:23.643] iteration 14007 : model1 loss : 0.435563 model2 loss : 0.027988
[11:24:23.819] iteration 14008 : model1 loss : 0.434751 model2 loss : 0.027148
[11:24:23.985] iteration 14009 : model1 loss : 0.433551 model2 loss : 0.022451
[11:24:24.155] iteration 14010 : model1 loss : 0.441089 model2 loss : 0.025159
[11:24:24.321] iteration 14011 : model1 loss : 0.440470 model2 loss : 0.027387
[11:24:24.490] iteration 14012 : model1 loss : 0.435308 model2 loss : 0.024909
[11:24:24.657] iteration 14013 : model1 loss : 0.438908 model2 loss : 0.027593
[11:24:24.826] iteration 14014 : model1 loss : 0.438070 model2 loss : 0.034780
[11:24:24.993] iteration 14015 : model1 loss : 0.437709 model2 loss : 0.023322
[11:24:25.160] iteration 14016 : model1 loss : 0.433675 model2 loss : 0.021266
[11:24:25.328] iteration 14017 : model1 loss : 0.440009 model2 loss : 0.028268
[11:24:25.497] iteration 14018 : model1 loss : 0.438433 model2 loss : 0.024477
[11:24:25.664] iteration 14019 : model1 loss : 0.435364 model2 loss : 0.026515
[11:24:25.832] iteration 14020 : model1 loss : 0.435443 model2 loss : 0.025088
[11:24:25.999] iteration 14021 : model1 loss : 0.441581 model2 loss : 0.030467
[11:24:26.168] iteration 14022 : model1 loss : 0.439442 model2 loss : 0.023526
[11:24:26.336] iteration 14023 : model1 loss : 0.438795 model2 loss : 0.024599
[11:24:26.504] iteration 14024 : model1 loss : 0.432208 model2 loss : 0.025485
[11:24:26.669] iteration 14025 : model1 loss : 0.439049 model2 loss : 0.027312
[11:24:28.684] iteration 14026 : model1 loss : 0.439544 model2 loss : 0.036376
[11:24:28.855] iteration 14027 : model1 loss : 0.437942 model2 loss : 0.026146
[11:24:29.027] iteration 14028 : model1 loss : 0.431027 model2 loss : 0.022621
[11:24:29.194] iteration 14029 : model1 loss : 0.436032 model2 loss : 0.025660
[11:24:29.362] iteration 14030 : model1 loss : 0.438891 model2 loss : 0.024413
[11:24:29.529] iteration 14031 : model1 loss : 0.438129 model2 loss : 0.028447
[11:24:29.698] iteration 14032 : model1 loss : 0.439040 model2 loss : 0.026582
[11:24:29.864] iteration 14033 : model1 loss : 0.436738 model2 loss : 0.024444
[11:24:30.032] iteration 14034 : model1 loss : 0.436294 model2 loss : 0.024279
[11:24:30.199] iteration 14035 : model1 loss : 0.434607 model2 loss : 0.024173
[11:24:30.367] iteration 14036 : model1 loss : 0.437336 model2 loss : 0.024313
[11:24:30.538] iteration 14037 : model1 loss : 0.433565 model2 loss : 0.022288
[11:24:30.707] iteration 14038 : model1 loss : 0.437823 model2 loss : 0.027355
[11:24:30.877] iteration 14039 : model1 loss : 0.441653 model2 loss : 0.027948
[11:24:31.043] iteration 14040 : model1 loss : 0.436466 model2 loss : 0.024686
[11:24:31.211] iteration 14041 : model1 loss : 0.436521 model2 loss : 0.025779
[11:24:31.378] iteration 14042 : model1 loss : 0.432344 model2 loss : 0.025968
[11:24:31.545] iteration 14043 : model1 loss : 0.434512 model2 loss : 0.023121
[11:24:31.715] iteration 14044 : model1 loss : 0.435943 model2 loss : 0.023671
[11:24:31.881] iteration 14045 : model1 loss : 0.438670 model2 loss : 0.027589
[11:24:32.049] iteration 14046 : model1 loss : 0.433840 model2 loss : 0.023851
[11:24:32.215] iteration 14047 : model1 loss : 0.437521 model2 loss : 0.025549
[11:24:32.385] iteration 14048 : model1 loss : 0.436408 model2 loss : 0.024149
[11:24:32.553] iteration 14049 : model1 loss : 0.433803 model2 loss : 0.024419
[11:24:32.723] iteration 14050 : model1 loss : 0.434954 model2 loss : 0.025763
[11:24:32.889] iteration 14051 : model1 loss : 0.438964 model2 loss : 0.026541
[11:24:33.057] iteration 14052 : model1 loss : 0.442388 model2 loss : 0.029558
[11:24:33.226] iteration 14053 : model1 loss : 0.443862 model2 loss : 0.029093
[11:24:33.394] iteration 14054 : model1 loss : 0.438796 model2 loss : 0.023180
[11:24:33.560] iteration 14055 : model1 loss : 0.437622 model2 loss : 0.027348
[11:24:33.730] iteration 14056 : model1 loss : 0.431716 model2 loss : 0.021926
[11:24:33.895] iteration 14057 : model1 loss : 0.441511 model2 loss : 0.027424
[11:24:34.063] iteration 14058 : model1 loss : 0.438096 model2 loss : 0.022832
[11:24:36.020] iteration 14059 : model1 loss : 0.438179 model2 loss : 0.026003
[11:24:36.188] iteration 14060 : model1 loss : 0.436282 model2 loss : 0.024103
[11:24:36.358] iteration 14061 : model1 loss : 0.438892 model2 loss : 0.026203
[11:24:36.529] iteration 14062 : model1 loss : 0.438537 model2 loss : 0.025183
[11:24:36.697] iteration 14063 : model1 loss : 0.438960 model2 loss : 0.025184
[11:24:36.866] iteration 14064 : model1 loss : 0.434091 model2 loss : 0.023779
[11:24:37.035] iteration 14065 : model1 loss : 0.437433 model2 loss : 0.023695
[11:24:37.202] iteration 14066 : model1 loss : 0.431472 model2 loss : 0.020894
[11:24:37.372] iteration 14067 : model1 loss : 0.432241 model2 loss : 0.023180
[11:24:37.539] iteration 14068 : model1 loss : 0.433777 model2 loss : 0.024880
[11:24:37.708] iteration 14069 : model1 loss : 0.437744 model2 loss : 0.026016
[11:24:37.876] iteration 14070 : model1 loss : 0.434457 model2 loss : 0.023886
[11:24:38.044] iteration 14071 : model1 loss : 0.437806 model2 loss : 0.027841
[11:24:38.212] iteration 14072 : model1 loss : 0.435687 model2 loss : 0.027120
[11:24:38.383] iteration 14073 : model1 loss : 0.433715 model2 loss : 0.023773
[11:24:38.551] iteration 14074 : model1 loss : 0.434918 model2 loss : 0.024203
[11:24:38.720] iteration 14075 : model1 loss : 0.433880 model2 loss : 0.023246
[11:24:38.886] iteration 14076 : model1 loss : 0.438152 model2 loss : 0.024152
[11:24:39.054] iteration 14077 : model1 loss : 0.441801 model2 loss : 0.026338
[11:24:39.221] iteration 14078 : model1 loss : 0.440968 model2 loss : 0.022325
[11:24:39.390] iteration 14079 : model1 loss : 0.436375 model2 loss : 0.025396
[11:24:39.557] iteration 14080 : model1 loss : 0.441943 model2 loss : 0.031044
[11:24:39.725] iteration 14081 : model1 loss : 0.438415 model2 loss : 0.027325
[11:24:39.893] iteration 14082 : model1 loss : 0.436583 model2 loss : 0.022335
[11:24:40.060] iteration 14083 : model1 loss : 0.434697 model2 loss : 0.023990
[11:24:40.228] iteration 14084 : model1 loss : 0.433230 model2 loss : 0.024874
[11:24:40.397] iteration 14085 : model1 loss : 0.435986 model2 loss : 0.024381
[11:24:40.566] iteration 14086 : model1 loss : 0.439653 model2 loss : 0.027452
[11:24:40.735] iteration 14087 : model1 loss : 0.439087 model2 loss : 0.027595
[11:24:40.905] iteration 14088 : model1 loss : 0.439246 model2 loss : 0.027851
[11:24:41.074] iteration 14089 : model1 loss : 0.435184 model2 loss : 0.023570
[11:24:41.242] iteration 14090 : model1 loss : 0.438521 model2 loss : 0.023483
[11:24:41.411] iteration 14091 : model1 loss : 0.439729 model2 loss : 0.027110
[11:24:43.374] iteration 14092 : model1 loss : 0.435760 model2 loss : 0.025819
[11:24:43.542] iteration 14093 : model1 loss : 0.438180 model2 loss : 0.027026
[11:24:43.714] iteration 14094 : model1 loss : 0.430785 model2 loss : 0.025276
[11:24:43.879] iteration 14095 : model1 loss : 0.433150 model2 loss : 0.024139
[11:24:44.050] iteration 14096 : model1 loss : 0.438287 model2 loss : 0.030211
[11:24:44.218] iteration 14097 : model1 loss : 0.438734 model2 loss : 0.026202
[11:24:44.386] iteration 14098 : model1 loss : 0.440424 model2 loss : 0.022415
[11:24:44.551] iteration 14099 : model1 loss : 0.439140 model2 loss : 0.028084
[11:24:44.720] iteration 14100 : model1 loss : 0.437977 model2 loss : 0.027081
[11:24:44.889] iteration 14101 : model1 loss : 0.438098 model2 loss : 0.023305
[11:24:45.057] iteration 14102 : model1 loss : 0.438991 model2 loss : 0.023909
[11:24:45.224] iteration 14103 : model1 loss : 0.436016 model2 loss : 0.023008
[11:24:45.391] iteration 14104 : model1 loss : 0.435507 model2 loss : 0.027176
[11:24:45.557] iteration 14105 : model1 loss : 0.438594 model2 loss : 0.025761
[11:24:45.725] iteration 14106 : model1 loss : 0.437452 model2 loss : 0.032654
[11:24:45.897] iteration 14107 : model1 loss : 0.436818 model2 loss : 0.023425
[11:24:46.069] iteration 14108 : model1 loss : 0.436875 model2 loss : 0.024635
[11:24:46.235] iteration 14109 : model1 loss : 0.438547 model2 loss : 0.025134
[11:24:46.403] iteration 14110 : model1 loss : 0.436563 model2 loss : 0.024067
[11:24:46.572] iteration 14111 : model1 loss : 0.440803 model2 loss : 0.027355
[11:24:46.740] iteration 14112 : model1 loss : 0.442617 model2 loss : 0.025732
[11:24:46.906] iteration 14113 : model1 loss : 0.433917 model2 loss : 0.023811
[11:24:47.093] iteration 14114 : model1 loss : 0.442177 model2 loss : 0.029255
[11:24:47.262] iteration 14115 : model1 loss : 0.441899 model2 loss : 0.030326
[11:24:47.431] iteration 14116 : model1 loss : 0.439037 model2 loss : 0.025487
[11:24:47.597] iteration 14117 : model1 loss : 0.434108 model2 loss : 0.024572
[11:24:47.766] iteration 14118 : model1 loss : 0.435687 model2 loss : 0.023785
[11:24:47.934] iteration 14119 : model1 loss : 0.434647 model2 loss : 0.023661
[11:24:48.100] iteration 14120 : model1 loss : 0.435289 model2 loss : 0.025670
[11:24:48.270] iteration 14121 : model1 loss : 0.440258 model2 loss : 0.024821
[11:24:48.438] iteration 14122 : model1 loss : 0.434754 model2 loss : 0.025861
[11:24:48.603] iteration 14123 : model1 loss : 0.438500 model2 loss : 0.026817
[11:24:48.770] iteration 14124 : model1 loss : 0.429739 model2 loss : 0.023249
[11:24:50.708] iteration 14125 : model1 loss : 0.433389 model2 loss : 0.026166
[11:24:50.876] iteration 14126 : model1 loss : 0.440662 model2 loss : 0.024650
[11:24:51.048] iteration 14127 : model1 loss : 0.437712 model2 loss : 0.026077
[11:24:51.215] iteration 14128 : model1 loss : 0.440164 model2 loss : 0.027621
[11:24:51.384] iteration 14129 : model1 loss : 0.433174 model2 loss : 0.022714
[11:24:51.565] iteration 14130 : model1 loss : 0.440454 model2 loss : 0.024122
[11:24:51.733] iteration 14131 : model1 loss : 0.441259 model2 loss : 0.030825
[11:24:51.899] iteration 14132 : model1 loss : 0.434529 model2 loss : 0.025214
[11:24:52.070] iteration 14133 : model1 loss : 0.436185 model2 loss : 0.022499
[11:24:52.234] iteration 14134 : model1 loss : 0.436501 model2 loss : 0.022571
[11:24:52.403] iteration 14135 : model1 loss : 0.435094 model2 loss : 0.022503
[11:24:52.572] iteration 14136 : model1 loss : 0.437701 model2 loss : 0.022818
[11:24:52.740] iteration 14137 : model1 loss : 0.444081 model2 loss : 0.032420
[11:24:52.908] iteration 14138 : model1 loss : 0.435460 model2 loss : 0.024422
[11:24:53.077] iteration 14139 : model1 loss : 0.436948 model2 loss : 0.023970
[11:24:53.245] iteration 14140 : model1 loss : 0.434731 model2 loss : 0.023744
[11:24:53.413] iteration 14141 : model1 loss : 0.433675 model2 loss : 0.028436
[11:24:53.580] iteration 14142 : model1 loss : 0.439422 model2 loss : 0.024655
[11:24:53.749] iteration 14143 : model1 loss : 0.438043 model2 loss : 0.022781
[11:24:53.916] iteration 14144 : model1 loss : 0.438389 model2 loss : 0.023205
[11:24:54.087] iteration 14145 : model1 loss : 0.438482 model2 loss : 0.025628
[11:24:54.253] iteration 14146 : model1 loss : 0.439218 model2 loss : 0.023315
[11:24:54.423] iteration 14147 : model1 loss : 0.432592 model2 loss : 0.024046
[11:24:54.594] iteration 14148 : model1 loss : 0.438391 model2 loss : 0.026409
[11:24:54.762] iteration 14149 : model1 loss : 0.439445 model2 loss : 0.027976
[11:24:54.929] iteration 14150 : model1 loss : 0.437295 model2 loss : 0.025121
[11:24:55.098] iteration 14151 : model1 loss : 0.436570 model2 loss : 0.022827
[11:24:55.266] iteration 14152 : model1 loss : 0.440536 model2 loss : 0.024789
[11:24:55.435] iteration 14153 : model1 loss : 0.433942 model2 loss : 0.023139
[11:24:55.602] iteration 14154 : model1 loss : 0.434693 model2 loss : 0.025648
[11:24:55.773] iteration 14155 : model1 loss : 0.439059 model2 loss : 0.025199
[11:24:55.938] iteration 14156 : model1 loss : 0.433714 model2 loss : 0.023537
[11:24:56.106] iteration 14157 : model1 loss : 0.436680 model2 loss : 0.020172
[11:24:58.084] iteration 14158 : model1 loss : 0.437533 model2 loss : 0.022922
[11:24:58.257] iteration 14159 : model1 loss : 0.435517 model2 loss : 0.025101
[11:24:58.428] iteration 14160 : model1 loss : 0.435658 model2 loss : 0.023485
[11:24:58.595] iteration 14161 : model1 loss : 0.434079 model2 loss : 0.019896
[11:24:58.765] iteration 14162 : model1 loss : 0.437178 model2 loss : 0.024851
[11:24:58.933] iteration 14163 : model1 loss : 0.437367 model2 loss : 0.024373
[11:24:59.103] iteration 14164 : model1 loss : 0.436850 model2 loss : 0.025365
[11:24:59.269] iteration 14165 : model1 loss : 0.437428 model2 loss : 0.026695
[11:24:59.437] iteration 14166 : model1 loss : 0.437705 model2 loss : 0.021852
[11:24:59.603] iteration 14167 : model1 loss : 0.436557 model2 loss : 0.023121
[11:24:59.772] iteration 14168 : model1 loss : 0.438143 model2 loss : 0.028405
[11:24:59.939] iteration 14169 : model1 loss : 0.429648 model2 loss : 0.023059
[11:25:00.111] iteration 14170 : model1 loss : 0.438330 model2 loss : 0.024301
[11:25:00.277] iteration 14171 : model1 loss : 0.435729 model2 loss : 0.023932
[11:25:00.445] iteration 14172 : model1 loss : 0.437345 model2 loss : 0.023961
[11:25:00.613] iteration 14173 : model1 loss : 0.436682 model2 loss : 0.023322
[11:25:00.783] iteration 14174 : model1 loss : 0.435512 model2 loss : 0.021736
[11:25:00.950] iteration 14175 : model1 loss : 0.437635 model2 loss : 0.023270
[11:25:01.121] iteration 14176 : model1 loss : 0.436497 model2 loss : 0.024510
[11:25:01.288] iteration 14177 : model1 loss : 0.439830 model2 loss : 0.027668
[11:25:01.457] iteration 14178 : model1 loss : 0.436392 model2 loss : 0.024577
[11:25:01.623] iteration 14179 : model1 loss : 0.436647 model2 loss : 0.022848
[11:25:01.791] iteration 14180 : model1 loss : 0.439269 model2 loss : 0.027377
[11:25:01.958] iteration 14181 : model1 loss : 0.435449 model2 loss : 0.023969
[11:25:02.126] iteration 14182 : model1 loss : 0.436721 model2 loss : 0.022714
[11:25:02.295] iteration 14183 : model1 loss : 0.441855 model2 loss : 0.023693
[11:25:02.464] iteration 14184 : model1 loss : 0.441652 model2 loss : 0.028322
[11:25:02.630] iteration 14185 : model1 loss : 0.441219 model2 loss : 0.023365
[11:25:02.800] iteration 14186 : model1 loss : 0.439140 model2 loss : 0.025451
[11:25:02.968] iteration 14187 : model1 loss : 0.440899 model2 loss : 0.025739
[11:25:03.138] iteration 14188 : model1 loss : 0.436541 model2 loss : 0.022930
[11:25:03.304] iteration 14189 : model1 loss : 0.432659 model2 loss : 0.023179
[11:25:03.474] iteration 14190 : model1 loss : 0.436129 model2 loss : 0.022988
[11:25:05.415] iteration 14191 : model1 loss : 0.435639 model2 loss : 0.024106
[11:25:05.582] iteration 14192 : model1 loss : 0.435461 model2 loss : 0.026115
[11:25:05.753] iteration 14193 : model1 loss : 0.433242 model2 loss : 0.022896
[11:25:05.923] iteration 14194 : model1 loss : 0.435530 model2 loss : 0.022049
[11:25:06.092] iteration 14195 : model1 loss : 0.439976 model2 loss : 0.024976
[11:25:06.260] iteration 14196 : model1 loss : 0.436825 model2 loss : 0.020582
[11:25:06.429] iteration 14197 : model1 loss : 0.440301 model2 loss : 0.021824
[11:25:06.599] iteration 14198 : model1 loss : 0.443145 model2 loss : 0.032897
[11:25:06.767] iteration 14199 : model1 loss : 0.439966 model2 loss : 0.021253
[11:25:06.935] iteration 14200 : model1 loss : 0.435343 model2 loss : 0.024996
[11:25:07.104] iteration 14201 : model1 loss : 0.438861 model2 loss : 0.024121
[11:25:07.271] iteration 14202 : model1 loss : 0.438896 model2 loss : 0.029740
[11:25:07.440] iteration 14203 : model1 loss : 0.437650 model2 loss : 0.027201
[11:25:07.606] iteration 14204 : model1 loss : 0.434084 model2 loss : 0.022636
[11:25:07.775] iteration 14205 : model1 loss : 0.432316 model2 loss : 0.025027
[11:25:07.943] iteration 14206 : model1 loss : 0.436578 model2 loss : 0.026303
[11:25:08.113] iteration 14207 : model1 loss : 0.435524 model2 loss : 0.022768
[11:25:08.278] iteration 14208 : model1 loss : 0.440112 model2 loss : 0.026598
[11:25:08.449] iteration 14209 : model1 loss : 0.439969 model2 loss : 0.026104
[11:25:08.615] iteration 14210 : model1 loss : 0.438140 model2 loss : 0.025104
[11:25:08.782] iteration 14211 : model1 loss : 0.434685 model2 loss : 0.023822
[11:25:08.949] iteration 14212 : model1 loss : 0.434944 model2 loss : 0.025178
[11:25:09.118] iteration 14213 : model1 loss : 0.436055 model2 loss : 0.022905
[11:25:09.287] iteration 14214 : model1 loss : 0.432853 model2 loss : 0.022363
[11:25:09.456] iteration 14215 : model1 loss : 0.440499 model2 loss : 0.026743
[11:25:09.624] iteration 14216 : model1 loss : 0.436122 model2 loss : 0.024199
[11:25:09.791] iteration 14217 : model1 loss : 0.439731 model2 loss : 0.023684
[11:25:09.959] iteration 14218 : model1 loss : 0.434082 model2 loss : 0.022242
[11:25:10.130] iteration 14219 : model1 loss : 0.435501 model2 loss : 0.023092
[11:25:10.297] iteration 14220 : model1 loss : 0.441603 model2 loss : 0.025719
[11:25:10.465] iteration 14221 : model1 loss : 0.436327 model2 loss : 0.023495
[11:25:10.630] iteration 14222 : model1 loss : 0.437230 model2 loss : 0.024540
[11:25:10.799] iteration 14223 : model1 loss : 0.440830 model2 loss : 0.028763
[11:25:12.735] iteration 14224 : model1 loss : 0.435445 model2 loss : 0.021686
[11:25:12.901] iteration 14225 : model1 loss : 0.442137 model2 loss : 0.032376
[11:25:13.070] iteration 14226 : model1 loss : 0.433605 model2 loss : 0.023424
[11:25:13.237] iteration 14227 : model1 loss : 0.434228 model2 loss : 0.022244
[11:25:13.408] iteration 14228 : model1 loss : 0.436581 model2 loss : 0.021982
[11:25:13.574] iteration 14229 : model1 loss : 0.436462 model2 loss : 0.020588
[11:25:13.745] iteration 14230 : model1 loss : 0.441574 model2 loss : 0.024501
[11:25:13.912] iteration 14231 : model1 loss : 0.438316 model2 loss : 0.026449
[11:25:14.082] iteration 14232 : model1 loss : 0.437381 model2 loss : 0.023609
[11:25:14.251] iteration 14233 : model1 loss : 0.436035 model2 loss : 0.024976
[11:25:14.420] iteration 14234 : model1 loss : 0.439869 model2 loss : 0.021523
[11:25:14.587] iteration 14235 : model1 loss : 0.437037 model2 loss : 0.021750
[11:25:14.755] iteration 14236 : model1 loss : 0.435400 model2 loss : 0.023602
[11:25:14.922] iteration 14237 : model1 loss : 0.432471 model2 loss : 0.022616
[11:25:15.092] iteration 14238 : model1 loss : 0.439496 model2 loss : 0.023894
[11:25:15.258] iteration 14239 : model1 loss : 0.438237 model2 loss : 0.024905
[11:25:15.428] iteration 14240 : model1 loss : 0.436895 model2 loss : 0.023209
[11:25:15.594] iteration 14241 : model1 loss : 0.435968 model2 loss : 0.024959
[11:25:15.765] iteration 14242 : model1 loss : 0.436422 model2 loss : 0.024642
[11:25:15.933] iteration 14243 : model1 loss : 0.436699 model2 loss : 0.026796
[11:25:16.101] iteration 14244 : model1 loss : 0.437766 model2 loss : 0.025341
[11:25:16.268] iteration 14245 : model1 loss : 0.432798 model2 loss : 0.028105
[11:25:16.437] iteration 14246 : model1 loss : 0.437470 model2 loss : 0.027699
[11:25:16.604] iteration 14247 : model1 loss : 0.429730 model2 loss : 0.022092
[11:25:16.772] iteration 14248 : model1 loss : 0.437113 model2 loss : 0.024942
[11:25:16.938] iteration 14249 : model1 loss : 0.443965 model2 loss : 0.028706
[11:25:17.109] iteration 14250 : model1 loss : 0.439731 model2 loss : 0.027796
[11:25:17.276] iteration 14251 : model1 loss : 0.436006 model2 loss : 0.024015
[11:25:17.445] iteration 14252 : model1 loss : 0.435806 model2 loss : 0.022629
[11:25:17.614] iteration 14253 : model1 loss : 0.439389 model2 loss : 0.027853
[11:25:17.782] iteration 14254 : model1 loss : 0.441397 model2 loss : 0.026205
[11:25:17.947] iteration 14255 : model1 loss : 0.433080 model2 loss : 0.024335
[11:25:18.117] iteration 14256 : model1 loss : 0.438311 model2 loss : 0.024803
[11:25:20.118] iteration 14257 : model1 loss : 0.434384 model2 loss : 0.023393
[11:25:20.285] iteration 14258 : model1 loss : 0.436187 model2 loss : 0.024049
[11:25:20.455] iteration 14259 : model1 loss : 0.437273 model2 loss : 0.024727
[11:25:20.622] iteration 14260 : model1 loss : 0.434311 model2 loss : 0.021875
[11:25:20.792] iteration 14261 : model1 loss : 0.435191 model2 loss : 0.023512
[11:25:20.959] iteration 14262 : model1 loss : 0.437437 model2 loss : 0.019248
[11:25:21.130] iteration 14263 : model1 loss : 0.435974 model2 loss : 0.023302
[11:25:21.296] iteration 14264 : model1 loss : 0.439819 model2 loss : 0.026163
[11:25:21.466] iteration 14265 : model1 loss : 0.439656 model2 loss : 0.024905
[11:25:21.634] iteration 14266 : model1 loss : 0.437453 model2 loss : 0.027680
[11:25:21.803] iteration 14267 : model1 loss : 0.436014 model2 loss : 0.025696
[11:25:21.970] iteration 14268 : model1 loss : 0.434470 model2 loss : 0.025004
[11:25:22.138] iteration 14269 : model1 loss : 0.433514 model2 loss : 0.021358
[11:25:22.305] iteration 14270 : model1 loss : 0.434731 model2 loss : 0.024413
[11:25:22.474] iteration 14271 : model1 loss : 0.439261 model2 loss : 0.026216
[11:25:22.640] iteration 14272 : model1 loss : 0.436504 model2 loss : 0.023156
[11:25:22.810] iteration 14273 : model1 loss : 0.439287 model2 loss : 0.025343
[11:25:22.976] iteration 14274 : model1 loss : 0.434168 model2 loss : 0.023737
[11:25:23.146] iteration 14275 : model1 loss : 0.437388 model2 loss : 0.022774
[11:25:23.313] iteration 14276 : model1 loss : 0.433081 model2 loss : 0.024529
[11:25:23.483] iteration 14277 : model1 loss : 0.444009 model2 loss : 0.027620
[11:25:23.652] iteration 14278 : model1 loss : 0.434648 model2 loss : 0.019806
[11:25:23.822] iteration 14279 : model1 loss : 0.442005 model2 loss : 0.027701
[11:25:23.991] iteration 14280 : model1 loss : 0.438189 model2 loss : 0.027165
[11:25:24.160] iteration 14281 : model1 loss : 0.442042 model2 loss : 0.029264
[11:25:24.327] iteration 14282 : model1 loss : 0.436956 model2 loss : 0.027223
[11:25:24.508] iteration 14283 : model1 loss : 0.434345 model2 loss : 0.023070
[11:25:24.676] iteration 14284 : model1 loss : 0.438671 model2 loss : 0.024564
[11:25:24.844] iteration 14285 : model1 loss : 0.436965 model2 loss : 0.024502
[11:25:25.010] iteration 14286 : model1 loss : 0.438387 model2 loss : 0.024073
[11:25:25.179] iteration 14287 : model1 loss : 0.437464 model2 loss : 0.025034
[11:25:25.346] iteration 14288 : model1 loss : 0.439374 model2 loss : 0.025192
[11:25:25.516] iteration 14289 : model1 loss : 0.438595 model2 loss : 0.027008
[11:25:27.496] iteration 14290 : model1 loss : 0.437506 model2 loss : 0.024279
[11:25:27.667] iteration 14291 : model1 loss : 0.436512 model2 loss : 0.024312
[11:25:27.836] iteration 14292 : model1 loss : 0.435053 model2 loss : 0.023509
[11:25:28.002] iteration 14293 : model1 loss : 0.440805 model2 loss : 0.028382
[11:25:28.172] iteration 14294 : model1 loss : 0.436107 model2 loss : 0.025815
[11:25:28.338] iteration 14295 : model1 loss : 0.438419 model2 loss : 0.024741
[11:25:28.512] iteration 14296 : model1 loss : 0.435540 model2 loss : 0.021828
[11:25:28.682] iteration 14297 : model1 loss : 0.435886 model2 loss : 0.026103
[11:25:28.849] iteration 14298 : model1 loss : 0.434815 model2 loss : 0.023340
[11:25:29.016] iteration 14299 : model1 loss : 0.433500 model2 loss : 0.024395
[11:25:29.186] iteration 14300 : model1 loss : 0.435006 model2 loss : 0.023019
[11:25:29.353] iteration 14301 : model1 loss : 0.443436 model2 loss : 0.031900
[11:25:29.526] iteration 14302 : model1 loss : 0.435347 model2 loss : 0.026251
[11:25:29.693] iteration 14303 : model1 loss : 0.438044 model2 loss : 0.026823
[11:25:29.863] iteration 14304 : model1 loss : 0.440744 model2 loss : 0.023932
[11:25:30.030] iteration 14305 : model1 loss : 0.438068 model2 loss : 0.023650
[11:25:30.198] iteration 14306 : model1 loss : 0.440411 model2 loss : 0.024120
[11:25:30.367] iteration 14307 : model1 loss : 0.436494 model2 loss : 0.023950
[11:25:30.542] iteration 14308 : model1 loss : 0.443686 model2 loss : 0.027126
[11:25:30.710] iteration 14309 : model1 loss : 0.435665 model2 loss : 0.024037
[11:25:30.880] iteration 14310 : model1 loss : 0.438616 model2 loss : 0.023093
[11:25:31.048] iteration 14311 : model1 loss : 0.437755 model2 loss : 0.024031
[11:25:31.216] iteration 14312 : model1 loss : 0.439508 model2 loss : 0.022506
[11:25:31.384] iteration 14313 : model1 loss : 0.438856 model2 loss : 0.023855
[11:25:31.552] iteration 14314 : model1 loss : 0.437763 model2 loss : 0.022220
[11:25:31.720] iteration 14315 : model1 loss : 0.437927 model2 loss : 0.025030
[11:25:31.891] iteration 14316 : model1 loss : 0.442500 model2 loss : 0.029214
[11:25:32.057] iteration 14317 : model1 loss : 0.440583 model2 loss : 0.025795
[11:25:32.227] iteration 14318 : model1 loss : 0.435044 model2 loss : 0.023194
[11:25:32.394] iteration 14319 : model1 loss : 0.436553 model2 loss : 0.024529
[11:25:32.566] iteration 14320 : model1 loss : 0.434031 model2 loss : 0.021400
[11:25:32.732] iteration 14321 : model1 loss : 0.434031 model2 loss : 0.022046
[11:25:32.901] iteration 14322 : model1 loss : 0.433578 model2 loss : 0.024323
[11:25:34.856] iteration 14323 : model1 loss : 0.440231 model2 loss : 0.025094
[11:25:35.024] iteration 14324 : model1 loss : 0.436789 model2 loss : 0.025138
[11:25:35.201] iteration 14325 : model1 loss : 0.435200 model2 loss : 0.023150
[11:25:35.367] iteration 14326 : model1 loss : 0.435254 model2 loss : 0.023019
[11:25:35.535] iteration 14327 : model1 loss : 0.436127 model2 loss : 0.022463
[11:25:35.702] iteration 14328 : model1 loss : 0.439472 model2 loss : 0.024843
[11:25:35.874] iteration 14329 : model1 loss : 0.440733 model2 loss : 0.027088
[11:25:36.042] iteration 14330 : model1 loss : 0.437368 model2 loss : 0.023135
[11:25:36.211] iteration 14331 : model1 loss : 0.433577 model2 loss : 0.022552
[11:25:36.378] iteration 14332 : model1 loss : 0.435565 model2 loss : 0.020511
[11:25:36.547] iteration 14333 : model1 loss : 0.435766 model2 loss : 0.025979
[11:25:36.713] iteration 14334 : model1 loss : 0.435596 model2 loss : 0.022761
[11:25:36.881] iteration 14335 : model1 loss : 0.444203 model2 loss : 0.030679
[11:25:37.047] iteration 14336 : model1 loss : 0.435347 model2 loss : 0.024810
[11:25:37.217] iteration 14337 : model1 loss : 0.437966 model2 loss : 0.023170
[11:25:37.384] iteration 14338 : model1 loss : 0.436013 model2 loss : 0.023688
[11:25:37.552] iteration 14339 : model1 loss : 0.439541 model2 loss : 0.022483
[11:25:37.720] iteration 14340 : model1 loss : 0.441686 model2 loss : 0.025341
[11:25:37.889] iteration 14341 : model1 loss : 0.433133 model2 loss : 0.022713
[11:25:38.057] iteration 14342 : model1 loss : 0.434166 model2 loss : 0.024030
[11:25:38.227] iteration 14343 : model1 loss : 0.434159 model2 loss : 0.022509
[11:25:38.393] iteration 14344 : model1 loss : 0.436052 model2 loss : 0.021946
[11:25:38.565] iteration 14345 : model1 loss : 0.437054 model2 loss : 0.022751
[11:25:38.731] iteration 14346 : model1 loss : 0.440583 model2 loss : 0.022069
[11:25:38.902] iteration 14347 : model1 loss : 0.430038 model2 loss : 0.022106
[11:25:39.069] iteration 14348 : model1 loss : 0.440147 model2 loss : 0.022732
[11:25:39.239] iteration 14349 : model1 loss : 0.432851 model2 loss : 0.023443
[11:25:39.404] iteration 14350 : model1 loss : 0.435311 model2 loss : 0.023147
[11:25:39.574] iteration 14351 : model1 loss : 0.442311 model2 loss : 0.029343
[11:25:39.742] iteration 14352 : model1 loss : 0.432920 model2 loss : 0.024280
[11:25:39.910] iteration 14353 : model1 loss : 0.441632 model2 loss : 0.026687
[11:25:40.078] iteration 14354 : model1 loss : 0.440366 model2 loss : 0.028509
[11:25:40.245] iteration 14355 : model1 loss : 0.438207 model2 loss : 0.023910
[11:25:42.197] iteration 14356 : model1 loss : 0.436950 model2 loss : 0.024575
[11:25:42.368] iteration 14357 : model1 loss : 0.434879 model2 loss : 0.023822
[11:25:42.541] iteration 14358 : model1 loss : 0.441323 model2 loss : 0.030646
[11:25:42.706] iteration 14359 : model1 loss : 0.433013 model2 loss : 0.023436
[11:25:42.876] iteration 14360 : model1 loss : 0.438704 model2 loss : 0.027963
[11:25:43.041] iteration 14361 : model1 loss : 0.434426 model2 loss : 0.022219
[11:25:43.211] iteration 14362 : model1 loss : 0.432993 model2 loss : 0.023678
[11:25:43.377] iteration 14363 : model1 loss : 0.442926 model2 loss : 0.030506
[11:25:43.546] iteration 14364 : model1 loss : 0.435492 model2 loss : 0.023515
[11:25:43.714] iteration 14365 : model1 loss : 0.440186 model2 loss : 0.022909
[11:25:43.882] iteration 14366 : model1 loss : 0.435858 model2 loss : 0.022381
[11:25:44.050] iteration 14367 : model1 loss : 0.438435 model2 loss : 0.028661
[11:25:44.218] iteration 14368 : model1 loss : 0.442159 model2 loss : 0.029767
[11:25:44.385] iteration 14369 : model1 loss : 0.437860 model2 loss : 0.026514
[11:25:44.553] iteration 14370 : model1 loss : 0.439327 model2 loss : 0.021108
[11:25:44.722] iteration 14371 : model1 loss : 0.439893 model2 loss : 0.022440
[11:25:44.899] iteration 14372 : model1 loss : 0.433673 model2 loss : 0.021249
[11:25:45.065] iteration 14373 : model1 loss : 0.433030 model2 loss : 0.022631
[11:25:45.235] iteration 14374 : model1 loss : 0.437569 model2 loss : 0.025479
[11:25:45.401] iteration 14375 : model1 loss : 0.439952 model2 loss : 0.027631
[11:25:45.570] iteration 14376 : model1 loss : 0.433927 model2 loss : 0.023203
[11:25:45.739] iteration 14377 : model1 loss : 0.436651 model2 loss : 0.023075
[11:25:45.914] iteration 14378 : model1 loss : 0.439005 model2 loss : 0.029103
[11:25:46.079] iteration 14379 : model1 loss : 0.436253 model2 loss : 0.024025
[11:25:46.248] iteration 14380 : model1 loss : 0.440236 model2 loss : 0.024783
[11:25:46.415] iteration 14381 : model1 loss : 0.434335 model2 loss : 0.023219
[11:25:46.584] iteration 14382 : model1 loss : 0.440420 model2 loss : 0.025299
[11:25:46.752] iteration 14383 : model1 loss : 0.438070 model2 loss : 0.021701
[11:25:46.922] iteration 14384 : model1 loss : 0.433862 model2 loss : 0.023252
[11:25:47.090] iteration 14385 : model1 loss : 0.434449 model2 loss : 0.024063
[11:25:47.259] iteration 14386 : model1 loss : 0.435202 model2 loss : 0.022158
[11:25:47.426] iteration 14387 : model1 loss : 0.437957 model2 loss : 0.025143
[11:25:47.593] iteration 14388 : model1 loss : 0.433927 model2 loss : 0.024250
[11:25:49.524] iteration 14389 : model1 loss : 0.432971 model2 loss : 0.025418
[11:25:49.693] iteration 14390 : model1 loss : 0.433881 model2 loss : 0.022700
[11:25:49.864] iteration 14391 : model1 loss : 0.441551 model2 loss : 0.025226
[11:25:50.031] iteration 14392 : model1 loss : 0.437396 model2 loss : 0.024293
[11:25:50.201] iteration 14393 : model1 loss : 0.432277 model2 loss : 0.020604
[11:25:50.368] iteration 14394 : model1 loss : 0.436094 model2 loss : 0.022803
[11:25:50.539] iteration 14395 : model1 loss : 0.431848 model2 loss : 0.023554
[11:25:50.705] iteration 14396 : model1 loss : 0.433414 model2 loss : 0.021654
[11:25:50.875] iteration 14397 : model1 loss : 0.433801 model2 loss : 0.022330
[11:25:51.043] iteration 14398 : model1 loss : 0.437055 model2 loss : 0.022475
[11:25:51.212] iteration 14399 : model1 loss : 0.439098 model2 loss : 0.024618
[11:25:51.380] iteration 14400 : model1 loss : 0.433897 model2 loss : 0.023288
[11:25:51.553] iteration 14401 : model1 loss : 0.438764 model2 loss : 0.025463
[11:25:51.725] iteration 14402 : model1 loss : 0.439974 model2 loss : 0.025646
[11:25:51.895] iteration 14403 : model1 loss : 0.438017 model2 loss : 0.025605
[11:25:52.064] iteration 14404 : model1 loss : 0.437310 model2 loss : 0.021752
[11:25:52.234] iteration 14405 : model1 loss : 0.439592 model2 loss : 0.031881
[11:25:52.402] iteration 14406 : model1 loss : 0.439808 model2 loss : 0.025830
[11:25:52.570] iteration 14407 : model1 loss : 0.439890 model2 loss : 0.024179
[11:25:52.737] iteration 14408 : model1 loss : 0.436292 model2 loss : 0.024147
[11:25:52.907] iteration 14409 : model1 loss : 0.441412 model2 loss : 0.028146
[11:25:53.074] iteration 14410 : model1 loss : 0.439129 model2 loss : 0.033109
[11:25:53.242] iteration 14411 : model1 loss : 0.436405 model2 loss : 0.023621
[11:25:53.408] iteration 14412 : model1 loss : 0.433354 model2 loss : 0.023292
[11:25:53.577] iteration 14413 : model1 loss : 0.438624 model2 loss : 0.027520
[11:25:53.756] iteration 14414 : model1 loss : 0.440114 model2 loss : 0.025653
[11:25:53.925] iteration 14415 : model1 loss : 0.435879 model2 loss : 0.025028
[11:25:54.095] iteration 14416 : model1 loss : 0.442430 model2 loss : 0.022929
[11:25:54.264] iteration 14417 : model1 loss : 0.439312 model2 loss : 0.029765
[11:25:54.431] iteration 14418 : model1 loss : 0.437490 model2 loss : 0.022257
[11:25:54.601] iteration 14419 : model1 loss : 0.436564 model2 loss : 0.027772
[11:25:54.765] iteration 14420 : model1 loss : 0.433588 model2 loss : 0.021730
[11:25:54.932] iteration 14421 : model1 loss : 0.436361 model2 loss : 0.023317
[11:25:56.899] iteration 14422 : model1 loss : 0.431306 model2 loss : 0.023330
[11:25:57.066] iteration 14423 : model1 loss : 0.438125 model2 loss : 0.023438
[11:25:57.237] iteration 14424 : model1 loss : 0.440593 model2 loss : 0.024447
[11:25:57.403] iteration 14425 : model1 loss : 0.437672 model2 loss : 0.024603
[11:25:57.571] iteration 14426 : model1 loss : 0.434895 model2 loss : 0.021853
[11:25:57.737] iteration 14427 : model1 loss : 0.435107 model2 loss : 0.024504
[11:25:57.908] iteration 14428 : model1 loss : 0.439441 model2 loss : 0.023190
[11:25:58.076] iteration 14429 : model1 loss : 0.442037 model2 loss : 0.026049
[11:25:58.246] iteration 14430 : model1 loss : 0.440269 model2 loss : 0.023475
[11:25:58.413] iteration 14431 : model1 loss : 0.435695 model2 loss : 0.022376
[11:25:58.581] iteration 14432 : model1 loss : 0.431508 model2 loss : 0.023357
[11:25:58.747] iteration 14433 : model1 loss : 0.439144 model2 loss : 0.025805
[11:25:58.914] iteration 14434 : model1 loss : 0.435557 model2 loss : 0.024189
[11:25:59.082] iteration 14435 : model1 loss : 0.436796 model2 loss : 0.025819
[11:25:59.250] iteration 14436 : model1 loss : 0.437274 model2 loss : 0.022156
[11:25:59.417] iteration 14437 : model1 loss : 0.439364 model2 loss : 0.025576
[11:25:59.586] iteration 14438 : model1 loss : 0.439066 model2 loss : 0.028367
[11:25:59.755] iteration 14439 : model1 loss : 0.440087 model2 loss : 0.031987
[11:25:59.923] iteration 14440 : model1 loss : 0.436176 model2 loss : 0.026351
[11:26:00.090] iteration 14441 : model1 loss : 0.433823 model2 loss : 0.021269
[11:26:00.262] iteration 14442 : model1 loss : 0.435926 model2 loss : 0.023566
[11:26:00.429] iteration 14443 : model1 loss : 0.434811 model2 loss : 0.020909
[11:26:00.599] iteration 14444 : model1 loss : 0.434972 model2 loss : 0.023299
[11:26:00.768] iteration 14445 : model1 loss : 0.435393 model2 loss : 0.024383
[11:26:00.938] iteration 14446 : model1 loss : 0.437081 model2 loss : 0.023480
[11:26:01.106] iteration 14447 : model1 loss : 0.441443 model2 loss : 0.028993
[11:26:01.276] iteration 14448 : model1 loss : 0.434359 model2 loss : 0.025069
[11:26:01.444] iteration 14449 : model1 loss : 0.439334 model2 loss : 0.023342
[11:26:01.614] iteration 14450 : model1 loss : 0.432776 model2 loss : 0.023073
[11:26:01.781] iteration 14451 : model1 loss : 0.438539 model2 loss : 0.024539
[11:26:01.949] iteration 14452 : model1 loss : 0.433854 model2 loss : 0.024329
[11:26:02.115] iteration 14453 : model1 loss : 0.436754 model2 loss : 0.028092
[11:26:02.283] iteration 14454 : model1 loss : 0.439581 model2 loss : 0.028904
[11:26:04.231] iteration 14455 : model1 loss : 0.433761 model2 loss : 0.021557
[11:26:04.404] iteration 14456 : model1 loss : 0.440677 model2 loss : 0.027615
[11:26:04.575] iteration 14457 : model1 loss : 0.440633 model2 loss : 0.027168
[11:26:04.745] iteration 14458 : model1 loss : 0.437146 model2 loss : 0.024734
[11:26:04.914] iteration 14459 : model1 loss : 0.440322 model2 loss : 0.026040
[11:26:05.082] iteration 14460 : model1 loss : 0.437165 model2 loss : 0.023920
[11:26:05.252] iteration 14461 : model1 loss : 0.433349 model2 loss : 0.022023
[11:26:05.420] iteration 14462 : model1 loss : 0.438500 model2 loss : 0.025887
[11:26:05.590] iteration 14463 : model1 loss : 0.437870 model2 loss : 0.024342
[11:26:05.758] iteration 14464 : model1 loss : 0.439539 model2 loss : 0.024948
[11:26:05.929] iteration 14465 : model1 loss : 0.431502 model2 loss : 0.022419
[11:26:06.098] iteration 14466 : model1 loss : 0.435580 model2 loss : 0.023614
[11:26:06.267] iteration 14467 : model1 loss : 0.439369 model2 loss : 0.026742
[11:26:06.436] iteration 14468 : model1 loss : 0.433706 model2 loss : 0.021835
[11:26:06.603] iteration 14469 : model1 loss : 0.436124 model2 loss : 0.023251
[11:26:06.769] iteration 14470 : model1 loss : 0.443900 model2 loss : 0.028274
[11:26:06.938] iteration 14471 : model1 loss : 0.437175 model2 loss : 0.025118
[11:26:07.106] iteration 14472 : model1 loss : 0.438614 model2 loss : 0.025387
[11:26:07.276] iteration 14473 : model1 loss : 0.436249 model2 loss : 0.024536
[11:26:07.444] iteration 14474 : model1 loss : 0.439397 model2 loss : 0.022383
[11:26:07.614] iteration 14475 : model1 loss : 0.437556 model2 loss : 0.022657
[11:26:07.781] iteration 14476 : model1 loss : 0.437309 model2 loss : 0.026424
[11:26:07.950] iteration 14477 : model1 loss : 0.436482 model2 loss : 0.023293
[11:26:08.116] iteration 14478 : model1 loss : 0.430612 model2 loss : 0.023224
[11:26:08.284] iteration 14479 : model1 loss : 0.437477 model2 loss : 0.023621
[11:26:08.451] iteration 14480 : model1 loss : 0.437841 model2 loss : 0.026715
[11:26:08.622] iteration 14481 : model1 loss : 0.435123 model2 loss : 0.024289
[11:26:08.790] iteration 14482 : model1 loss : 0.436257 model2 loss : 0.027196
[11:26:08.959] iteration 14483 : model1 loss : 0.437923 model2 loss : 0.023719
[11:26:09.127] iteration 14484 : model1 loss : 0.435008 model2 loss : 0.024550
[11:26:09.295] iteration 14485 : model1 loss : 0.438068 model2 loss : 0.027034
[11:26:09.460] iteration 14486 : model1 loss : 0.438248 model2 loss : 0.026760
[11:26:09.627] iteration 14487 : model1 loss : 0.438048 model2 loss : 0.026002
[11:26:11.584] iteration 14488 : model1 loss : 0.440552 model2 loss : 0.027121
[11:26:11.751] iteration 14489 : model1 loss : 0.440914 model2 loss : 0.029472
[11:26:11.922] iteration 14490 : model1 loss : 0.434495 model2 loss : 0.030997
[11:26:12.089] iteration 14491 : model1 loss : 0.433663 model2 loss : 0.024079
[11:26:12.259] iteration 14492 : model1 loss : 0.438849 model2 loss : 0.026648
[11:26:12.429] iteration 14493 : model1 loss : 0.437069 model2 loss : 0.022852
[11:26:12.600] iteration 14494 : model1 loss : 0.432577 model2 loss : 0.022006
[11:26:12.769] iteration 14495 : model1 loss : 0.438929 model2 loss : 0.027091
[11:26:12.938] iteration 14496 : model1 loss : 0.437985 model2 loss : 0.026691
[11:26:13.104] iteration 14497 : model1 loss : 0.432010 model2 loss : 0.021924
[11:26:13.275] iteration 14498 : model1 loss : 0.438032 model2 loss : 0.022796
[11:26:13.443] iteration 14499 : model1 loss : 0.442321 model2 loss : 0.033203
[11:26:13.610] iteration 14500 : model1 loss : 0.435174 model2 loss : 0.024806
[11:26:13.777] iteration 14501 : model1 loss : 0.436351 model2 loss : 0.021946
[11:26:13.947] iteration 14502 : model1 loss : 0.437293 model2 loss : 0.024536
[11:26:14.114] iteration 14503 : model1 loss : 0.435436 model2 loss : 0.023062
[11:26:14.282] iteration 14504 : model1 loss : 0.436084 model2 loss : 0.022753
[11:26:14.451] iteration 14505 : model1 loss : 0.436348 model2 loss : 0.024740
[11:26:14.619] iteration 14506 : model1 loss : 0.435894 model2 loss : 0.026023
[11:26:14.785] iteration 14507 : model1 loss : 0.436752 model2 loss : 0.023770
[11:26:14.955] iteration 14508 : model1 loss : 0.436321 model2 loss : 0.023403
[11:26:15.121] iteration 14509 : model1 loss : 0.441984 model2 loss : 0.028305
[11:26:15.290] iteration 14510 : model1 loss : 0.434092 model2 loss : 0.024880
[11:26:15.458] iteration 14511 : model1 loss : 0.438031 model2 loss : 0.027694
[11:26:15.627] iteration 14512 : model1 loss : 0.439787 model2 loss : 0.024475
[11:26:15.795] iteration 14513 : model1 loss : 0.437624 model2 loss : 0.020243
[11:26:15.965] iteration 14514 : model1 loss : 0.437527 model2 loss : 0.024988
[11:26:16.131] iteration 14515 : model1 loss : 0.433839 model2 loss : 0.023133
[11:26:16.302] iteration 14516 : model1 loss : 0.434420 model2 loss : 0.023327
[11:26:16.468] iteration 14517 : model1 loss : 0.435318 model2 loss : 0.025352
[11:26:16.639] iteration 14518 : model1 loss : 0.442100 model2 loss : 0.027716
[11:26:16.805] iteration 14519 : model1 loss : 0.440838 model2 loss : 0.031179
[11:26:16.974] iteration 14520 : model1 loss : 0.436077 model2 loss : 0.022272
[11:26:18.901] iteration 14521 : model1 loss : 0.437062 model2 loss : 0.023312
[11:26:19.070] iteration 14522 : model1 loss : 0.436592 model2 loss : 0.021788
[11:26:19.239] iteration 14523 : model1 loss : 0.436497 model2 loss : 0.023579
[11:26:19.406] iteration 14524 : model1 loss : 0.432328 model2 loss : 0.024846
[11:26:19.578] iteration 14525 : model1 loss : 0.436012 model2 loss : 0.027039
[11:26:19.745] iteration 14526 : model1 loss : 0.432322 model2 loss : 0.022052
[11:26:19.916] iteration 14527 : model1 loss : 0.436609 model2 loss : 0.021038
[11:26:20.085] iteration 14528 : model1 loss : 0.434464 model2 loss : 0.025228
[11:26:20.255] iteration 14529 : model1 loss : 0.436591 model2 loss : 0.025285
[11:26:20.422] iteration 14530 : model1 loss : 0.439970 model2 loss : 0.025582
[11:26:20.591] iteration 14531 : model1 loss : 0.435619 model2 loss : 0.019916
[11:26:20.759] iteration 14532 : model1 loss : 0.434960 model2 loss : 0.023000
[11:26:20.929] iteration 14533 : model1 loss : 0.435931 model2 loss : 0.021987
[11:26:21.096] iteration 14534 : model1 loss : 0.438542 model2 loss : 0.026179
[11:26:21.266] iteration 14535 : model1 loss : 0.440745 model2 loss : 0.028953
[11:26:21.433] iteration 14536 : model1 loss : 0.440768 model2 loss : 0.025871
[11:26:21.602] iteration 14537 : model1 loss : 0.438178 model2 loss : 0.026634
[11:26:21.771] iteration 14538 : model1 loss : 0.439118 model2 loss : 0.025026
[11:26:21.961] iteration 14539 : model1 loss : 0.439437 model2 loss : 0.022944
[11:26:22.129] iteration 14540 : model1 loss : 0.435966 model2 loss : 0.026746
[11:26:22.300] iteration 14541 : model1 loss : 0.434159 model2 loss : 0.022418
[11:26:22.467] iteration 14542 : model1 loss : 0.436884 model2 loss : 0.022344
[11:26:22.637] iteration 14543 : model1 loss : 0.438163 model2 loss : 0.024511
[11:26:22.805] iteration 14544 : model1 loss : 0.435479 model2 loss : 0.023719
[11:26:22.975] iteration 14545 : model1 loss : 0.437870 model2 loss : 0.022000
[11:26:23.141] iteration 14546 : model1 loss : 0.437451 model2 loss : 0.026443
[11:26:23.309] iteration 14547 : model1 loss : 0.437814 model2 loss : 0.024784
[11:26:23.475] iteration 14548 : model1 loss : 0.435197 model2 loss : 0.023336
[11:26:23.643] iteration 14549 : model1 loss : 0.438603 model2 loss : 0.024606
[11:26:23.811] iteration 14550 : model1 loss : 0.438734 model2 loss : 0.024187
[11:26:23.981] iteration 14551 : model1 loss : 0.435404 model2 loss : 0.023738
[11:26:24.148] iteration 14552 : model1 loss : 0.441959 model2 loss : 0.026144
[11:26:24.316] iteration 14553 : model1 loss : 0.437650 model2 loss : 0.025062
[11:26:26.311] iteration 14554 : model1 loss : 0.430899 model2 loss : 0.022013
[11:26:26.478] iteration 14555 : model1 loss : 0.437331 model2 loss : 0.022151
[11:26:26.648] iteration 14556 : model1 loss : 0.436829 model2 loss : 0.025934
[11:26:26.819] iteration 14557 : model1 loss : 0.435895 model2 loss : 0.022747
[11:26:26.987] iteration 14558 : model1 loss : 0.435970 model2 loss : 0.023199
[11:26:27.155] iteration 14559 : model1 loss : 0.435429 model2 loss : 0.021368
[11:26:27.324] iteration 14560 : model1 loss : 0.437677 model2 loss : 0.025869
[11:26:27.490] iteration 14561 : model1 loss : 0.432535 model2 loss : 0.021399
[11:26:27.660] iteration 14562 : model1 loss : 0.440897 model2 loss : 0.025931
[11:26:27.828] iteration 14563 : model1 loss : 0.439278 model2 loss : 0.025257
[11:26:27.997] iteration 14564 : model1 loss : 0.435829 model2 loss : 0.024093
[11:26:28.165] iteration 14565 : model1 loss : 0.432825 model2 loss : 0.023799
[11:26:28.331] iteration 14566 : model1 loss : 0.442175 model2 loss : 0.024452
[11:26:28.499] iteration 14567 : model1 loss : 0.437561 model2 loss : 0.025846
[11:26:28.670] iteration 14568 : model1 loss : 0.439850 model2 loss : 0.025052
[11:26:28.837] iteration 14569 : model1 loss : 0.435822 model2 loss : 0.023283
[11:26:29.005] iteration 14570 : model1 loss : 0.435450 model2 loss : 0.026118
[11:26:29.173] iteration 14571 : model1 loss : 0.438852 model2 loss : 0.027372
[11:26:29.343] iteration 14572 : model1 loss : 0.436845 model2 loss : 0.019440
[11:26:29.511] iteration 14573 : model1 loss : 0.436749 model2 loss : 0.025005
[11:26:29.680] iteration 14574 : model1 loss : 0.431908 model2 loss : 0.020717
[11:26:29.848] iteration 14575 : model1 loss : 0.435694 model2 loss : 0.024094
[11:26:30.016] iteration 14576 : model1 loss : 0.439398 model2 loss : 0.026640
[11:26:30.184] iteration 14577 : model1 loss : 0.439021 model2 loss : 0.025043
[11:26:30.368] iteration 14578 : model1 loss : 0.435769 model2 loss : 0.023858
[11:26:30.540] iteration 14579 : model1 loss : 0.436344 model2 loss : 0.021963
[11:26:30.709] iteration 14580 : model1 loss : 0.442016 model2 loss : 0.029564
[11:26:30.877] iteration 14581 : model1 loss : 0.440200 model2 loss : 0.024852
[11:26:31.046] iteration 14582 : model1 loss : 0.434627 model2 loss : 0.022123
[11:26:31.213] iteration 14583 : model1 loss : 0.436732 model2 loss : 0.024457
[11:26:31.383] iteration 14584 : model1 loss : 0.440982 model2 loss : 0.024393
[11:26:31.550] iteration 14585 : model1 loss : 0.439198 model2 loss : 0.025528
[11:26:31.719] iteration 14586 : model1 loss : 0.435989 model2 loss : 0.025077
[11:26:33.701] iteration 14587 : model1 loss : 0.435803 model2 loss : 0.023226
[11:26:33.867] iteration 14588 : model1 loss : 0.435476 model2 loss : 0.022781
[11:26:34.038] iteration 14589 : model1 loss : 0.438097 model2 loss : 0.027432
[11:26:34.207] iteration 14590 : model1 loss : 0.438792 model2 loss : 0.025972
[11:26:34.375] iteration 14591 : model1 loss : 0.440951 model2 loss : 0.025508
[11:26:34.543] iteration 14592 : model1 loss : 0.436875 model2 loss : 0.024432
[11:26:34.713] iteration 14593 : model1 loss : 0.440072 model2 loss : 0.024535
[11:26:34.878] iteration 14594 : model1 loss : 0.440673 model2 loss : 0.026427
[11:26:35.048] iteration 14595 : model1 loss : 0.439429 model2 loss : 0.026495
[11:26:35.215] iteration 14596 : model1 loss : 0.440960 model2 loss : 0.029779
[11:26:35.383] iteration 14597 : model1 loss : 0.441636 model2 loss : 0.033405
[11:26:35.550] iteration 14598 : model1 loss : 0.438902 model2 loss : 0.024839
[11:26:35.718] iteration 14599 : model1 loss : 0.437348 model2 loss : 0.024233
[11:26:35.887] iteration 14600 : model1 loss : 0.434511 model2 loss : 0.024392
[11:26:36.055] iteration 14601 : model1 loss : 0.432787 model2 loss : 0.021960
[11:26:36.223] iteration 14602 : model1 loss : 0.435599 model2 loss : 0.025844
[11:26:36.392] iteration 14603 : model1 loss : 0.432627 model2 loss : 0.022377
[11:26:36.559] iteration 14604 : model1 loss : 0.436679 model2 loss : 0.022661
[11:26:36.727] iteration 14605 : model1 loss : 0.440983 model2 loss : 0.035518
[11:26:36.894] iteration 14606 : model1 loss : 0.437708 model2 loss : 0.024435
[11:26:37.063] iteration 14607 : model1 loss : 0.431982 model2 loss : 0.022458
[11:26:37.231] iteration 14608 : model1 loss : 0.436457 model2 loss : 0.025665
[11:26:37.400] iteration 14609 : model1 loss : 0.438218 model2 loss : 0.025663
[11:26:37.569] iteration 14610 : model1 loss : 0.435580 model2 loss : 0.022436
[11:26:37.739] iteration 14611 : model1 loss : 0.441183 model2 loss : 0.029984
[11:26:37.908] iteration 14612 : model1 loss : 0.436019 model2 loss : 0.024972
[11:26:38.079] iteration 14613 : model1 loss : 0.439156 model2 loss : 0.022238
[11:26:38.245] iteration 14614 : model1 loss : 0.435280 model2 loss : 0.023414
[11:26:38.414] iteration 14615 : model1 loss : 0.435292 model2 loss : 0.025090
[11:26:38.580] iteration 14616 : model1 loss : 0.436764 model2 loss : 0.024532
[11:26:38.749] iteration 14617 : model1 loss : 0.434126 model2 loss : 0.024304
[11:26:38.916] iteration 14618 : model1 loss : 0.438254 model2 loss : 0.025884
[11:26:39.085] iteration 14619 : model1 loss : 0.430512 model2 loss : 0.020025
[11:26:41.049] iteration 14620 : model1 loss : 0.438582 model2 loss : 0.023070
[11:26:41.218] iteration 14621 : model1 loss : 0.435408 model2 loss : 0.023944
[11:26:41.390] iteration 14622 : model1 loss : 0.437461 model2 loss : 0.024717
[11:26:41.557] iteration 14623 : model1 loss : 0.434035 model2 loss : 0.023885
[11:26:41.728] iteration 14624 : model1 loss : 0.434785 model2 loss : 0.024019
[11:26:41.897] iteration 14625 : model1 loss : 0.436464 model2 loss : 0.023561
[11:26:42.066] iteration 14626 : model1 loss : 0.434929 model2 loss : 0.022490
[11:26:42.233] iteration 14627 : model1 loss : 0.436191 model2 loss : 0.022781
[11:26:42.403] iteration 14628 : model1 loss : 0.441269 model2 loss : 0.025068
[11:26:42.573] iteration 14629 : model1 loss : 0.431569 model2 loss : 0.022938
[11:26:42.742] iteration 14630 : model1 loss : 0.440502 model2 loss : 0.025166
[11:26:42.908] iteration 14631 : model1 loss : 0.441007 model2 loss : 0.027083
[11:26:43.077] iteration 14632 : model1 loss : 0.433885 model2 loss : 0.023346
[11:26:43.244] iteration 14633 : model1 loss : 0.437645 model2 loss : 0.022981
[11:26:43.415] iteration 14634 : model1 loss : 0.434393 model2 loss : 0.027379
[11:26:43.582] iteration 14635 : model1 loss : 0.435551 model2 loss : 0.024511
[11:26:43.752] iteration 14636 : model1 loss : 0.437318 model2 loss : 0.025561
[11:26:43.920] iteration 14637 : model1 loss : 0.439203 model2 loss : 0.021669
[11:26:44.089] iteration 14638 : model1 loss : 0.438230 model2 loss : 0.024728
[11:26:44.255] iteration 14639 : model1 loss : 0.441745 model2 loss : 0.024222
[11:26:44.426] iteration 14640 : model1 loss : 0.436800 model2 loss : 0.024000
[11:26:44.593] iteration 14641 : model1 loss : 0.433026 model2 loss : 0.020538
[11:26:44.761] iteration 14642 : model1 loss : 0.437883 model2 loss : 0.020841
[11:26:44.930] iteration 14643 : model1 loss : 0.437759 model2 loss : 0.021621
[11:26:45.101] iteration 14644 : model1 loss : 0.441054 model2 loss : 0.029342
[11:26:45.268] iteration 14645 : model1 loss : 0.435226 model2 loss : 0.023429
[11:26:45.437] iteration 14646 : model1 loss : 0.434864 model2 loss : 0.023922
[11:26:45.606] iteration 14647 : model1 loss : 0.438765 model2 loss : 0.026365
[11:26:45.777] iteration 14648 : model1 loss : 0.436560 model2 loss : 0.023838
[11:26:45.946] iteration 14649 : model1 loss : 0.433886 model2 loss : 0.021619
[11:26:46.113] iteration 14650 : model1 loss : 0.434123 model2 loss : 0.023483
[11:26:46.279] iteration 14651 : model1 loss : 0.439986 model2 loss : 0.024347
[11:26:46.447] iteration 14652 : model1 loss : 0.440014 model2 loss : 0.033894
[11:26:48.368] iteration 14653 : model1 loss : 0.435747 model2 loss : 0.020997
[11:26:48.537] iteration 14654 : model1 loss : 0.436738 model2 loss : 0.022434
[11:26:48.709] iteration 14655 : model1 loss : 0.434457 model2 loss : 0.023591
[11:26:48.875] iteration 14656 : model1 loss : 0.436286 model2 loss : 0.024233
[11:26:49.044] iteration 14657 : model1 loss : 0.434475 model2 loss : 0.025140
[11:26:49.212] iteration 14658 : model1 loss : 0.429806 model2 loss : 0.024801
[11:26:49.380] iteration 14659 : model1 loss : 0.435978 model2 loss : 0.026474
[11:26:49.547] iteration 14660 : model1 loss : 0.435109 model2 loss : 0.026113
[11:26:49.716] iteration 14661 : model1 loss : 0.436419 model2 loss : 0.022810
[11:26:49.883] iteration 14662 : model1 loss : 0.439964 model2 loss : 0.026218
[11:26:50.050] iteration 14663 : model1 loss : 0.438969 model2 loss : 0.029159
[11:26:50.217] iteration 14664 : model1 loss : 0.438529 model2 loss : 0.026361
[11:26:50.387] iteration 14665 : model1 loss : 0.438543 model2 loss : 0.025617
[11:26:50.555] iteration 14666 : model1 loss : 0.438600 model2 loss : 0.025149
[11:26:50.724] iteration 14667 : model1 loss : 0.437250 model2 loss : 0.030895
[11:26:50.895] iteration 14668 : model1 loss : 0.434583 model2 loss : 0.027733
[11:26:51.064] iteration 14669 : model1 loss : 0.437996 model2 loss : 0.029891
[11:26:51.230] iteration 14670 : model1 loss : 0.435229 model2 loss : 0.025491
[11:26:51.401] iteration 14671 : model1 loss : 0.435691 model2 loss : 0.022731
[11:26:51.567] iteration 14672 : model1 loss : 0.437770 model2 loss : 0.022423
[11:26:51.736] iteration 14673 : model1 loss : 0.438396 model2 loss : 0.026093
[11:26:51.903] iteration 14674 : model1 loss : 0.438223 model2 loss : 0.030686
[11:26:52.072] iteration 14675 : model1 loss : 0.437034 model2 loss : 0.022455
[11:26:52.240] iteration 14676 : model1 loss : 0.437996 model2 loss : 0.035359
[11:26:52.410] iteration 14677 : model1 loss : 0.435151 model2 loss : 0.024232
[11:26:52.577] iteration 14678 : model1 loss : 0.444424 model2 loss : 0.042178
[11:26:52.746] iteration 14679 : model1 loss : 0.434877 model2 loss : 0.023474
[11:26:52.913] iteration 14680 : model1 loss : 0.434904 model2 loss : 0.024370
[11:26:53.081] iteration 14681 : model1 loss : 0.441362 model2 loss : 0.027440
[11:26:53.249] iteration 14682 : model1 loss : 0.439847 model2 loss : 0.033252
[11:26:53.418] iteration 14683 : model1 loss : 0.441501 model2 loss : 0.026877
[11:26:53.583] iteration 14684 : model1 loss : 0.436019 model2 loss : 0.022860
[11:26:53.750] iteration 14685 : model1 loss : 0.436368 model2 loss : 0.023610
[11:26:55.665] iteration 14686 : model1 loss : 0.435797 model2 loss : 0.023082
[11:26:55.830] iteration 14687 : model1 loss : 0.439417 model2 loss : 0.026223
[11:26:55.998] iteration 14688 : model1 loss : 0.436655 model2 loss : 0.024719
[11:26:56.165] iteration 14689 : model1 loss : 0.440059 model2 loss : 0.028338
[11:26:56.334] iteration 14690 : model1 loss : 0.434287 model2 loss : 0.033962
[11:26:56.506] iteration 14691 : model1 loss : 0.432757 model2 loss : 0.025804
[11:26:56.678] iteration 14692 : model1 loss : 0.437548 model2 loss : 0.027019
[11:26:56.844] iteration 14693 : model1 loss : 0.436588 model2 loss : 0.023732
[11:26:57.013] iteration 14694 : model1 loss : 0.440861 model2 loss : 0.029470
[11:26:57.180] iteration 14695 : model1 loss : 0.433995 model2 loss : 0.028439
[11:26:57.347] iteration 14696 : model1 loss : 0.440793 model2 loss : 0.026847
[11:26:57.515] iteration 14697 : model1 loss : 0.440280 model2 loss : 0.029882
[11:26:57.684] iteration 14698 : model1 loss : 0.432986 model2 loss : 0.023453
[11:26:57.851] iteration 14699 : model1 loss : 0.439887 model2 loss : 0.029084
[11:26:58.018] iteration 14700 : model1 loss : 0.435743 model2 loss : 0.023464
[11:26:58.187] iteration 14701 : model1 loss : 0.441620 model2 loss : 0.027781
[11:26:58.357] iteration 14702 : model1 loss : 0.443030 model2 loss : 0.032052
[11:26:58.528] iteration 14703 : model1 loss : 0.436503 model2 loss : 0.026257
[11:26:58.698] iteration 14704 : model1 loss : 0.432486 model2 loss : 0.025071
[11:26:58.865] iteration 14705 : model1 loss : 0.435318 model2 loss : 0.023248
[11:26:59.035] iteration 14706 : model1 loss : 0.438596 model2 loss : 0.023393
[11:26:59.203] iteration 14707 : model1 loss : 0.438521 model2 loss : 0.025619
[11:26:59.372] iteration 14708 : model1 loss : 0.441431 model2 loss : 0.026346
[11:26:59.539] iteration 14709 : model1 loss : 0.439329 model2 loss : 0.027606
[11:26:59.709] iteration 14710 : model1 loss : 0.438714 model2 loss : 0.026132
[11:26:59.877] iteration 14711 : model1 loss : 0.438256 model2 loss : 0.026327
[11:27:00.047] iteration 14712 : model1 loss : 0.434409 model2 loss : 0.025958
[11:27:00.216] iteration 14713 : model1 loss : 0.443635 model2 loss : 0.030441
[11:27:00.385] iteration 14714 : model1 loss : 0.437468 model2 loss : 0.024532
[11:27:00.553] iteration 14715 : model1 loss : 0.433424 model2 loss : 0.026447
[11:27:00.722] iteration 14716 : model1 loss : 0.432602 model2 loss : 0.027044
[11:27:00.892] iteration 14717 : model1 loss : 0.431866 model2 loss : 0.023719
[11:27:01.061] iteration 14718 : model1 loss : 0.436929 model2 loss : 0.027612
[11:27:02.976] iteration 14719 : model1 loss : 0.431922 model2 loss : 0.022574
[11:27:03.147] iteration 14720 : model1 loss : 0.437907 model2 loss : 0.026976
[11:27:03.317] iteration 14721 : model1 loss : 0.439165 model2 loss : 0.027589
[11:27:03.483] iteration 14722 : model1 loss : 0.441241 model2 loss : 0.027651
[11:27:03.655] iteration 14723 : model1 loss : 0.440034 model2 loss : 0.025168
[11:27:03.823] iteration 14724 : model1 loss : 0.438566 model2 loss : 0.024055
[11:27:03.991] iteration 14725 : model1 loss : 0.434487 model2 loss : 0.023907
[11:27:04.157] iteration 14726 : model1 loss : 0.436168 model2 loss : 0.030139
[11:27:04.326] iteration 14727 : model1 loss : 0.438670 model2 loss : 0.022769
[11:27:04.493] iteration 14728 : model1 loss : 0.433962 model2 loss : 0.025931
[11:27:04.668] iteration 14729 : model1 loss : 0.439183 model2 loss : 0.026335
[11:27:04.834] iteration 14730 : model1 loss : 0.434889 model2 loss : 0.025200
[11:27:05.004] iteration 14731 : model1 loss : 0.434121 model2 loss : 0.026561
[11:27:05.171] iteration 14732 : model1 loss : 0.436166 model2 loss : 0.024584
[11:27:05.340] iteration 14733 : model1 loss : 0.434299 model2 loss : 0.022271
[11:27:05.510] iteration 14734 : model1 loss : 0.434361 model2 loss : 0.024795
[11:27:05.680] iteration 14735 : model1 loss : 0.435723 model2 loss : 0.026847
[11:27:05.851] iteration 14736 : model1 loss : 0.441701 model2 loss : 0.028945
[11:27:06.019] iteration 14737 : model1 loss : 0.436218 model2 loss : 0.025297
[11:27:06.186] iteration 14738 : model1 loss : 0.436735 model2 loss : 0.021550
[11:27:06.357] iteration 14739 : model1 loss : 0.436939 model2 loss : 0.024705
[11:27:06.529] iteration 14740 : model1 loss : 0.437593 model2 loss : 0.027878
[11:27:06.700] iteration 14741 : model1 loss : 0.438410 model2 loss : 0.025185
[11:27:06.868] iteration 14742 : model1 loss : 0.445617 model2 loss : 0.031979
[11:27:07.038] iteration 14743 : model1 loss : 0.442755 model2 loss : 0.027333
[11:27:07.206] iteration 14744 : model1 loss : 0.437701 model2 loss : 0.023995
[11:27:07.373] iteration 14745 : model1 loss : 0.435457 model2 loss : 0.022150
[11:27:07.542] iteration 14746 : model1 loss : 0.438789 model2 loss : 0.026535
[11:27:07.712] iteration 14747 : model1 loss : 0.434852 model2 loss : 0.024233
[11:27:07.879] iteration 14748 : model1 loss : 0.436870 model2 loss : 0.025903
[11:27:08.049] iteration 14749 : model1 loss : 0.436606 model2 loss : 0.023118
[11:27:08.215] iteration 14750 : model1 loss : 0.434587 model2 loss : 0.023444
[11:27:08.385] iteration 14751 : model1 loss : 0.437184 model2 loss : 0.021086
[11:27:10.317] iteration 14752 : model1 loss : 0.438361 model2 loss : 0.025311
[11:27:10.486] iteration 14753 : model1 loss : 0.437078 model2 loss : 0.024687
[11:27:10.657] iteration 14754 : model1 loss : 0.441580 model2 loss : 0.027130
[11:27:10.825] iteration 14755 : model1 loss : 0.438123 model2 loss : 0.023036
[11:27:10.994] iteration 14756 : model1 loss : 0.441615 model2 loss : 0.024831
[11:27:11.163] iteration 14757 : model1 loss : 0.435832 model2 loss : 0.023716
[11:27:11.331] iteration 14758 : model1 loss : 0.441605 model2 loss : 0.025703
[11:27:11.500] iteration 14759 : model1 loss : 0.434062 model2 loss : 0.023119
[11:27:11.669] iteration 14760 : model1 loss : 0.435570 model2 loss : 0.025429
[11:27:11.837] iteration 14761 : model1 loss : 0.436774 model2 loss : 0.025900
[11:27:12.005] iteration 14762 : model1 loss : 0.437542 model2 loss : 0.023104
[11:27:12.171] iteration 14763 : model1 loss : 0.437744 model2 loss : 0.027043
[11:27:12.341] iteration 14764 : model1 loss : 0.433699 model2 loss : 0.025561
[11:27:12.516] iteration 14765 : model1 loss : 0.438696 model2 loss : 0.027840
[11:27:12.687] iteration 14766 : model1 loss : 0.436015 model2 loss : 0.024306
[11:27:12.854] iteration 14767 : model1 loss : 0.437363 model2 loss : 0.025137
[11:27:13.023] iteration 14768 : model1 loss : 0.439620 model2 loss : 0.024511
[11:27:13.188] iteration 14769 : model1 loss : 0.434804 model2 loss : 0.023748
[11:27:13.359] iteration 14770 : model1 loss : 0.439588 model2 loss : 0.023490
[11:27:13.529] iteration 14771 : model1 loss : 0.435537 model2 loss : 0.021983
[11:27:13.702] iteration 14772 : model1 loss : 0.443204 model2 loss : 0.024516
[11:27:13.869] iteration 14773 : model1 loss : 0.435469 model2 loss : 0.022210
[11:27:14.039] iteration 14774 : model1 loss : 0.435170 model2 loss : 0.023088
[11:27:14.206] iteration 14775 : model1 loss : 0.437074 model2 loss : 0.024562
[11:27:14.374] iteration 14776 : model1 loss : 0.436458 model2 loss : 0.026140
[11:27:14.543] iteration 14777 : model1 loss : 0.434810 model2 loss : 0.024171
[11:27:14.714] iteration 14778 : model1 loss : 0.437457 model2 loss : 0.025939
[11:27:14.881] iteration 14779 : model1 loss : 0.430667 model2 loss : 0.027400
[11:27:15.049] iteration 14780 : model1 loss : 0.437001 model2 loss : 0.023026
[11:27:15.216] iteration 14781 : model1 loss : 0.434982 model2 loss : 0.025266
[11:27:15.383] iteration 14782 : model1 loss : 0.439420 model2 loss : 0.025351
[11:27:15.548] iteration 14783 : model1 loss : 0.437571 model2 loss : 0.023816
[11:27:15.718] iteration 14784 : model1 loss : 0.438630 model2 loss : 0.024249
[11:27:17.663] iteration 14785 : model1 loss : 0.434697 model2 loss : 0.020721
[11:27:17.835] iteration 14786 : model1 loss : 0.440052 model2 loss : 0.025644
[11:27:18.007] iteration 14787 : model1 loss : 0.439589 model2 loss : 0.027030
[11:27:18.175] iteration 14788 : model1 loss : 0.435858 model2 loss : 0.023783
[11:27:18.344] iteration 14789 : model1 loss : 0.440472 model2 loss : 0.025692
[11:27:18.514] iteration 14790 : model1 loss : 0.435914 model2 loss : 0.021870
[11:27:18.683] iteration 14791 : model1 loss : 0.438837 model2 loss : 0.025162
[11:27:18.848] iteration 14792 : model1 loss : 0.435257 model2 loss : 0.021083
[11:27:19.017] iteration 14793 : model1 loss : 0.435076 model2 loss : 0.022640
[11:27:19.184] iteration 14794 : model1 loss : 0.438459 model2 loss : 0.022286
[11:27:19.353] iteration 14795 : model1 loss : 0.437289 model2 loss : 0.022478
[11:27:19.523] iteration 14796 : model1 loss : 0.434864 model2 loss : 0.022375
[11:27:19.692] iteration 14797 : model1 loss : 0.440343 model2 loss : 0.024149
[11:27:19.865] iteration 14798 : model1 loss : 0.437397 model2 loss : 0.022695
[11:27:20.035] iteration 14799 : model1 loss : 0.436842 model2 loss : 0.023016
[11:27:20.202] iteration 14800 : model1 loss : 0.437981 model2 loss : 0.025694
[11:27:20.373] iteration 14801 : model1 loss : 0.434998 model2 loss : 0.022250
[11:27:20.544] iteration 14802 : model1 loss : 0.437331 model2 loss : 0.024232
[11:27:20.715] iteration 14803 : model1 loss : 0.440448 model2 loss : 0.028231
[11:27:20.885] iteration 14804 : model1 loss : 0.433600 model2 loss : 0.020164
[11:27:21.054] iteration 14805 : model1 loss : 0.438543 model2 loss : 0.029669
[11:27:21.222] iteration 14806 : model1 loss : 0.434789 model2 loss : 0.021914
[11:27:21.391] iteration 14807 : model1 loss : 0.438628 model2 loss : 0.026801
[11:27:21.559] iteration 14808 : model1 loss : 0.437151 model2 loss : 0.023323
[11:27:21.730] iteration 14809 : model1 loss : 0.434115 model2 loss : 0.025916
[11:27:21.897] iteration 14810 : model1 loss : 0.434770 model2 loss : 0.023220
[11:27:22.065] iteration 14811 : model1 loss : 0.434751 model2 loss : 0.022316
[11:27:22.234] iteration 14812 : model1 loss : 0.437566 model2 loss : 0.023757
[11:27:22.404] iteration 14813 : model1 loss : 0.440240 model2 loss : 0.025570
[11:27:22.571] iteration 14814 : model1 loss : 0.435329 model2 loss : 0.025048
[11:27:22.742] iteration 14815 : model1 loss : 0.439858 model2 loss : 0.026577
[11:27:22.909] iteration 14816 : model1 loss : 0.437645 model2 loss : 0.027589
[11:27:23.078] iteration 14817 : model1 loss : 0.437183 model2 loss : 0.023138
[11:27:25.005] iteration 14818 : model1 loss : 0.438344 model2 loss : 0.027933
[11:27:25.172] iteration 14819 : model1 loss : 0.438433 model2 loss : 0.025973
[11:27:25.342] iteration 14820 : model1 loss : 0.434819 model2 loss : 0.023525
[11:27:25.510] iteration 14821 : model1 loss : 0.436378 model2 loss : 0.022914
[11:27:25.681] iteration 14822 : model1 loss : 0.442154 model2 loss : 0.026173
[11:27:25.850] iteration 14823 : model1 loss : 0.433406 model2 loss : 0.022725
[11:27:26.019] iteration 14824 : model1 loss : 0.438071 model2 loss : 0.028725
[11:27:26.186] iteration 14825 : model1 loss : 0.432331 model2 loss : 0.024802
[11:27:26.354] iteration 14826 : model1 loss : 0.438166 model2 loss : 0.025033
[11:27:26.524] iteration 14827 : model1 loss : 0.436323 model2 loss : 0.027245
[11:27:26.692] iteration 14828 : model1 loss : 0.441665 model2 loss : 0.029182
[11:27:26.860] iteration 14829 : model1 loss : 0.434642 model2 loss : 0.023385
[11:27:27.029] iteration 14830 : model1 loss : 0.437105 model2 loss : 0.022013
[11:27:27.196] iteration 14831 : model1 loss : 0.435127 model2 loss : 0.021873
[11:27:27.365] iteration 14832 : model1 loss : 0.440609 model2 loss : 0.026335
[11:27:27.535] iteration 14833 : model1 loss : 0.436135 model2 loss : 0.024643
[11:27:27.703] iteration 14834 : model1 loss : 0.434951 model2 loss : 0.021738
[11:27:27.871] iteration 14835 : model1 loss : 0.437018 model2 loss : 0.027820
[11:27:28.041] iteration 14836 : model1 loss : 0.436922 model2 loss : 0.023818
[11:27:28.208] iteration 14837 : model1 loss : 0.437196 model2 loss : 0.024778
[11:27:28.380] iteration 14838 : model1 loss : 0.442817 model2 loss : 0.026253
[11:27:28.547] iteration 14839 : model1 loss : 0.442079 model2 loss : 0.023617
[11:27:28.716] iteration 14840 : model1 loss : 0.433414 model2 loss : 0.026658
[11:27:28.883] iteration 14841 : model1 loss : 0.441073 model2 loss : 0.024919
[11:27:29.055] iteration 14842 : model1 loss : 0.436310 model2 loss : 0.024821
[11:27:29.223] iteration 14843 : model1 loss : 0.434046 model2 loss : 0.024785
[11:27:29.392] iteration 14844 : model1 loss : 0.433307 model2 loss : 0.026169
[11:27:29.558] iteration 14845 : model1 loss : 0.438121 model2 loss : 0.023899
[11:27:29.726] iteration 14846 : model1 loss : 0.441700 model2 loss : 0.026251
[11:27:29.892] iteration 14847 : model1 loss : 0.435444 model2 loss : 0.022854
[11:27:30.062] iteration 14848 : model1 loss : 0.435386 model2 loss : 0.024240
[11:27:30.227] iteration 14849 : model1 loss : 0.436324 model2 loss : 0.024680
[11:27:30.396] iteration 14850 : model1 loss : 0.436358 model2 loss : 0.023302
[11:27:32.376] iteration 14851 : model1 loss : 0.436162 model2 loss : 0.023569
[11:27:32.549] iteration 14852 : model1 loss : 0.436003 model2 loss : 0.020955
[11:27:32.719] iteration 14853 : model1 loss : 0.437399 model2 loss : 0.020988
[11:27:32.885] iteration 14854 : model1 loss : 0.437020 model2 loss : 0.024023
[11:27:33.054] iteration 14855 : model1 loss : 0.433952 model2 loss : 0.024603
[11:27:33.227] iteration 14856 : model1 loss : 0.437388 model2 loss : 0.024667
[11:27:33.397] iteration 14857 : model1 loss : 0.433655 model2 loss : 0.021022
[11:27:33.563] iteration 14858 : model1 loss : 0.430064 model2 loss : 0.020603
[11:27:33.732] iteration 14859 : model1 loss : 0.436180 model2 loss : 0.022777
[11:27:33.901] iteration 14860 : model1 loss : 0.437350 model2 loss : 0.021948
[11:27:34.070] iteration 14861 : model1 loss : 0.436521 model2 loss : 0.023263
[11:27:34.238] iteration 14862 : model1 loss : 0.434206 model2 loss : 0.023510
[11:27:34.406] iteration 14863 : model1 loss : 0.439460 model2 loss : 0.028463
[11:27:34.575] iteration 14864 : model1 loss : 0.441689 model2 loss : 0.025001
[11:27:34.747] iteration 14865 : model1 loss : 0.436505 model2 loss : 0.021571
[11:27:34.913] iteration 14866 : model1 loss : 0.439765 model2 loss : 0.024238
[11:27:35.082] iteration 14867 : model1 loss : 0.439048 model2 loss : 0.026062
[11:27:35.250] iteration 14868 : model1 loss : 0.434591 model2 loss : 0.022045
[11:27:35.422] iteration 14869 : model1 loss : 0.435236 model2 loss : 0.021300
[11:27:35.589] iteration 14870 : model1 loss : 0.439472 model2 loss : 0.022660
[11:27:35.762] iteration 14871 : model1 loss : 0.437222 model2 loss : 0.023518
[11:27:35.930] iteration 14872 : model1 loss : 0.438541 model2 loss : 0.024842
[11:27:36.098] iteration 14873 : model1 loss : 0.444806 model2 loss : 0.028744
[11:27:36.266] iteration 14874 : model1 loss : 0.439599 model2 loss : 0.028408
[11:27:36.434] iteration 14875 : model1 loss : 0.437955 model2 loss : 0.022134
[11:27:36.602] iteration 14876 : model1 loss : 0.438849 model2 loss : 0.024506
[11:27:36.774] iteration 14877 : model1 loss : 0.439071 model2 loss : 0.025826
[11:27:36.942] iteration 14878 : model1 loss : 0.440131 model2 loss : 0.026450
[11:27:37.112] iteration 14879 : model1 loss : 0.433841 model2 loss : 0.025783
[11:27:37.279] iteration 14880 : model1 loss : 0.438454 model2 loss : 0.022763
[11:27:37.447] iteration 14881 : model1 loss : 0.434912 model2 loss : 0.024110
[11:27:37.614] iteration 14882 : model1 loss : 0.436531 model2 loss : 0.024435
[11:27:37.782] iteration 14883 : model1 loss : 0.436194 model2 loss : 0.024056
[11:27:39.720] iteration 14884 : model1 loss : 0.435430 model2 loss : 0.024699
[11:27:39.885] iteration 14885 : model1 loss : 0.443536 model2 loss : 0.028061
[11:27:40.056] iteration 14886 : model1 loss : 0.435671 model2 loss : 0.024661
[11:27:40.223] iteration 14887 : model1 loss : 0.436449 model2 loss : 0.022727
[11:27:40.391] iteration 14888 : model1 loss : 0.441708 model2 loss : 0.028003
[11:27:40.556] iteration 14889 : model1 loss : 0.440889 model2 loss : 0.024169
[11:27:40.724] iteration 14890 : model1 loss : 0.439428 model2 loss : 0.025832
[11:27:40.895] iteration 14891 : model1 loss : 0.431569 model2 loss : 0.019905
[11:27:41.065] iteration 14892 : model1 loss : 0.434097 model2 loss : 0.023503
[11:27:41.233] iteration 14893 : model1 loss : 0.433806 model2 loss : 0.021978
[11:27:41.402] iteration 14894 : model1 loss : 0.434431 model2 loss : 0.024160
[11:27:41.571] iteration 14895 : model1 loss : 0.437683 model2 loss : 0.023521
[11:27:41.740] iteration 14896 : model1 loss : 0.434758 model2 loss : 0.022067
[11:27:41.906] iteration 14897 : model1 loss : 0.434847 model2 loss : 0.022137
[11:27:42.076] iteration 14898 : model1 loss : 0.439278 model2 loss : 0.023744
[11:27:42.245] iteration 14899 : model1 loss : 0.438861 model2 loss : 0.024224
[11:27:42.414] iteration 14900 : model1 loss : 0.439084 model2 loss : 0.024136
[11:27:42.581] iteration 14901 : model1 loss : 0.440055 model2 loss : 0.021860
[11:27:42.749] iteration 14902 : model1 loss : 0.438702 model2 loss : 0.026080
[11:27:42.916] iteration 14903 : model1 loss : 0.437546 model2 loss : 0.025028
[11:27:43.085] iteration 14904 : model1 loss : 0.435133 model2 loss : 0.023683
[11:27:43.253] iteration 14905 : model1 loss : 0.435903 model2 loss : 0.025997
[11:27:43.423] iteration 14906 : model1 loss : 0.439896 model2 loss : 0.026744
[11:27:43.591] iteration 14907 : model1 loss : 0.434090 model2 loss : 0.022555
[11:27:43.761] iteration 14908 : model1 loss : 0.437407 model2 loss : 0.022247
[11:27:43.929] iteration 14909 : model1 loss : 0.436576 model2 loss : 0.021799
[11:27:44.098] iteration 14910 : model1 loss : 0.439419 model2 loss : 0.028061
[11:27:44.265] iteration 14911 : model1 loss : 0.438048 model2 loss : 0.023506
[11:27:44.435] iteration 14912 : model1 loss : 0.437505 model2 loss : 0.023903
[11:27:44.602] iteration 14913 : model1 loss : 0.436361 model2 loss : 0.025531
[11:27:44.776] iteration 14914 : model1 loss : 0.437838 model2 loss : 0.024599
[11:27:44.941] iteration 14915 : model1 loss : 0.438460 model2 loss : 0.024948
[11:27:45.110] iteration 14916 : model1 loss : 0.436713 model2 loss : 0.026734
[11:27:47.100] iteration 14917 : model1 loss : 0.435631 model2 loss : 0.019373
[11:27:47.268] iteration 14918 : model1 loss : 0.436779 model2 loss : 0.024188
[11:27:47.440] iteration 14919 : model1 loss : 0.439871 model2 loss : 0.025733
[11:27:47.606] iteration 14920 : model1 loss : 0.440554 model2 loss : 0.028149
[11:27:47.776] iteration 14921 : model1 loss : 0.437150 model2 loss : 0.023343
[11:27:47.944] iteration 14922 : model1 loss : 0.435351 model2 loss : 0.021832
[11:27:48.113] iteration 14923 : model1 loss : 0.434368 model2 loss : 0.027026
[11:27:48.281] iteration 14924 : model1 loss : 0.442182 model2 loss : 0.028364
[11:27:48.450] iteration 14925 : model1 loss : 0.441659 model2 loss : 0.032513
[11:27:48.617] iteration 14926 : model1 loss : 0.438157 model2 loss : 0.024000
[11:27:48.786] iteration 14927 : model1 loss : 0.440034 model2 loss : 0.024574
[11:27:48.955] iteration 14928 : model1 loss : 0.437036 model2 loss : 0.022380
[11:27:49.124] iteration 14929 : model1 loss : 0.438486 model2 loss : 0.024538
[11:27:49.292] iteration 14930 : model1 loss : 0.437970 model2 loss : 0.024764
[11:27:49.462] iteration 14931 : model1 loss : 0.436711 model2 loss : 0.024211
[11:27:49.631] iteration 14932 : model1 loss : 0.437713 model2 loss : 0.025305
[11:27:49.799] iteration 14933 : model1 loss : 0.440284 model2 loss : 0.023187
[11:27:49.966] iteration 14934 : model1 loss : 0.436187 model2 loss : 0.021024
[11:27:50.134] iteration 14935 : model1 loss : 0.438907 model2 loss : 0.025067
[11:27:50.300] iteration 14936 : model1 loss : 0.435977 model2 loss : 0.025635
[11:27:50.469] iteration 14937 : model1 loss : 0.439398 model2 loss : 0.025588
[11:27:50.636] iteration 14938 : model1 loss : 0.433527 model2 loss : 0.021977
[11:27:50.806] iteration 14939 : model1 loss : 0.440518 model2 loss : 0.026597
[11:27:50.974] iteration 14940 : model1 loss : 0.437032 model2 loss : 0.026012
[11:27:51.141] iteration 14941 : model1 loss : 0.431279 model2 loss : 0.022239
[11:27:51.310] iteration 14942 : model1 loss : 0.436878 model2 loss : 0.022767
[11:27:51.478] iteration 14943 : model1 loss : 0.430806 model2 loss : 0.022020
[11:27:51.644] iteration 14944 : model1 loss : 0.437581 model2 loss : 0.025163
[11:27:51.815] iteration 14945 : model1 loss : 0.437139 model2 loss : 0.024548
[11:27:51.982] iteration 14946 : model1 loss : 0.439918 model2 loss : 0.024889
[11:27:52.152] iteration 14947 : model1 loss : 0.433153 model2 loss : 0.022101
[11:27:52.319] iteration 14948 : model1 loss : 0.430878 model2 loss : 0.023194
[11:27:52.506] iteration 14949 : model1 loss : 0.440314 model2 loss : 0.027361
[11:27:54.457] iteration 14950 : model1 loss : 0.437643 model2 loss : 0.022632
[11:27:54.629] iteration 14951 : model1 loss : 0.437773 model2 loss : 0.025470
[11:27:54.800] iteration 14952 : model1 loss : 0.438613 model2 loss : 0.023474
[11:27:54.967] iteration 14953 : model1 loss : 0.432764 model2 loss : 0.021759
[11:27:55.137] iteration 14954 : model1 loss : 0.436058 model2 loss : 0.022269
[11:27:55.302] iteration 14955 : model1 loss : 0.435067 model2 loss : 0.023703
[11:27:55.471] iteration 14956 : model1 loss : 0.436580 model2 loss : 0.026605
[11:27:55.638] iteration 14957 : model1 loss : 0.438318 model2 loss : 0.024534
[11:27:55.808] iteration 14958 : model1 loss : 0.440992 model2 loss : 0.024089
[11:27:55.977] iteration 14959 : model1 loss : 0.438914 model2 loss : 0.023356
[11:27:56.145] iteration 14960 : model1 loss : 0.437187 model2 loss : 0.026173
[11:27:56.312] iteration 14961 : model1 loss : 0.438749 model2 loss : 0.023780
[11:27:56.481] iteration 14962 : model1 loss : 0.437783 model2 loss : 0.025105
[11:27:56.650] iteration 14963 : model1 loss : 0.435507 model2 loss : 0.019620
[11:27:56.823] iteration 14964 : model1 loss : 0.437572 model2 loss : 0.023773
[11:27:56.990] iteration 14965 : model1 loss : 0.435406 model2 loss : 0.021680
[11:27:57.158] iteration 14966 : model1 loss : 0.433749 model2 loss : 0.021099
[11:27:57.325] iteration 14967 : model1 loss : 0.435900 model2 loss : 0.023605
[11:27:57.495] iteration 14968 : model1 loss : 0.437137 model2 loss : 0.021904
[11:27:57.663] iteration 14969 : model1 loss : 0.439797 model2 loss : 0.023375
[11:27:57.834] iteration 14970 : model1 loss : 0.441777 model2 loss : 0.029077
[11:27:58.002] iteration 14971 : model1 loss : 0.435814 model2 loss : 0.025212
[11:27:58.170] iteration 14972 : model1 loss : 0.436430 model2 loss : 0.024887
[11:27:58.338] iteration 14973 : model1 loss : 0.439795 model2 loss : 0.025933
[11:27:58.508] iteration 14974 : model1 loss : 0.438093 model2 loss : 0.024404
[11:27:58.675] iteration 14975 : model1 loss : 0.438940 model2 loss : 0.023071
[11:27:58.847] iteration 14976 : model1 loss : 0.434636 model2 loss : 0.021430
[11:27:59.016] iteration 14977 : model1 loss : 0.437737 model2 loss : 0.021458
[11:27:59.184] iteration 14978 : model1 loss : 0.434310 model2 loss : 0.025482
[11:27:59.352] iteration 14979 : model1 loss : 0.432605 model2 loss : 0.025237
[11:27:59.524] iteration 14980 : model1 loss : 0.442311 model2 loss : 0.027435
[11:27:59.692] iteration 14981 : model1 loss : 0.437088 model2 loss : 0.023139
[11:27:59.859] iteration 14982 : model1 loss : 0.438823 model2 loss : 0.025325
[11:28:01.782] iteration 14983 : model1 loss : 0.437094 model2 loss : 0.024542
[11:28:01.951] iteration 14984 : model1 loss : 0.439978 model2 loss : 0.022601
[11:28:02.121] iteration 14985 : model1 loss : 0.433909 model2 loss : 0.021807
[11:28:02.291] iteration 14986 : model1 loss : 0.436580 model2 loss : 0.025368
[11:28:02.462] iteration 14987 : model1 loss : 0.436594 model2 loss : 0.021716
[11:28:02.631] iteration 14988 : model1 loss : 0.436602 model2 loss : 0.023176
[11:28:02.800] iteration 14989 : model1 loss : 0.433560 model2 loss : 0.021103
[11:28:02.967] iteration 14990 : model1 loss : 0.440160 model2 loss : 0.024715
[11:28:03.140] iteration 14991 : model1 loss : 0.437972 model2 loss : 0.024009
[11:28:03.307] iteration 14992 : model1 loss : 0.433128 model2 loss : 0.023597
[11:28:03.477] iteration 14993 : model1 loss : 0.434804 model2 loss : 0.021084
[11:28:03.645] iteration 14994 : model1 loss : 0.438225 model2 loss : 0.021711
[11:28:03.815] iteration 14995 : model1 loss : 0.436032 model2 loss : 0.023007
[11:28:03.982] iteration 14996 : model1 loss : 0.436976 model2 loss : 0.023056
[11:28:04.153] iteration 14997 : model1 loss : 0.436068 model2 loss : 0.022502
[11:28:04.322] iteration 14998 : model1 loss : 0.436662 model2 loss : 0.025729
[11:28:04.492] iteration 14999 : model1 loss : 0.438652 model2 loss : 0.026044
[11:28:04.662] iteration 15000 : model1 loss : 0.434406 model2 loss : 0.022939
[11:28:12.992] iteration 15000 : model1_mean_dice : 0.890898 model1_mean_hd95 : 3.803302
[11:28:21.257] iteration 15000 : model2_mean_dice : 0.899453 model2_mean_hd95 : 3.061461
[11:28:21.276] save model1 to ../model/ACDC/EVILv1_kl0.5_tau0.25_21_1337/unet\model1_iter_15000.pth
[11:28:21.294] save model2 to ../model/ACDC/EVILv1_kl0.5_tau0.25_21_1337/unet\model2_iter_15000.pth
[11:28:21.466] iteration 15001 : model1 loss : 0.438112 model2 loss : 0.023626
[11:28:21.640] iteration 15002 : model1 loss : 0.436873 model2 loss : 0.020885
[11:28:21.810] iteration 15003 : model1 loss : 0.435391 model2 loss : 0.021400
[11:28:21.978] iteration 15004 : model1 loss : 0.439100 model2 loss : 0.022777
[11:28:22.147] iteration 15005 : model1 loss : 0.437877 model2 loss : 0.023162
[11:28:22.314] iteration 15006 : model1 loss : 0.439077 model2 loss : 0.025250
[11:28:22.482] iteration 15007 : model1 loss : 0.438799 model2 loss : 0.026692
[11:28:22.649] iteration 15008 : model1 loss : 0.437130 model2 loss : 0.025775
[11:28:22.818] iteration 15009 : model1 loss : 0.437539 model2 loss : 0.020986
[11:28:22.983] iteration 15010 : model1 loss : 0.439459 model2 loss : 0.023586
[11:28:23.152] iteration 15011 : model1 loss : 0.441290 model2 loss : 0.024497
[11:28:23.317] iteration 15012 : model1 loss : 0.437166 model2 loss : 0.020517
[11:28:23.486] iteration 15013 : model1 loss : 0.437711 model2 loss : 0.022615
[11:28:23.651] iteration 15014 : model1 loss : 0.433669 model2 loss : 0.023835
[11:28:23.819] iteration 15015 : model1 loss : 0.437734 model2 loss : 0.021585
[11:28:25.741] iteration 15016 : model1 loss : 0.433772 model2 loss : 0.021154
[11:28:25.915] iteration 15017 : model1 loss : 0.434541 model2 loss : 0.022465
[11:28:26.085] iteration 15018 : model1 loss : 0.438509 model2 loss : 0.023100
[11:28:26.249] iteration 15019 : model1 loss : 0.435234 model2 loss : 0.020804
[11:28:26.416] iteration 15020 : model1 loss : 0.436626 model2 loss : 0.021527
[11:28:26.584] iteration 15021 : model1 loss : 0.437232 model2 loss : 0.022562
[11:28:26.753] iteration 15022 : model1 loss : 0.438833 model2 loss : 0.025676
[11:28:26.923] iteration 15023 : model1 loss : 0.435026 model2 loss : 0.022309
[11:28:27.091] iteration 15024 : model1 loss : 0.432646 model2 loss : 0.021973
[11:28:27.257] iteration 15025 : model1 loss : 0.437141 model2 loss : 0.024930
[11:28:27.427] iteration 15026 : model1 loss : 0.438994 model2 loss : 0.023427
[11:28:27.594] iteration 15027 : model1 loss : 0.438343 model2 loss : 0.022287
[11:28:27.761] iteration 15028 : model1 loss : 0.438194 model2 loss : 0.023467
[11:28:27.930] iteration 15029 : model1 loss : 0.437599 model2 loss : 0.021630
[11:28:28.099] iteration 15030 : model1 loss : 0.433433 model2 loss : 0.022119
[11:28:28.266] iteration 15031 : model1 loss : 0.440665 model2 loss : 0.026658
[11:28:28.435] iteration 15032 : model1 loss : 0.435372 model2 loss : 0.024056
[11:28:28.603] iteration 15033 : model1 loss : 0.436588 model2 loss : 0.022056
[11:28:28.771] iteration 15034 : model1 loss : 0.439452 model2 loss : 0.026413
[11:28:28.938] iteration 15035 : model1 loss : 0.435219 model2 loss : 0.025038
[11:28:29.107] iteration 15036 : model1 loss : 0.437881 model2 loss : 0.022517
[11:28:29.275] iteration 15037 : model1 loss : 0.439507 model2 loss : 0.022060
[11:28:29.443] iteration 15038 : model1 loss : 0.439778 model2 loss : 0.024613
[11:28:29.612] iteration 15039 : model1 loss : 0.435348 model2 loss : 0.023425
[11:28:29.782] iteration 15040 : model1 loss : 0.433844 model2 loss : 0.023460
[11:28:29.948] iteration 15041 : model1 loss : 0.439381 model2 loss : 0.025936
[11:28:30.132] iteration 15042 : model1 loss : 0.436301 model2 loss : 0.023628
[11:28:30.298] iteration 15043 : model1 loss : 0.437372 model2 loss : 0.022830
[11:28:30.466] iteration 15044 : model1 loss : 0.445633 model2 loss : 0.029343
[11:28:30.633] iteration 15045 : model1 loss : 0.434470 model2 loss : 0.022861
[11:28:30.800] iteration 15046 : model1 loss : 0.439496 model2 loss : 0.028182
[11:28:30.967] iteration 15047 : model1 loss : 0.436155 model2 loss : 0.021384
[11:28:31.134] iteration 15048 : model1 loss : 0.439318 model2 loss : 0.024078
[11:28:33.073] iteration 15049 : model1 loss : 0.438388 model2 loss : 0.025296
[11:28:33.245] iteration 15050 : model1 loss : 0.438511 model2 loss : 0.024257
[11:28:33.412] iteration 15051 : model1 loss : 0.437886 model2 loss : 0.022423
[11:28:33.578] iteration 15052 : model1 loss : 0.436808 model2 loss : 0.022310
[11:28:33.748] iteration 15053 : model1 loss : 0.439956 model2 loss : 0.026620
[11:28:33.915] iteration 15054 : model1 loss : 0.436528 model2 loss : 0.022763
[11:28:34.082] iteration 15055 : model1 loss : 0.437272 model2 loss : 0.022009
[11:28:34.248] iteration 15056 : model1 loss : 0.435346 model2 loss : 0.021311
[11:28:34.416] iteration 15057 : model1 loss : 0.432465 model2 loss : 0.019950
[11:28:34.582] iteration 15058 : model1 loss : 0.441926 model2 loss : 0.026346
[11:28:34.749] iteration 15059 : model1 loss : 0.443054 model2 loss : 0.025535
[11:28:34.914] iteration 15060 : model1 loss : 0.436293 model2 loss : 0.025034
[11:28:35.083] iteration 15061 : model1 loss : 0.432634 model2 loss : 0.020929
[11:28:35.249] iteration 15062 : model1 loss : 0.437097 model2 loss : 0.020381
[11:28:35.418] iteration 15063 : model1 loss : 0.440316 model2 loss : 0.025845
[11:28:35.586] iteration 15064 : model1 loss : 0.436618 model2 loss : 0.022310
[11:28:35.755] iteration 15065 : model1 loss : 0.435260 model2 loss : 0.023501
[11:28:35.924] iteration 15066 : model1 loss : 0.436442 model2 loss : 0.022618
[11:28:36.091] iteration 15067 : model1 loss : 0.441678 model2 loss : 0.024616
[11:28:36.256] iteration 15068 : model1 loss : 0.433958 model2 loss : 0.021364
[11:28:36.423] iteration 15069 : model1 loss : 0.435309 model2 loss : 0.021494
[11:28:36.589] iteration 15070 : model1 loss : 0.440090 model2 loss : 0.023350
[11:28:36.757] iteration 15071 : model1 loss : 0.441240 model2 loss : 0.026708
[11:28:36.924] iteration 15072 : model1 loss : 0.436454 model2 loss : 0.021630
[11:28:37.093] iteration 15073 : model1 loss : 0.430388 model2 loss : 0.024025
[11:28:37.260] iteration 15074 : model1 loss : 0.437000 model2 loss : 0.022795
[11:28:37.429] iteration 15075 : model1 loss : 0.436441 model2 loss : 0.024178
[11:28:37.595] iteration 15076 : model1 loss : 0.435855 model2 loss : 0.024640
[11:28:37.764] iteration 15077 : model1 loss : 0.433793 model2 loss : 0.024927
[11:28:37.929] iteration 15078 : model1 loss : 0.435239 model2 loss : 0.025505
[11:28:38.099] iteration 15079 : model1 loss : 0.438308 model2 loss : 0.021897
[11:28:38.264] iteration 15080 : model1 loss : 0.440635 model2 loss : 0.027174
[11:28:38.431] iteration 15081 : model1 loss : 0.437287 model2 loss : 0.023203
[11:28:40.377] iteration 15082 : model1 loss : 0.437184 model2 loss : 0.026183
[11:28:40.548] iteration 15083 : model1 loss : 0.437785 model2 loss : 0.023601
[11:28:40.717] iteration 15084 : model1 loss : 0.434162 model2 loss : 0.020725
[11:28:40.886] iteration 15085 : model1 loss : 0.439497 model2 loss : 0.021499
[11:28:41.056] iteration 15086 : model1 loss : 0.439205 model2 loss : 0.023064
[11:28:41.225] iteration 15087 : model1 loss : 0.436022 model2 loss : 0.022522
[11:28:41.394] iteration 15088 : model1 loss : 0.438952 model2 loss : 0.025753
[11:28:41.562] iteration 15089 : model1 loss : 0.438974 model2 loss : 0.020154
[11:28:41.730] iteration 15090 : model1 loss : 0.436208 model2 loss : 0.023223
[11:28:41.897] iteration 15091 : model1 loss : 0.439663 model2 loss : 0.025199
[11:28:42.064] iteration 15092 : model1 loss : 0.435540 model2 loss : 0.025115
[11:28:42.231] iteration 15093 : model1 loss : 0.438764 model2 loss : 0.024188
[11:28:42.400] iteration 15094 : model1 loss : 0.434422 model2 loss : 0.023039
[11:28:42.568] iteration 15095 : model1 loss : 0.437327 model2 loss : 0.024622
[11:28:42.739] iteration 15096 : model1 loss : 0.436403 model2 loss : 0.023110
[11:28:42.904] iteration 15097 : model1 loss : 0.438819 model2 loss : 0.022811
[11:28:43.076] iteration 15098 : model1 loss : 0.437359 model2 loss : 0.025070
[11:28:43.244] iteration 15099 : model1 loss : 0.435185 model2 loss : 0.024006
[11:28:43.413] iteration 15100 : model1 loss : 0.436531 model2 loss : 0.022626
[11:28:43.579] iteration 15101 : model1 loss : 0.443160 model2 loss : 0.027918
[11:28:43.749] iteration 15102 : model1 loss : 0.437234 model2 loss : 0.023680
[11:28:43.915] iteration 15103 : model1 loss : 0.439199 model2 loss : 0.021210
[11:28:44.085] iteration 15104 : model1 loss : 0.436253 model2 loss : 0.021756
[11:28:44.251] iteration 15105 : model1 loss : 0.440173 model2 loss : 0.023515
[11:28:44.421] iteration 15106 : model1 loss : 0.436019 model2 loss : 0.021621
[11:28:44.587] iteration 15107 : model1 loss : 0.436246 model2 loss : 0.023356
[11:28:44.756] iteration 15108 : model1 loss : 0.434030 model2 loss : 0.023272
[11:28:44.925] iteration 15109 : model1 loss : 0.431345 model2 loss : 0.022960
[11:28:45.095] iteration 15110 : model1 loss : 0.434101 model2 loss : 0.023562
[11:28:45.262] iteration 15111 : model1 loss : 0.435945 model2 loss : 0.021469
[11:28:45.430] iteration 15112 : model1 loss : 0.434402 model2 loss : 0.023420
[11:28:45.597] iteration 15113 : model1 loss : 0.434531 model2 loss : 0.022142
[11:28:45.765] iteration 15114 : model1 loss : 0.443591 model2 loss : 0.028152
[11:28:47.751] iteration 15115 : model1 loss : 0.435974 model2 loss : 0.022359
[11:28:47.922] iteration 15116 : model1 loss : 0.438479 model2 loss : 0.020579
[11:28:48.094] iteration 15117 : model1 loss : 0.437646 model2 loss : 0.023026
[11:28:48.261] iteration 15118 : model1 loss : 0.435530 model2 loss : 0.018369
[11:28:48.429] iteration 15119 : model1 loss : 0.440590 model2 loss : 0.024452
[11:28:48.596] iteration 15120 : model1 loss : 0.439888 model2 loss : 0.027687
[11:28:48.763] iteration 15121 : model1 loss : 0.436139 model2 loss : 0.022662
[11:28:48.930] iteration 15122 : model1 loss : 0.435365 model2 loss : 0.022168
[11:28:49.100] iteration 15123 : model1 loss : 0.439813 model2 loss : 0.026624
[11:28:49.269] iteration 15124 : model1 loss : 0.435982 model2 loss : 0.024851
[11:28:49.436] iteration 15125 : model1 loss : 0.433643 model2 loss : 0.020339
[11:28:49.602] iteration 15126 : model1 loss : 0.437952 model2 loss : 0.026399
[11:28:49.772] iteration 15127 : model1 loss : 0.440742 model2 loss : 0.026011
[11:28:49.939] iteration 15128 : model1 loss : 0.441830 model2 loss : 0.024066
[11:28:50.111] iteration 15129 : model1 loss : 0.440697 model2 loss : 0.026013
[11:28:50.277] iteration 15130 : model1 loss : 0.437329 model2 loss : 0.022420
[11:28:50.447] iteration 15131 : model1 loss : 0.431090 model2 loss : 0.020784
[11:28:50.615] iteration 15132 : model1 loss : 0.435692 model2 loss : 0.022212
[11:28:50.785] iteration 15133 : model1 loss : 0.433726 model2 loss : 0.023639
[11:28:50.953] iteration 15134 : model1 loss : 0.433654 model2 loss : 0.021955
[11:28:51.125] iteration 15135 : model1 loss : 0.432831 model2 loss : 0.021855
[11:28:51.292] iteration 15136 : model1 loss : 0.438106 model2 loss : 0.025538
[11:28:51.486] iteration 15137 : model1 loss : 0.435968 model2 loss : 0.021545
[11:28:51.653] iteration 15138 : model1 loss : 0.436756 model2 loss : 0.023531
[11:28:51.824] iteration 15139 : model1 loss : 0.440460 model2 loss : 0.024730
[11:28:51.992] iteration 15140 : model1 loss : 0.441204 model2 loss : 0.029857
[11:28:52.161] iteration 15141 : model1 loss : 0.432119 model2 loss : 0.023463
[11:28:52.327] iteration 15142 : model1 loss : 0.434462 model2 loss : 0.022014
[11:28:52.497] iteration 15143 : model1 loss : 0.438000 model2 loss : 0.024505
[11:28:52.665] iteration 15144 : model1 loss : 0.437967 model2 loss : 0.023591
[11:28:52.835] iteration 15145 : model1 loss : 0.441041 model2 loss : 0.023677
[11:28:53.001] iteration 15146 : model1 loss : 0.438268 model2 loss : 0.025081
[11:28:53.167] iteration 15147 : model1 loss : 0.439054 model2 loss : 0.022693
[11:28:55.099] iteration 15148 : model1 loss : 0.436810 model2 loss : 0.023229
[11:28:55.267] iteration 15149 : model1 loss : 0.438943 model2 loss : 0.026080
[11:28:55.437] iteration 15150 : model1 loss : 0.438526 model2 loss : 0.023724
[11:28:55.604] iteration 15151 : model1 loss : 0.436153 model2 loss : 0.023194
[11:28:55.771] iteration 15152 : model1 loss : 0.436719 model2 loss : 0.024856
[11:28:55.939] iteration 15153 : model1 loss : 0.436080 model2 loss : 0.025146
[11:28:56.106] iteration 15154 : model1 loss : 0.436658 model2 loss : 0.022532
[11:28:56.271] iteration 15155 : model1 loss : 0.436286 model2 loss : 0.021673
[11:28:56.441] iteration 15156 : model1 loss : 0.437922 model2 loss : 0.022042
[11:28:56.607] iteration 15157 : model1 loss : 0.436701 model2 loss : 0.020285
[11:28:56.777] iteration 15158 : model1 loss : 0.438406 model2 loss : 0.023025
[11:28:56.942] iteration 15159 : model1 loss : 0.438421 model2 loss : 0.021744
[11:28:57.111] iteration 15160 : model1 loss : 0.441003 model2 loss : 0.024894
[11:28:57.278] iteration 15161 : model1 loss : 0.432297 model2 loss : 0.020151
[11:28:57.449] iteration 15162 : model1 loss : 0.439467 model2 loss : 0.025384
[11:28:57.618] iteration 15163 : model1 loss : 0.435076 model2 loss : 0.021986
[11:28:57.787] iteration 15164 : model1 loss : 0.436193 model2 loss : 0.019291
[11:28:57.954] iteration 15165 : model1 loss : 0.438786 model2 loss : 0.021238
[11:28:58.128] iteration 15166 : model1 loss : 0.435899 model2 loss : 0.022876
[11:28:58.296] iteration 15167 : model1 loss : 0.431098 model2 loss : 0.021345
[11:28:58.465] iteration 15168 : model1 loss : 0.441804 model2 loss : 0.025858
[11:28:58.631] iteration 15169 : model1 loss : 0.438208 model2 loss : 0.022894
[11:28:58.801] iteration 15170 : model1 loss : 0.435292 model2 loss : 0.022595
[11:28:58.968] iteration 15171 : model1 loss : 0.438058 model2 loss : 0.024039
[11:28:59.140] iteration 15172 : model1 loss : 0.435576 model2 loss : 0.023435
[11:28:59.309] iteration 15173 : model1 loss : 0.433114 model2 loss : 0.018920
[11:28:59.476] iteration 15174 : model1 loss : 0.434671 model2 loss : 0.022345
[11:28:59.644] iteration 15175 : model1 loss : 0.437899 model2 loss : 0.025069
[11:28:59.812] iteration 15176 : model1 loss : 0.437295 model2 loss : 0.023706
[11:28:59.980] iteration 15177 : model1 loss : 0.439630 model2 loss : 0.025075
[11:29:00.153] iteration 15178 : model1 loss : 0.433901 model2 loss : 0.023328
[11:29:00.318] iteration 15179 : model1 loss : 0.439926 model2 loss : 0.026050
[11:29:00.487] iteration 15180 : model1 loss : 0.436463 model2 loss : 0.025343
[11:29:02.410] iteration 15181 : model1 loss : 0.439269 model2 loss : 0.024848
[11:29:02.580] iteration 15182 : model1 loss : 0.439010 model2 loss : 0.023154
[11:29:02.752] iteration 15183 : model1 loss : 0.436996 model2 loss : 0.025136
[11:29:02.921] iteration 15184 : model1 loss : 0.437638 model2 loss : 0.021300
[11:29:03.091] iteration 15185 : model1 loss : 0.438702 model2 loss : 0.021403
[11:29:03.257] iteration 15186 : model1 loss : 0.436050 model2 loss : 0.024123
[11:29:03.428] iteration 15187 : model1 loss : 0.430148 model2 loss : 0.020214
[11:29:03.594] iteration 15188 : model1 loss : 0.434471 model2 loss : 0.024116
[11:29:03.764] iteration 15189 : model1 loss : 0.432971 model2 loss : 0.023124
[11:29:03.932] iteration 15190 : model1 loss : 0.434527 model2 loss : 0.019685
[11:29:04.100] iteration 15191 : model1 loss : 0.437479 model2 loss : 0.023709
[11:29:04.269] iteration 15192 : model1 loss : 0.437137 model2 loss : 0.022980
[11:29:04.438] iteration 15193 : model1 loss : 0.436966 model2 loss : 0.023334
[11:29:04.607] iteration 15194 : model1 loss : 0.438928 model2 loss : 0.026497
[11:29:04.776] iteration 15195 : model1 loss : 0.436282 model2 loss : 0.021921
[11:29:04.943] iteration 15196 : model1 loss : 0.437306 model2 loss : 0.024540
[11:29:05.113] iteration 15197 : model1 loss : 0.442203 model2 loss : 0.022581
[11:29:05.279] iteration 15198 : model1 loss : 0.437634 model2 loss : 0.023801
[11:29:05.450] iteration 15199 : model1 loss : 0.434507 model2 loss : 0.020137
[11:29:05.617] iteration 15200 : model1 loss : 0.437575 model2 loss : 0.023775
[11:29:05.787] iteration 15201 : model1 loss : 0.439380 model2 loss : 0.027022
[11:29:05.952] iteration 15202 : model1 loss : 0.438129 model2 loss : 0.024358
[11:29:06.125] iteration 15203 : model1 loss : 0.434946 model2 loss : 0.023739
[11:29:06.293] iteration 15204 : model1 loss : 0.441486 model2 loss : 0.022652
[11:29:06.461] iteration 15205 : model1 loss : 0.438359 model2 loss : 0.021975
[11:29:06.629] iteration 15206 : model1 loss : 0.435063 model2 loss : 0.021896
[11:29:06.800] iteration 15207 : model1 loss : 0.434050 model2 loss : 0.021986
[11:29:06.967] iteration 15208 : model1 loss : 0.435192 model2 loss : 0.023640
[11:29:07.143] iteration 15209 : model1 loss : 0.438303 model2 loss : 0.023255
[11:29:07.311] iteration 15210 : model1 loss : 0.437871 model2 loss : 0.024744
[11:29:07.502] iteration 15211 : model1 loss : 0.440606 model2 loss : 0.025199
[11:29:07.668] iteration 15212 : model1 loss : 0.437590 model2 loss : 0.021157
[11:29:07.836] iteration 15213 : model1 loss : 0.434729 model2 loss : 0.020674
[11:29:09.750] iteration 15214 : model1 loss : 0.437177 model2 loss : 0.019575
[11:29:09.918] iteration 15215 : model1 loss : 0.437263 model2 loss : 0.023152
[11:29:10.088] iteration 15216 : model1 loss : 0.437742 model2 loss : 0.024050
[11:29:10.255] iteration 15217 : model1 loss : 0.433578 model2 loss : 0.023264
[11:29:10.424] iteration 15218 : model1 loss : 0.433081 model2 loss : 0.022202
[11:29:10.592] iteration 15219 : model1 loss : 0.433441 model2 loss : 0.022321
[11:29:10.763] iteration 15220 : model1 loss : 0.434671 model2 loss : 0.022993
[11:29:10.931] iteration 15221 : model1 loss : 0.439553 model2 loss : 0.019961
[11:29:11.103] iteration 15222 : model1 loss : 0.437067 model2 loss : 0.023549
[11:29:11.272] iteration 15223 : model1 loss : 0.442456 model2 loss : 0.029579
[11:29:11.442] iteration 15224 : model1 loss : 0.436152 model2 loss : 0.024534
[11:29:11.609] iteration 15225 : model1 loss : 0.437355 model2 loss : 0.024139
[11:29:11.782] iteration 15226 : model1 loss : 0.437674 model2 loss : 0.022669
[11:29:11.950] iteration 15227 : model1 loss : 0.437988 model2 loss : 0.023914
[11:29:12.119] iteration 15228 : model1 loss : 0.439837 model2 loss : 0.025857
[11:29:12.286] iteration 15229 : model1 loss : 0.436028 model2 loss : 0.023873
[11:29:12.456] iteration 15230 : model1 loss : 0.433594 model2 loss : 0.022918
[11:29:12.623] iteration 15231 : model1 loss : 0.434966 model2 loss : 0.023926
[11:29:12.791] iteration 15232 : model1 loss : 0.436387 model2 loss : 0.024976
[11:29:12.959] iteration 15233 : model1 loss : 0.434776 model2 loss : 0.022999
[11:29:13.127] iteration 15234 : model1 loss : 0.436766 model2 loss : 0.026116
[11:29:13.303] iteration 15235 : model1 loss : 0.440112 model2 loss : 0.024495
[11:29:13.473] iteration 15236 : model1 loss : 0.438384 model2 loss : 0.026389
[11:29:13.640] iteration 15237 : model1 loss : 0.439136 model2 loss : 0.032061
[11:29:13.811] iteration 15238 : model1 loss : 0.435944 model2 loss : 0.035452
[11:29:13.977] iteration 15239 : model1 loss : 0.438213 model2 loss : 0.023713
[11:29:14.147] iteration 15240 : model1 loss : 0.435836 model2 loss : 0.019304
[11:29:14.313] iteration 15241 : model1 loss : 0.435569 model2 loss : 0.022367
[11:29:14.482] iteration 15242 : model1 loss : 0.440400 model2 loss : 0.023333
[11:29:14.648] iteration 15243 : model1 loss : 0.435186 model2 loss : 0.022672
[11:29:14.817] iteration 15244 : model1 loss : 0.434381 model2 loss : 0.021088
[11:29:14.983] iteration 15245 : model1 loss : 0.445108 model2 loss : 0.030344
[11:29:15.153] iteration 15246 : model1 loss : 0.436968 model2 loss : 0.021652
[11:29:17.091] iteration 15247 : model1 loss : 0.440229 model2 loss : 0.023406
[11:29:17.264] iteration 15248 : model1 loss : 0.438833 model2 loss : 0.022112
[11:29:17.435] iteration 15249 : model1 loss : 0.438088 model2 loss : 0.024721
[11:29:17.599] iteration 15250 : model1 loss : 0.436363 model2 loss : 0.022472
[11:29:17.771] iteration 15251 : model1 loss : 0.435929 model2 loss : 0.026805
[11:29:17.940] iteration 15252 : model1 loss : 0.437585 model2 loss : 0.027249
[11:29:18.107] iteration 15253 : model1 loss : 0.437154 model2 loss : 0.025928
[11:29:18.276] iteration 15254 : model1 loss : 0.437502 model2 loss : 0.023632
[11:29:18.445] iteration 15255 : model1 loss : 0.435930 model2 loss : 0.022163
[11:29:18.625] iteration 15256 : model1 loss : 0.433389 model2 loss : 0.022802
[11:29:18.796] iteration 15257 : model1 loss : 0.435870 model2 loss : 0.026065
[11:29:18.963] iteration 15258 : model1 loss : 0.437250 model2 loss : 0.020200
[11:29:19.133] iteration 15259 : model1 loss : 0.437331 model2 loss : 0.024559
[11:29:19.300] iteration 15260 : model1 loss : 0.438468 model2 loss : 0.023578
[11:29:19.468] iteration 15261 : model1 loss : 0.435398 model2 loss : 0.024681
[11:29:19.634] iteration 15262 : model1 loss : 0.439324 model2 loss : 0.022981
[11:29:19.805] iteration 15263 : model1 loss : 0.436054 model2 loss : 0.021664
[11:29:19.972] iteration 15264 : model1 loss : 0.439208 model2 loss : 0.022733
[11:29:20.141] iteration 15265 : model1 loss : 0.434183 model2 loss : 0.021861
[11:29:20.310] iteration 15266 : model1 loss : 0.441649 model2 loss : 0.023322
[11:29:20.479] iteration 15267 : model1 loss : 0.440695 model2 loss : 0.026355
[11:29:20.647] iteration 15268 : model1 loss : 0.438837 model2 loss : 0.021394
[11:29:20.814] iteration 15269 : model1 loss : 0.435524 model2 loss : 0.022485
[11:29:20.980] iteration 15270 : model1 loss : 0.436574 model2 loss : 0.023689
[11:29:21.150] iteration 15271 : model1 loss : 0.437447 model2 loss : 0.020823
[11:29:21.317] iteration 15272 : model1 loss : 0.440129 model2 loss : 0.026410
[11:29:21.486] iteration 15273 : model1 loss : 0.434957 model2 loss : 0.022803
[11:29:21.653] iteration 15274 : model1 loss : 0.434350 model2 loss : 0.021788
[11:29:21.822] iteration 15275 : model1 loss : 0.438694 model2 loss : 0.023114
[11:29:22.004] iteration 15276 : model1 loss : 0.438638 model2 loss : 0.019535
[11:29:22.176] iteration 15277 : model1 loss : 0.433999 model2 loss : 0.022081
[11:29:22.342] iteration 15278 : model1 loss : 0.436338 model2 loss : 0.021574
[11:29:22.510] iteration 15279 : model1 loss : 0.439479 model2 loss : 0.022171
[11:29:24.418] iteration 15280 : model1 loss : 0.435721 model2 loss : 0.021376
[11:29:24.584] iteration 15281 : model1 loss : 0.435964 model2 loss : 0.025940
[11:29:24.754] iteration 15282 : model1 loss : 0.437883 model2 loss : 0.025194
[11:29:24.921] iteration 15283 : model1 loss : 0.433304 model2 loss : 0.022215
[11:29:25.107] iteration 15284 : model1 loss : 0.435441 model2 loss : 0.023528
[11:29:25.274] iteration 15285 : model1 loss : 0.440472 model2 loss : 0.021894
[11:29:25.443] iteration 15286 : model1 loss : 0.438272 model2 loss : 0.023585
[11:29:25.609] iteration 15287 : model1 loss : 0.441545 model2 loss : 0.027339
[11:29:25.777] iteration 15288 : model1 loss : 0.434975 model2 loss : 0.023555
[11:29:25.945] iteration 15289 : model1 loss : 0.438924 model2 loss : 0.026501
[11:29:26.115] iteration 15290 : model1 loss : 0.433358 model2 loss : 0.019348
[11:29:26.281] iteration 15291 : model1 loss : 0.438827 model2 loss : 0.025328
[11:29:26.450] iteration 15292 : model1 loss : 0.435803 model2 loss : 0.022951
[11:29:26.617] iteration 15293 : model1 loss : 0.433439 model2 loss : 0.021413
[11:29:26.788] iteration 15294 : model1 loss : 0.438626 model2 loss : 0.026009
[11:29:26.953] iteration 15295 : model1 loss : 0.432861 model2 loss : 0.022133
[11:29:27.123] iteration 15296 : model1 loss : 0.437462 model2 loss : 0.024542
[11:29:27.290] iteration 15297 : model1 loss : 0.438913 model2 loss : 0.019547
[11:29:27.461] iteration 15298 : model1 loss : 0.435991 model2 loss : 0.022947
[11:29:27.628] iteration 15299 : model1 loss : 0.435745 model2 loss : 0.023953
[11:29:27.796] iteration 15300 : model1 loss : 0.441962 model2 loss : 0.029491
[11:29:27.962] iteration 15301 : model1 loss : 0.438312 model2 loss : 0.021583
[11:29:28.130] iteration 15302 : model1 loss : 0.438282 model2 loss : 0.023038
[11:29:28.296] iteration 15303 : model1 loss : 0.437885 model2 loss : 0.027046
[11:29:28.464] iteration 15304 : model1 loss : 0.438410 model2 loss : 0.024192
[11:29:28.632] iteration 15305 : model1 loss : 0.440129 model2 loss : 0.024417
[11:29:28.801] iteration 15306 : model1 loss : 0.440064 model2 loss : 0.024958
[11:29:28.971] iteration 15307 : model1 loss : 0.435780 model2 loss : 0.023715
[11:29:29.139] iteration 15308 : model1 loss : 0.436353 model2 loss : 0.021463
[11:29:29.305] iteration 15309 : model1 loss : 0.437716 model2 loss : 0.023531
[11:29:29.477] iteration 15310 : model1 loss : 0.435530 model2 loss : 0.022487
[11:29:29.642] iteration 15311 : model1 loss : 0.438344 model2 loss : 0.023643
[11:29:29.810] iteration 15312 : model1 loss : 0.436024 model2 loss : 0.024583
[11:29:31.752] iteration 15313 : model1 loss : 0.434377 model2 loss : 0.022741
[11:29:31.918] iteration 15314 : model1 loss : 0.437621 model2 loss : 0.021643
[11:29:32.089] iteration 15315 : model1 loss : 0.441241 model2 loss : 0.023937
[11:29:32.257] iteration 15316 : model1 loss : 0.435253 model2 loss : 0.024821
[11:29:32.424] iteration 15317 : model1 loss : 0.435671 model2 loss : 0.021821
[11:29:32.591] iteration 15318 : model1 loss : 0.437919 model2 loss : 0.020559
[11:29:32.760] iteration 15319 : model1 loss : 0.437303 model2 loss : 0.023845
[11:29:32.927] iteration 15320 : model1 loss : 0.434850 model2 loss : 0.023424
[11:29:33.096] iteration 15321 : model1 loss : 0.437300 model2 loss : 0.022049
[11:29:33.265] iteration 15322 : model1 loss : 0.435114 model2 loss : 0.023229
[11:29:33.434] iteration 15323 : model1 loss : 0.437358 model2 loss : 0.023133
[11:29:33.600] iteration 15324 : model1 loss : 0.434701 model2 loss : 0.021878
[11:29:33.768] iteration 15325 : model1 loss : 0.434747 model2 loss : 0.022106
[11:29:33.935] iteration 15326 : model1 loss : 0.435525 model2 loss : 0.023397
[11:29:34.104] iteration 15327 : model1 loss : 0.436692 model2 loss : 0.023231
[11:29:34.269] iteration 15328 : model1 loss : 0.439277 model2 loss : 0.022515
[11:29:34.437] iteration 15329 : model1 loss : 0.440250 model2 loss : 0.023434
[11:29:34.603] iteration 15330 : model1 loss : 0.436490 model2 loss : 0.024467
[11:29:34.772] iteration 15331 : model1 loss : 0.435815 model2 loss : 0.021876
[11:29:34.941] iteration 15332 : model1 loss : 0.441011 model2 loss : 0.024500
[11:29:35.111] iteration 15333 : model1 loss : 0.439146 model2 loss : 0.025089
[11:29:35.276] iteration 15334 : model1 loss : 0.443033 model2 loss : 0.024094
[11:29:35.448] iteration 15335 : model1 loss : 0.434792 model2 loss : 0.023094
[11:29:35.613] iteration 15336 : model1 loss : 0.438446 model2 loss : 0.023873
[11:29:35.781] iteration 15337 : model1 loss : 0.434039 model2 loss : 0.022485
[11:29:35.951] iteration 15338 : model1 loss : 0.438772 model2 loss : 0.024562
[11:29:36.120] iteration 15339 : model1 loss : 0.437333 model2 loss : 0.020950
[11:29:36.287] iteration 15340 : model1 loss : 0.439080 model2 loss : 0.022508
[11:29:36.457] iteration 15341 : model1 loss : 0.435943 model2 loss : 0.023963
[11:29:36.624] iteration 15342 : model1 loss : 0.434588 model2 loss : 0.023789
[11:29:36.791] iteration 15343 : model1 loss : 0.440172 model2 loss : 0.025021
[11:29:36.956] iteration 15344 : model1 loss : 0.434511 model2 loss : 0.022528
[11:29:37.123] iteration 15345 : model1 loss : 0.435114 model2 loss : 0.023014
[11:29:39.054] iteration 15346 : model1 loss : 0.434128 model2 loss : 0.020671
[11:29:39.224] iteration 15347 : model1 loss : 0.437660 model2 loss : 0.026758
[11:29:39.394] iteration 15348 : model1 loss : 0.437342 model2 loss : 0.022054
[11:29:39.561] iteration 15349 : model1 loss : 0.436988 model2 loss : 0.020936
[11:29:39.731] iteration 15350 : model1 loss : 0.438057 model2 loss : 0.025491
[11:29:39.898] iteration 15351 : model1 loss : 0.436523 model2 loss : 0.023886
[11:29:40.068] iteration 15352 : model1 loss : 0.442027 model2 loss : 0.026191
[11:29:40.235] iteration 15353 : model1 loss : 0.434325 model2 loss : 0.024827
[11:29:40.402] iteration 15354 : model1 loss : 0.440893 model2 loss : 0.025728
[11:29:40.570] iteration 15355 : model1 loss : 0.440224 model2 loss : 0.026461
[11:29:40.740] iteration 15356 : model1 loss : 0.436706 model2 loss : 0.025588
[11:29:40.911] iteration 15357 : model1 loss : 0.437886 model2 loss : 0.023227
[11:29:41.081] iteration 15358 : model1 loss : 0.436329 model2 loss : 0.021465
[11:29:41.249] iteration 15359 : model1 loss : 0.439542 model2 loss : 0.024963
[11:29:41.417] iteration 15360 : model1 loss : 0.436528 model2 loss : 0.021917
[11:29:41.586] iteration 15361 : model1 loss : 0.439855 model2 loss : 0.022824
[11:29:41.756] iteration 15362 : model1 loss : 0.440630 model2 loss : 0.023073
[11:29:41.921] iteration 15363 : model1 loss : 0.440303 model2 loss : 0.020843
[11:29:42.091] iteration 15364 : model1 loss : 0.432407 model2 loss : 0.022521
[11:29:42.257] iteration 15365 : model1 loss : 0.434590 model2 loss : 0.023547
[11:29:42.428] iteration 15366 : model1 loss : 0.439640 model2 loss : 0.024922
[11:29:42.595] iteration 15367 : model1 loss : 0.433912 model2 loss : 0.021489
[11:29:42.764] iteration 15368 : model1 loss : 0.435635 model2 loss : 0.020556
[11:29:42.932] iteration 15369 : model1 loss : 0.432875 model2 loss : 0.021886
[11:29:43.100] iteration 15370 : model1 loss : 0.438807 model2 loss : 0.027100
[11:29:43.269] iteration 15371 : model1 loss : 0.436564 model2 loss : 0.023084
[11:29:43.436] iteration 15372 : model1 loss : 0.440447 model2 loss : 0.026863
[11:29:43.603] iteration 15373 : model1 loss : 0.433523 model2 loss : 0.023800
[11:29:43.773] iteration 15374 : model1 loss : 0.436328 model2 loss : 0.023539
[11:29:43.940] iteration 15375 : model1 loss : 0.435054 model2 loss : 0.021941
[11:29:44.111] iteration 15376 : model1 loss : 0.435110 model2 loss : 0.020841
[11:29:44.275] iteration 15377 : model1 loss : 0.438618 model2 loss : 0.021613
[11:29:44.445] iteration 15378 : model1 loss : 0.433172 model2 loss : 0.023242
[11:29:46.448] iteration 15379 : model1 loss : 0.442808 model2 loss : 0.026348
[11:29:46.620] iteration 15380 : model1 loss : 0.435584 model2 loss : 0.022106
[11:29:46.790] iteration 15381 : model1 loss : 0.438164 model2 loss : 0.024965
[11:29:46.958] iteration 15382 : model1 loss : 0.438422 model2 loss : 0.021984
[11:29:47.125] iteration 15383 : model1 loss : 0.436588 model2 loss : 0.023338
[11:29:47.292] iteration 15384 : model1 loss : 0.432549 model2 loss : 0.026355
[11:29:47.461] iteration 15385 : model1 loss : 0.440045 model2 loss : 0.026011
[11:29:47.628] iteration 15386 : model1 loss : 0.436447 model2 loss : 0.022683
[11:29:47.796] iteration 15387 : model1 loss : 0.436600 model2 loss : 0.025387
[11:29:47.963] iteration 15388 : model1 loss : 0.437584 model2 loss : 0.023009
[11:29:48.132] iteration 15389 : model1 loss : 0.434976 model2 loss : 0.020655
[11:29:48.300] iteration 15390 : model1 loss : 0.439139 model2 loss : 0.023948
[11:29:48.469] iteration 15391 : model1 loss : 0.441064 model2 loss : 0.025820
[11:29:48.638] iteration 15392 : model1 loss : 0.434994 model2 loss : 0.024325
[11:29:48.806] iteration 15393 : model1 loss : 0.434942 model2 loss : 0.022155
[11:29:48.974] iteration 15394 : model1 loss : 0.441161 model2 loss : 0.022588
[11:29:49.144] iteration 15395 : model1 loss : 0.434916 model2 loss : 0.021516
[11:29:49.312] iteration 15396 : model1 loss : 0.439976 model2 loss : 0.023453
[11:29:49.484] iteration 15397 : model1 loss : 0.439700 model2 loss : 0.022714
[11:29:49.651] iteration 15398 : model1 loss : 0.439598 model2 loss : 0.021838
[11:29:49.820] iteration 15399 : model1 loss : 0.430821 model2 loss : 0.022211
[11:29:49.986] iteration 15400 : model1 loss : 0.436562 model2 loss : 0.024189
[11:29:50.157] iteration 15401 : model1 loss : 0.436611 model2 loss : 0.023546
[11:29:50.326] iteration 15402 : model1 loss : 0.434339 model2 loss : 0.023762
[11:29:50.497] iteration 15403 : model1 loss : 0.430968 model2 loss : 0.024319
[11:29:50.664] iteration 15404 : model1 loss : 0.441374 model2 loss : 0.025931
[11:29:50.832] iteration 15405 : model1 loss : 0.431410 model2 loss : 0.019685
[11:29:51.000] iteration 15406 : model1 loss : 0.437788 model2 loss : 0.025030
[11:29:51.169] iteration 15407 : model1 loss : 0.438472 model2 loss : 0.024930
[11:29:51.337] iteration 15408 : model1 loss : 0.438578 model2 loss : 0.024184
[11:29:51.508] iteration 15409 : model1 loss : 0.439836 model2 loss : 0.023301
[11:29:51.672] iteration 15410 : model1 loss : 0.435789 model2 loss : 0.025470
[11:29:51.840] iteration 15411 : model1 loss : 0.440726 model2 loss : 0.025504
[11:29:53.766] iteration 15412 : model1 loss : 0.440488 model2 loss : 0.023376
[11:29:53.932] iteration 15413 : model1 loss : 0.437611 model2 loss : 0.021175
[11:29:54.104] iteration 15414 : model1 loss : 0.437026 model2 loss : 0.024306
[11:29:54.272] iteration 15415 : model1 loss : 0.436791 model2 loss : 0.023638
[11:29:54.441] iteration 15416 : model1 loss : 0.434191 model2 loss : 0.021909
[11:29:54.608] iteration 15417 : model1 loss : 0.436945 model2 loss : 0.022990
[11:29:54.786] iteration 15418 : model1 loss : 0.439218 model2 loss : 0.025095
[11:29:54.956] iteration 15419 : model1 loss : 0.439166 model2 loss : 0.019899
[11:29:55.126] iteration 15420 : model1 loss : 0.435181 model2 loss : 0.022001
[11:29:55.294] iteration 15421 : model1 loss : 0.438170 model2 loss : 0.025033
[11:29:55.462] iteration 15422 : model1 loss : 0.439627 model2 loss : 0.025856
[11:29:55.630] iteration 15423 : model1 loss : 0.438219 model2 loss : 0.024398
[11:29:55.799] iteration 15424 : model1 loss : 0.436674 model2 loss : 0.020171
[11:29:55.967] iteration 15425 : model1 loss : 0.438585 model2 loss : 0.023209
[11:29:56.137] iteration 15426 : model1 loss : 0.438120 model2 loss : 0.022068
[11:29:56.307] iteration 15427 : model1 loss : 0.432945 model2 loss : 0.020239
[11:29:56.475] iteration 15428 : model1 loss : 0.439951 model2 loss : 0.029032
[11:29:56.641] iteration 15429 : model1 loss : 0.440312 model2 loss : 0.022386
[11:29:56.811] iteration 15430 : model1 loss : 0.434788 model2 loss : 0.024072
[11:29:56.978] iteration 15431 : model1 loss : 0.435424 model2 loss : 0.021948
[11:29:57.148] iteration 15432 : model1 loss : 0.438695 model2 loss : 0.023338
[11:29:57.316] iteration 15433 : model1 loss : 0.440747 model2 loss : 0.028249
[11:29:57.485] iteration 15434 : model1 loss : 0.435937 model2 loss : 0.024598
[11:29:57.653] iteration 15435 : model1 loss : 0.434947 model2 loss : 0.023099
[11:29:57.823] iteration 15436 : model1 loss : 0.436189 model2 loss : 0.021218
[11:29:57.991] iteration 15437 : model1 loss : 0.435831 model2 loss : 0.022676
[11:29:58.162] iteration 15438 : model1 loss : 0.432058 model2 loss : 0.022499
[11:29:58.329] iteration 15439 : model1 loss : 0.438153 model2 loss : 0.023609
[11:29:58.501] iteration 15440 : model1 loss : 0.436087 model2 loss : 0.020953
[11:29:58.666] iteration 15441 : model1 loss : 0.435791 model2 loss : 0.026607
[11:29:58.835] iteration 15442 : model1 loss : 0.433218 model2 loss : 0.020779
[11:29:58.999] iteration 15443 : model1 loss : 0.438826 model2 loss : 0.026724
[11:29:59.173] iteration 15444 : model1 loss : 0.437859 model2 loss : 0.020848
[11:30:01.105] iteration 15445 : model1 loss : 0.438243 model2 loss : 0.023432
[11:30:01.275] iteration 15446 : model1 loss : 0.440754 model2 loss : 0.022336
[11:30:01.446] iteration 15447 : model1 loss : 0.441502 model2 loss : 0.025952
[11:30:01.616] iteration 15448 : model1 loss : 0.437359 model2 loss : 0.024170
[11:30:01.785] iteration 15449 : model1 loss : 0.433927 model2 loss : 0.021230
[11:30:01.953] iteration 15450 : model1 loss : 0.435069 model2 loss : 0.024591
[11:30:02.123] iteration 15451 : model1 loss : 0.439513 model2 loss : 0.027027
[11:30:02.288] iteration 15452 : model1 loss : 0.438870 model2 loss : 0.024033
[11:30:02.458] iteration 15453 : model1 loss : 0.438174 model2 loss : 0.025542
[11:30:02.625] iteration 15454 : model1 loss : 0.436865 model2 loss : 0.023429
[11:30:02.794] iteration 15455 : model1 loss : 0.435726 model2 loss : 0.020628
[11:30:02.961] iteration 15456 : model1 loss : 0.438241 model2 loss : 0.024860
[11:30:03.129] iteration 15457 : model1 loss : 0.438522 model2 loss : 0.023562
[11:30:03.298] iteration 15458 : model1 loss : 0.438009 model2 loss : 0.023160
[11:30:03.468] iteration 15459 : model1 loss : 0.433595 model2 loss : 0.021189
[11:30:03.648] iteration 15460 : model1 loss : 0.438688 model2 loss : 0.025386
[11:30:03.815] iteration 15461 : model1 loss : 0.434603 model2 loss : 0.021680
[11:30:03.983] iteration 15462 : model1 loss : 0.433737 model2 loss : 0.022064
[11:30:04.152] iteration 15463 : model1 loss : 0.439376 model2 loss : 0.024101
[11:30:04.319] iteration 15464 : model1 loss : 0.440244 model2 loss : 0.025384
[11:30:04.488] iteration 15465 : model1 loss : 0.438427 model2 loss : 0.022945
[11:30:04.657] iteration 15466 : model1 loss : 0.434733 model2 loss : 0.022063
[11:30:04.826] iteration 15467 : model1 loss : 0.438081 model2 loss : 0.024763
[11:30:04.993] iteration 15468 : model1 loss : 0.432458 model2 loss : 0.021369
[11:30:05.163] iteration 15469 : model1 loss : 0.436297 model2 loss : 0.022882
[11:30:05.330] iteration 15470 : model1 loss : 0.437497 model2 loss : 0.022156
[11:30:05.503] iteration 15471 : model1 loss : 0.436070 model2 loss : 0.022689
[11:30:05.672] iteration 15472 : model1 loss : 0.436394 model2 loss : 0.021907
[11:30:05.842] iteration 15473 : model1 loss : 0.433633 model2 loss : 0.021875
[11:30:06.010] iteration 15474 : model1 loss : 0.433720 model2 loss : 0.024594
[11:30:06.179] iteration 15475 : model1 loss : 0.440193 model2 loss : 0.023874
[11:30:06.346] iteration 15476 : model1 loss : 0.440379 model2 loss : 0.023984
[11:30:06.515] iteration 15477 : model1 loss : 0.438068 model2 loss : 0.026430
[11:30:08.432] iteration 15478 : model1 loss : 0.436635 model2 loss : 0.024151
[11:30:08.601] iteration 15479 : model1 loss : 0.437265 model2 loss : 0.025410
[11:30:08.776] iteration 15480 : model1 loss : 0.435621 model2 loss : 0.023682
[11:30:08.942] iteration 15481 : model1 loss : 0.439603 model2 loss : 0.023990
[11:30:09.111] iteration 15482 : model1 loss : 0.438008 model2 loss : 0.022006
[11:30:09.280] iteration 15483 : model1 loss : 0.438809 model2 loss : 0.022114
[11:30:09.451] iteration 15484 : model1 loss : 0.435917 model2 loss : 0.022136
[11:30:09.618] iteration 15485 : model1 loss : 0.437190 model2 loss : 0.022557
[11:30:09.789] iteration 15486 : model1 loss : 0.432283 model2 loss : 0.022479
[11:30:09.962] iteration 15487 : model1 loss : 0.433716 model2 loss : 0.024005
[11:30:10.131] iteration 15488 : model1 loss : 0.438290 model2 loss : 0.022195
[11:30:10.297] iteration 15489 : model1 loss : 0.438482 model2 loss : 0.020834
[11:30:10.466] iteration 15490 : model1 loss : 0.436646 model2 loss : 0.023853
[11:30:10.634] iteration 15491 : model1 loss : 0.436579 model2 loss : 0.022232
[11:30:10.802] iteration 15492 : model1 loss : 0.438414 model2 loss : 0.023152
[11:30:10.970] iteration 15493 : model1 loss : 0.439531 model2 loss : 0.025396
[11:30:11.138] iteration 15494 : model1 loss : 0.436537 model2 loss : 0.023123
[11:30:11.307] iteration 15495 : model1 loss : 0.437219 model2 loss : 0.022905
[11:30:11.476] iteration 15496 : model1 loss : 0.437583 model2 loss : 0.023543
[11:30:11.646] iteration 15497 : model1 loss : 0.434606 model2 loss : 0.023136
[11:30:11.816] iteration 15498 : model1 loss : 0.435514 model2 loss : 0.018832
[11:30:11.982] iteration 15499 : model1 loss : 0.436451 model2 loss : 0.022639
[11:30:12.151] iteration 15500 : model1 loss : 0.436782 model2 loss : 0.027859
[11:30:12.318] iteration 15501 : model1 loss : 0.439568 model2 loss : 0.024856
[11:30:12.487] iteration 15502 : model1 loss : 0.440020 model2 loss : 0.022909
[11:30:12.654] iteration 15503 : model1 loss : 0.439654 model2 loss : 0.025259
[11:30:12.824] iteration 15504 : model1 loss : 0.445641 model2 loss : 0.028208
[11:30:12.992] iteration 15505 : model1 loss : 0.434651 model2 loss : 0.024508
[11:30:13.160] iteration 15506 : model1 loss : 0.436364 model2 loss : 0.024902
[11:30:13.329] iteration 15507 : model1 loss : 0.435808 model2 loss : 0.026367
[11:30:13.498] iteration 15508 : model1 loss : 0.438051 model2 loss : 0.024746
[11:30:13.664] iteration 15509 : model1 loss : 0.437624 model2 loss : 0.024131
[11:30:13.832] iteration 15510 : model1 loss : 0.437310 model2 loss : 0.021979
[11:30:15.736] iteration 15511 : model1 loss : 0.439693 model2 loss : 0.021752
[11:30:15.912] iteration 15512 : model1 loss : 0.436972 model2 loss : 0.022630
[11:30:16.082] iteration 15513 : model1 loss : 0.438910 model2 loss : 0.026177
[11:30:16.250] iteration 15514 : model1 loss : 0.442261 model2 loss : 0.027221
[11:30:16.420] iteration 15515 : model1 loss : 0.441306 model2 loss : 0.025782
[11:30:16.588] iteration 15516 : model1 loss : 0.432427 model2 loss : 0.021778
[11:30:16.758] iteration 15517 : model1 loss : 0.437009 model2 loss : 0.022730
[11:30:16.924] iteration 15518 : model1 loss : 0.436527 model2 loss : 0.021618
[11:30:17.096] iteration 15519 : model1 loss : 0.440935 model2 loss : 0.026026
[11:30:17.264] iteration 15520 : model1 loss : 0.436613 model2 loss : 0.021738
[11:30:17.433] iteration 15521 : model1 loss : 0.438442 model2 loss : 0.028083
[11:30:17.600] iteration 15522 : model1 loss : 0.437829 model2 loss : 0.024780
[11:30:17.768] iteration 15523 : model1 loss : 0.438788 model2 loss : 0.024226
[11:30:17.936] iteration 15524 : model1 loss : 0.436781 model2 loss : 0.024206
[11:30:18.104] iteration 15525 : model1 loss : 0.440379 model2 loss : 0.021944
[11:30:18.275] iteration 15526 : model1 loss : 0.440398 model2 loss : 0.022833
[11:30:18.445] iteration 15527 : model1 loss : 0.433958 model2 loss : 0.023742
[11:30:18.612] iteration 15528 : model1 loss : 0.437642 model2 loss : 0.021100
[11:30:18.782] iteration 15529 : model1 loss : 0.443347 model2 loss : 0.028242
[11:30:18.949] iteration 15530 : model1 loss : 0.433220 model2 loss : 0.020745
[11:30:19.119] iteration 15531 : model1 loss : 0.437056 model2 loss : 0.021009
[11:30:19.290] iteration 15532 : model1 loss : 0.435977 model2 loss : 0.024194
[11:30:19.457] iteration 15533 : model1 loss : 0.438993 model2 loss : 0.022200
[11:30:19.625] iteration 15534 : model1 loss : 0.436936 model2 loss : 0.024186
[11:30:19.795] iteration 15535 : model1 loss : 0.437184 model2 loss : 0.023845
[11:30:19.963] iteration 15536 : model1 loss : 0.435532 model2 loss : 0.022101
[11:30:20.130] iteration 15537 : model1 loss : 0.436459 model2 loss : 0.021567
[11:30:20.300] iteration 15538 : model1 loss : 0.435464 model2 loss : 0.022038
[11:30:20.469] iteration 15539 : model1 loss : 0.437064 model2 loss : 0.023787
[11:30:20.636] iteration 15540 : model1 loss : 0.434516 model2 loss : 0.021024
[11:30:20.806] iteration 15541 : model1 loss : 0.434108 model2 loss : 0.023674
[11:30:20.971] iteration 15542 : model1 loss : 0.436826 model2 loss : 0.023232
[11:30:21.140] iteration 15543 : model1 loss : 0.430951 model2 loss : 0.022526
[11:30:23.079] iteration 15544 : model1 loss : 0.435650 model2 loss : 0.021932
[11:30:23.252] iteration 15545 : model1 loss : 0.437749 model2 loss : 0.023339
[11:30:23.423] iteration 15546 : model1 loss : 0.432869 model2 loss : 0.019897
[11:30:23.590] iteration 15547 : model1 loss : 0.436414 model2 loss : 0.023428
[11:30:23.759] iteration 15548 : model1 loss : 0.439058 model2 loss : 0.024833
[11:30:23.926] iteration 15549 : model1 loss : 0.439835 model2 loss : 0.023847
[11:30:24.097] iteration 15550 : model1 loss : 0.441907 model2 loss : 0.026832
[11:30:24.262] iteration 15551 : model1 loss : 0.440528 model2 loss : 0.024491
[11:30:24.432] iteration 15552 : model1 loss : 0.438778 model2 loss : 0.028331
[11:30:24.599] iteration 15553 : model1 loss : 0.434113 model2 loss : 0.020941
[11:30:24.767] iteration 15554 : model1 loss : 0.437945 model2 loss : 0.022825
[11:30:24.935] iteration 15555 : model1 loss : 0.436777 model2 loss : 0.021979
[11:30:25.105] iteration 15556 : model1 loss : 0.443052 model2 loss : 0.025925
[11:30:25.272] iteration 15557 : model1 loss : 0.442122 model2 loss : 0.023698
[11:30:25.441] iteration 15558 : model1 loss : 0.436798 model2 loss : 0.020824
[11:30:25.610] iteration 15559 : model1 loss : 0.435664 model2 loss : 0.022795
[11:30:25.778] iteration 15560 : model1 loss : 0.437073 model2 loss : 0.026440
[11:30:25.945] iteration 15561 : model1 loss : 0.432135 model2 loss : 0.021359
[11:30:26.116] iteration 15562 : model1 loss : 0.435935 model2 loss : 0.022850
[11:30:26.283] iteration 15563 : model1 loss : 0.438349 model2 loss : 0.026318
[11:30:26.451] iteration 15564 : model1 loss : 0.436332 model2 loss : 0.023105
[11:30:26.619] iteration 15565 : model1 loss : 0.435437 model2 loss : 0.022909
[11:30:26.804] iteration 15566 : model1 loss : 0.438927 model2 loss : 0.025294
[11:30:26.971] iteration 15567 : model1 loss : 0.436389 model2 loss : 0.021768
[11:30:27.141] iteration 15568 : model1 loss : 0.437102 model2 loss : 0.020914
[11:30:27.315] iteration 15569 : model1 loss : 0.433371 model2 loss : 0.023670
[11:30:27.484] iteration 15570 : model1 loss : 0.438330 model2 loss : 0.021886
[11:30:27.651] iteration 15571 : model1 loss : 0.435716 model2 loss : 0.023733
[11:30:27.822] iteration 15572 : model1 loss : 0.435594 model2 loss : 0.022946
[11:30:27.989] iteration 15573 : model1 loss : 0.434052 model2 loss : 0.022747
[11:30:28.160] iteration 15574 : model1 loss : 0.440839 model2 loss : 0.023835
[11:30:28.328] iteration 15575 : model1 loss : 0.439206 model2 loss : 0.020794
[11:30:28.499] iteration 15576 : model1 loss : 0.435838 model2 loss : 0.019972
[11:30:30.422] iteration 15577 : model1 loss : 0.435962 model2 loss : 0.022696
[11:30:30.589] iteration 15578 : model1 loss : 0.436329 model2 loss : 0.024791
[11:30:30.760] iteration 15579 : model1 loss : 0.443255 model2 loss : 0.024404
[11:30:30.927] iteration 15580 : model1 loss : 0.442372 model2 loss : 0.023930
[11:30:31.097] iteration 15581 : model1 loss : 0.438055 model2 loss : 0.021175
[11:30:31.264] iteration 15582 : model1 loss : 0.439109 model2 loss : 0.023977
[11:30:31.434] iteration 15583 : model1 loss : 0.439431 model2 loss : 0.023887
[11:30:31.600] iteration 15584 : model1 loss : 0.438610 model2 loss : 0.023792
[11:30:31.768] iteration 15585 : model1 loss : 0.436201 model2 loss : 0.020752
[11:30:31.936] iteration 15586 : model1 loss : 0.438276 model2 loss : 0.025076
[11:30:32.105] iteration 15587 : model1 loss : 0.433675 model2 loss : 0.022168
[11:30:32.273] iteration 15588 : model1 loss : 0.436853 model2 loss : 0.022602
[11:30:32.443] iteration 15589 : model1 loss : 0.435590 model2 loss : 0.022386
[11:30:32.610] iteration 15590 : model1 loss : 0.435541 model2 loss : 0.023453
[11:30:32.781] iteration 15591 : model1 loss : 0.430864 model2 loss : 0.023432
[11:30:32.948] iteration 15592 : model1 loss : 0.436787 model2 loss : 0.025417
[11:30:33.117] iteration 15593 : model1 loss : 0.436118 model2 loss : 0.021988
[11:30:33.282] iteration 15594 : model1 loss : 0.434821 model2 loss : 0.022342
[11:30:33.452] iteration 15595 : model1 loss : 0.441563 model2 loss : 0.026311
[11:30:33.620] iteration 15596 : model1 loss : 0.436843 model2 loss : 0.023371
[11:30:33.789] iteration 15597 : model1 loss : 0.439015 model2 loss : 0.021544
[11:30:33.958] iteration 15598 : model1 loss : 0.434027 model2 loss : 0.020493
[11:30:34.126] iteration 15599 : model1 loss : 0.440249 model2 loss : 0.024197
[11:30:34.295] iteration 15600 : model1 loss : 0.439603 model2 loss : 0.021793
[11:30:34.464] iteration 15601 : model1 loss : 0.438601 model2 loss : 0.022463
[11:30:34.631] iteration 15602 : model1 loss : 0.437344 model2 loss : 0.024579
[11:30:34.803] iteration 15603 : model1 loss : 0.434558 model2 loss : 0.022071
[11:30:34.969] iteration 15604 : model1 loss : 0.436720 model2 loss : 0.024195
[11:30:35.138] iteration 15605 : model1 loss : 0.438535 model2 loss : 0.022079
[11:30:35.313] iteration 15606 : model1 loss : 0.431415 model2 loss : 0.021507
[11:30:35.483] iteration 15607 : model1 loss : 0.440906 model2 loss : 0.023664
[11:30:35.651] iteration 15608 : model1 loss : 0.437017 model2 loss : 0.021630
[11:30:35.818] iteration 15609 : model1 loss : 0.436201 model2 loss : 0.019971
[11:30:37.748] iteration 15610 : model1 loss : 0.439625 model2 loss : 0.022999
[11:30:37.919] iteration 15611 : model1 loss : 0.435939 model2 loss : 0.021049
[11:30:38.088] iteration 15612 : model1 loss : 0.439437 model2 loss : 0.023974
[11:30:38.256] iteration 15613 : model1 loss : 0.441150 model2 loss : 0.023823
[11:30:38.425] iteration 15614 : model1 loss : 0.437632 model2 loss : 0.024142
[11:30:38.593] iteration 15615 : model1 loss : 0.431285 model2 loss : 0.022837
[11:30:38.763] iteration 15616 : model1 loss : 0.436004 model2 loss : 0.024258
[11:30:38.930] iteration 15617 : model1 loss : 0.437593 model2 loss : 0.022400
[11:30:39.100] iteration 15618 : model1 loss : 0.435581 model2 loss : 0.023647
[11:30:39.265] iteration 15619 : model1 loss : 0.437860 model2 loss : 0.024884
[11:30:39.436] iteration 15620 : model1 loss : 0.433395 model2 loss : 0.023383
[11:30:39.601] iteration 15621 : model1 loss : 0.438303 model2 loss : 0.020519
[11:30:39.770] iteration 15622 : model1 loss : 0.439919 model2 loss : 0.024608
[11:30:39.938] iteration 15623 : model1 loss : 0.437426 model2 loss : 0.022730
[11:30:40.106] iteration 15624 : model1 loss : 0.434011 model2 loss : 0.022958
[11:30:40.274] iteration 15625 : model1 loss : 0.437250 model2 loss : 0.023327
[11:30:40.443] iteration 15626 : model1 loss : 0.436592 model2 loss : 0.024462
[11:30:40.611] iteration 15627 : model1 loss : 0.440724 model2 loss : 0.023730
[11:30:40.779] iteration 15628 : model1 loss : 0.443163 model2 loss : 0.024111
[11:30:40.947] iteration 15629 : model1 loss : 0.434510 model2 loss : 0.023985
[11:30:41.115] iteration 15630 : model1 loss : 0.434750 model2 loss : 0.022027
[11:30:41.282] iteration 15631 : model1 loss : 0.434951 model2 loss : 0.025205
[11:30:41.451] iteration 15632 : model1 loss : 0.436383 model2 loss : 0.024470
[11:30:41.618] iteration 15633 : model1 loss : 0.436878 model2 loss : 0.024034
[11:30:41.786] iteration 15634 : model1 loss : 0.436609 model2 loss : 0.021084
[11:30:41.953] iteration 15635 : model1 loss : 0.442262 model2 loss : 0.025554
[11:30:42.122] iteration 15636 : model1 loss : 0.434445 model2 loss : 0.022354
[11:30:42.291] iteration 15637 : model1 loss : 0.439965 model2 loss : 0.025265
[11:30:42.461] iteration 15638 : model1 loss : 0.437202 model2 loss : 0.021239
[11:30:42.628] iteration 15639 : model1 loss : 0.438936 model2 loss : 0.023694
[11:30:42.799] iteration 15640 : model1 loss : 0.435470 model2 loss : 0.021906
[11:30:42.964] iteration 15641 : model1 loss : 0.437668 model2 loss : 0.024573
[11:30:43.134] iteration 15642 : model1 loss : 0.434892 model2 loss : 0.022218
[11:30:45.070] iteration 15643 : model1 loss : 0.434851 model2 loss : 0.022389
[11:30:45.238] iteration 15644 : model1 loss : 0.439594 model2 loss : 0.022616
[11:30:45.409] iteration 15645 : model1 loss : 0.435871 model2 loss : 0.024088
[11:30:45.575] iteration 15646 : model1 loss : 0.431932 model2 loss : 0.021973
[11:30:45.745] iteration 15647 : model1 loss : 0.436164 model2 loss : 0.024336
[11:30:45.914] iteration 15648 : model1 loss : 0.435811 model2 loss : 0.022498
[11:30:46.085] iteration 15649 : model1 loss : 0.435665 model2 loss : 0.023197
[11:30:46.253] iteration 15650 : model1 loss : 0.438295 model2 loss : 0.022935
[11:30:46.422] iteration 15651 : model1 loss : 0.437250 model2 loss : 0.021060
[11:30:46.588] iteration 15652 : model1 loss : 0.436542 model2 loss : 0.023895
[11:30:46.757] iteration 15653 : model1 loss : 0.436123 model2 loss : 0.022412
[11:30:46.924] iteration 15654 : model1 loss : 0.437507 model2 loss : 0.019883
[11:30:47.093] iteration 15655 : model1 loss : 0.437704 model2 loss : 0.022678
[11:30:47.261] iteration 15656 : model1 loss : 0.442234 model2 loss : 0.023920
[11:30:47.430] iteration 15657 : model1 loss : 0.438130 model2 loss : 0.024452
[11:30:47.599] iteration 15658 : model1 loss : 0.438159 model2 loss : 0.024253
[11:30:47.769] iteration 15659 : model1 loss : 0.437616 model2 loss : 0.022525
[11:30:47.934] iteration 15660 : model1 loss : 0.433655 model2 loss : 0.020462
[11:30:48.103] iteration 15661 : model1 loss : 0.437079 model2 loss : 0.022469
[11:30:48.272] iteration 15662 : model1 loss : 0.434632 model2 loss : 0.021640
[11:30:48.442] iteration 15663 : model1 loss : 0.441022 model2 loss : 0.027662
[11:30:48.612] iteration 15664 : model1 loss : 0.432917 model2 loss : 0.024142
[11:30:48.782] iteration 15665 : model1 loss : 0.436746 model2 loss : 0.019330
[11:30:48.949] iteration 15666 : model1 loss : 0.434306 model2 loss : 0.020258
[11:30:49.118] iteration 15667 : model1 loss : 0.439666 model2 loss : 0.024354
[11:30:49.285] iteration 15668 : model1 loss : 0.442987 model2 loss : 0.026327
[11:30:49.455] iteration 15669 : model1 loss : 0.439356 model2 loss : 0.023002
[11:30:49.624] iteration 15670 : model1 loss : 0.435946 model2 loss : 0.021667
[11:30:49.794] iteration 15671 : model1 loss : 0.438881 model2 loss : 0.024490
[11:30:49.962] iteration 15672 : model1 loss : 0.437094 model2 loss : 0.025230
[11:30:50.131] iteration 15673 : model1 loss : 0.440130 model2 loss : 0.026389
[11:30:50.299] iteration 15674 : model1 loss : 0.440697 model2 loss : 0.021790
[11:30:50.466] iteration 15675 : model1 loss : 0.431979 model2 loss : 0.023573
[11:30:52.395] iteration 15676 : model1 loss : 0.439460 model2 loss : 0.024119
[11:30:52.564] iteration 15677 : model1 loss : 0.433575 model2 loss : 0.019159
[11:30:52.734] iteration 15678 : model1 loss : 0.439951 model2 loss : 0.024437
[11:30:52.911] iteration 15679 : model1 loss : 0.444009 model2 loss : 0.023487
[11:30:53.080] iteration 15680 : model1 loss : 0.432002 model2 loss : 0.021828
[11:30:53.247] iteration 15681 : model1 loss : 0.439267 model2 loss : 0.023854
[11:30:53.414] iteration 15682 : model1 loss : 0.434218 model2 loss : 0.020986
[11:30:53.582] iteration 15683 : model1 loss : 0.436261 model2 loss : 0.021115
[11:30:53.749] iteration 15684 : model1 loss : 0.438114 model2 loss : 0.022737
[11:30:53.917] iteration 15685 : model1 loss : 0.436920 model2 loss : 0.021845
[11:30:54.087] iteration 15686 : model1 loss : 0.437322 model2 loss : 0.023539
[11:30:54.255] iteration 15687 : model1 loss : 0.436086 model2 loss : 0.024135
[11:30:54.423] iteration 15688 : model1 loss : 0.438522 model2 loss : 0.021748
[11:30:54.591] iteration 15689 : model1 loss : 0.432520 model2 loss : 0.023492
[11:30:54.761] iteration 15690 : model1 loss : 0.439141 model2 loss : 0.026294
[11:30:54.930] iteration 15691 : model1 loss : 0.430971 model2 loss : 0.021511
[11:30:55.101] iteration 15692 : model1 loss : 0.435370 model2 loss : 0.024709
[11:30:55.268] iteration 15693 : model1 loss : 0.432929 model2 loss : 0.022341
[11:30:55.441] iteration 15694 : model1 loss : 0.436343 model2 loss : 0.022380
[11:30:55.607] iteration 15695 : model1 loss : 0.440593 model2 loss : 0.023507
[11:30:55.777] iteration 15696 : model1 loss : 0.438361 model2 loss : 0.023251
[11:30:55.947] iteration 15697 : model1 loss : 0.441013 model2 loss : 0.024973
[11:30:56.115] iteration 15698 : model1 loss : 0.436090 model2 loss : 0.021880
[11:30:56.283] iteration 15699 : model1 loss : 0.437672 model2 loss : 0.023860
[11:30:56.452] iteration 15700 : model1 loss : 0.433808 model2 loss : 0.021576
[11:30:56.619] iteration 15701 : model1 loss : 0.434501 model2 loss : 0.021399
[11:30:56.789] iteration 15702 : model1 loss : 0.435725 model2 loss : 0.021877
[11:30:56.957] iteration 15703 : model1 loss : 0.439977 model2 loss : 0.021147
[11:30:57.127] iteration 15704 : model1 loss : 0.437989 model2 loss : 0.022178
[11:30:57.294] iteration 15705 : model1 loss : 0.442117 model2 loss : 0.023607
[11:30:57.464] iteration 15706 : model1 loss : 0.434979 model2 loss : 0.022492
[11:30:57.629] iteration 15707 : model1 loss : 0.439766 model2 loss : 0.025202
[11:30:57.797] iteration 15708 : model1 loss : 0.437979 model2 loss : 0.021155
[11:30:59.756] iteration 15709 : model1 loss : 0.437099 model2 loss : 0.022802
[11:30:59.923] iteration 15710 : model1 loss : 0.437875 model2 loss : 0.023595
[11:31:00.094] iteration 15711 : model1 loss : 0.440561 model2 loss : 0.024319
[11:31:00.259] iteration 15712 : model1 loss : 0.439549 model2 loss : 0.023238
[11:31:00.429] iteration 15713 : model1 loss : 0.439336 model2 loss : 0.022789
[11:31:00.599] iteration 15714 : model1 loss : 0.440404 model2 loss : 0.024610
[11:31:00.768] iteration 15715 : model1 loss : 0.442555 model2 loss : 0.023908
[11:31:00.937] iteration 15716 : model1 loss : 0.438879 model2 loss : 0.020510
[11:31:01.105] iteration 15717 : model1 loss : 0.432801 model2 loss : 0.021634
[11:31:01.274] iteration 15718 : model1 loss : 0.439775 model2 loss : 0.022523
[11:31:01.443] iteration 15719 : model1 loss : 0.437324 model2 loss : 0.023626
[11:31:01.610] iteration 15720 : model1 loss : 0.435145 model2 loss : 0.021972
[11:31:01.780] iteration 15721 : model1 loss : 0.432611 model2 loss : 0.023640
[11:31:01.947] iteration 15722 : model1 loss : 0.433263 model2 loss : 0.020490
[11:31:02.115] iteration 15723 : model1 loss : 0.437196 model2 loss : 0.023277
[11:31:02.284] iteration 15724 : model1 loss : 0.433909 model2 loss : 0.022545
[11:31:02.451] iteration 15725 : model1 loss : 0.433093 model2 loss : 0.022262
[11:31:02.620] iteration 15726 : model1 loss : 0.439597 model2 loss : 0.025413
[11:31:02.788] iteration 15727 : model1 loss : 0.437706 model2 loss : 0.023406
[11:31:02.955] iteration 15728 : model1 loss : 0.436540 model2 loss : 0.023082
[11:31:03.124] iteration 15729 : model1 loss : 0.439388 model2 loss : 0.023006
[11:31:03.290] iteration 15730 : model1 loss : 0.433553 model2 loss : 0.022442
[11:31:03.458] iteration 15731 : model1 loss : 0.439320 model2 loss : 0.025887
[11:31:03.626] iteration 15732 : model1 loss : 0.437484 model2 loss : 0.021399
[11:31:03.799] iteration 15733 : model1 loss : 0.434770 model2 loss : 0.019846
[11:31:03.969] iteration 15734 : model1 loss : 0.436391 model2 loss : 0.024362
[11:31:04.138] iteration 15735 : model1 loss : 0.436476 model2 loss : 0.023695
[11:31:04.306] iteration 15736 : model1 loss : 0.441808 model2 loss : 0.026605
[11:31:04.473] iteration 15737 : model1 loss : 0.438219 model2 loss : 0.023989
[11:31:04.641] iteration 15738 : model1 loss : 0.436257 model2 loss : 0.023923
[11:31:04.812] iteration 15739 : model1 loss : 0.433715 model2 loss : 0.023903
[11:31:04.977] iteration 15740 : model1 loss : 0.439346 model2 loss : 0.022886
[11:31:05.147] iteration 15741 : model1 loss : 0.437700 model2 loss : 0.024161
[11:31:07.136] iteration 15742 : model1 loss : 0.436042 model2 loss : 0.020510
[11:31:07.306] iteration 15743 : model1 loss : 0.434545 model2 loss : 0.020834
[11:31:07.475] iteration 15744 : model1 loss : 0.437295 model2 loss : 0.024748
[11:31:07.644] iteration 15745 : model1 loss : 0.440914 model2 loss : 0.023616
[11:31:07.812] iteration 15746 : model1 loss : 0.439711 model2 loss : 0.024729
[11:31:07.978] iteration 15747 : model1 loss : 0.440853 model2 loss : 0.023649
[11:31:08.147] iteration 15748 : model1 loss : 0.436399 model2 loss : 0.022595
[11:31:08.316] iteration 15749 : model1 loss : 0.437028 model2 loss : 0.023755
[11:31:08.486] iteration 15750 : model1 loss : 0.434764 model2 loss : 0.023128
[11:31:08.654] iteration 15751 : model1 loss : 0.440945 model2 loss : 0.023131
[11:31:08.825] iteration 15752 : model1 loss : 0.433222 model2 loss : 0.023057
[11:31:08.993] iteration 15753 : model1 loss : 0.436206 model2 loss : 0.022124
[11:31:09.163] iteration 15754 : model1 loss : 0.440998 model2 loss : 0.025791
[11:31:09.329] iteration 15755 : model1 loss : 0.437212 model2 loss : 0.023344
[11:31:09.499] iteration 15756 : model1 loss : 0.436366 model2 loss : 0.020976
[11:31:09.665] iteration 15757 : model1 loss : 0.440795 model2 loss : 0.026515
[11:31:09.835] iteration 15758 : model1 loss : 0.439184 model2 loss : 0.022250
[11:31:10.002] iteration 15759 : model1 loss : 0.437321 model2 loss : 0.023614
[11:31:10.172] iteration 15760 : model1 loss : 0.437229 model2 loss : 0.022501
[11:31:10.341] iteration 15761 : model1 loss : 0.440479 model2 loss : 0.024948
[11:31:10.513] iteration 15762 : model1 loss : 0.436473 model2 loss : 0.021372
[11:31:10.680] iteration 15763 : model1 loss : 0.434559 model2 loss : 0.022878
[11:31:10.851] iteration 15764 : model1 loss : 0.436123 model2 loss : 0.024081
[11:31:11.019] iteration 15765 : model1 loss : 0.433951 model2 loss : 0.022162
[11:31:11.188] iteration 15766 : model1 loss : 0.435771 model2 loss : 0.023115
[11:31:11.359] iteration 15767 : model1 loss : 0.433987 model2 loss : 0.024701
[11:31:11.530] iteration 15768 : model1 loss : 0.434249 model2 loss : 0.021183
[11:31:11.696] iteration 15769 : model1 loss : 0.432877 model2 loss : 0.020467
[11:31:11.866] iteration 15770 : model1 loss : 0.439604 model2 loss : 0.024707
[11:31:12.034] iteration 15771 : model1 loss : 0.440970 model2 loss : 0.024678
[11:31:12.205] iteration 15772 : model1 loss : 0.438766 model2 loss : 0.023401
[11:31:12.372] iteration 15773 : model1 loss : 0.440636 model2 loss : 0.022803
[11:31:12.542] iteration 15774 : model1 loss : 0.438180 model2 loss : 0.023819
[11:31:14.492] iteration 15775 : model1 loss : 0.437543 model2 loss : 0.020366
[11:31:14.659] iteration 15776 : model1 loss : 0.442436 model2 loss : 0.023083
[11:31:14.830] iteration 15777 : model1 loss : 0.437269 model2 loss : 0.024292
[11:31:14.998] iteration 15778 : model1 loss : 0.437713 model2 loss : 0.020663
[11:31:15.168] iteration 15779 : model1 loss : 0.437993 model2 loss : 0.023519
[11:31:15.335] iteration 15780 : model1 loss : 0.438343 model2 loss : 0.023337
[11:31:15.508] iteration 15781 : model1 loss : 0.432817 model2 loss : 0.020416
[11:31:15.676] iteration 15782 : model1 loss : 0.432878 model2 loss : 0.021567
[11:31:15.847] iteration 15783 : model1 loss : 0.437761 model2 loss : 0.022647
[11:31:16.015] iteration 15784 : model1 loss : 0.436945 model2 loss : 0.022094
[11:31:16.185] iteration 15785 : model1 loss : 0.432377 model2 loss : 0.019097
[11:31:16.353] iteration 15786 : model1 loss : 0.433031 model2 loss : 0.021411
[11:31:16.525] iteration 15787 : model1 loss : 0.439656 model2 loss : 0.027449
[11:31:16.692] iteration 15788 : model1 loss : 0.437963 model2 loss : 0.022425
[11:31:16.860] iteration 15789 : model1 loss : 0.437393 model2 loss : 0.020645
[11:31:17.028] iteration 15790 : model1 loss : 0.436513 model2 loss : 0.022508
[11:31:17.196] iteration 15791 : model1 loss : 0.435617 model2 loss : 0.022265
[11:31:17.364] iteration 15792 : model1 loss : 0.434542 model2 loss : 0.020219
[11:31:17.537] iteration 15793 : model1 loss : 0.437968 model2 loss : 0.024015
[11:31:17.706] iteration 15794 : model1 loss : 0.439579 model2 loss : 0.027383
[11:31:17.875] iteration 15795 : model1 loss : 0.431127 model2 loss : 0.021125
[11:31:18.042] iteration 15796 : model1 loss : 0.431933 model2 loss : 0.019699
[11:31:18.211] iteration 15797 : model1 loss : 0.442740 model2 loss : 0.027591
[11:31:18.379] iteration 15798 : model1 loss : 0.438002 model2 loss : 0.024857
[11:31:18.549] iteration 15799 : model1 loss : 0.438739 model2 loss : 0.024574
[11:31:18.716] iteration 15800 : model1 loss : 0.437261 model2 loss : 0.023717
[11:31:18.888] iteration 15801 : model1 loss : 0.437572 model2 loss : 0.023962
[11:31:19.071] iteration 15802 : model1 loss : 0.437287 model2 loss : 0.022484
[11:31:19.241] iteration 15803 : model1 loss : 0.438524 model2 loss : 0.025458
[11:31:19.411] iteration 15804 : model1 loss : 0.437307 model2 loss : 0.024495
[11:31:19.582] iteration 15805 : model1 loss : 0.442321 model2 loss : 0.024753
[11:31:19.748] iteration 15806 : model1 loss : 0.437870 model2 loss : 0.023410
[11:31:19.914] iteration 15807 : model1 loss : 0.438143 model2 loss : 0.022698
[11:31:21.913] iteration 15808 : model1 loss : 0.434668 model2 loss : 0.020228
[11:31:22.081] iteration 15809 : model1 loss : 0.435503 model2 loss : 0.022245
[11:31:22.253] iteration 15810 : model1 loss : 0.437986 model2 loss : 0.021965
[11:31:22.421] iteration 15811 : model1 loss : 0.438180 model2 loss : 0.022178
[11:31:22.591] iteration 15812 : model1 loss : 0.441557 model2 loss : 0.023332
[11:31:22.758] iteration 15813 : model1 loss : 0.437465 model2 loss : 0.024260
[11:31:22.927] iteration 15814 : model1 loss : 0.437465 model2 loss : 0.018743
[11:31:23.094] iteration 15815 : model1 loss : 0.433775 model2 loss : 0.022514
[11:31:23.264] iteration 15816 : model1 loss : 0.438259 model2 loss : 0.021764
[11:31:23.430] iteration 15817 : model1 loss : 0.436403 model2 loss : 0.022027
[11:31:23.600] iteration 15818 : model1 loss : 0.439669 model2 loss : 0.021784
[11:31:23.769] iteration 15819 : model1 loss : 0.439273 model2 loss : 0.024294
[11:31:23.938] iteration 15820 : model1 loss : 0.433910 model2 loss : 0.023773
[11:31:24.106] iteration 15821 : model1 loss : 0.439559 model2 loss : 0.025444
[11:31:24.275] iteration 15822 : model1 loss : 0.434692 model2 loss : 0.023413
[11:31:24.444] iteration 15823 : model1 loss : 0.435651 model2 loss : 0.020621
[11:31:24.613] iteration 15824 : model1 loss : 0.436300 model2 loss : 0.025027
[11:31:24.781] iteration 15825 : model1 loss : 0.438519 model2 loss : 0.021227
[11:31:24.952] iteration 15826 : model1 loss : 0.441058 model2 loss : 0.024980
[11:31:25.120] iteration 15827 : model1 loss : 0.431784 model2 loss : 0.021088
[11:31:25.290] iteration 15828 : model1 loss : 0.432552 model2 loss : 0.023427
[11:31:25.461] iteration 15829 : model1 loss : 0.441511 model2 loss : 0.026110
[11:31:25.631] iteration 15830 : model1 loss : 0.435244 model2 loss : 0.021224
[11:31:25.799] iteration 15831 : model1 loss : 0.434756 model2 loss : 0.022464
[11:31:25.969] iteration 15832 : model1 loss : 0.435960 model2 loss : 0.022620
[11:31:26.136] iteration 15833 : model1 loss : 0.436073 model2 loss : 0.021467
[11:31:26.306] iteration 15834 : model1 loss : 0.435709 model2 loss : 0.024184
[11:31:26.473] iteration 15835 : model1 loss : 0.444259 model2 loss : 0.024519
[11:31:26.642] iteration 15836 : model1 loss : 0.437448 model2 loss : 0.025264
[11:31:26.810] iteration 15837 : model1 loss : 0.439139 model2 loss : 0.022389
[11:31:26.980] iteration 15838 : model1 loss : 0.435969 model2 loss : 0.021473
[11:31:27.148] iteration 15839 : model1 loss : 0.438687 model2 loss : 0.021312
[11:31:27.315] iteration 15840 : model1 loss : 0.437446 model2 loss : 0.022473
[11:31:29.280] iteration 15841 : model1 loss : 0.436024 model2 loss : 0.020778
[11:31:29.449] iteration 15842 : model1 loss : 0.435656 model2 loss : 0.022932
[11:31:29.620] iteration 15843 : model1 loss : 0.434936 model2 loss : 0.020702
[11:31:29.788] iteration 15844 : model1 loss : 0.438842 model2 loss : 0.023867
[11:31:29.959] iteration 15845 : model1 loss : 0.436156 model2 loss : 0.021433
[11:31:30.127] iteration 15846 : model1 loss : 0.440830 model2 loss : 0.025294
[11:31:30.297] iteration 15847 : model1 loss : 0.434491 model2 loss : 0.021413
[11:31:30.469] iteration 15848 : model1 loss : 0.435694 model2 loss : 0.021052
[11:31:30.638] iteration 15849 : model1 loss : 0.437319 model2 loss : 0.024211
[11:31:30.806] iteration 15850 : model1 loss : 0.442067 model2 loss : 0.025985
[11:31:30.976] iteration 15851 : model1 loss : 0.438223 model2 loss : 0.023749
[11:31:31.143] iteration 15852 : model1 loss : 0.436961 model2 loss : 0.024062
[11:31:31.313] iteration 15853 : model1 loss : 0.436199 model2 loss : 0.023078
[11:31:31.484] iteration 15854 : model1 loss : 0.434355 model2 loss : 0.023938
[11:31:31.651] iteration 15855 : model1 loss : 0.438127 model2 loss : 0.023806
[11:31:31.819] iteration 15856 : model1 loss : 0.439802 model2 loss : 0.023694
[11:31:31.989] iteration 15857 : model1 loss : 0.435736 model2 loss : 0.024057
[11:31:32.155] iteration 15858 : model1 loss : 0.439894 model2 loss : 0.023185
[11:31:32.325] iteration 15859 : model1 loss : 0.437214 model2 loss : 0.020760
[11:31:32.495] iteration 15860 : model1 loss : 0.437162 model2 loss : 0.019105
[11:31:32.664] iteration 15861 : model1 loss : 0.437934 model2 loss : 0.025744
[11:31:32.831] iteration 15862 : model1 loss : 0.439992 model2 loss : 0.023957
[11:31:33.003] iteration 15863 : model1 loss : 0.432698 model2 loss : 0.020443
[11:31:33.169] iteration 15864 : model1 loss : 0.437673 model2 loss : 0.022853
[11:31:33.338] iteration 15865 : model1 loss : 0.444073 model2 loss : 0.029044
[11:31:33.506] iteration 15866 : model1 loss : 0.438059 model2 loss : 0.022012
[11:31:33.674] iteration 15867 : model1 loss : 0.435336 model2 loss : 0.023394
[11:31:33.842] iteration 15868 : model1 loss : 0.436520 model2 loss : 0.022092
[11:31:34.010] iteration 15869 : model1 loss : 0.433458 model2 loss : 0.022309
[11:31:34.178] iteration 15870 : model1 loss : 0.432927 model2 loss : 0.023588
[11:31:34.349] iteration 15871 : model1 loss : 0.438418 model2 loss : 0.019777
[11:31:34.517] iteration 15872 : model1 loss : 0.437837 model2 loss : 0.024117
[11:31:34.686] iteration 15873 : model1 loss : 0.436201 model2 loss : 0.022701
[11:31:36.624] iteration 15874 : model1 loss : 0.436469 model2 loss : 0.025333
[11:31:36.791] iteration 15875 : model1 loss : 0.435997 model2 loss : 0.020922
[11:31:36.965] iteration 15876 : model1 loss : 0.436702 model2 loss : 0.019502
[11:31:37.132] iteration 15877 : model1 loss : 0.434259 model2 loss : 0.022215
[11:31:37.302] iteration 15878 : model1 loss : 0.436402 model2 loss : 0.022855
[11:31:37.470] iteration 15879 : model1 loss : 0.438607 model2 loss : 0.022750
[11:31:37.639] iteration 15880 : model1 loss : 0.439393 model2 loss : 0.021416
[11:31:37.818] iteration 15881 : model1 loss : 0.434565 model2 loss : 0.022902
[11:31:37.987] iteration 15882 : model1 loss : 0.436438 model2 loss : 0.020768
[11:31:38.155] iteration 15883 : model1 loss : 0.438159 model2 loss : 0.022128
[11:31:38.326] iteration 15884 : model1 loss : 0.437894 model2 loss : 0.024548
[11:31:38.495] iteration 15885 : model1 loss : 0.434390 model2 loss : 0.022844
[11:31:38.667] iteration 15886 : model1 loss : 0.437632 model2 loss : 0.021508
[11:31:38.854] iteration 15887 : model1 loss : 0.437137 model2 loss : 0.021931
[11:31:39.026] iteration 15888 : model1 loss : 0.437277 model2 loss : 0.018133
[11:31:39.195] iteration 15889 : model1 loss : 0.438582 model2 loss : 0.023281
[11:31:39.364] iteration 15890 : model1 loss : 0.433668 model2 loss : 0.020131
[11:31:39.534] iteration 15891 : model1 loss : 0.436302 model2 loss : 0.021585
[11:31:39.703] iteration 15892 : model1 loss : 0.440810 model2 loss : 0.019979
[11:31:39.872] iteration 15893 : model1 loss : 0.440937 model2 loss : 0.027373
[11:31:40.041] iteration 15894 : model1 loss : 0.431836 model2 loss : 0.021276
[11:31:40.210] iteration 15895 : model1 loss : 0.437774 model2 loss : 0.019888
[11:31:40.378] iteration 15896 : model1 loss : 0.434048 model2 loss : 0.023520
[11:31:40.548] iteration 15897 : model1 loss : 0.436585 model2 loss : 0.020562
[11:31:40.717] iteration 15898 : model1 loss : 0.438971 model2 loss : 0.023245
[11:31:40.886] iteration 15899 : model1 loss : 0.442373 model2 loss : 0.022335
[11:31:41.054] iteration 15900 : model1 loss : 0.434501 model2 loss : 0.021403
[11:31:41.222] iteration 15901 : model1 loss : 0.439533 model2 loss : 0.028049
[11:31:41.392] iteration 15902 : model1 loss : 0.442110 model2 loss : 0.023113
[11:31:41.560] iteration 15903 : model1 loss : 0.436076 model2 loss : 0.022283
[11:31:41.730] iteration 15904 : model1 loss : 0.437998 model2 loss : 0.020258
[11:31:41.896] iteration 15905 : model1 loss : 0.442612 model2 loss : 0.028409
[11:31:42.065] iteration 15906 : model1 loss : 0.437172 model2 loss : 0.022272
[11:31:43.981] iteration 15907 : model1 loss : 0.437709 model2 loss : 0.023644
[11:31:44.147] iteration 15908 : model1 loss : 0.439345 model2 loss : 0.021104
[11:31:44.318] iteration 15909 : model1 loss : 0.441775 model2 loss : 0.023003
[11:31:44.487] iteration 15910 : model1 loss : 0.437241 model2 loss : 0.021399
[11:31:44.658] iteration 15911 : model1 loss : 0.435327 model2 loss : 0.021726
[11:31:44.825] iteration 15912 : model1 loss : 0.439887 model2 loss : 0.023827
[11:31:44.992] iteration 15913 : model1 loss : 0.438056 model2 loss : 0.023305
[11:31:45.160] iteration 15914 : model1 loss : 0.440314 model2 loss : 0.024372
[11:31:45.328] iteration 15915 : model1 loss : 0.438939 model2 loss : 0.020816
[11:31:45.500] iteration 15916 : model1 loss : 0.431949 model2 loss : 0.021239
[11:31:45.669] iteration 15917 : model1 loss : 0.441326 model2 loss : 0.025304
[11:31:45.846] iteration 15918 : model1 loss : 0.438162 model2 loss : 0.020335
[11:31:46.018] iteration 15919 : model1 loss : 0.436667 model2 loss : 0.023023
[11:31:46.185] iteration 15920 : model1 loss : 0.437104 model2 loss : 0.022508
[11:31:46.355] iteration 15921 : model1 loss : 0.437741 model2 loss : 0.022419
[11:31:46.524] iteration 15922 : model1 loss : 0.433619 model2 loss : 0.024091
[11:31:46.695] iteration 15923 : model1 loss : 0.436426 model2 loss : 0.021615
[11:31:46.862] iteration 15924 : model1 loss : 0.435456 model2 loss : 0.022919
[11:31:47.033] iteration 15925 : model1 loss : 0.439646 model2 loss : 0.028049
[11:31:47.202] iteration 15926 : model1 loss : 0.435423 model2 loss : 0.020092
[11:31:47.371] iteration 15927 : model1 loss : 0.434484 model2 loss : 0.020842
[11:31:47.541] iteration 15928 : model1 loss : 0.436010 model2 loss : 0.023574
[11:31:47.713] iteration 15929 : model1 loss : 0.437273 model2 loss : 0.023946
[11:31:47.881] iteration 15930 : model1 loss : 0.438580 model2 loss : 0.025339
[11:31:48.049] iteration 15931 : model1 loss : 0.432751 model2 loss : 0.023362
[11:31:48.216] iteration 15932 : model1 loss : 0.438249 model2 loss : 0.023700
[11:31:48.385] iteration 15933 : model1 loss : 0.439233 model2 loss : 0.024379
[11:31:48.554] iteration 15934 : model1 loss : 0.438313 model2 loss : 0.023536
[11:31:48.722] iteration 15935 : model1 loss : 0.433638 model2 loss : 0.022018
[11:31:48.889] iteration 15936 : model1 loss : 0.439672 model2 loss : 0.024760
[11:31:49.059] iteration 15937 : model1 loss : 0.432214 model2 loss : 0.023476
[11:31:49.225] iteration 15938 : model1 loss : 0.441987 model2 loss : 0.028013
[11:31:49.393] iteration 15939 : model1 loss : 0.439248 model2 loss : 0.022040
[11:31:51.317] iteration 15940 : model1 loss : 0.435482 model2 loss : 0.021424
[11:31:51.493] iteration 15941 : model1 loss : 0.440361 model2 loss : 0.028531
[11:31:51.664] iteration 15942 : model1 loss : 0.437243 model2 loss : 0.020224
[11:31:51.833] iteration 15943 : model1 loss : 0.437445 model2 loss : 0.022397
[11:31:52.002] iteration 15944 : model1 loss : 0.431945 model2 loss : 0.024307
[11:31:52.170] iteration 15945 : model1 loss : 0.439036 model2 loss : 0.024095
[11:31:52.343] iteration 15946 : model1 loss : 0.435571 model2 loss : 0.019813
[11:31:52.516] iteration 15947 : model1 loss : 0.436692 model2 loss : 0.019438
[11:31:52.686] iteration 15948 : model1 loss : 0.437263 model2 loss : 0.020871
[11:31:52.854] iteration 15949 : model1 loss : 0.438373 model2 loss : 0.022422
[11:31:53.025] iteration 15950 : model1 loss : 0.439127 model2 loss : 0.024177
[11:31:53.193] iteration 15951 : model1 loss : 0.434856 model2 loss : 0.023712
[11:31:53.362] iteration 15952 : model1 loss : 0.437090 model2 loss : 0.020664
[11:31:53.533] iteration 15953 : model1 loss : 0.440103 model2 loss : 0.021343
[11:31:53.703] iteration 15954 : model1 loss : 0.440668 model2 loss : 0.028481
[11:31:53.871] iteration 15955 : model1 loss : 0.433988 model2 loss : 0.021934
[11:31:54.040] iteration 15956 : model1 loss : 0.438342 model2 loss : 0.022218
[11:31:54.207] iteration 15957 : model1 loss : 0.432291 model2 loss : 0.024357
[11:31:54.375] iteration 15958 : model1 loss : 0.438550 model2 loss : 0.023657
[11:31:54.543] iteration 15959 : model1 loss : 0.436538 model2 loss : 0.023601
[11:31:54.712] iteration 15960 : model1 loss : 0.435520 model2 loss : 0.022460
[11:31:54.880] iteration 15961 : model1 loss : 0.443080 model2 loss : 0.025417
[11:31:55.049] iteration 15962 : model1 loss : 0.436661 model2 loss : 0.021361
[11:31:55.218] iteration 15963 : model1 loss : 0.433341 model2 loss : 0.021625
[11:31:55.388] iteration 15964 : model1 loss : 0.436161 model2 loss : 0.023895
[11:31:55.553] iteration 15965 : model1 loss : 0.439297 model2 loss : 0.023491
[11:31:55.722] iteration 15966 : model1 loss : 0.437019 model2 loss : 0.020150
[11:31:55.893] iteration 15967 : model1 loss : 0.439296 model2 loss : 0.024436
[11:31:56.063] iteration 15968 : model1 loss : 0.439775 model2 loss : 0.021902
[11:31:56.231] iteration 15969 : model1 loss : 0.434534 model2 loss : 0.023491
[11:31:56.399] iteration 15970 : model1 loss : 0.436829 model2 loss : 0.024411
[11:31:56.566] iteration 15971 : model1 loss : 0.435714 model2 loss : 0.023212
[11:31:56.735] iteration 15972 : model1 loss : 0.441734 model2 loss : 0.022054
[11:31:58.707] iteration 15973 : model1 loss : 0.438350 model2 loss : 0.024850
[11:31:58.876] iteration 15974 : model1 loss : 0.439314 model2 loss : 0.023531
[11:31:59.045] iteration 15975 : model1 loss : 0.436118 model2 loss : 0.022087
[11:31:59.212] iteration 15976 : model1 loss : 0.440968 model2 loss : 0.023076
[11:31:59.382] iteration 15977 : model1 loss : 0.432363 model2 loss : 0.022179
[11:31:59.553] iteration 15978 : model1 loss : 0.436837 model2 loss : 0.023503
[11:31:59.723] iteration 15979 : model1 loss : 0.435826 model2 loss : 0.024386
[11:31:59.888] iteration 15980 : model1 loss : 0.441378 model2 loss : 0.022009
[11:32:00.057] iteration 15981 : model1 loss : 0.436163 model2 loss : 0.022445
[11:32:00.224] iteration 15982 : model1 loss : 0.440564 model2 loss : 0.024360
[11:32:00.393] iteration 15983 : model1 loss : 0.436314 model2 loss : 0.021552
[11:32:00.562] iteration 15984 : model1 loss : 0.437586 model2 loss : 0.024552
[11:32:00.733] iteration 15985 : model1 loss : 0.434647 model2 loss : 0.024536
[11:32:00.903] iteration 15986 : model1 loss : 0.440872 model2 loss : 0.025201
[11:32:01.071] iteration 15987 : model1 loss : 0.435950 model2 loss : 0.022479
[11:32:01.238] iteration 15988 : model1 loss : 0.435670 model2 loss : 0.021659
[11:32:01.409] iteration 15989 : model1 loss : 0.435345 model2 loss : 0.020883
[11:32:01.578] iteration 15990 : model1 loss : 0.435713 model2 loss : 0.022624
[11:32:01.749] iteration 15991 : model1 loss : 0.437840 model2 loss : 0.021300
[11:32:01.916] iteration 15992 : model1 loss : 0.437613 model2 loss : 0.024348
[11:32:02.085] iteration 15993 : model1 loss : 0.435446 model2 loss : 0.019684
[11:32:02.252] iteration 15994 : model1 loss : 0.434998 model2 loss : 0.020062
[11:32:02.422] iteration 15995 : model1 loss : 0.437306 model2 loss : 0.022760
[11:32:02.589] iteration 15996 : model1 loss : 0.435741 model2 loss : 0.020946
[11:32:02.758] iteration 15997 : model1 loss : 0.436523 model2 loss : 0.024040
[11:32:02.926] iteration 15998 : model1 loss : 0.435245 model2 loss : 0.021500
[11:32:03.095] iteration 15999 : model1 loss : 0.435068 model2 loss : 0.024832
[11:32:03.264] iteration 16000 : model1 loss : 0.436185 model2 loss : 0.024036
[11:32:11.599] iteration 16000 : model1_mean_dice : 0.892198 model1_mean_hd95 : 3.530453
[11:32:19.923] iteration 16000 : model2_mean_dice : 0.890333 model2_mean_hd95 : 3.898708
[11:32:20.099] iteration 16001 : model1 loss : 0.439169 model2 loss : 0.022639
[11:32:20.272] iteration 16002 : model1 loss : 0.438438 model2 loss : 0.024973
[11:32:20.440] iteration 16003 : model1 loss : 0.442985 model2 loss : 0.028669
[11:32:20.606] iteration 16004 : model1 loss : 0.438671 model2 loss : 0.025044
[11:32:20.770] iteration 16005 : model1 loss : 0.442543 model2 loss : 0.023253
[11:32:22.732] iteration 16006 : model1 loss : 0.438716 model2 loss : 0.024572
[11:32:22.904] iteration 16007 : model1 loss : 0.438967 model2 loss : 0.025232
[11:32:23.075] iteration 16008 : model1 loss : 0.435610 model2 loss : 0.020180
[11:32:23.241] iteration 16009 : model1 loss : 0.438670 model2 loss : 0.023884
[11:32:23.413] iteration 16010 : model1 loss : 0.435795 model2 loss : 0.024404
[11:32:23.579] iteration 16011 : model1 loss : 0.436956 model2 loss : 0.022808
[11:32:23.746] iteration 16012 : model1 loss : 0.432745 model2 loss : 0.022026
[11:32:23.914] iteration 16013 : model1 loss : 0.440500 model2 loss : 0.026100
[11:32:24.082] iteration 16014 : model1 loss : 0.443961 model2 loss : 0.022477
[11:32:24.249] iteration 16015 : model1 loss : 0.439116 model2 loss : 0.024386
[11:32:24.417] iteration 16016 : model1 loss : 0.435423 model2 loss : 0.021171
[11:32:24.584] iteration 16017 : model1 loss : 0.439586 model2 loss : 0.023356
[11:32:24.751] iteration 16018 : model1 loss : 0.444053 model2 loss : 0.026111
[11:32:24.920] iteration 16019 : model1 loss : 0.439460 model2 loss : 0.025903
[11:32:25.087] iteration 16020 : model1 loss : 0.439443 model2 loss : 0.021519
[11:32:25.257] iteration 16021 : model1 loss : 0.436294 model2 loss : 0.021962
[11:32:25.425] iteration 16022 : model1 loss : 0.436038 model2 loss : 0.019469
[11:32:25.591] iteration 16023 : model1 loss : 0.436795 model2 loss : 0.021857
[11:32:25.759] iteration 16024 : model1 loss : 0.439090 model2 loss : 0.021573
[11:32:25.926] iteration 16025 : model1 loss : 0.439782 model2 loss : 0.026254
[11:32:26.095] iteration 16026 : model1 loss : 0.435937 model2 loss : 0.020612
[11:32:26.263] iteration 16027 : model1 loss : 0.438763 model2 loss : 0.023906
[11:32:26.431] iteration 16028 : model1 loss : 0.438119 model2 loss : 0.024363
[11:32:26.596] iteration 16029 : model1 loss : 0.436209 model2 loss : 0.022605
[11:32:26.765] iteration 16030 : model1 loss : 0.437044 model2 loss : 0.020590
[11:32:26.933] iteration 16031 : model1 loss : 0.439137 model2 loss : 0.022181
[11:32:27.104] iteration 16032 : model1 loss : 0.435528 model2 loss : 0.022344
[11:32:27.270] iteration 16033 : model1 loss : 0.437964 model2 loss : 0.020238
[11:32:27.439] iteration 16034 : model1 loss : 0.440636 model2 loss : 0.022965
[11:32:27.605] iteration 16035 : model1 loss : 0.437695 model2 loss : 0.022657
[11:32:27.772] iteration 16036 : model1 loss : 0.438004 model2 loss : 0.026954
[11:32:27.939] iteration 16037 : model1 loss : 0.439734 model2 loss : 0.023368
[11:32:28.105] iteration 16038 : model1 loss : 0.438259 model2 loss : 0.023517
[11:32:30.009] iteration 16039 : model1 loss : 0.437941 model2 loss : 0.020968
[11:32:30.174] iteration 16040 : model1 loss : 0.436125 model2 loss : 0.023658
[11:32:30.344] iteration 16041 : model1 loss : 0.435744 model2 loss : 0.022324
[11:32:30.512] iteration 16042 : model1 loss : 0.439333 model2 loss : 0.024453
[11:32:30.680] iteration 16043 : model1 loss : 0.434308 model2 loss : 0.021611
[11:32:30.848] iteration 16044 : model1 loss : 0.439303 model2 loss : 0.022448
[11:32:31.015] iteration 16045 : model1 loss : 0.433418 model2 loss : 0.021836
[11:32:31.181] iteration 16046 : model1 loss : 0.434499 model2 loss : 0.021037
[11:32:31.350] iteration 16047 : model1 loss : 0.439311 model2 loss : 0.023734
[11:32:31.522] iteration 16048 : model1 loss : 0.434873 model2 loss : 0.020821
[11:32:31.690] iteration 16049 : model1 loss : 0.435804 model2 loss : 0.022552
[11:32:31.857] iteration 16050 : model1 loss : 0.438988 model2 loss : 0.022256
[11:32:32.027] iteration 16051 : model1 loss : 0.442522 model2 loss : 0.023991
[11:32:32.192] iteration 16052 : model1 loss : 0.438015 model2 loss : 0.023914
[11:32:32.361] iteration 16053 : model1 loss : 0.437651 model2 loss : 0.026755
[11:32:32.533] iteration 16054 : model1 loss : 0.439575 model2 loss : 0.024073
[11:32:32.700] iteration 16055 : model1 loss : 0.435585 model2 loss : 0.019576
[11:32:32.868] iteration 16056 : model1 loss : 0.435382 model2 loss : 0.020005
[11:32:33.035] iteration 16057 : model1 loss : 0.437097 model2 loss : 0.020899
[11:32:33.202] iteration 16058 : model1 loss : 0.440350 model2 loss : 0.022682
[11:32:33.370] iteration 16059 : model1 loss : 0.438746 model2 loss : 0.023627
[11:32:33.541] iteration 16060 : model1 loss : 0.438688 model2 loss : 0.023096
[11:32:33.709] iteration 16061 : model1 loss : 0.436526 model2 loss : 0.023322
[11:32:33.876] iteration 16062 : model1 loss : 0.438853 model2 loss : 0.022510
[11:32:34.046] iteration 16063 : model1 loss : 0.438495 model2 loss : 0.025494
[11:32:34.211] iteration 16064 : model1 loss : 0.440185 model2 loss : 0.020791
[11:32:34.381] iteration 16065 : model1 loss : 0.435429 model2 loss : 0.022367
[11:32:34.548] iteration 16066 : model1 loss : 0.440720 model2 loss : 0.022497
[11:32:34.718] iteration 16067 : model1 loss : 0.437645 model2 loss : 0.019680
[11:32:34.884] iteration 16068 : model1 loss : 0.443621 model2 loss : 0.025803
[11:32:35.052] iteration 16069 : model1 loss : 0.435450 model2 loss : 0.023110
[11:32:35.218] iteration 16070 : model1 loss : 0.436125 model2 loss : 0.020940
[11:32:35.385] iteration 16071 : model1 loss : 0.436220 model2 loss : 0.021565
[11:32:37.333] iteration 16072 : model1 loss : 0.436123 model2 loss : 0.024547
[11:32:37.501] iteration 16073 : model1 loss : 0.434250 model2 loss : 0.023727
[11:32:37.673] iteration 16074 : model1 loss : 0.439673 model2 loss : 0.022146
[11:32:37.852] iteration 16075 : model1 loss : 0.435991 model2 loss : 0.021673
[11:32:38.020] iteration 16076 : model1 loss : 0.440760 model2 loss : 0.022384
[11:32:38.187] iteration 16077 : model1 loss : 0.438652 model2 loss : 0.021187
[11:32:38.356] iteration 16078 : model1 loss : 0.439856 model2 loss : 0.023742
[11:32:38.523] iteration 16079 : model1 loss : 0.436701 model2 loss : 0.022012
[11:32:38.691] iteration 16080 : model1 loss : 0.441127 model2 loss : 0.026299
[11:32:38.858] iteration 16081 : model1 loss : 0.436565 model2 loss : 0.021521
[11:32:39.027] iteration 16082 : model1 loss : 0.436075 model2 loss : 0.021233
[11:32:39.193] iteration 16083 : model1 loss : 0.435377 model2 loss : 0.022546
[11:32:39.361] iteration 16084 : model1 loss : 0.437652 model2 loss : 0.021220
[11:32:39.532] iteration 16085 : model1 loss : 0.442103 model2 loss : 0.023644
[11:32:39.701] iteration 16086 : model1 loss : 0.438868 model2 loss : 0.026798
[11:32:39.869] iteration 16087 : model1 loss : 0.434717 model2 loss : 0.020961
[11:32:40.037] iteration 16088 : model1 loss : 0.437400 model2 loss : 0.024923
[11:32:40.203] iteration 16089 : model1 loss : 0.436898 model2 loss : 0.020289
[11:32:40.372] iteration 16090 : model1 loss : 0.435920 model2 loss : 0.021527
[11:32:40.540] iteration 16091 : model1 loss : 0.443411 model2 loss : 0.022877
[11:32:40.708] iteration 16092 : model1 loss : 0.442425 model2 loss : 0.025925
[11:32:40.877] iteration 16093 : model1 loss : 0.436447 model2 loss : 0.020383
[11:32:41.044] iteration 16094 : model1 loss : 0.434790 model2 loss : 0.023527
[11:32:41.210] iteration 16095 : model1 loss : 0.439309 model2 loss : 0.025657
[11:32:41.379] iteration 16096 : model1 loss : 0.440794 model2 loss : 0.024056
[11:32:41.548] iteration 16097 : model1 loss : 0.435079 model2 loss : 0.021862
[11:32:41.717] iteration 16098 : model1 loss : 0.438907 model2 loss : 0.027247
[11:32:41.884] iteration 16099 : model1 loss : 0.436306 model2 loss : 0.022475
[11:32:42.055] iteration 16100 : model1 loss : 0.435472 model2 loss : 0.021743
[11:32:42.222] iteration 16101 : model1 loss : 0.435628 model2 loss : 0.019937
[11:32:42.392] iteration 16102 : model1 loss : 0.437318 model2 loss : 0.023160
[11:32:42.561] iteration 16103 : model1 loss : 0.438627 model2 loss : 0.022617
[11:32:42.730] iteration 16104 : model1 loss : 0.437398 model2 loss : 0.024137
[11:32:44.642] iteration 16105 : model1 loss : 0.435806 model2 loss : 0.020596
[11:32:44.816] iteration 16106 : model1 loss : 0.438768 model2 loss : 0.023540
[11:32:44.985] iteration 16107 : model1 loss : 0.441287 model2 loss : 0.024426
[11:32:45.152] iteration 16108 : model1 loss : 0.439249 model2 loss : 0.019469
[11:32:45.323] iteration 16109 : model1 loss : 0.437115 model2 loss : 0.023552
[11:32:45.492] iteration 16110 : model1 loss : 0.437964 model2 loss : 0.021220
[11:32:45.663] iteration 16111 : model1 loss : 0.439397 model2 loss : 0.023647
[11:32:45.830] iteration 16112 : model1 loss : 0.437146 model2 loss : 0.021897
[11:32:46.007] iteration 16113 : model1 loss : 0.438755 model2 loss : 0.023884
[11:32:46.177] iteration 16114 : model1 loss : 0.432248 model2 loss : 0.023474
[11:32:46.343] iteration 16115 : model1 loss : 0.434477 model2 loss : 0.024551
[11:32:46.511] iteration 16116 : model1 loss : 0.439524 model2 loss : 0.024254
[11:32:46.680] iteration 16117 : model1 loss : 0.439556 model2 loss : 0.023945
[11:32:46.847] iteration 16118 : model1 loss : 0.439717 model2 loss : 0.021187
[11:32:47.017] iteration 16119 : model1 loss : 0.439073 model2 loss : 0.024760
[11:32:47.185] iteration 16120 : model1 loss : 0.433634 model2 loss : 0.020156
[11:32:47.354] iteration 16121 : model1 loss : 0.438134 model2 loss : 0.021652
[11:32:47.525] iteration 16122 : model1 loss : 0.436479 model2 loss : 0.021094
[11:32:47.693] iteration 16123 : model1 loss : 0.437694 model2 loss : 0.020801
[11:32:47.860] iteration 16124 : model1 loss : 0.435306 model2 loss : 0.023556
[11:32:48.028] iteration 16125 : model1 loss : 0.430757 model2 loss : 0.020706
[11:32:48.196] iteration 16126 : model1 loss : 0.438742 model2 loss : 0.021926
[11:32:48.365] iteration 16127 : model1 loss : 0.444848 model2 loss : 0.025649
[11:32:48.533] iteration 16128 : model1 loss : 0.440573 model2 loss : 0.021379
[11:32:48.700] iteration 16129 : model1 loss : 0.432911 model2 loss : 0.023302
[11:32:48.867] iteration 16130 : model1 loss : 0.438540 model2 loss : 0.025940
[11:32:49.035] iteration 16131 : model1 loss : 0.436064 model2 loss : 0.023795
[11:32:49.207] iteration 16132 : model1 loss : 0.439201 model2 loss : 0.021719
[11:32:49.376] iteration 16133 : model1 loss : 0.433317 model2 loss : 0.021267
[11:32:49.545] iteration 16134 : model1 loss : 0.432018 model2 loss : 0.018799
[11:32:49.716] iteration 16135 : model1 loss : 0.436945 model2 loss : 0.023594
[11:32:49.881] iteration 16136 : model1 loss : 0.437626 model2 loss : 0.021270
[11:32:50.049] iteration 16137 : model1 loss : 0.436792 model2 loss : 0.024343
[11:32:51.985] iteration 16138 : model1 loss : 0.439728 model2 loss : 0.024569
[11:32:52.153] iteration 16139 : model1 loss : 0.438955 model2 loss : 0.023648
[11:32:52.324] iteration 16140 : model1 loss : 0.435359 model2 loss : 0.021963
[11:32:52.493] iteration 16141 : model1 loss : 0.435929 model2 loss : 0.021415
[11:32:52.663] iteration 16142 : model1 loss : 0.442434 model2 loss : 0.024396
[11:32:52.831] iteration 16143 : model1 loss : 0.435217 model2 loss : 0.021831
[11:32:53.002] iteration 16144 : model1 loss : 0.434783 model2 loss : 0.022086
[11:32:53.169] iteration 16145 : model1 loss : 0.442990 model2 loss : 0.025018
[11:32:53.340] iteration 16146 : model1 loss : 0.438089 model2 loss : 0.021764
[11:32:53.509] iteration 16147 : model1 loss : 0.435310 model2 loss : 0.023197
[11:32:53.679] iteration 16148 : model1 loss : 0.435706 model2 loss : 0.021035
[11:32:53.847] iteration 16149 : model1 loss : 0.429964 model2 loss : 0.021803
[11:32:54.016] iteration 16150 : model1 loss : 0.436444 model2 loss : 0.023045
[11:32:54.182] iteration 16151 : model1 loss : 0.436305 model2 loss : 0.021837
[11:32:54.353] iteration 16152 : model1 loss : 0.440275 model2 loss : 0.022338
[11:32:54.522] iteration 16153 : model1 loss : 0.437621 model2 loss : 0.021864
[11:32:54.691] iteration 16154 : model1 loss : 0.436469 model2 loss : 0.024432
[11:32:54.859] iteration 16155 : model1 loss : 0.442958 model2 loss : 0.025105
[11:32:55.028] iteration 16156 : model1 loss : 0.441287 model2 loss : 0.022605
[11:32:55.196] iteration 16157 : model1 loss : 0.437482 model2 loss : 0.022924
[11:32:55.367] iteration 16158 : model1 loss : 0.440945 model2 loss : 0.025092
[11:32:55.533] iteration 16159 : model1 loss : 0.438704 model2 loss : 0.023661
[11:32:55.705] iteration 16160 : model1 loss : 0.438444 model2 loss : 0.021420
[11:32:55.874] iteration 16161 : model1 loss : 0.439878 model2 loss : 0.024924
[11:32:56.043] iteration 16162 : model1 loss : 0.437294 model2 loss : 0.024354
[11:32:56.211] iteration 16163 : model1 loss : 0.441572 model2 loss : 0.022150
[11:32:56.380] iteration 16164 : model1 loss : 0.439495 model2 loss : 0.025810
[11:32:56.551] iteration 16165 : model1 loss : 0.439861 model2 loss : 0.019779
[11:32:56.722] iteration 16166 : model1 loss : 0.433290 model2 loss : 0.021234
[11:32:56.889] iteration 16167 : model1 loss : 0.441569 model2 loss : 0.024775
[11:32:57.057] iteration 16168 : model1 loss : 0.437279 model2 loss : 0.021309
[11:32:57.223] iteration 16169 : model1 loss : 0.444424 model2 loss : 0.022449
[11:32:57.391] iteration 16170 : model1 loss : 0.438024 model2 loss : 0.023794
[11:32:59.322] iteration 16171 : model1 loss : 0.441858 model2 loss : 0.022510
[11:32:59.494] iteration 16172 : model1 loss : 0.435716 model2 loss : 0.021245
[11:32:59.664] iteration 16173 : model1 loss : 0.436049 model2 loss : 0.019757
[11:32:59.830] iteration 16174 : model1 loss : 0.445116 model2 loss : 0.024841
[11:32:59.998] iteration 16175 : model1 loss : 0.430988 model2 loss : 0.022064
[11:33:00.167] iteration 16176 : model1 loss : 0.444370 model2 loss : 0.027225
[11:33:00.335] iteration 16177 : model1 loss : 0.437854 model2 loss : 0.022882
[11:33:00.504] iteration 16178 : model1 loss : 0.444239 model2 loss : 0.023990
[11:33:00.672] iteration 16179 : model1 loss : 0.439292 model2 loss : 0.024532
[11:33:00.841] iteration 16180 : model1 loss : 0.439723 model2 loss : 0.025354
[11:33:01.010] iteration 16181 : model1 loss : 0.434872 model2 loss : 0.022419
[11:33:01.178] iteration 16182 : model1 loss : 0.436384 model2 loss : 0.023486
[11:33:01.346] iteration 16183 : model1 loss : 0.439251 model2 loss : 0.023563
[11:33:01.514] iteration 16184 : model1 loss : 0.437739 model2 loss : 0.021550
[11:33:01.682] iteration 16185 : model1 loss : 0.441484 model2 loss : 0.023121
[11:33:01.848] iteration 16186 : model1 loss : 0.437986 model2 loss : 0.021234
[11:33:02.018] iteration 16187 : model1 loss : 0.441199 model2 loss : 0.023547
[11:33:02.185] iteration 16188 : model1 loss : 0.438516 model2 loss : 0.022826
[11:33:02.353] iteration 16189 : model1 loss : 0.437727 model2 loss : 0.020258
[11:33:02.524] iteration 16190 : model1 loss : 0.438438 model2 loss : 0.023461
[11:33:02.692] iteration 16191 : model1 loss : 0.436610 model2 loss : 0.021679
[11:33:02.858] iteration 16192 : model1 loss : 0.440380 model2 loss : 0.022229
[11:33:03.027] iteration 16193 : model1 loss : 0.442831 model2 loss : 0.024460
[11:33:03.193] iteration 16194 : model1 loss : 0.435485 model2 loss : 0.023256
[11:33:03.359] iteration 16195 : model1 loss : 0.437672 model2 loss : 0.021942
[11:33:03.527] iteration 16196 : model1 loss : 0.437905 model2 loss : 0.022975
[11:33:03.694] iteration 16197 : model1 loss : 0.437334 model2 loss : 0.024042
[11:33:03.861] iteration 16198 : model1 loss : 0.434728 model2 loss : 0.022829
[11:33:04.028] iteration 16199 : model1 loss : 0.439947 model2 loss : 0.021880
[11:33:04.197] iteration 16200 : model1 loss : 0.436528 model2 loss : 0.023868
[11:33:04.363] iteration 16201 : model1 loss : 0.432060 model2 loss : 0.022124
[11:33:04.531] iteration 16202 : model1 loss : 0.436528 model2 loss : 0.023387
[11:33:04.699] iteration 16203 : model1 loss : 0.437016 model2 loss : 0.020069
[11:33:06.633] iteration 16204 : model1 loss : 0.441535 model2 loss : 0.022652
[11:33:06.800] iteration 16205 : model1 loss : 0.437682 model2 loss : 0.021802
[11:33:06.967] iteration 16206 : model1 loss : 0.437460 model2 loss : 0.024994
[11:33:07.136] iteration 16207 : model1 loss : 0.435815 model2 loss : 0.022811
[11:33:07.305] iteration 16208 : model1 loss : 0.441693 model2 loss : 0.021444
[11:33:07.472] iteration 16209 : model1 loss : 0.436689 model2 loss : 0.019453
[11:33:07.645] iteration 16210 : model1 loss : 0.435649 model2 loss : 0.020973
[11:33:07.833] iteration 16211 : model1 loss : 0.442811 model2 loss : 0.024852
[11:33:08.004] iteration 16212 : model1 loss : 0.436689 model2 loss : 0.022778
[11:33:08.170] iteration 16213 : model1 loss : 0.437924 model2 loss : 0.021280
[11:33:08.341] iteration 16214 : model1 loss : 0.436988 model2 loss : 0.021921
[11:33:08.509] iteration 16215 : model1 loss : 0.438245 model2 loss : 0.021585
[11:33:08.680] iteration 16216 : model1 loss : 0.434698 model2 loss : 0.021706
[11:33:08.848] iteration 16217 : model1 loss : 0.436609 model2 loss : 0.021695
[11:33:09.017] iteration 16218 : model1 loss : 0.439861 model2 loss : 0.024982
[11:33:09.193] iteration 16219 : model1 loss : 0.437231 model2 loss : 0.022185
[11:33:09.360] iteration 16220 : model1 loss : 0.431135 model2 loss : 0.021550
[11:33:09.532] iteration 16221 : model1 loss : 0.443171 model2 loss : 0.023578
[11:33:09.702] iteration 16222 : model1 loss : 0.433794 model2 loss : 0.022491
[11:33:09.869] iteration 16223 : model1 loss : 0.439417 model2 loss : 0.021101
[11:33:10.038] iteration 16224 : model1 loss : 0.438504 model2 loss : 0.023846
[11:33:10.204] iteration 16225 : model1 loss : 0.441409 model2 loss : 0.022816
[11:33:10.375] iteration 16226 : model1 loss : 0.437224 model2 loss : 0.020494
[11:33:10.543] iteration 16227 : model1 loss : 0.438654 model2 loss : 0.024568
[11:33:10.712] iteration 16228 : model1 loss : 0.435331 model2 loss : 0.022181
[11:33:10.881] iteration 16229 : model1 loss : 0.437728 model2 loss : 0.024212
[11:33:11.051] iteration 16230 : model1 loss : 0.442022 model2 loss : 0.025650
[11:33:11.218] iteration 16231 : model1 loss : 0.435581 model2 loss : 0.022305
[11:33:11.387] iteration 16232 : model1 loss : 0.435957 model2 loss : 0.020719
[11:33:11.553] iteration 16233 : model1 loss : 0.438254 model2 loss : 0.022548
[11:33:11.724] iteration 16234 : model1 loss : 0.440704 model2 loss : 0.026166
[11:33:11.890] iteration 16235 : model1 loss : 0.433854 model2 loss : 0.022014
[11:33:12.059] iteration 16236 : model1 loss : 0.436456 model2 loss : 0.027289
[11:33:13.958] iteration 16237 : model1 loss : 0.437663 model2 loss : 0.021478
[11:33:14.128] iteration 16238 : model1 loss : 0.434653 model2 loss : 0.021180
[11:33:14.300] iteration 16239 : model1 loss : 0.442154 model2 loss : 0.029022
[11:33:14.467] iteration 16240 : model1 loss : 0.436436 model2 loss : 0.020353
[11:33:14.637] iteration 16241 : model1 loss : 0.436436 model2 loss : 0.020568
[11:33:14.803] iteration 16242 : model1 loss : 0.435078 model2 loss : 0.022835
[11:33:14.976] iteration 16243 : model1 loss : 0.436216 model2 loss : 0.025283
[11:33:15.143] iteration 16244 : model1 loss : 0.438363 model2 loss : 0.021766
[11:33:15.312] iteration 16245 : model1 loss : 0.437790 model2 loss : 0.024691
[11:33:15.481] iteration 16246 : model1 loss : 0.441033 model2 loss : 0.024211
[11:33:15.656] iteration 16247 : model1 loss : 0.437237 model2 loss : 0.023386
[11:33:15.824] iteration 16248 : model1 loss : 0.435568 model2 loss : 0.022975
[11:33:15.995] iteration 16249 : model1 loss : 0.438686 model2 loss : 0.024216
[11:33:16.165] iteration 16250 : model1 loss : 0.438549 model2 loss : 0.021642
[11:33:16.334] iteration 16251 : model1 loss : 0.444537 model2 loss : 0.023182
[11:33:16.504] iteration 16252 : model1 loss : 0.437224 model2 loss : 0.021642
[11:33:16.678] iteration 16253 : model1 loss : 0.441362 model2 loss : 0.023588
[11:33:16.845] iteration 16254 : model1 loss : 0.436388 model2 loss : 0.021632
[11:33:17.015] iteration 16255 : model1 loss : 0.441168 model2 loss : 0.023838
[11:33:17.183] iteration 16256 : model1 loss : 0.434121 model2 loss : 0.023600
[11:33:17.352] iteration 16257 : model1 loss : 0.438183 model2 loss : 0.024974
[11:33:17.520] iteration 16258 : model1 loss : 0.436568 model2 loss : 0.021586
[11:33:17.688] iteration 16259 : model1 loss : 0.437021 model2 loss : 0.022731
[11:33:17.853] iteration 16260 : model1 loss : 0.432322 model2 loss : 0.020177
[11:33:18.024] iteration 16261 : model1 loss : 0.437008 model2 loss : 0.023090
[11:33:18.191] iteration 16262 : model1 loss : 0.435003 model2 loss : 0.022965
[11:33:18.363] iteration 16263 : model1 loss : 0.440870 model2 loss : 0.024007
[11:33:18.532] iteration 16264 : model1 loss : 0.437204 model2 loss : 0.023234
[11:33:18.705] iteration 16265 : model1 loss : 0.432941 model2 loss : 0.021254
[11:33:18.870] iteration 16266 : model1 loss : 0.436792 model2 loss : 0.020406
[11:33:19.040] iteration 16267 : model1 loss : 0.434291 model2 loss : 0.021484
[11:33:19.206] iteration 16268 : model1 loss : 0.440087 model2 loss : 0.025602
[11:33:19.376] iteration 16269 : model1 loss : 0.439130 model2 loss : 0.022308
[11:33:21.335] iteration 16270 : model1 loss : 0.438758 model2 loss : 0.024120
[11:33:21.502] iteration 16271 : model1 loss : 0.433888 model2 loss : 0.023891
[11:33:21.676] iteration 16272 : model1 loss : 0.439591 model2 loss : 0.024599
[11:33:21.843] iteration 16273 : model1 loss : 0.435057 model2 loss : 0.020467
[11:33:22.012] iteration 16274 : model1 loss : 0.438615 model2 loss : 0.026417
[11:33:22.178] iteration 16275 : model1 loss : 0.440342 model2 loss : 0.022952
[11:33:22.349] iteration 16276 : model1 loss : 0.442421 model2 loss : 0.026239
[11:33:22.519] iteration 16277 : model1 loss : 0.437555 model2 loss : 0.022188
[11:33:22.691] iteration 16278 : model1 loss : 0.435954 model2 loss : 0.024055
[11:33:22.859] iteration 16279 : model1 loss : 0.438007 model2 loss : 0.022741
[11:33:23.027] iteration 16280 : model1 loss : 0.438769 model2 loss : 0.021518
[11:33:23.195] iteration 16281 : model1 loss : 0.436518 model2 loss : 0.022505
[11:33:23.363] iteration 16282 : model1 loss : 0.440625 model2 loss : 0.024840
[11:33:23.530] iteration 16283 : model1 loss : 0.439822 model2 loss : 0.023189
[11:33:23.703] iteration 16284 : model1 loss : 0.435954 model2 loss : 0.023414
[11:33:23.868] iteration 16285 : model1 loss : 0.440543 model2 loss : 0.020228
[11:33:24.037] iteration 16286 : model1 loss : 0.438525 model2 loss : 0.026043
[11:33:24.202] iteration 16287 : model1 loss : 0.434023 model2 loss : 0.020229
[11:33:24.373] iteration 16288 : model1 loss : 0.435890 model2 loss : 0.025941
[11:33:24.542] iteration 16289 : model1 loss : 0.432995 model2 loss : 0.021398
[11:33:24.713] iteration 16290 : model1 loss : 0.437585 model2 loss : 0.022408
[11:33:24.882] iteration 16291 : model1 loss : 0.438728 model2 loss : 0.023257
[11:33:25.051] iteration 16292 : model1 loss : 0.440432 model2 loss : 0.029762
[11:33:25.218] iteration 16293 : model1 loss : 0.434917 model2 loss : 0.021931
[11:33:25.388] iteration 16294 : model1 loss : 0.438831 model2 loss : 0.025181
[11:33:25.556] iteration 16295 : model1 loss : 0.433849 model2 loss : 0.021333
[11:33:25.728] iteration 16296 : model1 loss : 0.435499 model2 loss : 0.024749
[11:33:25.898] iteration 16297 : model1 loss : 0.433964 model2 loss : 0.023759
[11:33:26.069] iteration 16298 : model1 loss : 0.446159 model2 loss : 0.032094
[11:33:26.234] iteration 16299 : model1 loss : 0.441348 model2 loss : 0.025776
[11:33:26.405] iteration 16300 : model1 loss : 0.438394 model2 loss : 0.024073
[11:33:26.592] iteration 16301 : model1 loss : 0.437124 model2 loss : 0.022516
[11:33:26.760] iteration 16302 : model1 loss : 0.435673 model2 loss : 0.020958
[11:33:28.660] iteration 16303 : model1 loss : 0.435554 model2 loss : 0.023084
[11:33:28.830] iteration 16304 : model1 loss : 0.436009 model2 loss : 0.025006
[11:33:29.000] iteration 16305 : model1 loss : 0.437181 model2 loss : 0.025018
[11:33:29.166] iteration 16306 : model1 loss : 0.438995 model2 loss : 0.029666
[11:33:29.334] iteration 16307 : model1 loss : 0.435057 model2 loss : 0.024253
[11:33:29.502] iteration 16308 : model1 loss : 0.433593 model2 loss : 0.023459
[11:33:29.673] iteration 16309 : model1 loss : 0.439003 model2 loss : 0.027146
[11:33:29.841] iteration 16310 : model1 loss : 0.432327 model2 loss : 0.022948
[11:33:30.009] iteration 16311 : model1 loss : 0.440021 model2 loss : 0.025173
[11:33:30.177] iteration 16312 : model1 loss : 0.440569 model2 loss : 0.026204
[11:33:30.347] iteration 16313 : model1 loss : 0.442446 model2 loss : 0.029193
[11:33:30.515] iteration 16314 : model1 loss : 0.441554 model2 loss : 0.027090
[11:33:30.685] iteration 16315 : model1 loss : 0.439178 model2 loss : 0.027517
[11:33:30.855] iteration 16316 : model1 loss : 0.436940 model2 loss : 0.021823
[11:33:31.024] iteration 16317 : model1 loss : 0.440590 model2 loss : 0.027144
[11:33:31.188] iteration 16318 : model1 loss : 0.440002 model2 loss : 0.027356
[11:33:31.356] iteration 16319 : model1 loss : 0.434169 model2 loss : 0.025530
[11:33:31.523] iteration 16320 : model1 loss : 0.438374 model2 loss : 0.021499
[11:33:31.696] iteration 16321 : model1 loss : 0.435399 model2 loss : 0.026469
[11:33:31.863] iteration 16322 : model1 loss : 0.436395 model2 loss : 0.030880
[11:33:32.031] iteration 16323 : model1 loss : 0.438951 model2 loss : 0.024264
[11:33:32.198] iteration 16324 : model1 loss : 0.439062 model2 loss : 0.023427
[11:33:32.367] iteration 16325 : model1 loss : 0.436195 model2 loss : 0.022186
[11:33:32.536] iteration 16326 : model1 loss : 0.438409 model2 loss : 0.021133
[11:33:32.707] iteration 16327 : model1 loss : 0.429750 model2 loss : 0.021079
[11:33:32.874] iteration 16328 : model1 loss : 0.438106 model2 loss : 0.024841
[11:33:33.044] iteration 16329 : model1 loss : 0.437800 model2 loss : 0.024839
[11:33:33.211] iteration 16330 : model1 loss : 0.439207 model2 loss : 0.026566
[11:33:33.379] iteration 16331 : model1 loss : 0.436198 model2 loss : 0.026826
[11:33:33.548] iteration 16332 : model1 loss : 0.433641 model2 loss : 0.021410
[11:33:33.717] iteration 16333 : model1 loss : 0.441129 model2 loss : 0.027155
[11:33:33.882] iteration 16334 : model1 loss : 0.439431 model2 loss : 0.028254
[11:33:34.052] iteration 16335 : model1 loss : 0.438177 model2 loss : 0.028020
[11:33:36.000] iteration 16336 : model1 loss : 0.437081 model2 loss : 0.026394
[11:33:36.169] iteration 16337 : model1 loss : 0.431594 model2 loss : 0.024132
[11:33:36.339] iteration 16338 : model1 loss : 0.435246 model2 loss : 0.024120
[11:33:36.513] iteration 16339 : model1 loss : 0.436232 model2 loss : 0.025732
[11:33:36.681] iteration 16340 : model1 loss : 0.441129 model2 loss : 0.028574
[11:33:36.846] iteration 16341 : model1 loss : 0.437406 model2 loss : 0.026134
[11:33:37.013] iteration 16342 : model1 loss : 0.438156 model2 loss : 0.021694
[11:33:37.179] iteration 16343 : model1 loss : 0.433926 model2 loss : 0.022979
[11:33:37.348] iteration 16344 : model1 loss : 0.437181 model2 loss : 0.026255
[11:33:37.517] iteration 16345 : model1 loss : 0.439652 model2 loss : 0.023556
[11:33:37.687] iteration 16346 : model1 loss : 0.435080 model2 loss : 0.023623
[11:33:37.855] iteration 16347 : model1 loss : 0.437772 model2 loss : 0.025640
[11:33:38.024] iteration 16348 : model1 loss : 0.440824 model2 loss : 0.026901
[11:33:38.193] iteration 16349 : model1 loss : 0.437741 model2 loss : 0.024769
[11:33:38.362] iteration 16350 : model1 loss : 0.439698 model2 loss : 0.024457
[11:33:38.531] iteration 16351 : model1 loss : 0.437759 model2 loss : 0.026564
[11:33:38.703] iteration 16352 : model1 loss : 0.437992 model2 loss : 0.024189
[11:33:38.871] iteration 16353 : model1 loss : 0.437468 model2 loss : 0.021372
[11:33:39.039] iteration 16354 : model1 loss : 0.440205 model2 loss : 0.022913
[11:33:39.206] iteration 16355 : model1 loss : 0.434157 model2 loss : 0.022653
[11:33:39.376] iteration 16356 : model1 loss : 0.437832 model2 loss : 0.026320
[11:33:39.544] iteration 16357 : model1 loss : 0.436135 model2 loss : 0.026540
[11:33:39.717] iteration 16358 : model1 loss : 0.436319 model2 loss : 0.021496
[11:33:39.886] iteration 16359 : model1 loss : 0.435918 model2 loss : 0.026671
[11:33:40.056] iteration 16360 : model1 loss : 0.441765 model2 loss : 0.024952
[11:33:40.221] iteration 16361 : model1 loss : 0.434482 model2 loss : 0.020527
[11:33:40.415] iteration 16362 : model1 loss : 0.436852 model2 loss : 0.024845
[11:33:40.583] iteration 16363 : model1 loss : 0.434493 model2 loss : 0.022139
[11:33:40.752] iteration 16364 : model1 loss : 0.440356 model2 loss : 0.027108
[11:33:40.920] iteration 16365 : model1 loss : 0.443567 model2 loss : 0.031822
[11:33:41.089] iteration 16366 : model1 loss : 0.439851 model2 loss : 0.024160
[11:33:41.254] iteration 16367 : model1 loss : 0.439718 model2 loss : 0.022959
[11:33:41.422] iteration 16368 : model1 loss : 0.436728 model2 loss : 0.023200
[11:33:43.372] iteration 16369 : model1 loss : 0.438110 model2 loss : 0.021900
[11:33:43.544] iteration 16370 : model1 loss : 0.441079 model2 loss : 0.025645
[11:33:43.719] iteration 16371 : model1 loss : 0.438701 model2 loss : 0.026761
[11:33:43.887] iteration 16372 : model1 loss : 0.438800 model2 loss : 0.025825
[11:33:44.058] iteration 16373 : model1 loss : 0.440943 model2 loss : 0.024388
[11:33:44.226] iteration 16374 : model1 loss : 0.437212 model2 loss : 0.026186
[11:33:44.397] iteration 16375 : model1 loss : 0.443231 model2 loss : 0.028815
[11:33:44.563] iteration 16376 : model1 loss : 0.439357 model2 loss : 0.023218
[11:33:44.732] iteration 16377 : model1 loss : 0.436752 model2 loss : 0.023620
[11:33:44.900] iteration 16378 : model1 loss : 0.438574 model2 loss : 0.025112
[11:33:45.071] iteration 16379 : model1 loss : 0.433798 model2 loss : 0.022102
[11:33:45.238] iteration 16380 : model1 loss : 0.438966 model2 loss : 0.023396
[11:33:45.406] iteration 16381 : model1 loss : 0.436900 model2 loss : 0.024495
[11:33:45.574] iteration 16382 : model1 loss : 0.439379 model2 loss : 0.022845
[11:33:45.746] iteration 16383 : model1 loss : 0.432651 model2 loss : 0.021818
[11:33:45.917] iteration 16384 : model1 loss : 0.442432 model2 loss : 0.026250
[11:33:46.088] iteration 16385 : model1 loss : 0.437533 model2 loss : 0.023712
[11:33:46.255] iteration 16386 : model1 loss : 0.438499 model2 loss : 0.021936
[11:33:46.424] iteration 16387 : model1 loss : 0.434897 model2 loss : 0.023210
[11:33:46.592] iteration 16388 : model1 loss : 0.434293 model2 loss : 0.022535
[11:33:46.760] iteration 16389 : model1 loss : 0.435749 model2 loss : 0.023436
[11:33:46.927] iteration 16390 : model1 loss : 0.433355 model2 loss : 0.023709
[11:33:47.099] iteration 16391 : model1 loss : 0.439999 model2 loss : 0.021796
[11:33:47.265] iteration 16392 : model1 loss : 0.439865 model2 loss : 0.023126
[11:33:47.435] iteration 16393 : model1 loss : 0.439512 model2 loss : 0.026965
[11:33:47.601] iteration 16394 : model1 loss : 0.443918 model2 loss : 0.032091
[11:33:47.770] iteration 16395 : model1 loss : 0.435928 model2 loss : 0.024279
[11:33:47.940] iteration 16396 : model1 loss : 0.434502 model2 loss : 0.024427
[11:33:48.109] iteration 16397 : model1 loss : 0.435045 model2 loss : 0.021387
[11:33:48.276] iteration 16398 : model1 loss : 0.438856 model2 loss : 0.044034
[11:33:48.446] iteration 16399 : model1 loss : 0.435876 model2 loss : 0.024151
[11:33:48.611] iteration 16400 : model1 loss : 0.432958 model2 loss : 0.023104
[11:33:48.780] iteration 16401 : model1 loss : 0.435396 model2 loss : 0.021341
[11:33:50.698] iteration 16402 : model1 loss : 0.434864 model2 loss : 0.025981
[11:33:50.867] iteration 16403 : model1 loss : 0.440021 model2 loss : 0.020534
[11:33:51.038] iteration 16404 : model1 loss : 0.435720 model2 loss : 0.022819
[11:33:51.205] iteration 16405 : model1 loss : 0.440042 model2 loss : 0.028573
[11:33:51.374] iteration 16406 : model1 loss : 0.440135 model2 loss : 0.025142
[11:33:51.541] iteration 16407 : model1 loss : 0.436530 model2 loss : 0.022609
[11:33:51.710] iteration 16408 : model1 loss : 0.437446 model2 loss : 0.022992
[11:33:51.876] iteration 16409 : model1 loss : 0.439039 model2 loss : 0.025574
[11:33:52.045] iteration 16410 : model1 loss : 0.435124 model2 loss : 0.021042
[11:33:52.213] iteration 16411 : model1 loss : 0.437064 model2 loss : 0.022243
[11:33:52.383] iteration 16412 : model1 loss : 0.438520 model2 loss : 0.022727
[11:33:52.550] iteration 16413 : model1 loss : 0.436838 model2 loss : 0.022229
[11:33:52.718] iteration 16414 : model1 loss : 0.440789 model2 loss : 0.023028
[11:33:52.897] iteration 16415 : model1 loss : 0.437491 model2 loss : 0.022832
[11:33:53.067] iteration 16416 : model1 loss : 0.437918 model2 loss : 0.022711
[11:33:53.235] iteration 16417 : model1 loss : 0.434195 model2 loss : 0.022011
[11:33:53.405] iteration 16418 : model1 loss : 0.434795 model2 loss : 0.023368
[11:33:53.573] iteration 16419 : model1 loss : 0.445567 model2 loss : 0.035651
[11:33:53.744] iteration 16420 : model1 loss : 0.436229 model2 loss : 0.020806
[11:33:53.911] iteration 16421 : model1 loss : 0.437286 model2 loss : 0.022787
[11:33:54.079] iteration 16422 : model1 loss : 0.434625 model2 loss : 0.027968
[11:33:54.248] iteration 16423 : model1 loss : 0.441013 model2 loss : 0.025220
[11:33:54.417] iteration 16424 : model1 loss : 0.436509 model2 loss : 0.025891
[11:33:54.583] iteration 16425 : model1 loss : 0.439353 model2 loss : 0.027752
[11:33:54.755] iteration 16426 : model1 loss : 0.438129 model2 loss : 0.027656
[11:33:54.922] iteration 16427 : model1 loss : 0.439709 model2 loss : 0.025217
[11:33:55.092] iteration 16428 : model1 loss : 0.432002 model2 loss : 0.021944
[11:33:55.259] iteration 16429 : model1 loss : 0.438762 model2 loss : 0.022723
[11:33:55.428] iteration 16430 : model1 loss : 0.446452 model2 loss : 0.027411
[11:33:55.596] iteration 16431 : model1 loss : 0.434700 model2 loss : 0.023638
[11:33:55.767] iteration 16432 : model1 loss : 0.433805 model2 loss : 0.024149
[11:33:55.934] iteration 16433 : model1 loss : 0.437075 model2 loss : 0.024127
[11:33:56.102] iteration 16434 : model1 loss : 0.435717 model2 loss : 0.022583
[11:33:58.005] iteration 16435 : model1 loss : 0.434233 model2 loss : 0.022252
[11:33:58.178] iteration 16436 : model1 loss : 0.436752 model2 loss : 0.021166
[11:33:58.351] iteration 16437 : model1 loss : 0.439829 model2 loss : 0.023279
[11:33:58.521] iteration 16438 : model1 loss : 0.439130 model2 loss : 0.023637
[11:33:58.691] iteration 16439 : model1 loss : 0.438190 model2 loss : 0.025073
[11:33:58.858] iteration 16440 : model1 loss : 0.441115 model2 loss : 0.025520
[11:33:59.028] iteration 16441 : model1 loss : 0.435781 model2 loss : 0.023752
[11:33:59.195] iteration 16442 : model1 loss : 0.439534 model2 loss : 0.020469
[11:33:59.364] iteration 16443 : model1 loss : 0.437524 model2 loss : 0.022059
[11:33:59.533] iteration 16444 : model1 loss : 0.438072 model2 loss : 0.023310
[11:33:59.702] iteration 16445 : model1 loss : 0.436070 model2 loss : 0.022515
[11:33:59.869] iteration 16446 : model1 loss : 0.435463 model2 loss : 0.022541
[11:34:00.038] iteration 16447 : model1 loss : 0.437726 model2 loss : 0.024734
[11:34:00.205] iteration 16448 : model1 loss : 0.438368 model2 loss : 0.024200
[11:34:00.375] iteration 16449 : model1 loss : 0.430926 model2 loss : 0.023518
[11:34:00.543] iteration 16450 : model1 loss : 0.438578 model2 loss : 0.025504
[11:34:00.715] iteration 16451 : model1 loss : 0.435214 model2 loss : 0.022653
[11:34:00.883] iteration 16452 : model1 loss : 0.439906 model2 loss : 0.024682
[11:34:01.054] iteration 16453 : model1 loss : 0.440337 model2 loss : 0.022638
[11:34:01.220] iteration 16454 : model1 loss : 0.442248 model2 loss : 0.025865
[11:34:01.390] iteration 16455 : model1 loss : 0.439787 model2 loss : 0.026791
[11:34:01.560] iteration 16456 : model1 loss : 0.432991 model2 loss : 0.024251
[11:34:01.729] iteration 16457 : model1 loss : 0.436459 model2 loss : 0.023775
[11:34:01.898] iteration 16458 : model1 loss : 0.435294 model2 loss : 0.024076
[11:34:02.067] iteration 16459 : model1 loss : 0.436197 model2 loss : 0.020980
[11:34:02.234] iteration 16460 : model1 loss : 0.438742 model2 loss : 0.024339
[11:34:02.403] iteration 16461 : model1 loss : 0.434626 model2 loss : 0.021286
[11:34:02.573] iteration 16462 : model1 loss : 0.440361 model2 loss : 0.030656
[11:34:02.750] iteration 16463 : model1 loss : 0.434161 model2 loss : 0.023242
[11:34:02.916] iteration 16464 : model1 loss : 0.438177 model2 loss : 0.028893
[11:34:03.086] iteration 16465 : model1 loss : 0.438556 model2 loss : 0.024833
[11:34:03.252] iteration 16466 : model1 loss : 0.440315 model2 loss : 0.026863
[11:34:03.422] iteration 16467 : model1 loss : 0.439498 model2 loss : 0.025303
[11:34:05.397] iteration 16468 : model1 loss : 0.434953 model2 loss : 0.025377
[11:34:05.566] iteration 16469 : model1 loss : 0.434831 model2 loss : 0.024363
[11:34:05.735] iteration 16470 : model1 loss : 0.438002 model2 loss : 0.025418
[11:34:05.909] iteration 16471 : model1 loss : 0.438425 model2 loss : 0.025306
[11:34:06.079] iteration 16472 : model1 loss : 0.437556 model2 loss : 0.024581
[11:34:06.247] iteration 16473 : model1 loss : 0.442167 model2 loss : 0.030945
[11:34:06.417] iteration 16474 : model1 loss : 0.438199 model2 loss : 0.022177
[11:34:06.584] iteration 16475 : model1 loss : 0.442610 model2 loss : 0.023041
[11:34:06.754] iteration 16476 : model1 loss : 0.439489 model2 loss : 0.029468
[11:34:06.921] iteration 16477 : model1 loss : 0.438012 model2 loss : 0.023838
[11:34:07.091] iteration 16478 : model1 loss : 0.439694 model2 loss : 0.026239
[11:34:07.260] iteration 16479 : model1 loss : 0.433477 model2 loss : 0.022312
[11:34:07.428] iteration 16480 : model1 loss : 0.432597 model2 loss : 0.024789
[11:34:07.596] iteration 16481 : model1 loss : 0.435521 model2 loss : 0.021375
[11:34:07.766] iteration 16482 : model1 loss : 0.435411 model2 loss : 0.023872
[11:34:07.934] iteration 16483 : model1 loss : 0.436308 model2 loss : 0.022682
[11:34:08.104] iteration 16484 : model1 loss : 0.439450 model2 loss : 0.023744
[11:34:08.270] iteration 16485 : model1 loss : 0.437692 model2 loss : 0.024322
[11:34:08.440] iteration 16486 : model1 loss : 0.434428 model2 loss : 0.022729
[11:34:08.608] iteration 16487 : model1 loss : 0.442606 model2 loss : 0.024093
[11:34:08.781] iteration 16488 : model1 loss : 0.436919 model2 loss : 0.025723
[11:34:08.950] iteration 16489 : model1 loss : 0.435453 model2 loss : 0.022193
[11:34:09.118] iteration 16490 : model1 loss : 0.440147 model2 loss : 0.023603
[11:34:09.286] iteration 16491 : model1 loss : 0.442714 model2 loss : 0.026639
[11:34:09.454] iteration 16492 : model1 loss : 0.432496 model2 loss : 0.023494
[11:34:09.621] iteration 16493 : model1 loss : 0.441929 model2 loss : 0.029072
[11:34:09.794] iteration 16494 : model1 loss : 0.442535 model2 loss : 0.028296
[11:34:09.966] iteration 16495 : model1 loss : 0.436449 model2 loss : 0.022292
[11:34:10.135] iteration 16496 : model1 loss : 0.435666 model2 loss : 0.025320
[11:34:10.302] iteration 16497 : model1 loss : 0.440719 model2 loss : 0.025364
[11:34:10.471] iteration 16498 : model1 loss : 0.437012 model2 loss : 0.024650
[11:34:10.636] iteration 16499 : model1 loss : 0.433368 model2 loss : 0.021856
[11:34:10.805] iteration 16500 : model1 loss : 0.435387 model2 loss : 0.023745
[11:34:12.723] iteration 16501 : model1 loss : 0.438771 model2 loss : 0.021385
[11:34:12.892] iteration 16502 : model1 loss : 0.439068 model2 loss : 0.025766
[11:34:13.064] iteration 16503 : model1 loss : 0.437834 model2 loss : 0.022294
[11:34:13.228] iteration 16504 : model1 loss : 0.431540 model2 loss : 0.022870
[11:34:13.398] iteration 16505 : model1 loss : 0.438467 model2 loss : 0.023599
[11:34:13.565] iteration 16506 : model1 loss : 0.439795 model2 loss : 0.022573
[11:34:13.733] iteration 16507 : model1 loss : 0.437541 model2 loss : 0.022510
[11:34:13.901] iteration 16508 : model1 loss : 0.436365 model2 loss : 0.021225
[11:34:14.072] iteration 16509 : model1 loss : 0.440247 model2 loss : 0.023746
[11:34:14.240] iteration 16510 : model1 loss : 0.435619 model2 loss : 0.024778
[11:34:14.408] iteration 16511 : model1 loss : 0.442064 model2 loss : 0.024195
[11:34:14.576] iteration 16512 : model1 loss : 0.435322 model2 loss : 0.019590
[11:34:14.746] iteration 16513 : model1 loss : 0.434807 model2 loss : 0.023770
[11:34:14.915] iteration 16514 : model1 loss : 0.436285 model2 loss : 0.022940
[11:34:15.084] iteration 16515 : model1 loss : 0.438708 model2 loss : 0.023765
[11:34:15.253] iteration 16516 : model1 loss : 0.440007 model2 loss : 0.024051
[11:34:15.423] iteration 16517 : model1 loss : 0.437240 model2 loss : 0.023759
[11:34:15.591] iteration 16518 : model1 loss : 0.436508 model2 loss : 0.023122
[11:34:15.765] iteration 16519 : model1 loss : 0.434650 model2 loss : 0.022924
[11:34:15.933] iteration 16520 : model1 loss : 0.434139 model2 loss : 0.021823
[11:34:16.103] iteration 16521 : model1 loss : 0.437041 model2 loss : 0.024095
[11:34:16.289] iteration 16522 : model1 loss : 0.442460 model2 loss : 0.026903
[11:34:16.458] iteration 16523 : model1 loss : 0.440512 model2 loss : 0.023466
[11:34:16.625] iteration 16524 : model1 loss : 0.438215 model2 loss : 0.021877
[11:34:16.793] iteration 16525 : model1 loss : 0.438161 model2 loss : 0.020960
[11:34:16.960] iteration 16526 : model1 loss : 0.441151 model2 loss : 0.023737
[11:34:17.129] iteration 16527 : model1 loss : 0.440603 model2 loss : 0.026108
[11:34:17.297] iteration 16528 : model1 loss : 0.437623 model2 loss : 0.022483
[11:34:17.467] iteration 16529 : model1 loss : 0.435089 model2 loss : 0.023200
[11:34:17.634] iteration 16530 : model1 loss : 0.438951 model2 loss : 0.026603
[11:34:17.805] iteration 16531 : model1 loss : 0.434013 model2 loss : 0.027028
[11:34:17.971] iteration 16532 : model1 loss : 0.434928 model2 loss : 0.024369
[11:34:18.138] iteration 16533 : model1 loss : 0.434815 model2 loss : 0.022591
[11:34:20.053] iteration 16534 : model1 loss : 0.437497 model2 loss : 0.024728
[11:34:20.220] iteration 16535 : model1 loss : 0.437618 model2 loss : 0.026161
[11:34:20.389] iteration 16536 : model1 loss : 0.438850 model2 loss : 0.026598
[11:34:20.564] iteration 16537 : model1 loss : 0.439713 model2 loss : 0.027783
[11:34:20.734] iteration 16538 : model1 loss : 0.438306 model2 loss : 0.022794
[11:34:20.904] iteration 16539 : model1 loss : 0.442383 model2 loss : 0.021986
[11:34:21.073] iteration 16540 : model1 loss : 0.437178 model2 loss : 0.021858
[11:34:21.239] iteration 16541 : model1 loss : 0.433178 model2 loss : 0.025275
[11:34:21.408] iteration 16542 : model1 loss : 0.441311 model2 loss : 0.028277
[11:34:21.577] iteration 16543 : model1 loss : 0.436231 model2 loss : 0.023612
[11:34:21.746] iteration 16544 : model1 loss : 0.440021 model2 loss : 0.024837
[11:34:21.914] iteration 16545 : model1 loss : 0.437519 model2 loss : 0.025614
[11:34:22.081] iteration 16546 : model1 loss : 0.432858 model2 loss : 0.022428
[11:34:22.248] iteration 16547 : model1 loss : 0.441305 model2 loss : 0.024068
[11:34:22.417] iteration 16548 : model1 loss : 0.435808 model2 loss : 0.025063
[11:34:22.584] iteration 16549 : model1 loss : 0.439724 model2 loss : 0.023881
[11:34:22.751] iteration 16550 : model1 loss : 0.443559 model2 loss : 0.025409
[11:34:22.921] iteration 16551 : model1 loss : 0.434168 model2 loss : 0.024764
[11:34:23.089] iteration 16552 : model1 loss : 0.433376 model2 loss : 0.022010
[11:34:23.255] iteration 16553 : model1 loss : 0.433842 model2 loss : 0.024755
[11:34:23.425] iteration 16554 : model1 loss : 0.438884 model2 loss : 0.024816
[11:34:23.593] iteration 16555 : model1 loss : 0.433359 model2 loss : 0.020790
[11:34:23.764] iteration 16556 : model1 loss : 0.446164 model2 loss : 0.031945
[11:34:23.933] iteration 16557 : model1 loss : 0.437756 model2 loss : 0.022521
[11:34:24.103] iteration 16558 : model1 loss : 0.438391 model2 loss : 0.024486
[11:34:24.270] iteration 16559 : model1 loss : 0.433329 model2 loss : 0.020444
[11:34:24.439] iteration 16560 : model1 loss : 0.434467 model2 loss : 0.022665
[11:34:24.606] iteration 16561 : model1 loss : 0.439201 model2 loss : 0.024083
[11:34:24.775] iteration 16562 : model1 loss : 0.436279 model2 loss : 0.024502
[11:34:24.942] iteration 16563 : model1 loss : 0.439425 model2 loss : 0.024081
[11:34:25.114] iteration 16564 : model1 loss : 0.440523 model2 loss : 0.022701
[11:34:25.280] iteration 16565 : model1 loss : 0.437171 model2 loss : 0.024016
[11:34:25.447] iteration 16566 : model1 loss : 0.434995 model2 loss : 0.021748
[11:34:27.397] iteration 16567 : model1 loss : 0.437463 model2 loss : 0.022808
[11:34:27.568] iteration 16568 : model1 loss : 0.441006 model2 loss : 0.023357
[11:34:27.741] iteration 16569 : model1 loss : 0.441283 model2 loss : 0.023254
[11:34:27.909] iteration 16570 : model1 loss : 0.435799 model2 loss : 0.026102
[11:34:28.077] iteration 16571 : model1 loss : 0.436980 model2 loss : 0.025632
[11:34:28.244] iteration 16572 : model1 loss : 0.438281 model2 loss : 0.022336
[11:34:28.414] iteration 16573 : model1 loss : 0.439617 model2 loss : 0.025102
[11:34:28.582] iteration 16574 : model1 loss : 0.437739 model2 loss : 0.021595
[11:34:28.751] iteration 16575 : model1 loss : 0.436302 model2 loss : 0.025423
[11:34:28.921] iteration 16576 : model1 loss : 0.436988 model2 loss : 0.020833
[11:34:29.090] iteration 16577 : model1 loss : 0.435439 model2 loss : 0.019828
[11:34:29.256] iteration 16578 : model1 loss : 0.439008 model2 loss : 0.025018
[11:34:29.426] iteration 16579 : model1 loss : 0.436830 model2 loss : 0.022656
[11:34:29.594] iteration 16580 : model1 loss : 0.440664 model2 loss : 0.023271
[11:34:29.763] iteration 16581 : model1 loss : 0.435247 model2 loss : 0.022245
[11:34:29.930] iteration 16582 : model1 loss : 0.438630 model2 loss : 0.022546
[11:34:30.099] iteration 16583 : model1 loss : 0.437233 model2 loss : 0.021460
[11:34:30.267] iteration 16584 : model1 loss : 0.436294 model2 loss : 0.024197
[11:34:30.438] iteration 16585 : model1 loss : 0.438185 model2 loss : 0.023534
[11:34:30.606] iteration 16586 : model1 loss : 0.434810 model2 loss : 0.022201
[11:34:30.776] iteration 16587 : model1 loss : 0.437466 model2 loss : 0.023303
[11:34:30.947] iteration 16588 : model1 loss : 0.435106 model2 loss : 0.021866
[11:34:31.118] iteration 16589 : model1 loss : 0.440315 model2 loss : 0.029297
[11:34:31.287] iteration 16590 : model1 loss : 0.436874 model2 loss : 0.019751
[11:34:31.456] iteration 16591 : model1 loss : 0.435533 model2 loss : 0.020627
[11:34:31.624] iteration 16592 : model1 loss : 0.440722 model2 loss : 0.024848
[11:34:31.793] iteration 16593 : model1 loss : 0.436744 model2 loss : 0.022503
[11:34:31.961] iteration 16594 : model1 loss : 0.438920 model2 loss : 0.027678
[11:34:32.129] iteration 16595 : model1 loss : 0.438068 model2 loss : 0.021449
[11:34:32.295] iteration 16596 : model1 loss : 0.434507 model2 loss : 0.023788
[11:34:32.464] iteration 16597 : model1 loss : 0.435220 model2 loss : 0.024170
[11:34:32.630] iteration 16598 : model1 loss : 0.438309 model2 loss : 0.023620
[11:34:32.799] iteration 16599 : model1 loss : 0.437881 model2 loss : 0.021890
[11:34:34.719] iteration 16600 : model1 loss : 0.437206 model2 loss : 0.021660
[11:34:34.890] iteration 16601 : model1 loss : 0.438639 model2 loss : 0.024034
[11:34:35.060] iteration 16602 : model1 loss : 0.436591 model2 loss : 0.020469
[11:34:35.228] iteration 16603 : model1 loss : 0.432763 model2 loss : 0.020735
[11:34:35.397] iteration 16604 : model1 loss : 0.439307 model2 loss : 0.022753
[11:34:35.562] iteration 16605 : model1 loss : 0.435396 model2 loss : 0.022154
[11:34:35.733] iteration 16606 : model1 loss : 0.438022 model2 loss : 0.024989
[11:34:35.908] iteration 16607 : model1 loss : 0.437769 model2 loss : 0.021450
[11:34:36.078] iteration 16608 : model1 loss : 0.436728 model2 loss : 0.021740
[11:34:36.245] iteration 16609 : model1 loss : 0.433227 model2 loss : 0.021869
[11:34:36.414] iteration 16610 : model1 loss : 0.438284 model2 loss : 0.022770
[11:34:36.582] iteration 16611 : model1 loss : 0.439154 model2 loss : 0.024824
[11:34:36.751] iteration 16612 : model1 loss : 0.437576 model2 loss : 0.021456
[11:34:36.923] iteration 16613 : model1 loss : 0.439834 model2 loss : 0.026382
[11:34:37.105] iteration 16614 : model1 loss : 0.440693 model2 loss : 0.023845
[11:34:37.272] iteration 16615 : model1 loss : 0.437596 model2 loss : 0.021881
[11:34:37.441] iteration 16616 : model1 loss : 0.438035 model2 loss : 0.024145
[11:34:37.610] iteration 16617 : model1 loss : 0.437738 model2 loss : 0.022360
[11:34:37.780] iteration 16618 : model1 loss : 0.432295 model2 loss : 0.024969
[11:34:37.949] iteration 16619 : model1 loss : 0.433918 model2 loss : 0.021991
[11:34:38.119] iteration 16620 : model1 loss : 0.435952 model2 loss : 0.023270
[11:34:38.287] iteration 16621 : model1 loss : 0.435996 model2 loss : 0.026071
[11:34:38.455] iteration 16622 : model1 loss : 0.433878 model2 loss : 0.024322
[11:34:38.622] iteration 16623 : model1 loss : 0.440939 model2 loss : 0.021287
[11:34:38.792] iteration 16624 : model1 loss : 0.440657 model2 loss : 0.024555
[11:34:38.960] iteration 16625 : model1 loss : 0.435743 model2 loss : 0.024046
[11:34:39.128] iteration 16626 : model1 loss : 0.440607 model2 loss : 0.028311
[11:34:39.296] iteration 16627 : model1 loss : 0.437987 model2 loss : 0.020948
[11:34:39.466] iteration 16628 : model1 loss : 0.435922 model2 loss : 0.020976
[11:34:39.635] iteration 16629 : model1 loss : 0.437172 model2 loss : 0.025519
[11:34:39.804] iteration 16630 : model1 loss : 0.442937 model2 loss : 0.026629
[11:34:39.969] iteration 16631 : model1 loss : 0.435176 model2 loss : 0.022425
[11:34:40.138] iteration 16632 : model1 loss : 0.440629 model2 loss : 0.026324
[11:34:42.074] iteration 16633 : model1 loss : 0.441653 model2 loss : 0.021810
[11:34:42.247] iteration 16634 : model1 loss : 0.432186 model2 loss : 0.022307
[11:34:42.417] iteration 16635 : model1 loss : 0.434294 model2 loss : 0.023197
[11:34:42.586] iteration 16636 : model1 loss : 0.434795 model2 loss : 0.021947
[11:34:42.756] iteration 16637 : model1 loss : 0.434695 model2 loss : 0.021979
[11:34:42.924] iteration 16638 : model1 loss : 0.439346 model2 loss : 0.021800
[11:34:43.093] iteration 16639 : model1 loss : 0.435625 model2 loss : 0.022395
[11:34:43.262] iteration 16640 : model1 loss : 0.437032 model2 loss : 0.022653
[11:34:43.433] iteration 16641 : model1 loss : 0.437635 model2 loss : 0.020381
[11:34:43.600] iteration 16642 : model1 loss : 0.435736 model2 loss : 0.023516
[11:34:43.770] iteration 16643 : model1 loss : 0.442142 model2 loss : 0.028662
[11:34:43.940] iteration 16644 : model1 loss : 0.437704 model2 loss : 0.020370
[11:34:44.109] iteration 16645 : model1 loss : 0.439666 model2 loss : 0.022483
[11:34:44.277] iteration 16646 : model1 loss : 0.437921 model2 loss : 0.023645
[11:34:44.446] iteration 16647 : model1 loss : 0.439332 model2 loss : 0.024527
[11:34:44.614] iteration 16648 : model1 loss : 0.434829 model2 loss : 0.021794
[11:34:44.783] iteration 16649 : model1 loss : 0.436543 model2 loss : 0.019765
[11:34:44.953] iteration 16650 : model1 loss : 0.440497 model2 loss : 0.024403
[11:34:45.123] iteration 16651 : model1 loss : 0.434027 model2 loss : 0.023652
[11:34:45.291] iteration 16652 : model1 loss : 0.441616 model2 loss : 0.025793
[11:34:45.459] iteration 16653 : model1 loss : 0.437425 model2 loss : 0.023355
[11:34:45.626] iteration 16654 : model1 loss : 0.437435 model2 loss : 0.022292
[11:34:45.795] iteration 16655 : model1 loss : 0.436150 model2 loss : 0.022319
[11:34:45.963] iteration 16656 : model1 loss : 0.437717 model2 loss : 0.021278
[11:34:46.133] iteration 16657 : model1 loss : 0.435392 model2 loss : 0.020631
[11:34:46.300] iteration 16658 : model1 loss : 0.441543 model2 loss : 0.025588
[11:34:46.469] iteration 16659 : model1 loss : 0.437165 model2 loss : 0.022396
[11:34:46.638] iteration 16660 : model1 loss : 0.438598 model2 loss : 0.024727
[11:34:46.807] iteration 16661 : model1 loss : 0.437717 model2 loss : 0.022586
[11:34:46.973] iteration 16662 : model1 loss : 0.432999 model2 loss : 0.022511
[11:34:47.144] iteration 16663 : model1 loss : 0.438460 model2 loss : 0.022459
[11:34:47.308] iteration 16664 : model1 loss : 0.439512 model2 loss : 0.020025
[11:34:47.477] iteration 16665 : model1 loss : 0.436281 model2 loss : 0.022965
[11:34:49.396] iteration 16666 : model1 loss : 0.434482 model2 loss : 0.021253
[11:34:49.564] iteration 16667 : model1 loss : 0.439539 model2 loss : 0.024689
[11:34:49.735] iteration 16668 : model1 loss : 0.441760 model2 loss : 0.027286
[11:34:49.903] iteration 16669 : model1 loss : 0.442163 model2 loss : 0.027836
[11:34:50.074] iteration 16670 : model1 loss : 0.439472 model2 loss : 0.023006
[11:34:50.245] iteration 16671 : model1 loss : 0.439505 model2 loss : 0.023146
[11:34:50.415] iteration 16672 : model1 loss : 0.438056 model2 loss : 0.023317
[11:34:50.581] iteration 16673 : model1 loss : 0.437459 model2 loss : 0.025397
[11:34:50.751] iteration 16674 : model1 loss : 0.438360 model2 loss : 0.021641
[11:34:50.919] iteration 16675 : model1 loss : 0.436200 model2 loss : 0.021837
[11:34:51.088] iteration 16676 : model1 loss : 0.438326 model2 loss : 0.023796
[11:34:51.257] iteration 16677 : model1 loss : 0.437336 model2 loss : 0.021976
[11:34:51.427] iteration 16678 : model1 loss : 0.431761 model2 loss : 0.021568
[11:34:51.596] iteration 16679 : model1 loss : 0.438380 model2 loss : 0.021435
[11:34:51.765] iteration 16680 : model1 loss : 0.436327 model2 loss : 0.022823
[11:34:51.932] iteration 16681 : model1 loss : 0.436184 model2 loss : 0.022231
[11:34:52.099] iteration 16682 : model1 loss : 0.439168 model2 loss : 0.023236
[11:34:52.267] iteration 16683 : model1 loss : 0.434809 model2 loss : 0.023913
[11:34:52.436] iteration 16684 : model1 loss : 0.439112 model2 loss : 0.024846
[11:34:52.605] iteration 16685 : model1 loss : 0.430864 model2 loss : 0.022153
[11:34:52.776] iteration 16686 : model1 loss : 0.431852 model2 loss : 0.021828
[11:34:52.944] iteration 16687 : model1 loss : 0.442843 model2 loss : 0.027222
[11:34:53.114] iteration 16688 : model1 loss : 0.437521 model2 loss : 0.023487
[11:34:53.281] iteration 16689 : model1 loss : 0.440570 model2 loss : 0.024486
[11:34:53.451] iteration 16690 : model1 loss : 0.441313 model2 loss : 0.024034
[11:34:53.619] iteration 16691 : model1 loss : 0.438881 model2 loss : 0.025830
[11:34:53.787] iteration 16692 : model1 loss : 0.438455 model2 loss : 0.020724
[11:34:53.955] iteration 16693 : model1 loss : 0.440504 model2 loss : 0.025332
[11:34:54.126] iteration 16694 : model1 loss : 0.438507 model2 loss : 0.024654
[11:34:54.293] iteration 16695 : model1 loss : 0.433889 model2 loss : 0.022836
[11:34:54.463] iteration 16696 : model1 loss : 0.438055 model2 loss : 0.021822
[11:34:54.628] iteration 16697 : model1 loss : 0.433834 model2 loss : 0.019428
[11:34:54.796] iteration 16698 : model1 loss : 0.433479 model2 loss : 0.024567
[11:34:56.742] iteration 16699 : model1 loss : 0.438334 model2 loss : 0.023390
[11:34:56.913] iteration 16700 : model1 loss : 0.441476 model2 loss : 0.026033
[11:34:57.085] iteration 16701 : model1 loss : 0.436784 model2 loss : 0.021135
[11:34:57.253] iteration 16702 : model1 loss : 0.438032 model2 loss : 0.022749
[11:34:57.422] iteration 16703 : model1 loss : 0.436885 model2 loss : 0.025888
[11:34:57.589] iteration 16704 : model1 loss : 0.435877 model2 loss : 0.020799
[11:34:57.759] iteration 16705 : model1 loss : 0.434283 model2 loss : 0.021931
[11:34:57.927] iteration 16706 : model1 loss : 0.437929 model2 loss : 0.022646
[11:34:58.098] iteration 16707 : model1 loss : 0.441556 model2 loss : 0.024633
[11:34:58.267] iteration 16708 : model1 loss : 0.438899 model2 loss : 0.027228
[11:34:58.436] iteration 16709 : model1 loss : 0.441848 model2 loss : 0.026750
[11:34:58.605] iteration 16710 : model1 loss : 0.435921 model2 loss : 0.022908
[11:34:58.774] iteration 16711 : model1 loss : 0.432485 model2 loss : 0.023584
[11:34:58.941] iteration 16712 : model1 loss : 0.435988 model2 loss : 0.023152
[11:34:59.110] iteration 16713 : model1 loss : 0.435906 model2 loss : 0.022431
[11:34:59.279] iteration 16714 : model1 loss : 0.434017 model2 loss : 0.020788
[11:34:59.448] iteration 16715 : model1 loss : 0.434662 model2 loss : 0.022159
[11:34:59.618] iteration 16716 : model1 loss : 0.437218 model2 loss : 0.022377
[11:34:59.785] iteration 16717 : model1 loss : 0.434707 model2 loss : 0.021515
[11:34:59.954] iteration 16718 : model1 loss : 0.440194 model2 loss : 0.024709
[11:35:00.126] iteration 16719 : model1 loss : 0.440596 model2 loss : 0.022693
[11:35:00.296] iteration 16720 : model1 loss : 0.440115 model2 loss : 0.025055
[11:35:00.464] iteration 16721 : model1 loss : 0.439598 model2 loss : 0.021394
[11:35:00.633] iteration 16722 : model1 loss : 0.441051 model2 loss : 0.024113
[11:35:00.801] iteration 16723 : model1 loss : 0.434762 model2 loss : 0.025386
[11:35:00.972] iteration 16724 : model1 loss : 0.434837 model2 loss : 0.020632
[11:35:01.141] iteration 16725 : model1 loss : 0.434937 model2 loss : 0.021176
[11:35:01.310] iteration 16726 : model1 loss : 0.438302 model2 loss : 0.024093
[11:35:01.480] iteration 16727 : model1 loss : 0.435357 model2 loss : 0.019614
[11:35:01.647] iteration 16728 : model1 loss : 0.437596 model2 loss : 0.023572
[11:35:01.815] iteration 16729 : model1 loss : 0.436621 model2 loss : 0.024695
[11:35:01.983] iteration 16730 : model1 loss : 0.439901 model2 loss : 0.019980
[11:35:02.151] iteration 16731 : model1 loss : 0.438510 model2 loss : 0.023876
[11:35:04.057] iteration 16732 : model1 loss : 0.437440 model2 loss : 0.023804
[11:35:04.225] iteration 16733 : model1 loss : 0.437045 model2 loss : 0.023109
[11:35:04.394] iteration 16734 : model1 loss : 0.435560 model2 loss : 0.021744
[11:35:04.561] iteration 16735 : model1 loss : 0.434540 model2 loss : 0.023892
[11:35:04.728] iteration 16736 : model1 loss : 0.440303 model2 loss : 0.019629
[11:35:04.897] iteration 16737 : model1 loss : 0.435351 model2 loss : 0.022846
[11:35:05.066] iteration 16738 : model1 loss : 0.439391 model2 loss : 0.022738
[11:35:05.234] iteration 16739 : model1 loss : 0.435849 model2 loss : 0.023685
[11:35:05.405] iteration 16740 : model1 loss : 0.433988 model2 loss : 0.021290
[11:35:05.573] iteration 16741 : model1 loss : 0.436433 model2 loss : 0.023177
[11:35:05.742] iteration 16742 : model1 loss : 0.435599 model2 loss : 0.022872
[11:35:05.913] iteration 16743 : model1 loss : 0.436547 model2 loss : 0.022893
[11:35:06.082] iteration 16744 : model1 loss : 0.440054 model2 loss : 0.024230
[11:35:06.249] iteration 16745 : model1 loss : 0.436127 model2 loss : 0.022110
[11:35:06.420] iteration 16746 : model1 loss : 0.438050 model2 loss : 0.024194
[11:35:06.586] iteration 16747 : model1 loss : 0.437179 model2 loss : 0.022765
[11:35:06.756] iteration 16748 : model1 loss : 0.435952 model2 loss : 0.021607
[11:35:06.923] iteration 16749 : model1 loss : 0.435748 model2 loss : 0.023174
[11:35:07.092] iteration 16750 : model1 loss : 0.440619 model2 loss : 0.024296
[11:35:07.261] iteration 16751 : model1 loss : 0.435361 model2 loss : 0.021286
[11:35:07.428] iteration 16752 : model1 loss : 0.438124 model2 loss : 0.024117
[11:35:07.596] iteration 16753 : model1 loss : 0.440515 model2 loss : 0.023259
[11:35:07.765] iteration 16754 : model1 loss : 0.436767 model2 loss : 0.023386
[11:35:07.933] iteration 16755 : model1 loss : 0.436561 model2 loss : 0.021387
[11:35:08.103] iteration 16756 : model1 loss : 0.441002 model2 loss : 0.024202
[11:35:08.270] iteration 16757 : model1 loss : 0.438364 model2 loss : 0.022726
[11:35:08.440] iteration 16758 : model1 loss : 0.433924 model2 loss : 0.020647
[11:35:08.608] iteration 16759 : model1 loss : 0.438821 model2 loss : 0.022220
[11:35:08.777] iteration 16760 : model1 loss : 0.437741 model2 loss : 0.025380
[11:35:08.945] iteration 16761 : model1 loss : 0.441565 model2 loss : 0.021161
[11:35:09.113] iteration 16762 : model1 loss : 0.437026 model2 loss : 0.019985
[11:35:09.281] iteration 16763 : model1 loss : 0.436131 model2 loss : 0.022362
[11:35:09.449] iteration 16764 : model1 loss : 0.440685 model2 loss : 0.022882
[11:35:11.393] iteration 16765 : model1 loss : 0.441623 model2 loss : 0.024027
[11:35:11.566] iteration 16766 : model1 loss : 0.439085 model2 loss : 0.022494
[11:35:11.739] iteration 16767 : model1 loss : 0.433051 model2 loss : 0.022180
[11:35:11.905] iteration 16768 : model1 loss : 0.436735 model2 loss : 0.023067
[11:35:12.075] iteration 16769 : model1 loss : 0.436205 model2 loss : 0.021551
[11:35:12.243] iteration 16770 : model1 loss : 0.436364 model2 loss : 0.023626
[11:35:12.414] iteration 16771 : model1 loss : 0.434307 model2 loss : 0.023845
[11:35:12.580] iteration 16772 : model1 loss : 0.441664 model2 loss : 0.023870
[11:35:12.749] iteration 16773 : model1 loss : 0.438923 model2 loss : 0.022422
[11:35:12.918] iteration 16774 : model1 loss : 0.436163 model2 loss : 0.023523
[11:35:13.094] iteration 16775 : model1 loss : 0.438011 model2 loss : 0.024897
[11:35:13.262] iteration 16776 : model1 loss : 0.443465 model2 loss : 0.022715
[11:35:13.430] iteration 16777 : model1 loss : 0.431821 model2 loss : 0.022367
[11:35:13.599] iteration 16778 : model1 loss : 0.437981 model2 loss : 0.021369
[11:35:13.769] iteration 16779 : model1 loss : 0.436521 model2 loss : 0.020889
[11:35:13.937] iteration 16780 : model1 loss : 0.439849 model2 loss : 0.026692
[11:35:14.106] iteration 16781 : model1 loss : 0.443792 model2 loss : 0.025332
[11:35:14.275] iteration 16782 : model1 loss : 0.437419 model2 loss : 0.027523
[11:35:14.445] iteration 16783 : model1 loss : 0.432254 model2 loss : 0.024189
[11:35:14.612] iteration 16784 : model1 loss : 0.438895 model2 loss : 0.022757
[11:35:14.783] iteration 16785 : model1 loss : 0.435122 model2 loss : 0.023053
[11:35:14.948] iteration 16786 : model1 loss : 0.433629 model2 loss : 0.026315
[11:35:15.118] iteration 16787 : model1 loss : 0.437425 model2 loss : 0.027815
[11:35:15.284] iteration 16788 : model1 loss : 0.441341 model2 loss : 0.024250
[11:35:15.454] iteration 16789 : model1 loss : 0.437639 model2 loss : 0.028972
[11:35:15.620] iteration 16790 : model1 loss : 0.448285 model2 loss : 0.029327
[11:35:15.789] iteration 16791 : model1 loss : 0.436555 model2 loss : 0.024736
[11:35:15.956] iteration 16792 : model1 loss : 0.442256 model2 loss : 0.027943
[11:35:16.123] iteration 16793 : model1 loss : 0.436332 model2 loss : 0.022934
[11:35:16.291] iteration 16794 : model1 loss : 0.438414 model2 loss : 0.023673
[11:35:16.460] iteration 16795 : model1 loss : 0.439187 model2 loss : 0.030392
[11:35:16.627] iteration 16796 : model1 loss : 0.438769 model2 loss : 0.026136
[11:35:16.795] iteration 16797 : model1 loss : 0.440066 model2 loss : 0.024169
[11:35:18.736] iteration 16798 : model1 loss : 0.438083 model2 loss : 0.027404
[11:35:18.904] iteration 16799 : model1 loss : 0.438773 model2 loss : 0.022574
[11:35:19.073] iteration 16800 : model1 loss : 0.439969 model2 loss : 0.028744
[11:35:19.241] iteration 16801 : model1 loss : 0.437607 model2 loss : 0.021530
[11:35:19.410] iteration 16802 : model1 loss : 0.437603 model2 loss : 0.027695
[11:35:19.577] iteration 16803 : model1 loss : 0.439562 model2 loss : 0.027301
[11:35:19.748] iteration 16804 : model1 loss : 0.442215 model2 loss : 0.024167
[11:35:19.916] iteration 16805 : model1 loss : 0.443353 model2 loss : 0.026418
[11:35:20.086] iteration 16806 : model1 loss : 0.438085 model2 loss : 0.022602
[11:35:20.251] iteration 16807 : model1 loss : 0.437184 model2 loss : 0.024668
[11:35:20.420] iteration 16808 : model1 loss : 0.431970 model2 loss : 0.021570
[11:35:20.596] iteration 16809 : model1 loss : 0.438396 model2 loss : 0.026300
[11:35:20.765] iteration 16810 : model1 loss : 0.440577 model2 loss : 0.023657
[11:35:20.932] iteration 16811 : model1 loss : 0.438757 model2 loss : 0.030873
[11:35:21.100] iteration 16812 : model1 loss : 0.437864 model2 loss : 0.025114
[11:35:21.268] iteration 16813 : model1 loss : 0.439555 model2 loss : 0.028755
[11:35:21.436] iteration 16814 : model1 loss : 0.436860 model2 loss : 0.024350
[11:35:21.604] iteration 16815 : model1 loss : 0.435585 model2 loss : 0.023395
[11:35:21.773] iteration 16816 : model1 loss : 0.434790 model2 loss : 0.023466
[11:35:21.942] iteration 16817 : model1 loss : 0.436848 model2 loss : 0.026986
[11:35:22.111] iteration 16818 : model1 loss : 0.436548 model2 loss : 0.023370
[11:35:22.278] iteration 16819 : model1 loss : 0.440066 model2 loss : 0.026532
[11:35:22.446] iteration 16820 : model1 loss : 0.438215 model2 loss : 0.023267
[11:35:22.613] iteration 16821 : model1 loss : 0.432781 model2 loss : 0.022611
[11:35:22.783] iteration 16822 : model1 loss : 0.437931 model2 loss : 0.024102
[11:35:22.950] iteration 16823 : model1 loss : 0.436085 model2 loss : 0.025191
[11:35:23.119] iteration 16824 : model1 loss : 0.439611 model2 loss : 0.026826
[11:35:23.287] iteration 16825 : model1 loss : 0.439583 model2 loss : 0.024286
[11:35:23.456] iteration 16826 : model1 loss : 0.434878 model2 loss : 0.026382
[11:35:23.625] iteration 16827 : model1 loss : 0.433452 model2 loss : 0.021519
[11:35:23.792] iteration 16828 : model1 loss : 0.439451 model2 loss : 0.026249
[11:35:23.958] iteration 16829 : model1 loss : 0.437775 model2 loss : 0.023331
[11:35:24.126] iteration 16830 : model1 loss : 0.434911 model2 loss : 0.020864
[11:35:26.206] iteration 16831 : model1 loss : 0.440145 model2 loss : 0.024743
[11:35:26.374] iteration 16832 : model1 loss : 0.437410 model2 loss : 0.025114
[11:35:26.545] iteration 16833 : model1 loss : 0.439517 model2 loss : 0.024401
[11:35:26.714] iteration 16834 : model1 loss : 0.436065 model2 loss : 0.028082
[11:35:26.885] iteration 16835 : model1 loss : 0.442802 model2 loss : 0.025286
[11:35:27.056] iteration 16836 : model1 loss : 0.440884 model2 loss : 0.023990
[11:35:27.229] iteration 16837 : model1 loss : 0.434862 model2 loss : 0.021690
[11:35:27.397] iteration 16838 : model1 loss : 0.442097 model2 loss : 0.022573
[11:35:27.565] iteration 16839 : model1 loss : 0.436652 model2 loss : 0.024543
[11:35:27.731] iteration 16840 : model1 loss : 0.439189 model2 loss : 0.023897
[11:35:27.899] iteration 16841 : model1 loss : 0.438982 model2 loss : 0.028153
[11:35:28.068] iteration 16842 : model1 loss : 0.434905 model2 loss : 0.020842
[11:35:28.238] iteration 16843 : model1 loss : 0.439019 model2 loss : 0.023109
[11:35:28.406] iteration 16844 : model1 loss : 0.437372 model2 loss : 0.023686
[11:35:28.575] iteration 16845 : model1 loss : 0.436821 model2 loss : 0.024519
[11:35:28.744] iteration 16846 : model1 loss : 0.437005 model2 loss : 0.021587
[11:35:28.913] iteration 16847 : model1 loss : 0.436469 model2 loss : 0.023429
[11:35:29.085] iteration 16848 : model1 loss : 0.432271 model2 loss : 0.021252
[11:35:29.254] iteration 16849 : model1 loss : 0.438673 model2 loss : 0.023040
[11:35:29.422] iteration 16850 : model1 loss : 0.435840 model2 loss : 0.025820
[11:35:29.617] iteration 16851 : model1 loss : 0.439203 model2 loss : 0.024921
[11:35:29.785] iteration 16852 : model1 loss : 0.432801 model2 loss : 0.023236
[11:35:29.958] iteration 16853 : model1 loss : 0.441525 model2 loss : 0.025694
[11:35:30.125] iteration 16854 : model1 loss : 0.438734 model2 loss : 0.021584
[11:35:30.295] iteration 16855 : model1 loss : 0.437146 model2 loss : 0.023225
[11:35:30.465] iteration 16856 : model1 loss : 0.434926 model2 loss : 0.023579
[11:35:30.635] iteration 16857 : model1 loss : 0.437082 model2 loss : 0.021495
[11:35:30.803] iteration 16858 : model1 loss : 0.435678 model2 loss : 0.022793
[11:35:30.974] iteration 16859 : model1 loss : 0.437053 model2 loss : 0.020528
[11:35:31.141] iteration 16860 : model1 loss : 0.436390 model2 loss : 0.022784
[11:35:31.312] iteration 16861 : model1 loss : 0.441892 model2 loss : 0.024940
[11:35:31.480] iteration 16862 : model1 loss : 0.439889 model2 loss : 0.021477
[11:35:31.646] iteration 16863 : model1 loss : 0.437553 model2 loss : 0.024433
[11:35:33.593] iteration 16864 : model1 loss : 0.436398 model2 loss : 0.022049
[11:35:33.762] iteration 16865 : model1 loss : 0.437705 model2 loss : 0.023739
[11:35:33.930] iteration 16866 : model1 loss : 0.439168 model2 loss : 0.022557
[11:35:34.097] iteration 16867 : model1 loss : 0.439951 model2 loss : 0.025161
[11:35:34.266] iteration 16868 : model1 loss : 0.441721 model2 loss : 0.023636
[11:35:34.433] iteration 16869 : model1 loss : 0.435696 model2 loss : 0.022808
[11:35:34.602] iteration 16870 : model1 loss : 0.440923 model2 loss : 0.026827
[11:35:34.770] iteration 16871 : model1 loss : 0.432162 model2 loss : 0.020684
[11:35:34.941] iteration 16872 : model1 loss : 0.437927 model2 loss : 0.022880
[11:35:35.108] iteration 16873 : model1 loss : 0.437782 model2 loss : 0.023848
[11:35:35.277] iteration 16874 : model1 loss : 0.438141 model2 loss : 0.024973
[11:35:35.444] iteration 16875 : model1 loss : 0.439551 model2 loss : 0.023249
[11:35:35.613] iteration 16876 : model1 loss : 0.437427 model2 loss : 0.020772
[11:35:35.779] iteration 16877 : model1 loss : 0.433656 model2 loss : 0.020945
[11:35:35.947] iteration 16878 : model1 loss : 0.439380 model2 loss : 0.021941
[11:35:36.114] iteration 16879 : model1 loss : 0.434350 model2 loss : 0.021105
[11:35:36.285] iteration 16880 : model1 loss : 0.434848 model2 loss : 0.023371
[11:35:36.452] iteration 16881 : model1 loss : 0.438895 model2 loss : 0.024310
[11:35:36.624] iteration 16882 : model1 loss : 0.435969 model2 loss : 0.023532
[11:35:36.791] iteration 16883 : model1 loss : 0.436347 model2 loss : 0.022751
[11:35:36.960] iteration 16884 : model1 loss : 0.438030 model2 loss : 0.021582
[11:35:37.127] iteration 16885 : model1 loss : 0.434128 model2 loss : 0.020986
[11:35:37.296] iteration 16886 : model1 loss : 0.433372 model2 loss : 0.021281
[11:35:37.465] iteration 16887 : model1 loss : 0.439329 model2 loss : 0.021790
[11:35:37.636] iteration 16888 : model1 loss : 0.440912 model2 loss : 0.025010
[11:35:37.802] iteration 16889 : model1 loss : 0.441069 model2 loss : 0.023323
[11:35:37.972] iteration 16890 : model1 loss : 0.436895 model2 loss : 0.021590
[11:35:38.142] iteration 16891 : model1 loss : 0.441743 model2 loss : 0.022114
[11:35:38.313] iteration 16892 : model1 loss : 0.437556 model2 loss : 0.021337
[11:35:38.481] iteration 16893 : model1 loss : 0.433399 model2 loss : 0.024769
[11:35:38.649] iteration 16894 : model1 loss : 0.436531 model2 loss : 0.021934
[11:35:38.814] iteration 16895 : model1 loss : 0.439186 model2 loss : 0.022072
[11:35:38.982] iteration 16896 : model1 loss : 0.439065 model2 loss : 0.022133
[11:35:40.891] iteration 16897 : model1 loss : 0.432462 model2 loss : 0.021182
[11:35:41.062] iteration 16898 : model1 loss : 0.436294 model2 loss : 0.020480
[11:35:41.230] iteration 16899 : model1 loss : 0.441448 model2 loss : 0.021124
[11:35:41.395] iteration 16900 : model1 loss : 0.441124 model2 loss : 0.025709
[11:35:41.568] iteration 16901 : model1 loss : 0.437439 model2 loss : 0.022078
[11:35:41.734] iteration 16902 : model1 loss : 0.439206 model2 loss : 0.022668
[11:35:41.904] iteration 16903 : model1 loss : 0.434266 model2 loss : 0.021813
[11:35:42.072] iteration 16904 : model1 loss : 0.441978 model2 loss : 0.024421
[11:35:42.242] iteration 16905 : model1 loss : 0.439188 model2 loss : 0.024754
[11:35:42.431] iteration 16906 : model1 loss : 0.438977 model2 loss : 0.026162
[11:35:42.600] iteration 16907 : model1 loss : 0.442591 model2 loss : 0.025906
[11:35:42.765] iteration 16908 : model1 loss : 0.437315 model2 loss : 0.022709
[11:35:42.935] iteration 16909 : model1 loss : 0.435363 model2 loss : 0.024050
[11:35:43.106] iteration 16910 : model1 loss : 0.436983 model2 loss : 0.020622
[11:35:43.275] iteration 16911 : model1 loss : 0.437988 model2 loss : 0.023074
[11:35:43.443] iteration 16912 : model1 loss : 0.436351 model2 loss : 0.022899
[11:35:43.614] iteration 16913 : model1 loss : 0.441662 model2 loss : 0.022950
[11:35:43.791] iteration 16914 : model1 loss : 0.432196 model2 loss : 0.021257
[11:35:43.962] iteration 16915 : model1 loss : 0.440144 model2 loss : 0.026373
[11:35:44.130] iteration 16916 : model1 loss : 0.434597 model2 loss : 0.020502
[11:35:44.300] iteration 16917 : model1 loss : 0.440209 model2 loss : 0.022748
[11:35:44.467] iteration 16918 : model1 loss : 0.438783 model2 loss : 0.022365
[11:35:44.634] iteration 16919 : model1 loss : 0.440637 model2 loss : 0.025424
[11:35:44.803] iteration 16920 : model1 loss : 0.436375 model2 loss : 0.022472
[11:35:44.972] iteration 16921 : model1 loss : 0.431580 model2 loss : 0.021333
[11:35:45.140] iteration 16922 : model1 loss : 0.437134 model2 loss : 0.023734
[11:35:45.309] iteration 16923 : model1 loss : 0.433703 model2 loss : 0.021266
[11:35:45.474] iteration 16924 : model1 loss : 0.434438 model2 loss : 0.025126
[11:35:45.644] iteration 16925 : model1 loss : 0.437858 model2 loss : 0.023281
[11:35:45.813] iteration 16926 : model1 loss : 0.439863 model2 loss : 0.019515
[11:35:45.985] iteration 16927 : model1 loss : 0.436903 model2 loss : 0.023615
[11:35:46.151] iteration 16928 : model1 loss : 0.436137 model2 loss : 0.021685
[11:35:46.320] iteration 16929 : model1 loss : 0.436503 model2 loss : 0.021166
[11:35:48.272] iteration 16930 : model1 loss : 0.439691 model2 loss : 0.019969
[11:35:48.443] iteration 16931 : model1 loss : 0.438043 model2 loss : 0.025371
[11:35:48.627] iteration 16932 : model1 loss : 0.439133 model2 loss : 0.022817
[11:35:48.795] iteration 16933 : model1 loss : 0.441678 model2 loss : 0.024740
[11:35:48.964] iteration 16934 : model1 loss : 0.441038 model2 loss : 0.024156
[11:35:49.132] iteration 16935 : model1 loss : 0.435692 model2 loss : 0.025093
[11:35:49.301] iteration 16936 : model1 loss : 0.438924 model2 loss : 0.022693
[11:35:49.469] iteration 16937 : model1 loss : 0.432533 model2 loss : 0.021742
[11:35:49.638] iteration 16938 : model1 loss : 0.436536 model2 loss : 0.021118
[11:35:49.806] iteration 16939 : model1 loss : 0.434071 model2 loss : 0.022587
[11:35:49.974] iteration 16940 : model1 loss : 0.437340 model2 loss : 0.022930
[11:35:50.142] iteration 16941 : model1 loss : 0.436852 model2 loss : 0.020782
[11:35:50.311] iteration 16942 : model1 loss : 0.436510 model2 loss : 0.024354
[11:35:50.478] iteration 16943 : model1 loss : 0.438680 model2 loss : 0.022483
[11:35:50.656] iteration 16944 : model1 loss : 0.435246 model2 loss : 0.021381
[11:35:50.822] iteration 16945 : model1 loss : 0.437512 model2 loss : 0.023476
[11:35:50.990] iteration 16946 : model1 loss : 0.439745 model2 loss : 0.022597
[11:35:51.156] iteration 16947 : model1 loss : 0.439699 model2 loss : 0.023065
[11:35:51.328] iteration 16948 : model1 loss : 0.439575 model2 loss : 0.024167
[11:35:51.492] iteration 16949 : model1 loss : 0.440470 model2 loss : 0.019192
[11:35:51.662] iteration 16950 : model1 loss : 0.436279 model2 loss : 0.022995
[11:35:51.830] iteration 16951 : model1 loss : 0.437389 model2 loss : 0.022667
[11:35:52.000] iteration 16952 : model1 loss : 0.440009 model2 loss : 0.024680
[11:35:52.169] iteration 16953 : model1 loss : 0.436054 model2 loss : 0.021831
[11:35:52.339] iteration 16954 : model1 loss : 0.434887 model2 loss : 0.023242
[11:35:52.508] iteration 16955 : model1 loss : 0.433265 model2 loss : 0.022719
[11:35:52.677] iteration 16956 : model1 loss : 0.434290 model2 loss : 0.022079
[11:35:52.846] iteration 16957 : model1 loss : 0.436884 model2 loss : 0.022578
[11:35:53.016] iteration 16958 : model1 loss : 0.430490 model2 loss : 0.018107
[11:35:53.184] iteration 16959 : model1 loss : 0.434271 model2 loss : 0.024785
[11:35:53.354] iteration 16960 : model1 loss : 0.445147 model2 loss : 0.028427
[11:35:53.522] iteration 16961 : model1 loss : 0.440227 model2 loss : 0.025716
[11:35:53.691] iteration 16962 : model1 loss : 0.439349 model2 loss : 0.025156
[11:35:55.619] iteration 16963 : model1 loss : 0.443773 model2 loss : 0.028007
[11:35:55.787] iteration 16964 : model1 loss : 0.435403 model2 loss : 0.023231
[11:35:55.956] iteration 16965 : model1 loss : 0.436795 model2 loss : 0.022210
[11:35:56.125] iteration 16966 : model1 loss : 0.436415 model2 loss : 0.021701
[11:35:56.293] iteration 16967 : model1 loss : 0.436215 model2 loss : 0.022594
[11:35:56.461] iteration 16968 : model1 loss : 0.436975 model2 loss : 0.022255
[11:35:56.627] iteration 16969 : model1 loss : 0.440852 model2 loss : 0.022736
[11:35:56.793] iteration 16970 : model1 loss : 0.433762 model2 loss : 0.021029
[11:35:56.962] iteration 16971 : model1 loss : 0.434780 model2 loss : 0.021839
[11:35:57.130] iteration 16972 : model1 loss : 0.437555 model2 loss : 0.022444
[11:35:57.301] iteration 16973 : model1 loss : 0.438415 model2 loss : 0.021184
[11:35:57.469] iteration 16974 : model1 loss : 0.440825 model2 loss : 0.023712
[11:35:57.638] iteration 16975 : model1 loss : 0.435034 model2 loss : 0.020670
[11:35:57.806] iteration 16976 : model1 loss : 0.438313 model2 loss : 0.024412
[11:35:57.977] iteration 16977 : model1 loss : 0.436639 model2 loss : 0.025769
[11:35:58.146] iteration 16978 : model1 loss : 0.438065 model2 loss : 0.021398
[11:35:58.316] iteration 16979 : model1 loss : 0.434529 model2 loss : 0.022609
[11:35:58.481] iteration 16980 : model1 loss : 0.438651 model2 loss : 0.021865
[11:35:58.651] iteration 16981 : model1 loss : 0.432743 model2 loss : 0.018954
[11:35:58.820] iteration 16982 : model1 loss : 0.436211 model2 loss : 0.022369
[11:35:58.990] iteration 16983 : model1 loss : 0.439877 model2 loss : 0.024896
[11:35:59.158] iteration 16984 : model1 loss : 0.438210 model2 loss : 0.023936
[11:35:59.329] iteration 16985 : model1 loss : 0.435622 model2 loss : 0.023102
[11:35:59.498] iteration 16986 : model1 loss : 0.440524 model2 loss : 0.024434
[11:35:59.669] iteration 16987 : model1 loss : 0.436187 model2 loss : 0.022768
[11:35:59.839] iteration 16988 : model1 loss : 0.435750 model2 loss : 0.022231
[11:36:00.008] iteration 16989 : model1 loss : 0.444570 model2 loss : 0.023870
[11:36:00.176] iteration 16990 : model1 loss : 0.439836 model2 loss : 0.021262
[11:36:00.367] iteration 16991 : model1 loss : 0.436942 model2 loss : 0.023631
[11:36:00.538] iteration 16992 : model1 loss : 0.438326 model2 loss : 0.021649
[11:36:00.707] iteration 16993 : model1 loss : 0.438822 model2 loss : 0.025386
[11:36:00.875] iteration 16994 : model1 loss : 0.433421 model2 loss : 0.021013
[11:36:01.044] iteration 16995 : model1 loss : 0.438828 model2 loss : 0.022801
[11:36:02.986] iteration 16996 : model1 loss : 0.437216 model2 loss : 0.019773
[11:36:03.154] iteration 16997 : model1 loss : 0.436389 model2 loss : 0.021554
[11:36:03.326] iteration 16998 : model1 loss : 0.438147 model2 loss : 0.022105
[11:36:03.495] iteration 16999 : model1 loss : 0.439416 model2 loss : 0.023057
[11:36:03.665] iteration 17000 : model1 loss : 0.436764 model2 loss : 0.024956
[11:36:11.983] iteration 17000 : model1_mean_dice : 0.894465 model1_mean_hd95 : 3.910928
[11:36:20.274] iteration 17000 : model2_mean_dice : 0.896230 model2_mean_hd95 : 1.963704
[11:36:20.448] iteration 17001 : model1 loss : 0.437829 model2 loss : 0.020841
[11:36:20.617] iteration 17002 : model1 loss : 0.434060 model2 loss : 0.020807
[11:36:20.783] iteration 17003 : model1 loss : 0.441498 model2 loss : 0.024770
[11:36:20.951] iteration 17004 : model1 loss : 0.431729 model2 loss : 0.022720
[11:36:21.117] iteration 17005 : model1 loss : 0.436043 model2 loss : 0.020985
[11:36:21.287] iteration 17006 : model1 loss : 0.438235 model2 loss : 0.022043
[11:36:21.452] iteration 17007 : model1 loss : 0.437849 model2 loss : 0.025240
[11:36:21.619] iteration 17008 : model1 loss : 0.438208 model2 loss : 0.024355
[11:36:21.786] iteration 17009 : model1 loss : 0.438933 model2 loss : 0.022129
[11:36:21.954] iteration 17010 : model1 loss : 0.433983 model2 loss : 0.021366
[11:36:22.121] iteration 17011 : model1 loss : 0.434094 model2 loss : 0.022240
[11:36:22.289] iteration 17012 : model1 loss : 0.434230 model2 loss : 0.021502
[11:36:22.455] iteration 17013 : model1 loss : 0.436799 model2 loss : 0.019618
[11:36:22.622] iteration 17014 : model1 loss : 0.434602 model2 loss : 0.022413
[11:36:22.789] iteration 17015 : model1 loss : 0.436907 model2 loss : 0.020662
[11:36:22.957] iteration 17016 : model1 loss : 0.440202 model2 loss : 0.026859
[11:36:23.122] iteration 17017 : model1 loss : 0.435779 model2 loss : 0.019582
[11:36:23.294] iteration 17018 : model1 loss : 0.436552 model2 loss : 0.024367
[11:36:23.459] iteration 17019 : model1 loss : 0.439059 model2 loss : 0.026543
[11:36:23.628] iteration 17020 : model1 loss : 0.436393 model2 loss : 0.020956
[11:36:23.795] iteration 17021 : model1 loss : 0.437243 model2 loss : 0.022511
[11:36:23.963] iteration 17022 : model1 loss : 0.441001 model2 loss : 0.025539
[11:36:24.131] iteration 17023 : model1 loss : 0.443932 model2 loss : 0.033278
[11:36:24.297] iteration 17024 : model1 loss : 0.440753 model2 loss : 0.023426
[11:36:24.463] iteration 17025 : model1 loss : 0.435519 model2 loss : 0.022748
[11:36:24.632] iteration 17026 : model1 loss : 0.438866 model2 loss : 0.021391
[11:36:24.796] iteration 17027 : model1 loss : 0.435318 model2 loss : 0.023233
[11:36:24.963] iteration 17028 : model1 loss : 0.440159 model2 loss : 0.022427
[11:36:26.912] iteration 17029 : model1 loss : 0.435741 model2 loss : 0.022523
[11:36:27.078] iteration 17030 : model1 loss : 0.433754 model2 loss : 0.024538
[11:36:27.247] iteration 17031 : model1 loss : 0.439632 model2 loss : 0.022847
[11:36:27.414] iteration 17032 : model1 loss : 0.433799 model2 loss : 0.019117
[11:36:27.581] iteration 17033 : model1 loss : 0.439990 model2 loss : 0.021660
[11:36:27.746] iteration 17034 : model1 loss : 0.434716 model2 loss : 0.021237
[11:36:27.913] iteration 17035 : model1 loss : 0.439600 model2 loss : 0.021738
[11:36:28.078] iteration 17036 : model1 loss : 0.441803 model2 loss : 0.024544
[11:36:28.248] iteration 17037 : model1 loss : 0.436137 model2 loss : 0.020447
[11:36:28.413] iteration 17038 : model1 loss : 0.440121 model2 loss : 0.021335
[11:36:28.583] iteration 17039 : model1 loss : 0.431990 model2 loss : 0.022458
[11:36:28.749] iteration 17040 : model1 loss : 0.435833 model2 loss : 0.022026
[11:36:28.920] iteration 17041 : model1 loss : 0.439737 model2 loss : 0.021896
[11:36:29.085] iteration 17042 : model1 loss : 0.436679 model2 loss : 0.024393
[11:36:29.254] iteration 17043 : model1 loss : 0.441647 model2 loss : 0.026619
[11:36:29.420] iteration 17044 : model1 loss : 0.438352 model2 loss : 0.022842
[11:36:29.588] iteration 17045 : model1 loss : 0.435285 model2 loss : 0.020812
[11:36:29.764] iteration 17046 : model1 loss : 0.437278 model2 loss : 0.025487
[11:36:29.932] iteration 17047 : model1 loss : 0.436814 model2 loss : 0.025498
[11:36:30.100] iteration 17048 : model1 loss : 0.432379 model2 loss : 0.020795
[11:36:30.268] iteration 17049 : model1 loss : 0.433962 model2 loss : 0.022755
[11:36:30.436] iteration 17050 : model1 loss : 0.439977 model2 loss : 0.024294
[11:36:30.605] iteration 17051 : model1 loss : 0.440849 model2 loss : 0.025391
[11:36:30.772] iteration 17052 : model1 loss : 0.438781 model2 loss : 0.022007
[11:36:30.941] iteration 17053 : model1 loss : 0.432702 model2 loss : 0.023886
[11:36:31.106] iteration 17054 : model1 loss : 0.436693 model2 loss : 0.022776
[11:36:31.274] iteration 17055 : model1 loss : 0.437188 model2 loss : 0.021833
[11:36:31.443] iteration 17056 : model1 loss : 0.443333 model2 loss : 0.027825
[11:36:31.612] iteration 17057 : model1 loss : 0.439879 model2 loss : 0.023592
[11:36:31.779] iteration 17058 : model1 loss : 0.436441 model2 loss : 0.024094
[11:36:31.948] iteration 17059 : model1 loss : 0.437252 model2 loss : 0.024279
[11:36:32.114] iteration 17060 : model1 loss : 0.436711 model2 loss : 0.021989
[11:36:32.281] iteration 17061 : model1 loss : 0.437878 model2 loss : 0.023836
[11:36:34.194] iteration 17062 : model1 loss : 0.434689 model2 loss : 0.019475
[11:36:34.362] iteration 17063 : model1 loss : 0.434039 model2 loss : 0.020862
[11:36:34.532] iteration 17064 : model1 loss : 0.436061 model2 loss : 0.022583
[11:36:34.698] iteration 17065 : model1 loss : 0.435090 model2 loss : 0.021522
[11:36:34.869] iteration 17066 : model1 loss : 0.436050 model2 loss : 0.022711
[11:36:35.035] iteration 17067 : model1 loss : 0.432600 model2 loss : 0.021779
[11:36:35.202] iteration 17068 : model1 loss : 0.439963 model2 loss : 0.023056
[11:36:35.371] iteration 17069 : model1 loss : 0.440113 model2 loss : 0.025608
[11:36:35.540] iteration 17070 : model1 loss : 0.436361 model2 loss : 0.023805
[11:36:35.707] iteration 17071 : model1 loss : 0.441508 model2 loss : 0.025181
[11:36:35.876] iteration 17072 : model1 loss : 0.435940 model2 loss : 0.023559
[11:36:36.041] iteration 17073 : model1 loss : 0.433399 model2 loss : 0.021414
[11:36:36.210] iteration 17074 : model1 loss : 0.441588 model2 loss : 0.024632
[11:36:36.376] iteration 17075 : model1 loss : 0.438118 model2 loss : 0.021217
[11:36:36.544] iteration 17076 : model1 loss : 0.436056 model2 loss : 0.021046
[11:36:36.710] iteration 17077 : model1 loss : 0.443547 model2 loss : 0.026538
[11:36:36.881] iteration 17078 : model1 loss : 0.436076 model2 loss : 0.020288
[11:36:37.048] iteration 17079 : model1 loss : 0.438042 model2 loss : 0.024510
[11:36:37.216] iteration 17080 : model1 loss : 0.437651 model2 loss : 0.023173
[11:36:37.383] iteration 17081 : model1 loss : 0.436577 model2 loss : 0.020574
[11:36:37.551] iteration 17082 : model1 loss : 0.435065 model2 loss : 0.022759
[11:36:37.717] iteration 17083 : model1 loss : 0.436573 model2 loss : 0.022795
[11:36:37.885] iteration 17084 : model1 loss : 0.435144 model2 loss : 0.019786
[11:36:38.049] iteration 17085 : model1 loss : 0.438712 model2 loss : 0.024543
[11:36:38.218] iteration 17086 : model1 loss : 0.437957 model2 loss : 0.022760
[11:36:38.383] iteration 17087 : model1 loss : 0.437654 model2 loss : 0.023188
[11:36:38.552] iteration 17088 : model1 loss : 0.437690 model2 loss : 0.023295
[11:36:38.718] iteration 17089 : model1 loss : 0.440408 model2 loss : 0.022646
[11:36:38.886] iteration 17090 : model1 loss : 0.435188 model2 loss : 0.019496
[11:36:39.054] iteration 17091 : model1 loss : 0.438279 model2 loss : 0.023787
[11:36:39.222] iteration 17092 : model1 loss : 0.437381 model2 loss : 0.021531
[11:36:39.402] iteration 17093 : model1 loss : 0.438205 model2 loss : 0.022639
[11:36:39.572] iteration 17094 : model1 loss : 0.441313 model2 loss : 0.025806
[11:36:41.525] iteration 17095 : model1 loss : 0.437379 model2 loss : 0.024106
[11:36:41.696] iteration 17096 : model1 loss : 0.442302 model2 loss : 0.025068
[11:36:41.865] iteration 17097 : model1 loss : 0.438515 model2 loss : 0.023402
[11:36:42.030] iteration 17098 : model1 loss : 0.436036 model2 loss : 0.024434
[11:36:42.198] iteration 17099 : model1 loss : 0.437911 model2 loss : 0.024363
[11:36:42.363] iteration 17100 : model1 loss : 0.438372 model2 loss : 0.023355
[11:36:42.535] iteration 17101 : model1 loss : 0.439515 model2 loss : 0.022500
[11:36:42.699] iteration 17102 : model1 loss : 0.442773 model2 loss : 0.025441
[11:36:42.869] iteration 17103 : model1 loss : 0.435522 model2 loss : 0.023391
[11:36:43.036] iteration 17104 : model1 loss : 0.435384 model2 loss : 0.021071
[11:36:43.202] iteration 17105 : model1 loss : 0.440450 model2 loss : 0.022388
[11:36:43.369] iteration 17106 : model1 loss : 0.441960 model2 loss : 0.024853
[11:36:43.540] iteration 17107 : model1 loss : 0.438530 model2 loss : 0.023320
[11:36:43.706] iteration 17108 : model1 loss : 0.432554 model2 loss : 0.019561
[11:36:43.873] iteration 17109 : model1 loss : 0.436055 model2 loss : 0.022636
[11:36:44.039] iteration 17110 : model1 loss : 0.431388 model2 loss : 0.019350
[11:36:44.208] iteration 17111 : model1 loss : 0.436968 model2 loss : 0.023840
[11:36:44.373] iteration 17112 : model1 loss : 0.437040 model2 loss : 0.027077
[11:36:44.548] iteration 17113 : model1 loss : 0.434930 model2 loss : 0.020507
[11:36:44.715] iteration 17114 : model1 loss : 0.435420 model2 loss : 0.022537
[11:36:44.882] iteration 17115 : model1 loss : 0.435315 model2 loss : 0.021933
[11:36:45.050] iteration 17116 : model1 loss : 0.439872 model2 loss : 0.023210
[11:36:45.218] iteration 17117 : model1 loss : 0.430174 model2 loss : 0.021801
[11:36:45.384] iteration 17118 : model1 loss : 0.445217 model2 loss : 0.027155
[11:36:45.555] iteration 17119 : model1 loss : 0.438294 model2 loss : 0.025710
[11:36:45.726] iteration 17120 : model1 loss : 0.437313 model2 loss : 0.024433
[11:36:45.898] iteration 17121 : model1 loss : 0.437929 model2 loss : 0.025075
[11:36:46.064] iteration 17122 : model1 loss : 0.432383 model2 loss : 0.022247
[11:36:46.232] iteration 17123 : model1 loss : 0.438729 model2 loss : 0.022825
[11:36:46.397] iteration 17124 : model1 loss : 0.442724 model2 loss : 0.027198
[11:36:46.566] iteration 17125 : model1 loss : 0.442380 model2 loss : 0.030898
[11:36:46.731] iteration 17126 : model1 loss : 0.439422 model2 loss : 0.024600
[11:36:46.898] iteration 17127 : model1 loss : 0.436662 model2 loss : 0.021219
[11:36:48.807] iteration 17128 : model1 loss : 0.440814 model2 loss : 0.024492
[11:36:48.974] iteration 17129 : model1 loss : 0.437447 model2 loss : 0.020991
[11:36:49.147] iteration 17130 : model1 loss : 0.436301 model2 loss : 0.021047
[11:36:49.313] iteration 17131 : model1 loss : 0.433660 model2 loss : 0.020806
[11:36:49.480] iteration 17132 : model1 loss : 0.437135 model2 loss : 0.021695
[11:36:49.646] iteration 17133 : model1 loss : 0.438814 model2 loss : 0.021719
[11:36:49.815] iteration 17134 : model1 loss : 0.438526 model2 loss : 0.022649
[11:36:49.980] iteration 17135 : model1 loss : 0.437744 model2 loss : 0.024110
[11:36:50.148] iteration 17136 : model1 loss : 0.437004 model2 loss : 0.022675
[11:36:50.316] iteration 17137 : model1 loss : 0.438679 model2 loss : 0.024435
[11:36:50.484] iteration 17138 : model1 loss : 0.438611 model2 loss : 0.026421
[11:36:50.653] iteration 17139 : model1 loss : 0.436800 model2 loss : 0.023364
[11:36:50.821] iteration 17140 : model1 loss : 0.434905 model2 loss : 0.020421
[11:36:50.987] iteration 17141 : model1 loss : 0.438071 model2 loss : 0.022400
[11:36:51.156] iteration 17142 : model1 loss : 0.438312 model2 loss : 0.023281
[11:36:51.322] iteration 17143 : model1 loss : 0.438023 model2 loss : 0.023287
[11:36:51.491] iteration 17144 : model1 loss : 0.437182 model2 loss : 0.020961
[11:36:51.659] iteration 17145 : model1 loss : 0.436922 model2 loss : 0.021578
[11:36:51.828] iteration 17146 : model1 loss : 0.438740 model2 loss : 0.021255
[11:36:51.995] iteration 17147 : model1 loss : 0.438640 model2 loss : 0.023218
[11:36:52.162] iteration 17148 : model1 loss : 0.437266 model2 loss : 0.024493
[11:36:52.329] iteration 17149 : model1 loss : 0.434262 model2 loss : 0.022156
[11:36:52.497] iteration 17150 : model1 loss : 0.442092 model2 loss : 0.025040
[11:36:52.664] iteration 17151 : model1 loss : 0.434544 model2 loss : 0.023434
[11:36:52.832] iteration 17152 : model1 loss : 0.437619 model2 loss : 0.024223
[11:36:52.998] iteration 17153 : model1 loss : 0.441144 model2 loss : 0.022501
[11:36:53.168] iteration 17154 : model1 loss : 0.437440 model2 loss : 0.022586
[11:36:53.337] iteration 17155 : model1 loss : 0.436612 model2 loss : 0.023788
[11:36:53.507] iteration 17156 : model1 loss : 0.433743 model2 loss : 0.020975
[11:36:53.675] iteration 17157 : model1 loss : 0.436795 model2 loss : 0.019887
[11:36:53.844] iteration 17158 : model1 loss : 0.437270 model2 loss : 0.018863
[11:36:54.010] iteration 17159 : model1 loss : 0.438678 model2 loss : 0.024254
[11:36:54.178] iteration 17160 : model1 loss : 0.434663 model2 loss : 0.021329
[11:36:56.084] iteration 17161 : model1 loss : 0.435234 model2 loss : 0.020878
[11:36:56.250] iteration 17162 : model1 loss : 0.437300 model2 loss : 0.022523
[11:36:56.421] iteration 17163 : model1 loss : 0.441215 model2 loss : 0.022319
[11:36:56.586] iteration 17164 : model1 loss : 0.437245 model2 loss : 0.022449
[11:36:56.754] iteration 17165 : model1 loss : 0.435741 model2 loss : 0.023330
[11:36:56.921] iteration 17166 : model1 loss : 0.436872 model2 loss : 0.024569
[11:36:57.088] iteration 17167 : model1 loss : 0.443781 model2 loss : 0.025734
[11:36:57.256] iteration 17168 : model1 loss : 0.437180 model2 loss : 0.023312
[11:36:57.424] iteration 17169 : model1 loss : 0.435722 model2 loss : 0.020367
[11:36:57.591] iteration 17170 : model1 loss : 0.439045 model2 loss : 0.023184
[11:36:57.758] iteration 17171 : model1 loss : 0.435007 model2 loss : 0.021851
[11:36:57.925] iteration 17172 : model1 loss : 0.432116 model2 loss : 0.021058
[11:36:58.094] iteration 17173 : model1 loss : 0.438958 model2 loss : 0.024775
[11:36:58.260] iteration 17174 : model1 loss : 0.438639 model2 loss : 0.024636
[11:36:58.428] iteration 17175 : model1 loss : 0.436818 model2 loss : 0.023710
[11:36:58.595] iteration 17176 : model1 loss : 0.439309 model2 loss : 0.023108
[11:36:58.764] iteration 17177 : model1 loss : 0.437593 model2 loss : 0.021400
[11:36:58.932] iteration 17178 : model1 loss : 0.440051 model2 loss : 0.023562
[11:36:59.100] iteration 17179 : model1 loss : 0.438614 model2 loss : 0.021580
[11:36:59.267] iteration 17180 : model1 loss : 0.437183 model2 loss : 0.022170
[11:36:59.436] iteration 17181 : model1 loss : 0.437476 model2 loss : 0.020301
[11:36:59.602] iteration 17182 : model1 loss : 0.435581 model2 loss : 0.021558
[11:36:59.771] iteration 17183 : model1 loss : 0.441001 model2 loss : 0.020081
[11:36:59.939] iteration 17184 : model1 loss : 0.434892 model2 loss : 0.022188
[11:37:00.110] iteration 17185 : model1 loss : 0.436309 model2 loss : 0.021753
[11:37:00.279] iteration 17186 : model1 loss : 0.439291 model2 loss : 0.023807
[11:37:00.449] iteration 17187 : model1 loss : 0.439559 model2 loss : 0.019695
[11:37:00.618] iteration 17188 : model1 loss : 0.440294 model2 loss : 0.026592
[11:37:00.788] iteration 17189 : model1 loss : 0.441457 model2 loss : 0.028365
[11:37:00.957] iteration 17190 : model1 loss : 0.437154 model2 loss : 0.023264
[11:37:01.124] iteration 17191 : model1 loss : 0.435656 model2 loss : 0.020447
[11:37:01.294] iteration 17192 : model1 loss : 0.438796 model2 loss : 0.030696
[11:37:01.460] iteration 17193 : model1 loss : 0.430039 model2 loss : 0.020622
[11:37:03.404] iteration 17194 : model1 loss : 0.441041 model2 loss : 0.022701
[11:37:03.576] iteration 17195 : model1 loss : 0.434695 model2 loss : 0.023711
[11:37:03.746] iteration 17196 : model1 loss : 0.439253 model2 loss : 0.023647
[11:37:03.911] iteration 17197 : model1 loss : 0.439156 model2 loss : 0.026284
[11:37:04.079] iteration 17198 : model1 loss : 0.441288 model2 loss : 0.027487
[11:37:04.244] iteration 17199 : model1 loss : 0.438570 model2 loss : 0.022301
[11:37:04.412] iteration 17200 : model1 loss : 0.440884 model2 loss : 0.024924
[11:37:04.580] iteration 17201 : model1 loss : 0.437304 model2 loss : 0.023414
[11:37:04.747] iteration 17202 : model1 loss : 0.438637 model2 loss : 0.023313
[11:37:04.915] iteration 17203 : model1 loss : 0.435719 model2 loss : 0.020921
[11:37:05.083] iteration 17204 : model1 loss : 0.437633 model2 loss : 0.025428
[11:37:05.249] iteration 17205 : model1 loss : 0.433729 model2 loss : 0.024416
[11:37:05.418] iteration 17206 : model1 loss : 0.436331 model2 loss : 0.023232
[11:37:05.585] iteration 17207 : model1 loss : 0.435955 model2 loss : 0.023197
[11:37:05.754] iteration 17208 : model1 loss : 0.437332 model2 loss : 0.024413
[11:37:05.921] iteration 17209 : model1 loss : 0.437628 model2 loss : 0.022444
[11:37:06.091] iteration 17210 : model1 loss : 0.441686 model2 loss : 0.025316
[11:37:06.257] iteration 17211 : model1 loss : 0.436509 model2 loss : 0.020520
[11:37:06.427] iteration 17212 : model1 loss : 0.442249 model2 loss : 0.028254
[11:37:06.595] iteration 17213 : model1 loss : 0.437220 model2 loss : 0.024629
[11:37:06.772] iteration 17214 : model1 loss : 0.438127 model2 loss : 0.022747
[11:37:06.939] iteration 17215 : model1 loss : 0.440377 model2 loss : 0.022741
[11:37:07.108] iteration 17216 : model1 loss : 0.438524 model2 loss : 0.023659
[11:37:07.277] iteration 17217 : model1 loss : 0.438088 model2 loss : 0.023349
[11:37:07.446] iteration 17218 : model1 loss : 0.434053 model2 loss : 0.024592
[11:37:07.612] iteration 17219 : model1 loss : 0.437413 model2 loss : 0.022069
[11:37:07.783] iteration 17220 : model1 loss : 0.433520 model2 loss : 0.020419
[11:37:07.950] iteration 17221 : model1 loss : 0.438745 model2 loss : 0.025641
[11:37:08.119] iteration 17222 : model1 loss : 0.441371 model2 loss : 0.030737
[11:37:08.288] iteration 17223 : model1 loss : 0.434285 model2 loss : 0.018720
[11:37:08.458] iteration 17224 : model1 loss : 0.431468 model2 loss : 0.023836
[11:37:08.625] iteration 17225 : model1 loss : 0.436499 model2 loss : 0.024949
[11:37:08.802] iteration 17226 : model1 loss : 0.440904 model2 loss : 0.023739
[11:37:10.720] iteration 17227 : model1 loss : 0.433781 model2 loss : 0.021619
[11:37:10.889] iteration 17228 : model1 loss : 0.438243 model2 loss : 0.025735
[11:37:11.063] iteration 17229 : model1 loss : 0.442817 model2 loss : 0.027979
[11:37:11.229] iteration 17230 : model1 loss : 0.440906 model2 loss : 0.027934
[11:37:11.398] iteration 17231 : model1 loss : 0.435570 model2 loss : 0.019473
[11:37:11.563] iteration 17232 : model1 loss : 0.436587 model2 loss : 0.023109
[11:37:11.732] iteration 17233 : model1 loss : 0.435707 model2 loss : 0.021140
[11:37:11.898] iteration 17234 : model1 loss : 0.440136 model2 loss : 0.023012
[11:37:12.064] iteration 17235 : model1 loss : 0.435869 model2 loss : 0.020301
[11:37:12.230] iteration 17236 : model1 loss : 0.433022 model2 loss : 0.024112
[11:37:12.398] iteration 17237 : model1 loss : 0.434575 model2 loss : 0.020771
[11:37:12.565] iteration 17238 : model1 loss : 0.441457 model2 loss : 0.023832
[11:37:12.734] iteration 17239 : model1 loss : 0.437480 model2 loss : 0.021405
[11:37:12.900] iteration 17240 : model1 loss : 0.435223 model2 loss : 0.022124
[11:37:13.068] iteration 17241 : model1 loss : 0.435214 model2 loss : 0.022733
[11:37:13.235] iteration 17242 : model1 loss : 0.434672 model2 loss : 0.021954
[11:37:13.405] iteration 17243 : model1 loss : 0.437428 model2 loss : 0.022544
[11:37:13.574] iteration 17244 : model1 loss : 0.440729 model2 loss : 0.022479
[11:37:13.744] iteration 17245 : model1 loss : 0.440825 model2 loss : 0.024789
[11:37:13.912] iteration 17246 : model1 loss : 0.434452 model2 loss : 0.021702
[11:37:14.080] iteration 17247 : model1 loss : 0.439330 model2 loss : 0.024093
[11:37:14.248] iteration 17248 : model1 loss : 0.436011 model2 loss : 0.021466
[11:37:14.417] iteration 17249 : model1 loss : 0.439087 model2 loss : 0.026308
[11:37:14.586] iteration 17250 : model1 loss : 0.436664 model2 loss : 0.024389
[11:37:14.756] iteration 17251 : model1 loss : 0.437141 model2 loss : 0.023991
[11:37:14.921] iteration 17252 : model1 loss : 0.437856 model2 loss : 0.021108
[11:37:15.090] iteration 17253 : model1 loss : 0.433987 model2 loss : 0.020992
[11:37:15.257] iteration 17254 : model1 loss : 0.441808 model2 loss : 0.027574
[11:37:15.427] iteration 17255 : model1 loss : 0.439741 model2 loss : 0.021505
[11:37:15.595] iteration 17256 : model1 loss : 0.435447 model2 loss : 0.021746
[11:37:15.789] iteration 17257 : model1 loss : 0.441703 model2 loss : 0.027648
[11:37:15.955] iteration 17258 : model1 loss : 0.434004 model2 loss : 0.020942
[11:37:16.123] iteration 17259 : model1 loss : 0.439515 model2 loss : 0.023726
[11:37:18.044] iteration 17260 : model1 loss : 0.437116 model2 loss : 0.022092
[11:37:18.210] iteration 17261 : model1 loss : 0.437030 model2 loss : 0.024840
[11:37:18.380] iteration 17262 : model1 loss : 0.435883 model2 loss : 0.024691
[11:37:18.545] iteration 17263 : model1 loss : 0.433762 model2 loss : 0.021638
[11:37:18.713] iteration 17264 : model1 loss : 0.441896 model2 loss : 0.025330
[11:37:18.880] iteration 17265 : model1 loss : 0.433591 model2 loss : 0.020125
[11:37:19.048] iteration 17266 : model1 loss : 0.439592 model2 loss : 0.022602
[11:37:19.217] iteration 17267 : model1 loss : 0.439737 model2 loss : 0.022239
[11:37:19.387] iteration 17268 : model1 loss : 0.441640 model2 loss : 0.020806
[11:37:19.555] iteration 17269 : model1 loss : 0.434705 model2 loss : 0.022801
[11:37:19.724] iteration 17270 : model1 loss : 0.439799 model2 loss : 0.022979
[11:37:19.892] iteration 17271 : model1 loss : 0.438907 model2 loss : 0.023452
[11:37:20.061] iteration 17272 : model1 loss : 0.437011 model2 loss : 0.020537
[11:37:20.228] iteration 17273 : model1 loss : 0.437797 model2 loss : 0.022595
[11:37:20.398] iteration 17274 : model1 loss : 0.435817 model2 loss : 0.020899
[11:37:20.563] iteration 17275 : model1 loss : 0.438457 model2 loss : 0.023822
[11:37:20.734] iteration 17276 : model1 loss : 0.441122 model2 loss : 0.027607
[11:37:20.903] iteration 17277 : model1 loss : 0.434522 model2 loss : 0.021330
[11:37:21.073] iteration 17278 : model1 loss : 0.443587 model2 loss : 0.029370
[11:37:21.240] iteration 17279 : model1 loss : 0.435315 model2 loss : 0.024034
[11:37:21.412] iteration 17280 : model1 loss : 0.435969 model2 loss : 0.019931
[11:37:21.578] iteration 17281 : model1 loss : 0.435224 model2 loss : 0.024024
[11:37:21.747] iteration 17282 : model1 loss : 0.439529 model2 loss : 0.025972
[11:37:21.915] iteration 17283 : model1 loss : 0.436044 model2 loss : 0.023059
[11:37:22.084] iteration 17284 : model1 loss : 0.439207 model2 loss : 0.026842
[11:37:22.252] iteration 17285 : model1 loss : 0.438222 model2 loss : 0.021145
[11:37:22.422] iteration 17286 : model1 loss : 0.435255 model2 loss : 0.021525
[11:37:22.589] iteration 17287 : model1 loss : 0.434922 model2 loss : 0.021579
[11:37:22.759] iteration 17288 : model1 loss : 0.438078 model2 loss : 0.022361
[11:37:22.926] iteration 17289 : model1 loss : 0.441483 model2 loss : 0.023648
[11:37:23.096] iteration 17290 : model1 loss : 0.437241 model2 loss : 0.023426
[11:37:23.261] iteration 17291 : model1 loss : 0.435939 model2 loss : 0.022999
[11:37:23.428] iteration 17292 : model1 loss : 0.436479 model2 loss : 0.023620
[11:37:25.345] iteration 17293 : model1 loss : 0.437659 model2 loss : 0.023472
[11:37:25.516] iteration 17294 : model1 loss : 0.439805 model2 loss : 0.024208
[11:37:25.687] iteration 17295 : model1 loss : 0.432152 model2 loss : 0.020355
[11:37:25.857] iteration 17296 : model1 loss : 0.437654 model2 loss : 0.023468
[11:37:26.026] iteration 17297 : model1 loss : 0.437857 model2 loss : 0.023469
[11:37:26.193] iteration 17298 : model1 loss : 0.442393 model2 loss : 0.026558
[11:37:26.368] iteration 17299 : model1 loss : 0.435116 model2 loss : 0.023144
[11:37:26.535] iteration 17300 : model1 loss : 0.438392 model2 loss : 0.025554
[11:37:26.705] iteration 17301 : model1 loss : 0.436864 model2 loss : 0.020208
[11:37:26.873] iteration 17302 : model1 loss : 0.436116 model2 loss : 0.024157
[11:37:27.043] iteration 17303 : model1 loss : 0.431351 model2 loss : 0.022588
[11:37:27.208] iteration 17304 : model1 loss : 0.440548 model2 loss : 0.022780
[11:37:27.376] iteration 17305 : model1 loss : 0.438047 model2 loss : 0.022784
[11:37:27.544] iteration 17306 : model1 loss : 0.433870 model2 loss : 0.020449
[11:37:27.713] iteration 17307 : model1 loss : 0.435965 model2 loss : 0.023144
[11:37:27.881] iteration 17308 : model1 loss : 0.445805 model2 loss : 0.026461
[11:37:28.051] iteration 17309 : model1 loss : 0.441274 model2 loss : 0.024140
[11:37:28.217] iteration 17310 : model1 loss : 0.437512 model2 loss : 0.022071
[11:37:28.387] iteration 17311 : model1 loss : 0.435209 model2 loss : 0.022534
[11:37:28.553] iteration 17312 : model1 loss : 0.438886 model2 loss : 0.023422
[11:37:28.722] iteration 17313 : model1 loss : 0.437791 model2 loss : 0.022762
[11:37:28.890] iteration 17314 : model1 loss : 0.435319 model2 loss : 0.021708
[11:37:29.062] iteration 17315 : model1 loss : 0.435732 model2 loss : 0.020823
[11:37:29.230] iteration 17316 : model1 loss : 0.437817 model2 loss : 0.021218
[11:37:29.399] iteration 17317 : model1 loss : 0.434467 model2 loss : 0.021295
[11:37:29.569] iteration 17318 : model1 loss : 0.441871 model2 loss : 0.024356
[11:37:29.740] iteration 17319 : model1 loss : 0.438416 model2 loss : 0.022544
[11:37:29.907] iteration 17320 : model1 loss : 0.436815 model2 loss : 0.021832
[11:37:30.075] iteration 17321 : model1 loss : 0.440743 model2 loss : 0.021456
[11:37:30.242] iteration 17322 : model1 loss : 0.434260 model2 loss : 0.022519
[11:37:30.412] iteration 17323 : model1 loss : 0.437724 model2 loss : 0.024485
[11:37:30.577] iteration 17324 : model1 loss : 0.434590 model2 loss : 0.021565
[11:37:30.745] iteration 17325 : model1 loss : 0.440497 model2 loss : 0.022950
[11:37:32.697] iteration 17326 : model1 loss : 0.434234 model2 loss : 0.020689
[11:37:32.868] iteration 17327 : model1 loss : 0.435825 model2 loss : 0.022710
[11:37:33.038] iteration 17328 : model1 loss : 0.436382 model2 loss : 0.022821
[11:37:33.204] iteration 17329 : model1 loss : 0.440587 model2 loss : 0.022811
[11:37:33.375] iteration 17330 : model1 loss : 0.442564 model2 loss : 0.023040
[11:37:33.544] iteration 17331 : model1 loss : 0.437808 model2 loss : 0.020010
[11:37:33.713] iteration 17332 : model1 loss : 0.438035 model2 loss : 0.023973
[11:37:33.897] iteration 17333 : model1 loss : 0.437379 model2 loss : 0.024090
[11:37:34.066] iteration 17334 : model1 loss : 0.435304 model2 loss : 0.022789
[11:37:34.234] iteration 17335 : model1 loss : 0.437489 model2 loss : 0.023641
[11:37:34.405] iteration 17336 : model1 loss : 0.440412 model2 loss : 0.021960
[11:37:34.574] iteration 17337 : model1 loss : 0.440105 model2 loss : 0.019983
[11:37:34.743] iteration 17338 : model1 loss : 0.441596 model2 loss : 0.024244
[11:37:34.910] iteration 17339 : model1 loss : 0.433850 model2 loss : 0.020358
[11:37:35.081] iteration 17340 : model1 loss : 0.435985 model2 loss : 0.022274
[11:37:35.249] iteration 17341 : model1 loss : 0.438960 model2 loss : 0.021272
[11:37:35.419] iteration 17342 : model1 loss : 0.438658 model2 loss : 0.023240
[11:37:35.585] iteration 17343 : model1 loss : 0.433856 model2 loss : 0.021348
[11:37:35.754] iteration 17344 : model1 loss : 0.439517 model2 loss : 0.023682
[11:37:35.924] iteration 17345 : model1 loss : 0.438230 model2 loss : 0.022180
[11:37:36.093] iteration 17346 : model1 loss : 0.440650 model2 loss : 0.023616
[11:37:36.259] iteration 17347 : model1 loss : 0.436883 model2 loss : 0.022789
[11:37:36.427] iteration 17348 : model1 loss : 0.435168 model2 loss : 0.021278
[11:37:36.594] iteration 17349 : model1 loss : 0.436830 model2 loss : 0.021755
[11:37:36.762] iteration 17350 : model1 loss : 0.435944 model2 loss : 0.021952
[11:37:36.930] iteration 17351 : model1 loss : 0.434756 model2 loss : 0.021586
[11:37:37.098] iteration 17352 : model1 loss : 0.434517 model2 loss : 0.021063
[11:37:37.266] iteration 17353 : model1 loss : 0.437051 model2 loss : 0.020985
[11:37:37.440] iteration 17354 : model1 loss : 0.437809 model2 loss : 0.023973
[11:37:37.607] iteration 17355 : model1 loss : 0.434620 model2 loss : 0.022459
[11:37:37.775] iteration 17356 : model1 loss : 0.437870 model2 loss : 0.024084
[11:37:37.941] iteration 17357 : model1 loss : 0.437770 model2 loss : 0.024667
[11:37:38.109] iteration 17358 : model1 loss : 0.439874 model2 loss : 0.022085
[11:37:40.071] iteration 17359 : model1 loss : 0.436947 model2 loss : 0.021777
[11:37:40.239] iteration 17360 : model1 loss : 0.436715 model2 loss : 0.022905
[11:37:40.412] iteration 17361 : model1 loss : 0.437943 model2 loss : 0.024835
[11:37:40.579] iteration 17362 : model1 loss : 0.435768 model2 loss : 0.022761
[11:37:40.746] iteration 17363 : model1 loss : 0.437538 model2 loss : 0.021911
[11:37:40.917] iteration 17364 : model1 loss : 0.436202 model2 loss : 0.023491
[11:37:41.085] iteration 17365 : model1 loss : 0.436994 model2 loss : 0.023553
[11:37:41.251] iteration 17366 : model1 loss : 0.437812 model2 loss : 0.021927
[11:37:41.424] iteration 17367 : model1 loss : 0.439447 model2 loss : 0.023528
[11:37:41.590] iteration 17368 : model1 loss : 0.444034 model2 loss : 0.027708
[11:37:41.760] iteration 17369 : model1 loss : 0.430967 model2 loss : 0.022402
[11:37:41.926] iteration 17370 : model1 loss : 0.436797 model2 loss : 0.024059
[11:37:42.095] iteration 17371 : model1 loss : 0.436202 model2 loss : 0.024130
[11:37:42.261] iteration 17372 : model1 loss : 0.438049 model2 loss : 0.021608
[11:37:42.431] iteration 17373 : model1 loss : 0.441648 model2 loss : 0.027168
[11:37:42.596] iteration 17374 : model1 loss : 0.439918 model2 loss : 0.023477
[11:37:42.766] iteration 17375 : model1 loss : 0.433177 model2 loss : 0.021480
[11:37:42.933] iteration 17376 : model1 loss : 0.437030 model2 loss : 0.021763
[11:37:43.102] iteration 17377 : model1 loss : 0.438176 model2 loss : 0.021758
[11:37:43.270] iteration 17378 : model1 loss : 0.442214 model2 loss : 0.023276
[11:37:43.440] iteration 17379 : model1 loss : 0.439264 model2 loss : 0.023596
[11:37:43.607] iteration 17380 : model1 loss : 0.439721 model2 loss : 0.021645
[11:37:43.777] iteration 17381 : model1 loss : 0.438868 model2 loss : 0.021293
[11:37:43.945] iteration 17382 : model1 loss : 0.434229 model2 loss : 0.022238
[11:37:44.115] iteration 17383 : model1 loss : 0.439793 model2 loss : 0.022357
[11:37:44.281] iteration 17384 : model1 loss : 0.433775 model2 loss : 0.021613
[11:37:44.450] iteration 17385 : model1 loss : 0.439302 model2 loss : 0.024789
[11:37:44.618] iteration 17386 : model1 loss : 0.441938 model2 loss : 0.023513
[11:37:44.786] iteration 17387 : model1 loss : 0.431312 model2 loss : 0.022425
[11:37:44.953] iteration 17388 : model1 loss : 0.440066 model2 loss : 0.023485
[11:37:45.122] iteration 17389 : model1 loss : 0.440578 model2 loss : 0.025570
[11:37:45.289] iteration 17390 : model1 loss : 0.435452 model2 loss : 0.019707
[11:37:45.456] iteration 17391 : model1 loss : 0.435237 model2 loss : 0.023661
[11:37:47.400] iteration 17392 : model1 loss : 0.440475 model2 loss : 0.020907
[11:37:47.568] iteration 17393 : model1 loss : 0.435493 model2 loss : 0.024970
[11:37:47.737] iteration 17394 : model1 loss : 0.442232 model2 loss : 0.023859
[11:37:47.905] iteration 17395 : model1 loss : 0.437599 model2 loss : 0.023451
[11:37:48.075] iteration 17396 : model1 loss : 0.434136 model2 loss : 0.023081
[11:37:48.243] iteration 17397 : model1 loss : 0.434338 model2 loss : 0.020257
[11:37:48.415] iteration 17398 : model1 loss : 0.434419 model2 loss : 0.022871
[11:37:48.582] iteration 17399 : model1 loss : 0.441552 model2 loss : 0.022398
[11:37:48.753] iteration 17400 : model1 loss : 0.437661 model2 loss : 0.020739
[11:37:48.919] iteration 17401 : model1 loss : 0.437481 model2 loss : 0.021958
[11:37:49.089] iteration 17402 : model1 loss : 0.436235 model2 loss : 0.023036
[11:37:49.256] iteration 17403 : model1 loss : 0.436331 model2 loss : 0.022610
[11:37:49.428] iteration 17404 : model1 loss : 0.439389 model2 loss : 0.020101
[11:37:49.594] iteration 17405 : model1 loss : 0.437720 model2 loss : 0.021569
[11:37:49.763] iteration 17406 : model1 loss : 0.435671 model2 loss : 0.022990
[11:37:49.929] iteration 17407 : model1 loss : 0.435653 model2 loss : 0.023625
[11:37:50.096] iteration 17408 : model1 loss : 0.440378 model2 loss : 0.020214
[11:37:50.265] iteration 17409 : model1 loss : 0.443530 model2 loss : 0.023868
[11:37:50.434] iteration 17410 : model1 loss : 0.439844 model2 loss : 0.023375
[11:37:50.601] iteration 17411 : model1 loss : 0.443505 model2 loss : 0.025092
[11:37:50.771] iteration 17412 : model1 loss : 0.437755 model2 loss : 0.022406
[11:37:50.952] iteration 17413 : model1 loss : 0.437195 model2 loss : 0.020157
[11:37:51.123] iteration 17414 : model1 loss : 0.437395 model2 loss : 0.024268
[11:37:51.290] iteration 17415 : model1 loss : 0.435087 model2 loss : 0.022488
[11:37:51.460] iteration 17416 : model1 loss : 0.435004 model2 loss : 0.021054
[11:37:51.629] iteration 17417 : model1 loss : 0.434702 model2 loss : 0.019743
[11:37:51.798] iteration 17418 : model1 loss : 0.434050 model2 loss : 0.023347
[11:37:51.965] iteration 17419 : model1 loss : 0.440691 model2 loss : 0.022219
[11:37:52.135] iteration 17420 : model1 loss : 0.435119 model2 loss : 0.022232
[11:37:52.304] iteration 17421 : model1 loss : 0.434284 model2 loss : 0.020558
[11:37:52.475] iteration 17422 : model1 loss : 0.435320 model2 loss : 0.024178
[11:37:52.641] iteration 17423 : model1 loss : 0.444724 model2 loss : 0.025998
[11:37:52.811] iteration 17424 : model1 loss : 0.436804 model2 loss : 0.018867
[11:37:54.764] iteration 17425 : model1 loss : 0.440806 model2 loss : 0.023959
[11:37:54.932] iteration 17426 : model1 loss : 0.441336 model2 loss : 0.024217
[11:37:55.104] iteration 17427 : model1 loss : 0.435416 model2 loss : 0.020310
[11:37:55.272] iteration 17428 : model1 loss : 0.436533 model2 loss : 0.022374
[11:37:55.445] iteration 17429 : model1 loss : 0.439234 model2 loss : 0.022318
[11:37:55.614] iteration 17430 : model1 loss : 0.438229 model2 loss : 0.019918
[11:37:55.785] iteration 17431 : model1 loss : 0.439224 model2 loss : 0.025749
[11:37:55.954] iteration 17432 : model1 loss : 0.433519 model2 loss : 0.022628
[11:37:56.123] iteration 17433 : model1 loss : 0.439157 model2 loss : 0.025167
[11:37:56.291] iteration 17434 : model1 loss : 0.435275 model2 loss : 0.024565
[11:37:56.461] iteration 17435 : model1 loss : 0.438693 model2 loss : 0.022424
[11:37:56.628] iteration 17436 : model1 loss : 0.439981 model2 loss : 0.025229
[11:37:56.799] iteration 17437 : model1 loss : 0.435876 model2 loss : 0.024264
[11:37:56.965] iteration 17438 : model1 loss : 0.434774 model2 loss : 0.020566
[11:37:57.135] iteration 17439 : model1 loss : 0.430795 model2 loss : 0.020387
[11:37:57.302] iteration 17440 : model1 loss : 0.435840 model2 loss : 0.021026
[11:37:57.470] iteration 17441 : model1 loss : 0.437090 model2 loss : 0.022287
[11:37:57.637] iteration 17442 : model1 loss : 0.435983 model2 loss : 0.021547
[11:37:57.808] iteration 17443 : model1 loss : 0.440718 model2 loss : 0.023402
[11:37:57.975] iteration 17444 : model1 loss : 0.439200 model2 loss : 0.023073
[11:37:58.145] iteration 17445 : model1 loss : 0.441680 model2 loss : 0.022536
[11:37:58.312] iteration 17446 : model1 loss : 0.435417 model2 loss : 0.020653
[11:37:58.486] iteration 17447 : model1 loss : 0.436994 model2 loss : 0.021389
[11:37:58.653] iteration 17448 : model1 loss : 0.434387 model2 loss : 0.020498
[11:37:58.824] iteration 17449 : model1 loss : 0.436852 model2 loss : 0.020444
[11:37:58.991] iteration 17450 : model1 loss : 0.441597 model2 loss : 0.021804
[11:37:59.161] iteration 17451 : model1 loss : 0.435877 model2 loss : 0.022094
[11:37:59.328] iteration 17452 : model1 loss : 0.439798 model2 loss : 0.024321
[11:37:59.498] iteration 17453 : model1 loss : 0.438434 model2 loss : 0.022050
[11:37:59.666] iteration 17454 : model1 loss : 0.438663 model2 loss : 0.026251
[11:37:59.835] iteration 17455 : model1 loss : 0.438318 model2 loss : 0.020716
[11:38:00.001] iteration 17456 : model1 loss : 0.440976 model2 loss : 0.024215
[11:38:00.170] iteration 17457 : model1 loss : 0.434032 model2 loss : 0.021973
[11:38:02.164] iteration 17458 : model1 loss : 0.434442 model2 loss : 0.022539
[11:38:02.334] iteration 17459 : model1 loss : 0.437154 model2 loss : 0.021573
[11:38:02.507] iteration 17460 : model1 loss : 0.436094 model2 loss : 0.023436
[11:38:02.676] iteration 17461 : model1 loss : 0.436788 model2 loss : 0.022505
[11:38:02.844] iteration 17462 : model1 loss : 0.442336 model2 loss : 0.025130
[11:38:03.010] iteration 17463 : model1 loss : 0.433183 model2 loss : 0.021445
[11:38:03.179] iteration 17464 : model1 loss : 0.438922 model2 loss : 0.022147
[11:38:03.349] iteration 17465 : model1 loss : 0.438681 model2 loss : 0.021748
[11:38:03.520] iteration 17466 : model1 loss : 0.436856 model2 loss : 0.021340
[11:38:03.687] iteration 17467 : model1 loss : 0.438482 model2 loss : 0.023149
[11:38:03.856] iteration 17468 : model1 loss : 0.436943 model2 loss : 0.021211
[11:38:04.039] iteration 17469 : model1 loss : 0.438442 model2 loss : 0.024271
[11:38:04.210] iteration 17470 : model1 loss : 0.437194 model2 loss : 0.021125
[11:38:04.377] iteration 17471 : model1 loss : 0.440278 model2 loss : 0.021213
[11:38:04.547] iteration 17472 : model1 loss : 0.438178 model2 loss : 0.020294
[11:38:04.715] iteration 17473 : model1 loss : 0.438494 model2 loss : 0.023856
[11:38:04.885] iteration 17474 : model1 loss : 0.437345 model2 loss : 0.021030
[11:38:05.054] iteration 17475 : model1 loss : 0.438916 model2 loss : 0.023923
[11:38:05.222] iteration 17476 : model1 loss : 0.437924 model2 loss : 0.026250
[11:38:05.390] iteration 17477 : model1 loss : 0.440064 model2 loss : 0.022144
[11:38:05.560] iteration 17478 : model1 loss : 0.440852 model2 loss : 0.024653
[11:38:05.729] iteration 17479 : model1 loss : 0.437000 model2 loss : 0.023898
[11:38:05.903] iteration 17480 : model1 loss : 0.439183 model2 loss : 0.022900
[11:38:06.070] iteration 17481 : model1 loss : 0.437403 model2 loss : 0.023742
[11:38:06.240] iteration 17482 : model1 loss : 0.435827 model2 loss : 0.021311
[11:38:06.407] iteration 17483 : model1 loss : 0.435220 model2 loss : 0.020118
[11:38:06.577] iteration 17484 : model1 loss : 0.435733 model2 loss : 0.020917
[11:38:06.747] iteration 17485 : model1 loss : 0.439846 model2 loss : 0.023512
[11:38:06.936] iteration 17486 : model1 loss : 0.439882 model2 loss : 0.023558
[11:38:07.104] iteration 17487 : model1 loss : 0.432557 model2 loss : 0.019881
[11:38:07.274] iteration 17488 : model1 loss : 0.437710 model2 loss : 0.022082
[11:38:07.441] iteration 17489 : model1 loss : 0.435501 model2 loss : 0.019542
[11:38:07.610] iteration 17490 : model1 loss : 0.437781 model2 loss : 0.023417
[11:38:09.593] iteration 17491 : model1 loss : 0.434704 model2 loss : 0.022756
[11:38:09.762] iteration 17492 : model1 loss : 0.434405 model2 loss : 0.021530
[11:38:09.934] iteration 17493 : model1 loss : 0.434107 model2 loss : 0.020532
[11:38:10.102] iteration 17494 : model1 loss : 0.435713 model2 loss : 0.024207
[11:38:10.272] iteration 17495 : model1 loss : 0.439653 model2 loss : 0.022873
[11:38:10.440] iteration 17496 : model1 loss : 0.439454 model2 loss : 0.024731
[11:38:10.610] iteration 17497 : model1 loss : 0.440591 model2 loss : 0.026349
[11:38:10.777] iteration 17498 : model1 loss : 0.435887 model2 loss : 0.021684
[11:38:10.947] iteration 17499 : model1 loss : 0.440577 model2 loss : 0.025690
[11:38:11.114] iteration 17500 : model1 loss : 0.437031 model2 loss : 0.023832
[11:38:11.283] iteration 17501 : model1 loss : 0.441548 model2 loss : 0.022290
[11:38:11.450] iteration 17502 : model1 loss : 0.434579 model2 loss : 0.022737
[11:38:11.619] iteration 17503 : model1 loss : 0.434353 model2 loss : 0.021042
[11:38:11.788] iteration 17504 : model1 loss : 0.433178 model2 loss : 0.021056
[11:38:11.959] iteration 17505 : model1 loss : 0.439463 model2 loss : 0.024608
[11:38:12.127] iteration 17506 : model1 loss : 0.437214 model2 loss : 0.022523
[11:38:12.298] iteration 17507 : model1 loss : 0.439168 model2 loss : 0.021932
[11:38:12.467] iteration 17508 : model1 loss : 0.436985 model2 loss : 0.021709
[11:38:12.638] iteration 17509 : model1 loss : 0.437625 model2 loss : 0.023161
[11:38:12.805] iteration 17510 : model1 loss : 0.433917 model2 loss : 0.020730
[11:38:12.974] iteration 17511 : model1 loss : 0.436817 model2 loss : 0.022927
[11:38:13.143] iteration 17512 : model1 loss : 0.439602 model2 loss : 0.022252
[11:38:13.310] iteration 17513 : model1 loss : 0.439650 model2 loss : 0.021177
[11:38:13.475] iteration 17514 : model1 loss : 0.437696 model2 loss : 0.024535
[11:38:13.645] iteration 17515 : model1 loss : 0.437985 model2 loss : 0.023304
[11:38:13.814] iteration 17516 : model1 loss : 0.434426 model2 loss : 0.020867
[11:38:13.982] iteration 17517 : model1 loss : 0.438119 model2 loss : 0.021375
[11:38:14.150] iteration 17518 : model1 loss : 0.436922 model2 loss : 0.019637
[11:38:14.321] iteration 17519 : model1 loss : 0.438608 model2 loss : 0.022956
[11:38:14.490] iteration 17520 : model1 loss : 0.440167 model2 loss : 0.022417
[11:38:14.660] iteration 17521 : model1 loss : 0.442371 model2 loss : 0.021851
[11:38:14.827] iteration 17522 : model1 loss : 0.434888 model2 loss : 0.023276
[11:38:14.995] iteration 17523 : model1 loss : 0.438438 model2 loss : 0.021945
[11:38:16.955] iteration 17524 : model1 loss : 0.438949 model2 loss : 0.024850
[11:38:17.122] iteration 17525 : model1 loss : 0.433153 model2 loss : 0.020913
[11:38:17.294] iteration 17526 : model1 loss : 0.435275 model2 loss : 0.023565
[11:38:17.462] iteration 17527 : model1 loss : 0.432330 model2 loss : 0.021635
[11:38:17.632] iteration 17528 : model1 loss : 0.435594 model2 loss : 0.020967
[11:38:17.801] iteration 17529 : model1 loss : 0.438626 model2 loss : 0.025224
[11:38:17.971] iteration 17530 : model1 loss : 0.439648 model2 loss : 0.024233
[11:38:18.139] iteration 17531 : model1 loss : 0.444430 model2 loss : 0.026079
[11:38:18.309] iteration 17532 : model1 loss : 0.440035 model2 loss : 0.022092
[11:38:18.475] iteration 17533 : model1 loss : 0.438983 model2 loss : 0.021898
[11:38:18.644] iteration 17534 : model1 loss : 0.438140 model2 loss : 0.021813
[11:38:18.813] iteration 17535 : model1 loss : 0.438159 model2 loss : 0.023671
[11:38:18.984] iteration 17536 : model1 loss : 0.431924 model2 loss : 0.019622
[11:38:19.150] iteration 17537 : model1 loss : 0.434475 model2 loss : 0.020323
[11:38:19.319] iteration 17538 : model1 loss : 0.440970 model2 loss : 0.021457
[11:38:19.489] iteration 17539 : model1 loss : 0.437485 model2 loss : 0.022345
[11:38:19.660] iteration 17540 : model1 loss : 0.432844 model2 loss : 0.020613
[11:38:19.826] iteration 17541 : model1 loss : 0.438420 model2 loss : 0.022551
[11:38:19.997] iteration 17542 : model1 loss : 0.437780 model2 loss : 0.024374
[11:38:20.165] iteration 17543 : model1 loss : 0.443921 model2 loss : 0.025011
[11:38:20.333] iteration 17544 : model1 loss : 0.438146 model2 loss : 0.020201
[11:38:20.503] iteration 17545 : model1 loss : 0.433901 model2 loss : 0.021818
[11:38:20.673] iteration 17546 : model1 loss : 0.437017 model2 loss : 0.021976
[11:38:20.843] iteration 17547 : model1 loss : 0.440316 model2 loss : 0.021200
[11:38:21.013] iteration 17548 : model1 loss : 0.440744 model2 loss : 0.024354
[11:38:21.181] iteration 17549 : model1 loss : 0.441122 model2 loss : 0.023586
[11:38:21.354] iteration 17550 : model1 loss : 0.434140 model2 loss : 0.021448
[11:38:21.521] iteration 17551 : model1 loss : 0.435804 model2 loss : 0.022674
[11:38:21.691] iteration 17552 : model1 loss : 0.437981 model2 loss : 0.022254
[11:38:21.858] iteration 17553 : model1 loss : 0.438319 model2 loss : 0.024686
[11:38:22.027] iteration 17554 : model1 loss : 0.435995 model2 loss : 0.021886
[11:38:22.192] iteration 17555 : model1 loss : 0.441721 model2 loss : 0.021961
[11:38:22.361] iteration 17556 : model1 loss : 0.435178 model2 loss : 0.020439
[11:38:24.321] iteration 17557 : model1 loss : 0.436140 model2 loss : 0.021607
[11:38:24.492] iteration 17558 : model1 loss : 0.442393 model2 loss : 0.023888
[11:38:24.664] iteration 17559 : model1 loss : 0.432605 model2 loss : 0.019529
[11:38:24.832] iteration 17560 : model1 loss : 0.440624 model2 loss : 0.021422
[11:38:25.001] iteration 17561 : model1 loss : 0.445923 model2 loss : 0.024498
[11:38:25.168] iteration 17562 : model1 loss : 0.440031 model2 loss : 0.023513
[11:38:25.337] iteration 17563 : model1 loss : 0.434317 model2 loss : 0.022630
[11:38:25.506] iteration 17564 : model1 loss : 0.440158 model2 loss : 0.022426
[11:38:25.676] iteration 17565 : model1 loss : 0.437432 model2 loss : 0.021276
[11:38:25.845] iteration 17566 : model1 loss : 0.438385 model2 loss : 0.021653
[11:38:26.014] iteration 17567 : model1 loss : 0.437984 model2 loss : 0.019150
[11:38:26.181] iteration 17568 : model1 loss : 0.436695 model2 loss : 0.020031
[11:38:26.351] iteration 17569 : model1 loss : 0.439792 model2 loss : 0.022174
[11:38:26.521] iteration 17570 : model1 loss : 0.435211 model2 loss : 0.021858
[11:38:26.691] iteration 17571 : model1 loss : 0.437429 model2 loss : 0.023638
[11:38:26.862] iteration 17572 : model1 loss : 0.441687 model2 loss : 0.023703
[11:38:27.030] iteration 17573 : model1 loss : 0.436363 model2 loss : 0.022651
[11:38:27.197] iteration 17574 : model1 loss : 0.439826 model2 loss : 0.022632
[11:38:27.366] iteration 17575 : model1 loss : 0.433092 model2 loss : 0.021521
[11:38:27.534] iteration 17576 : model1 loss : 0.434393 model2 loss : 0.021999
[11:38:27.704] iteration 17577 : model1 loss : 0.434678 model2 loss : 0.022519
[11:38:27.871] iteration 17578 : model1 loss : 0.439740 model2 loss : 0.020612
[11:38:28.043] iteration 17579 : model1 loss : 0.437345 model2 loss : 0.029410
[11:38:28.210] iteration 17580 : model1 loss : 0.434032 model2 loss : 0.019764
[11:38:28.381] iteration 17581 : model1 loss : 0.442631 model2 loss : 0.025664
[11:38:28.550] iteration 17582 : model1 loss : 0.439287 model2 loss : 0.021937
[11:38:28.718] iteration 17583 : model1 loss : 0.436704 model2 loss : 0.021706
[11:38:28.885] iteration 17584 : model1 loss : 0.437699 model2 loss : 0.022163
[11:38:29.054] iteration 17585 : model1 loss : 0.435995 model2 loss : 0.020823
[11:38:29.220] iteration 17586 : model1 loss : 0.439634 model2 loss : 0.022170
[11:38:29.390] iteration 17587 : model1 loss : 0.433966 model2 loss : 0.020306
[11:38:29.556] iteration 17588 : model1 loss : 0.436306 model2 loss : 0.024123
[11:38:29.723] iteration 17589 : model1 loss : 0.434326 model2 loss : 0.021185
[11:38:31.665] iteration 17590 : model1 loss : 0.439608 model2 loss : 0.024332
[11:38:31.837] iteration 17591 : model1 loss : 0.437787 model2 loss : 0.023508
[11:38:32.009] iteration 17592 : model1 loss : 0.438499 model2 loss : 0.023161
[11:38:32.174] iteration 17593 : model1 loss : 0.441382 model2 loss : 0.025316
[11:38:32.342] iteration 17594 : model1 loss : 0.435595 model2 loss : 0.022771
[11:38:32.513] iteration 17595 : model1 loss : 0.438189 model2 loss : 0.020812
[11:38:32.684] iteration 17596 : model1 loss : 0.437784 model2 loss : 0.024581
[11:38:32.850] iteration 17597 : model1 loss : 0.436674 model2 loss : 0.021392
[11:38:33.021] iteration 17598 : model1 loss : 0.439874 model2 loss : 0.023250
[11:38:33.189] iteration 17599 : model1 loss : 0.432950 model2 loss : 0.022356
[11:38:33.359] iteration 17600 : model1 loss : 0.437214 model2 loss : 0.021884
[11:38:33.527] iteration 17601 : model1 loss : 0.437473 model2 loss : 0.022344
[11:38:33.697] iteration 17602 : model1 loss : 0.436526 model2 loss : 0.020418
[11:38:33.865] iteration 17603 : model1 loss : 0.437177 model2 loss : 0.020921
[11:38:34.034] iteration 17604 : model1 loss : 0.440100 model2 loss : 0.023414
[11:38:34.202] iteration 17605 : model1 loss : 0.435929 model2 loss : 0.020319
[11:38:34.371] iteration 17606 : model1 loss : 0.438260 model2 loss : 0.021592
[11:38:34.539] iteration 17607 : model1 loss : 0.434831 model2 loss : 0.022059
[11:38:34.709] iteration 17608 : model1 loss : 0.441949 model2 loss : 0.021705
[11:38:34.876] iteration 17609 : model1 loss : 0.439739 model2 loss : 0.022044
[11:38:35.046] iteration 17610 : model1 loss : 0.438002 model2 loss : 0.020668
[11:38:35.212] iteration 17611 : model1 loss : 0.435787 model2 loss : 0.018051
[11:38:35.383] iteration 17612 : model1 loss : 0.437417 model2 loss : 0.023384
[11:38:35.549] iteration 17613 : model1 loss : 0.439302 model2 loss : 0.022315
[11:38:35.717] iteration 17614 : model1 loss : 0.434296 model2 loss : 0.019561
[11:38:35.888] iteration 17615 : model1 loss : 0.435495 model2 loss : 0.022626
[11:38:36.056] iteration 17616 : model1 loss : 0.436585 model2 loss : 0.023938
[11:38:36.224] iteration 17617 : model1 loss : 0.434584 model2 loss : 0.020176
[11:38:36.392] iteration 17618 : model1 loss : 0.437882 model2 loss : 0.020890
[11:38:36.559] iteration 17619 : model1 loss : 0.437469 model2 loss : 0.023742
[11:38:36.728] iteration 17620 : model1 loss : 0.442190 model2 loss : 0.021568
[11:38:36.892] iteration 17621 : model1 loss : 0.440436 model2 loss : 0.020476
[11:38:37.060] iteration 17622 : model1 loss : 0.438227 model2 loss : 0.022443
[11:38:38.987] iteration 17623 : model1 loss : 0.441387 model2 loss : 0.023229
[11:38:39.154] iteration 17624 : model1 loss : 0.440582 model2 loss : 0.026744
[11:38:39.325] iteration 17625 : model1 loss : 0.438727 model2 loss : 0.020838
[11:38:39.493] iteration 17626 : model1 loss : 0.439732 model2 loss : 0.022996
[11:38:39.661] iteration 17627 : model1 loss : 0.436548 model2 loss : 0.017663
[11:38:39.830] iteration 17628 : model1 loss : 0.441111 model2 loss : 0.023745
[11:38:39.998] iteration 17629 : model1 loss : 0.441274 model2 loss : 0.025025
[11:38:40.168] iteration 17630 : model1 loss : 0.438994 model2 loss : 0.021545
[11:38:40.339] iteration 17631 : model1 loss : 0.437662 model2 loss : 0.021016
[11:38:40.506] iteration 17632 : model1 loss : 0.436382 model2 loss : 0.021945
[11:38:40.677] iteration 17633 : model1 loss : 0.439786 model2 loss : 0.024876
[11:38:40.846] iteration 17634 : model1 loss : 0.435236 model2 loss : 0.021816
[11:38:41.016] iteration 17635 : model1 loss : 0.441121 model2 loss : 0.021324
[11:38:41.184] iteration 17636 : model1 loss : 0.436559 model2 loss : 0.022474
[11:38:41.352] iteration 17637 : model1 loss : 0.435357 model2 loss : 0.024107
[11:38:41.521] iteration 17638 : model1 loss : 0.435374 model2 loss : 0.022444
[11:38:41.690] iteration 17639 : model1 loss : 0.437447 model2 loss : 0.024057
[11:38:41.855] iteration 17640 : model1 loss : 0.431970 model2 loss : 0.020942
[11:38:42.025] iteration 17641 : model1 loss : 0.444693 model2 loss : 0.021866
[11:38:42.192] iteration 17642 : model1 loss : 0.438308 model2 loss : 0.020682
[11:38:42.361] iteration 17643 : model1 loss : 0.439373 model2 loss : 0.022566
[11:38:42.529] iteration 17644 : model1 loss : 0.441792 model2 loss : 0.025308
[11:38:42.699] iteration 17645 : model1 loss : 0.437714 model2 loss : 0.020993
[11:38:42.868] iteration 17646 : model1 loss : 0.435519 model2 loss : 0.020258
[11:38:43.037] iteration 17647 : model1 loss : 0.441659 model2 loss : 0.024740
[11:38:43.205] iteration 17648 : model1 loss : 0.440124 model2 loss : 0.022711
[11:38:43.377] iteration 17649 : model1 loss : 0.438047 model2 loss : 0.022159
[11:38:43.547] iteration 17650 : model1 loss : 0.440134 model2 loss : 0.023022
[11:38:43.717] iteration 17651 : model1 loss : 0.438482 model2 loss : 0.019406
[11:38:43.884] iteration 17652 : model1 loss : 0.439174 model2 loss : 0.023251
[11:38:44.054] iteration 17653 : model1 loss : 0.435523 model2 loss : 0.021455
[11:38:44.219] iteration 17654 : model1 loss : 0.438293 model2 loss : 0.021516
[11:38:44.387] iteration 17655 : model1 loss : 0.436091 model2 loss : 0.020750
[11:38:46.327] iteration 17656 : model1 loss : 0.439296 model2 loss : 0.023036
[11:38:46.496] iteration 17657 : model1 loss : 0.441356 model2 loss : 0.022190
[11:38:46.664] iteration 17658 : model1 loss : 0.440146 model2 loss : 0.022834
[11:38:46.832] iteration 17659 : model1 loss : 0.437263 model2 loss : 0.019883
[11:38:47.002] iteration 17660 : model1 loss : 0.438543 model2 loss : 0.021690
[11:38:47.171] iteration 17661 : model1 loss : 0.443230 model2 loss : 0.022114
[11:38:47.339] iteration 17662 : model1 loss : 0.437092 model2 loss : 0.021148
[11:38:47.508] iteration 17663 : model1 loss : 0.436749 model2 loss : 0.021086
[11:38:47.678] iteration 17664 : model1 loss : 0.440220 model2 loss : 0.022023
[11:38:47.846] iteration 17665 : model1 loss : 0.442910 model2 loss : 0.020357
[11:38:48.014] iteration 17666 : model1 loss : 0.438531 model2 loss : 0.021606
[11:38:48.181] iteration 17667 : model1 loss : 0.438666 model2 loss : 0.024077
[11:38:48.353] iteration 17668 : model1 loss : 0.437385 model2 loss : 0.021064
[11:38:48.523] iteration 17669 : model1 loss : 0.439639 model2 loss : 0.020835
[11:38:48.692] iteration 17670 : model1 loss : 0.440314 model2 loss : 0.021798
[11:38:48.857] iteration 17671 : model1 loss : 0.437608 model2 loss : 0.024888
[11:38:49.028] iteration 17672 : model1 loss : 0.438051 model2 loss : 0.023353
[11:38:49.195] iteration 17673 : model1 loss : 0.436842 model2 loss : 0.023007
[11:38:49.365] iteration 17674 : model1 loss : 0.438316 model2 loss : 0.023287
[11:38:49.534] iteration 17675 : model1 loss : 0.440007 model2 loss : 0.021729
[11:38:49.704] iteration 17676 : model1 loss : 0.437347 model2 loss : 0.020920
[11:38:49.870] iteration 17677 : model1 loss : 0.435868 model2 loss : 0.021471
[11:38:50.038] iteration 17678 : model1 loss : 0.437850 model2 loss : 0.021018
[11:38:50.205] iteration 17679 : model1 loss : 0.436630 model2 loss : 0.022880
[11:38:50.374] iteration 17680 : model1 loss : 0.437294 model2 loss : 0.024765
[11:38:50.543] iteration 17681 : model1 loss : 0.437152 model2 loss : 0.022623
[11:38:50.712] iteration 17682 : model1 loss : 0.433596 model2 loss : 0.021171
[11:38:50.882] iteration 17683 : model1 loss : 0.433730 model2 loss : 0.020340
[11:38:51.052] iteration 17684 : model1 loss : 0.437943 model2 loss : 0.022900
[11:38:51.221] iteration 17685 : model1 loss : 0.436420 model2 loss : 0.023946
[11:38:51.389] iteration 17686 : model1 loss : 0.440130 model2 loss : 0.022673
[11:38:51.555] iteration 17687 : model1 loss : 0.434985 model2 loss : 0.019553
[11:38:51.724] iteration 17688 : model1 loss : 0.432502 model2 loss : 0.021399
[11:38:53.663] iteration 17689 : model1 loss : 0.440761 model2 loss : 0.022846
[11:38:53.830] iteration 17690 : model1 loss : 0.433831 model2 loss : 0.021332
[11:38:54.001] iteration 17691 : model1 loss : 0.435004 model2 loss : 0.020441
[11:38:54.169] iteration 17692 : model1 loss : 0.439491 model2 loss : 0.022578
[11:38:54.338] iteration 17693 : model1 loss : 0.435598 model2 loss : 0.020468
[11:38:54.507] iteration 17694 : model1 loss : 0.441662 model2 loss : 0.023009
[11:38:54.678] iteration 17695 : model1 loss : 0.442588 model2 loss : 0.022642
[11:38:54.847] iteration 17696 : model1 loss : 0.435438 model2 loss : 0.021150
[11:38:55.017] iteration 17697 : model1 loss : 0.440352 model2 loss : 0.024361
[11:38:55.184] iteration 17698 : model1 loss : 0.438896 model2 loss : 0.023008
[11:38:55.353] iteration 17699 : model1 loss : 0.435702 model2 loss : 0.019646
[11:38:55.523] iteration 17700 : model1 loss : 0.440873 model2 loss : 0.026396
[11:38:55.691] iteration 17701 : model1 loss : 0.436684 model2 loss : 0.022083
[11:38:55.861] iteration 17702 : model1 loss : 0.438361 model2 loss : 0.022683
[11:38:56.030] iteration 17703 : model1 loss : 0.444052 model2 loss : 0.025913
[11:38:56.197] iteration 17704 : model1 loss : 0.439740 model2 loss : 0.022936
[11:38:56.365] iteration 17705 : model1 loss : 0.431409 model2 loss : 0.020431
[11:38:56.533] iteration 17706 : model1 loss : 0.435000 model2 loss : 0.022392
[11:38:56.703] iteration 17707 : model1 loss : 0.439663 model2 loss : 0.022518
[11:38:56.872] iteration 17708 : model1 loss : 0.435772 model2 loss : 0.022379
[11:38:57.040] iteration 17709 : model1 loss : 0.436977 model2 loss : 0.022311
[11:38:57.209] iteration 17710 : model1 loss : 0.432284 model2 loss : 0.020419
[11:38:57.397] iteration 17711 : model1 loss : 0.436502 model2 loss : 0.020103
[11:38:57.566] iteration 17712 : model1 loss : 0.439716 model2 loss : 0.021788
[11:38:57.737] iteration 17713 : model1 loss : 0.443997 model2 loss : 0.024119
[11:38:57.903] iteration 17714 : model1 loss : 0.439039 model2 loss : 0.022475
[11:38:58.072] iteration 17715 : model1 loss : 0.440141 model2 loss : 0.023892
[11:38:58.238] iteration 17716 : model1 loss : 0.439923 model2 loss : 0.022100
[11:38:58.409] iteration 17717 : model1 loss : 0.439639 model2 loss : 0.021799
[11:38:58.577] iteration 17718 : model1 loss : 0.438828 model2 loss : 0.021717
[11:38:58.747] iteration 17719 : model1 loss : 0.436148 model2 loss : 0.023773
[11:38:58.915] iteration 17720 : model1 loss : 0.437465 model2 loss : 0.020955
[11:38:59.082] iteration 17721 : model1 loss : 0.436166 model2 loss : 0.022534
[11:39:01.075] iteration 17722 : model1 loss : 0.438638 model2 loss : 0.020827
[11:39:01.246] iteration 17723 : model1 loss : 0.433325 model2 loss : 0.022980
[11:39:01.418] iteration 17724 : model1 loss : 0.440286 model2 loss : 0.024293
[11:39:01.587] iteration 17725 : model1 loss : 0.434995 model2 loss : 0.020603
[11:39:01.756] iteration 17726 : model1 loss : 0.439398 model2 loss : 0.024609
[11:39:01.922] iteration 17727 : model1 loss : 0.440258 model2 loss : 0.025449
[11:39:02.092] iteration 17728 : model1 loss : 0.438556 model2 loss : 0.022556
[11:39:02.261] iteration 17729 : model1 loss : 0.437646 model2 loss : 0.023408
[11:39:02.431] iteration 17730 : model1 loss : 0.436734 model2 loss : 0.021843
[11:39:02.598] iteration 17731 : model1 loss : 0.440579 model2 loss : 0.026507
[11:39:02.770] iteration 17732 : model1 loss : 0.436977 model2 loss : 0.020766
[11:39:02.936] iteration 17733 : model1 loss : 0.440868 model2 loss : 0.023727
[11:39:03.106] iteration 17734 : model1 loss : 0.439671 model2 loss : 0.022990
[11:39:03.271] iteration 17735 : model1 loss : 0.437081 model2 loss : 0.021851
[11:39:03.440] iteration 17736 : model1 loss : 0.434329 model2 loss : 0.021726
[11:39:03.609] iteration 17737 : model1 loss : 0.437152 model2 loss : 0.022082
[11:39:03.780] iteration 17738 : model1 loss : 0.438551 model2 loss : 0.021085
[11:39:03.948] iteration 17739 : model1 loss : 0.441029 model2 loss : 0.022750
[11:39:04.117] iteration 17740 : model1 loss : 0.440775 model2 loss : 0.022717
[11:39:04.284] iteration 17741 : model1 loss : 0.437777 model2 loss : 0.023802
[11:39:04.453] iteration 17742 : model1 loss : 0.438215 model2 loss : 0.020909
[11:39:04.622] iteration 17743 : model1 loss : 0.436067 model2 loss : 0.023366
[11:39:04.790] iteration 17744 : model1 loss : 0.441160 model2 loss : 0.021383
[11:39:04.957] iteration 17745 : model1 loss : 0.437279 model2 loss : 0.026004
[11:39:05.126] iteration 17746 : model1 loss : 0.443283 model2 loss : 0.023440
[11:39:05.294] iteration 17747 : model1 loss : 0.436897 model2 loss : 0.019705
[11:39:05.465] iteration 17748 : model1 loss : 0.438176 model2 loss : 0.021062
[11:39:05.637] iteration 17749 : model1 loss : 0.434579 model2 loss : 0.020357
[11:39:05.805] iteration 17750 : model1 loss : 0.435614 model2 loss : 0.022240
[11:39:05.975] iteration 17751 : model1 loss : 0.438911 model2 loss : 0.023356
[11:39:06.142] iteration 17752 : model1 loss : 0.439111 model2 loss : 0.023034
[11:39:06.309] iteration 17753 : model1 loss : 0.439930 model2 loss : 0.023416
[11:39:06.477] iteration 17754 : model1 loss : 0.441715 model2 loss : 0.022329
[11:39:08.426] iteration 17755 : model1 loss : 0.439906 model2 loss : 0.024389
[11:39:08.592] iteration 17756 : model1 loss : 0.439796 model2 loss : 0.020626
[11:39:08.763] iteration 17757 : model1 loss : 0.439094 model2 loss : 0.020802
[11:39:08.930] iteration 17758 : model1 loss : 0.439382 model2 loss : 0.023464
[11:39:09.102] iteration 17759 : model1 loss : 0.438791 model2 loss : 0.021458
[11:39:09.271] iteration 17760 : model1 loss : 0.439010 model2 loss : 0.024731
[11:39:09.442] iteration 17761 : model1 loss : 0.436211 model2 loss : 0.021670
[11:39:09.610] iteration 17762 : model1 loss : 0.435508 model2 loss : 0.020865
[11:39:09.779] iteration 17763 : model1 loss : 0.431089 model2 loss : 0.023012
[11:39:09.945] iteration 17764 : model1 loss : 0.437257 model2 loss : 0.023685
[11:39:10.116] iteration 17765 : model1 loss : 0.437108 model2 loss : 0.022374
[11:39:10.282] iteration 17766 : model1 loss : 0.432517 model2 loss : 0.021017
[11:39:10.451] iteration 17767 : model1 loss : 0.437104 model2 loss : 0.021201
[11:39:10.616] iteration 17768 : model1 loss : 0.444723 model2 loss : 0.025426
[11:39:10.786] iteration 17769 : model1 loss : 0.441068 model2 loss : 0.023752
[11:39:10.953] iteration 17770 : model1 loss : 0.435882 model2 loss : 0.024174
[11:39:11.122] iteration 17771 : model1 loss : 0.435311 model2 loss : 0.021634
[11:39:11.289] iteration 17772 : model1 loss : 0.437944 model2 loss : 0.023086
[11:39:11.457] iteration 17773 : model1 loss : 0.444320 model2 loss : 0.025784
[11:39:11.624] iteration 17774 : model1 loss : 0.435147 model2 loss : 0.020581
[11:39:11.793] iteration 17775 : model1 loss : 0.444136 model2 loss : 0.025189
[11:39:11.961] iteration 17776 : model1 loss : 0.437829 model2 loss : 0.022645
[11:39:12.132] iteration 17777 : model1 loss : 0.436560 model2 loss : 0.022565
[11:39:12.298] iteration 17778 : model1 loss : 0.434399 model2 loss : 0.020554
[11:39:12.467] iteration 17779 : model1 loss : 0.438661 model2 loss : 0.022549
[11:39:12.637] iteration 17780 : model1 loss : 0.438142 model2 loss : 0.021000
[11:39:12.807] iteration 17781 : model1 loss : 0.437970 model2 loss : 0.022258
[11:39:12.975] iteration 17782 : model1 loss : 0.439103 model2 loss : 0.021728
[11:39:13.143] iteration 17783 : model1 loss : 0.437437 model2 loss : 0.019705
[11:39:13.310] iteration 17784 : model1 loss : 0.432342 model2 loss : 0.021564
[11:39:13.480] iteration 17785 : model1 loss : 0.438677 model2 loss : 0.022841
[11:39:13.644] iteration 17786 : model1 loss : 0.437616 model2 loss : 0.023195
[11:39:13.810] iteration 17787 : model1 loss : 0.438700 model2 loss : 0.021490
[11:39:15.758] iteration 17788 : model1 loss : 0.438248 model2 loss : 0.023034
[11:39:15.930] iteration 17789 : model1 loss : 0.438273 model2 loss : 0.021479
[11:39:16.102] iteration 17790 : model1 loss : 0.438356 model2 loss : 0.022047
[11:39:16.269] iteration 17791 : model1 loss : 0.438858 model2 loss : 0.019593
[11:39:16.438] iteration 17792 : model1 loss : 0.437931 model2 loss : 0.023023
[11:39:16.605] iteration 17793 : model1 loss : 0.440470 model2 loss : 0.021982
[11:39:16.776] iteration 17794 : model1 loss : 0.432666 model2 loss : 0.021735
[11:39:16.944] iteration 17795 : model1 loss : 0.438263 model2 loss : 0.020718
[11:39:17.114] iteration 17796 : model1 loss : 0.438620 model2 loss : 0.020324
[11:39:17.279] iteration 17797 : model1 loss : 0.436264 model2 loss : 0.020785
[11:39:17.450] iteration 17798 : model1 loss : 0.439898 model2 loss : 0.024553
[11:39:17.617] iteration 17799 : model1 loss : 0.438715 model2 loss : 0.023337
[11:39:17.785] iteration 17800 : model1 loss : 0.437797 model2 loss : 0.023287
[11:39:17.956] iteration 17801 : model1 loss : 0.437508 model2 loss : 0.021773
[11:39:18.125] iteration 17802 : model1 loss : 0.438210 model2 loss : 0.023304
[11:39:18.293] iteration 17803 : model1 loss : 0.441078 model2 loss : 0.023101
[11:39:18.463] iteration 17804 : model1 loss : 0.433760 model2 loss : 0.022516
[11:39:18.630] iteration 17805 : model1 loss : 0.432690 model2 loss : 0.022227
[11:39:18.800] iteration 17806 : model1 loss : 0.440271 model2 loss : 0.023624
[11:39:18.966] iteration 17807 : model1 loss : 0.438751 model2 loss : 0.019640
[11:39:19.136] iteration 17808 : model1 loss : 0.437289 model2 loss : 0.020773
[11:39:19.304] iteration 17809 : model1 loss : 0.438497 model2 loss : 0.021213
[11:39:19.473] iteration 17810 : model1 loss : 0.442343 model2 loss : 0.022554
[11:39:19.656] iteration 17811 : model1 loss : 0.436345 model2 loss : 0.022693
[11:39:19.826] iteration 17812 : model1 loss : 0.440446 model2 loss : 0.023052
[11:39:19.996] iteration 17813 : model1 loss : 0.437085 model2 loss : 0.020945
[11:39:20.165] iteration 17814 : model1 loss : 0.437324 model2 loss : 0.022286
[11:39:20.334] iteration 17815 : model1 loss : 0.435476 model2 loss : 0.022056
[11:39:20.506] iteration 17816 : model1 loss : 0.439335 model2 loss : 0.023023
[11:39:20.677] iteration 17817 : model1 loss : 0.436643 model2 loss : 0.019913
[11:39:20.848] iteration 17818 : model1 loss : 0.435021 model2 loss : 0.023372
[11:39:21.014] iteration 17819 : model1 loss : 0.443041 model2 loss : 0.023827
[11:39:21.183] iteration 17820 : model1 loss : 0.443115 model2 loss : 0.023836
[11:39:23.106] iteration 17821 : model1 loss : 0.440158 model2 loss : 0.021802
[11:39:23.275] iteration 17822 : model1 loss : 0.443192 model2 loss : 0.024344
[11:39:23.444] iteration 17823 : model1 loss : 0.439563 model2 loss : 0.022608
[11:39:23.612] iteration 17824 : model1 loss : 0.437875 model2 loss : 0.022812
[11:39:23.780] iteration 17825 : model1 loss : 0.437081 model2 loss : 0.021852
[11:39:23.947] iteration 17826 : model1 loss : 0.433398 model2 loss : 0.020341
[11:39:24.118] iteration 17827 : model1 loss : 0.435416 model2 loss : 0.020769
[11:39:24.286] iteration 17828 : model1 loss : 0.438332 model2 loss : 0.022521
[11:39:24.455] iteration 17829 : model1 loss : 0.438629 model2 loss : 0.022443
[11:39:24.621] iteration 17830 : model1 loss : 0.434215 model2 loss : 0.022632
[11:39:24.791] iteration 17831 : model1 loss : 0.441475 model2 loss : 0.024316
[11:39:24.957] iteration 17832 : model1 loss : 0.437893 model2 loss : 0.019595
[11:39:25.127] iteration 17833 : model1 loss : 0.441888 model2 loss : 0.022377
[11:39:25.294] iteration 17834 : model1 loss : 0.436254 model2 loss : 0.020461
[11:39:25.464] iteration 17835 : model1 loss : 0.440640 model2 loss : 0.022558
[11:39:25.630] iteration 17836 : model1 loss : 0.436206 model2 loss : 0.022800
[11:39:25.799] iteration 17837 : model1 loss : 0.439804 model2 loss : 0.024836
[11:39:25.967] iteration 17838 : model1 loss : 0.438105 model2 loss : 0.022713
[11:39:26.136] iteration 17839 : model1 loss : 0.439306 model2 loss : 0.024539
[11:39:26.304] iteration 17840 : model1 loss : 0.437764 model2 loss : 0.022285
[11:39:26.473] iteration 17841 : model1 loss : 0.438119 model2 loss : 0.023215
[11:39:26.641] iteration 17842 : model1 loss : 0.440210 model2 loss : 0.026257
[11:39:26.810] iteration 17843 : model1 loss : 0.437738 model2 loss : 0.021934
[11:39:26.979] iteration 17844 : model1 loss : 0.433741 model2 loss : 0.020912
[11:39:27.147] iteration 17845 : model1 loss : 0.433632 model2 loss : 0.020140
[11:39:27.315] iteration 17846 : model1 loss : 0.436918 model2 loss : 0.021591
[11:39:27.489] iteration 17847 : model1 loss : 0.436334 model2 loss : 0.019469
[11:39:27.656] iteration 17848 : model1 loss : 0.439065 model2 loss : 0.023837
[11:39:27.826] iteration 17849 : model1 loss : 0.435500 model2 loss : 0.021832
[11:39:27.993] iteration 17850 : model1 loss : 0.438201 model2 loss : 0.026296
[11:39:28.161] iteration 17851 : model1 loss : 0.438311 model2 loss : 0.023833
[11:39:28.326] iteration 17852 : model1 loss : 0.435727 model2 loss : 0.021754
[11:39:28.495] iteration 17853 : model1 loss : 0.437019 model2 loss : 0.021512
[11:39:30.414] iteration 17854 : model1 loss : 0.437502 model2 loss : 0.023160
[11:39:30.587] iteration 17855 : model1 loss : 0.444021 model2 loss : 0.028302
[11:39:30.757] iteration 17856 : model1 loss : 0.439530 model2 loss : 0.020899
[11:39:30.926] iteration 17857 : model1 loss : 0.436027 model2 loss : 0.021482
[11:39:31.094] iteration 17858 : model1 loss : 0.438371 model2 loss : 0.020160
[11:39:31.260] iteration 17859 : model1 loss : 0.436505 model2 loss : 0.022097
[11:39:31.431] iteration 17860 : model1 loss : 0.436608 model2 loss : 0.020021
[11:39:31.606] iteration 17861 : model1 loss : 0.440769 model2 loss : 0.022151
[11:39:31.781] iteration 17862 : model1 loss : 0.437486 model2 loss : 0.023185
[11:39:31.948] iteration 17863 : model1 loss : 0.438796 model2 loss : 0.023737
[11:39:32.118] iteration 17864 : model1 loss : 0.437450 model2 loss : 0.020729
[11:39:32.286] iteration 17865 : model1 loss : 0.435641 model2 loss : 0.020856
[11:39:32.454] iteration 17866 : model1 loss : 0.436273 model2 loss : 0.021766
[11:39:32.621] iteration 17867 : model1 loss : 0.433383 model2 loss : 0.022995
[11:39:32.805] iteration 17868 : model1 loss : 0.437752 model2 loss : 0.021413
[11:39:32.972] iteration 17869 : model1 loss : 0.436261 model2 loss : 0.022571
[11:39:33.142] iteration 17870 : model1 loss : 0.442592 model2 loss : 0.022800
[11:39:33.310] iteration 17871 : model1 loss : 0.438530 model2 loss : 0.021081
[11:39:33.479] iteration 17872 : model1 loss : 0.434073 model2 loss : 0.022469
[11:39:33.646] iteration 17873 : model1 loss : 0.437704 model2 loss : 0.024587
[11:39:33.815] iteration 17874 : model1 loss : 0.438607 model2 loss : 0.024304
[11:39:33.981] iteration 17875 : model1 loss : 0.436848 model2 loss : 0.018302
[11:39:34.151] iteration 17876 : model1 loss : 0.441720 model2 loss : 0.024869
[11:39:34.319] iteration 17877 : model1 loss : 0.439004 model2 loss : 0.022029
[11:39:34.487] iteration 17878 : model1 loss : 0.431239 model2 loss : 0.019481
[11:39:34.656] iteration 17879 : model1 loss : 0.436454 model2 loss : 0.020594
[11:39:34.825] iteration 17880 : model1 loss : 0.436709 model2 loss : 0.022882
[11:39:34.991] iteration 17881 : model1 loss : 0.440248 model2 loss : 0.023378
[11:39:35.159] iteration 17882 : model1 loss : 0.439167 model2 loss : 0.020578
[11:39:35.328] iteration 17883 : model1 loss : 0.438407 model2 loss : 0.022800
[11:39:35.499] iteration 17884 : model1 loss : 0.436698 model2 loss : 0.021331
[11:39:35.667] iteration 17885 : model1 loss : 0.441226 model2 loss : 0.022467
[11:39:35.835] iteration 17886 : model1 loss : 0.436762 model2 loss : 0.020863
[11:39:37.765] iteration 17887 : model1 loss : 0.437730 model2 loss : 0.022950
[11:39:37.932] iteration 17888 : model1 loss : 0.433917 model2 loss : 0.022571
[11:39:38.102] iteration 17889 : model1 loss : 0.434704 model2 loss : 0.021413
[11:39:38.268] iteration 17890 : model1 loss : 0.437873 model2 loss : 0.023081
[11:39:38.440] iteration 17891 : model1 loss : 0.436476 model2 loss : 0.019926
[11:39:38.606] iteration 17892 : model1 loss : 0.437393 model2 loss : 0.022885
[11:39:38.777] iteration 17893 : model1 loss : 0.437648 model2 loss : 0.020358
[11:39:38.945] iteration 17894 : model1 loss : 0.434198 model2 loss : 0.019992
[11:39:39.115] iteration 17895 : model1 loss : 0.437696 model2 loss : 0.021566
[11:39:39.282] iteration 17896 : model1 loss : 0.443789 model2 loss : 0.024956
[11:39:39.451] iteration 17897 : model1 loss : 0.439039 model2 loss : 0.022766
[11:39:39.618] iteration 17898 : model1 loss : 0.436358 model2 loss : 0.019411
[11:39:39.787] iteration 17899 : model1 loss : 0.437320 model2 loss : 0.022182
[11:39:39.955] iteration 17900 : model1 loss : 0.437829 model2 loss : 0.023445
[11:39:40.124] iteration 17901 : model1 loss : 0.433440 model2 loss : 0.023278
[11:39:40.290] iteration 17902 : model1 loss : 0.439077 model2 loss : 0.022943
[11:39:40.461] iteration 17903 : model1 loss : 0.437070 model2 loss : 0.021024
[11:39:40.629] iteration 17904 : model1 loss : 0.437563 model2 loss : 0.021989
[11:39:40.799] iteration 17905 : model1 loss : 0.438680 model2 loss : 0.023186
[11:39:40.965] iteration 17906 : model1 loss : 0.439355 model2 loss : 0.019989
[11:39:41.135] iteration 17907 : model1 loss : 0.440138 model2 loss : 0.021781
[11:39:41.303] iteration 17908 : model1 loss : 0.439796 model2 loss : 0.022227
[11:39:41.472] iteration 17909 : model1 loss : 0.441977 model2 loss : 0.024778
[11:39:41.640] iteration 17910 : model1 loss : 0.436927 model2 loss : 0.022281
[11:39:41.810] iteration 17911 : model1 loss : 0.442326 model2 loss : 0.022279
[11:39:41.978] iteration 17912 : model1 loss : 0.440272 model2 loss : 0.024401
[11:39:42.147] iteration 17913 : model1 loss : 0.441024 model2 loss : 0.025149
[11:39:42.314] iteration 17914 : model1 loss : 0.435844 model2 loss : 0.018623
[11:39:42.483] iteration 17915 : model1 loss : 0.438936 model2 loss : 0.024116
[11:39:42.650] iteration 17916 : model1 loss : 0.433431 model2 loss : 0.019742
[11:39:42.820] iteration 17917 : model1 loss : 0.435211 model2 loss : 0.022744
[11:39:43.006] iteration 17918 : model1 loss : 0.437181 model2 loss : 0.021455
[11:39:43.173] iteration 17919 : model1 loss : 0.434939 model2 loss : 0.022892
[11:39:45.121] iteration 17920 : model1 loss : 0.430558 model2 loss : 0.021630
[11:39:45.289] iteration 17921 : model1 loss : 0.435521 model2 loss : 0.020315
[11:39:45.460] iteration 17922 : model1 loss : 0.440663 model2 loss : 0.024655
[11:39:45.627] iteration 17923 : model1 loss : 0.436026 model2 loss : 0.019677
[11:39:45.796] iteration 17924 : model1 loss : 0.443543 model2 loss : 0.027477
[11:39:45.964] iteration 17925 : model1 loss : 0.438957 model2 loss : 0.021200
[11:39:46.134] iteration 17926 : model1 loss : 0.441294 model2 loss : 0.024903
[11:39:46.300] iteration 17927 : model1 loss : 0.440664 model2 loss : 0.020160
[11:39:46.470] iteration 17928 : model1 loss : 0.441126 model2 loss : 0.023641
[11:39:46.637] iteration 17929 : model1 loss : 0.440261 model2 loss : 0.022976
[11:39:46.806] iteration 17930 : model1 loss : 0.438908 model2 loss : 0.021344
[11:39:46.973] iteration 17931 : model1 loss : 0.444494 model2 loss : 0.028573
[11:39:47.142] iteration 17932 : model1 loss : 0.438452 model2 loss : 0.022151
[11:39:47.308] iteration 17933 : model1 loss : 0.432872 model2 loss : 0.021068
[11:39:47.479] iteration 17934 : model1 loss : 0.438506 model2 loss : 0.023978
[11:39:47.645] iteration 17935 : model1 loss : 0.438921 model2 loss : 0.023164
[11:39:47.813] iteration 17936 : model1 loss : 0.435212 model2 loss : 0.024488
[11:39:47.981] iteration 17937 : model1 loss : 0.437518 model2 loss : 0.021774
[11:39:48.150] iteration 17938 : model1 loss : 0.437078 model2 loss : 0.023881
[11:39:48.320] iteration 17939 : model1 loss : 0.435917 model2 loss : 0.023115
[11:39:48.495] iteration 17940 : model1 loss : 0.439965 model2 loss : 0.020766
[11:39:48.663] iteration 17941 : model1 loss : 0.438748 model2 loss : 0.025979
[11:39:48.832] iteration 17942 : model1 loss : 0.443981 model2 loss : 0.026001
[11:39:48.999] iteration 17943 : model1 loss : 0.434874 model2 loss : 0.021706
[11:39:49.168] iteration 17944 : model1 loss : 0.438433 model2 loss : 0.022817
[11:39:49.336] iteration 17945 : model1 loss : 0.439441 model2 loss : 0.023794
[11:39:49.509] iteration 17946 : model1 loss : 0.441678 model2 loss : 0.022957
[11:39:49.676] iteration 17947 : model1 loss : 0.442311 model2 loss : 0.026877
[11:39:49.846] iteration 17948 : model1 loss : 0.435909 model2 loss : 0.022549
[11:39:50.013] iteration 17949 : model1 loss : 0.435958 model2 loss : 0.022691
[11:39:50.184] iteration 17950 : model1 loss : 0.438862 model2 loss : 0.020983
[11:39:50.351] iteration 17951 : model1 loss : 0.435731 model2 loss : 0.023032
[11:39:50.521] iteration 17952 : model1 loss : 0.434681 model2 loss : 0.023400
[11:39:52.461] iteration 17953 : model1 loss : 0.433935 model2 loss : 0.021000
[11:39:52.629] iteration 17954 : model1 loss : 0.438118 model2 loss : 0.022488
[11:39:52.798] iteration 17955 : model1 loss : 0.440023 model2 loss : 0.021248
[11:39:52.966] iteration 17956 : model1 loss : 0.444807 model2 loss : 0.025635
[11:39:53.133] iteration 17957 : model1 loss : 0.438226 model2 loss : 0.024250
[11:39:53.301] iteration 17958 : model1 loss : 0.438467 model2 loss : 0.024718
[11:39:53.469] iteration 17959 : model1 loss : 0.437700 model2 loss : 0.026221
[11:39:53.655] iteration 17960 : model1 loss : 0.441145 model2 loss : 0.023689
[11:39:53.825] iteration 17961 : model1 loss : 0.436663 model2 loss : 0.021792
[11:39:53.992] iteration 17962 : model1 loss : 0.442031 model2 loss : 0.023508
[11:39:54.162] iteration 17963 : model1 loss : 0.436009 model2 loss : 0.022526
[11:39:54.330] iteration 17964 : model1 loss : 0.439475 model2 loss : 0.026436
[11:39:54.501] iteration 17965 : model1 loss : 0.433660 model2 loss : 0.022563
[11:39:54.668] iteration 17966 : model1 loss : 0.436195 model2 loss : 0.021777
[11:39:54.836] iteration 17967 : model1 loss : 0.438364 model2 loss : 0.022017
[11:39:55.004] iteration 17968 : model1 loss : 0.436497 model2 loss : 0.020287
[11:39:55.173] iteration 17969 : model1 loss : 0.436050 model2 loss : 0.021131
[11:39:55.342] iteration 17970 : model1 loss : 0.435889 model2 loss : 0.020906
[11:39:55.523] iteration 17971 : model1 loss : 0.442010 model2 loss : 0.024193
[11:39:55.692] iteration 17972 : model1 loss : 0.437189 model2 loss : 0.021692
[11:39:55.862] iteration 17973 : model1 loss : 0.439450 model2 loss : 0.022495
[11:39:56.027] iteration 17974 : model1 loss : 0.437049 model2 loss : 0.021161
[11:39:56.197] iteration 17975 : model1 loss : 0.438615 model2 loss : 0.020245
[11:39:56.366] iteration 17976 : model1 loss : 0.436259 model2 loss : 0.020977
[11:39:56.537] iteration 17977 : model1 loss : 0.441626 model2 loss : 0.025247
[11:39:56.706] iteration 17978 : model1 loss : 0.436230 model2 loss : 0.022207
[11:39:56.875] iteration 17979 : model1 loss : 0.431171 model2 loss : 0.020471
[11:39:57.042] iteration 17980 : model1 loss : 0.440952 model2 loss : 0.019832
[11:39:57.212] iteration 17981 : model1 loss : 0.438578 model2 loss : 0.022278
[11:39:57.380] iteration 17982 : model1 loss : 0.439816 model2 loss : 0.020230
[11:39:57.550] iteration 17983 : model1 loss : 0.436987 model2 loss : 0.021824
[11:39:57.719] iteration 17984 : model1 loss : 0.438030 model2 loss : 0.021789
[11:39:57.888] iteration 17985 : model1 loss : 0.437435 model2 loss : 0.021006
[11:39:59.829] iteration 17986 : model1 loss : 0.439570 model2 loss : 0.021930
[11:39:59.997] iteration 17987 : model1 loss : 0.435798 model2 loss : 0.021646
[11:40:00.169] iteration 17988 : model1 loss : 0.438840 model2 loss : 0.019143
[11:40:00.337] iteration 17989 : model1 loss : 0.436520 model2 loss : 0.020993
[11:40:00.511] iteration 17990 : model1 loss : 0.441747 model2 loss : 0.025815
[11:40:00.680] iteration 17991 : model1 loss : 0.443267 model2 loss : 0.025175
[11:40:00.851] iteration 17992 : model1 loss : 0.442387 model2 loss : 0.027016
[11:40:01.019] iteration 17993 : model1 loss : 0.436010 model2 loss : 0.021004
[11:40:01.189] iteration 17994 : model1 loss : 0.437827 model2 loss : 0.023436
[11:40:01.356] iteration 17995 : model1 loss : 0.438447 model2 loss : 0.022959
[11:40:01.529] iteration 17996 : model1 loss : 0.437116 model2 loss : 0.022752
[11:40:01.697] iteration 17997 : model1 loss : 0.434371 model2 loss : 0.020069
[11:40:01.869] iteration 17998 : model1 loss : 0.436149 model2 loss : 0.020920
[11:40:02.037] iteration 17999 : model1 loss : 0.438832 model2 loss : 0.020426
[11:40:02.205] iteration 18000 : model1 loss : 0.437468 model2 loss : 0.020564
[11:40:10.502] iteration 18000 : model1_mean_dice : 0.895581 model1_mean_hd95 : 3.731656
[11:40:18.789] iteration 18000 : model2_mean_dice : 0.890774 model2_mean_hd95 : 2.185001
[11:40:18.809] save model1 to ../model/ACDC/EVILv1_kl0.5_tau0.25_21_1337/unet\model1_iter_18000.pth
[11:40:18.829] save model2 to ../model/ACDC/EVILv1_kl0.5_tau0.25_21_1337/unet\model2_iter_18000.pth
[11:40:19.003] iteration 18001 : model1 loss : 0.436582 model2 loss : 0.019919
[11:40:19.174] iteration 18002 : model1 loss : 0.437459 model2 loss : 0.020989
[11:40:19.344] iteration 18003 : model1 loss : 0.435953 model2 loss : 0.023336
[11:40:19.516] iteration 18004 : model1 loss : 0.437131 model2 loss : 0.022734
[11:40:19.686] iteration 18005 : model1 loss : 0.439126 model2 loss : 0.022078
[11:40:19.856] iteration 18006 : model1 loss : 0.439139 model2 loss : 0.023500
[11:40:20.025] iteration 18007 : model1 loss : 0.436108 model2 loss : 0.021013
[11:40:20.192] iteration 18008 : model1 loss : 0.437740 model2 loss : 0.021357
[11:40:20.361] iteration 18009 : model1 loss : 0.440713 model2 loss : 0.023148
[11:40:20.526] iteration 18010 : model1 loss : 0.436720 model2 loss : 0.020312
[11:40:20.695] iteration 18011 : model1 loss : 0.434194 model2 loss : 0.022131
[11:40:20.862] iteration 18012 : model1 loss : 0.435727 model2 loss : 0.020956
[11:40:21.030] iteration 18013 : model1 loss : 0.437380 model2 loss : 0.021725
[11:40:21.196] iteration 18014 : model1 loss : 0.434399 model2 loss : 0.018820
[11:40:21.365] iteration 18015 : model1 loss : 0.436328 model2 loss : 0.022292
[11:40:21.531] iteration 18016 : model1 loss : 0.439601 model2 loss : 0.021712
[11:40:21.698] iteration 18017 : model1 loss : 0.436432 model2 loss : 0.018812
[11:40:21.880] iteration 18018 : model1 loss : 0.440603 model2 loss : 0.023921
[11:40:23.821] iteration 18019 : model1 loss : 0.437079 model2 loss : 0.020977
[11:40:23.987] iteration 18020 : model1 loss : 0.441267 model2 loss : 0.021662
[11:40:24.158] iteration 18021 : model1 loss : 0.435898 model2 loss : 0.021118
[11:40:24.323] iteration 18022 : model1 loss : 0.443810 model2 loss : 0.023669
[11:40:24.493] iteration 18023 : model1 loss : 0.439109 model2 loss : 0.026155
[11:40:24.659] iteration 18024 : model1 loss : 0.434218 model2 loss : 0.019955
[11:40:24.831] iteration 18025 : model1 loss : 0.438476 model2 loss : 0.022641
[11:40:24.996] iteration 18026 : model1 loss : 0.439085 model2 loss : 0.021042
[11:40:25.169] iteration 18027 : model1 loss : 0.438111 model2 loss : 0.023893
[11:40:25.335] iteration 18028 : model1 loss : 0.433185 model2 loss : 0.022595
[11:40:25.505] iteration 18029 : model1 loss : 0.436911 model2 loss : 0.020175
[11:40:25.673] iteration 18030 : model1 loss : 0.442661 model2 loss : 0.025402
[11:40:25.845] iteration 18031 : model1 loss : 0.436413 model2 loss : 0.021752
[11:40:26.012] iteration 18032 : model1 loss : 0.443871 model2 loss : 0.024613
[11:40:26.180] iteration 18033 : model1 loss : 0.439355 model2 loss : 0.022295
[11:40:26.345] iteration 18034 : model1 loss : 0.442132 model2 loss : 0.024687
[11:40:26.516] iteration 18035 : model1 loss : 0.437245 model2 loss : 0.024091
[11:40:26.685] iteration 18036 : model1 loss : 0.437583 model2 loss : 0.021855
[11:40:26.855] iteration 18037 : model1 loss : 0.433818 model2 loss : 0.021171
[11:40:27.022] iteration 18038 : model1 loss : 0.442630 model2 loss : 0.024849
[11:40:27.192] iteration 18039 : model1 loss : 0.437627 model2 loss : 0.021891
[11:40:27.357] iteration 18040 : model1 loss : 0.435903 model2 loss : 0.023247
[11:40:27.531] iteration 18041 : model1 loss : 0.437832 model2 loss : 0.019478
[11:40:27.698] iteration 18042 : model1 loss : 0.439164 model2 loss : 0.020894
[11:40:27.866] iteration 18043 : model1 loss : 0.431281 model2 loss : 0.020909
[11:40:28.033] iteration 18044 : model1 loss : 0.439139 model2 loss : 0.020657
[11:40:28.203] iteration 18045 : model1 loss : 0.438166 model2 loss : 0.023248
[11:40:28.371] iteration 18046 : model1 loss : 0.438961 model2 loss : 0.020432
[11:40:28.541] iteration 18047 : model1 loss : 0.434043 model2 loss : 0.023270
[11:40:28.709] iteration 18048 : model1 loss : 0.439193 model2 loss : 0.021458
[11:40:28.879] iteration 18049 : model1 loss : 0.439232 model2 loss : 0.021133
[11:40:29.047] iteration 18050 : model1 loss : 0.438580 model2 loss : 0.021733
[11:40:29.213] iteration 18051 : model1 loss : 0.436796 model2 loss : 0.021769
[11:40:31.140] iteration 18052 : model1 loss : 0.438030 model2 loss : 0.024060
[11:40:31.312] iteration 18053 : model1 loss : 0.437407 model2 loss : 0.022470
[11:40:31.480] iteration 18054 : model1 loss : 0.438418 model2 loss : 0.022198
[11:40:31.646] iteration 18055 : model1 loss : 0.437928 model2 loss : 0.020268
[11:40:31.815] iteration 18056 : model1 loss : 0.434796 model2 loss : 0.022064
[11:40:31.982] iteration 18057 : model1 loss : 0.437715 model2 loss : 0.021648
[11:40:32.152] iteration 18058 : model1 loss : 0.436794 model2 loss : 0.020387
[11:40:32.317] iteration 18059 : model1 loss : 0.440065 model2 loss : 0.023549
[11:40:32.487] iteration 18060 : model1 loss : 0.440967 model2 loss : 0.025237
[11:40:32.653] iteration 18061 : model1 loss : 0.440287 model2 loss : 0.023833
[11:40:32.824] iteration 18062 : model1 loss : 0.439424 model2 loss : 0.021033
[11:40:32.990] iteration 18063 : model1 loss : 0.439683 model2 loss : 0.022732
[11:40:33.158] iteration 18064 : model1 loss : 0.438028 model2 loss : 0.021734
[11:40:33.326] iteration 18065 : model1 loss : 0.436725 model2 loss : 0.020440
[11:40:33.495] iteration 18066 : model1 loss : 0.436048 model2 loss : 0.022055
[11:40:33.662] iteration 18067 : model1 loss : 0.443750 model2 loss : 0.025898
[11:40:33.829] iteration 18068 : model1 loss : 0.434746 model2 loss : 0.021113
[11:40:33.998] iteration 18069 : model1 loss : 0.438622 model2 loss : 0.021544
[11:40:34.165] iteration 18070 : model1 loss : 0.436313 model2 loss : 0.022216
[11:40:34.333] iteration 18071 : model1 loss : 0.434596 model2 loss : 0.018167
[11:40:34.503] iteration 18072 : model1 loss : 0.435981 model2 loss : 0.023453
[11:40:34.670] iteration 18073 : model1 loss : 0.443007 model2 loss : 0.023333
[11:40:34.839] iteration 18074 : model1 loss : 0.438240 model2 loss : 0.020762
[11:40:35.005] iteration 18075 : model1 loss : 0.433207 model2 loss : 0.020393
[11:40:35.172] iteration 18076 : model1 loss : 0.441266 model2 loss : 0.023587
[11:40:35.339] iteration 18077 : model1 loss : 0.438479 model2 loss : 0.021773
[11:40:35.511] iteration 18078 : model1 loss : 0.433951 model2 loss : 0.020254
[11:40:35.701] iteration 18079 : model1 loss : 0.440780 model2 loss : 0.025963
[11:40:35.874] iteration 18080 : model1 loss : 0.439119 model2 loss : 0.021243
[11:40:36.039] iteration 18081 : model1 loss : 0.441484 model2 loss : 0.022624
[11:40:36.208] iteration 18082 : model1 loss : 0.434313 model2 loss : 0.019155
[11:40:36.372] iteration 18083 : model1 loss : 0.437629 model2 loss : 0.025052
[11:40:36.540] iteration 18084 : model1 loss : 0.436294 model2 loss : 0.020729
[11:40:38.461] iteration 18085 : model1 loss : 0.435389 model2 loss : 0.021781
[11:40:38.626] iteration 18086 : model1 loss : 0.438163 model2 loss : 0.022955
[11:40:38.796] iteration 18087 : model1 loss : 0.437866 model2 loss : 0.024135
[11:40:38.962] iteration 18088 : model1 loss : 0.440167 model2 loss : 0.023244
[11:40:39.129] iteration 18089 : model1 loss : 0.437740 model2 loss : 0.021759
[11:40:39.297] iteration 18090 : model1 loss : 0.434794 model2 loss : 0.021043
[11:40:39.463] iteration 18091 : model1 loss : 0.438474 model2 loss : 0.026593
[11:40:39.630] iteration 18092 : model1 loss : 0.436380 model2 loss : 0.021330
[11:40:39.798] iteration 18093 : model1 loss : 0.434900 model2 loss : 0.019676
[11:40:39.967] iteration 18094 : model1 loss : 0.443857 model2 loss : 0.021223
[11:40:40.135] iteration 18095 : model1 loss : 0.433733 model2 loss : 0.022147
[11:40:40.302] iteration 18096 : model1 loss : 0.435067 model2 loss : 0.018891
[11:40:40.471] iteration 18097 : model1 loss : 0.438932 model2 loss : 0.023029
[11:40:40.636] iteration 18098 : model1 loss : 0.440087 model2 loss : 0.021830
[11:40:40.805] iteration 18099 : model1 loss : 0.436852 model2 loss : 0.024694
[11:40:40.972] iteration 18100 : model1 loss : 0.444067 model2 loss : 0.029948
[11:40:41.141] iteration 18101 : model1 loss : 0.435687 model2 loss : 0.021658
[11:40:41.305] iteration 18102 : model1 loss : 0.439366 model2 loss : 0.020889
[11:40:41.471] iteration 18103 : model1 loss : 0.435632 model2 loss : 0.020762
[11:40:41.637] iteration 18104 : model1 loss : 0.436196 model2 loss : 0.022923
[11:40:41.805] iteration 18105 : model1 loss : 0.442130 model2 loss : 0.023859
[11:40:41.973] iteration 18106 : model1 loss : 0.437428 model2 loss : 0.021346
[11:40:42.144] iteration 18107 : model1 loss : 0.435234 model2 loss : 0.017428
[11:40:42.309] iteration 18108 : model1 loss : 0.432990 model2 loss : 0.022495
[11:40:42.478] iteration 18109 : model1 loss : 0.437995 model2 loss : 0.020537
[11:40:42.645] iteration 18110 : model1 loss : 0.439153 model2 loss : 0.023558
[11:40:42.819] iteration 18111 : model1 loss : 0.441997 model2 loss : 0.022803
[11:40:42.985] iteration 18112 : model1 loss : 0.435157 model2 loss : 0.022519
[11:40:43.153] iteration 18113 : model1 loss : 0.438084 model2 loss : 0.021702
[11:40:43.319] iteration 18114 : model1 loss : 0.439331 model2 loss : 0.019262
[11:40:43.486] iteration 18115 : model1 loss : 0.437856 model2 loss : 0.020195
[11:40:43.652] iteration 18116 : model1 loss : 0.438742 model2 loss : 0.023368
[11:40:43.820] iteration 18117 : model1 loss : 0.440312 model2 loss : 0.022957
[11:40:45.723] iteration 18118 : model1 loss : 0.440116 model2 loss : 0.023352
[11:40:45.899] iteration 18119 : model1 loss : 0.438240 model2 loss : 0.023069
[11:40:46.067] iteration 18120 : model1 loss : 0.435557 model2 loss : 0.020444
[11:40:46.234] iteration 18121 : model1 loss : 0.437677 model2 loss : 0.022396
[11:40:46.402] iteration 18122 : model1 loss : 0.433264 model2 loss : 0.021931
[11:40:46.570] iteration 18123 : model1 loss : 0.440738 model2 loss : 0.025164
[11:40:46.740] iteration 18124 : model1 loss : 0.439173 model2 loss : 0.022938
[11:40:46.911] iteration 18125 : model1 loss : 0.444652 model2 loss : 0.024307
[11:40:47.081] iteration 18126 : model1 loss : 0.435764 model2 loss : 0.023701
[11:40:47.247] iteration 18127 : model1 loss : 0.436333 model2 loss : 0.018478
[11:40:47.416] iteration 18128 : model1 loss : 0.435810 model2 loss : 0.022051
[11:40:47.581] iteration 18129 : model1 loss : 0.438711 model2 loss : 0.022438
[11:40:47.750] iteration 18130 : model1 loss : 0.436269 model2 loss : 0.020814
[11:40:47.920] iteration 18131 : model1 loss : 0.432251 model2 loss : 0.021034
[11:40:48.088] iteration 18132 : model1 loss : 0.437604 model2 loss : 0.020909
[11:40:48.256] iteration 18133 : model1 loss : 0.443498 model2 loss : 0.022792
[11:40:48.425] iteration 18134 : model1 loss : 0.435138 model2 loss : 0.020953
[11:40:48.593] iteration 18135 : model1 loss : 0.435222 model2 loss : 0.019692
[11:40:48.761] iteration 18136 : model1 loss : 0.438605 model2 loss : 0.021741
[11:40:48.930] iteration 18137 : model1 loss : 0.440585 model2 loss : 0.027497
[11:40:49.099] iteration 18138 : model1 loss : 0.436290 model2 loss : 0.022469
[11:40:49.266] iteration 18139 : model1 loss : 0.437152 model2 loss : 0.022151
[11:40:49.434] iteration 18140 : model1 loss : 0.434487 model2 loss : 0.020622
[11:40:49.603] iteration 18141 : model1 loss : 0.436565 model2 loss : 0.019474
[11:40:49.771] iteration 18142 : model1 loss : 0.436907 model2 loss : 0.021559
[11:40:49.938] iteration 18143 : model1 loss : 0.439414 model2 loss : 0.021707
[11:40:50.107] iteration 18144 : model1 loss : 0.436757 model2 loss : 0.018217
[11:40:50.275] iteration 18145 : model1 loss : 0.439121 model2 loss : 0.023287
[11:40:50.444] iteration 18146 : model1 loss : 0.436366 model2 loss : 0.020197
[11:40:50.611] iteration 18147 : model1 loss : 0.437613 model2 loss : 0.024110
[11:40:50.780] iteration 18148 : model1 loss : 0.435111 model2 loss : 0.022003
[11:40:50.946] iteration 18149 : model1 loss : 0.441108 model2 loss : 0.023810
[11:40:51.113] iteration 18150 : model1 loss : 0.443110 model2 loss : 0.022192
[11:40:53.028] iteration 18151 : model1 loss : 0.436774 model2 loss : 0.021027
[11:40:53.200] iteration 18152 : model1 loss : 0.435907 model2 loss : 0.021729
[11:40:53.371] iteration 18153 : model1 loss : 0.435037 model2 loss : 0.019942
[11:40:53.537] iteration 18154 : model1 loss : 0.436813 model2 loss : 0.022998
[11:40:53.705] iteration 18155 : model1 loss : 0.437708 model2 loss : 0.021614
[11:40:53.872] iteration 18156 : model1 loss : 0.437060 model2 loss : 0.019947
[11:40:54.047] iteration 18157 : model1 loss : 0.436862 model2 loss : 0.022116
[11:40:54.214] iteration 18158 : model1 loss : 0.436275 model2 loss : 0.020250
[11:40:54.383] iteration 18159 : model1 loss : 0.440817 model2 loss : 0.026885
[11:40:54.552] iteration 18160 : model1 loss : 0.439303 model2 loss : 0.023946
[11:40:54.721] iteration 18161 : model1 loss : 0.440172 model2 loss : 0.022842
[11:40:54.888] iteration 18162 : model1 loss : 0.435635 model2 loss : 0.023919
[11:40:55.055] iteration 18163 : model1 loss : 0.438376 model2 loss : 0.021249
[11:40:55.221] iteration 18164 : model1 loss : 0.436976 model2 loss : 0.021825
[11:40:55.388] iteration 18165 : model1 loss : 0.440895 model2 loss : 0.024035
[11:40:55.556] iteration 18166 : model1 loss : 0.438232 model2 loss : 0.019019
[11:40:55.724] iteration 18167 : model1 loss : 0.444685 model2 loss : 0.023707
[11:40:55.894] iteration 18168 : model1 loss : 0.436789 model2 loss : 0.021484
[11:40:56.063] iteration 18169 : model1 loss : 0.442837 model2 loss : 0.027048
[11:40:56.230] iteration 18170 : model1 loss : 0.434546 model2 loss : 0.021248
[11:40:56.397] iteration 18171 : model1 loss : 0.439895 model2 loss : 0.025056
[11:40:56.566] iteration 18172 : model1 loss : 0.440823 model2 loss : 0.023456
[11:40:56.737] iteration 18173 : model1 loss : 0.438100 model2 loss : 0.020302
[11:40:56.906] iteration 18174 : model1 loss : 0.439921 model2 loss : 0.021731
[11:40:57.074] iteration 18175 : model1 loss : 0.437308 model2 loss : 0.021138
[11:40:57.241] iteration 18176 : model1 loss : 0.434120 model2 loss : 0.022430
[11:40:57.411] iteration 18177 : model1 loss : 0.434510 model2 loss : 0.019939
[11:40:57.580] iteration 18178 : model1 loss : 0.432455 model2 loss : 0.019432
[11:40:57.751] iteration 18179 : model1 loss : 0.438711 model2 loss : 0.020634
[11:40:57.921] iteration 18180 : model1 loss : 0.439231 model2 loss : 0.024340
[11:40:58.090] iteration 18181 : model1 loss : 0.439102 model2 loss : 0.020294
[11:40:58.256] iteration 18182 : model1 loss : 0.436960 model2 loss : 0.020120
[11:40:58.424] iteration 18183 : model1 loss : 0.438289 model2 loss : 0.021762
[11:41:00.359] iteration 18184 : model1 loss : 0.436650 model2 loss : 0.019795
[11:41:00.527] iteration 18185 : model1 loss : 0.437551 model2 loss : 0.022421
[11:41:00.696] iteration 18186 : model1 loss : 0.433299 model2 loss : 0.020430
[11:41:00.863] iteration 18187 : model1 loss : 0.433940 model2 loss : 0.021817
[11:41:01.033] iteration 18188 : model1 loss : 0.436129 model2 loss : 0.024991
[11:41:01.199] iteration 18189 : model1 loss : 0.435544 model2 loss : 0.019186
[11:41:01.369] iteration 18190 : model1 loss : 0.439864 model2 loss : 0.021863
[11:41:01.537] iteration 18191 : model1 loss : 0.435103 model2 loss : 0.018384
[11:41:01.706] iteration 18192 : model1 loss : 0.434398 model2 loss : 0.020447
[11:41:01.873] iteration 18193 : model1 loss : 0.437462 model2 loss : 0.024421
[11:41:02.040] iteration 18194 : model1 loss : 0.437752 model2 loss : 0.019818
[11:41:02.209] iteration 18195 : model1 loss : 0.443016 model2 loss : 0.022652
[11:41:02.377] iteration 18196 : model1 loss : 0.435494 model2 loss : 0.018957
[11:41:02.545] iteration 18197 : model1 loss : 0.440128 model2 loss : 0.023990
[11:41:02.717] iteration 18198 : model1 loss : 0.434943 model2 loss : 0.021895
[11:41:02.884] iteration 18199 : model1 loss : 0.439255 model2 loss : 0.022119
[11:41:03.054] iteration 18200 : model1 loss : 0.444275 model2 loss : 0.026372
[11:41:03.221] iteration 18201 : model1 loss : 0.439531 model2 loss : 0.022192
[11:41:03.389] iteration 18202 : model1 loss : 0.437075 model2 loss : 0.019953
[11:41:03.557] iteration 18203 : model1 loss : 0.440321 model2 loss : 0.024843
[11:41:03.725] iteration 18204 : model1 loss : 0.438005 model2 loss : 0.021185
[11:41:03.893] iteration 18205 : model1 loss : 0.443601 model2 loss : 0.025111
[11:41:04.064] iteration 18206 : model1 loss : 0.442947 model2 loss : 0.025212
[11:41:04.231] iteration 18207 : model1 loss : 0.430530 model2 loss : 0.019774
[11:41:04.401] iteration 18208 : model1 loss : 0.440118 model2 loss : 0.023104
[11:41:04.568] iteration 18209 : model1 loss : 0.437146 model2 loss : 0.024708
[11:41:04.737] iteration 18210 : model1 loss : 0.435010 model2 loss : 0.023484
[11:41:04.905] iteration 18211 : model1 loss : 0.436339 model2 loss : 0.021096
[11:41:05.075] iteration 18212 : model1 loss : 0.440602 model2 loss : 0.023393
[11:41:05.243] iteration 18213 : model1 loss : 0.441487 model2 loss : 0.026886
[11:41:05.412] iteration 18214 : model1 loss : 0.439815 model2 loss : 0.021019
[11:41:05.578] iteration 18215 : model1 loss : 0.435626 model2 loss : 0.022224
[11:41:05.746] iteration 18216 : model1 loss : 0.439743 model2 loss : 0.022286
[11:41:07.776] iteration 18217 : model1 loss : 0.433423 model2 loss : 0.017948
[11:41:07.946] iteration 18218 : model1 loss : 0.436091 model2 loss : 0.019914
[11:41:08.116] iteration 18219 : model1 loss : 0.436510 model2 loss : 0.021830
[11:41:08.283] iteration 18220 : model1 loss : 0.437312 model2 loss : 0.020991
[11:41:08.454] iteration 18221 : model1 loss : 0.440215 model2 loss : 0.022275
[11:41:08.620] iteration 18222 : model1 loss : 0.438826 model2 loss : 0.019995
[11:41:08.790] iteration 18223 : model1 loss : 0.440745 model2 loss : 0.025273
[11:41:08.958] iteration 18224 : model1 loss : 0.438174 model2 loss : 0.024378
[11:41:09.126] iteration 18225 : model1 loss : 0.440719 model2 loss : 0.023033
[11:41:09.293] iteration 18226 : model1 loss : 0.436633 model2 loss : 0.023472
[11:41:09.463] iteration 18227 : model1 loss : 0.436467 model2 loss : 0.025222
[11:41:09.630] iteration 18228 : model1 loss : 0.442147 model2 loss : 0.025217
[11:41:09.797] iteration 18229 : model1 loss : 0.439522 model2 loss : 0.021946
[11:41:09.969] iteration 18230 : model1 loss : 0.438542 model2 loss : 0.022059
[11:41:10.138] iteration 18231 : model1 loss : 0.440997 model2 loss : 0.021698
[11:41:10.306] iteration 18232 : model1 loss : 0.439904 model2 loss : 0.022193
[11:41:10.474] iteration 18233 : model1 loss : 0.429487 model2 loss : 0.019396
[11:41:10.641] iteration 18234 : model1 loss : 0.434791 model2 loss : 0.020867
[11:41:10.812] iteration 18235 : model1 loss : 0.436703 model2 loss : 0.024194
[11:41:10.982] iteration 18236 : model1 loss : 0.434592 model2 loss : 0.020584
[11:41:11.150] iteration 18237 : model1 loss : 0.441171 model2 loss : 0.023284
[11:41:11.318] iteration 18238 : model1 loss : 0.436226 model2 loss : 0.024430
[11:41:11.488] iteration 18239 : model1 loss : 0.441577 model2 loss : 0.023880
[11:41:11.658] iteration 18240 : model1 loss : 0.437178 model2 loss : 0.021677
[11:41:11.826] iteration 18241 : model1 loss : 0.439392 model2 loss : 0.020087
[11:41:11.997] iteration 18242 : model1 loss : 0.437340 model2 loss : 0.023283
[11:41:12.165] iteration 18243 : model1 loss : 0.433924 model2 loss : 0.021304
[11:41:12.333] iteration 18244 : model1 loss : 0.438177 model2 loss : 0.022910
[11:41:12.503] iteration 18245 : model1 loss : 0.439999 model2 loss : 0.021534
[11:41:12.670] iteration 18246 : model1 loss : 0.436227 model2 loss : 0.020834
[11:41:12.841] iteration 18247 : model1 loss : 0.441252 model2 loss : 0.021896
[11:41:13.008] iteration 18248 : model1 loss : 0.440314 model2 loss : 0.019539
[11:41:13.176] iteration 18249 : model1 loss : 0.435336 model2 loss : 0.020313
[11:41:15.093] iteration 18250 : model1 loss : 0.441581 model2 loss : 0.022918
[11:41:15.261] iteration 18251 : model1 loss : 0.436690 model2 loss : 0.020128
[11:41:15.431] iteration 18252 : model1 loss : 0.439324 model2 loss : 0.024589
[11:41:15.598] iteration 18253 : model1 loss : 0.439667 model2 loss : 0.020058
[11:41:15.769] iteration 18254 : model1 loss : 0.443422 model2 loss : 0.023559
[11:41:15.937] iteration 18255 : model1 loss : 0.434717 model2 loss : 0.019330
[11:41:16.105] iteration 18256 : model1 loss : 0.436722 model2 loss : 0.024238
[11:41:16.272] iteration 18257 : model1 loss : 0.433080 model2 loss : 0.019608
[11:41:16.442] iteration 18258 : model1 loss : 0.435216 model2 loss : 0.021203
[11:41:16.610] iteration 18259 : model1 loss : 0.432707 model2 loss : 0.021554
[11:41:16.778] iteration 18260 : model1 loss : 0.439388 model2 loss : 0.023764
[11:41:16.945] iteration 18261 : model1 loss : 0.440970 model2 loss : 0.022107
[11:41:17.113] iteration 18262 : model1 loss : 0.440249 model2 loss : 0.022537
[11:41:17.280] iteration 18263 : model1 loss : 0.438256 model2 loss : 0.024768
[11:41:17.450] iteration 18264 : model1 loss : 0.434181 model2 loss : 0.019865
[11:41:17.615] iteration 18265 : model1 loss : 0.438606 model2 loss : 0.024983
[11:41:17.784] iteration 18266 : model1 loss : 0.438087 model2 loss : 0.021274
[11:41:17.952] iteration 18267 : model1 loss : 0.436825 model2 loss : 0.020444
[11:41:18.120] iteration 18268 : model1 loss : 0.439195 model2 loss : 0.020926
[11:41:18.288] iteration 18269 : model1 loss : 0.437720 model2 loss : 0.022048
[11:41:18.457] iteration 18270 : model1 loss : 0.438764 model2 loss : 0.019783
[11:41:18.623] iteration 18271 : model1 loss : 0.437281 model2 loss : 0.024542
[11:41:18.793] iteration 18272 : model1 loss : 0.439442 model2 loss : 0.023364
[11:41:18.959] iteration 18273 : model1 loss : 0.441429 model2 loss : 0.023438
[11:41:19.127] iteration 18274 : model1 loss : 0.434283 model2 loss : 0.020162
[11:41:19.295] iteration 18275 : model1 loss : 0.441355 model2 loss : 0.022298
[11:41:19.464] iteration 18276 : model1 loss : 0.435526 model2 loss : 0.020296
[11:41:19.632] iteration 18277 : model1 loss : 0.434682 model2 loss : 0.018553
[11:41:19.800] iteration 18278 : model1 loss : 0.436458 model2 loss : 0.019927
[11:41:19.971] iteration 18279 : model1 loss : 0.435336 model2 loss : 0.021741
[11:41:20.140] iteration 18280 : model1 loss : 0.435259 model2 loss : 0.019888
[11:41:20.306] iteration 18281 : model1 loss : 0.440688 model2 loss : 0.022512
[11:41:20.475] iteration 18282 : model1 loss : 0.437454 model2 loss : 0.021961
[11:41:22.424] iteration 18283 : model1 loss : 0.438081 model2 loss : 0.022019
[11:41:22.596] iteration 18284 : model1 loss : 0.431232 model2 loss : 0.020897
[11:41:22.766] iteration 18285 : model1 loss : 0.437371 model2 loss : 0.022452
[11:41:22.935] iteration 18286 : model1 loss : 0.440441 model2 loss : 0.022944
[11:41:23.104] iteration 18287 : model1 loss : 0.439145 model2 loss : 0.023393
[11:41:23.273] iteration 18288 : model1 loss : 0.446167 model2 loss : 0.025721
[11:41:23.442] iteration 18289 : model1 loss : 0.443060 model2 loss : 0.021884
[11:41:23.608] iteration 18290 : model1 loss : 0.437329 model2 loss : 0.020099
[11:41:23.777] iteration 18291 : model1 loss : 0.442604 model2 loss : 0.024467
[11:41:23.945] iteration 18292 : model1 loss : 0.444025 model2 loss : 0.030787
[11:41:24.113] iteration 18293 : model1 loss : 0.436723 model2 loss : 0.021677
[11:41:24.281] iteration 18294 : model1 loss : 0.438638 model2 loss : 0.019408
[11:41:24.450] iteration 18295 : model1 loss : 0.435217 model2 loss : 0.019744
[11:41:24.617] iteration 18296 : model1 loss : 0.442400 model2 loss : 0.021534
[11:41:24.787] iteration 18297 : model1 loss : 0.438004 model2 loss : 0.021699
[11:41:24.957] iteration 18298 : model1 loss : 0.438489 model2 loss : 0.020589
[11:41:25.125] iteration 18299 : model1 loss : 0.438474 model2 loss : 0.021907
[11:41:25.292] iteration 18300 : model1 loss : 0.438448 model2 loss : 0.023082
[11:41:25.463] iteration 18301 : model1 loss : 0.437544 model2 loss : 0.019301
[11:41:25.629] iteration 18302 : model1 loss : 0.437357 model2 loss : 0.023939
[11:41:25.797] iteration 18303 : model1 loss : 0.437024 model2 loss : 0.022146
[11:41:25.966] iteration 18304 : model1 loss : 0.434644 model2 loss : 0.020553
[11:41:26.133] iteration 18305 : model1 loss : 0.438610 model2 loss : 0.023318
[11:41:26.300] iteration 18306 : model1 loss : 0.436351 model2 loss : 0.021990
[11:41:26.469] iteration 18307 : model1 loss : 0.434254 model2 loss : 0.023194
[11:41:26.637] iteration 18308 : model1 loss : 0.434564 model2 loss : 0.019630
[11:41:26.805] iteration 18309 : model1 loss : 0.439651 model2 loss : 0.022385
[11:41:26.972] iteration 18310 : model1 loss : 0.433210 model2 loss : 0.021107
[11:41:27.141] iteration 18311 : model1 loss : 0.439487 model2 loss : 0.021288
[11:41:27.310] iteration 18312 : model1 loss : 0.437852 model2 loss : 0.022187
[11:41:27.478] iteration 18313 : model1 loss : 0.435572 model2 loss : 0.023252
[11:41:27.643] iteration 18314 : model1 loss : 0.433944 model2 loss : 0.021622
[11:41:27.812] iteration 18315 : model1 loss : 0.433738 model2 loss : 0.021222
[11:41:29.795] iteration 18316 : model1 loss : 0.434342 model2 loss : 0.021587
[11:41:29.962] iteration 18317 : model1 loss : 0.437629 model2 loss : 0.025037
[11:41:30.132] iteration 18318 : model1 loss : 0.438821 model2 loss : 0.021793
[11:41:30.300] iteration 18319 : model1 loss : 0.441658 model2 loss : 0.020355
[11:41:30.469] iteration 18320 : model1 loss : 0.439866 model2 loss : 0.022406
[11:41:30.637] iteration 18321 : model1 loss : 0.442584 model2 loss : 0.020937
[11:41:30.805] iteration 18322 : model1 loss : 0.440542 model2 loss : 0.024008
[11:41:30.973] iteration 18323 : model1 loss : 0.437052 model2 loss : 0.019073
[11:41:31.142] iteration 18324 : model1 loss : 0.440864 model2 loss : 0.023060
[11:41:31.310] iteration 18325 : model1 loss : 0.440762 model2 loss : 0.023614
[11:41:31.479] iteration 18326 : model1 loss : 0.436209 model2 loss : 0.019703
[11:41:31.646] iteration 18327 : model1 loss : 0.434893 model2 loss : 0.023297
[11:41:31.815] iteration 18328 : model1 loss : 0.434168 model2 loss : 0.021082
[11:41:31.982] iteration 18329 : model1 loss : 0.441066 model2 loss : 0.023363
[11:41:32.150] iteration 18330 : model1 loss : 0.435989 model2 loss : 0.022130
[11:41:32.319] iteration 18331 : model1 loss : 0.441293 model2 loss : 0.020436
[11:41:32.489] iteration 18332 : model1 loss : 0.437374 model2 loss : 0.018351
[11:41:32.684] iteration 18333 : model1 loss : 0.436270 model2 loss : 0.019340
[11:41:32.852] iteration 18334 : model1 loss : 0.437309 model2 loss : 0.022052
[11:41:33.021] iteration 18335 : model1 loss : 0.434516 model2 loss : 0.022826
[11:41:33.189] iteration 18336 : model1 loss : 0.437942 model2 loss : 0.025832
[11:41:33.357] iteration 18337 : model1 loss : 0.439563 model2 loss : 0.022231
[11:41:33.528] iteration 18338 : model1 loss : 0.433721 model2 loss : 0.019185
[11:41:33.696] iteration 18339 : model1 loss : 0.439781 model2 loss : 0.024065
[11:41:33.867] iteration 18340 : model1 loss : 0.440542 model2 loss : 0.022348
[11:41:34.037] iteration 18341 : model1 loss : 0.434510 model2 loss : 0.020531
[11:41:34.205] iteration 18342 : model1 loss : 0.437381 model2 loss : 0.022072
[11:41:34.373] iteration 18343 : model1 loss : 0.438192 model2 loss : 0.019420
[11:41:34.546] iteration 18344 : model1 loss : 0.437360 model2 loss : 0.021863
[11:41:34.715] iteration 18345 : model1 loss : 0.437167 model2 loss : 0.019593
[11:41:34.884] iteration 18346 : model1 loss : 0.441212 model2 loss : 0.021312
[11:41:35.053] iteration 18347 : model1 loss : 0.437210 model2 loss : 0.020722
[11:41:35.222] iteration 18348 : model1 loss : 0.437014 model2 loss : 0.022379
[11:41:37.215] iteration 18349 : model1 loss : 0.437631 model2 loss : 0.020743
[11:41:37.382] iteration 18350 : model1 loss : 0.438213 model2 loss : 0.025070
[11:41:37.551] iteration 18351 : model1 loss : 0.444795 model2 loss : 0.024667
[11:41:37.719] iteration 18352 : model1 loss : 0.439007 model2 loss : 0.021538
[11:41:37.888] iteration 18353 : model1 loss : 0.436566 model2 loss : 0.021736
[11:41:38.056] iteration 18354 : model1 loss : 0.440079 model2 loss : 0.021314
[11:41:38.228] iteration 18355 : model1 loss : 0.437456 model2 loss : 0.022474
[11:41:38.395] iteration 18356 : model1 loss : 0.440740 model2 loss : 0.019255
[11:41:38.565] iteration 18357 : model1 loss : 0.434212 model2 loss : 0.019771
[11:41:38.731] iteration 18358 : model1 loss : 0.434999 model2 loss : 0.022564
[11:41:38.900] iteration 18359 : model1 loss : 0.440210 model2 loss : 0.021975
[11:41:39.071] iteration 18360 : model1 loss : 0.438268 model2 loss : 0.018706
[11:41:39.240] iteration 18361 : model1 loss : 0.436512 model2 loss : 0.022637
[11:41:39.408] iteration 18362 : model1 loss : 0.440896 model2 loss : 0.023783
[11:41:39.578] iteration 18363 : model1 loss : 0.441244 model2 loss : 0.023971
[11:41:39.744] iteration 18364 : model1 loss : 0.434358 model2 loss : 0.019921
[11:41:39.914] iteration 18365 : model1 loss : 0.437242 model2 loss : 0.020340
[11:41:40.082] iteration 18366 : model1 loss : 0.440724 model2 loss : 0.023153
[11:41:40.251] iteration 18367 : model1 loss : 0.434532 model2 loss : 0.022331
[11:41:40.419] iteration 18368 : model1 loss : 0.439569 model2 loss : 0.021325
[11:41:40.589] iteration 18369 : model1 loss : 0.434795 model2 loss : 0.020332
[11:41:40.755] iteration 18370 : model1 loss : 0.435398 model2 loss : 0.020730
[11:41:40.926] iteration 18371 : model1 loss : 0.442759 model2 loss : 0.024615
[11:41:41.094] iteration 18372 : model1 loss : 0.435614 model2 loss : 0.020950
[11:41:41.264] iteration 18373 : model1 loss : 0.437575 model2 loss : 0.021329
[11:41:41.431] iteration 18374 : model1 loss : 0.438421 model2 loss : 0.021045
[11:41:41.602] iteration 18375 : model1 loss : 0.440585 model2 loss : 0.026723
[11:41:41.769] iteration 18376 : model1 loss : 0.438148 model2 loss : 0.020767
[11:41:41.937] iteration 18377 : model1 loss : 0.436902 model2 loss : 0.022359
[11:41:42.105] iteration 18378 : model1 loss : 0.437437 model2 loss : 0.020295
[11:41:42.274] iteration 18379 : model1 loss : 0.435656 model2 loss : 0.020967
[11:41:42.442] iteration 18380 : model1 loss : 0.434677 model2 loss : 0.020430
[11:41:42.611] iteration 18381 : model1 loss : 0.436808 model2 loss : 0.022689
[11:41:44.558] iteration 18382 : model1 loss : 0.440076 model2 loss : 0.025250
[11:41:44.730] iteration 18383 : model1 loss : 0.432855 model2 loss : 0.018328
[11:41:44.899] iteration 18384 : model1 loss : 0.441857 model2 loss : 0.023828
[11:41:45.070] iteration 18385 : model1 loss : 0.438315 model2 loss : 0.020018
[11:41:45.240] iteration 18386 : model1 loss : 0.431476 model2 loss : 0.023263
[11:41:45.408] iteration 18387 : model1 loss : 0.442355 model2 loss : 0.024385
[11:41:45.579] iteration 18388 : model1 loss : 0.442736 model2 loss : 0.022309
[11:41:45.746] iteration 18389 : model1 loss : 0.436904 model2 loss : 0.021542
[11:41:45.928] iteration 18390 : model1 loss : 0.436073 model2 loss : 0.021948
[11:41:46.093] iteration 18391 : model1 loss : 0.437878 model2 loss : 0.022660
[11:41:46.265] iteration 18392 : model1 loss : 0.438121 model2 loss : 0.021858
[11:41:46.432] iteration 18393 : model1 loss : 0.434998 model2 loss : 0.022308
[11:41:46.601] iteration 18394 : model1 loss : 0.436507 model2 loss : 0.019604
[11:41:46.770] iteration 18395 : model1 loss : 0.436375 model2 loss : 0.021890
[11:41:46.937] iteration 18396 : model1 loss : 0.435353 model2 loss : 0.020215
[11:41:47.105] iteration 18397 : model1 loss : 0.437216 model2 loss : 0.020592
[11:41:47.276] iteration 18398 : model1 loss : 0.436325 model2 loss : 0.018021
[11:41:47.444] iteration 18399 : model1 loss : 0.443858 model2 loss : 0.029808
[11:41:47.614] iteration 18400 : model1 loss : 0.435497 model2 loss : 0.022004
[11:41:47.782] iteration 18401 : model1 loss : 0.435697 model2 loss : 0.022303
[11:41:47.950] iteration 18402 : model1 loss : 0.436865 model2 loss : 0.022745
[11:41:48.115] iteration 18403 : model1 loss : 0.435661 model2 loss : 0.021009
[11:41:48.283] iteration 18404 : model1 loss : 0.436321 model2 loss : 0.020263
[11:41:48.451] iteration 18405 : model1 loss : 0.439917 model2 loss : 0.020394
[11:41:48.621] iteration 18406 : model1 loss : 0.444325 model2 loss : 0.030875
[11:41:48.787] iteration 18407 : model1 loss : 0.438982 model2 loss : 0.021822
[11:41:48.956] iteration 18408 : model1 loss : 0.439302 model2 loss : 0.023649
[11:41:49.123] iteration 18409 : model1 loss : 0.435259 model2 loss : 0.021803
[11:41:49.291] iteration 18410 : model1 loss : 0.437142 model2 loss : 0.025077
[11:41:49.457] iteration 18411 : model1 loss : 0.437497 model2 loss : 0.021248
[11:41:49.626] iteration 18412 : model1 loss : 0.438418 model2 loss : 0.022460
[11:41:49.793] iteration 18413 : model1 loss : 0.441363 model2 loss : 0.024367
[11:41:49.960] iteration 18414 : model1 loss : 0.440031 model2 loss : 0.023327
[11:41:51.912] iteration 18415 : model1 loss : 0.442364 model2 loss : 0.023555
[11:41:52.084] iteration 18416 : model1 loss : 0.436605 model2 loss : 0.024184
[11:41:52.254] iteration 18417 : model1 loss : 0.441920 model2 loss : 0.025114
[11:41:52.420] iteration 18418 : model1 loss : 0.437947 model2 loss : 0.025172
[11:41:52.590] iteration 18419 : model1 loss : 0.436488 model2 loss : 0.022149
[11:41:52.757] iteration 18420 : model1 loss : 0.442543 model2 loss : 0.024057
[11:41:52.925] iteration 18421 : model1 loss : 0.438080 model2 loss : 0.023078
[11:41:53.095] iteration 18422 : model1 loss : 0.437250 model2 loss : 0.023094
[11:41:53.264] iteration 18423 : model1 loss : 0.437104 model2 loss : 0.023619
[11:41:53.431] iteration 18424 : model1 loss : 0.439623 model2 loss : 0.021431
[11:41:53.599] iteration 18425 : model1 loss : 0.440405 model2 loss : 0.023165
[11:41:53.767] iteration 18426 : model1 loss : 0.441118 model2 loss : 0.022964
[11:41:53.937] iteration 18427 : model1 loss : 0.436342 model2 loss : 0.022972
[11:41:54.106] iteration 18428 : model1 loss : 0.438189 model2 loss : 0.024315
[11:41:54.276] iteration 18429 : model1 loss : 0.438293 model2 loss : 0.021905
[11:41:54.443] iteration 18430 : model1 loss : 0.437689 model2 loss : 0.021638
[11:41:54.611] iteration 18431 : model1 loss : 0.434777 model2 loss : 0.023501
[11:41:54.778] iteration 18432 : model1 loss : 0.434357 model2 loss : 0.023548
[11:41:54.948] iteration 18433 : model1 loss : 0.438213 model2 loss : 0.020779
[11:41:55.119] iteration 18434 : model1 loss : 0.436218 model2 loss : 0.023652
[11:41:55.287] iteration 18435 : model1 loss : 0.440179 model2 loss : 0.022767
[11:41:55.453] iteration 18436 : model1 loss : 0.438067 model2 loss : 0.023100
[11:41:55.624] iteration 18437 : model1 loss : 0.440213 model2 loss : 0.023111
[11:41:55.791] iteration 18438 : model1 loss : 0.437036 model2 loss : 0.020675
[11:41:55.960] iteration 18439 : model1 loss : 0.436900 model2 loss : 0.019871
[11:41:56.131] iteration 18440 : model1 loss : 0.436988 model2 loss : 0.022405
[11:41:56.300] iteration 18441 : model1 loss : 0.441939 model2 loss : 0.025486
[11:41:56.467] iteration 18442 : model1 loss : 0.436175 model2 loss : 0.021988
[11:41:56.635] iteration 18443 : model1 loss : 0.434828 model2 loss : 0.019686
[11:41:56.801] iteration 18444 : model1 loss : 0.433370 model2 loss : 0.018539
[11:41:56.976] iteration 18445 : model1 loss : 0.440704 model2 loss : 0.019558
[11:41:57.142] iteration 18446 : model1 loss : 0.435326 model2 loss : 0.023183
[11:41:57.311] iteration 18447 : model1 loss : 0.438259 model2 loss : 0.022622
[11:41:59.280] iteration 18448 : model1 loss : 0.437927 model2 loss : 0.021101
[11:41:59.448] iteration 18449 : model1 loss : 0.438710 model2 loss : 0.022557
[11:41:59.619] iteration 18450 : model1 loss : 0.432739 model2 loss : 0.020747
[11:41:59.785] iteration 18451 : model1 loss : 0.436257 model2 loss : 0.021705
[11:41:59.957] iteration 18452 : model1 loss : 0.439577 model2 loss : 0.022672
[11:42:00.127] iteration 18453 : model1 loss : 0.436828 model2 loss : 0.022067
[11:42:00.297] iteration 18454 : model1 loss : 0.442313 model2 loss : 0.022862
[11:42:00.464] iteration 18455 : model1 loss : 0.440416 model2 loss : 0.024082
[11:42:00.632] iteration 18456 : model1 loss : 0.437355 model2 loss : 0.022422
[11:42:00.800] iteration 18457 : model1 loss : 0.434869 model2 loss : 0.022077
[11:42:00.968] iteration 18458 : model1 loss : 0.435843 model2 loss : 0.021905
[11:42:01.137] iteration 18459 : model1 loss : 0.435900 model2 loss : 0.020864
[11:42:01.305] iteration 18460 : model1 loss : 0.439151 model2 loss : 0.024223
[11:42:01.474] iteration 18461 : model1 loss : 0.440310 model2 loss : 0.021841
[11:42:01.644] iteration 18462 : model1 loss : 0.438364 model2 loss : 0.023331
[11:42:01.810] iteration 18463 : model1 loss : 0.437773 model2 loss : 0.021015
[11:42:01.979] iteration 18464 : model1 loss : 0.435242 model2 loss : 0.020310
[11:42:02.147] iteration 18465 : model1 loss : 0.435966 model2 loss : 0.021175
[11:42:02.316] iteration 18466 : model1 loss : 0.436291 model2 loss : 0.022009
[11:42:02.485] iteration 18467 : model1 loss : 0.445004 model2 loss : 0.023137
[11:42:02.654] iteration 18468 : model1 loss : 0.439344 model2 loss : 0.021237
[11:42:02.823] iteration 18469 : model1 loss : 0.432662 model2 loss : 0.020912
[11:42:02.993] iteration 18470 : model1 loss : 0.440896 model2 loss : 0.023863
[11:42:03.160] iteration 18471 : model1 loss : 0.441140 model2 loss : 0.027073
[11:42:03.329] iteration 18472 : model1 loss : 0.437606 model2 loss : 0.020655
[11:42:03.497] iteration 18473 : model1 loss : 0.439587 model2 loss : 0.022813
[11:42:03.666] iteration 18474 : model1 loss : 0.441774 model2 loss : 0.025741
[11:42:03.833] iteration 18475 : model1 loss : 0.436041 model2 loss : 0.020877
[11:42:04.001] iteration 18476 : model1 loss : 0.440503 model2 loss : 0.024699
[11:42:04.170] iteration 18477 : model1 loss : 0.437496 model2 loss : 0.021270
[11:42:04.338] iteration 18478 : model1 loss : 0.439561 model2 loss : 0.019679
[11:42:04.506] iteration 18479 : model1 loss : 0.434163 model2 loss : 0.021050
[11:42:04.673] iteration 18480 : model1 loss : 0.434206 model2 loss : 0.021718
[11:42:06.606] iteration 18481 : model1 loss : 0.438982 model2 loss : 0.027082
[11:42:06.774] iteration 18482 : model1 loss : 0.437066 model2 loss : 0.021877
[11:42:06.944] iteration 18483 : model1 loss : 0.436690 model2 loss : 0.020909
[11:42:07.114] iteration 18484 : model1 loss : 0.437292 model2 loss : 0.021852
[11:42:07.284] iteration 18485 : model1 loss : 0.438522 model2 loss : 0.023005
[11:42:07.450] iteration 18486 : model1 loss : 0.440182 model2 loss : 0.021611
[11:42:07.621] iteration 18487 : model1 loss : 0.437966 model2 loss : 0.022817
[11:42:07.788] iteration 18488 : model1 loss : 0.437163 model2 loss : 0.021609
[11:42:07.958] iteration 18489 : model1 loss : 0.440778 model2 loss : 0.022486
[11:42:08.126] iteration 18490 : model1 loss : 0.443113 model2 loss : 0.021805
[11:42:08.294] iteration 18491 : model1 loss : 0.435554 model2 loss : 0.021360
[11:42:08.462] iteration 18492 : model1 loss : 0.436863 model2 loss : 0.024239
[11:42:08.632] iteration 18493 : model1 loss : 0.434926 model2 loss : 0.020951
[11:42:08.800] iteration 18494 : model1 loss : 0.437435 model2 loss : 0.024096
[11:42:08.968] iteration 18495 : model1 loss : 0.438323 model2 loss : 0.021772
[11:42:09.134] iteration 18496 : model1 loss : 0.441945 model2 loss : 0.024301
[11:42:09.304] iteration 18497 : model1 loss : 0.437159 model2 loss : 0.023011
[11:42:09.469] iteration 18498 : model1 loss : 0.436836 model2 loss : 0.020324
[11:42:09.639] iteration 18499 : model1 loss : 0.436651 model2 loss : 0.020510
[11:42:09.806] iteration 18500 : model1 loss : 0.437236 model2 loss : 0.021285
[11:42:09.979] iteration 18501 : model1 loss : 0.437596 model2 loss : 0.023468
[11:42:10.147] iteration 18502 : model1 loss : 0.438539 model2 loss : 0.024759
[11:42:10.315] iteration 18503 : model1 loss : 0.436595 model2 loss : 0.020606
[11:42:10.481] iteration 18504 : model1 loss : 0.438744 model2 loss : 0.021465
[11:42:10.650] iteration 18505 : model1 loss : 0.438447 model2 loss : 0.024330
[11:42:10.820] iteration 18506 : model1 loss : 0.433480 model2 loss : 0.020959
[11:42:10.988] iteration 18507 : model1 loss : 0.443449 model2 loss : 0.026437
[11:42:11.156] iteration 18508 : model1 loss : 0.435056 model2 loss : 0.023135
[11:42:11.325] iteration 18509 : model1 loss : 0.435651 model2 loss : 0.022159
[11:42:11.495] iteration 18510 : model1 loss : 0.440598 model2 loss : 0.023372
[11:42:11.664] iteration 18511 : model1 loss : 0.440625 model2 loss : 0.024000
[11:42:11.829] iteration 18512 : model1 loss : 0.436789 model2 loss : 0.019331
[11:42:11.997] iteration 18513 : model1 loss : 0.439544 model2 loss : 0.022944
[11:42:13.901] iteration 18514 : model1 loss : 0.436686 model2 loss : 0.021510
[11:42:14.068] iteration 18515 : model1 loss : 0.437033 model2 loss : 0.018223
[11:42:14.239] iteration 18516 : model1 loss : 0.439109 model2 loss : 0.020995
[11:42:14.405] iteration 18517 : model1 loss : 0.435613 model2 loss : 0.023911
[11:42:14.575] iteration 18518 : model1 loss : 0.439039 model2 loss : 0.019618
[11:42:14.743] iteration 18519 : model1 loss : 0.441755 model2 loss : 0.022534
[11:42:14.912] iteration 18520 : model1 loss : 0.439411 model2 loss : 0.020917
[11:42:15.080] iteration 18521 : model1 loss : 0.437900 model2 loss : 0.021280
[11:42:15.249] iteration 18522 : model1 loss : 0.435472 model2 loss : 0.019754
[11:42:15.418] iteration 18523 : model1 loss : 0.440839 model2 loss : 0.024610
[11:42:15.587] iteration 18524 : model1 loss : 0.434034 model2 loss : 0.019399
[11:42:15.754] iteration 18525 : model1 loss : 0.438762 model2 loss : 0.025461
[11:42:15.923] iteration 18526 : model1 loss : 0.441704 model2 loss : 0.025654
[11:42:16.092] iteration 18527 : model1 loss : 0.439896 model2 loss : 0.022920
[11:42:16.262] iteration 18528 : model1 loss : 0.440120 model2 loss : 0.018711
[11:42:16.430] iteration 18529 : model1 loss : 0.441272 model2 loss : 0.024508
[11:42:16.598] iteration 18530 : model1 loss : 0.439475 model2 loss : 0.022700
[11:42:16.764] iteration 18531 : model1 loss : 0.435885 model2 loss : 0.023438
[11:42:16.935] iteration 18532 : model1 loss : 0.436625 model2 loss : 0.021955
[11:42:17.104] iteration 18533 : model1 loss : 0.439197 model2 loss : 0.019381
[11:42:17.274] iteration 18534 : model1 loss : 0.431569 model2 loss : 0.021720
[11:42:17.442] iteration 18535 : model1 loss : 0.438203 model2 loss : 0.023701
[11:42:17.611] iteration 18536 : model1 loss : 0.440510 model2 loss : 0.024313
[11:42:17.779] iteration 18537 : model1 loss : 0.438613 model2 loss : 0.022875
[11:42:17.948] iteration 18538 : model1 loss : 0.437010 model2 loss : 0.021438
[11:42:18.119] iteration 18539 : model1 loss : 0.436922 model2 loss : 0.020427
[11:42:18.287] iteration 18540 : model1 loss : 0.435564 model2 loss : 0.023116
[11:42:18.455] iteration 18541 : model1 loss : 0.440531 model2 loss : 0.028112
[11:42:18.625] iteration 18542 : model1 loss : 0.435277 model2 loss : 0.022109
[11:42:18.792] iteration 18543 : model1 loss : 0.443345 model2 loss : 0.025805
[11:42:18.961] iteration 18544 : model1 loss : 0.436096 model2 loss : 0.020881
[11:42:19.130] iteration 18545 : model1 loss : 0.435816 model2 loss : 0.021484
[11:42:19.297] iteration 18546 : model1 loss : 0.437356 model2 loss : 0.019956
[11:42:21.237] iteration 18547 : model1 loss : 0.438988 model2 loss : 0.024512
[11:42:21.403] iteration 18548 : model1 loss : 0.436634 model2 loss : 0.021080
[11:42:21.574] iteration 18549 : model1 loss : 0.437008 model2 loss : 0.021736
[11:42:21.740] iteration 18550 : model1 loss : 0.437020 model2 loss : 0.021218
[11:42:21.909] iteration 18551 : model1 loss : 0.442524 model2 loss : 0.023494
[11:42:22.077] iteration 18552 : model1 loss : 0.437842 model2 loss : 0.019732
[11:42:22.245] iteration 18553 : model1 loss : 0.435750 model2 loss : 0.020720
[11:42:22.412] iteration 18554 : model1 loss : 0.432866 model2 loss : 0.019787
[11:42:22.582] iteration 18555 : model1 loss : 0.435651 model2 loss : 0.021306
[11:42:22.748] iteration 18556 : model1 loss : 0.439529 model2 loss : 0.022563
[11:42:22.919] iteration 18557 : model1 loss : 0.444359 model2 loss : 0.025810
[11:42:23.086] iteration 18558 : model1 loss : 0.439496 model2 loss : 0.024691
[11:42:23.255] iteration 18559 : model1 loss : 0.438064 model2 loss : 0.021333
[11:42:23.422] iteration 18560 : model1 loss : 0.437540 model2 loss : 0.019368
[11:42:23.591] iteration 18561 : model1 loss : 0.438304 model2 loss : 0.024648
[11:42:23.756] iteration 18562 : model1 loss : 0.441862 model2 loss : 0.022273
[11:42:23.924] iteration 18563 : model1 loss : 0.439376 model2 loss : 0.020966
[11:42:24.090] iteration 18564 : model1 loss : 0.445896 model2 loss : 0.026566
[11:42:24.258] iteration 18565 : model1 loss : 0.436297 model2 loss : 0.022471
[11:42:24.427] iteration 18566 : model1 loss : 0.434796 model2 loss : 0.022782
[11:42:24.596] iteration 18567 : model1 loss : 0.438697 model2 loss : 0.022598
[11:42:24.761] iteration 18568 : model1 loss : 0.437279 model2 loss : 0.019389
[11:42:24.929] iteration 18569 : model1 loss : 0.435024 model2 loss : 0.021476
[11:42:25.120] iteration 18570 : model1 loss : 0.437913 model2 loss : 0.022163
[11:42:25.289] iteration 18571 : model1 loss : 0.438488 model2 loss : 0.021277
[11:42:25.457] iteration 18572 : model1 loss : 0.440095 model2 loss : 0.024266
[11:42:25.626] iteration 18573 : model1 loss : 0.438176 model2 loss : 0.021786
[11:42:25.795] iteration 18574 : model1 loss : 0.437515 model2 loss : 0.022706
[11:42:25.964] iteration 18575 : model1 loss : 0.438130 model2 loss : 0.022034
[11:42:26.134] iteration 18576 : model1 loss : 0.439487 model2 loss : 0.021744
[11:42:26.301] iteration 18577 : model1 loss : 0.435188 model2 loss : 0.021919
[11:42:26.468] iteration 18578 : model1 loss : 0.438360 model2 loss : 0.020849
[11:42:26.636] iteration 18579 : model1 loss : 0.437418 model2 loss : 0.021402
[11:42:28.559] iteration 18580 : model1 loss : 0.439408 model2 loss : 0.021568
[11:42:28.729] iteration 18581 : model1 loss : 0.437276 model2 loss : 0.021746
[11:42:28.900] iteration 18582 : model1 loss : 0.436682 model2 loss : 0.023375
[11:42:29.068] iteration 18583 : model1 loss : 0.436557 model2 loss : 0.022439
[11:42:29.237] iteration 18584 : model1 loss : 0.437151 model2 loss : 0.020522
[11:42:29.405] iteration 18585 : model1 loss : 0.435897 model2 loss : 0.021993
[11:42:29.576] iteration 18586 : model1 loss : 0.438101 model2 loss : 0.019813
[11:42:29.743] iteration 18587 : model1 loss : 0.436816 model2 loss : 0.019371
[11:42:29.911] iteration 18588 : model1 loss : 0.438946 model2 loss : 0.024946
[11:42:30.081] iteration 18589 : model1 loss : 0.436768 model2 loss : 0.022343
[11:42:30.250] iteration 18590 : model1 loss : 0.436195 model2 loss : 0.024260
[11:42:30.419] iteration 18591 : model1 loss : 0.442866 model2 loss : 0.022771
[11:42:30.590] iteration 18592 : model1 loss : 0.441698 model2 loss : 0.022131
[11:42:30.757] iteration 18593 : model1 loss : 0.437064 model2 loss : 0.024296
[11:42:30.926] iteration 18594 : model1 loss : 0.434438 model2 loss : 0.020857
[11:42:31.095] iteration 18595 : model1 loss : 0.440840 model2 loss : 0.023444
[11:42:31.264] iteration 18596 : model1 loss : 0.434124 model2 loss : 0.022882
[11:42:31.431] iteration 18597 : model1 loss : 0.435786 model2 loss : 0.022139
[11:42:31.600] iteration 18598 : model1 loss : 0.441145 model2 loss : 0.026557
[11:42:31.767] iteration 18599 : model1 loss : 0.439020 model2 loss : 0.022376
[11:42:31.935] iteration 18600 : model1 loss : 0.439442 model2 loss : 0.022164
[11:42:32.103] iteration 18601 : model1 loss : 0.435214 model2 loss : 0.020409
[11:42:32.271] iteration 18602 : model1 loss : 0.437762 model2 loss : 0.021303
[11:42:32.437] iteration 18603 : model1 loss : 0.440002 model2 loss : 0.023912
[11:42:32.606] iteration 18604 : model1 loss : 0.435347 model2 loss : 0.018785
[11:42:32.775] iteration 18605 : model1 loss : 0.436241 model2 loss : 0.020369
[11:42:32.945] iteration 18606 : model1 loss : 0.436768 model2 loss : 0.021978
[11:42:33.111] iteration 18607 : model1 loss : 0.442142 model2 loss : 0.024979
[11:42:33.280] iteration 18608 : model1 loss : 0.435902 model2 loss : 0.019824
[11:42:33.447] iteration 18609 : model1 loss : 0.438113 model2 loss : 0.021495
[11:42:33.616] iteration 18610 : model1 loss : 0.436237 model2 loss : 0.022980
[11:42:33.783] iteration 18611 : model1 loss : 0.441579 model2 loss : 0.022452
[11:42:33.952] iteration 18612 : model1 loss : 0.436686 model2 loss : 0.020991
[11:42:35.880] iteration 18613 : model1 loss : 0.440987 model2 loss : 0.022678
[11:42:36.045] iteration 18614 : model1 loss : 0.435784 model2 loss : 0.021388
[11:42:36.215] iteration 18615 : model1 loss : 0.438502 model2 loss : 0.021042
[11:42:36.379] iteration 18616 : model1 loss : 0.440417 model2 loss : 0.023720
[11:42:36.549] iteration 18617 : model1 loss : 0.437153 model2 loss : 0.022002
[11:42:36.716] iteration 18618 : model1 loss : 0.438353 model2 loss : 0.025510
[11:42:36.884] iteration 18619 : model1 loss : 0.435277 model2 loss : 0.021306
[11:42:37.052] iteration 18620 : model1 loss : 0.437458 model2 loss : 0.021695
[11:42:37.221] iteration 18621 : model1 loss : 0.437755 model2 loss : 0.021344
[11:42:37.388] iteration 18622 : model1 loss : 0.436364 model2 loss : 0.020628
[11:42:37.559] iteration 18623 : model1 loss : 0.438909 model2 loss : 0.021518
[11:42:37.726] iteration 18624 : model1 loss : 0.439131 model2 loss : 0.023905
[11:42:37.895] iteration 18625 : model1 loss : 0.437584 model2 loss : 0.021887
[11:42:38.062] iteration 18626 : model1 loss : 0.436856 model2 loss : 0.025948
[11:42:38.236] iteration 18627 : model1 loss : 0.438732 model2 loss : 0.023153
[11:42:38.402] iteration 18628 : model1 loss : 0.440586 model2 loss : 0.021686
[11:42:38.571] iteration 18629 : model1 loss : 0.436175 model2 loss : 0.020789
[11:42:38.739] iteration 18630 : model1 loss : 0.438811 model2 loss : 0.022972
[11:42:38.908] iteration 18631 : model1 loss : 0.436221 model2 loss : 0.019788
[11:42:39.074] iteration 18632 : model1 loss : 0.440456 model2 loss : 0.021034
[11:42:39.242] iteration 18633 : model1 loss : 0.442193 model2 loss : 0.025467
[11:42:39.409] iteration 18634 : model1 loss : 0.436568 model2 loss : 0.019897
[11:42:39.577] iteration 18635 : model1 loss : 0.438555 model2 loss : 0.021820
[11:42:39.743] iteration 18636 : model1 loss : 0.436006 model2 loss : 0.023113
[11:42:39.913] iteration 18637 : model1 loss : 0.433169 model2 loss : 0.020192
[11:42:40.080] iteration 18638 : model1 loss : 0.437629 model2 loss : 0.021990
[11:42:40.249] iteration 18639 : model1 loss : 0.435599 model2 loss : 0.022423
[11:42:40.416] iteration 18640 : model1 loss : 0.431643 model2 loss : 0.021332
[11:42:40.586] iteration 18641 : model1 loss : 0.440592 model2 loss : 0.020452
[11:42:40.753] iteration 18642 : model1 loss : 0.442850 model2 loss : 0.023553
[11:42:40.923] iteration 18643 : model1 loss : 0.438070 model2 loss : 0.019398
[11:42:41.088] iteration 18644 : model1 loss : 0.441146 model2 loss : 0.023372
[11:42:41.255] iteration 18645 : model1 loss : 0.441296 model2 loss : 0.023399
[11:42:43.176] iteration 18646 : model1 loss : 0.436881 model2 loss : 0.021252
[11:42:43.346] iteration 18647 : model1 loss : 0.442388 model2 loss : 0.021856
[11:42:43.518] iteration 18648 : model1 loss : 0.441959 model2 loss : 0.024343
[11:42:43.685] iteration 18649 : model1 loss : 0.436809 model2 loss : 0.023220
[11:42:43.854] iteration 18650 : model1 loss : 0.438408 model2 loss : 0.020863
[11:42:44.020] iteration 18651 : model1 loss : 0.431371 model2 loss : 0.018364
[11:42:44.191] iteration 18652 : model1 loss : 0.434359 model2 loss : 0.020809
[11:42:44.358] iteration 18653 : model1 loss : 0.440698 model2 loss : 0.022287
[11:42:44.530] iteration 18654 : model1 loss : 0.441798 model2 loss : 0.025788
[11:42:44.698] iteration 18655 : model1 loss : 0.437741 model2 loss : 0.018592
[11:42:44.867] iteration 18656 : model1 loss : 0.436566 model2 loss : 0.022617
[11:42:45.034] iteration 18657 : model1 loss : 0.434435 model2 loss : 0.020744
[11:42:45.206] iteration 18658 : model1 loss : 0.438728 model2 loss : 0.020624
[11:42:45.373] iteration 18659 : model1 loss : 0.439788 model2 loss : 0.024505
[11:42:45.541] iteration 18660 : model1 loss : 0.442788 model2 loss : 0.024277
[11:42:45.707] iteration 18661 : model1 loss : 0.439036 model2 loss : 0.022606
[11:42:45.879] iteration 18662 : model1 loss : 0.436494 model2 loss : 0.025963
[11:42:46.046] iteration 18663 : model1 loss : 0.437787 model2 loss : 0.021293
[11:42:46.215] iteration 18664 : model1 loss : 0.437466 model2 loss : 0.021885
[11:42:46.380] iteration 18665 : model1 loss : 0.440014 model2 loss : 0.024378
[11:42:46.552] iteration 18666 : model1 loss : 0.437432 model2 loss : 0.021306
[11:42:46.718] iteration 18667 : model1 loss : 0.439433 model2 loss : 0.022799
[11:42:46.887] iteration 18668 : model1 loss : 0.437352 model2 loss : 0.021999
[11:42:47.054] iteration 18669 : model1 loss : 0.440252 model2 loss : 0.023404
[11:42:47.223] iteration 18670 : model1 loss : 0.432919 model2 loss : 0.021295
[11:42:47.389] iteration 18671 : model1 loss : 0.439984 model2 loss : 0.023117
[11:42:47.560] iteration 18672 : model1 loss : 0.432911 model2 loss : 0.021124
[11:42:47.727] iteration 18673 : model1 loss : 0.436083 model2 loss : 0.020634
[11:42:47.899] iteration 18674 : model1 loss : 0.439712 model2 loss : 0.022878
[11:42:48.066] iteration 18675 : model1 loss : 0.439750 model2 loss : 0.020745
[11:42:48.236] iteration 18676 : model1 loss : 0.439364 model2 loss : 0.025050
[11:42:48.402] iteration 18677 : model1 loss : 0.438824 model2 loss : 0.024841
[11:42:48.570] iteration 18678 : model1 loss : 0.435585 model2 loss : 0.019647
[11:42:50.516] iteration 18679 : model1 loss : 0.438254 model2 loss : 0.021253
[11:42:50.685] iteration 18680 : model1 loss : 0.439193 model2 loss : 0.022381
[11:42:50.856] iteration 18681 : model1 loss : 0.436732 model2 loss : 0.020799
[11:42:51.022] iteration 18682 : model1 loss : 0.442143 model2 loss : 0.023731
[11:42:51.193] iteration 18683 : model1 loss : 0.442147 model2 loss : 0.024266
[11:42:51.358] iteration 18684 : model1 loss : 0.439749 model2 loss : 0.023539
[11:42:51.533] iteration 18685 : model1 loss : 0.437532 model2 loss : 0.021113
[11:42:51.700] iteration 18686 : model1 loss : 0.435086 model2 loss : 0.022282
[11:42:51.868] iteration 18687 : model1 loss : 0.434520 model2 loss : 0.020665
[11:42:52.035] iteration 18688 : model1 loss : 0.441928 model2 loss : 0.021686
[11:42:52.209] iteration 18689 : model1 loss : 0.438359 model2 loss : 0.022141
[11:42:52.378] iteration 18690 : model1 loss : 0.437784 model2 loss : 0.021792
[11:42:52.546] iteration 18691 : model1 loss : 0.440385 model2 loss : 0.022824
[11:42:52.712] iteration 18692 : model1 loss : 0.433064 model2 loss : 0.019635
[11:42:52.881] iteration 18693 : model1 loss : 0.434646 model2 loss : 0.021143
[11:42:53.046] iteration 18694 : model1 loss : 0.441259 model2 loss : 0.023594
[11:42:53.216] iteration 18695 : model1 loss : 0.440537 model2 loss : 0.022767
[11:42:53.384] iteration 18696 : model1 loss : 0.436574 model2 loss : 0.019819
[11:42:53.554] iteration 18697 : model1 loss : 0.435306 model2 loss : 0.021426
[11:42:53.721] iteration 18698 : model1 loss : 0.437332 model2 loss : 0.022622
[11:42:53.891] iteration 18699 : model1 loss : 0.444421 model2 loss : 0.025334
[11:42:54.059] iteration 18700 : model1 loss : 0.437776 model2 loss : 0.019452
[11:42:54.229] iteration 18701 : model1 loss : 0.430538 model2 loss : 0.020840
[11:42:54.396] iteration 18702 : model1 loss : 0.437538 model2 loss : 0.021436
[11:42:54.565] iteration 18703 : model1 loss : 0.436900 model2 loss : 0.021129
[11:42:54.732] iteration 18704 : model1 loss : 0.432915 model2 loss : 0.019712
[11:42:54.901] iteration 18705 : model1 loss : 0.438721 model2 loss : 0.020274
[11:42:55.068] iteration 18706 : model1 loss : 0.442972 model2 loss : 0.025029
[11:42:55.252] iteration 18707 : model1 loss : 0.435227 model2 loss : 0.024885
[11:42:55.421] iteration 18708 : model1 loss : 0.439955 model2 loss : 0.023292
[11:42:55.592] iteration 18709 : model1 loss : 0.445225 model2 loss : 0.021305
[11:42:55.756] iteration 18710 : model1 loss : 0.434707 model2 loss : 0.022500
[11:42:55.925] iteration 18711 : model1 loss : 0.440293 model2 loss : 0.025474
[11:42:57.855] iteration 18712 : model1 loss : 0.436923 model2 loss : 0.019858
[11:42:58.022] iteration 18713 : model1 loss : 0.436652 model2 loss : 0.020490
[11:42:58.192] iteration 18714 : model1 loss : 0.441853 model2 loss : 0.023218
[11:42:58.360] iteration 18715 : model1 loss : 0.437817 model2 loss : 0.021800
[11:42:58.531] iteration 18716 : model1 loss : 0.438375 model2 loss : 0.022510
[11:42:58.699] iteration 18717 : model1 loss : 0.435864 model2 loss : 0.023433
[11:42:58.869] iteration 18718 : model1 loss : 0.436086 model2 loss : 0.022572
[11:42:59.036] iteration 18719 : model1 loss : 0.438872 model2 loss : 0.019747
[11:42:59.207] iteration 18720 : model1 loss : 0.443725 model2 loss : 0.025399
[11:42:59.372] iteration 18721 : model1 loss : 0.440964 model2 loss : 0.023765
[11:42:59.547] iteration 18722 : model1 loss : 0.434567 model2 loss : 0.021720
[11:42:59.713] iteration 18723 : model1 loss : 0.437706 model2 loss : 0.021773
[11:42:59.884] iteration 18724 : model1 loss : 0.440014 model2 loss : 0.020905
[11:43:00.050] iteration 18725 : model1 loss : 0.440391 model2 loss : 0.021937
[11:43:00.223] iteration 18726 : model1 loss : 0.434349 model2 loss : 0.019946
[11:43:00.392] iteration 18727 : model1 loss : 0.436098 model2 loss : 0.020489
[11:43:00.561] iteration 18728 : model1 loss : 0.438001 model2 loss : 0.021568
[11:43:00.730] iteration 18729 : model1 loss : 0.435405 model2 loss : 0.019835
[11:43:00.902] iteration 18730 : model1 loss : 0.440291 model2 loss : 0.019918
[11:43:01.068] iteration 18731 : model1 loss : 0.439922 model2 loss : 0.020946
[11:43:01.241] iteration 18732 : model1 loss : 0.440323 model2 loss : 0.020654
[11:43:01.408] iteration 18733 : model1 loss : 0.436583 model2 loss : 0.020821
[11:43:01.578] iteration 18734 : model1 loss : 0.436320 model2 loss : 0.023110
[11:43:01.745] iteration 18735 : model1 loss : 0.436203 model2 loss : 0.021482
[11:43:01.915] iteration 18736 : model1 loss : 0.437631 model2 loss : 0.022105
[11:43:02.081] iteration 18737 : model1 loss : 0.437667 model2 loss : 0.022065
[11:43:02.251] iteration 18738 : model1 loss : 0.441111 model2 loss : 0.022467
[11:43:02.420] iteration 18739 : model1 loss : 0.434474 model2 loss : 0.022496
[11:43:02.588] iteration 18740 : model1 loss : 0.433939 model2 loss : 0.021085
[11:43:02.756] iteration 18741 : model1 loss : 0.439993 model2 loss : 0.022899
[11:43:02.925] iteration 18742 : model1 loss : 0.439442 model2 loss : 0.021296
[11:43:03.091] iteration 18743 : model1 loss : 0.439881 model2 loss : 0.022791
[11:43:03.258] iteration 18744 : model1 loss : 0.438944 model2 loss : 0.022054
[11:43:05.162] iteration 18745 : model1 loss : 0.437738 model2 loss : 0.020154
[11:43:05.332] iteration 18746 : model1 loss : 0.437821 model2 loss : 0.020780
[11:43:05.505] iteration 18747 : model1 loss : 0.441530 model2 loss : 0.026020
[11:43:05.672] iteration 18748 : model1 loss : 0.436127 model2 loss : 0.019240
[11:43:05.844] iteration 18749 : model1 loss : 0.443222 model2 loss : 0.023053
[11:43:06.011] iteration 18750 : model1 loss : 0.439398 model2 loss : 0.020843
[11:43:06.182] iteration 18751 : model1 loss : 0.434652 model2 loss : 0.021189
[11:43:06.350] iteration 18752 : model1 loss : 0.434622 model2 loss : 0.020290
[11:43:06.522] iteration 18753 : model1 loss : 0.438016 model2 loss : 0.021263
[11:43:06.690] iteration 18754 : model1 loss : 0.433895 model2 loss : 0.019485
[11:43:06.860] iteration 18755 : model1 loss : 0.436697 model2 loss : 0.020239
[11:43:07.028] iteration 18756 : model1 loss : 0.437336 model2 loss : 0.020077
[11:43:07.197] iteration 18757 : model1 loss : 0.444403 model2 loss : 0.025584
[11:43:07.364] iteration 18758 : model1 loss : 0.438370 model2 loss : 0.022203
[11:43:07.534] iteration 18759 : model1 loss : 0.437758 model2 loss : 0.022951
[11:43:07.698] iteration 18760 : model1 loss : 0.439748 model2 loss : 0.020869
[11:43:07.873] iteration 18761 : model1 loss : 0.436691 model2 loss : 0.021270
[11:43:08.041] iteration 18762 : model1 loss : 0.439974 model2 loss : 0.019599
[11:43:08.212] iteration 18763 : model1 loss : 0.436314 model2 loss : 0.019658
[11:43:08.378] iteration 18764 : model1 loss : 0.437632 model2 loss : 0.025485
[11:43:08.548] iteration 18765 : model1 loss : 0.438732 model2 loss : 0.020920
[11:43:08.715] iteration 18766 : model1 loss : 0.438910 model2 loss : 0.022186
[11:43:08.885] iteration 18767 : model1 loss : 0.439395 model2 loss : 0.024465
[11:43:09.051] iteration 18768 : model1 loss : 0.437846 model2 loss : 0.022803
[11:43:09.221] iteration 18769 : model1 loss : 0.434110 model2 loss : 0.022103
[11:43:09.390] iteration 18770 : model1 loss : 0.436886 model2 loss : 0.020415
[11:43:09.559] iteration 18771 : model1 loss : 0.438706 model2 loss : 0.022325
[11:43:09.727] iteration 18772 : model1 loss : 0.436696 model2 loss : 0.019350
[11:43:09.895] iteration 18773 : model1 loss : 0.440304 model2 loss : 0.021692
[11:43:10.063] iteration 18774 : model1 loss : 0.441057 model2 loss : 0.023954
[11:43:10.231] iteration 18775 : model1 loss : 0.435396 model2 loss : 0.022392
[11:43:10.399] iteration 18776 : model1 loss : 0.437963 model2 loss : 0.024002
[11:43:10.568] iteration 18777 : model1 loss : 0.438008 model2 loss : 0.022504
[11:43:12.510] iteration 18778 : model1 loss : 0.434493 model2 loss : 0.019681
[11:43:12.675] iteration 18779 : model1 loss : 0.432486 model2 loss : 0.019950
[11:43:12.843] iteration 18780 : model1 loss : 0.438886 model2 loss : 0.022679
[11:43:13.010] iteration 18781 : model1 loss : 0.437046 model2 loss : 0.021891
[11:43:13.180] iteration 18782 : model1 loss : 0.437760 model2 loss : 0.020798
[11:43:13.347] iteration 18783 : model1 loss : 0.442644 model2 loss : 0.024062
[11:43:13.519] iteration 18784 : model1 loss : 0.437931 model2 loss : 0.021906
[11:43:13.685] iteration 18785 : model1 loss : 0.439726 model2 loss : 0.020348
[11:43:13.855] iteration 18786 : model1 loss : 0.434934 model2 loss : 0.021800
[11:43:14.021] iteration 18787 : model1 loss : 0.434299 model2 loss : 0.019618
[11:43:14.200] iteration 18788 : model1 loss : 0.442924 model2 loss : 0.025945
[11:43:14.366] iteration 18789 : model1 loss : 0.440964 model2 loss : 0.022772
[11:43:14.538] iteration 18790 : model1 loss : 0.443114 model2 loss : 0.022927
[11:43:14.704] iteration 18791 : model1 loss : 0.439219 model2 loss : 0.021015
[11:43:14.872] iteration 18792 : model1 loss : 0.440163 model2 loss : 0.021271
[11:43:15.039] iteration 18793 : model1 loss : 0.441274 model2 loss : 0.024893
[11:43:15.204] iteration 18794 : model1 loss : 0.434275 model2 loss : 0.020696
[11:43:15.374] iteration 18795 : model1 loss : 0.435816 model2 loss : 0.021967
[11:43:15.544] iteration 18796 : model1 loss : 0.434310 model2 loss : 0.021233
[11:43:15.712] iteration 18797 : model1 loss : 0.434168 model2 loss : 0.021168
[11:43:15.883] iteration 18798 : model1 loss : 0.438443 model2 loss : 0.022500
[11:43:16.050] iteration 18799 : model1 loss : 0.441315 model2 loss : 0.023065
[11:43:16.220] iteration 18800 : model1 loss : 0.438762 model2 loss : 0.019978
[11:43:16.387] iteration 18801 : model1 loss : 0.439589 model2 loss : 0.021386
[11:43:16.557] iteration 18802 : model1 loss : 0.443620 model2 loss : 0.028277
[11:43:16.723] iteration 18803 : model1 loss : 0.438079 model2 loss : 0.020227
[11:43:16.892] iteration 18804 : model1 loss : 0.433017 model2 loss : 0.020470
[11:43:17.059] iteration 18805 : model1 loss : 0.440263 model2 loss : 0.020832
[11:43:17.228] iteration 18806 : model1 loss : 0.438316 model2 loss : 0.022532
[11:43:17.396] iteration 18807 : model1 loss : 0.442557 model2 loss : 0.022080
[11:43:17.566] iteration 18808 : model1 loss : 0.436269 model2 loss : 0.022570
[11:43:17.732] iteration 18809 : model1 loss : 0.439440 model2 loss : 0.022569
[11:43:17.900] iteration 18810 : model1 loss : 0.434063 model2 loss : 0.020961
[11:43:19.834] iteration 18811 : model1 loss : 0.431988 model2 loss : 0.022093
[11:43:20.007] iteration 18812 : model1 loss : 0.437292 model2 loss : 0.021566
[11:43:20.177] iteration 18813 : model1 loss : 0.432646 model2 loss : 0.023365
[11:43:20.343] iteration 18814 : model1 loss : 0.437693 model2 loss : 0.021282
[11:43:20.515] iteration 18815 : model1 loss : 0.435730 model2 loss : 0.022163
[11:43:20.683] iteration 18816 : model1 loss : 0.437729 model2 loss : 0.021609
[11:43:20.851] iteration 18817 : model1 loss : 0.441773 model2 loss : 0.021925
[11:43:21.018] iteration 18818 : model1 loss : 0.431476 model2 loss : 0.021364
[11:43:21.188] iteration 18819 : model1 loss : 0.442865 model2 loss : 0.021161
[11:43:21.356] iteration 18820 : model1 loss : 0.438447 model2 loss : 0.021872
[11:43:21.530] iteration 18821 : model1 loss : 0.436045 model2 loss : 0.018301
[11:43:21.696] iteration 18822 : model1 loss : 0.441148 model2 loss : 0.022323
[11:43:21.864] iteration 18823 : model1 loss : 0.438169 model2 loss : 0.022800
[11:43:22.034] iteration 18824 : model1 loss : 0.436361 model2 loss : 0.021354
[11:43:22.203] iteration 18825 : model1 loss : 0.438903 model2 loss : 0.020769
[11:43:22.371] iteration 18826 : model1 loss : 0.435952 model2 loss : 0.021984
[11:43:22.540] iteration 18827 : model1 loss : 0.437756 model2 loss : 0.023431
[11:43:22.704] iteration 18828 : model1 loss : 0.442939 model2 loss : 0.023481
[11:43:22.875] iteration 18829 : model1 loss : 0.440620 model2 loss : 0.025435
[11:43:23.041] iteration 18830 : model1 loss : 0.437417 model2 loss : 0.021298
[11:43:23.212] iteration 18831 : model1 loss : 0.437213 model2 loss : 0.020898
[11:43:23.377] iteration 18832 : model1 loss : 0.436905 model2 loss : 0.021078
[11:43:23.548] iteration 18833 : model1 loss : 0.440391 model2 loss : 0.025093
[11:43:23.714] iteration 18834 : model1 loss : 0.438085 model2 loss : 0.022479
[11:43:23.883] iteration 18835 : model1 loss : 0.437404 model2 loss : 0.021772
[11:43:24.051] iteration 18836 : model1 loss : 0.438661 model2 loss : 0.021173
[11:43:24.221] iteration 18837 : model1 loss : 0.439776 model2 loss : 0.023109
[11:43:24.388] iteration 18838 : model1 loss : 0.441467 model2 loss : 0.022511
[11:43:24.558] iteration 18839 : model1 loss : 0.436192 model2 loss : 0.020672
[11:43:24.725] iteration 18840 : model1 loss : 0.439883 model2 loss : 0.021257
[11:43:24.894] iteration 18841 : model1 loss : 0.435386 model2 loss : 0.021568
[11:43:25.059] iteration 18842 : model1 loss : 0.440702 model2 loss : 0.024256
[11:43:25.227] iteration 18843 : model1 loss : 0.440616 model2 loss : 0.022936
[11:43:27.174] iteration 18844 : model1 loss : 0.441975 model2 loss : 0.025600
[11:43:27.342] iteration 18845 : model1 loss : 0.435363 model2 loss : 0.019954
[11:43:27.518] iteration 18846 : model1 loss : 0.435872 model2 loss : 0.019076
[11:43:27.686] iteration 18847 : model1 loss : 0.442887 model2 loss : 0.022619
[11:43:27.854] iteration 18848 : model1 loss : 0.440828 model2 loss : 0.024939
[11:43:28.021] iteration 18849 : model1 loss : 0.438914 model2 loss : 0.022252
[11:43:28.190] iteration 18850 : model1 loss : 0.439142 model2 loss : 0.022839
[11:43:28.358] iteration 18851 : model1 loss : 0.436905 model2 loss : 0.024315
[11:43:28.527] iteration 18852 : model1 loss : 0.439598 model2 loss : 0.021823
[11:43:28.695] iteration 18853 : model1 loss : 0.432851 model2 loss : 0.020863
[11:43:28.863] iteration 18854 : model1 loss : 0.438480 model2 loss : 0.022853
[11:43:29.029] iteration 18855 : model1 loss : 0.444517 model2 loss : 0.025836
[11:43:29.198] iteration 18856 : model1 loss : 0.436943 model2 loss : 0.021791
[11:43:29.363] iteration 18857 : model1 loss : 0.434821 model2 loss : 0.023324
[11:43:29.536] iteration 18858 : model1 loss : 0.434637 model2 loss : 0.021441
[11:43:29.704] iteration 18859 : model1 loss : 0.438552 model2 loss : 0.021487
[11:43:29.873] iteration 18860 : model1 loss : 0.439099 model2 loss : 0.022187
[11:43:30.041] iteration 18861 : model1 loss : 0.440345 model2 loss : 0.023277
[11:43:30.210] iteration 18862 : model1 loss : 0.440084 model2 loss : 0.023226
[11:43:30.375] iteration 18863 : model1 loss : 0.433302 model2 loss : 0.021559
[11:43:30.545] iteration 18864 : model1 loss : 0.439557 model2 loss : 0.023474
[11:43:30.712] iteration 18865 : model1 loss : 0.441873 model2 loss : 0.024080
[11:43:30.883] iteration 18866 : model1 loss : 0.433619 model2 loss : 0.023596
[11:43:31.050] iteration 18867 : model1 loss : 0.440125 model2 loss : 0.023298
[11:43:31.218] iteration 18868 : model1 loss : 0.438668 model2 loss : 0.021475
[11:43:31.385] iteration 18869 : model1 loss : 0.435571 model2 loss : 0.021874
[11:43:31.555] iteration 18870 : model1 loss : 0.439802 model2 loss : 0.022154
[11:43:31.722] iteration 18871 : model1 loss : 0.439468 model2 loss : 0.021745
[11:43:31.892] iteration 18872 : model1 loss : 0.434007 model2 loss : 0.020063
[11:43:32.059] iteration 18873 : model1 loss : 0.436506 model2 loss : 0.019016
[11:43:32.229] iteration 18874 : model1 loss : 0.440395 model2 loss : 0.019664
[11:43:32.393] iteration 18875 : model1 loss : 0.435799 model2 loss : 0.020077
[11:43:32.561] iteration 18876 : model1 loss : 0.434767 model2 loss : 0.020169
[11:43:34.493] iteration 18877 : model1 loss : 0.437670 model2 loss : 0.021332
[11:43:34.663] iteration 18878 : model1 loss : 0.441858 model2 loss : 0.026280
[11:43:34.834] iteration 18879 : model1 loss : 0.439060 model2 loss : 0.021113
[11:43:35.000] iteration 18880 : model1 loss : 0.436158 model2 loss : 0.021971
[11:43:35.168] iteration 18881 : model1 loss : 0.438671 model2 loss : 0.022095
[11:43:35.339] iteration 18882 : model1 loss : 0.441442 model2 loss : 0.023231
[11:43:35.510] iteration 18883 : model1 loss : 0.436830 model2 loss : 0.020081
[11:43:35.676] iteration 18884 : model1 loss : 0.438485 model2 loss : 0.021774
[11:43:35.846] iteration 18885 : model1 loss : 0.439729 model2 loss : 0.023197
[11:43:36.012] iteration 18886 : model1 loss : 0.442464 model2 loss : 0.023605
[11:43:36.183] iteration 18887 : model1 loss : 0.441903 model2 loss : 0.023860
[11:43:36.349] iteration 18888 : model1 loss : 0.436344 model2 loss : 0.021368
[11:43:36.520] iteration 18889 : model1 loss : 0.436604 model2 loss : 0.020594
[11:43:36.687] iteration 18890 : model1 loss : 0.434126 model2 loss : 0.019695
[11:43:36.855] iteration 18891 : model1 loss : 0.440407 model2 loss : 0.023967
[11:43:37.022] iteration 18892 : model1 loss : 0.438887 model2 loss : 0.021928
[11:43:37.192] iteration 18893 : model1 loss : 0.439961 model2 loss : 0.020478
[11:43:37.358] iteration 18894 : model1 loss : 0.436617 model2 loss : 0.021859
[11:43:37.528] iteration 18895 : model1 loss : 0.439751 model2 loss : 0.022051
[11:43:37.693] iteration 18896 : model1 loss : 0.437194 model2 loss : 0.019147
[11:43:37.864] iteration 18897 : model1 loss : 0.437854 model2 loss : 0.021946
[11:43:38.030] iteration 18898 : model1 loss : 0.435469 model2 loss : 0.020547
[11:43:38.200] iteration 18899 : model1 loss : 0.438783 model2 loss : 0.021437
[11:43:38.368] iteration 18900 : model1 loss : 0.437515 model2 loss : 0.021562
[11:43:38.537] iteration 18901 : model1 loss : 0.431650 model2 loss : 0.018912
[11:43:38.703] iteration 18902 : model1 loss : 0.437310 model2 loss : 0.021547
[11:43:38.875] iteration 18903 : model1 loss : 0.433116 model2 loss : 0.020186
[11:43:39.042] iteration 18904 : model1 loss : 0.441346 model2 loss : 0.022437
[11:43:39.211] iteration 18905 : model1 loss : 0.438417 model2 loss : 0.024170
[11:43:39.378] iteration 18906 : model1 loss : 0.437428 model2 loss : 0.022143
[11:43:39.548] iteration 18907 : model1 loss : 0.434474 model2 loss : 0.020947
[11:43:39.714] iteration 18908 : model1 loss : 0.435212 model2 loss : 0.019862
[11:43:39.882] iteration 18909 : model1 loss : 0.439517 model2 loss : 0.023561
[11:43:41.864] iteration 18910 : model1 loss : 0.434578 model2 loss : 0.017995
[11:43:42.031] iteration 18911 : model1 loss : 0.440837 model2 loss : 0.025985
[11:43:42.201] iteration 18912 : model1 loss : 0.436129 model2 loss : 0.022568
[11:43:42.370] iteration 18913 : model1 loss : 0.440528 model2 loss : 0.021376
[11:43:42.541] iteration 18914 : model1 loss : 0.436957 model2 loss : 0.022244
[11:43:42.706] iteration 18915 : model1 loss : 0.435861 model2 loss : 0.019815
[11:43:42.877] iteration 18916 : model1 loss : 0.437051 model2 loss : 0.022895
[11:43:43.044] iteration 18917 : model1 loss : 0.433934 model2 loss : 0.021670
[11:43:43.212] iteration 18918 : model1 loss : 0.440731 model2 loss : 0.027766
[11:43:43.381] iteration 18919 : model1 loss : 0.437274 model2 loss : 0.022572
[11:43:43.550] iteration 18920 : model1 loss : 0.438964 model2 loss : 0.022901
[11:43:43.716] iteration 18921 : model1 loss : 0.438034 model2 loss : 0.020420
[11:43:43.885] iteration 18922 : model1 loss : 0.441879 model2 loss : 0.020385
[11:43:44.051] iteration 18923 : model1 loss : 0.438956 model2 loss : 0.021013
[11:43:44.219] iteration 18924 : model1 loss : 0.433475 model2 loss : 0.022586
[11:43:44.387] iteration 18925 : model1 loss : 0.440692 model2 loss : 0.023826
[11:43:44.557] iteration 18926 : model1 loss : 0.437722 model2 loss : 0.021234
[11:43:44.724] iteration 18927 : model1 loss : 0.437387 model2 loss : 0.021274
[11:43:44.893] iteration 18928 : model1 loss : 0.434600 model2 loss : 0.018200
[11:43:45.059] iteration 18929 : model1 loss : 0.442414 model2 loss : 0.022426
[11:43:45.225] iteration 18930 : model1 loss : 0.434393 model2 loss : 0.020838
[11:43:45.393] iteration 18931 : model1 loss : 0.440496 model2 loss : 0.021630
[11:43:45.563] iteration 18932 : model1 loss : 0.436971 model2 loss : 0.023212
[11:43:45.730] iteration 18933 : model1 loss : 0.438424 model2 loss : 0.017537
[11:43:45.902] iteration 18934 : model1 loss : 0.440042 model2 loss : 0.024345
[11:43:46.068] iteration 18935 : model1 loss : 0.440658 model2 loss : 0.020332
[11:43:46.237] iteration 18936 : model1 loss : 0.437737 model2 loss : 0.021332
[11:43:46.404] iteration 18937 : model1 loss : 0.437857 model2 loss : 0.019788
[11:43:46.575] iteration 18938 : model1 loss : 0.438942 model2 loss : 0.021435
[11:43:46.742] iteration 18939 : model1 loss : 0.438460 model2 loss : 0.021493
[11:43:46.911] iteration 18940 : model1 loss : 0.435399 model2 loss : 0.019980
[11:43:47.076] iteration 18941 : model1 loss : 0.436911 model2 loss : 0.021243
[11:43:47.243] iteration 18942 : model1 loss : 0.441459 model2 loss : 0.023739
[11:43:49.161] iteration 18943 : model1 loss : 0.433285 model2 loss : 0.019634
[11:43:49.335] iteration 18944 : model1 loss : 0.437312 model2 loss : 0.021939
[11:43:49.508] iteration 18945 : model1 loss : 0.437489 model2 loss : 0.021690
[11:43:49.676] iteration 18946 : model1 loss : 0.435490 model2 loss : 0.021222
[11:43:49.847] iteration 18947 : model1 loss : 0.440363 model2 loss : 0.022650
[11:43:50.014] iteration 18948 : model1 loss : 0.437539 model2 loss : 0.022923
[11:43:50.183] iteration 18949 : model1 loss : 0.434543 model2 loss : 0.019899
[11:43:50.354] iteration 18950 : model1 loss : 0.442874 model2 loss : 0.023408
[11:43:50.524] iteration 18951 : model1 loss : 0.436065 model2 loss : 0.020363
[11:43:50.691] iteration 18952 : model1 loss : 0.436287 model2 loss : 0.015941
[11:43:50.861] iteration 18953 : model1 loss : 0.438740 model2 loss : 0.023228
[11:43:51.029] iteration 18954 : model1 loss : 0.439289 model2 loss : 0.020862
[11:43:51.197] iteration 18955 : model1 loss : 0.438119 model2 loss : 0.020961
[11:43:51.367] iteration 18956 : model1 loss : 0.441113 model2 loss : 0.022215
[11:43:51.538] iteration 18957 : model1 loss : 0.437534 model2 loss : 0.020172
[11:43:51.703] iteration 18958 : model1 loss : 0.440098 model2 loss : 0.021150
[11:43:51.871] iteration 18959 : model1 loss : 0.435335 model2 loss : 0.021308
[11:43:52.038] iteration 18960 : model1 loss : 0.433285 model2 loss : 0.020453
[11:43:52.208] iteration 18961 : model1 loss : 0.436922 model2 loss : 0.020664
[11:43:52.380] iteration 18962 : model1 loss : 0.442119 model2 loss : 0.022969
[11:43:52.547] iteration 18963 : model1 loss : 0.437506 model2 loss : 0.022595
[11:43:52.715] iteration 18964 : model1 loss : 0.439459 model2 loss : 0.023022
[11:43:52.883] iteration 18965 : model1 loss : 0.439888 model2 loss : 0.020425
[11:43:53.052] iteration 18966 : model1 loss : 0.435109 model2 loss : 0.021560
[11:43:53.222] iteration 18967 : model1 loss : 0.441853 model2 loss : 0.024160
[11:43:53.389] iteration 18968 : model1 loss : 0.437872 model2 loss : 0.020179
[11:43:53.558] iteration 18969 : model1 loss : 0.444373 model2 loss : 0.026909
[11:43:53.741] iteration 18970 : model1 loss : 0.436316 model2 loss : 0.022300
[11:43:53.913] iteration 18971 : model1 loss : 0.439452 model2 loss : 0.021356
[11:43:54.079] iteration 18972 : model1 loss : 0.441841 model2 loss : 0.023652
[11:43:54.247] iteration 18973 : model1 loss : 0.438149 model2 loss : 0.021364
[11:43:54.413] iteration 18974 : model1 loss : 0.434581 model2 loss : 0.019512
[11:43:54.579] iteration 18975 : model1 loss : 0.432778 model2 loss : 0.021360
[11:43:56.527] iteration 18976 : model1 loss : 0.439438 model2 loss : 0.021338
[11:43:56.695] iteration 18977 : model1 loss : 0.441880 model2 loss : 0.023472
[11:43:56.865] iteration 18978 : model1 loss : 0.438974 model2 loss : 0.021217
[11:43:57.032] iteration 18979 : model1 loss : 0.437439 model2 loss : 0.021386
[11:43:57.199] iteration 18980 : model1 loss : 0.438469 model2 loss : 0.018939
[11:43:57.369] iteration 18981 : model1 loss : 0.438975 model2 loss : 0.022360
[11:43:57.541] iteration 18982 : model1 loss : 0.439455 model2 loss : 0.021968
[11:43:57.709] iteration 18983 : model1 loss : 0.435862 model2 loss : 0.020655
[11:43:57.878] iteration 18984 : model1 loss : 0.436935 model2 loss : 0.020793
[11:43:58.044] iteration 18985 : model1 loss : 0.438593 model2 loss : 0.022294
[11:43:58.213] iteration 18986 : model1 loss : 0.435455 model2 loss : 0.020760
[11:43:58.382] iteration 18987 : model1 loss : 0.435302 model2 loss : 0.021971
[11:43:58.552] iteration 18988 : model1 loss : 0.435416 model2 loss : 0.022205
[11:43:58.720] iteration 18989 : model1 loss : 0.436667 model2 loss : 0.018491
[11:43:58.888] iteration 18990 : model1 loss : 0.435778 model2 loss : 0.021652
[11:43:59.057] iteration 18991 : model1 loss : 0.438403 model2 loss : 0.019633
[11:43:59.224] iteration 18992 : model1 loss : 0.437555 model2 loss : 0.022099
[11:43:59.393] iteration 18993 : model1 loss : 0.435392 model2 loss : 0.018832
[11:43:59.562] iteration 18994 : model1 loss : 0.438377 model2 loss : 0.023189
[11:43:59.729] iteration 18995 : model1 loss : 0.439389 model2 loss : 0.021345
[11:43:59.899] iteration 18996 : model1 loss : 0.438031 model2 loss : 0.022271
[11:44:00.065] iteration 18997 : model1 loss : 0.442177 model2 loss : 0.024904
[11:44:00.234] iteration 18998 : model1 loss : 0.438049 model2 loss : 0.022583
[11:44:00.402] iteration 18999 : model1 loss : 0.434014 model2 loss : 0.018578
[11:44:00.572] iteration 19000 : model1 loss : 0.439775 model2 loss : 0.022211
[11:44:08.910] iteration 19000 : model1_mean_dice : 0.897849 model1_mean_hd95 : 3.716250
[11:44:17.266] iteration 19000 : model2_mean_dice : 0.895862 model2_mean_hd95 : 2.087178
[11:44:17.445] iteration 19001 : model1 loss : 0.433481 model2 loss : 0.020315
[11:44:17.619] iteration 19002 : model1 loss : 0.440249 model2 loss : 0.023569
[11:44:17.783] iteration 19003 : model1 loss : 0.438925 model2 loss : 0.023920
[11:44:17.951] iteration 19004 : model1 loss : 0.439082 model2 loss : 0.020060
[11:44:18.117] iteration 19005 : model1 loss : 0.436717 model2 loss : 0.022009
[11:44:18.284] iteration 19006 : model1 loss : 0.436904 model2 loss : 0.020717
[11:44:18.449] iteration 19007 : model1 loss : 0.440075 model2 loss : 0.024052
[11:44:18.616] iteration 19008 : model1 loss : 0.442065 model2 loss : 0.021717
[11:44:20.551] iteration 19009 : model1 loss : 0.438811 model2 loss : 0.020544
[11:44:20.720] iteration 19010 : model1 loss : 0.436556 model2 loss : 0.024009
[11:44:20.890] iteration 19011 : model1 loss : 0.436073 model2 loss : 0.022106
[11:44:21.057] iteration 19012 : model1 loss : 0.435172 model2 loss : 0.021272
[11:44:21.226] iteration 19013 : model1 loss : 0.439535 model2 loss : 0.023307
[11:44:21.391] iteration 19014 : model1 loss : 0.440619 model2 loss : 0.021573
[11:44:21.561] iteration 19015 : model1 loss : 0.436809 model2 loss : 0.020746
[11:44:21.728] iteration 19016 : model1 loss : 0.436639 model2 loss : 0.022537
[11:44:21.898] iteration 19017 : model1 loss : 0.444732 model2 loss : 0.021034
[11:44:22.065] iteration 19018 : model1 loss : 0.436484 model2 loss : 0.020124
[11:44:22.236] iteration 19019 : model1 loss : 0.438853 model2 loss : 0.024300
[11:44:22.404] iteration 19020 : model1 loss : 0.440303 model2 loss : 0.024456
[11:44:22.573] iteration 19021 : model1 loss : 0.436255 model2 loss : 0.020741
[11:44:22.739] iteration 19022 : model1 loss : 0.441466 model2 loss : 0.019870
[11:44:22.909] iteration 19023 : model1 loss : 0.442728 model2 loss : 0.027433
[11:44:23.074] iteration 19024 : model1 loss : 0.437021 model2 loss : 0.021844
[11:44:23.242] iteration 19025 : model1 loss : 0.435801 model2 loss : 0.022429
[11:44:23.411] iteration 19026 : model1 loss : 0.441130 model2 loss : 0.024908
[11:44:23.579] iteration 19027 : model1 loss : 0.432963 model2 loss : 0.019537
[11:44:23.746] iteration 19028 : model1 loss : 0.439991 model2 loss : 0.022088
[11:44:23.923] iteration 19029 : model1 loss : 0.440003 model2 loss : 0.023275
[11:44:24.090] iteration 19030 : model1 loss : 0.436744 model2 loss : 0.021619
[11:44:24.259] iteration 19031 : model1 loss : 0.435085 model2 loss : 0.021047
[11:44:24.429] iteration 19032 : model1 loss : 0.437081 model2 loss : 0.019904
[11:44:24.596] iteration 19033 : model1 loss : 0.436633 model2 loss : 0.022289
[11:44:24.764] iteration 19034 : model1 loss : 0.440881 model2 loss : 0.021703
[11:44:24.932] iteration 19035 : model1 loss : 0.438264 model2 loss : 0.020622
[11:44:25.102] iteration 19036 : model1 loss : 0.437587 model2 loss : 0.020375
[11:44:25.271] iteration 19037 : model1 loss : 0.438709 model2 loss : 0.022000
[11:44:25.439] iteration 19038 : model1 loss : 0.438129 model2 loss : 0.019982
[11:44:25.608] iteration 19039 : model1 loss : 0.436815 model2 loss : 0.020187
[11:44:25.773] iteration 19040 : model1 loss : 0.440409 model2 loss : 0.022443
[11:44:25.941] iteration 19041 : model1 loss : 0.434335 model2 loss : 0.022149
[11:44:27.909] iteration 19042 : model1 loss : 0.438671 model2 loss : 0.024832
[11:44:28.075] iteration 19043 : model1 loss : 0.438676 model2 loss : 0.022476
[11:44:28.244] iteration 19044 : model1 loss : 0.433860 model2 loss : 0.021698
[11:44:28.411] iteration 19045 : model1 loss : 0.441280 model2 loss : 0.024922
[11:44:28.578] iteration 19046 : model1 loss : 0.435685 model2 loss : 0.022157
[11:44:28.745] iteration 19047 : model1 loss : 0.436921 model2 loss : 0.019285
[11:44:28.914] iteration 19048 : model1 loss : 0.436526 model2 loss : 0.022639
[11:44:29.081] iteration 19049 : model1 loss : 0.438910 model2 loss : 0.021649
[11:44:29.251] iteration 19050 : model1 loss : 0.437003 model2 loss : 0.019912
[11:44:29.417] iteration 19051 : model1 loss : 0.438935 model2 loss : 0.022979
[11:44:29.585] iteration 19052 : model1 loss : 0.436680 model2 loss : 0.022670
[11:44:29.751] iteration 19053 : model1 loss : 0.432090 model2 loss : 0.018435
[11:44:29.919] iteration 19054 : model1 loss : 0.442367 model2 loss : 0.023759
[11:44:30.085] iteration 19055 : model1 loss : 0.436114 model2 loss : 0.020633
[11:44:30.253] iteration 19056 : model1 loss : 0.437841 model2 loss : 0.024134
[11:44:30.420] iteration 19057 : model1 loss : 0.442794 model2 loss : 0.023110
[11:44:30.589] iteration 19058 : model1 loss : 0.438308 model2 loss : 0.022127
[11:44:30.753] iteration 19059 : model1 loss : 0.435886 model2 loss : 0.021221
[11:44:30.925] iteration 19060 : model1 loss : 0.441727 model2 loss : 0.022573
[11:44:31.091] iteration 19061 : model1 loss : 0.439707 model2 loss : 0.022116
[11:44:31.258] iteration 19062 : model1 loss : 0.432599 model2 loss : 0.022377
[11:44:31.425] iteration 19063 : model1 loss : 0.432865 model2 loss : 0.022640
[11:44:31.594] iteration 19064 : model1 loss : 0.437701 model2 loss : 0.020290
[11:44:31.775] iteration 19065 : model1 loss : 0.440804 model2 loss : 0.021966
[11:44:31.945] iteration 19066 : model1 loss : 0.438719 model2 loss : 0.020485
[11:44:32.111] iteration 19067 : model1 loss : 0.438545 model2 loss : 0.022035
[11:44:32.280] iteration 19068 : model1 loss : 0.439508 model2 loss : 0.019346
[11:44:32.450] iteration 19069 : model1 loss : 0.440163 model2 loss : 0.020574
[11:44:32.618] iteration 19070 : model1 loss : 0.440804 model2 loss : 0.025197
[11:44:32.786] iteration 19071 : model1 loss : 0.440059 model2 loss : 0.022504
[11:44:32.953] iteration 19072 : model1 loss : 0.437236 model2 loss : 0.021948
[11:44:33.118] iteration 19073 : model1 loss : 0.436580 model2 loss : 0.022036
[11:44:33.285] iteration 19074 : model1 loss : 0.440271 model2 loss : 0.024434
[11:44:35.210] iteration 19075 : model1 loss : 0.444725 model2 loss : 0.026040
[11:44:35.380] iteration 19076 : model1 loss : 0.441054 model2 loss : 0.024836
[11:44:35.548] iteration 19077 : model1 loss : 0.440032 model2 loss : 0.021060
[11:44:35.714] iteration 19078 : model1 loss : 0.439125 model2 loss : 0.022119
[11:44:35.885] iteration 19079 : model1 loss : 0.443383 model2 loss : 0.026377
[11:44:36.051] iteration 19080 : model1 loss : 0.435857 model2 loss : 0.021305
[11:44:36.220] iteration 19081 : model1 loss : 0.435285 model2 loss : 0.022425
[11:44:36.387] iteration 19082 : model1 loss : 0.435799 model2 loss : 0.021401
[11:44:36.558] iteration 19083 : model1 loss : 0.437477 model2 loss : 0.020517
[11:44:36.725] iteration 19084 : model1 loss : 0.435482 model2 loss : 0.022956
[11:44:36.894] iteration 19085 : model1 loss : 0.437558 model2 loss : 0.022244
[11:44:37.063] iteration 19086 : model1 loss : 0.436744 model2 loss : 0.022507
[11:44:37.232] iteration 19087 : model1 loss : 0.434383 model2 loss : 0.019948
[11:44:37.401] iteration 19088 : model1 loss : 0.437976 model2 loss : 0.021178
[11:44:37.568] iteration 19089 : model1 loss : 0.440192 model2 loss : 0.021817
[11:44:37.733] iteration 19090 : model1 loss : 0.438507 model2 loss : 0.020496
[11:44:37.902] iteration 19091 : model1 loss : 0.435478 model2 loss : 0.023517
[11:44:38.068] iteration 19092 : model1 loss : 0.437614 model2 loss : 0.019064
[11:44:38.234] iteration 19093 : model1 loss : 0.437187 model2 loss : 0.019876
[11:44:38.400] iteration 19094 : model1 loss : 0.444053 model2 loss : 0.024622
[11:44:38.569] iteration 19095 : model1 loss : 0.443611 model2 loss : 0.024571
[11:44:38.733] iteration 19096 : model1 loss : 0.435308 model2 loss : 0.022391
[11:44:38.902] iteration 19097 : model1 loss : 0.439359 model2 loss : 0.021999
[11:44:39.069] iteration 19098 : model1 loss : 0.434824 model2 loss : 0.019448
[11:44:39.238] iteration 19099 : model1 loss : 0.440777 model2 loss : 0.023551
[11:44:39.405] iteration 19100 : model1 loss : 0.436973 model2 loss : 0.024459
[11:44:39.572] iteration 19101 : model1 loss : 0.435056 model2 loss : 0.020212
[11:44:39.738] iteration 19102 : model1 loss : 0.442892 model2 loss : 0.024348
[11:44:39.908] iteration 19103 : model1 loss : 0.437167 model2 loss : 0.021499
[11:44:40.074] iteration 19104 : model1 loss : 0.431908 model2 loss : 0.019657
[11:44:40.243] iteration 19105 : model1 loss : 0.433242 model2 loss : 0.020958
[11:44:40.406] iteration 19106 : model1 loss : 0.439495 model2 loss : 0.020339
[11:44:40.575] iteration 19107 : model1 loss : 0.440670 model2 loss : 0.021859
[11:44:42.484] iteration 19108 : model1 loss : 0.433241 model2 loss : 0.022196
[11:44:42.650] iteration 19109 : model1 loss : 0.440675 model2 loss : 0.022232
[11:44:42.820] iteration 19110 : model1 loss : 0.438959 model2 loss : 0.024153
[11:44:42.987] iteration 19111 : model1 loss : 0.437083 model2 loss : 0.021622
[11:44:43.155] iteration 19112 : model1 loss : 0.442282 model2 loss : 0.023263
[11:44:43.321] iteration 19113 : model1 loss : 0.433923 model2 loss : 0.019538
[11:44:43.495] iteration 19114 : model1 loss : 0.443821 model2 loss : 0.021600
[11:44:43.661] iteration 19115 : model1 loss : 0.435206 model2 loss : 0.020464
[11:44:43.828] iteration 19116 : model1 loss : 0.437429 model2 loss : 0.021459
[11:44:43.995] iteration 19117 : model1 loss : 0.441349 model2 loss : 0.027232
[11:44:44.165] iteration 19118 : model1 loss : 0.435937 model2 loss : 0.021093
[11:44:44.329] iteration 19119 : model1 loss : 0.438912 model2 loss : 0.022544
[11:44:44.500] iteration 19120 : model1 loss : 0.439921 model2 loss : 0.026095
[11:44:44.666] iteration 19121 : model1 loss : 0.439393 model2 loss : 0.020957
[11:44:44.834] iteration 19122 : model1 loss : 0.439186 model2 loss : 0.023030
[11:44:45.002] iteration 19123 : model1 loss : 0.432960 model2 loss : 0.020457
[11:44:45.168] iteration 19124 : model1 loss : 0.438059 model2 loss : 0.023089
[11:44:45.335] iteration 19125 : model1 loss : 0.437904 model2 loss : 0.024733
[11:44:45.507] iteration 19126 : model1 loss : 0.437766 model2 loss : 0.021019
[11:44:45.674] iteration 19127 : model1 loss : 0.437987 model2 loss : 0.021163
[11:44:45.841] iteration 19128 : model1 loss : 0.440723 model2 loss : 0.022053
[11:44:46.008] iteration 19129 : model1 loss : 0.439649 model2 loss : 0.024358
[11:44:46.176] iteration 19130 : model1 loss : 0.438363 model2 loss : 0.022414
[11:44:46.342] iteration 19131 : model1 loss : 0.436699 model2 loss : 0.020710
[11:44:46.513] iteration 19132 : model1 loss : 0.441750 model2 loss : 0.021205
[11:44:46.679] iteration 19133 : model1 loss : 0.434015 model2 loss : 0.021565
[11:44:46.848] iteration 19134 : model1 loss : 0.440841 model2 loss : 0.023600
[11:44:47.013] iteration 19135 : model1 loss : 0.439755 model2 loss : 0.022184
[11:44:47.184] iteration 19136 : model1 loss : 0.434655 model2 loss : 0.023083
[11:44:47.348] iteration 19137 : model1 loss : 0.436706 model2 loss : 0.022933
[11:44:47.519] iteration 19138 : model1 loss : 0.433973 model2 loss : 0.021906
[11:44:47.686] iteration 19139 : model1 loss : 0.441294 model2 loss : 0.024996
[11:44:47.852] iteration 19140 : model1 loss : 0.435753 model2 loss : 0.022462
[11:44:49.768] iteration 19141 : model1 loss : 0.442686 model2 loss : 0.024581
[11:44:49.935] iteration 19142 : model1 loss : 0.440382 model2 loss : 0.022434
[11:44:50.109] iteration 19143 : model1 loss : 0.435081 model2 loss : 0.021316
[11:44:50.277] iteration 19144 : model1 loss : 0.437805 model2 loss : 0.022876
[11:44:50.446] iteration 19145 : model1 loss : 0.442951 model2 loss : 0.026251
[11:44:50.612] iteration 19146 : model1 loss : 0.438687 model2 loss : 0.021169
[11:44:50.780] iteration 19147 : model1 loss : 0.436900 model2 loss : 0.023165
[11:44:50.945] iteration 19148 : model1 loss : 0.437351 model2 loss : 0.024227
[11:44:51.113] iteration 19149 : model1 loss : 0.436865 model2 loss : 0.023412
[11:44:51.280] iteration 19150 : model1 loss : 0.437137 model2 loss : 0.021364
[11:44:51.451] iteration 19151 : model1 loss : 0.438131 model2 loss : 0.027034
[11:44:51.617] iteration 19152 : model1 loss : 0.438925 model2 loss : 0.023731
[11:44:51.784] iteration 19153 : model1 loss : 0.438035 model2 loss : 0.022294
[11:44:51.950] iteration 19154 : model1 loss : 0.441613 model2 loss : 0.025177
[11:44:52.119] iteration 19155 : model1 loss : 0.429427 model2 loss : 0.021343
[11:44:52.286] iteration 19156 : model1 loss : 0.438389 model2 loss : 0.020377
[11:44:52.454] iteration 19157 : model1 loss : 0.435569 model2 loss : 0.021524
[11:44:52.620] iteration 19158 : model1 loss : 0.437005 model2 loss : 0.022045
[11:44:52.788] iteration 19159 : model1 loss : 0.442339 model2 loss : 0.024044
[11:44:52.953] iteration 19160 : model1 loss : 0.436221 model2 loss : 0.022947
[11:44:53.123] iteration 19161 : model1 loss : 0.442662 model2 loss : 0.024416
[11:44:53.288] iteration 19162 : model1 loss : 0.437650 model2 loss : 0.020756
[11:44:53.461] iteration 19163 : model1 loss : 0.438149 model2 loss : 0.023167
[11:44:53.628] iteration 19164 : model1 loss : 0.434616 model2 loss : 0.021167
[11:44:53.798] iteration 19165 : model1 loss : 0.439265 model2 loss : 0.022194
[11:44:53.966] iteration 19166 : model1 loss : 0.436071 model2 loss : 0.022061
[11:44:54.134] iteration 19167 : model1 loss : 0.440976 model2 loss : 0.022583
[11:44:54.302] iteration 19168 : model1 loss : 0.440843 model2 loss : 0.024485
[11:44:54.473] iteration 19169 : model1 loss : 0.439544 model2 loss : 0.024188
[11:44:54.639] iteration 19170 : model1 loss : 0.440343 model2 loss : 0.025887
[11:44:54.809] iteration 19171 : model1 loss : 0.433964 model2 loss : 0.021505
[11:44:54.974] iteration 19172 : model1 loss : 0.439810 model2 loss : 0.018727
[11:44:55.142] iteration 19173 : model1 loss : 0.437834 model2 loss : 0.022043
[11:44:57.078] iteration 19174 : model1 loss : 0.435823 model2 loss : 0.021874
[11:44:57.245] iteration 19175 : model1 loss : 0.440244 model2 loss : 0.024416
[11:44:57.412] iteration 19176 : model1 loss : 0.438086 model2 loss : 0.023969
[11:44:57.579] iteration 19177 : model1 loss : 0.438599 model2 loss : 0.022773
[11:44:57.747] iteration 19178 : model1 loss : 0.443011 model2 loss : 0.024464
[11:44:57.915] iteration 19179 : model1 loss : 0.439118 model2 loss : 0.021443
[11:44:58.100] iteration 19180 : model1 loss : 0.432596 model2 loss : 0.022376
[11:44:58.268] iteration 19181 : model1 loss : 0.439985 model2 loss : 0.023151
[11:44:58.436] iteration 19182 : model1 loss : 0.437871 model2 loss : 0.023703
[11:44:58.604] iteration 19183 : model1 loss : 0.434882 model2 loss : 0.021458
[11:44:58.773] iteration 19184 : model1 loss : 0.437849 model2 loss : 0.021940
[11:44:58.939] iteration 19185 : model1 loss : 0.436066 model2 loss : 0.020102
[11:44:59.107] iteration 19186 : model1 loss : 0.437446 model2 loss : 0.021232
[11:44:59.273] iteration 19187 : model1 loss : 0.436170 model2 loss : 0.020666
[11:44:59.442] iteration 19188 : model1 loss : 0.439039 model2 loss : 0.022762
[11:44:59.626] iteration 19189 : model1 loss : 0.433364 model2 loss : 0.018849
[11:44:59.795] iteration 19190 : model1 loss : 0.438157 model2 loss : 0.021575
[11:44:59.962] iteration 19191 : model1 loss : 0.438639 model2 loss : 0.023387
[11:45:00.133] iteration 19192 : model1 loss : 0.436052 model2 loss : 0.023708
[11:45:00.299] iteration 19193 : model1 loss : 0.443581 model2 loss : 0.022930
[11:45:00.469] iteration 19194 : model1 loss : 0.439164 model2 loss : 0.020508
[11:45:00.637] iteration 19195 : model1 loss : 0.440905 model2 loss : 0.022955
[11:45:00.805] iteration 19196 : model1 loss : 0.440624 model2 loss : 0.023178
[11:45:00.974] iteration 19197 : model1 loss : 0.440132 model2 loss : 0.022457
[11:45:01.142] iteration 19198 : model1 loss : 0.437762 model2 loss : 0.020394
[11:45:01.309] iteration 19199 : model1 loss : 0.437603 model2 loss : 0.024385
[11:45:01.476] iteration 19200 : model1 loss : 0.436876 model2 loss : 0.021329
[11:45:01.642] iteration 19201 : model1 loss : 0.438231 model2 loss : 0.020478
[11:45:01.811] iteration 19202 : model1 loss : 0.439797 model2 loss : 0.023193
[11:45:01.980] iteration 19203 : model1 loss : 0.439229 model2 loss : 0.022177
[11:45:02.150] iteration 19204 : model1 loss : 0.435764 model2 loss : 0.022013
[11:45:02.316] iteration 19205 : model1 loss : 0.440963 model2 loss : 0.025443
[11:45:02.487] iteration 19206 : model1 loss : 0.438544 model2 loss : 0.022292
[11:45:04.411] iteration 19207 : model1 loss : 0.441017 model2 loss : 0.023736
[11:45:04.580] iteration 19208 : model1 loss : 0.433898 model2 loss : 0.020465
[11:45:04.749] iteration 19209 : model1 loss : 0.440693 model2 loss : 0.024109
[11:45:04.917] iteration 19210 : model1 loss : 0.436959 model2 loss : 0.022837
[11:45:05.085] iteration 19211 : model1 loss : 0.438763 model2 loss : 0.022739
[11:45:05.252] iteration 19212 : model1 loss : 0.432932 model2 loss : 0.019419
[11:45:05.422] iteration 19213 : model1 loss : 0.435928 model2 loss : 0.021133
[11:45:05.589] iteration 19214 : model1 loss : 0.441547 model2 loss : 0.023780
[11:45:05.757] iteration 19215 : model1 loss : 0.439658 model2 loss : 0.021571
[11:45:05.929] iteration 19216 : model1 loss : 0.442744 model2 loss : 0.022348
[11:45:06.096] iteration 19217 : model1 loss : 0.434853 model2 loss : 0.021653
[11:45:06.262] iteration 19218 : model1 loss : 0.441133 model2 loss : 0.027652
[11:45:06.431] iteration 19219 : model1 loss : 0.437240 model2 loss : 0.021307
[11:45:06.602] iteration 19220 : model1 loss : 0.440808 model2 loss : 0.023632
[11:45:06.770] iteration 19221 : model1 loss : 0.435554 model2 loss : 0.020388
[11:45:06.939] iteration 19222 : model1 loss : 0.441178 model2 loss : 0.022668
[11:45:07.107] iteration 19223 : model1 loss : 0.436487 model2 loss : 0.021977
[11:45:07.274] iteration 19224 : model1 loss : 0.435454 model2 loss : 0.021692
[11:45:07.442] iteration 19225 : model1 loss : 0.440227 model2 loss : 0.024722
[11:45:07.609] iteration 19226 : model1 loss : 0.437896 model2 loss : 0.020512
[11:45:07.778] iteration 19227 : model1 loss : 0.435896 model2 loss : 0.020788
[11:45:07.955] iteration 19228 : model1 loss : 0.437748 model2 loss : 0.021237
[11:45:08.124] iteration 19229 : model1 loss : 0.437983 model2 loss : 0.023585
[11:45:08.290] iteration 19230 : model1 loss : 0.440310 model2 loss : 0.022311
[11:45:08.460] iteration 19231 : model1 loss : 0.432908 model2 loss : 0.021610
[11:45:08.627] iteration 19232 : model1 loss : 0.443291 model2 loss : 0.026328
[11:45:08.797] iteration 19233 : model1 loss : 0.438725 model2 loss : 0.021970
[11:45:08.963] iteration 19234 : model1 loss : 0.439320 model2 loss : 0.022109
[11:45:09.135] iteration 19235 : model1 loss : 0.438128 model2 loss : 0.018605
[11:45:09.301] iteration 19236 : model1 loss : 0.435216 model2 loss : 0.021550
[11:45:09.468] iteration 19237 : model1 loss : 0.439666 model2 loss : 0.024649
[11:45:09.635] iteration 19238 : model1 loss : 0.437825 model2 loss : 0.019837
[11:45:09.802] iteration 19239 : model1 loss : 0.436983 model2 loss : 0.020016
[11:45:11.745] iteration 19240 : model1 loss : 0.445111 model2 loss : 0.023015
[11:45:11.911] iteration 19241 : model1 loss : 0.435584 model2 loss : 0.022242
[11:45:12.079] iteration 19242 : model1 loss : 0.439627 model2 loss : 0.021784
[11:45:12.246] iteration 19243 : model1 loss : 0.439674 model2 loss : 0.021972
[11:45:12.416] iteration 19244 : model1 loss : 0.440805 model2 loss : 0.021048
[11:45:12.586] iteration 19245 : model1 loss : 0.438523 model2 loss : 0.022392
[11:45:12.781] iteration 19246 : model1 loss : 0.436331 model2 loss : 0.023942
[11:45:12.945] iteration 19247 : model1 loss : 0.440983 model2 loss : 0.023491
[11:45:13.114] iteration 19248 : model1 loss : 0.441311 model2 loss : 0.024999
[11:45:13.280] iteration 19249 : model1 loss : 0.437422 model2 loss : 0.018883
[11:45:13.448] iteration 19250 : model1 loss : 0.440702 model2 loss : 0.020696
[11:45:13.616] iteration 19251 : model1 loss : 0.441182 model2 loss : 0.021380
[11:45:13.786] iteration 19252 : model1 loss : 0.433186 model2 loss : 0.020526
[11:45:13.955] iteration 19253 : model1 loss : 0.436465 model2 loss : 0.023280
[11:45:14.124] iteration 19254 : model1 loss : 0.436560 model2 loss : 0.023548
[11:45:14.290] iteration 19255 : model1 loss : 0.440535 model2 loss : 0.022052
[11:45:14.459] iteration 19256 : model1 loss : 0.432875 model2 loss : 0.021317
[11:45:14.625] iteration 19257 : model1 loss : 0.438558 model2 loss : 0.021471
[11:45:14.804] iteration 19258 : model1 loss : 0.430888 model2 loss : 0.019898
[11:45:14.972] iteration 19259 : model1 loss : 0.439684 model2 loss : 0.021382
[11:45:15.141] iteration 19260 : model1 loss : 0.438188 model2 loss : 0.021297
[11:45:15.306] iteration 19261 : model1 loss : 0.437335 model2 loss : 0.020153
[11:45:15.474] iteration 19262 : model1 loss : 0.440781 model2 loss : 0.023515
[11:45:15.641] iteration 19263 : model1 loss : 0.442327 model2 loss : 0.023803
[11:45:15.811] iteration 19264 : model1 loss : 0.439781 model2 loss : 0.021125
[11:45:15.978] iteration 19265 : model1 loss : 0.436840 model2 loss : 0.018651
[11:45:16.147] iteration 19266 : model1 loss : 0.438561 model2 loss : 0.020704
[11:45:16.319] iteration 19267 : model1 loss : 0.436917 model2 loss : 0.020312
[11:45:16.487] iteration 19268 : model1 loss : 0.436142 model2 loss : 0.020704
[11:45:16.670] iteration 19269 : model1 loss : 0.439096 model2 loss : 0.023117
[11:45:16.839] iteration 19270 : model1 loss : 0.434415 model2 loss : 0.022057
[11:45:17.005] iteration 19271 : model1 loss : 0.436923 model2 loss : 0.021724
[11:45:17.174] iteration 19272 : model1 loss : 0.436266 model2 loss : 0.019763
[11:45:19.108] iteration 19273 : model1 loss : 0.439524 model2 loss : 0.020436
[11:45:19.275] iteration 19274 : model1 loss : 0.438502 model2 loss : 0.019891
[11:45:19.445] iteration 19275 : model1 loss : 0.437350 model2 loss : 0.021294
[11:45:19.612] iteration 19276 : model1 loss : 0.440219 model2 loss : 0.025142
[11:45:19.782] iteration 19277 : model1 loss : 0.439123 model2 loss : 0.020888
[11:45:19.949] iteration 19278 : model1 loss : 0.439378 model2 loss : 0.021930
[11:45:20.119] iteration 19279 : model1 loss : 0.434591 model2 loss : 0.019581
[11:45:20.287] iteration 19280 : model1 loss : 0.438117 model2 loss : 0.023140
[11:45:20.456] iteration 19281 : model1 loss : 0.434055 model2 loss : 0.020880
[11:45:20.623] iteration 19282 : model1 loss : 0.441759 model2 loss : 0.021979
[11:45:20.794] iteration 19283 : model1 loss : 0.434628 model2 loss : 0.021379
[11:45:20.961] iteration 19284 : model1 loss : 0.442379 model2 loss : 0.022919
[11:45:21.131] iteration 19285 : model1 loss : 0.439834 model2 loss : 0.022574
[11:45:21.297] iteration 19286 : model1 loss : 0.436978 model2 loss : 0.021090
[11:45:21.466] iteration 19287 : model1 loss : 0.437570 model2 loss : 0.022498
[11:45:21.632] iteration 19288 : model1 loss : 0.439150 model2 loss : 0.023900
[11:45:21.804] iteration 19289 : model1 loss : 0.436149 model2 loss : 0.021191
[11:45:21.971] iteration 19290 : model1 loss : 0.435104 model2 loss : 0.020992
[11:45:22.140] iteration 19291 : model1 loss : 0.440607 model2 loss : 0.021560
[11:45:22.308] iteration 19292 : model1 loss : 0.436727 model2 loss : 0.020986
[11:45:22.474] iteration 19293 : model1 loss : 0.439058 model2 loss : 0.023845
[11:45:22.642] iteration 19294 : model1 loss : 0.440179 model2 loss : 0.021395
[11:45:22.810] iteration 19295 : model1 loss : 0.435573 model2 loss : 0.020862
[11:45:22.978] iteration 19296 : model1 loss : 0.439645 model2 loss : 0.022517
[11:45:23.146] iteration 19297 : model1 loss : 0.440414 model2 loss : 0.021700
[11:45:23.313] iteration 19298 : model1 loss : 0.438383 model2 loss : 0.023739
[11:45:23.482] iteration 19299 : model1 loss : 0.438107 model2 loss : 0.021921
[11:45:23.649] iteration 19300 : model1 loss : 0.439702 model2 loss : 0.022318
[11:45:23.817] iteration 19301 : model1 loss : 0.434210 model2 loss : 0.019793
[11:45:23.986] iteration 19302 : model1 loss : 0.437585 model2 loss : 0.019227
[11:45:24.156] iteration 19303 : model1 loss : 0.439905 model2 loss : 0.020706
[11:45:24.321] iteration 19304 : model1 loss : 0.437741 model2 loss : 0.021788
[11:45:24.489] iteration 19305 : model1 loss : 0.437059 model2 loss : 0.021424
[11:45:26.405] iteration 19306 : model1 loss : 0.433072 model2 loss : 0.022493
[11:45:26.576] iteration 19307 : model1 loss : 0.438333 model2 loss : 0.020926
[11:45:26.748] iteration 19308 : model1 loss : 0.443839 model2 loss : 0.021728
[11:45:26.914] iteration 19309 : model1 loss : 0.442800 model2 loss : 0.023536
[11:45:27.082] iteration 19310 : model1 loss : 0.443483 model2 loss : 0.022095
[11:45:27.248] iteration 19311 : model1 loss : 0.439586 model2 loss : 0.026640
[11:45:27.419] iteration 19312 : model1 loss : 0.440356 model2 loss : 0.021878
[11:45:27.589] iteration 19313 : model1 loss : 0.440114 model2 loss : 0.021641
[11:45:27.758] iteration 19314 : model1 loss : 0.438196 model2 loss : 0.020466
[11:45:27.926] iteration 19315 : model1 loss : 0.440150 model2 loss : 0.025685
[11:45:28.095] iteration 19316 : model1 loss : 0.439830 model2 loss : 0.020877
[11:45:28.262] iteration 19317 : model1 loss : 0.433300 model2 loss : 0.019596
[11:45:28.431] iteration 19318 : model1 loss : 0.435226 model2 loss : 0.020951
[11:45:28.604] iteration 19319 : model1 loss : 0.438784 model2 loss : 0.019732
[11:45:28.774] iteration 19320 : model1 loss : 0.439968 model2 loss : 0.022237
[11:45:28.942] iteration 19321 : model1 loss : 0.430598 model2 loss : 0.021131
[11:45:29.109] iteration 19322 : model1 loss : 0.436624 model2 loss : 0.021512
[11:45:29.277] iteration 19323 : model1 loss : 0.440468 model2 loss : 0.021394
[11:45:29.446] iteration 19324 : model1 loss : 0.437981 model2 loss : 0.021510
[11:45:29.613] iteration 19325 : model1 loss : 0.440876 model2 loss : 0.021681
[11:45:29.782] iteration 19326 : model1 loss : 0.440175 model2 loss : 0.023923
[11:45:29.947] iteration 19327 : model1 loss : 0.433635 model2 loss : 0.021680
[11:45:30.117] iteration 19328 : model1 loss : 0.436143 model2 loss : 0.021528
[11:45:30.284] iteration 19329 : model1 loss : 0.435251 model2 loss : 0.022742
[11:45:30.454] iteration 19330 : model1 loss : 0.435198 model2 loss : 0.021911
[11:45:30.621] iteration 19331 : model1 loss : 0.440587 model2 loss : 0.021352
[11:45:30.791] iteration 19332 : model1 loss : 0.438061 model2 loss : 0.018215
[11:45:30.959] iteration 19333 : model1 loss : 0.438788 model2 loss : 0.024640
[11:45:31.129] iteration 19334 : model1 loss : 0.435258 model2 loss : 0.019103
[11:45:31.298] iteration 19335 : model1 loss : 0.438099 model2 loss : 0.021281
[11:45:31.466] iteration 19336 : model1 loss : 0.439309 model2 loss : 0.022527
[11:45:31.632] iteration 19337 : model1 loss : 0.436051 model2 loss : 0.020654
[11:45:31.800] iteration 19338 : model1 loss : 0.440274 model2 loss : 0.023847
[11:45:33.742] iteration 19339 : model1 loss : 0.438654 model2 loss : 0.020000
[11:45:33.912] iteration 19340 : model1 loss : 0.441532 model2 loss : 0.021933
[11:45:34.085] iteration 19341 : model1 loss : 0.437557 model2 loss : 0.022137
[11:45:34.254] iteration 19342 : model1 loss : 0.441631 model2 loss : 0.019945
[11:45:34.422] iteration 19343 : model1 loss : 0.433924 model2 loss : 0.019441
[11:45:34.590] iteration 19344 : model1 loss : 0.434382 model2 loss : 0.019056
[11:45:34.758] iteration 19345 : model1 loss : 0.435819 model2 loss : 0.019956
[11:45:34.926] iteration 19346 : model1 loss : 0.437037 model2 loss : 0.023514
[11:45:35.094] iteration 19347 : model1 loss : 0.438060 model2 loss : 0.021003
[11:45:35.262] iteration 19348 : model1 loss : 0.438198 model2 loss : 0.020541
[11:45:35.431] iteration 19349 : model1 loss : 0.438975 model2 loss : 0.022713
[11:45:35.600] iteration 19350 : model1 loss : 0.440276 model2 loss : 0.023944
[11:45:35.768] iteration 19351 : model1 loss : 0.437033 model2 loss : 0.022133
[11:45:35.938] iteration 19352 : model1 loss : 0.436818 model2 loss : 0.020418
[11:45:36.108] iteration 19353 : model1 loss : 0.436554 model2 loss : 0.019673
[11:45:36.274] iteration 19354 : model1 loss : 0.435948 model2 loss : 0.020971
[11:45:36.445] iteration 19355 : model1 loss : 0.439438 model2 loss : 0.022739
[11:45:36.614] iteration 19356 : model1 loss : 0.436284 model2 loss : 0.022898
[11:45:36.783] iteration 19357 : model1 loss : 0.438392 model2 loss : 0.023348
[11:45:36.949] iteration 19358 : model1 loss : 0.432470 model2 loss : 0.019810
[11:45:37.118] iteration 19359 : model1 loss : 0.442590 model2 loss : 0.024775
[11:45:37.285] iteration 19360 : model1 loss : 0.441324 model2 loss : 0.026542
[11:45:37.454] iteration 19361 : model1 loss : 0.437748 model2 loss : 0.020915
[11:45:37.624] iteration 19362 : model1 loss : 0.437620 model2 loss : 0.022482
[11:45:37.791] iteration 19363 : model1 loss : 0.439693 model2 loss : 0.020785
[11:45:37.958] iteration 19364 : model1 loss : 0.442879 model2 loss : 0.023714
[11:45:38.126] iteration 19365 : model1 loss : 0.437323 model2 loss : 0.021049
[11:45:38.294] iteration 19366 : model1 loss : 0.441799 model2 loss : 0.022725
[11:45:38.463] iteration 19367 : model1 loss : 0.438080 model2 loss : 0.021772
[11:45:38.633] iteration 19368 : model1 loss : 0.436316 model2 loss : 0.020619
[11:45:38.802] iteration 19369 : model1 loss : 0.437160 model2 loss : 0.022592
[11:45:38.966] iteration 19370 : model1 loss : 0.438406 model2 loss : 0.021752
[11:45:39.134] iteration 19371 : model1 loss : 0.436366 model2 loss : 0.022217
[11:45:41.090] iteration 19372 : model1 loss : 0.435244 model2 loss : 0.021074
[11:45:41.256] iteration 19373 : model1 loss : 0.436609 model2 loss : 0.021738
[11:45:41.433] iteration 19374 : model1 loss : 0.442369 model2 loss : 0.021691
[11:45:41.600] iteration 19375 : model1 loss : 0.441733 model2 loss : 0.023798
[11:45:41.767] iteration 19376 : model1 loss : 0.438610 model2 loss : 0.020926
[11:45:41.935] iteration 19377 : model1 loss : 0.432114 model2 loss : 0.021567
[11:45:42.105] iteration 19378 : model1 loss : 0.440072 model2 loss : 0.022583
[11:45:42.273] iteration 19379 : model1 loss : 0.438483 model2 loss : 0.022963
[11:45:42.442] iteration 19380 : model1 loss : 0.437775 model2 loss : 0.023147
[11:45:42.609] iteration 19381 : model1 loss : 0.439754 model2 loss : 0.022130
[11:45:42.779] iteration 19382 : model1 loss : 0.439431 model2 loss : 0.021777
[11:45:42.947] iteration 19383 : model1 loss : 0.435977 model2 loss : 0.020367
[11:45:43.116] iteration 19384 : model1 loss : 0.439383 model2 loss : 0.024319
[11:45:43.285] iteration 19385 : model1 loss : 0.440382 model2 loss : 0.023545
[11:45:43.455] iteration 19386 : model1 loss : 0.435053 model2 loss : 0.020573
[11:45:43.623] iteration 19387 : model1 loss : 0.442459 model2 loss : 0.022676
[11:45:43.793] iteration 19388 : model1 loss : 0.434334 model2 loss : 0.020841
[11:45:43.961] iteration 19389 : model1 loss : 0.438455 model2 loss : 0.021146
[11:45:44.129] iteration 19390 : model1 loss : 0.438854 model2 loss : 0.019442
[11:45:44.297] iteration 19391 : model1 loss : 0.440199 model2 loss : 0.022727
[11:45:44.465] iteration 19392 : model1 loss : 0.438105 model2 loss : 0.019705
[11:45:44.634] iteration 19393 : model1 loss : 0.437668 model2 loss : 0.021101
[11:45:44.804] iteration 19394 : model1 loss : 0.441334 model2 loss : 0.021487
[11:45:44.972] iteration 19395 : model1 loss : 0.437710 model2 loss : 0.021099
[11:45:45.138] iteration 19396 : model1 loss : 0.440974 model2 loss : 0.023958
[11:45:45.304] iteration 19397 : model1 loss : 0.433822 model2 loss : 0.023646
[11:45:45.472] iteration 19398 : model1 loss : 0.442148 model2 loss : 0.021041
[11:45:45.645] iteration 19399 : model1 loss : 0.439410 model2 loss : 0.021880
[11:45:45.815] iteration 19400 : model1 loss : 0.437716 model2 loss : 0.021987
[11:45:45.982] iteration 19401 : model1 loss : 0.435864 model2 loss : 0.020958
[11:45:46.151] iteration 19402 : model1 loss : 0.439299 model2 loss : 0.021059
[11:45:46.317] iteration 19403 : model1 loss : 0.435631 model2 loss : 0.022099
[11:45:46.485] iteration 19404 : model1 loss : 0.434984 model2 loss : 0.020523
[11:45:48.440] iteration 19405 : model1 loss : 0.440782 model2 loss : 0.024595
[11:45:48.611] iteration 19406 : model1 loss : 0.433246 model2 loss : 0.021881
[11:45:48.783] iteration 19407 : model1 loss : 0.442761 model2 loss : 0.022762
[11:45:48.949] iteration 19408 : model1 loss : 0.440347 model2 loss : 0.022563
[11:45:49.121] iteration 19409 : model1 loss : 0.437001 model2 loss : 0.022481
[11:45:49.287] iteration 19410 : model1 loss : 0.437623 model2 loss : 0.021374
[11:45:49.457] iteration 19411 : model1 loss : 0.438954 model2 loss : 0.020523
[11:45:49.624] iteration 19412 : model1 loss : 0.437822 model2 loss : 0.022933
[11:45:49.793] iteration 19413 : model1 loss : 0.435298 model2 loss : 0.022034
[11:45:49.960] iteration 19414 : model1 loss : 0.438434 model2 loss : 0.023658
[11:45:50.128] iteration 19415 : model1 loss : 0.435558 model2 loss : 0.022714
[11:45:50.296] iteration 19416 : model1 loss : 0.439567 model2 loss : 0.022117
[11:45:50.467] iteration 19417 : model1 loss : 0.436217 model2 loss : 0.021102
[11:45:50.636] iteration 19418 : model1 loss : 0.442867 model2 loss : 0.024594
[11:45:50.806] iteration 19419 : model1 loss : 0.435946 model2 loss : 0.021193
[11:45:50.975] iteration 19420 : model1 loss : 0.433589 model2 loss : 0.021441
[11:45:51.145] iteration 19421 : model1 loss : 0.440495 model2 loss : 0.020811
[11:45:51.312] iteration 19422 : model1 loss : 0.435115 model2 loss : 0.022991
[11:45:51.482] iteration 19423 : model1 loss : 0.435483 model2 loss : 0.021793
[11:45:51.653] iteration 19424 : model1 loss : 0.440156 model2 loss : 0.019056
[11:45:51.824] iteration 19425 : model1 loss : 0.440941 model2 loss : 0.022431
[11:45:51.991] iteration 19426 : model1 loss : 0.435224 model2 loss : 0.021386
[11:45:52.159] iteration 19427 : model1 loss : 0.434656 model2 loss : 0.019773
[11:45:52.329] iteration 19428 : model1 loss : 0.445439 model2 loss : 0.023796
[11:45:52.498] iteration 19429 : model1 loss : 0.436391 model2 loss : 0.024226
[11:45:52.669] iteration 19430 : model1 loss : 0.441410 model2 loss : 0.021897
[11:45:52.839] iteration 19431 : model1 loss : 0.438153 model2 loss : 0.020070
[11:45:53.006] iteration 19432 : model1 loss : 0.440769 model2 loss : 0.020081
[11:45:53.175] iteration 19433 : model1 loss : 0.442148 model2 loss : 0.026390
[11:45:53.346] iteration 19434 : model1 loss : 0.439359 model2 loss : 0.022793
[11:45:53.520] iteration 19435 : model1 loss : 0.437489 model2 loss : 0.025939
[11:45:53.687] iteration 19436 : model1 loss : 0.442115 model2 loss : 0.021800
[11:45:53.857] iteration 19437 : model1 loss : 0.434120 model2 loss : 0.019971
[11:45:55.765] iteration 19438 : model1 loss : 0.438422 model2 loss : 0.023555
[11:45:55.938] iteration 19439 : model1 loss : 0.436788 model2 loss : 0.020121
[11:45:56.109] iteration 19440 : model1 loss : 0.436924 model2 loss : 0.021666
[11:45:56.277] iteration 19441 : model1 loss : 0.435202 model2 loss : 0.021065
[11:45:56.447] iteration 19442 : model1 loss : 0.435142 model2 loss : 0.020569
[11:45:56.614] iteration 19443 : model1 loss : 0.435392 model2 loss : 0.020063
[11:45:56.786] iteration 19444 : model1 loss : 0.439177 model2 loss : 0.020231
[11:45:56.952] iteration 19445 : model1 loss : 0.439393 model2 loss : 0.024151
[11:45:57.121] iteration 19446 : model1 loss : 0.436967 model2 loss : 0.019365
[11:45:57.288] iteration 19447 : model1 loss : 0.437520 model2 loss : 0.022929
[11:45:57.457] iteration 19448 : model1 loss : 0.441078 model2 loss : 0.023817
[11:45:57.625] iteration 19449 : model1 loss : 0.437097 model2 loss : 0.023477
[11:45:57.795] iteration 19450 : model1 loss : 0.438763 model2 loss : 0.024713
[11:45:57.964] iteration 19451 : model1 loss : 0.435680 model2 loss : 0.020809
[11:45:58.133] iteration 19452 : model1 loss : 0.433934 model2 loss : 0.021280
[11:45:58.301] iteration 19453 : model1 loss : 0.439473 model2 loss : 0.021766
[11:45:58.470] iteration 19454 : model1 loss : 0.440312 model2 loss : 0.022314
[11:45:58.636] iteration 19455 : model1 loss : 0.433071 model2 loss : 0.022224
[11:45:58.805] iteration 19456 : model1 loss : 0.440297 model2 loss : 0.021184
[11:45:58.971] iteration 19457 : model1 loss : 0.434636 model2 loss : 0.019518
[11:45:59.142] iteration 19458 : model1 loss : 0.437059 model2 loss : 0.021393
[11:45:59.309] iteration 19459 : model1 loss : 0.437091 model2 loss : 0.020716
[11:45:59.480] iteration 19460 : model1 loss : 0.442517 model2 loss : 0.029541
[11:45:59.647] iteration 19461 : model1 loss : 0.439739 model2 loss : 0.024371
[11:45:59.818] iteration 19462 : model1 loss : 0.439797 model2 loss : 0.020356
[11:45:59.987] iteration 19463 : model1 loss : 0.441273 model2 loss : 0.022863
[11:46:00.157] iteration 19464 : model1 loss : 0.439635 model2 loss : 0.030445
[11:46:00.326] iteration 19465 : model1 loss : 0.439686 model2 loss : 0.025150
[11:46:00.497] iteration 19466 : model1 loss : 0.439006 model2 loss : 0.020121
[11:46:00.667] iteration 19467 : model1 loss : 0.439134 model2 loss : 0.021007
[11:46:00.837] iteration 19468 : model1 loss : 0.438915 model2 loss : 0.021874
[11:46:01.002] iteration 19469 : model1 loss : 0.442352 model2 loss : 0.025847
[11:46:01.171] iteration 19470 : model1 loss : 0.440446 model2 loss : 0.022995
[11:46:03.086] iteration 19471 : model1 loss : 0.433314 model2 loss : 0.021189
[11:46:03.258] iteration 19472 : model1 loss : 0.439864 model2 loss : 0.023120
[11:46:03.429] iteration 19473 : model1 loss : 0.435308 model2 loss : 0.019619
[11:46:03.597] iteration 19474 : model1 loss : 0.438580 model2 loss : 0.023072
[11:46:03.766] iteration 19475 : model1 loss : 0.435021 model2 loss : 0.020864
[11:46:03.938] iteration 19476 : model1 loss : 0.436194 model2 loss : 0.023537
[11:46:04.105] iteration 19477 : model1 loss : 0.440313 model2 loss : 0.024115
[11:46:04.273] iteration 19478 : model1 loss : 0.437723 model2 loss : 0.023327
[11:46:04.442] iteration 19479 : model1 loss : 0.443655 model2 loss : 0.022296
[11:46:04.609] iteration 19480 : model1 loss : 0.439182 model2 loss : 0.023787
[11:46:04.779] iteration 19481 : model1 loss : 0.441241 model2 loss : 0.021892
[11:46:04.947] iteration 19482 : model1 loss : 0.436043 model2 loss : 0.021442
[11:46:05.116] iteration 19483 : model1 loss : 0.436525 model2 loss : 0.023989
[11:46:05.284] iteration 19484 : model1 loss : 0.440263 model2 loss : 0.023841
[11:46:05.452] iteration 19485 : model1 loss : 0.437178 model2 loss : 0.022800
[11:46:05.622] iteration 19486 : model1 loss : 0.437869 model2 loss : 0.019833
[11:46:05.790] iteration 19487 : model1 loss : 0.437791 model2 loss : 0.021265
[11:46:05.957] iteration 19488 : model1 loss : 0.442122 model2 loss : 0.026433
[11:46:06.127] iteration 19489 : model1 loss : 0.436449 model2 loss : 0.021687
[11:46:06.296] iteration 19490 : model1 loss : 0.443215 model2 loss : 0.026202
[11:46:06.465] iteration 19491 : model1 loss : 0.442165 model2 loss : 0.025223
[11:46:06.634] iteration 19492 : model1 loss : 0.433047 model2 loss : 0.021380
[11:46:06.801] iteration 19493 : model1 loss : 0.441426 model2 loss : 0.024294
[11:46:06.971] iteration 19494 : model1 loss : 0.439362 model2 loss : 0.022105
[11:46:07.141] iteration 19495 : model1 loss : 0.431460 model2 loss : 0.021357
[11:46:07.309] iteration 19496 : model1 loss : 0.438758 model2 loss : 0.023564
[11:46:07.478] iteration 19497 : model1 loss : 0.435828 model2 loss : 0.022155
[11:46:07.645] iteration 19498 : model1 loss : 0.441664 model2 loss : 0.024274
[11:46:07.813] iteration 19499 : model1 loss : 0.441862 model2 loss : 0.020951
[11:46:07.980] iteration 19500 : model1 loss : 0.438243 model2 loss : 0.019771
[11:46:08.150] iteration 19501 : model1 loss : 0.436854 model2 loss : 0.020927
[11:46:08.316] iteration 19502 : model1 loss : 0.438874 model2 loss : 0.023594
[11:46:08.483] iteration 19503 : model1 loss : 0.438532 model2 loss : 0.021019
[11:46:10.427] iteration 19504 : model1 loss : 0.436127 model2 loss : 0.019691
[11:46:10.595] iteration 19505 : model1 loss : 0.439796 model2 loss : 0.019553
[11:46:10.767] iteration 19506 : model1 loss : 0.437201 model2 loss : 0.020084
[11:46:10.939] iteration 19507 : model1 loss : 0.442259 model2 loss : 0.020940
[11:46:11.109] iteration 19508 : model1 loss : 0.436021 model2 loss : 0.019702
[11:46:11.278] iteration 19509 : model1 loss : 0.442605 model2 loss : 0.021656
[11:46:11.447] iteration 19510 : model1 loss : 0.434340 model2 loss : 0.021549
[11:46:11.613] iteration 19511 : model1 loss : 0.437892 model2 loss : 0.022718
[11:46:11.781] iteration 19512 : model1 loss : 0.440886 model2 loss : 0.020918
[11:46:11.950] iteration 19513 : model1 loss : 0.439890 model2 loss : 0.025687
[11:46:12.119] iteration 19514 : model1 loss : 0.440320 model2 loss : 0.020333
[11:46:12.288] iteration 19515 : model1 loss : 0.436709 model2 loss : 0.020516
[11:46:12.457] iteration 19516 : model1 loss : 0.438065 model2 loss : 0.019242
[11:46:12.623] iteration 19517 : model1 loss : 0.434414 model2 loss : 0.021123
[11:46:12.792] iteration 19518 : model1 loss : 0.436967 model2 loss : 0.021427
[11:46:12.960] iteration 19519 : model1 loss : 0.443764 model2 loss : 0.025243
[11:46:13.130] iteration 19520 : model1 loss : 0.435294 model2 loss : 0.022444
[11:46:13.299] iteration 19521 : model1 loss : 0.436036 model2 loss : 0.019817
[11:46:13.469] iteration 19522 : model1 loss : 0.439958 model2 loss : 0.023137
[11:46:13.637] iteration 19523 : model1 loss : 0.435104 model2 loss : 0.022061
[11:46:13.805] iteration 19524 : model1 loss : 0.439812 model2 loss : 0.025568
[11:46:13.971] iteration 19525 : model1 loss : 0.437955 model2 loss : 0.021388
[11:46:14.142] iteration 19526 : model1 loss : 0.440234 model2 loss : 0.023280
[11:46:14.309] iteration 19527 : model1 loss : 0.435785 model2 loss : 0.020101
[11:46:14.480] iteration 19528 : model1 loss : 0.438114 model2 loss : 0.023196
[11:46:14.648] iteration 19529 : model1 loss : 0.440876 model2 loss : 0.023999
[11:46:14.816] iteration 19530 : model1 loss : 0.436677 model2 loss : 0.022771
[11:46:14.982] iteration 19531 : model1 loss : 0.438154 model2 loss : 0.020583
[11:46:15.152] iteration 19532 : model1 loss : 0.437258 model2 loss : 0.021332
[11:46:15.317] iteration 19533 : model1 loss : 0.442889 model2 loss : 0.025364
[11:46:15.487] iteration 19534 : model1 loss : 0.439073 model2 loss : 0.020316
[11:46:15.654] iteration 19535 : model1 loss : 0.435569 model2 loss : 0.018878
[11:46:15.823] iteration 19536 : model1 loss : 0.440281 model2 loss : 0.023618
[11:46:17.740] iteration 19537 : model1 loss : 0.439192 model2 loss : 0.023014
[11:46:17.912] iteration 19538 : model1 loss : 0.438198 model2 loss : 0.022506
[11:46:18.083] iteration 19539 : model1 loss : 0.436502 model2 loss : 0.022437
[11:46:18.251] iteration 19540 : model1 loss : 0.436561 model2 loss : 0.022574
[11:46:18.421] iteration 19541 : model1 loss : 0.438762 model2 loss : 0.018778
[11:46:18.589] iteration 19542 : model1 loss : 0.437163 model2 loss : 0.021241
[11:46:18.760] iteration 19543 : model1 loss : 0.436274 model2 loss : 0.020544
[11:46:18.928] iteration 19544 : model1 loss : 0.436845 model2 loss : 0.022747
[11:46:19.099] iteration 19545 : model1 loss : 0.439463 model2 loss : 0.021895
[11:46:19.264] iteration 19546 : model1 loss : 0.436110 model2 loss : 0.020278
[11:46:19.434] iteration 19547 : model1 loss : 0.436908 model2 loss : 0.020428
[11:46:19.603] iteration 19548 : model1 loss : 0.438498 model2 loss : 0.019601
[11:46:19.776] iteration 19549 : model1 loss : 0.438552 model2 loss : 0.022229
[11:46:19.944] iteration 19550 : model1 loss : 0.440313 model2 loss : 0.023087
[11:46:20.114] iteration 19551 : model1 loss : 0.432646 model2 loss : 0.020532
[11:46:20.280] iteration 19552 : model1 loss : 0.438533 model2 loss : 0.021357
[11:46:20.450] iteration 19553 : model1 loss : 0.438662 model2 loss : 0.021377
[11:46:20.619] iteration 19554 : model1 loss : 0.443430 model2 loss : 0.024347
[11:46:20.788] iteration 19555 : model1 loss : 0.436761 model2 loss : 0.021064
[11:46:20.956] iteration 19556 : model1 loss : 0.437430 model2 loss : 0.020901
[11:46:21.126] iteration 19557 : model1 loss : 0.442841 model2 loss : 0.021061
[11:46:21.296] iteration 19558 : model1 loss : 0.442041 model2 loss : 0.020412
[11:46:21.464] iteration 19559 : model1 loss : 0.442055 model2 loss : 0.024604
[11:46:21.631] iteration 19560 : model1 loss : 0.440663 model2 loss : 0.022870
[11:46:21.801] iteration 19561 : model1 loss : 0.440756 model2 loss : 0.020713
[11:46:21.970] iteration 19562 : model1 loss : 0.439072 model2 loss : 0.022030
[11:46:22.139] iteration 19563 : model1 loss : 0.436787 model2 loss : 0.023757
[11:46:22.308] iteration 19564 : model1 loss : 0.436906 model2 loss : 0.020413
[11:46:22.477] iteration 19565 : model1 loss : 0.438677 model2 loss : 0.020046
[11:46:22.645] iteration 19566 : model1 loss : 0.435506 model2 loss : 0.021084
[11:46:22.813] iteration 19567 : model1 loss : 0.437237 model2 loss : 0.021501
[11:46:22.980] iteration 19568 : model1 loss : 0.434362 model2 loss : 0.021300
[11:46:23.147] iteration 19569 : model1 loss : 0.438455 model2 loss : 0.021323
[11:46:25.055] iteration 19570 : model1 loss : 0.438340 model2 loss : 0.019677
[11:46:25.222] iteration 19571 : model1 loss : 0.439533 model2 loss : 0.021793
[11:46:25.395] iteration 19572 : model1 loss : 0.441165 model2 loss : 0.023301
[11:46:25.564] iteration 19573 : model1 loss : 0.439387 model2 loss : 0.019288
[11:46:25.736] iteration 19574 : model1 loss : 0.436353 model2 loss : 0.018824
[11:46:25.907] iteration 19575 : model1 loss : 0.435695 model2 loss : 0.021297
[11:46:26.077] iteration 19576 : model1 loss : 0.434979 model2 loss : 0.019441
[11:46:26.244] iteration 19577 : model1 loss : 0.439250 model2 loss : 0.023972
[11:46:26.413] iteration 19578 : model1 loss : 0.435673 model2 loss : 0.021688
[11:46:26.580] iteration 19579 : model1 loss : 0.439012 model2 loss : 0.025664
[11:46:26.751] iteration 19580 : model1 loss : 0.434561 model2 loss : 0.023376
[11:46:26.921] iteration 19581 : model1 loss : 0.434841 model2 loss : 0.020787
[11:46:27.091] iteration 19582 : model1 loss : 0.436523 model2 loss : 0.019513
[11:46:27.259] iteration 19583 : model1 loss : 0.439429 model2 loss : 0.022422
[11:46:27.429] iteration 19584 : model1 loss : 0.435257 model2 loss : 0.023249
[11:46:27.597] iteration 19585 : model1 loss : 0.440273 model2 loss : 0.024060
[11:46:27.766] iteration 19586 : model1 loss : 0.438841 model2 loss : 0.021298
[11:46:27.935] iteration 19587 : model1 loss : 0.440332 model2 loss : 0.022157
[11:46:28.104] iteration 19588 : model1 loss : 0.437144 model2 loss : 0.019682
[11:46:28.272] iteration 19589 : model1 loss : 0.439906 model2 loss : 0.023609
[11:46:28.442] iteration 19590 : model1 loss : 0.435298 model2 loss : 0.020724
[11:46:28.609] iteration 19591 : model1 loss : 0.438714 model2 loss : 0.019761
[11:46:28.779] iteration 19592 : model1 loss : 0.443316 model2 loss : 0.021968
[11:46:28.947] iteration 19593 : model1 loss : 0.437522 model2 loss : 0.019760
[11:46:29.118] iteration 19594 : model1 loss : 0.440393 model2 loss : 0.022511
[11:46:29.287] iteration 19595 : model1 loss : 0.441466 model2 loss : 0.024265
[11:46:29.456] iteration 19596 : model1 loss : 0.437224 model2 loss : 0.023451
[11:46:29.624] iteration 19597 : model1 loss : 0.439437 model2 loss : 0.022052
[11:46:29.794] iteration 19598 : model1 loss : 0.436028 model2 loss : 0.021236
[11:46:29.964] iteration 19599 : model1 loss : 0.440991 model2 loss : 0.024802
[11:46:30.134] iteration 19600 : model1 loss : 0.438608 model2 loss : 0.021082
[11:46:30.300] iteration 19601 : model1 loss : 0.437488 model2 loss : 0.020875
[11:46:30.466] iteration 19602 : model1 loss : 0.439136 model2 loss : 0.021841
[11:46:32.382] iteration 19603 : model1 loss : 0.436441 model2 loss : 0.022740
[11:46:32.551] iteration 19604 : model1 loss : 0.446386 model2 loss : 0.023110
[11:46:32.725] iteration 19605 : model1 loss : 0.438982 model2 loss : 0.021853
[11:46:32.893] iteration 19606 : model1 loss : 0.436733 model2 loss : 0.021754
[11:46:33.064] iteration 19607 : model1 loss : 0.436452 model2 loss : 0.021331
[11:46:33.231] iteration 19608 : model1 loss : 0.430625 model2 loss : 0.020015
[11:46:33.397] iteration 19609 : model1 loss : 0.438927 model2 loss : 0.023956
[11:46:33.578] iteration 19610 : model1 loss : 0.434729 model2 loss : 0.019187
[11:46:33.748] iteration 19611 : model1 loss : 0.435748 model2 loss : 0.019780
[11:46:33.916] iteration 19612 : model1 loss : 0.442440 model2 loss : 0.021948
[11:46:34.086] iteration 19613 : model1 loss : 0.441389 model2 loss : 0.020924
[11:46:34.254] iteration 19614 : model1 loss : 0.435755 model2 loss : 0.019784
[11:46:34.422] iteration 19615 : model1 loss : 0.433354 model2 loss : 0.019685
[11:46:34.588] iteration 19616 : model1 loss : 0.440828 model2 loss : 0.024100
[11:46:34.759] iteration 19617 : model1 loss : 0.437648 model2 loss : 0.020497
[11:46:34.926] iteration 19618 : model1 loss : 0.439226 model2 loss : 0.020662
[11:46:35.095] iteration 19619 : model1 loss : 0.437102 model2 loss : 0.021726
[11:46:35.263] iteration 19620 : model1 loss : 0.434782 model2 loss : 0.021646
[11:46:35.435] iteration 19621 : model1 loss : 0.438656 model2 loss : 0.024624
[11:46:35.603] iteration 19622 : model1 loss : 0.436291 model2 loss : 0.021848
[11:46:35.774] iteration 19623 : model1 loss : 0.438210 model2 loss : 0.021339
[11:46:35.945] iteration 19624 : model1 loss : 0.441223 model2 loss : 0.023607
[11:46:36.114] iteration 19625 : model1 loss : 0.441644 model2 loss : 0.024261
[11:46:36.282] iteration 19626 : model1 loss : 0.436219 model2 loss : 0.019536
[11:46:36.454] iteration 19627 : model1 loss : 0.438969 model2 loss : 0.020316
[11:46:36.623] iteration 19628 : model1 loss : 0.439328 model2 loss : 0.022837
[11:46:36.794] iteration 19629 : model1 loss : 0.437726 model2 loss : 0.021520
[11:46:36.962] iteration 19630 : model1 loss : 0.441196 model2 loss : 0.020547
[11:46:37.131] iteration 19631 : model1 loss : 0.439692 model2 loss : 0.020080
[11:46:37.298] iteration 19632 : model1 loss : 0.435418 model2 loss : 0.020523
[11:46:37.468] iteration 19633 : model1 loss : 0.439793 model2 loss : 0.022053
[11:46:37.634] iteration 19634 : model1 loss : 0.442068 model2 loss : 0.024894
[11:46:37.801] iteration 19635 : model1 loss : 0.437304 model2 loss : 0.021730
[11:46:39.704] iteration 19636 : model1 loss : 0.439205 model2 loss : 0.024084
[11:46:39.872] iteration 19637 : model1 loss : 0.437481 model2 loss : 0.020161
[11:46:40.043] iteration 19638 : model1 loss : 0.442955 model2 loss : 0.023071
[11:46:40.212] iteration 19639 : model1 loss : 0.439097 model2 loss : 0.019971
[11:46:40.380] iteration 19640 : model1 loss : 0.436120 model2 loss : 0.023415
[11:46:40.547] iteration 19641 : model1 loss : 0.436772 model2 loss : 0.021393
[11:46:40.718] iteration 19642 : model1 loss : 0.437948 model2 loss : 0.022540
[11:46:40.886] iteration 19643 : model1 loss : 0.440959 model2 loss : 0.021640
[11:46:41.057] iteration 19644 : model1 loss : 0.437511 model2 loss : 0.019833
[11:46:41.226] iteration 19645 : model1 loss : 0.444818 model2 loss : 0.025503
[11:46:41.395] iteration 19646 : model1 loss : 0.439266 model2 loss : 0.022159
[11:46:41.565] iteration 19647 : model1 loss : 0.441275 model2 loss : 0.020552
[11:46:41.737] iteration 19648 : model1 loss : 0.435519 model2 loss : 0.021052
[11:46:41.910] iteration 19649 : model1 loss : 0.436612 model2 loss : 0.020866
[11:46:42.078] iteration 19650 : model1 loss : 0.435007 model2 loss : 0.019161
[11:46:42.248] iteration 19651 : model1 loss : 0.438468 model2 loss : 0.021896
[11:46:42.417] iteration 19652 : model1 loss : 0.440595 model2 loss : 0.025028
[11:46:42.586] iteration 19653 : model1 loss : 0.438393 model2 loss : 0.021147
[11:46:42.761] iteration 19654 : model1 loss : 0.434897 model2 loss : 0.019761
[11:46:42.928] iteration 19655 : model1 loss : 0.437445 model2 loss : 0.023034
[11:46:43.097] iteration 19656 : model1 loss : 0.441567 model2 loss : 0.021229
[11:46:43.266] iteration 19657 : model1 loss : 0.435439 model2 loss : 0.020804
[11:46:43.437] iteration 19658 : model1 loss : 0.440151 model2 loss : 0.020752
[11:46:43.605] iteration 19659 : model1 loss : 0.434169 model2 loss : 0.022839
[11:46:43.780] iteration 19660 : model1 loss : 0.437976 model2 loss : 0.020550
[11:46:43.945] iteration 19661 : model1 loss : 0.439479 model2 loss : 0.022555
[11:46:44.114] iteration 19662 : model1 loss : 0.434774 model2 loss : 0.020699
[11:46:44.281] iteration 19663 : model1 loss : 0.439450 model2 loss : 0.022978
[11:46:44.451] iteration 19664 : model1 loss : 0.438909 model2 loss : 0.023079
[11:46:44.619] iteration 19665 : model1 loss : 0.435867 model2 loss : 0.022701
[11:46:44.788] iteration 19666 : model1 loss : 0.441772 model2 loss : 0.023028
[11:46:44.956] iteration 19667 : model1 loss : 0.438189 model2 loss : 0.022357
[11:46:45.125] iteration 19668 : model1 loss : 0.435120 model2 loss : 0.020504
[11:46:47.068] iteration 19669 : model1 loss : 0.440785 model2 loss : 0.023283
[11:46:47.233] iteration 19670 : model1 loss : 0.437067 model2 loss : 0.021817
[11:46:47.406] iteration 19671 : model1 loss : 0.437066 model2 loss : 0.023595
[11:46:47.573] iteration 19672 : model1 loss : 0.437235 model2 loss : 0.019881
[11:46:47.741] iteration 19673 : model1 loss : 0.436288 model2 loss : 0.019650
[11:46:47.908] iteration 19674 : model1 loss : 0.441679 model2 loss : 0.022922
[11:46:48.077] iteration 19675 : model1 loss : 0.438776 model2 loss : 0.021742
[11:46:48.244] iteration 19676 : model1 loss : 0.433410 model2 loss : 0.020522
[11:46:48.412] iteration 19677 : model1 loss : 0.435471 model2 loss : 0.021925
[11:46:48.580] iteration 19678 : model1 loss : 0.439223 model2 loss : 0.023235
[11:46:48.750] iteration 19679 : model1 loss : 0.436099 model2 loss : 0.020368
[11:46:48.916] iteration 19680 : model1 loss : 0.438040 model2 loss : 0.020461
[11:46:49.085] iteration 19681 : model1 loss : 0.436190 model2 loss : 0.020964
[11:46:49.253] iteration 19682 : model1 loss : 0.438740 model2 loss : 0.023569
[11:46:49.422] iteration 19683 : model1 loss : 0.443328 model2 loss : 0.021890
[11:46:49.589] iteration 19684 : model1 loss : 0.438308 model2 loss : 0.021326
[11:46:49.762] iteration 19685 : model1 loss : 0.438072 model2 loss : 0.021687
[11:46:49.930] iteration 19686 : model1 loss : 0.437171 model2 loss : 0.022071
[11:46:50.098] iteration 19687 : model1 loss : 0.430232 model2 loss : 0.021988
[11:46:50.264] iteration 19688 : model1 loss : 0.440572 model2 loss : 0.022131
[11:46:50.433] iteration 19689 : model1 loss : 0.437616 model2 loss : 0.021002
[11:46:50.599] iteration 19690 : model1 loss : 0.442131 model2 loss : 0.020183
[11:46:50.771] iteration 19691 : model1 loss : 0.437587 model2 loss : 0.021578
[11:46:50.942] iteration 19692 : model1 loss : 0.439094 model2 loss : 0.020575
[11:46:51.112] iteration 19693 : model1 loss : 0.436856 model2 loss : 0.022999
[11:46:51.282] iteration 19694 : model1 loss : 0.436023 model2 loss : 0.023107
[11:46:51.450] iteration 19695 : model1 loss : 0.439641 model2 loss : 0.020982
[11:46:51.616] iteration 19696 : model1 loss : 0.443273 model2 loss : 0.023549
[11:46:51.789] iteration 19697 : model1 loss : 0.441301 model2 loss : 0.021909
[11:46:51.956] iteration 19698 : model1 loss : 0.442316 model2 loss : 0.026924
[11:46:52.124] iteration 19699 : model1 loss : 0.440569 model2 loss : 0.023259
[11:46:52.288] iteration 19700 : model1 loss : 0.444138 model2 loss : 0.024282
[11:46:52.456] iteration 19701 : model1 loss : 0.430627 model2 loss : 0.019656
[11:46:54.404] iteration 19702 : model1 loss : 0.437510 model2 loss : 0.019017
[11:46:54.574] iteration 19703 : model1 loss : 0.437500 model2 loss : 0.020042
[11:46:54.746] iteration 19704 : model1 loss : 0.437069 model2 loss : 0.022117
[11:46:54.912] iteration 19705 : model1 loss : 0.435029 model2 loss : 0.019479
[11:46:55.080] iteration 19706 : model1 loss : 0.436811 model2 loss : 0.020540
[11:46:55.246] iteration 19707 : model1 loss : 0.443475 model2 loss : 0.023588
[11:46:55.414] iteration 19708 : model1 loss : 0.439579 model2 loss : 0.023088
[11:46:55.583] iteration 19709 : model1 loss : 0.436312 model2 loss : 0.022215
[11:46:55.751] iteration 19710 : model1 loss : 0.432817 model2 loss : 0.020178
[11:46:55.921] iteration 19711 : model1 loss : 0.438627 model2 loss : 0.020675
[11:46:56.089] iteration 19712 : model1 loss : 0.438208 model2 loss : 0.020633
[11:46:56.257] iteration 19713 : model1 loss : 0.442018 model2 loss : 0.021806
[11:46:56.425] iteration 19714 : model1 loss : 0.436296 model2 loss : 0.021287
[11:46:56.592] iteration 19715 : model1 loss : 0.433690 model2 loss : 0.020530
[11:46:56.763] iteration 19716 : model1 loss : 0.438620 model2 loss : 0.022492
[11:46:56.933] iteration 19717 : model1 loss : 0.440237 model2 loss : 0.023262
[11:46:57.102] iteration 19718 : model1 loss : 0.437174 model2 loss : 0.019976
[11:46:57.270] iteration 19719 : model1 loss : 0.438372 model2 loss : 0.021213
[11:46:57.438] iteration 19720 : model1 loss : 0.440384 model2 loss : 0.022018
[11:46:57.607] iteration 19721 : model1 loss : 0.438385 model2 loss : 0.023443
[11:46:57.779] iteration 19722 : model1 loss : 0.433819 model2 loss : 0.019048
[11:46:57.947] iteration 19723 : model1 loss : 0.437766 model2 loss : 0.020730
[11:46:58.116] iteration 19724 : model1 loss : 0.440858 model2 loss : 0.022952
[11:46:58.283] iteration 19725 : model1 loss : 0.441760 model2 loss : 0.024903
[11:46:58.453] iteration 19726 : model1 loss : 0.437214 model2 loss : 0.023282
[11:46:58.618] iteration 19727 : model1 loss : 0.436064 model2 loss : 0.021496
[11:46:58.791] iteration 19728 : model1 loss : 0.442840 model2 loss : 0.024247
[11:46:58.959] iteration 19729 : model1 loss : 0.440964 model2 loss : 0.025361
[11:46:59.129] iteration 19730 : model1 loss : 0.438169 model2 loss : 0.022882
[11:46:59.297] iteration 19731 : model1 loss : 0.440923 model2 loss : 0.019685
[11:46:59.466] iteration 19732 : model1 loss : 0.441349 model2 loss : 0.023379
[11:46:59.631] iteration 19733 : model1 loss : 0.438831 model2 loss : 0.022936
[11:46:59.802] iteration 19734 : model1 loss : 0.435291 model2 loss : 0.021574
[11:47:01.799] iteration 19735 : model1 loss : 0.433536 model2 loss : 0.020684
[11:47:01.969] iteration 19736 : model1 loss : 0.438003 model2 loss : 0.020983
[11:47:02.142] iteration 19737 : model1 loss : 0.439466 model2 loss : 0.020346
[11:47:02.309] iteration 19738 : model1 loss : 0.437615 model2 loss : 0.021044
[11:47:02.479] iteration 19739 : model1 loss : 0.440495 model2 loss : 0.022458
[11:47:02.647] iteration 19740 : model1 loss : 0.439616 model2 loss : 0.022031
[11:47:02.820] iteration 19741 : model1 loss : 0.439507 model2 loss : 0.023464
[11:47:02.988] iteration 19742 : model1 loss : 0.437852 model2 loss : 0.024523
[11:47:03.159] iteration 19743 : model1 loss : 0.434742 model2 loss : 0.019969
[11:47:03.328] iteration 19744 : model1 loss : 0.437317 model2 loss : 0.022874
[11:47:03.500] iteration 19745 : model1 loss : 0.435840 model2 loss : 0.020315
[11:47:03.668] iteration 19746 : model1 loss : 0.445082 model2 loss : 0.026307
[11:47:03.838] iteration 19747 : model1 loss : 0.436876 model2 loss : 0.020718
[11:47:04.007] iteration 19748 : model1 loss : 0.440287 model2 loss : 0.023042
[11:47:04.177] iteration 19749 : model1 loss : 0.438080 model2 loss : 0.023241
[11:47:04.344] iteration 19750 : model1 loss : 0.434777 model2 loss : 0.020435
[11:47:04.516] iteration 19751 : model1 loss : 0.435735 model2 loss : 0.021251
[11:47:04.685] iteration 19752 : model1 loss : 0.435276 model2 loss : 0.022333
[11:47:04.854] iteration 19753 : model1 loss : 0.444162 model2 loss : 0.022242
[11:47:05.022] iteration 19754 : model1 loss : 0.440858 model2 loss : 0.026117
[11:47:05.195] iteration 19755 : model1 loss : 0.436095 model2 loss : 0.020835
[11:47:05.362] iteration 19756 : model1 loss : 0.436635 model2 loss : 0.020300
[11:47:05.536] iteration 19757 : model1 loss : 0.438429 model2 loss : 0.022507
[11:47:05.705] iteration 19758 : model1 loss : 0.434183 model2 loss : 0.021356
[11:47:05.874] iteration 19759 : model1 loss : 0.438552 model2 loss : 0.023315
[11:47:06.041] iteration 19760 : model1 loss : 0.438428 model2 loss : 0.019659
[11:47:06.211] iteration 19761 : model1 loss : 0.437732 model2 loss : 0.021899
[11:47:06.377] iteration 19762 : model1 loss : 0.437692 model2 loss : 0.019838
[11:47:06.547] iteration 19763 : model1 loss : 0.440730 model2 loss : 0.023527
[11:47:06.716] iteration 19764 : model1 loss : 0.442779 model2 loss : 0.022855
[11:47:06.883] iteration 19765 : model1 loss : 0.436572 model2 loss : 0.019568
[11:47:07.050] iteration 19766 : model1 loss : 0.435602 model2 loss : 0.023119
[11:47:07.217] iteration 19767 : model1 loss : 0.441442 model2 loss : 0.021528
[11:47:09.174] iteration 19768 : model1 loss : 0.439859 model2 loss : 0.023028
[11:47:09.344] iteration 19769 : model1 loss : 0.439212 model2 loss : 0.022885
[11:47:09.517] iteration 19770 : model1 loss : 0.438051 model2 loss : 0.021069
[11:47:09.684] iteration 19771 : model1 loss : 0.435684 model2 loss : 0.021623
[11:47:09.855] iteration 19772 : model1 loss : 0.440635 model2 loss : 0.024519
[11:47:10.025] iteration 19773 : model1 loss : 0.440187 model2 loss : 0.029183
[11:47:10.195] iteration 19774 : model1 loss : 0.434225 model2 loss : 0.021241
[11:47:10.362] iteration 19775 : model1 loss : 0.437258 model2 loss : 0.021204
[11:47:10.533] iteration 19776 : model1 loss : 0.434284 model2 loss : 0.018983
[11:47:10.700] iteration 19777 : model1 loss : 0.440934 model2 loss : 0.019527
[11:47:10.872] iteration 19778 : model1 loss : 0.441366 model2 loss : 0.020577
[11:47:11.038] iteration 19779 : model1 loss : 0.438969 model2 loss : 0.021082
[11:47:11.209] iteration 19780 : model1 loss : 0.438258 model2 loss : 0.020889
[11:47:11.377] iteration 19781 : model1 loss : 0.438408 model2 loss : 0.021124
[11:47:11.548] iteration 19782 : model1 loss : 0.437597 model2 loss : 0.019816
[11:47:11.714] iteration 19783 : model1 loss : 0.439744 model2 loss : 0.021825
[11:47:11.884] iteration 19784 : model1 loss : 0.438361 model2 loss : 0.020712
[11:47:12.053] iteration 19785 : model1 loss : 0.438254 model2 loss : 0.021547
[11:47:12.222] iteration 19786 : model1 loss : 0.435516 model2 loss : 0.022378
[11:47:12.390] iteration 19787 : model1 loss : 0.435418 model2 loss : 0.020995
[11:47:12.560] iteration 19788 : model1 loss : 0.436318 model2 loss : 0.023531
[11:47:12.742] iteration 19789 : model1 loss : 0.440903 model2 loss : 0.022600
[11:47:12.913] iteration 19790 : model1 loss : 0.439972 model2 loss : 0.025156
[11:47:13.081] iteration 19791 : model1 loss : 0.444132 model2 loss : 0.023657
[11:47:13.250] iteration 19792 : model1 loss : 0.439696 model2 loss : 0.020697
[11:47:13.417] iteration 19793 : model1 loss : 0.440790 model2 loss : 0.023792
[11:47:13.587] iteration 19794 : model1 loss : 0.439891 model2 loss : 0.022019
[11:47:13.755] iteration 19795 : model1 loss : 0.437988 model2 loss : 0.022169
[11:47:13.924] iteration 19796 : model1 loss : 0.433872 model2 loss : 0.021146
[11:47:14.093] iteration 19797 : model1 loss : 0.435562 model2 loss : 0.022368
[11:47:14.262] iteration 19798 : model1 loss : 0.439555 model2 loss : 0.023684
[11:47:14.428] iteration 19799 : model1 loss : 0.440877 model2 loss : 0.023019
[11:47:14.598] iteration 19800 : model1 loss : 0.434795 model2 loss : 0.020829
[11:47:16.536] iteration 19801 : model1 loss : 0.440327 model2 loss : 0.023138
[11:47:16.702] iteration 19802 : model1 loss : 0.437086 model2 loss : 0.022944
[11:47:16.872] iteration 19803 : model1 loss : 0.440682 model2 loss : 0.023276
[11:47:17.040] iteration 19804 : model1 loss : 0.441991 model2 loss : 0.024889
[11:47:17.210] iteration 19805 : model1 loss : 0.440974 model2 loss : 0.023989
[11:47:17.376] iteration 19806 : model1 loss : 0.438048 model2 loss : 0.019951
[11:47:17.550] iteration 19807 : model1 loss : 0.435028 model2 loss : 0.021488
[11:47:17.716] iteration 19808 : model1 loss : 0.444325 model2 loss : 0.025778
[11:47:17.887] iteration 19809 : model1 loss : 0.441870 model2 loss : 0.022877
[11:47:18.053] iteration 19810 : model1 loss : 0.436603 model2 loss : 0.020652
[11:47:18.223] iteration 19811 : model1 loss : 0.437595 model2 loss : 0.023032
[11:47:18.391] iteration 19812 : model1 loss : 0.438026 model2 loss : 0.021410
[11:47:18.560] iteration 19813 : model1 loss : 0.437375 model2 loss : 0.022964
[11:47:18.728] iteration 19814 : model1 loss : 0.437725 model2 loss : 0.021540
[11:47:18.898] iteration 19815 : model1 loss : 0.438809 model2 loss : 0.022330
[11:47:19.066] iteration 19816 : model1 loss : 0.442438 model2 loss : 0.021110
[11:47:19.237] iteration 19817 : model1 loss : 0.438737 model2 loss : 0.021889
[11:47:19.406] iteration 19818 : model1 loss : 0.437484 model2 loss : 0.021371
[11:47:19.577] iteration 19819 : model1 loss : 0.434728 model2 loss : 0.025017
[11:47:19.745] iteration 19820 : model1 loss : 0.438071 model2 loss : 0.021921
[11:47:19.916] iteration 19821 : model1 loss : 0.436862 model2 loss : 0.019802
[11:47:20.084] iteration 19822 : model1 loss : 0.440731 model2 loss : 0.024287
[11:47:20.253] iteration 19823 : model1 loss : 0.442604 model2 loss : 0.021984
[11:47:20.421] iteration 19824 : model1 loss : 0.432899 model2 loss : 0.021877
[11:47:20.591] iteration 19825 : model1 loss : 0.439658 model2 loss : 0.022158
[11:47:20.758] iteration 19826 : model1 loss : 0.437328 model2 loss : 0.021516
[11:47:20.931] iteration 19827 : model1 loss : 0.433425 model2 loss : 0.017988
[11:47:21.099] iteration 19828 : model1 loss : 0.440590 model2 loss : 0.022722
[11:47:21.269] iteration 19829 : model1 loss : 0.439156 model2 loss : 0.025758
[11:47:21.436] iteration 19830 : model1 loss : 0.435557 model2 loss : 0.018812
[11:47:21.604] iteration 19831 : model1 loss : 0.438606 model2 loss : 0.022410
[11:47:21.770] iteration 19832 : model1 loss : 0.440505 model2 loss : 0.023700
[11:47:21.939] iteration 19833 : model1 loss : 0.439359 model2 loss : 0.024894
[11:47:23.879] iteration 19834 : model1 loss : 0.438010 model2 loss : 0.021280
[11:47:24.050] iteration 19835 : model1 loss : 0.436910 model2 loss : 0.019735
[11:47:24.221] iteration 19836 : model1 loss : 0.435825 model2 loss : 0.017949
[11:47:24.389] iteration 19837 : model1 loss : 0.434538 model2 loss : 0.019016
[11:47:24.558] iteration 19838 : model1 loss : 0.439753 model2 loss : 0.021244
[11:47:24.725] iteration 19839 : model1 loss : 0.437227 model2 loss : 0.023789
[11:47:24.898] iteration 19840 : model1 loss : 0.439353 model2 loss : 0.023271
[11:47:25.065] iteration 19841 : model1 loss : 0.434571 model2 loss : 0.022607
[11:47:25.235] iteration 19842 : model1 loss : 0.442392 model2 loss : 0.022244
[11:47:25.405] iteration 19843 : model1 loss : 0.436286 model2 loss : 0.021333
[11:47:25.576] iteration 19844 : model1 loss : 0.438320 model2 loss : 0.023867
[11:47:25.742] iteration 19845 : model1 loss : 0.435853 model2 loss : 0.021263
[11:47:25.914] iteration 19846 : model1 loss : 0.442607 model2 loss : 0.021407
[11:47:26.083] iteration 19847 : model1 loss : 0.438197 model2 loss : 0.019895
[11:47:26.253] iteration 19848 : model1 loss : 0.437688 model2 loss : 0.021945
[11:47:26.419] iteration 19849 : model1 loss : 0.440752 model2 loss : 0.024815
[11:47:26.589] iteration 19850 : model1 loss : 0.440752 model2 loss : 0.022156
[11:47:26.756] iteration 19851 : model1 loss : 0.445479 model2 loss : 0.023766
[11:47:26.924] iteration 19852 : model1 loss : 0.433622 model2 loss : 0.021123
[11:47:27.092] iteration 19853 : model1 loss : 0.441633 model2 loss : 0.022248
[11:47:27.263] iteration 19854 : model1 loss : 0.440774 model2 loss : 0.024377
[11:47:27.431] iteration 19855 : model1 loss : 0.442790 model2 loss : 0.022541
[11:47:27.602] iteration 19856 : model1 loss : 0.440653 model2 loss : 0.023488
[11:47:27.769] iteration 19857 : model1 loss : 0.438119 model2 loss : 0.020436
[11:47:27.940] iteration 19858 : model1 loss : 0.433284 model2 loss : 0.021354
[11:47:28.108] iteration 19859 : model1 loss : 0.439367 model2 loss : 0.022639
[11:47:28.277] iteration 19860 : model1 loss : 0.433981 model2 loss : 0.019680
[11:47:28.445] iteration 19861 : model1 loss : 0.436932 model2 loss : 0.022534
[11:47:28.616] iteration 19862 : model1 loss : 0.438626 model2 loss : 0.021032
[11:47:28.783] iteration 19863 : model1 loss : 0.436648 model2 loss : 0.021152
[11:47:28.952] iteration 19864 : model1 loss : 0.438395 model2 loss : 0.021051
[11:47:29.120] iteration 19865 : model1 loss : 0.436561 model2 loss : 0.021799
[11:47:29.288] iteration 19866 : model1 loss : 0.440779 model2 loss : 0.022062
[11:47:31.243] iteration 19867 : model1 loss : 0.437924 model2 loss : 0.023121
[11:47:31.409] iteration 19868 : model1 loss : 0.440059 model2 loss : 0.021865
[11:47:31.580] iteration 19869 : model1 loss : 0.440115 model2 loss : 0.020377
[11:47:31.748] iteration 19870 : model1 loss : 0.436831 model2 loss : 0.019753
[11:47:31.916] iteration 19871 : model1 loss : 0.436017 model2 loss : 0.020143
[11:47:32.082] iteration 19872 : model1 loss : 0.437690 model2 loss : 0.022563
[11:47:32.250] iteration 19873 : model1 loss : 0.443595 model2 loss : 0.027595
[11:47:32.417] iteration 19874 : model1 loss : 0.437977 model2 loss : 0.022059
[11:47:32.586] iteration 19875 : model1 loss : 0.435006 model2 loss : 0.018167
[11:47:32.754] iteration 19876 : model1 loss : 0.435859 model2 loss : 0.019948
[11:47:32.924] iteration 19877 : model1 loss : 0.441519 model2 loss : 0.024352
[11:47:33.091] iteration 19878 : model1 loss : 0.437178 model2 loss : 0.021701
[11:47:33.260] iteration 19879 : model1 loss : 0.439688 model2 loss : 0.020360
[11:47:33.426] iteration 19880 : model1 loss : 0.446542 model2 loss : 0.028444
[11:47:33.598] iteration 19881 : model1 loss : 0.441119 model2 loss : 0.020275
[11:47:33.765] iteration 19882 : model1 loss : 0.441187 model2 loss : 0.021081
[11:47:33.936] iteration 19883 : model1 loss : 0.437262 model2 loss : 0.021362
[11:47:34.105] iteration 19884 : model1 loss : 0.436215 model2 loss : 0.021571
[11:47:34.274] iteration 19885 : model1 loss : 0.435433 model2 loss : 0.022185
[11:47:34.441] iteration 19886 : model1 loss : 0.434072 model2 loss : 0.020059
[11:47:34.611] iteration 19887 : model1 loss : 0.441264 model2 loss : 0.023388
[11:47:34.779] iteration 19888 : model1 loss : 0.440272 model2 loss : 0.023229
[11:47:34.949] iteration 19889 : model1 loss : 0.438392 model2 loss : 0.026912
[11:47:35.117] iteration 19890 : model1 loss : 0.435817 model2 loss : 0.020129
[11:47:35.287] iteration 19891 : model1 loss : 0.437379 model2 loss : 0.021355
[11:47:35.454] iteration 19892 : model1 loss : 0.436988 model2 loss : 0.019962
[11:47:35.626] iteration 19893 : model1 loss : 0.436288 model2 loss : 0.020973
[11:47:35.795] iteration 19894 : model1 loss : 0.438998 model2 loss : 0.019889
[11:47:35.965] iteration 19895 : model1 loss : 0.440175 model2 loss : 0.021384
[11:47:36.133] iteration 19896 : model1 loss : 0.432380 model2 loss : 0.020234
[11:47:36.302] iteration 19897 : model1 loss : 0.440569 model2 loss : 0.023588
[11:47:36.468] iteration 19898 : model1 loss : 0.437542 model2 loss : 0.023301
[11:47:36.636] iteration 19899 : model1 loss : 0.437423 model2 loss : 0.020991
[11:47:38.552] iteration 19900 : model1 loss : 0.439194 model2 loss : 0.021009
[11:47:38.720] iteration 19901 : model1 loss : 0.436250 model2 loss : 0.020675
[11:47:38.891] iteration 19902 : model1 loss : 0.436732 model2 loss : 0.021383
[11:47:39.059] iteration 19903 : model1 loss : 0.437283 model2 loss : 0.021873
[11:47:39.227] iteration 19904 : model1 loss : 0.438648 model2 loss : 0.020515
[11:47:39.395] iteration 19905 : model1 loss : 0.440161 model2 loss : 0.019863
[11:47:39.565] iteration 19906 : model1 loss : 0.438340 model2 loss : 0.021130
[11:47:39.732] iteration 19907 : model1 loss : 0.437527 model2 loss : 0.022328
[11:47:39.905] iteration 19908 : model1 loss : 0.443898 model2 loss : 0.024051
[11:47:40.074] iteration 19909 : model1 loss : 0.435426 model2 loss : 0.022499
[11:47:40.244] iteration 19910 : model1 loss : 0.438199 model2 loss : 0.021019
[11:47:40.411] iteration 19911 : model1 loss : 0.437451 model2 loss : 0.018624
[11:47:40.581] iteration 19912 : model1 loss : 0.442327 model2 loss : 0.021275
[11:47:40.746] iteration 19913 : model1 loss : 0.434252 model2 loss : 0.018525
[11:47:40.920] iteration 19914 : model1 loss : 0.438318 model2 loss : 0.020316
[11:47:41.087] iteration 19915 : model1 loss : 0.437416 model2 loss : 0.023129
[11:47:41.258] iteration 19916 : model1 loss : 0.436314 model2 loss : 0.021048
[11:47:41.425] iteration 19917 : model1 loss : 0.436646 model2 loss : 0.019536
[11:47:41.595] iteration 19918 : model1 loss : 0.443143 model2 loss : 0.023456
[11:47:41.761] iteration 19919 : model1 loss : 0.438678 model2 loss : 0.021890
[11:47:41.934] iteration 19920 : model1 loss : 0.436416 model2 loss : 0.020664
[11:47:42.101] iteration 19921 : model1 loss : 0.437954 model2 loss : 0.018538
[11:47:42.272] iteration 19922 : model1 loss : 0.438161 model2 loss : 0.020395
[11:47:42.438] iteration 19923 : model1 loss : 0.438722 model2 loss : 0.022760
[11:47:42.608] iteration 19924 : model1 loss : 0.439805 model2 loss : 0.021912
[11:47:42.774] iteration 19925 : model1 loss : 0.440591 model2 loss : 0.023148
[11:47:42.945] iteration 19926 : model1 loss : 0.436064 model2 loss : 0.021123
[11:47:43.113] iteration 19927 : model1 loss : 0.436880 model2 loss : 0.021237
[11:47:43.283] iteration 19928 : model1 loss : 0.437097 model2 loss : 0.021444
[11:47:43.449] iteration 19929 : model1 loss : 0.435848 model2 loss : 0.022515
[11:47:43.619] iteration 19930 : model1 loss : 0.439018 model2 loss : 0.021156
[11:47:43.785] iteration 19931 : model1 loss : 0.441884 model2 loss : 0.022672
[11:47:43.952] iteration 19932 : model1 loss : 0.438747 model2 loss : 0.020480
[11:47:45.912] iteration 19933 : model1 loss : 0.439129 model2 loss : 0.019543
[11:47:46.078] iteration 19934 : model1 loss : 0.438239 model2 loss : 0.021427
[11:47:46.249] iteration 19935 : model1 loss : 0.435200 model2 loss : 0.021655
[11:47:46.416] iteration 19936 : model1 loss : 0.438955 model2 loss : 0.020599
[11:47:46.587] iteration 19937 : model1 loss : 0.438907 model2 loss : 0.020359
[11:47:46.755] iteration 19938 : model1 loss : 0.438233 model2 loss : 0.024259
[11:47:46.927] iteration 19939 : model1 loss : 0.440228 model2 loss : 0.023174
[11:47:47.092] iteration 19940 : model1 loss : 0.443429 model2 loss : 0.023884
[11:47:47.263] iteration 19941 : model1 loss : 0.438774 model2 loss : 0.021857
[11:47:47.429] iteration 19942 : model1 loss : 0.432389 model2 loss : 0.019993
[11:47:47.599] iteration 19943 : model1 loss : 0.437580 model2 loss : 0.021734
[11:47:47.767] iteration 19944 : model1 loss : 0.436669 model2 loss : 0.022686
[11:47:47.941] iteration 19945 : model1 loss : 0.441284 model2 loss : 0.022901
[11:47:48.110] iteration 19946 : model1 loss : 0.439975 model2 loss : 0.025246
[11:47:48.280] iteration 19947 : model1 loss : 0.434772 model2 loss : 0.020298
[11:47:48.448] iteration 19948 : model1 loss : 0.441834 model2 loss : 0.025148
[11:47:48.618] iteration 19949 : model1 loss : 0.439398 model2 loss : 0.023432
[11:47:48.786] iteration 19950 : model1 loss : 0.440872 model2 loss : 0.020875
[11:47:48.958] iteration 19951 : model1 loss : 0.436739 model2 loss : 0.020910
[11:47:49.126] iteration 19952 : model1 loss : 0.432723 model2 loss : 0.019398
[11:47:49.296] iteration 19953 : model1 loss : 0.438503 model2 loss : 0.020737
[11:47:49.465] iteration 19954 : model1 loss : 0.439490 model2 loss : 0.022416
[11:47:49.634] iteration 19955 : model1 loss : 0.442488 model2 loss : 0.021942
[11:47:49.801] iteration 19956 : model1 loss : 0.434861 model2 loss : 0.021152
[11:47:49.968] iteration 19957 : model1 loss : 0.439587 model2 loss : 0.021099
[11:47:50.135] iteration 19958 : model1 loss : 0.438011 model2 loss : 0.019747
[11:47:50.303] iteration 19959 : model1 loss : 0.438570 model2 loss : 0.021573
[11:47:50.470] iteration 19960 : model1 loss : 0.440746 model2 loss : 0.022333
[11:47:50.639] iteration 19961 : model1 loss : 0.439767 model2 loss : 0.024148
[11:47:50.807] iteration 19962 : model1 loss : 0.439734 model2 loss : 0.022012
[11:47:50.980] iteration 19963 : model1 loss : 0.436316 model2 loss : 0.020053
[11:47:51.146] iteration 19964 : model1 loss : 0.436022 model2 loss : 0.023060
[11:47:51.315] iteration 19965 : model1 loss : 0.436304 model2 loss : 0.020310
[11:47:53.267] iteration 19966 : model1 loss : 0.439927 model2 loss : 0.022837
[11:47:53.438] iteration 19967 : model1 loss : 0.436131 model2 loss : 0.022021
[11:47:53.606] iteration 19968 : model1 loss : 0.438005 model2 loss : 0.023688
[11:47:53.772] iteration 19969 : model1 loss : 0.440961 model2 loss : 0.022515
[11:47:53.944] iteration 19970 : model1 loss : 0.435164 model2 loss : 0.025987
[11:47:54.112] iteration 19971 : model1 loss : 0.438237 model2 loss : 0.019877
[11:47:54.281] iteration 19972 : model1 loss : 0.438895 model2 loss : 0.020441
[11:47:54.450] iteration 19973 : model1 loss : 0.434339 model2 loss : 0.020839
[11:47:54.619] iteration 19974 : model1 loss : 0.437970 model2 loss : 0.025456
[11:47:54.785] iteration 19975 : model1 loss : 0.438602 model2 loss : 0.021652
[11:47:54.957] iteration 19976 : model1 loss : 0.435784 model2 loss : 0.022140
[11:47:55.122] iteration 19977 : model1 loss : 0.438718 model2 loss : 0.022660
[11:47:55.290] iteration 19978 : model1 loss : 0.437759 model2 loss : 0.020972
[11:47:55.457] iteration 19979 : model1 loss : 0.438066 model2 loss : 0.022822
[11:47:55.626] iteration 19980 : model1 loss : 0.438404 model2 loss : 0.023174
[11:47:55.794] iteration 19981 : model1 loss : 0.439223 model2 loss : 0.024575
[11:47:55.966] iteration 19982 : model1 loss : 0.434747 model2 loss : 0.022841
[11:47:56.133] iteration 19983 : model1 loss : 0.447983 model2 loss : 0.031271
[11:47:56.301] iteration 19984 : model1 loss : 0.438452 model2 loss : 0.019156
[11:47:56.476] iteration 19985 : model1 loss : 0.435994 model2 loss : 0.024584
[11:47:56.645] iteration 19986 : model1 loss : 0.442318 model2 loss : 0.028797
[11:47:56.812] iteration 19987 : model1 loss : 0.441917 model2 loss : 0.023571
[11:47:56.983] iteration 19988 : model1 loss : 0.436570 model2 loss : 0.021640
[11:47:57.149] iteration 19989 : model1 loss : 0.441405 model2 loss : 0.022762
[11:47:57.319] iteration 19990 : model1 loss : 0.434780 model2 loss : 0.020067
[11:47:57.486] iteration 19991 : model1 loss : 0.435783 model2 loss : 0.021460
[11:47:57.656] iteration 19992 : model1 loss : 0.440499 model2 loss : 0.023039
[11:47:57.823] iteration 19993 : model1 loss : 0.441388 model2 loss : 0.021801
[11:47:57.992] iteration 19994 : model1 loss : 0.440152 model2 loss : 0.023756
[11:47:58.160] iteration 19995 : model1 loss : 0.434410 model2 loss : 0.022767
[11:47:58.329] iteration 19996 : model1 loss : 0.439167 model2 loss : 0.023667
[11:47:58.495] iteration 19997 : model1 loss : 0.439866 model2 loss : 0.022517
[11:47:58.665] iteration 19998 : model1 loss : 0.437899 model2 loss : 0.022490
[11:48:00.616] iteration 19999 : model1 loss : 0.438108 model2 loss : 0.023841
[11:48:00.784] iteration 20000 : model1 loss : 0.440165 model2 loss : 0.023805
[11:48:09.153] iteration 20000 : model1_mean_dice : 0.897133 model1_mean_hd95 : 3.502073
[11:48:17.525] iteration 20000 : model2_mean_dice : 0.887316 model2_mean_hd95 : 6.041278
[11:48:17.702] iteration 20001 : model1 loss : 0.438789 model2 loss : 0.022066
[11:48:17.874] iteration 20002 : model1 loss : 0.436895 model2 loss : 0.023692
[11:48:18.041] iteration 20003 : model1 loss : 0.436365 model2 loss : 0.021379
[11:48:18.209] iteration 20004 : model1 loss : 0.441890 model2 loss : 0.022613
[11:48:18.376] iteration 20005 : model1 loss : 0.437955 model2 loss : 0.021971
[11:48:18.546] iteration 20006 : model1 loss : 0.434484 model2 loss : 0.021732
[11:48:18.711] iteration 20007 : model1 loss : 0.440078 model2 loss : 0.023189
[11:48:18.882] iteration 20008 : model1 loss : 0.432737 model2 loss : 0.021592
[11:48:19.048] iteration 20009 : model1 loss : 0.437492 model2 loss : 0.022465
[11:48:19.217] iteration 20010 : model1 loss : 0.435603 model2 loss : 0.021280
[11:48:19.384] iteration 20011 : model1 loss : 0.438056 model2 loss : 0.020868
[11:48:19.554] iteration 20012 : model1 loss : 0.441892 model2 loss : 0.023229
[11:48:19.720] iteration 20013 : model1 loss : 0.436209 model2 loss : 0.021319
[11:48:19.887] iteration 20014 : model1 loss : 0.439323 model2 loss : 0.021313
[11:48:20.055] iteration 20015 : model1 loss : 0.439529 model2 loss : 0.021268
[11:48:20.222] iteration 20016 : model1 loss : 0.441056 model2 loss : 0.023553
[11:48:20.388] iteration 20017 : model1 loss : 0.434752 model2 loss : 0.022268
[11:48:20.560] iteration 20018 : model1 loss : 0.438134 model2 loss : 0.022917
[11:48:20.727] iteration 20019 : model1 loss : 0.438199 model2 loss : 0.019535
[11:48:20.897] iteration 20020 : model1 loss : 0.438700 model2 loss : 0.019071
[11:48:21.061] iteration 20021 : model1 loss : 0.440283 model2 loss : 0.023779
[11:48:21.230] iteration 20022 : model1 loss : 0.441332 model2 loss : 0.018643
[11:48:21.396] iteration 20023 : model1 loss : 0.435317 model2 loss : 0.020146
[11:48:21.565] iteration 20024 : model1 loss : 0.438417 model2 loss : 0.022216
[11:48:21.732] iteration 20025 : model1 loss : 0.435925 model2 loss : 0.021314
[11:48:21.901] iteration 20026 : model1 loss : 0.441223 model2 loss : 0.022694
[11:48:22.068] iteration 20027 : model1 loss : 0.439082 model2 loss : 0.021193
[11:48:22.236] iteration 20028 : model1 loss : 0.439896 model2 loss : 0.021145
[11:48:22.404] iteration 20029 : model1 loss : 0.439117 model2 loss : 0.023326
[11:48:22.571] iteration 20030 : model1 loss : 0.446088 model2 loss : 0.024350
[11:48:22.736] iteration 20031 : model1 loss : 0.438767 model2 loss : 0.023060
[11:48:24.669] iteration 20032 : model1 loss : 0.439824 model2 loss : 0.021753
[11:48:24.837] iteration 20033 : model1 loss : 0.439274 model2 loss : 0.022924
[11:48:25.009] iteration 20034 : model1 loss : 0.438946 model2 loss : 0.018749
[11:48:25.175] iteration 20035 : model1 loss : 0.442711 model2 loss : 0.023488
[11:48:25.343] iteration 20036 : model1 loss : 0.433590 model2 loss : 0.020093
[11:48:25.514] iteration 20037 : model1 loss : 0.439475 model2 loss : 0.021303
[11:48:25.684] iteration 20038 : model1 loss : 0.436429 model2 loss : 0.019675
[11:48:25.850] iteration 20039 : model1 loss : 0.440893 model2 loss : 0.021572
[11:48:26.021] iteration 20040 : model1 loss : 0.440776 model2 loss : 0.024195
[11:48:26.188] iteration 20041 : model1 loss : 0.436514 model2 loss : 0.021023
[11:48:26.355] iteration 20042 : model1 loss : 0.436458 model2 loss : 0.022132
[11:48:26.524] iteration 20043 : model1 loss : 0.439185 model2 loss : 0.022948
[11:48:26.690] iteration 20044 : model1 loss : 0.442347 model2 loss : 0.023158
[11:48:26.857] iteration 20045 : model1 loss : 0.439571 model2 loss : 0.022032
[11:48:27.027] iteration 20046 : model1 loss : 0.439492 model2 loss : 0.021321
[11:48:27.193] iteration 20047 : model1 loss : 0.438099 model2 loss : 0.021006
[11:48:27.362] iteration 20048 : model1 loss : 0.442629 model2 loss : 0.023653
[11:48:27.531] iteration 20049 : model1 loss : 0.439579 model2 loss : 0.022519
[11:48:27.700] iteration 20050 : model1 loss : 0.435638 model2 loss : 0.022260
[11:48:27.865] iteration 20051 : model1 loss : 0.438086 model2 loss : 0.023333
[11:48:28.038] iteration 20052 : model1 loss : 0.434180 model2 loss : 0.018315
[11:48:28.204] iteration 20053 : model1 loss : 0.437117 model2 loss : 0.024074
[11:48:28.372] iteration 20054 : model1 loss : 0.440670 model2 loss : 0.023395
[11:48:28.543] iteration 20055 : model1 loss : 0.440344 model2 loss : 0.022024
[11:48:28.712] iteration 20056 : model1 loss : 0.437031 model2 loss : 0.019847
[11:48:28.877] iteration 20057 : model1 loss : 0.441557 model2 loss : 0.021963
[11:48:29.050] iteration 20058 : model1 loss : 0.434598 model2 loss : 0.020826
[11:48:29.216] iteration 20059 : model1 loss : 0.437752 model2 loss : 0.021294
[11:48:29.386] iteration 20060 : model1 loss : 0.438014 model2 loss : 0.023562
[11:48:29.555] iteration 20061 : model1 loss : 0.438306 model2 loss : 0.021843
[11:48:29.724] iteration 20062 : model1 loss : 0.443034 model2 loss : 0.024895
[11:48:29.890] iteration 20063 : model1 loss : 0.437399 model2 loss : 0.022850
[11:48:30.057] iteration 20064 : model1 loss : 0.438752 model2 loss : 0.023182
[11:48:32.028] iteration 20065 : model1 loss : 0.438701 model2 loss : 0.022962
[11:48:32.195] iteration 20066 : model1 loss : 0.441876 model2 loss : 0.021960
[11:48:32.364] iteration 20067 : model1 loss : 0.437742 model2 loss : 0.019465
[11:48:32.533] iteration 20068 : model1 loss : 0.438154 model2 loss : 0.020555
[11:48:32.700] iteration 20069 : model1 loss : 0.437961 model2 loss : 0.020397
[11:48:32.868] iteration 20070 : model1 loss : 0.441253 model2 loss : 0.023831
[11:48:33.038] iteration 20071 : model1 loss : 0.439490 model2 loss : 0.023458
[11:48:33.205] iteration 20072 : model1 loss : 0.437032 model2 loss : 0.020800
[11:48:33.371] iteration 20073 : model1 loss : 0.438353 model2 loss : 0.021580
[11:48:33.542] iteration 20074 : model1 loss : 0.440003 model2 loss : 0.022508
[11:48:33.709] iteration 20075 : model1 loss : 0.438445 model2 loss : 0.022625
[11:48:33.876] iteration 20076 : model1 loss : 0.434576 model2 loss : 0.021349
[11:48:34.047] iteration 20077 : model1 loss : 0.438628 model2 loss : 0.021565
[11:48:34.213] iteration 20078 : model1 loss : 0.438199 model2 loss : 0.021227
[11:48:34.381] iteration 20079 : model1 loss : 0.442915 model2 loss : 0.021961
[11:48:34.547] iteration 20080 : model1 loss : 0.440110 model2 loss : 0.021315
[11:48:34.716] iteration 20081 : model1 loss : 0.439490 model2 loss : 0.022166
[11:48:34.883] iteration 20082 : model1 loss : 0.437011 model2 loss : 0.021531
[11:48:35.053] iteration 20083 : model1 loss : 0.436984 model2 loss : 0.019557
[11:48:35.221] iteration 20084 : model1 loss : 0.437827 model2 loss : 0.021550
[11:48:35.390] iteration 20085 : model1 loss : 0.442092 model2 loss : 0.022042
[11:48:35.555] iteration 20086 : model1 loss : 0.438818 model2 loss : 0.022143
[11:48:35.726] iteration 20087 : model1 loss : 0.439956 model2 loss : 0.022489
[11:48:35.895] iteration 20088 : model1 loss : 0.433429 model2 loss : 0.021058
[11:48:36.067] iteration 20089 : model1 loss : 0.438869 model2 loss : 0.022573
[11:48:36.232] iteration 20090 : model1 loss : 0.436401 model2 loss : 0.021980
[11:48:36.400] iteration 20091 : model1 loss : 0.442834 model2 loss : 0.022179
[11:48:36.568] iteration 20092 : model1 loss : 0.440686 model2 loss : 0.024210
[11:48:36.736] iteration 20093 : model1 loss : 0.437300 model2 loss : 0.020997
[11:48:36.902] iteration 20094 : model1 loss : 0.435000 model2 loss : 0.019443
[11:48:37.085] iteration 20095 : model1 loss : 0.440061 model2 loss : 0.021830
[11:48:37.249] iteration 20096 : model1 loss : 0.434822 model2 loss : 0.021321
[11:48:37.416] iteration 20097 : model1 loss : 0.440597 model2 loss : 0.023870
[11:48:39.329] iteration 20098 : model1 loss : 0.438451 model2 loss : 0.021659
[11:48:39.500] iteration 20099 : model1 loss : 0.441825 model2 loss : 0.024782
[11:48:39.670] iteration 20100 : model1 loss : 0.437344 model2 loss : 0.021557
[11:48:39.836] iteration 20101 : model1 loss : 0.432580 model2 loss : 0.021606
[11:48:40.004] iteration 20102 : model1 loss : 0.437126 model2 loss : 0.020501
[11:48:40.169] iteration 20103 : model1 loss : 0.435724 model2 loss : 0.018679
[11:48:40.338] iteration 20104 : model1 loss : 0.441640 model2 loss : 0.022432
[11:48:40.515] iteration 20105 : model1 loss : 0.436433 model2 loss : 0.020314
[11:48:40.684] iteration 20106 : model1 loss : 0.438507 model2 loss : 0.021522
[11:48:40.849] iteration 20107 : model1 loss : 0.439528 model2 loss : 0.022716
[11:48:41.017] iteration 20108 : model1 loss : 0.438103 model2 loss : 0.025138
[11:48:41.181] iteration 20109 : model1 loss : 0.439685 model2 loss : 0.021959
[11:48:41.350] iteration 20110 : model1 loss : 0.435443 model2 loss : 0.021281
[11:48:41.519] iteration 20111 : model1 loss : 0.441859 model2 loss : 0.024572
[11:48:41.690] iteration 20112 : model1 loss : 0.438735 model2 loss : 0.018928
[11:48:41.859] iteration 20113 : model1 loss : 0.440877 model2 loss : 0.021549
[11:48:42.028] iteration 20114 : model1 loss : 0.437214 model2 loss : 0.022376
[11:48:42.194] iteration 20115 : model1 loss : 0.436987 model2 loss : 0.023919
[11:48:42.362] iteration 20116 : model1 loss : 0.440998 model2 loss : 0.024999
[11:48:42.529] iteration 20117 : model1 loss : 0.434834 model2 loss : 0.019945
[11:48:42.698] iteration 20118 : model1 loss : 0.436909 model2 loss : 0.020620
[11:48:42.866] iteration 20119 : model1 loss : 0.442423 model2 loss : 0.021834
[11:48:43.035] iteration 20120 : model1 loss : 0.442175 model2 loss : 0.026328
[11:48:43.202] iteration 20121 : model1 loss : 0.434875 model2 loss : 0.019637
[11:48:43.371] iteration 20122 : model1 loss : 0.440028 model2 loss : 0.022775
[11:48:43.538] iteration 20123 : model1 loss : 0.438815 model2 loss : 0.020731
[11:48:43.717] iteration 20124 : model1 loss : 0.442951 model2 loss : 0.024731
[11:48:43.884] iteration 20125 : model1 loss : 0.438137 model2 loss : 0.023249
[11:48:44.052] iteration 20126 : model1 loss : 0.444323 model2 loss : 0.022507
[11:48:44.217] iteration 20127 : model1 loss : 0.439364 model2 loss : 0.023542
[11:48:44.388] iteration 20128 : model1 loss : 0.440111 model2 loss : 0.019309
[11:48:44.554] iteration 20129 : model1 loss : 0.434975 model2 loss : 0.019073
[11:48:44.720] iteration 20130 : model1 loss : 0.439905 model2 loss : 0.021977
[11:48:46.687] iteration 20131 : model1 loss : 0.435240 model2 loss : 0.021583
[11:48:46.854] iteration 20132 : model1 loss : 0.436118 model2 loss : 0.021856
[11:48:47.024] iteration 20133 : model1 loss : 0.437577 model2 loss : 0.023420
[11:48:47.190] iteration 20134 : model1 loss : 0.439433 model2 loss : 0.020735
[11:48:47.360] iteration 20135 : model1 loss : 0.440042 model2 loss : 0.023314
[11:48:47.529] iteration 20136 : model1 loss : 0.438193 model2 loss : 0.019972
[11:48:47.698] iteration 20137 : model1 loss : 0.439139 model2 loss : 0.022499
[11:48:47.865] iteration 20138 : model1 loss : 0.436051 model2 loss : 0.018783
[11:48:48.034] iteration 20139 : model1 loss : 0.439770 model2 loss : 0.022868
[11:48:48.199] iteration 20140 : model1 loss : 0.441159 model2 loss : 0.021436
[11:48:48.368] iteration 20141 : model1 loss : 0.439269 model2 loss : 0.019116
[11:48:48.537] iteration 20142 : model1 loss : 0.439576 model2 loss : 0.019761
[11:48:48.705] iteration 20143 : model1 loss : 0.440567 model2 loss : 0.022722
[11:48:48.871] iteration 20144 : model1 loss : 0.439364 model2 loss : 0.021641
[11:48:49.038] iteration 20145 : model1 loss : 0.437442 model2 loss : 0.020008
[11:48:49.219] iteration 20146 : model1 loss : 0.438239 model2 loss : 0.021125
[11:48:49.386] iteration 20147 : model1 loss : 0.436609 model2 loss : 0.021296
[11:48:49.553] iteration 20148 : model1 loss : 0.441650 model2 loss : 0.022125
[11:48:49.721] iteration 20149 : model1 loss : 0.439325 model2 loss : 0.020824
[11:48:49.887] iteration 20150 : model1 loss : 0.435790 model2 loss : 0.021314
[11:48:50.056] iteration 20151 : model1 loss : 0.441671 model2 loss : 0.020515
[11:48:50.224] iteration 20152 : model1 loss : 0.440843 model2 loss : 0.022516
[11:48:50.393] iteration 20153 : model1 loss : 0.439593 model2 loss : 0.023966
[11:48:50.560] iteration 20154 : model1 loss : 0.436911 model2 loss : 0.020314
[11:48:50.729] iteration 20155 : model1 loss : 0.436595 model2 loss : 0.021190
[11:48:50.896] iteration 20156 : model1 loss : 0.440363 model2 loss : 0.019681
[11:48:51.066] iteration 20157 : model1 loss : 0.440678 model2 loss : 0.022203
[11:48:51.232] iteration 20158 : model1 loss : 0.436310 model2 loss : 0.019841
[11:48:51.402] iteration 20159 : model1 loss : 0.437480 model2 loss : 0.021825
[11:48:51.571] iteration 20160 : model1 loss : 0.432096 model2 loss : 0.020388
[11:48:51.738] iteration 20161 : model1 loss : 0.433654 model2 loss : 0.020043
[11:48:51.906] iteration 20162 : model1 loss : 0.440216 model2 loss : 0.022053
[11:48:52.073] iteration 20163 : model1 loss : 0.444128 model2 loss : 0.021623
[11:48:53.981] iteration 20164 : model1 loss : 0.439739 model2 loss : 0.022578
[11:48:54.156] iteration 20165 : model1 loss : 0.441043 model2 loss : 0.021224
[11:48:54.326] iteration 20166 : model1 loss : 0.438802 model2 loss : 0.021253
[11:48:54.498] iteration 20167 : model1 loss : 0.440007 model2 loss : 0.019553
[11:48:54.666] iteration 20168 : model1 loss : 0.436271 model2 loss : 0.019804
[11:48:54.833] iteration 20169 : model1 loss : 0.435731 model2 loss : 0.018496
[11:48:55.002] iteration 20170 : model1 loss : 0.439044 model2 loss : 0.020215
[11:48:55.168] iteration 20171 : model1 loss : 0.439533 model2 loss : 0.022483
[11:48:55.337] iteration 20172 : model1 loss : 0.435188 model2 loss : 0.020580
[11:48:55.503] iteration 20173 : model1 loss : 0.437731 model2 loss : 0.022564
[11:48:55.672] iteration 20174 : model1 loss : 0.437595 model2 loss : 0.021948
[11:48:55.838] iteration 20175 : model1 loss : 0.436116 model2 loss : 0.022102
[11:48:56.011] iteration 20176 : model1 loss : 0.437482 model2 loss : 0.022800
[11:48:56.178] iteration 20177 : model1 loss : 0.443901 model2 loss : 0.022028
[11:48:56.347] iteration 20178 : model1 loss : 0.441524 model2 loss : 0.022550
[11:48:56.519] iteration 20179 : model1 loss : 0.435384 model2 loss : 0.019847
[11:48:56.687] iteration 20180 : model1 loss : 0.445115 model2 loss : 0.020806
[11:48:56.855] iteration 20181 : model1 loss : 0.441158 model2 loss : 0.022355
[11:48:57.025] iteration 20182 : model1 loss : 0.438192 model2 loss : 0.021345
[11:48:57.192] iteration 20183 : model1 loss : 0.438007 model2 loss : 0.021889
[11:48:57.360] iteration 20184 : model1 loss : 0.434594 model2 loss : 0.022033
[11:48:57.530] iteration 20185 : model1 loss : 0.440513 model2 loss : 0.022263
[11:48:57.699] iteration 20186 : model1 loss : 0.442310 model2 loss : 0.020883
[11:48:57.867] iteration 20187 : model1 loss : 0.436832 model2 loss : 0.021049
[11:48:58.036] iteration 20188 : model1 loss : 0.435832 model2 loss : 0.020501
[11:48:58.203] iteration 20189 : model1 loss : 0.440458 model2 loss : 0.023031
[11:48:58.372] iteration 20190 : model1 loss : 0.437338 model2 loss : 0.020954
[11:48:58.542] iteration 20191 : model1 loss : 0.437046 model2 loss : 0.021867
[11:48:58.711] iteration 20192 : model1 loss : 0.441754 model2 loss : 0.023616
[11:48:58.876] iteration 20193 : model1 loss : 0.433186 model2 loss : 0.020921
[11:48:59.045] iteration 20194 : model1 loss : 0.433588 model2 loss : 0.019996
[11:48:59.210] iteration 20195 : model1 loss : 0.434653 model2 loss : 0.019667
[11:48:59.376] iteration 20196 : model1 loss : 0.439373 model2 loss : 0.021567
[11:49:01.320] iteration 20197 : model1 loss : 0.438873 model2 loss : 0.022043
[11:49:01.485] iteration 20198 : model1 loss : 0.432598 model2 loss : 0.019755
[11:49:01.653] iteration 20199 : model1 loss : 0.433922 model2 loss : 0.022313
[11:49:01.818] iteration 20200 : model1 loss : 0.439410 model2 loss : 0.024916
[11:49:02.006] iteration 20201 : model1 loss : 0.443618 model2 loss : 0.024053
[11:49:02.172] iteration 20202 : model1 loss : 0.435144 model2 loss : 0.020072
[11:49:02.340] iteration 20203 : model1 loss : 0.442013 model2 loss : 0.026273
[11:49:02.508] iteration 20204 : model1 loss : 0.438050 model2 loss : 0.023270
[11:49:02.677] iteration 20205 : model1 loss : 0.435941 model2 loss : 0.020796
[11:49:02.845] iteration 20206 : model1 loss : 0.442302 model2 loss : 0.025803
[11:49:03.013] iteration 20207 : model1 loss : 0.442086 model2 loss : 0.022008
[11:49:03.180] iteration 20208 : model1 loss : 0.437602 model2 loss : 0.018140
[11:49:03.351] iteration 20209 : model1 loss : 0.441840 model2 loss : 0.022179
[11:49:03.520] iteration 20210 : model1 loss : 0.436240 model2 loss : 0.020495
[11:49:03.689] iteration 20211 : model1 loss : 0.435688 model2 loss : 0.024589
[11:49:03.856] iteration 20212 : model1 loss : 0.437759 model2 loss : 0.019436
[11:49:04.025] iteration 20213 : model1 loss : 0.438436 model2 loss : 0.022162
[11:49:04.192] iteration 20214 : model1 loss : 0.440309 model2 loss : 0.021111
[11:49:04.361] iteration 20215 : model1 loss : 0.436588 model2 loss : 0.020258
[11:49:04.529] iteration 20216 : model1 loss : 0.439606 model2 loss : 0.020388
[11:49:04.699] iteration 20217 : model1 loss : 0.439218 model2 loss : 0.023664
[11:49:04.866] iteration 20218 : model1 loss : 0.444115 model2 loss : 0.024954
[11:49:05.037] iteration 20219 : model1 loss : 0.437639 model2 loss : 0.022988
[11:49:05.204] iteration 20220 : model1 loss : 0.437559 model2 loss : 0.021503
[11:49:05.374] iteration 20221 : model1 loss : 0.442691 model2 loss : 0.023972
[11:49:05.542] iteration 20222 : model1 loss : 0.437547 model2 loss : 0.022284
[11:49:05.711] iteration 20223 : model1 loss : 0.438670 model2 loss : 0.021007
[11:49:05.881] iteration 20224 : model1 loss : 0.438879 model2 loss : 0.021061
[11:49:06.049] iteration 20225 : model1 loss : 0.431714 model2 loss : 0.022463
[11:49:06.215] iteration 20226 : model1 loss : 0.437034 model2 loss : 0.024334
[11:49:06.383] iteration 20227 : model1 loss : 0.437164 model2 loss : 0.020485
[11:49:06.549] iteration 20228 : model1 loss : 0.440274 model2 loss : 0.023258
[11:49:06.715] iteration 20229 : model1 loss : 0.441257 model2 loss : 0.023281
[11:49:08.640] iteration 20230 : model1 loss : 0.438489 model2 loss : 0.020891
[11:49:08.807] iteration 20231 : model1 loss : 0.442257 model2 loss : 0.022676
[11:49:08.975] iteration 20232 : model1 loss : 0.437817 model2 loss : 0.023714
[11:49:09.142] iteration 20233 : model1 loss : 0.438964 model2 loss : 0.022005
[11:49:09.313] iteration 20234 : model1 loss : 0.439895 model2 loss : 0.020470
[11:49:09.480] iteration 20235 : model1 loss : 0.436942 model2 loss : 0.020657
[11:49:09.662] iteration 20236 : model1 loss : 0.441263 model2 loss : 0.020578
[11:49:09.829] iteration 20237 : model1 loss : 0.435184 model2 loss : 0.021824
[11:49:09.998] iteration 20238 : model1 loss : 0.437483 model2 loss : 0.021729
[11:49:10.165] iteration 20239 : model1 loss : 0.434831 model2 loss : 0.019585
[11:49:10.334] iteration 20240 : model1 loss : 0.437683 model2 loss : 0.021167
[11:49:10.504] iteration 20241 : model1 loss : 0.443605 model2 loss : 0.021217
[11:49:10.675] iteration 20242 : model1 loss : 0.439638 model2 loss : 0.021993
[11:49:10.844] iteration 20243 : model1 loss : 0.438025 model2 loss : 0.021220
[11:49:11.014] iteration 20244 : model1 loss : 0.439283 model2 loss : 0.023108
[11:49:11.180] iteration 20245 : model1 loss : 0.434739 model2 loss : 0.019686
[11:49:11.350] iteration 20246 : model1 loss : 0.440066 model2 loss : 0.023385
[11:49:11.526] iteration 20247 : model1 loss : 0.436611 model2 loss : 0.021396
[11:49:11.696] iteration 20248 : model1 loss : 0.435086 model2 loss : 0.020818
[11:49:11.863] iteration 20249 : model1 loss : 0.440195 model2 loss : 0.023332
[11:49:12.032] iteration 20250 : model1 loss : 0.434376 model2 loss : 0.021368
[11:49:12.199] iteration 20251 : model1 loss : 0.437288 model2 loss : 0.021790
[11:49:12.368] iteration 20252 : model1 loss : 0.440498 model2 loss : 0.021325
[11:49:12.538] iteration 20253 : model1 loss : 0.437667 model2 loss : 0.022672
[11:49:12.705] iteration 20254 : model1 loss : 0.438565 model2 loss : 0.022080
[11:49:12.872] iteration 20255 : model1 loss : 0.439163 model2 loss : 0.022750
[11:49:13.040] iteration 20256 : model1 loss : 0.435872 model2 loss : 0.021191
[11:49:13.209] iteration 20257 : model1 loss : 0.435179 model2 loss : 0.018101
[11:49:13.379] iteration 20258 : model1 loss : 0.440544 model2 loss : 0.022872
[11:49:13.546] iteration 20259 : model1 loss : 0.440564 model2 loss : 0.023771
[11:49:13.716] iteration 20260 : model1 loss : 0.442958 model2 loss : 0.023827
[11:49:13.881] iteration 20261 : model1 loss : 0.441813 model2 loss : 0.020572
[11:49:14.049] iteration 20262 : model1 loss : 0.439659 model2 loss : 0.021951
[11:49:15.996] iteration 20263 : model1 loss : 0.434890 model2 loss : 0.021016
[11:49:16.163] iteration 20264 : model1 loss : 0.441591 model2 loss : 0.027503
[11:49:16.333] iteration 20265 : model1 loss : 0.441615 model2 loss : 0.021485
[11:49:16.501] iteration 20266 : model1 loss : 0.437817 model2 loss : 0.021100
[11:49:16.670] iteration 20267 : model1 loss : 0.440933 model2 loss : 0.022851
[11:49:16.839] iteration 20268 : model1 loss : 0.438822 model2 loss : 0.022349
[11:49:17.006] iteration 20269 : model1 loss : 0.442051 model2 loss : 0.022050
[11:49:17.176] iteration 20270 : model1 loss : 0.440952 model2 loss : 0.022066
[11:49:17.345] iteration 20271 : model1 loss : 0.442485 model2 loss : 0.026692
[11:49:17.517] iteration 20272 : model1 loss : 0.436227 model2 loss : 0.021384
[11:49:17.685] iteration 20273 : model1 loss : 0.438475 model2 loss : 0.021294
[11:49:17.854] iteration 20274 : model1 loss : 0.437205 model2 loss : 0.021878
[11:49:18.023] iteration 20275 : model1 loss : 0.438801 model2 loss : 0.022751
[11:49:18.189] iteration 20276 : model1 loss : 0.437608 model2 loss : 0.020253
[11:49:18.361] iteration 20277 : model1 loss : 0.437716 model2 loss : 0.018091
[11:49:18.530] iteration 20278 : model1 loss : 0.440600 model2 loss : 0.022233
[11:49:18.698] iteration 20279 : model1 loss : 0.439014 model2 loss : 0.021172
[11:49:18.867] iteration 20280 : model1 loss : 0.437270 model2 loss : 0.021434
[11:49:19.036] iteration 20281 : model1 loss : 0.442208 model2 loss : 0.021533
[11:49:19.203] iteration 20282 : model1 loss : 0.436922 model2 loss : 0.020949
[11:49:19.373] iteration 20283 : model1 loss : 0.436071 model2 loss : 0.022236
[11:49:19.542] iteration 20284 : model1 loss : 0.436890 model2 loss : 0.019718
[11:49:19.711] iteration 20285 : model1 loss : 0.437697 model2 loss : 0.021189
[11:49:19.879] iteration 20286 : model1 loss : 0.437000 model2 loss : 0.022088
[11:49:20.049] iteration 20287 : model1 loss : 0.436953 model2 loss : 0.021994
[11:49:20.216] iteration 20288 : model1 loss : 0.439028 model2 loss : 0.019509
[11:49:20.386] iteration 20289 : model1 loss : 0.439188 model2 loss : 0.021978
[11:49:20.552] iteration 20290 : model1 loss : 0.435845 model2 loss : 0.018856
[11:49:20.721] iteration 20291 : model1 loss : 0.434193 model2 loss : 0.021392
[11:49:20.890] iteration 20292 : model1 loss : 0.438139 model2 loss : 0.022138
[11:49:21.057] iteration 20293 : model1 loss : 0.436520 model2 loss : 0.020346
[11:49:21.225] iteration 20294 : model1 loss : 0.441851 model2 loss : 0.024365
[11:49:21.392] iteration 20295 : model1 loss : 0.440563 model2 loss : 0.021715
[11:49:23.323] iteration 20296 : model1 loss : 0.436933 model2 loss : 0.019807
[11:49:23.489] iteration 20297 : model1 loss : 0.439146 model2 loss : 0.019018
[11:49:23.660] iteration 20298 : model1 loss : 0.437496 model2 loss : 0.019769
[11:49:23.827] iteration 20299 : model1 loss : 0.440143 model2 loss : 0.025904
[11:49:23.997] iteration 20300 : model1 loss : 0.439680 model2 loss : 0.021610
[11:49:24.166] iteration 20301 : model1 loss : 0.438302 model2 loss : 0.020001
[11:49:24.332] iteration 20302 : model1 loss : 0.437037 model2 loss : 0.022747
[11:49:24.500] iteration 20303 : model1 loss : 0.439129 model2 loss : 0.020997
[11:49:24.671] iteration 20304 : model1 loss : 0.441053 model2 loss : 0.020071
[11:49:24.837] iteration 20305 : model1 loss : 0.440848 model2 loss : 0.019370
[11:49:25.007] iteration 20306 : model1 loss : 0.433710 model2 loss : 0.021349
[11:49:25.177] iteration 20307 : model1 loss : 0.440581 model2 loss : 0.019885
[11:49:25.344] iteration 20308 : model1 loss : 0.439482 model2 loss : 0.021250
[11:49:25.512] iteration 20309 : model1 loss : 0.434027 model2 loss : 0.022635
[11:49:25.684] iteration 20310 : model1 loss : 0.433001 model2 loss : 0.019732
[11:49:25.850] iteration 20311 : model1 loss : 0.443026 model2 loss : 0.025101
[11:49:26.019] iteration 20312 : model1 loss : 0.440242 model2 loss : 0.020235
[11:49:26.188] iteration 20313 : model1 loss : 0.439341 model2 loss : 0.021651
[11:49:26.357] iteration 20314 : model1 loss : 0.434657 model2 loss : 0.019475
[11:49:26.529] iteration 20315 : model1 loss : 0.441337 model2 loss : 0.021000
[11:49:26.697] iteration 20316 : model1 loss : 0.442744 model2 loss : 0.023702
[11:49:26.864] iteration 20317 : model1 loss : 0.434874 model2 loss : 0.021702
[11:49:27.034] iteration 20318 : model1 loss : 0.439537 model2 loss : 0.022649
[11:49:27.203] iteration 20319 : model1 loss : 0.438370 model2 loss : 0.021496
[11:49:27.371] iteration 20320 : model1 loss : 0.439058 model2 loss : 0.022789
[11:49:27.538] iteration 20321 : model1 loss : 0.435271 model2 loss : 0.019847
[11:49:27.707] iteration 20322 : model1 loss : 0.434380 model2 loss : 0.023092
[11:49:27.886] iteration 20323 : model1 loss : 0.441694 model2 loss : 0.023031
[11:49:28.055] iteration 20324 : model1 loss : 0.438155 model2 loss : 0.020756
[11:49:28.223] iteration 20325 : model1 loss : 0.440902 model2 loss : 0.021078
[11:49:28.393] iteration 20326 : model1 loss : 0.439328 model2 loss : 0.020428
[11:49:28.560] iteration 20327 : model1 loss : 0.436570 model2 loss : 0.022287
[11:49:28.728] iteration 20328 : model1 loss : 0.439272 model2 loss : 0.023509
[11:49:30.643] iteration 20329 : model1 loss : 0.438298 model2 loss : 0.020559
[11:49:30.810] iteration 20330 : model1 loss : 0.438003 model2 loss : 0.022987
[11:49:30.981] iteration 20331 : model1 loss : 0.436703 model2 loss : 0.017227
[11:49:31.151] iteration 20332 : model1 loss : 0.442613 model2 loss : 0.023590
[11:49:31.318] iteration 20333 : model1 loss : 0.435630 model2 loss : 0.020700
[11:49:31.484] iteration 20334 : model1 loss : 0.440425 model2 loss : 0.019744
[11:49:31.655] iteration 20335 : model1 loss : 0.438389 model2 loss : 0.020882
[11:49:31.823] iteration 20336 : model1 loss : 0.439391 model2 loss : 0.020127
[11:49:31.993] iteration 20337 : model1 loss : 0.442200 model2 loss : 0.022714
[11:49:32.160] iteration 20338 : model1 loss : 0.444406 model2 loss : 0.024619
[11:49:32.331] iteration 20339 : model1 loss : 0.438676 model2 loss : 0.020696
[11:49:32.498] iteration 20340 : model1 loss : 0.439657 model2 loss : 0.021314
[11:49:32.666] iteration 20341 : model1 loss : 0.436765 model2 loss : 0.022241
[11:49:32.834] iteration 20342 : model1 loss : 0.435425 model2 loss : 0.020920
[11:49:33.002] iteration 20343 : model1 loss : 0.434595 model2 loss : 0.020025
[11:49:33.171] iteration 20344 : model1 loss : 0.443049 model2 loss : 0.021151
[11:49:33.341] iteration 20345 : model1 loss : 0.441005 model2 loss : 0.020953
[11:49:33.510] iteration 20346 : model1 loss : 0.437015 model2 loss : 0.021193
[11:49:33.679] iteration 20347 : model1 loss : 0.440885 model2 loss : 0.021694
[11:49:33.847] iteration 20348 : model1 loss : 0.434905 model2 loss : 0.020859
[11:49:34.017] iteration 20349 : model1 loss : 0.437967 model2 loss : 0.020825
[11:49:34.184] iteration 20350 : model1 loss : 0.437902 model2 loss : 0.021351
[11:49:34.356] iteration 20351 : model1 loss : 0.441272 model2 loss : 0.021099
[11:49:34.528] iteration 20352 : model1 loss : 0.434985 model2 loss : 0.020288
[11:49:34.696] iteration 20353 : model1 loss : 0.436209 model2 loss : 0.019292
[11:49:34.864] iteration 20354 : model1 loss : 0.438865 model2 loss : 0.022340
[11:49:35.035] iteration 20355 : model1 loss : 0.438435 model2 loss : 0.020304
[11:49:35.206] iteration 20356 : model1 loss : 0.435673 model2 loss : 0.020833
[11:49:35.375] iteration 20357 : model1 loss : 0.435838 model2 loss : 0.021251
[11:49:35.543] iteration 20358 : model1 loss : 0.440752 model2 loss : 0.022857
[11:49:35.713] iteration 20359 : model1 loss : 0.437159 model2 loss : 0.023068
[11:49:35.880] iteration 20360 : model1 loss : 0.439621 model2 loss : 0.022925
[11:49:36.048] iteration 20361 : model1 loss : 0.434806 model2 loss : 0.020630
[11:49:38.111] iteration 20362 : model1 loss : 0.440071 model2 loss : 0.021219
[11:49:38.280] iteration 20363 : model1 loss : 0.440725 model2 loss : 0.020772
[11:49:38.451] iteration 20364 : model1 loss : 0.443343 model2 loss : 0.022983
[11:49:38.618] iteration 20365 : model1 loss : 0.439183 model2 loss : 0.019506
[11:49:38.787] iteration 20366 : model1 loss : 0.437954 model2 loss : 0.023699
[11:49:38.954] iteration 20367 : model1 loss : 0.438398 model2 loss : 0.022512
[11:49:39.123] iteration 20368 : model1 loss : 0.437052 model2 loss : 0.020151
[11:49:39.290] iteration 20369 : model1 loss : 0.433418 model2 loss : 0.019906
[11:49:39.458] iteration 20370 : model1 loss : 0.436074 model2 loss : 0.021443
[11:49:39.626] iteration 20371 : model1 loss : 0.436946 model2 loss : 0.018840
[11:49:39.795] iteration 20372 : model1 loss : 0.438682 model2 loss : 0.020699
[11:49:39.964] iteration 20373 : model1 loss : 0.441585 model2 loss : 0.023220
[11:49:40.132] iteration 20374 : model1 loss : 0.441733 model2 loss : 0.024645
[11:49:40.300] iteration 20375 : model1 loss : 0.434909 model2 loss : 0.022590
[11:49:40.471] iteration 20376 : model1 loss : 0.438829 model2 loss : 0.019166
[11:49:40.637] iteration 20377 : model1 loss : 0.438415 model2 loss : 0.019196
[11:49:40.806] iteration 20378 : model1 loss : 0.443898 model2 loss : 0.027201
[11:49:40.975] iteration 20379 : model1 loss : 0.440857 model2 loss : 0.023993
[11:49:41.144] iteration 20380 : model1 loss : 0.434435 model2 loss : 0.019458
[11:49:41.310] iteration 20381 : model1 loss : 0.436201 model2 loss : 0.019894
[11:49:41.481] iteration 20382 : model1 loss : 0.433532 model2 loss : 0.019745
[11:49:41.648] iteration 20383 : model1 loss : 0.436116 model2 loss : 0.019222
[11:49:41.817] iteration 20384 : model1 loss : 0.441684 model2 loss : 0.022416
[11:49:41.986] iteration 20385 : model1 loss : 0.438699 model2 loss : 0.022169
[11:49:42.154] iteration 20386 : model1 loss : 0.436649 model2 loss : 0.020907
[11:49:42.322] iteration 20387 : model1 loss : 0.440217 model2 loss : 0.020594
[11:49:42.494] iteration 20388 : model1 loss : 0.437904 model2 loss : 0.021793
[11:49:42.660] iteration 20389 : model1 loss : 0.438288 model2 loss : 0.018819
[11:49:42.830] iteration 20390 : model1 loss : 0.440243 model2 loss : 0.020633
[11:49:42.996] iteration 20391 : model1 loss : 0.437358 model2 loss : 0.021442
[11:49:43.168] iteration 20392 : model1 loss : 0.436956 model2 loss : 0.019623
[11:49:43.333] iteration 20393 : model1 loss : 0.438199 model2 loss : 0.022083
[11:49:43.503] iteration 20394 : model1 loss : 0.438955 model2 loss : 0.020994
[11:49:45.391] iteration 20395 : model1 loss : 0.441245 model2 loss : 0.020075
[11:49:45.558] iteration 20396 : model1 loss : 0.438746 model2 loss : 0.020333
[11:49:45.730] iteration 20397 : model1 loss : 0.435231 model2 loss : 0.019562
[11:49:45.900] iteration 20398 : model1 loss : 0.440167 model2 loss : 0.020673
[11:49:46.069] iteration 20399 : model1 loss : 0.438260 model2 loss : 0.020675
[11:49:46.238] iteration 20400 : model1 loss : 0.440404 model2 loss : 0.021524
[11:49:46.408] iteration 20401 : model1 loss : 0.436811 model2 loss : 0.019549
[11:49:46.577] iteration 20402 : model1 loss : 0.442530 model2 loss : 0.020758
[11:49:46.746] iteration 20403 : model1 loss : 0.437766 model2 loss : 0.022561
[11:49:46.914] iteration 20404 : model1 loss : 0.436140 model2 loss : 0.021490
[11:49:47.083] iteration 20405 : model1 loss : 0.436638 model2 loss : 0.021109
[11:49:47.255] iteration 20406 : model1 loss : 0.436500 model2 loss : 0.019736
[11:49:47.424] iteration 20407 : model1 loss : 0.440241 model2 loss : 0.022392
[11:49:47.591] iteration 20408 : model1 loss : 0.439831 model2 loss : 0.022867
[11:49:47.759] iteration 20409 : model1 loss : 0.432220 model2 loss : 0.020472
[11:49:47.929] iteration 20410 : model1 loss : 0.437223 model2 loss : 0.021233
[11:49:48.097] iteration 20411 : model1 loss : 0.435167 model2 loss : 0.020709
[11:49:48.276] iteration 20412 : model1 loss : 0.439788 model2 loss : 0.022563
[11:49:48.446] iteration 20413 : model1 loss : 0.438023 model2 loss : 0.020563
[11:49:48.617] iteration 20414 : model1 loss : 0.436683 model2 loss : 0.022558
[11:49:48.785] iteration 20415 : model1 loss : 0.433675 model2 loss : 0.020321
[11:49:48.954] iteration 20416 : model1 loss : 0.442924 model2 loss : 0.022461
[11:49:49.122] iteration 20417 : model1 loss : 0.438271 model2 loss : 0.020245
[11:49:49.291] iteration 20418 : model1 loss : 0.439869 model2 loss : 0.019759
[11:49:49.461] iteration 20419 : model1 loss : 0.440042 model2 loss : 0.021751
[11:49:49.628] iteration 20420 : model1 loss : 0.437174 model2 loss : 0.020547
[11:49:49.798] iteration 20421 : model1 loss : 0.438890 model2 loss : 0.022050
[11:49:49.967] iteration 20422 : model1 loss : 0.439463 model2 loss : 0.019026
[11:49:50.138] iteration 20423 : model1 loss : 0.443377 model2 loss : 0.023521
[11:49:50.304] iteration 20424 : model1 loss : 0.439062 model2 loss : 0.022138
[11:49:50.474] iteration 20425 : model1 loss : 0.436677 model2 loss : 0.022300
[11:49:50.641] iteration 20426 : model1 loss : 0.438150 model2 loss : 0.019734
[11:49:50.809] iteration 20427 : model1 loss : 0.441282 model2 loss : 0.022728
[11:49:52.721] iteration 20428 : model1 loss : 0.443364 model2 loss : 0.022950
[11:49:52.895] iteration 20429 : model1 loss : 0.441140 model2 loss : 0.023352
[11:49:53.064] iteration 20430 : model1 loss : 0.434900 model2 loss : 0.019087
[11:49:53.231] iteration 20431 : model1 loss : 0.439993 model2 loss : 0.021411
[11:49:53.399] iteration 20432 : model1 loss : 0.436969 model2 loss : 0.020924
[11:49:53.566] iteration 20433 : model1 loss : 0.436403 model2 loss : 0.021266
[11:49:53.735] iteration 20434 : model1 loss : 0.437338 model2 loss : 0.017475
[11:49:53.903] iteration 20435 : model1 loss : 0.441667 model2 loss : 0.023913
[11:49:54.073] iteration 20436 : model1 loss : 0.436622 model2 loss : 0.018095
[11:49:54.243] iteration 20437 : model1 loss : 0.435397 model2 loss : 0.020869
[11:49:54.413] iteration 20438 : model1 loss : 0.439212 model2 loss : 0.022783
[11:49:54.580] iteration 20439 : model1 loss : 0.439457 model2 loss : 0.019969
[11:49:54.749] iteration 20440 : model1 loss : 0.440311 model2 loss : 0.024081
[11:49:54.916] iteration 20441 : model1 loss : 0.433870 model2 loss : 0.021105
[11:49:55.089] iteration 20442 : model1 loss : 0.435956 model2 loss : 0.021460
[11:49:55.260] iteration 20443 : model1 loss : 0.437229 model2 loss : 0.019907
[11:49:55.428] iteration 20444 : model1 loss : 0.437911 model2 loss : 0.022518
[11:49:55.596] iteration 20445 : model1 loss : 0.440571 model2 loss : 0.022406
[11:49:55.766] iteration 20446 : model1 loss : 0.440815 model2 loss : 0.023500
[11:49:55.936] iteration 20447 : model1 loss : 0.437912 model2 loss : 0.022241
[11:49:56.114] iteration 20448 : model1 loss : 0.445687 model2 loss : 0.025727
[11:49:56.282] iteration 20449 : model1 loss : 0.439015 model2 loss : 0.021585
[11:49:56.452] iteration 20450 : model1 loss : 0.435494 model2 loss : 0.018789
[11:49:56.621] iteration 20451 : model1 loss : 0.441450 model2 loss : 0.020135
[11:49:56.791] iteration 20452 : model1 loss : 0.442796 model2 loss : 0.022754
[11:49:56.959] iteration 20453 : model1 loss : 0.440193 model2 loss : 0.023692
[11:49:57.128] iteration 20454 : model1 loss : 0.434652 model2 loss : 0.020295
[11:49:57.297] iteration 20455 : model1 loss : 0.437458 model2 loss : 0.021423
[11:49:57.467] iteration 20456 : model1 loss : 0.435991 model2 loss : 0.019258
[11:49:57.635] iteration 20457 : model1 loss : 0.438327 model2 loss : 0.022308
[11:49:57.805] iteration 20458 : model1 loss : 0.435433 model2 loss : 0.019364
[11:49:57.970] iteration 20459 : model1 loss : 0.437428 model2 loss : 0.020678
[11:49:58.140] iteration 20460 : model1 loss : 0.439147 model2 loss : 0.022971
[11:50:00.077] iteration 20461 : model1 loss : 0.438979 model2 loss : 0.022435
[11:50:00.247] iteration 20462 : model1 loss : 0.437109 model2 loss : 0.021566
[11:50:00.418] iteration 20463 : model1 loss : 0.441891 model2 loss : 0.021214
[11:50:00.585] iteration 20464 : model1 loss : 0.441248 model2 loss : 0.025540
[11:50:00.756] iteration 20465 : model1 loss : 0.439140 model2 loss : 0.022130
[11:50:00.925] iteration 20466 : model1 loss : 0.440051 model2 loss : 0.023316
[11:50:01.095] iteration 20467 : model1 loss : 0.440401 model2 loss : 0.021786
[11:50:01.265] iteration 20468 : model1 loss : 0.433177 model2 loss : 0.020328
[11:50:01.436] iteration 20469 : model1 loss : 0.441771 model2 loss : 0.025320
[11:50:01.604] iteration 20470 : model1 loss : 0.437737 model2 loss : 0.022434
[11:50:01.772] iteration 20471 : model1 loss : 0.443112 model2 loss : 0.022405
[11:50:01.939] iteration 20472 : model1 loss : 0.437633 model2 loss : 0.021431
[11:50:02.108] iteration 20473 : model1 loss : 0.438866 model2 loss : 0.019280
[11:50:02.281] iteration 20474 : model1 loss : 0.436532 model2 loss : 0.022504
[11:50:02.453] iteration 20475 : model1 loss : 0.439263 model2 loss : 0.022532
[11:50:02.620] iteration 20476 : model1 loss : 0.434144 model2 loss : 0.019907
[11:50:02.789] iteration 20477 : model1 loss : 0.440323 model2 loss : 0.022249
[11:50:02.958] iteration 20478 : model1 loss : 0.440169 model2 loss : 0.020744
[11:50:03.129] iteration 20479 : model1 loss : 0.438337 model2 loss : 0.022386
[11:50:03.295] iteration 20480 : model1 loss : 0.439473 model2 loss : 0.027574
[11:50:03.464] iteration 20481 : model1 loss : 0.438248 model2 loss : 0.020688
[11:50:03.630] iteration 20482 : model1 loss : 0.433545 model2 loss : 0.021812
[11:50:03.801] iteration 20483 : model1 loss : 0.433179 model2 loss : 0.020867
[11:50:03.974] iteration 20484 : model1 loss : 0.441174 model2 loss : 0.021697
[11:50:04.143] iteration 20485 : model1 loss : 0.439009 model2 loss : 0.020875
[11:50:04.311] iteration 20486 : model1 loss : 0.436375 model2 loss : 0.020411
[11:50:04.480] iteration 20487 : model1 loss : 0.437958 model2 loss : 0.021658
[11:50:04.648] iteration 20488 : model1 loss : 0.441537 model2 loss : 0.022313
[11:50:04.818] iteration 20489 : model1 loss : 0.440557 model2 loss : 0.022186
[11:50:04.984] iteration 20490 : model1 loss : 0.442172 model2 loss : 0.024621
[11:50:05.155] iteration 20491 : model1 loss : 0.434939 model2 loss : 0.021424
[11:50:05.321] iteration 20492 : model1 loss : 0.438105 model2 loss : 0.020409
[11:50:05.490] iteration 20493 : model1 loss : 0.436547 model2 loss : 0.021452
[11:50:07.450] iteration 20494 : model1 loss : 0.443989 model2 loss : 0.024171
[11:50:07.620] iteration 20495 : model1 loss : 0.437112 model2 loss : 0.022389
[11:50:07.790] iteration 20496 : model1 loss : 0.435799 model2 loss : 0.021439
[11:50:07.958] iteration 20497 : model1 loss : 0.431470 model2 loss : 0.019920
[11:50:08.127] iteration 20498 : model1 loss : 0.440049 model2 loss : 0.022355
[11:50:08.298] iteration 20499 : model1 loss : 0.437574 model2 loss : 0.021721
[11:50:08.467] iteration 20500 : model1 loss : 0.441820 model2 loss : 0.023948
[11:50:08.634] iteration 20501 : model1 loss : 0.437862 model2 loss : 0.020272
[11:50:08.804] iteration 20502 : model1 loss : 0.440415 model2 loss : 0.020978
[11:50:08.972] iteration 20503 : model1 loss : 0.441272 model2 loss : 0.024975
[11:50:09.143] iteration 20504 : model1 loss : 0.440353 model2 loss : 0.019651
[11:50:09.312] iteration 20505 : model1 loss : 0.437713 model2 loss : 0.020905
[11:50:09.483] iteration 20506 : model1 loss : 0.438091 model2 loss : 0.022540
[11:50:09.652] iteration 20507 : model1 loss : 0.440866 model2 loss : 0.024685
[11:50:09.822] iteration 20508 : model1 loss : 0.436203 model2 loss : 0.020277
[11:50:09.989] iteration 20509 : model1 loss : 0.437687 model2 loss : 0.020471
[11:50:10.158] iteration 20510 : model1 loss : 0.442047 model2 loss : 0.021243
[11:50:10.325] iteration 20511 : model1 loss : 0.439181 model2 loss : 0.020956
[11:50:10.497] iteration 20512 : model1 loss : 0.437518 model2 loss : 0.022067
[11:50:10.663] iteration 20513 : model1 loss : 0.436346 model2 loss : 0.021429
[11:50:10.833] iteration 20514 : model1 loss : 0.441736 model2 loss : 0.023509
[11:50:11.002] iteration 20515 : model1 loss : 0.437922 model2 loss : 0.020445
[11:50:11.169] iteration 20516 : model1 loss : 0.436690 model2 loss : 0.021422
[11:50:11.338] iteration 20517 : model1 loss : 0.441337 model2 loss : 0.021065
[11:50:11.506] iteration 20518 : model1 loss : 0.439780 model2 loss : 0.020227
[11:50:11.673] iteration 20519 : model1 loss : 0.438234 model2 loss : 0.023834
[11:50:11.846] iteration 20520 : model1 loss : 0.435994 model2 loss : 0.019643
[11:50:12.013] iteration 20521 : model1 loss : 0.437342 model2 loss : 0.025143
[11:50:12.185] iteration 20522 : model1 loss : 0.437273 model2 loss : 0.021977
[11:50:12.354] iteration 20523 : model1 loss : 0.438053 model2 loss : 0.020352
[11:50:12.525] iteration 20524 : model1 loss : 0.436654 model2 loss : 0.018952
[11:50:12.694] iteration 20525 : model1 loss : 0.439256 model2 loss : 0.022333
[11:50:12.865] iteration 20526 : model1 loss : 0.438757 model2 loss : 0.022065
[11:50:14.787] iteration 20527 : model1 loss : 0.435605 model2 loss : 0.020683
[11:50:14.956] iteration 20528 : model1 loss : 0.446919 model2 loss : 0.027495
[11:50:15.126] iteration 20529 : model1 loss : 0.436334 model2 loss : 0.021435
[11:50:15.295] iteration 20530 : model1 loss : 0.440786 model2 loss : 0.019816
[11:50:15.464] iteration 20531 : model1 loss : 0.436470 model2 loss : 0.021572
[11:50:15.632] iteration 20532 : model1 loss : 0.435278 model2 loss : 0.023450
[11:50:15.801] iteration 20533 : model1 loss : 0.438979 model2 loss : 0.021090
[11:50:15.969] iteration 20534 : model1 loss : 0.440081 model2 loss : 0.022070
[11:50:16.138] iteration 20535 : model1 loss : 0.437092 model2 loss : 0.021877
[11:50:16.305] iteration 20536 : model1 loss : 0.434505 model2 loss : 0.022993
[11:50:16.474] iteration 20537 : model1 loss : 0.435744 model2 loss : 0.020008
[11:50:16.642] iteration 20538 : model1 loss : 0.438026 model2 loss : 0.020531
[11:50:16.812] iteration 20539 : model1 loss : 0.437365 model2 loss : 0.020972
[11:50:16.977] iteration 20540 : model1 loss : 0.439474 model2 loss : 0.019950
[11:50:17.146] iteration 20541 : model1 loss : 0.437219 model2 loss : 0.021339
[11:50:17.316] iteration 20542 : model1 loss : 0.438532 model2 loss : 0.020583
[11:50:17.485] iteration 20543 : model1 loss : 0.440188 model2 loss : 0.020433
[11:50:17.652] iteration 20544 : model1 loss : 0.435626 model2 loss : 0.020508
[11:50:17.821] iteration 20545 : model1 loss : 0.445050 model2 loss : 0.026245
[11:50:17.988] iteration 20546 : model1 loss : 0.436554 model2 loss : 0.020043
[11:50:18.157] iteration 20547 : model1 loss : 0.442432 model2 loss : 0.023746
[11:50:18.327] iteration 20548 : model1 loss : 0.437509 model2 loss : 0.020962
[11:50:18.497] iteration 20549 : model1 loss : 0.439556 model2 loss : 0.021529
[11:50:18.664] iteration 20550 : model1 loss : 0.437222 model2 loss : 0.025695
[11:50:18.833] iteration 20551 : model1 loss : 0.437930 model2 loss : 0.019457
[11:50:19.000] iteration 20552 : model1 loss : 0.441735 model2 loss : 0.022162
[11:50:19.168] iteration 20553 : model1 loss : 0.440930 model2 loss : 0.024063
[11:50:19.339] iteration 20554 : model1 loss : 0.445776 model2 loss : 0.019662
[11:50:19.509] iteration 20555 : model1 loss : 0.433568 model2 loss : 0.019686
[11:50:19.676] iteration 20556 : model1 loss : 0.440414 model2 loss : 0.018612
[11:50:19.845] iteration 20557 : model1 loss : 0.435094 model2 loss : 0.021208
[11:50:20.011] iteration 20558 : model1 loss : 0.438064 model2 loss : 0.023511
[11:50:20.178] iteration 20559 : model1 loss : 0.439016 model2 loss : 0.022647
[11:50:22.126] iteration 20560 : model1 loss : 0.437975 model2 loss : 0.021699
[11:50:22.294] iteration 20561 : model1 loss : 0.437907 model2 loss : 0.020903
[11:50:22.465] iteration 20562 : model1 loss : 0.435084 model2 loss : 0.018677
[11:50:22.632] iteration 20563 : model1 loss : 0.439118 model2 loss : 0.020277
[11:50:22.802] iteration 20564 : model1 loss : 0.439899 model2 loss : 0.020263
[11:50:22.969] iteration 20565 : model1 loss : 0.436728 model2 loss : 0.018973
[11:50:23.137] iteration 20566 : model1 loss : 0.438507 model2 loss : 0.020471
[11:50:23.306] iteration 20567 : model1 loss : 0.438972 model2 loss : 0.018756
[11:50:23.476] iteration 20568 : model1 loss : 0.439999 model2 loss : 0.020040
[11:50:23.642] iteration 20569 : model1 loss : 0.436254 model2 loss : 0.020084
[11:50:23.814] iteration 20570 : model1 loss : 0.440243 model2 loss : 0.021304
[11:50:23.983] iteration 20571 : model1 loss : 0.436849 model2 loss : 0.019930
[11:50:24.153] iteration 20572 : model1 loss : 0.436849 model2 loss : 0.021649
[11:50:24.322] iteration 20573 : model1 loss : 0.437977 model2 loss : 0.019855
[11:50:24.491] iteration 20574 : model1 loss : 0.438348 model2 loss : 0.021424
[11:50:24.657] iteration 20575 : model1 loss : 0.444172 model2 loss : 0.023952
[11:50:24.826] iteration 20576 : model1 loss : 0.438276 model2 loss : 0.023731
[11:50:24.993] iteration 20577 : model1 loss : 0.437803 model2 loss : 0.020501
[11:50:25.163] iteration 20578 : model1 loss : 0.437730 model2 loss : 0.020602
[11:50:25.332] iteration 20579 : model1 loss : 0.441155 model2 loss : 0.024078
[11:50:25.500] iteration 20580 : model1 loss : 0.438608 model2 loss : 0.023089
[11:50:25.668] iteration 20581 : model1 loss : 0.443535 model2 loss : 0.023565
[11:50:25.836] iteration 20582 : model1 loss : 0.434109 model2 loss : 0.020668
[11:50:26.004] iteration 20583 : model1 loss : 0.438728 model2 loss : 0.020647
[11:50:26.172] iteration 20584 : model1 loss : 0.439303 model2 loss : 0.022745
[11:50:26.342] iteration 20585 : model1 loss : 0.438971 model2 loss : 0.021650
[11:50:26.514] iteration 20586 : model1 loss : 0.437893 model2 loss : 0.021401
[11:50:26.681] iteration 20587 : model1 loss : 0.439686 model2 loss : 0.021477
[11:50:26.851] iteration 20588 : model1 loss : 0.436412 model2 loss : 0.020808
[11:50:27.019] iteration 20589 : model1 loss : 0.438429 model2 loss : 0.020361
[11:50:27.187] iteration 20590 : model1 loss : 0.441442 model2 loss : 0.021945
[11:50:27.357] iteration 20591 : model1 loss : 0.437742 model2 loss : 0.020024
[11:50:27.525] iteration 20592 : model1 loss : 0.437713 model2 loss : 0.024052
[11:50:29.461] iteration 20593 : model1 loss : 0.439242 model2 loss : 0.020399
[11:50:29.647] iteration 20594 : model1 loss : 0.437320 model2 loss : 0.019452
[11:50:29.817] iteration 20595 : model1 loss : 0.439420 model2 loss : 0.023088
[11:50:29.984] iteration 20596 : model1 loss : 0.435370 model2 loss : 0.020095
[11:50:30.154] iteration 20597 : model1 loss : 0.434270 model2 loss : 0.020872
[11:50:30.323] iteration 20598 : model1 loss : 0.437433 model2 loss : 0.018217
[11:50:30.493] iteration 20599 : model1 loss : 0.441198 model2 loss : 0.022117
[11:50:30.661] iteration 20600 : model1 loss : 0.443275 model2 loss : 0.022702
[11:50:30.830] iteration 20601 : model1 loss : 0.434659 model2 loss : 0.021486
[11:50:30.999] iteration 20602 : model1 loss : 0.438568 model2 loss : 0.022251
[11:50:31.167] iteration 20603 : model1 loss : 0.441527 model2 loss : 0.021577
[11:50:31.333] iteration 20604 : model1 loss : 0.435930 model2 loss : 0.021037
[11:50:31.504] iteration 20605 : model1 loss : 0.438657 model2 loss : 0.021430
[11:50:31.671] iteration 20606 : model1 loss : 0.438931 model2 loss : 0.023872
[11:50:31.840] iteration 20607 : model1 loss : 0.438676 model2 loss : 0.021305
[11:50:32.006] iteration 20608 : model1 loss : 0.439265 model2 loss : 0.020068
[11:50:32.175] iteration 20609 : model1 loss : 0.433845 model2 loss : 0.018904
[11:50:32.345] iteration 20610 : model1 loss : 0.441042 model2 loss : 0.022433
[11:50:32.515] iteration 20611 : model1 loss : 0.442540 model2 loss : 0.021998
[11:50:32.680] iteration 20612 : model1 loss : 0.443169 model2 loss : 0.024725
[11:50:32.848] iteration 20613 : model1 loss : 0.436785 model2 loss : 0.020755
[11:50:33.015] iteration 20614 : model1 loss : 0.445800 model2 loss : 0.026449
[11:50:33.185] iteration 20615 : model1 loss : 0.440247 model2 loss : 0.022733
[11:50:33.354] iteration 20616 : model1 loss : 0.436739 model2 loss : 0.021308
[11:50:33.526] iteration 20617 : model1 loss : 0.437848 model2 loss : 0.021775
[11:50:33.693] iteration 20618 : model1 loss : 0.437529 model2 loss : 0.019988
[11:50:33.863] iteration 20619 : model1 loss : 0.438841 model2 loss : 0.019807
[11:50:34.044] iteration 20620 : model1 loss : 0.440738 model2 loss : 0.041023
[11:50:34.214] iteration 20621 : model1 loss : 0.439799 model2 loss : 0.023867
[11:50:34.383] iteration 20622 : model1 loss : 0.437280 model2 loss : 0.028286
[11:50:34.552] iteration 20623 : model1 loss : 0.434576 model2 loss : 0.021644
[11:50:34.719] iteration 20624 : model1 loss : 0.438738 model2 loss : 0.022352
[11:50:34.887] iteration 20625 : model1 loss : 0.440829 model2 loss : 0.022517
[11:50:36.804] iteration 20626 : model1 loss : 0.434612 model2 loss : 0.021171
[11:50:36.972] iteration 20627 : model1 loss : 0.437605 model2 loss : 0.023522
[11:50:37.146] iteration 20628 : model1 loss : 0.442068 model2 loss : 0.031687
[11:50:37.313] iteration 20629 : model1 loss : 0.436337 model2 loss : 0.023039
[11:50:37.482] iteration 20630 : model1 loss : 0.438868 model2 loss : 0.021929
[11:50:37.649] iteration 20631 : model1 loss : 0.441853 model2 loss : 0.021046
[11:50:37.819] iteration 20632 : model1 loss : 0.440365 model2 loss : 0.022402
[11:50:37.988] iteration 20633 : model1 loss : 0.438832 model2 loss : 0.023095
[11:50:38.158] iteration 20634 : model1 loss : 0.437963 model2 loss : 0.024651
[11:50:38.324] iteration 20635 : model1 loss : 0.437658 model2 loss : 0.027289
[11:50:38.497] iteration 20636 : model1 loss : 0.442438 model2 loss : 0.024572
[11:50:38.664] iteration 20637 : model1 loss : 0.441937 model2 loss : 0.024930
[11:50:38.833] iteration 20638 : model1 loss : 0.438752 model2 loss : 0.024743
[11:50:39.000] iteration 20639 : model1 loss : 0.438480 model2 loss : 0.021480
[11:50:39.169] iteration 20640 : model1 loss : 0.438721 model2 loss : 0.024638
[11:50:39.336] iteration 20641 : model1 loss : 0.442245 model2 loss : 0.025019
[11:50:39.506] iteration 20642 : model1 loss : 0.437532 model2 loss : 0.025787
[11:50:39.676] iteration 20643 : model1 loss : 0.435046 model2 loss : 0.022721
[11:50:39.846] iteration 20644 : model1 loss : 0.437455 model2 loss : 0.023344
[11:50:40.015] iteration 20645 : model1 loss : 0.440282 model2 loss : 0.027727
[11:50:40.185] iteration 20646 : model1 loss : 0.441313 model2 loss : 0.024983
[11:50:40.353] iteration 20647 : model1 loss : 0.436516 model2 loss : 0.021336
[11:50:40.527] iteration 20648 : model1 loss : 0.436465 model2 loss : 0.022870
[11:50:40.694] iteration 20649 : model1 loss : 0.438857 model2 loss : 0.024046
[11:50:40.864] iteration 20650 : model1 loss : 0.441013 model2 loss : 0.024053
[11:50:41.032] iteration 20651 : model1 loss : 0.437291 model2 loss : 0.025165
[11:50:41.201] iteration 20652 : model1 loss : 0.439000 model2 loss : 0.023854
[11:50:41.369] iteration 20653 : model1 loss : 0.441641 model2 loss : 0.025103
[11:50:41.540] iteration 20654 : model1 loss : 0.436040 model2 loss : 0.022829
[11:50:41.707] iteration 20655 : model1 loss : 0.436722 model2 loss : 0.021058
[11:50:41.877] iteration 20656 : model1 loss : 0.436306 model2 loss : 0.023635
[11:50:42.042] iteration 20657 : model1 loss : 0.440912 model2 loss : 0.025751
[11:50:42.212] iteration 20658 : model1 loss : 0.444817 model2 loss : 0.028607
[11:50:44.148] iteration 20659 : model1 loss : 0.436346 model2 loss : 0.021520
[11:50:44.315] iteration 20660 : model1 loss : 0.437536 model2 loss : 0.020596
[11:50:44.484] iteration 20661 : model1 loss : 0.439562 model2 loss : 0.023370
[11:50:44.653] iteration 20662 : model1 loss : 0.437857 model2 loss : 0.022159
[11:50:44.822] iteration 20663 : model1 loss : 0.439484 model2 loss : 0.022297
[11:50:44.989] iteration 20664 : model1 loss : 0.444161 model2 loss : 0.026442
[11:50:45.157] iteration 20665 : model1 loss : 0.438015 model2 loss : 0.024412
[11:50:45.324] iteration 20666 : model1 loss : 0.436947 model2 loss : 0.020305
[11:50:45.494] iteration 20667 : model1 loss : 0.434145 model2 loss : 0.020591
[11:50:45.662] iteration 20668 : model1 loss : 0.438111 model2 loss : 0.024710
[11:50:45.832] iteration 20669 : model1 loss : 0.436794 model2 loss : 0.024374
[11:50:45.998] iteration 20670 : model1 loss : 0.438146 model2 loss : 0.021952
[11:50:46.165] iteration 20671 : model1 loss : 0.438116 model2 loss : 0.022389
[11:50:46.331] iteration 20672 : model1 loss : 0.436402 model2 loss : 0.021637
[11:50:46.506] iteration 20673 : model1 loss : 0.439762 model2 loss : 0.022488
[11:50:46.673] iteration 20674 : model1 loss : 0.442324 model2 loss : 0.025733
[11:50:46.843] iteration 20675 : model1 loss : 0.439866 model2 loss : 0.023031
[11:50:47.010] iteration 20676 : model1 loss : 0.440975 model2 loss : 0.025055
[11:50:47.179] iteration 20677 : model1 loss : 0.440997 model2 loss : 0.025247
[11:50:47.346] iteration 20678 : model1 loss : 0.439615 model2 loss : 0.022309
[11:50:47.518] iteration 20679 : model1 loss : 0.435602 model2 loss : 0.021754
[11:50:47.686] iteration 20680 : model1 loss : 0.438820 model2 loss : 0.021687
[11:50:47.854] iteration 20681 : model1 loss : 0.436402 model2 loss : 0.021445
[11:50:48.022] iteration 20682 : model1 loss : 0.444290 model2 loss : 0.023097
[11:50:48.190] iteration 20683 : model1 loss : 0.438128 model2 loss : 0.020594
[11:50:48.358] iteration 20684 : model1 loss : 0.437224 model2 loss : 0.022835
[11:50:48.532] iteration 20685 : model1 loss : 0.439517 model2 loss : 0.022353
[11:50:48.700] iteration 20686 : model1 loss : 0.440843 model2 loss : 0.023390
[11:50:48.869] iteration 20687 : model1 loss : 0.438795 model2 loss : 0.022313
[11:50:49.035] iteration 20688 : model1 loss : 0.439328 model2 loss : 0.022419
[11:50:49.203] iteration 20689 : model1 loss : 0.441686 model2 loss : 0.021698
[11:50:49.371] iteration 20690 : model1 loss : 0.435808 model2 loss : 0.022008
[11:50:49.542] iteration 20691 : model1 loss : 0.431985 model2 loss : 0.022159
[11:50:51.516] iteration 20692 : model1 loss : 0.440573 model2 loss : 0.021726
[11:50:51.684] iteration 20693 : model1 loss : 0.435233 model2 loss : 0.021183
[11:50:51.855] iteration 20694 : model1 loss : 0.441975 model2 loss : 0.023581
[11:50:52.020] iteration 20695 : model1 loss : 0.437465 model2 loss : 0.019566
[11:50:52.189] iteration 20696 : model1 loss : 0.435085 model2 loss : 0.020745
[11:50:52.356] iteration 20697 : model1 loss : 0.441336 model2 loss : 0.025235
[11:50:52.527] iteration 20698 : model1 loss : 0.441663 model2 loss : 0.025683
[11:50:52.692] iteration 20699 : model1 loss : 0.440211 model2 loss : 0.022507
[11:50:52.861] iteration 20700 : model1 loss : 0.439894 model2 loss : 0.021872
[11:50:53.027] iteration 20701 : model1 loss : 0.440961 model2 loss : 0.023440
[11:50:53.193] iteration 20702 : model1 loss : 0.435987 model2 loss : 0.021844
[11:50:53.361] iteration 20703 : model1 loss : 0.439650 model2 loss : 0.022577
[11:50:53.535] iteration 20704 : model1 loss : 0.436598 model2 loss : 0.022000
[11:50:53.702] iteration 20705 : model1 loss : 0.435105 model2 loss : 0.023484
[11:50:53.872] iteration 20706 : model1 loss : 0.439544 model2 loss : 0.021482
[11:50:54.038] iteration 20707 : model1 loss : 0.440607 model2 loss : 0.023413
[11:50:54.207] iteration 20708 : model1 loss : 0.434524 model2 loss : 0.019557
[11:50:54.374] iteration 20709 : model1 loss : 0.443004 model2 loss : 0.021286
[11:50:54.543] iteration 20710 : model1 loss : 0.436167 model2 loss : 0.019998
[11:50:54.708] iteration 20711 : model1 loss : 0.440515 model2 loss : 0.024353
[11:50:54.877] iteration 20712 : model1 loss : 0.437489 model2 loss : 0.023534
[11:50:55.044] iteration 20713 : model1 loss : 0.436786 model2 loss : 0.021237
[11:50:55.214] iteration 20714 : model1 loss : 0.442493 model2 loss : 0.022911
[11:50:55.380] iteration 20715 : model1 loss : 0.436362 model2 loss : 0.020856
[11:50:55.551] iteration 20716 : model1 loss : 0.437947 model2 loss : 0.023759
[11:50:55.733] iteration 20717 : model1 loss : 0.437721 model2 loss : 0.020954
[11:50:55.903] iteration 20718 : model1 loss : 0.443373 model2 loss : 0.024204
[11:50:56.071] iteration 20719 : model1 loss : 0.438605 model2 loss : 0.022579
[11:50:56.240] iteration 20720 : model1 loss : 0.435658 model2 loss : 0.020088
[11:50:56.409] iteration 20721 : model1 loss : 0.440521 model2 loss : 0.020393
[11:50:56.580] iteration 20722 : model1 loss : 0.439704 model2 loss : 0.023938
[11:50:56.747] iteration 20723 : model1 loss : 0.444633 model2 loss : 0.027976
[11:50:56.915] iteration 20724 : model1 loss : 0.433523 model2 loss : 0.020578
[11:50:58.826] iteration 20725 : model1 loss : 0.438558 model2 loss : 0.021477
[11:50:58.993] iteration 20726 : model1 loss : 0.439218 model2 loss : 0.022812
[11:50:59.164] iteration 20727 : model1 loss : 0.437110 model2 loss : 0.020272
[11:50:59.329] iteration 20728 : model1 loss : 0.437371 model2 loss : 0.021067
[11:50:59.505] iteration 20729 : model1 loss : 0.436819 model2 loss : 0.021857
[11:50:59.671] iteration 20730 : model1 loss : 0.435325 model2 loss : 0.021408
[11:50:59.838] iteration 20731 : model1 loss : 0.436013 model2 loss : 0.019245
[11:51:00.006] iteration 20732 : model1 loss : 0.436647 model2 loss : 0.021453
[11:51:00.177] iteration 20733 : model1 loss : 0.446908 model2 loss : 0.020826
[11:51:00.343] iteration 20734 : model1 loss : 0.439131 model2 loss : 0.021731
[11:51:00.516] iteration 20735 : model1 loss : 0.436844 model2 loss : 0.020198
[11:51:00.685] iteration 20736 : model1 loss : 0.436258 model2 loss : 0.020714
[11:51:00.854] iteration 20737 : model1 loss : 0.439258 model2 loss : 0.023571
[11:51:01.023] iteration 20738 : model1 loss : 0.431542 model2 loss : 0.019463
[11:51:01.194] iteration 20739 : model1 loss : 0.437248 model2 loss : 0.021074
[11:51:01.363] iteration 20740 : model1 loss : 0.434568 model2 loss : 0.019793
[11:51:01.534] iteration 20741 : model1 loss : 0.440677 model2 loss : 0.025676
[11:51:01.701] iteration 20742 : model1 loss : 0.440102 model2 loss : 0.020543
[11:51:01.883] iteration 20743 : model1 loss : 0.443433 model2 loss : 0.022852
[11:51:02.050] iteration 20744 : model1 loss : 0.435813 model2 loss : 0.021276
[11:51:02.219] iteration 20745 : model1 loss : 0.443105 model2 loss : 0.021830
[11:51:02.386] iteration 20746 : model1 loss : 0.441271 model2 loss : 0.020574
[11:51:02.555] iteration 20747 : model1 loss : 0.441924 model2 loss : 0.023508
[11:51:02.721] iteration 20748 : model1 loss : 0.438518 model2 loss : 0.019193
[11:51:02.891] iteration 20749 : model1 loss : 0.437615 model2 loss : 0.021926
[11:51:03.056] iteration 20750 : model1 loss : 0.443499 model2 loss : 0.027752
[11:51:03.226] iteration 20751 : model1 loss : 0.436976 model2 loss : 0.021184
[11:51:03.393] iteration 20752 : model1 loss : 0.438443 model2 loss : 0.023568
[11:51:03.562] iteration 20753 : model1 loss : 0.439298 model2 loss : 0.020042
[11:51:03.730] iteration 20754 : model1 loss : 0.437038 model2 loss : 0.022486
[11:51:03.898] iteration 20755 : model1 loss : 0.437595 model2 loss : 0.024065
[11:51:04.066] iteration 20756 : model1 loss : 0.441564 model2 loss : 0.026175
[11:51:04.232] iteration 20757 : model1 loss : 0.438754 model2 loss : 0.023220
[11:51:06.166] iteration 20758 : model1 loss : 0.436990 model2 loss : 0.023792
[11:51:06.335] iteration 20759 : model1 loss : 0.435368 model2 loss : 0.020956
[11:51:06.510] iteration 20760 : model1 loss : 0.438634 model2 loss : 0.022450
[11:51:06.678] iteration 20761 : model1 loss : 0.438155 model2 loss : 0.022807
[11:51:06.847] iteration 20762 : model1 loss : 0.436242 model2 loss : 0.022438
[11:51:07.015] iteration 20763 : model1 loss : 0.439006 model2 loss : 0.021494
[11:51:07.185] iteration 20764 : model1 loss : 0.435645 model2 loss : 0.020956
[11:51:07.353] iteration 20765 : model1 loss : 0.437463 model2 loss : 0.022030
[11:51:07.522] iteration 20766 : model1 loss : 0.439559 model2 loss : 0.021158
[11:51:07.690] iteration 20767 : model1 loss : 0.438888 model2 loss : 0.022169
[11:51:07.861] iteration 20768 : model1 loss : 0.435983 model2 loss : 0.022883
[11:51:08.028] iteration 20769 : model1 loss : 0.438949 model2 loss : 0.022495
[11:51:08.199] iteration 20770 : model1 loss : 0.441065 model2 loss : 0.022249
[11:51:08.366] iteration 20771 : model1 loss : 0.441294 model2 loss : 0.020935
[11:51:08.538] iteration 20772 : model1 loss : 0.436871 model2 loss : 0.021875
[11:51:08.706] iteration 20773 : model1 loss : 0.441781 model2 loss : 0.023529
[11:51:08.875] iteration 20774 : model1 loss : 0.442346 model2 loss : 0.022329
[11:51:09.044] iteration 20775 : model1 loss : 0.440487 model2 loss : 0.024565
[11:51:09.213] iteration 20776 : model1 loss : 0.440372 model2 loss : 0.021351
[11:51:09.380] iteration 20777 : model1 loss : 0.438697 model2 loss : 0.019212
[11:51:09.548] iteration 20778 : model1 loss : 0.441363 model2 loss : 0.022646
[11:51:09.716] iteration 20779 : model1 loss : 0.439427 model2 loss : 0.018038
[11:51:09.886] iteration 20780 : model1 loss : 0.438750 model2 loss : 0.023097
[11:51:10.053] iteration 20781 : model1 loss : 0.434437 model2 loss : 0.022018
[11:51:10.224] iteration 20782 : model1 loss : 0.436884 model2 loss : 0.020112
[11:51:10.391] iteration 20783 : model1 loss : 0.439592 model2 loss : 0.022969
[11:51:10.561] iteration 20784 : model1 loss : 0.441716 model2 loss : 0.022367
[11:51:10.728] iteration 20785 : model1 loss : 0.440654 model2 loss : 0.023907
[11:51:10.899] iteration 20786 : model1 loss : 0.441918 model2 loss : 0.022843
[11:51:11.066] iteration 20787 : model1 loss : 0.439689 model2 loss : 0.022855
[11:51:11.235] iteration 20788 : model1 loss : 0.437200 model2 loss : 0.021207
[11:51:11.402] iteration 20789 : model1 loss : 0.437430 model2 loss : 0.023344
[11:51:11.570] iteration 20790 : model1 loss : 0.439361 model2 loss : 0.019759
[11:51:13.517] iteration 20791 : model1 loss : 0.444732 model2 loss : 0.029262
[11:51:13.685] iteration 20792 : model1 loss : 0.440375 model2 loss : 0.021634
[11:51:13.858] iteration 20793 : model1 loss : 0.440356 model2 loss : 0.024224
[11:51:14.025] iteration 20794 : model1 loss : 0.442728 model2 loss : 0.026478
[11:51:14.195] iteration 20795 : model1 loss : 0.437026 model2 loss : 0.021631
[11:51:14.362] iteration 20796 : model1 loss : 0.437934 model2 loss : 0.022163
[11:51:14.537] iteration 20797 : model1 loss : 0.444059 model2 loss : 0.022276
[11:51:14.719] iteration 20798 : model1 loss : 0.433944 model2 loss : 0.022830
[11:51:14.888] iteration 20799 : model1 loss : 0.439931 model2 loss : 0.021970
[11:51:15.058] iteration 20800 : model1 loss : 0.442985 model2 loss : 0.021477
[11:51:15.227] iteration 20801 : model1 loss : 0.439583 model2 loss : 0.021821
[11:51:15.395] iteration 20802 : model1 loss : 0.438001 model2 loss : 0.025603
[11:51:15.568] iteration 20803 : model1 loss : 0.439860 model2 loss : 0.023238
[11:51:15.734] iteration 20804 : model1 loss : 0.434173 model2 loss : 0.023299
[11:51:15.905] iteration 20805 : model1 loss : 0.439088 model2 loss : 0.020810
[11:51:16.072] iteration 20806 : model1 loss : 0.440613 model2 loss : 0.025672
[11:51:16.241] iteration 20807 : model1 loss : 0.439643 model2 loss : 0.021387
[11:51:16.410] iteration 20808 : model1 loss : 0.444045 model2 loss : 0.024330
[11:51:16.580] iteration 20809 : model1 loss : 0.437586 model2 loss : 0.023898
[11:51:16.747] iteration 20810 : model1 loss : 0.437201 model2 loss : 0.019571
[11:51:16.918] iteration 20811 : model1 loss : 0.440744 model2 loss : 0.021983
[11:51:17.084] iteration 20812 : model1 loss : 0.435454 model2 loss : 0.022930
[11:51:17.255] iteration 20813 : model1 loss : 0.440035 model2 loss : 0.020517
[11:51:17.423] iteration 20814 : model1 loss : 0.435048 model2 loss : 0.022103
[11:51:17.593] iteration 20815 : model1 loss : 0.441519 model2 loss : 0.021337
[11:51:17.762] iteration 20816 : model1 loss : 0.438327 model2 loss : 0.022479
[11:51:17.932] iteration 20817 : model1 loss : 0.437412 model2 loss : 0.020811
[11:51:18.101] iteration 20818 : model1 loss : 0.439578 model2 loss : 0.022421
[11:51:18.269] iteration 20819 : model1 loss : 0.435088 model2 loss : 0.023340
[11:51:18.438] iteration 20820 : model1 loss : 0.441093 model2 loss : 0.023307
[11:51:18.608] iteration 20821 : model1 loss : 0.437709 model2 loss : 0.020262
[11:51:18.774] iteration 20822 : model1 loss : 0.433239 model2 loss : 0.022301
[11:51:18.944] iteration 20823 : model1 loss : 0.436148 model2 loss : 0.025812
[11:51:20.853] iteration 20824 : model1 loss : 0.436459 model2 loss : 0.023957
[11:51:21.019] iteration 20825 : model1 loss : 0.439862 model2 loss : 0.024679
[11:51:21.191] iteration 20826 : model1 loss : 0.443733 model2 loss : 0.027072
[11:51:21.358] iteration 20827 : model1 loss : 0.438037 model2 loss : 0.022084
[11:51:21.532] iteration 20828 : model1 loss : 0.440053 model2 loss : 0.021031
[11:51:21.701] iteration 20829 : model1 loss : 0.441264 model2 loss : 0.023624
[11:51:21.871] iteration 20830 : model1 loss : 0.440939 model2 loss : 0.022066
[11:51:22.039] iteration 20831 : model1 loss : 0.438370 model2 loss : 0.020124
[11:51:22.210] iteration 20832 : model1 loss : 0.441298 model2 loss : 0.021745
[11:51:22.379] iteration 20833 : model1 loss : 0.432985 model2 loss : 0.020928
[11:51:22.553] iteration 20834 : model1 loss : 0.437418 model2 loss : 0.020093
[11:51:22.718] iteration 20835 : model1 loss : 0.435825 model2 loss : 0.021578
[11:51:22.889] iteration 20836 : model1 loss : 0.439000 model2 loss : 0.022167
[11:51:23.055] iteration 20837 : model1 loss : 0.441068 model2 loss : 0.021364
[11:51:23.225] iteration 20838 : model1 loss : 0.435203 model2 loss : 0.021923
[11:51:23.394] iteration 20839 : model1 loss : 0.441044 model2 loss : 0.023173
[11:51:23.565] iteration 20840 : model1 loss : 0.439749 model2 loss : 0.023494
[11:51:23.732] iteration 20841 : model1 loss : 0.439584 model2 loss : 0.024583
[11:51:23.903] iteration 20842 : model1 loss : 0.440266 model2 loss : 0.019202
[11:51:24.070] iteration 20843 : model1 loss : 0.438778 model2 loss : 0.021283
[11:51:24.240] iteration 20844 : model1 loss : 0.440127 model2 loss : 0.021575
[11:51:24.410] iteration 20845 : model1 loss : 0.441907 model2 loss : 0.023222
[11:51:24.582] iteration 20846 : model1 loss : 0.436937 model2 loss : 0.022812
[11:51:24.749] iteration 20847 : model1 loss : 0.436948 model2 loss : 0.020521
[11:51:24.920] iteration 20848 : model1 loss : 0.438294 model2 loss : 0.019730
[11:51:25.087] iteration 20849 : model1 loss : 0.440960 model2 loss : 0.025005
[11:51:25.256] iteration 20850 : model1 loss : 0.436609 model2 loss : 0.022184
[11:51:25.422] iteration 20851 : model1 loss : 0.432303 model2 loss : 0.020741
[11:51:25.589] iteration 20852 : model1 loss : 0.439917 model2 loss : 0.019497
[11:51:25.757] iteration 20853 : model1 loss : 0.434564 model2 loss : 0.019294
[11:51:25.929] iteration 20854 : model1 loss : 0.445321 model2 loss : 0.024203
[11:51:26.095] iteration 20855 : model1 loss : 0.436566 model2 loss : 0.020262
[11:51:26.263] iteration 20856 : model1 loss : 0.438310 model2 loss : 0.022815
[11:51:28.187] iteration 20857 : model1 loss : 0.436257 model2 loss : 0.019997
[11:51:28.355] iteration 20858 : model1 loss : 0.436301 model2 loss : 0.020184
[11:51:28.526] iteration 20859 : model1 loss : 0.438410 model2 loss : 0.021488
[11:51:28.693] iteration 20860 : model1 loss : 0.442938 model2 loss : 0.025570
[11:51:28.863] iteration 20861 : model1 loss : 0.442785 model2 loss : 0.022735
[11:51:29.031] iteration 20862 : model1 loss : 0.445089 model2 loss : 0.028319
[11:51:29.201] iteration 20863 : model1 loss : 0.441075 model2 loss : 0.023621
[11:51:29.385] iteration 20864 : model1 loss : 0.437945 model2 loss : 0.023628
[11:51:29.558] iteration 20865 : model1 loss : 0.437435 model2 loss : 0.023884
[11:51:29.723] iteration 20866 : model1 loss : 0.434903 model2 loss : 0.022982
[11:51:29.893] iteration 20867 : model1 loss : 0.435557 model2 loss : 0.020985
[11:51:30.059] iteration 20868 : model1 loss : 0.431580 model2 loss : 0.021591
[11:51:30.231] iteration 20869 : model1 loss : 0.442206 model2 loss : 0.022913
[11:51:30.399] iteration 20870 : model1 loss : 0.438615 model2 loss : 0.024487
[11:51:30.572] iteration 20871 : model1 loss : 0.437960 model2 loss : 0.020431
[11:51:30.738] iteration 20872 : model1 loss : 0.439983 model2 loss : 0.019661
[11:51:30.910] iteration 20873 : model1 loss : 0.436127 model2 loss : 0.022088
[11:51:31.079] iteration 20874 : model1 loss : 0.438130 model2 loss : 0.022390
[11:51:31.248] iteration 20875 : model1 loss : 0.438950 model2 loss : 0.021967
[11:51:31.415] iteration 20876 : model1 loss : 0.438420 model2 loss : 0.022633
[11:51:31.585] iteration 20877 : model1 loss : 0.441500 model2 loss : 0.021090
[11:51:31.752] iteration 20878 : model1 loss : 0.438035 model2 loss : 0.020607
[11:51:31.920] iteration 20879 : model1 loss : 0.440286 model2 loss : 0.020261
[11:51:32.088] iteration 20880 : model1 loss : 0.441177 model2 loss : 0.023433
[11:51:32.258] iteration 20881 : model1 loss : 0.442109 model2 loss : 0.021374
[11:51:32.427] iteration 20882 : model1 loss : 0.439744 model2 loss : 0.019985
[11:51:32.596] iteration 20883 : model1 loss : 0.440485 model2 loss : 0.022287
[11:51:32.763] iteration 20884 : model1 loss : 0.438971 model2 loss : 0.023694
[11:51:32.933] iteration 20885 : model1 loss : 0.437327 model2 loss : 0.020535
[11:51:33.099] iteration 20886 : model1 loss : 0.437935 model2 loss : 0.025445
[11:51:33.269] iteration 20887 : model1 loss : 0.438483 model2 loss : 0.022903
[11:51:33.436] iteration 20888 : model1 loss : 0.439235 model2 loss : 0.021261
[11:51:33.604] iteration 20889 : model1 loss : 0.438939 model2 loss : 0.021813
[11:51:35.519] iteration 20890 : model1 loss : 0.440534 model2 loss : 0.023556
[11:51:35.686] iteration 20891 : model1 loss : 0.439396 model2 loss : 0.019185
[11:51:35.857] iteration 20892 : model1 loss : 0.435019 model2 loss : 0.021367
[11:51:36.024] iteration 20893 : model1 loss : 0.437211 model2 loss : 0.021054
[11:51:36.192] iteration 20894 : model1 loss : 0.443460 model2 loss : 0.022774
[11:51:36.360] iteration 20895 : model1 loss : 0.442890 model2 loss : 0.023711
[11:51:36.534] iteration 20896 : model1 loss : 0.438729 model2 loss : 0.021788
[11:51:36.701] iteration 20897 : model1 loss : 0.436083 model2 loss : 0.019787
[11:51:36.872] iteration 20898 : model1 loss : 0.438939 model2 loss : 0.020255
[11:51:37.038] iteration 20899 : model1 loss : 0.439286 model2 loss : 0.020402
[11:51:37.208] iteration 20900 : model1 loss : 0.441360 model2 loss : 0.024143
[11:51:37.377] iteration 20901 : model1 loss : 0.437504 model2 loss : 0.022883
[11:51:37.552] iteration 20902 : model1 loss : 0.435743 model2 loss : 0.021562
[11:51:37.720] iteration 20903 : model1 loss : 0.438230 model2 loss : 0.020876
[11:51:37.888] iteration 20904 : model1 loss : 0.437354 model2 loss : 0.018901
[11:51:38.056] iteration 20905 : model1 loss : 0.436731 model2 loss : 0.023203
[11:51:38.227] iteration 20906 : model1 loss : 0.437665 model2 loss : 0.024042
[11:51:38.394] iteration 20907 : model1 loss : 0.437861 model2 loss : 0.022458
[11:51:38.569] iteration 20908 : model1 loss : 0.432744 model2 loss : 0.017768
[11:51:38.736] iteration 20909 : model1 loss : 0.438092 model2 loss : 0.019944
[11:51:38.905] iteration 20910 : model1 loss : 0.445187 model2 loss : 0.020946
[11:51:39.073] iteration 20911 : model1 loss : 0.440438 model2 loss : 0.024112
[11:51:39.241] iteration 20912 : model1 loss : 0.437132 model2 loss : 0.021506
[11:51:39.410] iteration 20913 : model1 loss : 0.438777 model2 loss : 0.022573
[11:51:39.579] iteration 20914 : model1 loss : 0.439487 model2 loss : 0.022925
[11:51:39.747] iteration 20915 : model1 loss : 0.431989 model2 loss : 0.021293
[11:51:39.917] iteration 20916 : model1 loss : 0.444100 model2 loss : 0.023466
[11:51:40.094] iteration 20917 : model1 loss : 0.438802 model2 loss : 0.023348
[11:51:40.265] iteration 20918 : model1 loss : 0.441051 model2 loss : 0.027098
[11:51:40.433] iteration 20919 : model1 loss : 0.443260 model2 loss : 0.022179
[11:51:40.602] iteration 20920 : model1 loss : 0.439073 model2 loss : 0.024280
[11:51:40.767] iteration 20921 : model1 loss : 0.436903 model2 loss : 0.022975
[11:51:40.937] iteration 20922 : model1 loss : 0.441355 model2 loss : 0.022169
[11:51:42.824] iteration 20923 : model1 loss : 0.442079 model2 loss : 0.024713
[11:51:42.992] iteration 20924 : model1 loss : 0.436610 model2 loss : 0.021868
[11:51:43.163] iteration 20925 : model1 loss : 0.443541 model2 loss : 0.026586
[11:51:43.329] iteration 20926 : model1 loss : 0.436456 model2 loss : 0.020085
[11:51:43.502] iteration 20927 : model1 loss : 0.435717 model2 loss : 0.021792
[11:51:43.674] iteration 20928 : model1 loss : 0.436718 model2 loss : 0.020821
[11:51:43.844] iteration 20929 : model1 loss : 0.437447 model2 loss : 0.020345
[11:51:44.011] iteration 20930 : model1 loss : 0.433417 model2 loss : 0.021351
[11:51:44.179] iteration 20931 : model1 loss : 0.437431 model2 loss : 0.019109
[11:51:44.345] iteration 20932 : model1 loss : 0.439693 model2 loss : 0.022951
[11:51:44.520] iteration 20933 : model1 loss : 0.441210 model2 loss : 0.024738
[11:51:44.686] iteration 20934 : model1 loss : 0.439668 model2 loss : 0.021168
[11:51:44.855] iteration 20935 : model1 loss : 0.437141 model2 loss : 0.019651
[11:51:45.022] iteration 20936 : model1 loss : 0.444830 model2 loss : 0.022032
[11:51:45.191] iteration 20937 : model1 loss : 0.438018 model2 loss : 0.021921
[11:51:45.357] iteration 20938 : model1 loss : 0.442989 model2 loss : 0.022921
[11:51:45.533] iteration 20939 : model1 loss : 0.437794 model2 loss : 0.023212
[11:51:45.700] iteration 20940 : model1 loss : 0.438754 model2 loss : 0.021405
[11:51:45.870] iteration 20941 : model1 loss : 0.442118 model2 loss : 0.022376
[11:51:46.036] iteration 20942 : model1 loss : 0.441082 model2 loss : 0.022998
[11:51:46.206] iteration 20943 : model1 loss : 0.439962 model2 loss : 0.022201
[11:51:46.373] iteration 20944 : model1 loss : 0.433348 model2 loss : 0.022503
[11:51:46.545] iteration 20945 : model1 loss : 0.440104 model2 loss : 0.020984
[11:51:46.711] iteration 20946 : model1 loss : 0.438857 model2 loss : 0.021886
[11:51:46.880] iteration 20947 : model1 loss : 0.438745 model2 loss : 0.024280
[11:51:47.048] iteration 20948 : model1 loss : 0.439970 model2 loss : 0.021813
[11:51:47.216] iteration 20949 : model1 loss : 0.443161 model2 loss : 0.024700
[11:51:47.382] iteration 20950 : model1 loss : 0.437259 model2 loss : 0.020172
[11:51:47.555] iteration 20951 : model1 loss : 0.434537 model2 loss : 0.021440
[11:51:47.721] iteration 20952 : model1 loss : 0.437211 model2 loss : 0.020312
[11:51:47.890] iteration 20953 : model1 loss : 0.437585 model2 loss : 0.022254
[11:51:48.058] iteration 20954 : model1 loss : 0.438082 model2 loss : 0.021022
[11:51:48.227] iteration 20955 : model1 loss : 0.441523 model2 loss : 0.023963
[11:51:50.199] iteration 20956 : model1 loss : 0.436779 model2 loss : 0.021208
[11:51:50.368] iteration 20957 : model1 loss : 0.438203 model2 loss : 0.019559
[11:51:50.542] iteration 20958 : model1 loss : 0.440669 model2 loss : 0.021411
[11:51:50.708] iteration 20959 : model1 loss : 0.441590 model2 loss : 0.021011
[11:51:50.878] iteration 20960 : model1 loss : 0.438472 model2 loss : 0.021402
[11:51:51.043] iteration 20961 : model1 loss : 0.437024 model2 loss : 0.022008
[11:51:51.214] iteration 20962 : model1 loss : 0.436027 model2 loss : 0.022465
[11:51:51.381] iteration 20963 : model1 loss : 0.435953 model2 loss : 0.021798
[11:51:51.553] iteration 20964 : model1 loss : 0.436972 model2 loss : 0.022984
[11:51:51.721] iteration 20965 : model1 loss : 0.438917 model2 loss : 0.020498
[11:51:51.897] iteration 20966 : model1 loss : 0.438474 model2 loss : 0.021358
[11:51:52.063] iteration 20967 : model1 loss : 0.441383 model2 loss : 0.024357
[11:51:52.235] iteration 20968 : model1 loss : 0.441640 model2 loss : 0.025106
[11:51:52.403] iteration 20969 : model1 loss : 0.433700 model2 loss : 0.020474
[11:51:52.575] iteration 20970 : model1 loss : 0.438134 model2 loss : 0.020138
[11:51:52.743] iteration 20971 : model1 loss : 0.436620 model2 loss : 0.018541
[11:51:52.913] iteration 20972 : model1 loss : 0.440928 model2 loss : 0.023993
[11:51:53.079] iteration 20973 : model1 loss : 0.437580 model2 loss : 0.019609
[11:51:53.250] iteration 20974 : model1 loss : 0.436355 model2 loss : 0.017991
[11:51:53.416] iteration 20975 : model1 loss : 0.439736 model2 loss : 0.021331
[11:51:53.593] iteration 20976 : model1 loss : 0.442858 model2 loss : 0.023732
[11:51:53.760] iteration 20977 : model1 loss : 0.440126 model2 loss : 0.026371
[11:51:53.931] iteration 20978 : model1 loss : 0.435546 model2 loss : 0.020951
[11:51:54.097] iteration 20979 : model1 loss : 0.438881 model2 loss : 0.020906
[11:51:54.267] iteration 20980 : model1 loss : 0.445310 model2 loss : 0.021871
[11:51:54.434] iteration 20981 : model1 loss : 0.440267 model2 loss : 0.021723
[11:51:54.607] iteration 20982 : model1 loss : 0.436853 model2 loss : 0.020603
[11:51:54.775] iteration 20983 : model1 loss : 0.444666 model2 loss : 0.023437
[11:51:54.945] iteration 20984 : model1 loss : 0.443649 model2 loss : 0.023901
[11:51:55.112] iteration 20985 : model1 loss : 0.436164 model2 loss : 0.024409
[11:51:55.280] iteration 20986 : model1 loss : 0.435453 model2 loss : 0.021358
[11:51:55.446] iteration 20987 : model1 loss : 0.436976 model2 loss : 0.021832
[11:51:55.615] iteration 20988 : model1 loss : 0.438798 model2 loss : 0.020700
[11:51:57.561] iteration 20989 : model1 loss : 0.434625 model2 loss : 0.020917
[11:51:57.731] iteration 20990 : model1 loss : 0.435658 model2 loss : 0.022244
[11:51:57.902] iteration 20991 : model1 loss : 0.440397 model2 loss : 0.021917
[11:51:58.070] iteration 20992 : model1 loss : 0.439626 model2 loss : 0.021060
[11:51:58.239] iteration 20993 : model1 loss : 0.442131 model2 loss : 0.021188
[11:51:58.421] iteration 20994 : model1 loss : 0.438716 model2 loss : 0.019914
[11:51:58.589] iteration 20995 : model1 loss : 0.439966 model2 loss : 0.021052
[11:51:58.755] iteration 20996 : model1 loss : 0.443915 model2 loss : 0.025378
[11:51:58.926] iteration 20997 : model1 loss : 0.440047 model2 loss : 0.021557
[11:51:59.093] iteration 20998 : model1 loss : 0.437312 model2 loss : 0.023605
[11:51:59.264] iteration 20999 : model1 loss : 0.441967 model2 loss : 0.019877
[11:51:59.431] iteration 21000 : model1 loss : 0.434371 model2 loss : 0.021293
[11:52:07.772] iteration 21000 : model1_mean_dice : 0.901998 model1_mean_hd95 : 3.047659
[11:52:16.083] iteration 21000 : model2_mean_dice : 0.896668 model2_mean_hd95 : 2.211661
[11:52:16.103] save model1 to ../model/ACDC/EVILv1_kl0.5_tau0.25_21_1337/unet\model1_iter_21000.pth
[11:52:16.122] save model2 to ../model/ACDC/EVILv1_kl0.5_tau0.25_21_1337/unet\model2_iter_21000.pth
[11:52:16.296] iteration 21001 : model1 loss : 0.436991 model2 loss : 0.020139
[11:52:16.468] iteration 21002 : model1 loss : 0.437653 model2 loss : 0.022257
[11:52:16.636] iteration 21003 : model1 loss : 0.438678 model2 loss : 0.023821
[11:52:16.804] iteration 21004 : model1 loss : 0.438639 model2 loss : 0.019856
[11:52:16.971] iteration 21005 : model1 loss : 0.436660 model2 loss : 0.021507
[11:52:17.138] iteration 21006 : model1 loss : 0.439196 model2 loss : 0.021626
[11:52:17.305] iteration 21007 : model1 loss : 0.439881 model2 loss : 0.021933
[11:52:17.472] iteration 21008 : model1 loss : 0.437148 model2 loss : 0.019014
[11:52:17.641] iteration 21009 : model1 loss : 0.439163 model2 loss : 0.022082
[11:52:17.807] iteration 21010 : model1 loss : 0.440909 model2 loss : 0.023603
[11:52:17.975] iteration 21011 : model1 loss : 0.437406 model2 loss : 0.020201
[11:52:18.141] iteration 21012 : model1 loss : 0.442361 model2 loss : 0.022091
[11:52:18.310] iteration 21013 : model1 loss : 0.438046 model2 loss : 0.020785
[11:52:18.477] iteration 21014 : model1 loss : 0.436691 model2 loss : 0.019944
[11:52:18.646] iteration 21015 : model1 loss : 0.437061 model2 loss : 0.022667
[11:52:18.814] iteration 21016 : model1 loss : 0.438967 model2 loss : 0.023356
[11:52:18.982] iteration 21017 : model1 loss : 0.436079 model2 loss : 0.020467
[11:52:19.149] iteration 21018 : model1 loss : 0.439059 model2 loss : 0.020384
[11:52:19.318] iteration 21019 : model1 loss : 0.440051 model2 loss : 0.023629
[11:52:19.483] iteration 21020 : model1 loss : 0.437793 model2 loss : 0.021333
[11:52:19.652] iteration 21021 : model1 loss : 0.439872 model2 loss : 0.020549
[11:52:21.623] iteration 21022 : model1 loss : 0.439669 model2 loss : 0.020526
[11:52:21.792] iteration 21023 : model1 loss : 0.437885 model2 loss : 0.020178
[11:52:21.963] iteration 21024 : model1 loss : 0.438764 model2 loss : 0.020051
[11:52:22.130] iteration 21025 : model1 loss : 0.435945 model2 loss : 0.021012
[11:52:22.298] iteration 21026 : model1 loss : 0.441157 model2 loss : 0.020487
[11:52:22.463] iteration 21027 : model1 loss : 0.435350 model2 loss : 0.017862
[11:52:22.631] iteration 21028 : model1 loss : 0.438057 model2 loss : 0.025353
[11:52:22.797] iteration 21029 : model1 loss : 0.438373 model2 loss : 0.019941
[11:52:22.966] iteration 21030 : model1 loss : 0.432831 model2 loss : 0.020950
[11:52:23.132] iteration 21031 : model1 loss : 0.440335 model2 loss : 0.020678
[11:52:23.302] iteration 21032 : model1 loss : 0.440279 model2 loss : 0.021939
[11:52:23.470] iteration 21033 : model1 loss : 0.437351 model2 loss : 0.019552
[11:52:23.638] iteration 21034 : model1 loss : 0.437238 model2 loss : 0.018963
[11:52:23.805] iteration 21035 : model1 loss : 0.436653 model2 loss : 0.019821
[11:52:23.973] iteration 21036 : model1 loss : 0.440432 model2 loss : 0.025115
[11:52:24.140] iteration 21037 : model1 loss : 0.441868 model2 loss : 0.021335
[11:52:24.312] iteration 21038 : model1 loss : 0.445976 model2 loss : 0.026036
[11:52:24.481] iteration 21039 : model1 loss : 0.440670 model2 loss : 0.023318
[11:52:24.651] iteration 21040 : model1 loss : 0.442545 model2 loss : 0.021067
[11:52:24.817] iteration 21041 : model1 loss : 0.439958 model2 loss : 0.021966
[11:52:24.987] iteration 21042 : model1 loss : 0.439851 model2 loss : 0.022617
[11:52:25.153] iteration 21043 : model1 loss : 0.437606 model2 loss : 0.020150
[11:52:25.325] iteration 21044 : model1 loss : 0.438910 model2 loss : 0.020579
[11:52:25.490] iteration 21045 : model1 loss : 0.440344 model2 loss : 0.022747
[11:52:25.660] iteration 21046 : model1 loss : 0.438466 model2 loss : 0.021001
[11:52:25.826] iteration 21047 : model1 loss : 0.435957 model2 loss : 0.021612
[11:52:25.995] iteration 21048 : model1 loss : 0.435965 model2 loss : 0.020731
[11:52:26.161] iteration 21049 : model1 loss : 0.435384 model2 loss : 0.020364
[11:52:26.330] iteration 21050 : model1 loss : 0.439989 model2 loss : 0.019835
[11:52:26.497] iteration 21051 : model1 loss : 0.436077 model2 loss : 0.019081
[11:52:26.666] iteration 21052 : model1 loss : 0.437589 model2 loss : 0.021657
[11:52:26.832] iteration 21053 : model1 loss : 0.442909 model2 loss : 0.021849
[11:52:26.999] iteration 21054 : model1 loss : 0.436454 model2 loss : 0.021420
[11:52:28.902] iteration 21055 : model1 loss : 0.442111 model2 loss : 0.023433
[11:52:29.070] iteration 21056 : model1 loss : 0.439921 model2 loss : 0.020538
[11:52:29.240] iteration 21057 : model1 loss : 0.439160 model2 loss : 0.018881
[11:52:29.406] iteration 21058 : model1 loss : 0.442679 model2 loss : 0.019836
[11:52:29.579] iteration 21059 : model1 loss : 0.442663 model2 loss : 0.024700
[11:52:29.745] iteration 21060 : model1 loss : 0.436416 model2 loss : 0.019724
[11:52:29.915] iteration 21061 : model1 loss : 0.437804 model2 loss : 0.020172
[11:52:30.083] iteration 21062 : model1 loss : 0.438459 model2 loss : 0.019633
[11:52:30.252] iteration 21063 : model1 loss : 0.439379 model2 loss : 0.021805
[11:52:30.418] iteration 21064 : model1 loss : 0.440860 model2 loss : 0.022179
[11:52:30.587] iteration 21065 : model1 loss : 0.438602 model2 loss : 0.021376
[11:52:30.752] iteration 21066 : model1 loss : 0.440401 model2 loss : 0.022536
[11:52:30.925] iteration 21067 : model1 loss : 0.439423 model2 loss : 0.023776
[11:52:31.093] iteration 21068 : model1 loss : 0.435369 model2 loss : 0.019665
[11:52:31.262] iteration 21069 : model1 loss : 0.437968 model2 loss : 0.021616
[11:52:31.429] iteration 21070 : model1 loss : 0.437156 model2 loss : 0.018626
[11:52:31.602] iteration 21071 : model1 loss : 0.440668 model2 loss : 0.022174
[11:52:31.766] iteration 21072 : model1 loss : 0.438585 model2 loss : 0.024110
[11:52:31.936] iteration 21073 : model1 loss : 0.438824 model2 loss : 0.020454
[11:52:32.103] iteration 21074 : model1 loss : 0.439190 model2 loss : 0.020683
[11:52:32.273] iteration 21075 : model1 loss : 0.436148 model2 loss : 0.023398
[11:52:32.442] iteration 21076 : model1 loss : 0.435002 model2 loss : 0.021314
[11:52:32.613] iteration 21077 : model1 loss : 0.437154 model2 loss : 0.019856
[11:52:32.781] iteration 21078 : model1 loss : 0.438645 model2 loss : 0.020033
[11:52:32.950] iteration 21079 : model1 loss : 0.441687 model2 loss : 0.023785
[11:52:33.117] iteration 21080 : model1 loss : 0.433478 model2 loss : 0.018653
[11:52:33.288] iteration 21081 : model1 loss : 0.442098 model2 loss : 0.021534
[11:52:33.453] iteration 21082 : model1 loss : 0.440263 model2 loss : 0.023758
[11:52:33.627] iteration 21083 : model1 loss : 0.437410 model2 loss : 0.019629
[11:52:33.821] iteration 21084 : model1 loss : 0.435349 model2 loss : 0.020605
[11:52:33.991] iteration 21085 : model1 loss : 0.437014 model2 loss : 0.019779
[11:52:34.156] iteration 21086 : model1 loss : 0.435621 model2 loss : 0.019499
[11:52:34.325] iteration 21087 : model1 loss : 0.441214 model2 loss : 0.021264
[11:52:36.303] iteration 21088 : model1 loss : 0.435037 model2 loss : 0.021839
[11:52:36.470] iteration 21089 : model1 loss : 0.437913 model2 loss : 0.021582
[11:52:36.641] iteration 21090 : model1 loss : 0.438721 model2 loss : 0.020383
[11:52:36.807] iteration 21091 : model1 loss : 0.434551 model2 loss : 0.021346
[11:52:36.975] iteration 21092 : model1 loss : 0.433751 model2 loss : 0.019457
[11:52:37.144] iteration 21093 : model1 loss : 0.441603 model2 loss : 0.022683
[11:52:37.312] iteration 21094 : model1 loss : 0.440794 model2 loss : 0.019827
[11:52:37.479] iteration 21095 : model1 loss : 0.438200 model2 loss : 0.018236
[11:52:37.649] iteration 21096 : model1 loss : 0.440006 model2 loss : 0.022198
[11:52:37.814] iteration 21097 : model1 loss : 0.437264 model2 loss : 0.023141
[11:52:37.986] iteration 21098 : model1 loss : 0.439369 model2 loss : 0.019358
[11:52:38.152] iteration 21099 : model1 loss : 0.439456 model2 loss : 0.020726
[11:52:38.324] iteration 21100 : model1 loss : 0.438849 model2 loss : 0.018263
[11:52:38.490] iteration 21101 : model1 loss : 0.438251 model2 loss : 0.019319
[11:52:38.660] iteration 21102 : model1 loss : 0.438268 model2 loss : 0.021291
[11:52:38.826] iteration 21103 : model1 loss : 0.437817 model2 loss : 0.017555
[11:52:38.994] iteration 21104 : model1 loss : 0.437351 model2 loss : 0.023955
[11:52:39.162] iteration 21105 : model1 loss : 0.439774 model2 loss : 0.020892
[11:52:39.331] iteration 21106 : model1 loss : 0.437170 model2 loss : 0.019551
[11:52:39.501] iteration 21107 : model1 loss : 0.437345 model2 loss : 0.020044
[11:52:39.670] iteration 21108 : model1 loss : 0.436864 model2 loss : 0.018835
[11:52:39.838] iteration 21109 : model1 loss : 0.442415 model2 loss : 0.022726
[11:52:40.007] iteration 21110 : model1 loss : 0.441165 model2 loss : 0.019997
[11:52:40.173] iteration 21111 : model1 loss : 0.442641 model2 loss : 0.024894
[11:52:40.341] iteration 21112 : model1 loss : 0.438404 model2 loss : 0.021242
[11:52:40.511] iteration 21113 : model1 loss : 0.441260 model2 loss : 0.021687
[11:52:40.681] iteration 21114 : model1 loss : 0.435358 model2 loss : 0.021913
[11:52:40.847] iteration 21115 : model1 loss : 0.439620 model2 loss : 0.021118
[11:52:41.016] iteration 21116 : model1 loss : 0.441313 model2 loss : 0.021038
[11:52:41.182] iteration 21117 : model1 loss : 0.440295 model2 loss : 0.023006
[11:52:41.352] iteration 21118 : model1 loss : 0.436791 model2 loss : 0.022857
[11:52:41.519] iteration 21119 : model1 loss : 0.441996 model2 loss : 0.021662
[11:52:41.686] iteration 21120 : model1 loss : 0.436893 model2 loss : 0.019037
[11:52:43.614] iteration 21121 : model1 loss : 0.439147 model2 loss : 0.022863
[11:52:43.780] iteration 21122 : model1 loss : 0.436853 model2 loss : 0.019843
[11:52:43.951] iteration 21123 : model1 loss : 0.436008 model2 loss : 0.021290
[11:52:44.116] iteration 21124 : model1 loss : 0.439106 model2 loss : 0.020279
[11:52:44.295] iteration 21125 : model1 loss : 0.438529 model2 loss : 0.020666
[11:52:44.463] iteration 21126 : model1 loss : 0.440176 model2 loss : 0.024616
[11:52:44.636] iteration 21127 : model1 loss : 0.443183 model2 loss : 0.023652
[11:52:44.804] iteration 21128 : model1 loss : 0.434166 model2 loss : 0.022594
[11:52:44.973] iteration 21129 : model1 loss : 0.440056 model2 loss : 0.022162
[11:52:45.139] iteration 21130 : model1 loss : 0.438605 model2 loss : 0.022176
[11:52:45.309] iteration 21131 : model1 loss : 0.441548 model2 loss : 0.022180
[11:52:45.475] iteration 21132 : model1 loss : 0.442896 model2 loss : 0.019956
[11:52:45.643] iteration 21133 : model1 loss : 0.433531 model2 loss : 0.021597
[11:52:45.810] iteration 21134 : model1 loss : 0.441580 model2 loss : 0.023947
[11:52:45.980] iteration 21135 : model1 loss : 0.440810 model2 loss : 0.026066
[11:52:46.147] iteration 21136 : model1 loss : 0.435842 model2 loss : 0.022233
[11:52:46.315] iteration 21137 : model1 loss : 0.439958 model2 loss : 0.021136
[11:52:46.481] iteration 21138 : model1 loss : 0.438596 model2 loss : 0.019770
[11:52:46.651] iteration 21139 : model1 loss : 0.439417 model2 loss : 0.022808
[11:52:46.818] iteration 21140 : model1 loss : 0.438635 model2 loss : 0.023417
[11:52:46.987] iteration 21141 : model1 loss : 0.436696 model2 loss : 0.022589
[11:52:47.155] iteration 21142 : model1 loss : 0.434773 model2 loss : 0.021840
[11:52:47.324] iteration 21143 : model1 loss : 0.436800 model2 loss : 0.021437
[11:52:47.490] iteration 21144 : model1 loss : 0.436601 model2 loss : 0.023119
[11:52:47.659] iteration 21145 : model1 loss : 0.445264 model2 loss : 0.024106
[11:52:47.826] iteration 21146 : model1 loss : 0.437429 model2 loss : 0.020109
[11:52:47.997] iteration 21147 : model1 loss : 0.438139 model2 loss : 0.019860
[11:52:48.164] iteration 21148 : model1 loss : 0.434909 model2 loss : 0.021647
[11:52:48.342] iteration 21149 : model1 loss : 0.438966 model2 loss : 0.021018
[11:52:48.515] iteration 21150 : model1 loss : 0.440150 model2 loss : 0.019973
[11:52:48.683] iteration 21151 : model1 loss : 0.442428 model2 loss : 0.022688
[11:52:48.848] iteration 21152 : model1 loss : 0.441601 model2 loss : 0.019099
[11:52:49.016] iteration 21153 : model1 loss : 0.436468 model2 loss : 0.019701
[11:52:50.971] iteration 21154 : model1 loss : 0.442230 model2 loss : 0.019813
[11:52:51.136] iteration 21155 : model1 loss : 0.440332 model2 loss : 0.022624
[11:52:51.308] iteration 21156 : model1 loss : 0.439009 model2 loss : 0.020908
[11:52:51.473] iteration 21157 : model1 loss : 0.441136 model2 loss : 0.022821
[11:52:51.642] iteration 21158 : model1 loss : 0.439356 model2 loss : 0.021341
[11:52:51.811] iteration 21159 : model1 loss : 0.439986 model2 loss : 0.021140
[11:52:51.980] iteration 21160 : model1 loss : 0.436682 model2 loss : 0.020312
[11:52:52.147] iteration 21161 : model1 loss : 0.439897 model2 loss : 0.020829
[11:52:52.318] iteration 21162 : model1 loss : 0.442361 model2 loss : 0.022227
[11:52:52.485] iteration 21163 : model1 loss : 0.439507 model2 loss : 0.020431
[11:52:52.655] iteration 21164 : model1 loss : 0.436646 model2 loss : 0.021267
[11:52:52.823] iteration 21165 : model1 loss : 0.437158 model2 loss : 0.023391
[11:52:52.992] iteration 21166 : model1 loss : 0.442184 model2 loss : 0.023726
[11:52:53.158] iteration 21167 : model1 loss : 0.436103 model2 loss : 0.022732
[11:52:53.329] iteration 21168 : model1 loss : 0.434612 model2 loss : 0.020332
[11:52:53.497] iteration 21169 : model1 loss : 0.438144 model2 loss : 0.021019
[11:52:53.668] iteration 21170 : model1 loss : 0.440910 model2 loss : 0.022356
[11:52:53.836] iteration 21171 : model1 loss : 0.437469 model2 loss : 0.018418
[11:52:54.004] iteration 21172 : model1 loss : 0.438309 model2 loss : 0.020211
[11:52:54.172] iteration 21173 : model1 loss : 0.437154 model2 loss : 0.023769
[11:52:54.340] iteration 21174 : model1 loss : 0.434113 model2 loss : 0.019372
[11:52:54.507] iteration 21175 : model1 loss : 0.436145 model2 loss : 0.019305
[11:52:54.680] iteration 21176 : model1 loss : 0.440307 model2 loss : 0.021904
[11:52:54.847] iteration 21177 : model1 loss : 0.440147 model2 loss : 0.019408
[11:52:55.017] iteration 21178 : model1 loss : 0.435529 model2 loss : 0.021110
[11:52:55.185] iteration 21179 : model1 loss : 0.437168 model2 loss : 0.022806
[11:52:55.355] iteration 21180 : model1 loss : 0.438359 model2 loss : 0.020364
[11:52:55.525] iteration 21181 : model1 loss : 0.440111 model2 loss : 0.023175
[11:52:55.694] iteration 21182 : model1 loss : 0.437813 model2 loss : 0.019814
[11:52:55.864] iteration 21183 : model1 loss : 0.439535 model2 loss : 0.021116
[11:52:56.035] iteration 21184 : model1 loss : 0.439099 model2 loss : 0.019069
[11:52:56.201] iteration 21185 : model1 loss : 0.441442 model2 loss : 0.021842
[11:52:56.369] iteration 21186 : model1 loss : 0.439625 model2 loss : 0.022610
[11:52:58.285] iteration 21187 : model1 loss : 0.443491 model2 loss : 0.022887
[11:52:58.451] iteration 21188 : model1 loss : 0.435184 model2 loss : 0.020668
[11:52:58.620] iteration 21189 : model1 loss : 0.441626 model2 loss : 0.021728
[11:52:58.787] iteration 21190 : model1 loss : 0.433849 model2 loss : 0.021791
[11:52:58.956] iteration 21191 : model1 loss : 0.441062 model2 loss : 0.022796
[11:52:59.123] iteration 21192 : model1 loss : 0.442831 model2 loss : 0.021525
[11:52:59.297] iteration 21193 : model1 loss : 0.434250 model2 loss : 0.018664
[11:52:59.463] iteration 21194 : model1 loss : 0.438061 model2 loss : 0.020462
[11:52:59.635] iteration 21195 : model1 loss : 0.440954 model2 loss : 0.023674
[11:52:59.804] iteration 21196 : model1 loss : 0.436233 model2 loss : 0.019885
[11:52:59.973] iteration 21197 : model1 loss : 0.435017 model2 loss : 0.020536
[11:53:00.140] iteration 21198 : model1 loss : 0.439074 model2 loss : 0.021445
[11:53:00.309] iteration 21199 : model1 loss : 0.434699 model2 loss : 0.019538
[11:53:00.475] iteration 21200 : model1 loss : 0.442463 model2 loss : 0.022911
[11:53:00.649] iteration 21201 : model1 loss : 0.436260 model2 loss : 0.019618
[11:53:00.815] iteration 21202 : model1 loss : 0.439386 model2 loss : 0.020573
[11:53:00.985] iteration 21203 : model1 loss : 0.436432 model2 loss : 0.020507
[11:53:01.154] iteration 21204 : model1 loss : 0.439543 model2 loss : 0.021451
[11:53:01.321] iteration 21205 : model1 loss : 0.433512 model2 loss : 0.019998
[11:53:01.488] iteration 21206 : model1 loss : 0.442591 model2 loss : 0.023445
[11:53:01.657] iteration 21207 : model1 loss : 0.442645 model2 loss : 0.020515
[11:53:01.825] iteration 21208 : model1 loss : 0.438922 model2 loss : 0.020636
[11:53:01.994] iteration 21209 : model1 loss : 0.442421 model2 loss : 0.023576
[11:53:02.161] iteration 21210 : model1 loss : 0.439843 model2 loss : 0.023900
[11:53:02.330] iteration 21211 : model1 loss : 0.437766 model2 loss : 0.022362
[11:53:02.501] iteration 21212 : model1 loss : 0.439057 model2 loss : 0.022152
[11:53:02.672] iteration 21213 : model1 loss : 0.437456 model2 loss : 0.020190
[11:53:02.839] iteration 21214 : model1 loss : 0.438790 model2 loss : 0.021551
[11:53:03.008] iteration 21215 : model1 loss : 0.441020 model2 loss : 0.023667
[11:53:03.176] iteration 21216 : model1 loss : 0.437633 model2 loss : 0.020143
[11:53:03.347] iteration 21217 : model1 loss : 0.437922 model2 loss : 0.022322
[11:53:03.519] iteration 21218 : model1 loss : 0.443171 model2 loss : 0.021596
[11:53:03.687] iteration 21219 : model1 loss : 0.436331 model2 loss : 0.019735
[11:53:05.595] iteration 21220 : model1 loss : 0.440649 model2 loss : 0.023914
[11:53:05.765] iteration 21221 : model1 loss : 0.435425 model2 loss : 0.020453
[11:53:05.939] iteration 21222 : model1 loss : 0.436454 model2 loss : 0.021284
[11:53:06.109] iteration 21223 : model1 loss : 0.435978 model2 loss : 0.018807
[11:53:06.279] iteration 21224 : model1 loss : 0.441230 model2 loss : 0.022134
[11:53:06.446] iteration 21225 : model1 loss : 0.434488 model2 loss : 0.020514
[11:53:06.617] iteration 21226 : model1 loss : 0.440782 model2 loss : 0.021145
[11:53:06.783] iteration 21227 : model1 loss : 0.439962 model2 loss : 0.022625
[11:53:06.952] iteration 21228 : model1 loss : 0.434979 model2 loss : 0.018987
[11:53:07.120] iteration 21229 : model1 loss : 0.439547 model2 loss : 0.022321
[11:53:07.291] iteration 21230 : model1 loss : 0.437795 model2 loss : 0.021768
[11:53:07.475] iteration 21231 : model1 loss : 0.440141 model2 loss : 0.024249
[11:53:07.647] iteration 21232 : model1 loss : 0.440461 model2 loss : 0.022168
[11:53:07.815] iteration 21233 : model1 loss : 0.440195 model2 loss : 0.021655
[11:53:07.983] iteration 21234 : model1 loss : 0.439336 model2 loss : 0.019758
[11:53:08.152] iteration 21235 : model1 loss : 0.439787 model2 loss : 0.021805
[11:53:08.322] iteration 21236 : model1 loss : 0.434454 model2 loss : 0.019820
[11:53:08.490] iteration 21237 : model1 loss : 0.440078 model2 loss : 0.020854
[11:53:08.665] iteration 21238 : model1 loss : 0.438853 model2 loss : 0.020188
[11:53:08.833] iteration 21239 : model1 loss : 0.437256 model2 loss : 0.021028
[11:53:09.002] iteration 21240 : model1 loss : 0.439896 model2 loss : 0.021947
[11:53:09.170] iteration 21241 : model1 loss : 0.440181 model2 loss : 0.022152
[11:53:09.340] iteration 21242 : model1 loss : 0.434110 model2 loss : 0.018929
[11:53:09.510] iteration 21243 : model1 loss : 0.439552 model2 loss : 0.022824
[11:53:09.682] iteration 21244 : model1 loss : 0.438902 model2 loss : 0.018945
[11:53:09.848] iteration 21245 : model1 loss : 0.443368 model2 loss : 0.024227
[11:53:10.018] iteration 21246 : model1 loss : 0.434368 model2 loss : 0.020602
[11:53:10.186] iteration 21247 : model1 loss : 0.436504 model2 loss : 0.021253
[11:53:10.356] iteration 21248 : model1 loss : 0.437360 model2 loss : 0.018385
[11:53:10.526] iteration 21249 : model1 loss : 0.443835 model2 loss : 0.024816
[11:53:10.695] iteration 21250 : model1 loss : 0.439445 model2 loss : 0.020117
[11:53:10.861] iteration 21251 : model1 loss : 0.436659 model2 loss : 0.019600
[11:53:11.029] iteration 21252 : model1 loss : 0.442685 model2 loss : 0.023086
[11:53:12.918] iteration 21253 : model1 loss : 0.439750 model2 loss : 0.022969
[11:53:13.101] iteration 21254 : model1 loss : 0.437059 model2 loss : 0.021600
[11:53:13.272] iteration 21255 : model1 loss : 0.444921 model2 loss : 0.025828
[11:53:13.441] iteration 21256 : model1 loss : 0.439946 model2 loss : 0.021714
[11:53:13.610] iteration 21257 : model1 loss : 0.440143 model2 loss : 0.027300
[11:53:13.779] iteration 21258 : model1 loss : 0.440075 model2 loss : 0.020880
[11:53:13.948] iteration 21259 : model1 loss : 0.443352 model2 loss : 0.023378
[11:53:14.115] iteration 21260 : model1 loss : 0.442377 model2 loss : 0.022028
[11:53:14.285] iteration 21261 : model1 loss : 0.437247 model2 loss : 0.020994
[11:53:14.452] iteration 21262 : model1 loss : 0.436720 model2 loss : 0.018970
[11:53:14.623] iteration 21263 : model1 loss : 0.441088 model2 loss : 0.025110
[11:53:14.791] iteration 21264 : model1 loss : 0.436109 model2 loss : 0.022049
[11:53:14.960] iteration 21265 : model1 loss : 0.442108 model2 loss : 0.020407
[11:53:15.128] iteration 21266 : model1 loss : 0.442014 model2 loss : 0.021278
[11:53:15.297] iteration 21267 : model1 loss : 0.435213 model2 loss : 0.021105
[11:53:15.465] iteration 21268 : model1 loss : 0.438269 model2 loss : 0.020632
[11:53:15.636] iteration 21269 : model1 loss : 0.436694 model2 loss : 0.020126
[11:53:15.802] iteration 21270 : model1 loss : 0.437532 model2 loss : 0.019689
[11:53:15.972] iteration 21271 : model1 loss : 0.440193 model2 loss : 0.021433
[11:53:16.142] iteration 21272 : model1 loss : 0.441751 model2 loss : 0.022953
[11:53:16.311] iteration 21273 : model1 loss : 0.435683 model2 loss : 0.023225
[11:53:16.480] iteration 21274 : model1 loss : 0.446309 model2 loss : 0.023674
[11:53:16.651] iteration 21275 : model1 loss : 0.436550 model2 loss : 0.022203
[11:53:16.818] iteration 21276 : model1 loss : 0.435712 model2 loss : 0.022312
[11:53:16.987] iteration 21277 : model1 loss : 0.437125 model2 loss : 0.020101
[11:53:17.154] iteration 21278 : model1 loss : 0.441263 model2 loss : 0.021337
[11:53:17.323] iteration 21279 : model1 loss : 0.438430 model2 loss : 0.020570
[11:53:17.492] iteration 21280 : model1 loss : 0.438319 model2 loss : 0.022685
[11:53:17.665] iteration 21281 : model1 loss : 0.433320 model2 loss : 0.019882
[11:53:17.832] iteration 21282 : model1 loss : 0.436006 model2 loss : 0.023746
[11:53:18.002] iteration 21283 : model1 loss : 0.439505 model2 loss : 0.021232
[11:53:18.167] iteration 21284 : model1 loss : 0.433766 model2 loss : 0.019707
[11:53:18.334] iteration 21285 : model1 loss : 0.439717 model2 loss : 0.022053
[11:53:20.265] iteration 21286 : model1 loss : 0.437490 model2 loss : 0.022953
[11:53:20.436] iteration 21287 : model1 loss : 0.439439 model2 loss : 0.020392
[11:53:20.608] iteration 21288 : model1 loss : 0.437848 model2 loss : 0.021115
[11:53:20.774] iteration 21289 : model1 loss : 0.436664 model2 loss : 0.021309
[11:53:20.949] iteration 21290 : model1 loss : 0.441617 model2 loss : 0.025139
[11:53:21.117] iteration 21291 : model1 loss : 0.440959 model2 loss : 0.020225
[11:53:21.286] iteration 21292 : model1 loss : 0.437766 model2 loss : 0.017064
[11:53:21.454] iteration 21293 : model1 loss : 0.436323 model2 loss : 0.019834
[11:53:21.622] iteration 21294 : model1 loss : 0.438231 model2 loss : 0.019824
[11:53:21.791] iteration 21295 : model1 loss : 0.439227 model2 loss : 0.020812
[11:53:21.961] iteration 21296 : model1 loss : 0.441533 model2 loss : 0.021907
[11:53:22.129] iteration 21297 : model1 loss : 0.438319 model2 loss : 0.020193
[11:53:22.311] iteration 21298 : model1 loss : 0.441494 model2 loss : 0.018320
[11:53:22.478] iteration 21299 : model1 loss : 0.441525 model2 loss : 0.021882
[11:53:22.648] iteration 21300 : model1 loss : 0.440434 model2 loss : 0.018815
[11:53:22.816] iteration 21301 : model1 loss : 0.438172 model2 loss : 0.019718
[11:53:22.986] iteration 21302 : model1 loss : 0.436813 model2 loss : 0.020271
[11:53:23.156] iteration 21303 : model1 loss : 0.432874 model2 loss : 0.021779
[11:53:23.325] iteration 21304 : model1 loss : 0.442858 model2 loss : 0.023544
[11:53:23.495] iteration 21305 : model1 loss : 0.436215 model2 loss : 0.021188
[11:53:23.667] iteration 21306 : model1 loss : 0.438129 model2 loss : 0.021235
[11:53:23.834] iteration 21307 : model1 loss : 0.440533 model2 loss : 0.022072
[11:53:24.005] iteration 21308 : model1 loss : 0.438854 model2 loss : 0.020426
[11:53:24.172] iteration 21309 : model1 loss : 0.438749 model2 loss : 0.022969
[11:53:24.341] iteration 21310 : model1 loss : 0.444254 model2 loss : 0.024122
[11:53:24.511] iteration 21311 : model1 loss : 0.435078 model2 loss : 0.020884
[11:53:24.686] iteration 21312 : model1 loss : 0.436886 model2 loss : 0.020156
[11:53:24.853] iteration 21313 : model1 loss : 0.438809 model2 loss : 0.019428
[11:53:25.024] iteration 21314 : model1 loss : 0.433461 model2 loss : 0.020094
[11:53:25.192] iteration 21315 : model1 loss : 0.440020 model2 loss : 0.023335
[11:53:25.362] iteration 21316 : model1 loss : 0.439266 model2 loss : 0.022416
[11:53:25.530] iteration 21317 : model1 loss : 0.439802 model2 loss : 0.020151
[11:53:25.698] iteration 21318 : model1 loss : 0.435976 model2 loss : 0.018391
[11:53:27.633] iteration 21319 : model1 loss : 0.435971 model2 loss : 0.022383
[11:53:27.815] iteration 21320 : model1 loss : 0.439069 model2 loss : 0.019017
[11:53:27.985] iteration 21321 : model1 loss : 0.434429 model2 loss : 0.018199
[11:53:28.154] iteration 21322 : model1 loss : 0.439731 model2 loss : 0.017662
[11:53:28.322] iteration 21323 : model1 loss : 0.440994 model2 loss : 0.023615
[11:53:28.490] iteration 21324 : model1 loss : 0.441692 model2 loss : 0.025660
[11:53:28.662] iteration 21325 : model1 loss : 0.440245 model2 loss : 0.021167
[11:53:28.831] iteration 21326 : model1 loss : 0.435303 model2 loss : 0.021173
[11:53:29.000] iteration 21327 : model1 loss : 0.440059 model2 loss : 0.022053
[11:53:29.169] iteration 21328 : model1 loss : 0.441442 model2 loss : 0.021456
[11:53:29.338] iteration 21329 : model1 loss : 0.436807 model2 loss : 0.022244
[11:53:29.508] iteration 21330 : model1 loss : 0.439851 model2 loss : 0.022010
[11:53:29.676] iteration 21331 : model1 loss : 0.435739 model2 loss : 0.023138
[11:53:29.844] iteration 21332 : model1 loss : 0.435847 model2 loss : 0.019208
[11:53:30.016] iteration 21333 : model1 loss : 0.436027 model2 loss : 0.021366
[11:53:30.183] iteration 21334 : model1 loss : 0.439567 model2 loss : 0.023013
[11:53:30.353] iteration 21335 : model1 loss : 0.445450 model2 loss : 0.022422
[11:53:30.522] iteration 21336 : model1 loss : 0.442799 model2 loss : 0.021403
[11:53:30.695] iteration 21337 : model1 loss : 0.438651 model2 loss : 0.020503
[11:53:30.864] iteration 21338 : model1 loss : 0.436637 model2 loss : 0.019525
[11:53:31.032] iteration 21339 : model1 loss : 0.441230 model2 loss : 0.021370
[11:53:31.201] iteration 21340 : model1 loss : 0.439073 model2 loss : 0.019412
[11:53:31.369] iteration 21341 : model1 loss : 0.432612 model2 loss : 0.023377
[11:53:31.538] iteration 21342 : model1 loss : 0.440208 model2 loss : 0.022528
[11:53:31.706] iteration 21343 : model1 loss : 0.440751 model2 loss : 0.024124
[11:53:31.882] iteration 21344 : model1 loss : 0.442258 model2 loss : 0.025098
[11:53:32.053] iteration 21345 : model1 loss : 0.437260 model2 loss : 0.021454
[11:53:32.219] iteration 21346 : model1 loss : 0.435848 model2 loss : 0.021705
[11:53:32.390] iteration 21347 : model1 loss : 0.433883 model2 loss : 0.021735
[11:53:32.559] iteration 21348 : model1 loss : 0.442185 model2 loss : 0.023154
[11:53:32.728] iteration 21349 : model1 loss : 0.438260 model2 loss : 0.021383
[11:53:32.896] iteration 21350 : model1 loss : 0.442234 model2 loss : 0.022483
[11:53:33.064] iteration 21351 : model1 loss : 0.438816 model2 loss : 0.021566
[11:53:34.986] iteration 21352 : model1 loss : 0.436718 model2 loss : 0.021035
[11:53:35.152] iteration 21353 : model1 loss : 0.437824 model2 loss : 0.018570
[11:53:35.323] iteration 21354 : model1 loss : 0.441611 model2 loss : 0.022337
[11:53:35.491] iteration 21355 : model1 loss : 0.442283 model2 loss : 0.021860
[11:53:35.663] iteration 21356 : model1 loss : 0.440956 model2 loss : 0.023419
[11:53:35.830] iteration 21357 : model1 loss : 0.440055 model2 loss : 0.022745
[11:53:35.998] iteration 21358 : model1 loss : 0.440245 model2 loss : 0.019498
[11:53:36.168] iteration 21359 : model1 loss : 0.440136 model2 loss : 0.019937
[11:53:36.338] iteration 21360 : model1 loss : 0.440252 model2 loss : 0.020973
[11:53:36.508] iteration 21361 : model1 loss : 0.435654 model2 loss : 0.022247
[11:53:36.680] iteration 21362 : model1 loss : 0.441653 model2 loss : 0.021974
[11:53:36.846] iteration 21363 : model1 loss : 0.436468 model2 loss : 0.020873
[11:53:37.017] iteration 21364 : model1 loss : 0.437774 model2 loss : 0.019353
[11:53:37.182] iteration 21365 : model1 loss : 0.437673 model2 loss : 0.020603
[11:53:37.352] iteration 21366 : model1 loss : 0.442706 model2 loss : 0.025635
[11:53:37.522] iteration 21367 : model1 loss : 0.440053 model2 loss : 0.021101
[11:53:37.693] iteration 21368 : model1 loss : 0.440376 model2 loss : 0.024817
[11:53:37.861] iteration 21369 : model1 loss : 0.439161 model2 loss : 0.022570
[11:53:38.030] iteration 21370 : model1 loss : 0.439320 model2 loss : 0.022108
[11:53:38.198] iteration 21371 : model1 loss : 0.442846 model2 loss : 0.021611
[11:53:38.365] iteration 21372 : model1 loss : 0.432799 model2 loss : 0.018564
[11:53:38.532] iteration 21373 : model1 loss : 0.435386 model2 loss : 0.022262
[11:53:38.705] iteration 21374 : model1 loss : 0.438334 model2 loss : 0.021462
[11:53:38.873] iteration 21375 : model1 loss : 0.435555 model2 loss : 0.022064
[11:53:39.043] iteration 21376 : model1 loss : 0.439232 model2 loss : 0.022912
[11:53:39.211] iteration 21377 : model1 loss : 0.436967 model2 loss : 0.023869
[11:53:39.379] iteration 21378 : model1 loss : 0.444550 model2 loss : 0.027842
[11:53:39.547] iteration 21379 : model1 loss : 0.433889 model2 loss : 0.019063
[11:53:39.720] iteration 21380 : model1 loss : 0.437222 model2 loss : 0.019387
[11:53:39.888] iteration 21381 : model1 loss : 0.439542 model2 loss : 0.023467
[11:53:40.056] iteration 21382 : model1 loss : 0.440083 model2 loss : 0.022177
[11:53:40.222] iteration 21383 : model1 loss : 0.439316 model2 loss : 0.021204
[11:53:40.390] iteration 21384 : model1 loss : 0.439321 model2 loss : 0.020927
[11:53:42.329] iteration 21385 : model1 loss : 0.436572 model2 loss : 0.020077
[11:53:42.501] iteration 21386 : model1 loss : 0.441264 model2 loss : 0.020511
[11:53:42.672] iteration 21387 : model1 loss : 0.438515 model2 loss : 0.022619
[11:53:42.842] iteration 21388 : model1 loss : 0.442639 model2 loss : 0.020246
[11:53:43.013] iteration 21389 : model1 loss : 0.440306 model2 loss : 0.021056
[11:53:43.179] iteration 21390 : model1 loss : 0.437432 model2 loss : 0.021950
[11:53:43.349] iteration 21391 : model1 loss : 0.437697 model2 loss : 0.021821
[11:53:43.517] iteration 21392 : model1 loss : 0.436687 model2 loss : 0.020449
[11:53:43.687] iteration 21393 : model1 loss : 0.441103 model2 loss : 0.023580
[11:53:43.855] iteration 21394 : model1 loss : 0.444126 model2 loss : 0.021508
[11:53:44.022] iteration 21395 : model1 loss : 0.442073 model2 loss : 0.024140
[11:53:44.190] iteration 21396 : model1 loss : 0.434361 model2 loss : 0.021307
[11:53:44.357] iteration 21397 : model1 loss : 0.439194 model2 loss : 0.017202
[11:53:44.527] iteration 21398 : model1 loss : 0.435064 model2 loss : 0.019382
[11:53:44.698] iteration 21399 : model1 loss : 0.440596 model2 loss : 0.020962
[11:53:44.865] iteration 21400 : model1 loss : 0.440975 model2 loss : 0.021650
[11:53:45.036] iteration 21401 : model1 loss : 0.442656 model2 loss : 0.020811
[11:53:45.201] iteration 21402 : model1 loss : 0.437923 model2 loss : 0.021143
[11:53:45.371] iteration 21403 : model1 loss : 0.438531 model2 loss : 0.020239
[11:53:45.538] iteration 21404 : model1 loss : 0.436686 model2 loss : 0.020492
[11:53:45.712] iteration 21405 : model1 loss : 0.441373 model2 loss : 0.023247
[11:53:45.882] iteration 21406 : model1 loss : 0.436078 model2 loss : 0.020186
[11:53:46.049] iteration 21407 : model1 loss : 0.439040 model2 loss : 0.020332
[11:53:46.216] iteration 21408 : model1 loss : 0.439306 model2 loss : 0.022486
[11:53:46.384] iteration 21409 : model1 loss : 0.436224 model2 loss : 0.023021
[11:53:46.554] iteration 21410 : model1 loss : 0.434738 model2 loss : 0.019391
[11:53:46.729] iteration 21411 : model1 loss : 0.438994 model2 loss : 0.021079
[11:53:46.895] iteration 21412 : model1 loss : 0.434730 model2 loss : 0.020307
[11:53:47.065] iteration 21413 : model1 loss : 0.439848 model2 loss : 0.022313
[11:53:47.232] iteration 21414 : model1 loss : 0.436661 model2 loss : 0.018361
[11:53:47.403] iteration 21415 : model1 loss : 0.439528 model2 loss : 0.021870
[11:53:47.569] iteration 21416 : model1 loss : 0.436178 model2 loss : 0.020646
[11:53:47.740] iteration 21417 : model1 loss : 0.439005 model2 loss : 0.021976
[11:53:49.702] iteration 21418 : model1 loss : 0.437658 model2 loss : 0.020575
[11:53:49.869] iteration 21419 : model1 loss : 0.443012 model2 loss : 0.023269
[11:53:50.039] iteration 21420 : model1 loss : 0.437563 model2 loss : 0.020253
[11:53:50.206] iteration 21421 : model1 loss : 0.436023 model2 loss : 0.020442
[11:53:50.377] iteration 21422 : model1 loss : 0.435179 model2 loss : 0.020863
[11:53:50.543] iteration 21423 : model1 loss : 0.446164 model2 loss : 0.023191
[11:53:50.713] iteration 21424 : model1 loss : 0.439642 model2 loss : 0.019409
[11:53:50.881] iteration 21425 : model1 loss : 0.437073 model2 loss : 0.019405
[11:53:51.049] iteration 21426 : model1 loss : 0.441511 model2 loss : 0.019136
[11:53:51.217] iteration 21427 : model1 loss : 0.439414 model2 loss : 0.021361
[11:53:51.384] iteration 21428 : model1 loss : 0.436229 model2 loss : 0.019689
[11:53:51.554] iteration 21429 : model1 loss : 0.437076 model2 loss : 0.021138
[11:53:51.722] iteration 21430 : model1 loss : 0.438247 model2 loss : 0.021421
[11:53:51.892] iteration 21431 : model1 loss : 0.435321 model2 loss : 0.020106
[11:53:52.061] iteration 21432 : model1 loss : 0.441113 model2 loss : 0.018565
[11:53:52.230] iteration 21433 : model1 loss : 0.439940 model2 loss : 0.019767
[11:53:52.398] iteration 21434 : model1 loss : 0.439139 model2 loss : 0.022240
[11:53:52.566] iteration 21435 : model1 loss : 0.437069 model2 loss : 0.023930
[11:53:52.737] iteration 21436 : model1 loss : 0.440689 model2 loss : 0.021193
[11:53:52.903] iteration 21437 : model1 loss : 0.445628 model2 loss : 0.022218
[11:53:53.073] iteration 21438 : model1 loss : 0.439185 model2 loss : 0.019564
[11:53:53.240] iteration 21439 : model1 loss : 0.438221 model2 loss : 0.022379
[11:53:53.410] iteration 21440 : model1 loss : 0.438590 model2 loss : 0.023430
[11:53:53.576] iteration 21441 : model1 loss : 0.434668 model2 loss : 0.021904
[11:53:53.750] iteration 21442 : model1 loss : 0.437477 model2 loss : 0.021413
[11:53:53.919] iteration 21443 : model1 loss : 0.443581 model2 loss : 0.024785
[11:53:54.089] iteration 21444 : model1 loss : 0.438123 model2 loss : 0.020375
[11:53:54.256] iteration 21445 : model1 loss : 0.432469 model2 loss : 0.018620
[11:53:54.424] iteration 21446 : model1 loss : 0.443857 model2 loss : 0.018999
[11:53:54.594] iteration 21447 : model1 loss : 0.431373 model2 loss : 0.019530
[11:53:54.770] iteration 21448 : model1 loss : 0.440562 model2 loss : 0.019670
[11:53:54.936] iteration 21449 : model1 loss : 0.437874 model2 loss : 0.022477
[11:53:55.106] iteration 21450 : model1 loss : 0.439319 model2 loss : 0.018946
[11:53:57.058] iteration 21451 : model1 loss : 0.441477 model2 loss : 0.019569
[11:53:57.229] iteration 21452 : model1 loss : 0.436224 model2 loss : 0.020561
[11:53:57.400] iteration 21453 : model1 loss : 0.436877 model2 loss : 0.020098
[11:53:57.567] iteration 21454 : model1 loss : 0.439260 model2 loss : 0.019969
[11:53:57.735] iteration 21455 : model1 loss : 0.443629 model2 loss : 0.024893
[11:53:57.903] iteration 21456 : model1 loss : 0.438898 model2 loss : 0.020837
[11:53:58.073] iteration 21457 : model1 loss : 0.441108 model2 loss : 0.023343
[11:53:58.240] iteration 21458 : model1 loss : 0.435066 model2 loss : 0.018711
[11:53:58.409] iteration 21459 : model1 loss : 0.433608 model2 loss : 0.021726
[11:53:58.578] iteration 21460 : model1 loss : 0.442860 model2 loss : 0.022722
[11:53:58.749] iteration 21461 : model1 loss : 0.438727 model2 loss : 0.018899
[11:53:58.916] iteration 21462 : model1 loss : 0.439699 model2 loss : 0.020093
[11:53:59.085] iteration 21463 : model1 loss : 0.439152 model2 loss : 0.021732
[11:53:59.251] iteration 21464 : model1 loss : 0.437732 model2 loss : 0.021279
[11:53:59.421] iteration 21465 : model1 loss : 0.438139 model2 loss : 0.020551
[11:53:59.589] iteration 21466 : model1 loss : 0.437402 model2 loss : 0.019443
[11:53:59.759] iteration 21467 : model1 loss : 0.439237 model2 loss : 0.020729
[11:53:59.927] iteration 21468 : model1 loss : 0.444577 model2 loss : 0.023301
[11:54:00.098] iteration 21469 : model1 loss : 0.443530 model2 loss : 0.023969
[11:54:00.268] iteration 21470 : model1 loss : 0.444014 model2 loss : 0.024662
[11:54:00.436] iteration 21471 : model1 loss : 0.435483 model2 loss : 0.021965
[11:54:00.604] iteration 21472 : model1 loss : 0.435941 model2 loss : 0.021069
[11:54:00.777] iteration 21473 : model1 loss : 0.439719 model2 loss : 0.022832
[11:54:00.966] iteration 21474 : model1 loss : 0.439395 model2 loss : 0.023838
[11:54:01.135] iteration 21475 : model1 loss : 0.439038 model2 loss : 0.020408
[11:54:01.303] iteration 21476 : model1 loss : 0.439141 model2 loss : 0.022716
[11:54:01.471] iteration 21477 : model1 loss : 0.440530 model2 loss : 0.021958
[11:54:01.637] iteration 21478 : model1 loss : 0.438634 model2 loss : 0.023008
[11:54:01.807] iteration 21479 : model1 loss : 0.439866 model2 loss : 0.021448
[11:54:01.977] iteration 21480 : model1 loss : 0.435366 model2 loss : 0.023507
[11:54:02.147] iteration 21481 : model1 loss : 0.437616 model2 loss : 0.024558
[11:54:02.313] iteration 21482 : model1 loss : 0.436382 model2 loss : 0.022070
[11:54:02.482] iteration 21483 : model1 loss : 0.438938 model2 loss : 0.021262
[11:54:04.394] iteration 21484 : model1 loss : 0.435253 model2 loss : 0.020814
[11:54:04.561] iteration 21485 : model1 loss : 0.436232 model2 loss : 0.020996
[11:54:04.732] iteration 21486 : model1 loss : 0.442669 model2 loss : 0.020036
[11:54:04.899] iteration 21487 : model1 loss : 0.436511 model2 loss : 0.022837
[11:54:05.067] iteration 21488 : model1 loss : 0.435799 model2 loss : 0.022524
[11:54:05.234] iteration 21489 : model1 loss : 0.438932 model2 loss : 0.023616
[11:54:05.403] iteration 21490 : model1 loss : 0.440374 model2 loss : 0.019944
[11:54:05.573] iteration 21491 : model1 loss : 0.440643 model2 loss : 0.021132
[11:54:05.742] iteration 21492 : model1 loss : 0.435191 model2 loss : 0.023108
[11:54:05.913] iteration 21493 : model1 loss : 0.444708 model2 loss : 0.024985
[11:54:06.081] iteration 21494 : model1 loss : 0.440045 model2 loss : 0.020467
[11:54:06.249] iteration 21495 : model1 loss : 0.440419 model2 loss : 0.022716
[11:54:06.419] iteration 21496 : model1 loss : 0.440479 model2 loss : 0.023441
[11:54:06.587] iteration 21497 : model1 loss : 0.437777 model2 loss : 0.022763
[11:54:06.758] iteration 21498 : model1 loss : 0.441865 model2 loss : 0.022421
[11:54:06.924] iteration 21499 : model1 loss : 0.437535 model2 loss : 0.021363
[11:54:07.094] iteration 21500 : model1 loss : 0.440771 model2 loss : 0.025253
[11:54:07.262] iteration 21501 : model1 loss : 0.437823 model2 loss : 0.019542
[11:54:07.432] iteration 21502 : model1 loss : 0.438074 model2 loss : 0.020297
[11:54:07.600] iteration 21503 : model1 loss : 0.441973 model2 loss : 0.020297
[11:54:07.770] iteration 21504 : model1 loss : 0.441588 model2 loss : 0.022484
[11:54:07.938] iteration 21505 : model1 loss : 0.435819 model2 loss : 0.019426
[11:54:08.105] iteration 21506 : model1 loss : 0.437418 model2 loss : 0.021189
[11:54:08.275] iteration 21507 : model1 loss : 0.438530 model2 loss : 0.021111
[11:54:08.446] iteration 21508 : model1 loss : 0.436295 model2 loss : 0.018834
[11:54:08.614] iteration 21509 : model1 loss : 0.440893 model2 loss : 0.020685
[11:54:08.784] iteration 21510 : model1 loss : 0.443846 model2 loss : 0.023986
[11:54:08.952] iteration 21511 : model1 loss : 0.436377 model2 loss : 0.019274
[11:54:09.122] iteration 21512 : model1 loss : 0.434418 model2 loss : 0.020586
[11:54:09.293] iteration 21513 : model1 loss : 0.440905 model2 loss : 0.022236
[11:54:09.464] iteration 21514 : model1 loss : 0.437871 model2 loss : 0.019263
[11:54:09.631] iteration 21515 : model1 loss : 0.438538 model2 loss : 0.018242
[11:54:09.802] iteration 21516 : model1 loss : 0.439505 model2 loss : 0.022581
[11:54:11.777] iteration 21517 : model1 loss : 0.437959 model2 loss : 0.019942
[11:54:11.946] iteration 21518 : model1 loss : 0.443036 model2 loss : 0.022445
[11:54:12.117] iteration 21519 : model1 loss : 0.443042 model2 loss : 0.024185
[11:54:12.286] iteration 21520 : model1 loss : 0.440067 model2 loss : 0.020332
[11:54:12.454] iteration 21521 : model1 loss : 0.439341 model2 loss : 0.020163
[11:54:12.622] iteration 21522 : model1 loss : 0.440856 model2 loss : 0.022860
[11:54:12.794] iteration 21523 : model1 loss : 0.439968 model2 loss : 0.022097
[11:54:12.961] iteration 21524 : model1 loss : 0.436240 model2 loss : 0.019579
[11:54:13.130] iteration 21525 : model1 loss : 0.438864 model2 loss : 0.021978
[11:54:13.297] iteration 21526 : model1 loss : 0.436916 model2 loss : 0.020396
[11:54:13.467] iteration 21527 : model1 loss : 0.439191 model2 loss : 0.020697
[11:54:13.637] iteration 21528 : model1 loss : 0.439883 model2 loss : 0.021807
[11:54:13.809] iteration 21529 : model1 loss : 0.436017 model2 loss : 0.021038
[11:54:13.976] iteration 21530 : model1 loss : 0.434663 model2 loss : 0.019952
[11:54:14.147] iteration 21531 : model1 loss : 0.434764 model2 loss : 0.018895
[11:54:14.313] iteration 21532 : model1 loss : 0.441148 model2 loss : 0.020531
[11:54:14.484] iteration 21533 : model1 loss : 0.442070 model2 loss : 0.023061
[11:54:14.654] iteration 21534 : model1 loss : 0.439104 model2 loss : 0.020179
[11:54:14.823] iteration 21535 : model1 loss : 0.437749 model2 loss : 0.020937
[11:54:14.990] iteration 21536 : model1 loss : 0.436154 model2 loss : 0.021386
[11:54:15.159] iteration 21537 : model1 loss : 0.439037 model2 loss : 0.022278
[11:54:15.327] iteration 21538 : model1 loss : 0.438336 model2 loss : 0.022255
[11:54:15.499] iteration 21539 : model1 loss : 0.439477 model2 loss : 0.021529
[11:54:15.668] iteration 21540 : model1 loss : 0.441507 model2 loss : 0.019917
[11:54:15.838] iteration 21541 : model1 loss : 0.441173 model2 loss : 0.023666
[11:54:16.004] iteration 21542 : model1 loss : 0.440494 model2 loss : 0.023591
[11:54:16.177] iteration 21543 : model1 loss : 0.436190 model2 loss : 0.022152
[11:54:16.344] iteration 21544 : model1 loss : 0.436611 model2 loss : 0.020273
[11:54:16.518] iteration 21545 : model1 loss : 0.440056 model2 loss : 0.019872
[11:54:16.687] iteration 21546 : model1 loss : 0.439920 model2 loss : 0.020985
[11:54:16.854] iteration 21547 : model1 loss : 0.438782 model2 loss : 0.020547
[11:54:17.045] iteration 21548 : model1 loss : 0.437101 model2 loss : 0.020227
[11:54:17.212] iteration 21549 : model1 loss : 0.439055 model2 loss : 0.020748
[11:54:19.162] iteration 21550 : model1 loss : 0.437657 model2 loss : 0.022308
[11:54:19.334] iteration 21551 : model1 loss : 0.441179 model2 loss : 0.023847
[11:54:19.508] iteration 21552 : model1 loss : 0.440004 model2 loss : 0.020299
[11:54:19.676] iteration 21553 : model1 loss : 0.441085 model2 loss : 0.020707
[11:54:19.849] iteration 21554 : model1 loss : 0.438786 model2 loss : 0.020597
[11:54:20.015] iteration 21555 : model1 loss : 0.438470 model2 loss : 0.022325
[11:54:20.184] iteration 21556 : model1 loss : 0.436681 model2 loss : 0.019284
[11:54:20.352] iteration 21557 : model1 loss : 0.438035 model2 loss : 0.020456
[11:54:20.526] iteration 21558 : model1 loss : 0.435508 model2 loss : 0.021080
[11:54:20.694] iteration 21559 : model1 loss : 0.436708 model2 loss : 0.022574
[11:54:20.863] iteration 21560 : model1 loss : 0.436019 model2 loss : 0.020272
[11:54:21.029] iteration 21561 : model1 loss : 0.438222 model2 loss : 0.022819
[11:54:21.198] iteration 21562 : model1 loss : 0.440450 model2 loss : 0.022139
[11:54:21.366] iteration 21563 : model1 loss : 0.439490 model2 loss : 0.022009
[11:54:21.538] iteration 21564 : model1 loss : 0.439549 model2 loss : 0.023260
[11:54:21.704] iteration 21565 : model1 loss : 0.437802 model2 loss : 0.019984
[11:54:21.874] iteration 21566 : model1 loss : 0.437707 model2 loss : 0.021096
[11:54:22.041] iteration 21567 : model1 loss : 0.438421 model2 loss : 0.020015
[11:54:22.208] iteration 21568 : model1 loss : 0.440281 model2 loss : 0.020630
[11:54:22.374] iteration 21569 : model1 loss : 0.439478 model2 loss : 0.020317
[11:54:22.545] iteration 21570 : model1 loss : 0.441885 model2 loss : 0.019965
[11:54:22.711] iteration 21571 : model1 loss : 0.443063 model2 loss : 0.020364
[11:54:22.882] iteration 21572 : model1 loss : 0.434572 model2 loss : 0.021380
[11:54:23.049] iteration 21573 : model1 loss : 0.436638 model2 loss : 0.018224
[11:54:23.218] iteration 21574 : model1 loss : 0.438005 model2 loss : 0.019224
[11:54:23.388] iteration 21575 : model1 loss : 0.435774 model2 loss : 0.020381
[11:54:23.556] iteration 21576 : model1 loss : 0.442535 model2 loss : 0.021817
[11:54:23.724] iteration 21577 : model1 loss : 0.437677 model2 loss : 0.019732
[11:54:23.895] iteration 21578 : model1 loss : 0.441448 model2 loss : 0.020131
[11:54:24.063] iteration 21579 : model1 loss : 0.436299 model2 loss : 0.018074
[11:54:24.233] iteration 21580 : model1 loss : 0.441217 model2 loss : 0.019646
[11:54:24.398] iteration 21581 : model1 loss : 0.440225 model2 loss : 0.022606
[11:54:24.567] iteration 21582 : model1 loss : 0.438084 model2 loss : 0.021059
[11:54:26.523] iteration 21583 : model1 loss : 0.444625 model2 loss : 0.022333
[11:54:26.694] iteration 21584 : model1 loss : 0.441917 model2 loss : 0.022084
[11:54:26.869] iteration 21585 : model1 loss : 0.434505 model2 loss : 0.020920
[11:54:27.037] iteration 21586 : model1 loss : 0.440538 model2 loss : 0.020788
[11:54:27.206] iteration 21587 : model1 loss : 0.438557 model2 loss : 0.020227
[11:54:27.371] iteration 21588 : model1 loss : 0.439895 model2 loss : 0.020432
[11:54:27.540] iteration 21589 : model1 loss : 0.440209 model2 loss : 0.020644
[11:54:27.707] iteration 21590 : model1 loss : 0.442870 model2 loss : 0.022794
[11:54:27.875] iteration 21591 : model1 loss : 0.433987 model2 loss : 0.019911
[11:54:28.045] iteration 21592 : model1 loss : 0.436705 model2 loss : 0.020255
[11:54:28.215] iteration 21593 : model1 loss : 0.436295 model2 loss : 0.021171
[11:54:28.383] iteration 21594 : model1 loss : 0.437474 model2 loss : 0.019725
[11:54:28.551] iteration 21595 : model1 loss : 0.435983 model2 loss : 0.018325
[11:54:28.720] iteration 21596 : model1 loss : 0.438524 model2 loss : 0.022136
[11:54:28.889] iteration 21597 : model1 loss : 0.436882 model2 loss : 0.020490
[11:54:29.057] iteration 21598 : model1 loss : 0.441544 model2 loss : 0.023514
[11:54:29.227] iteration 21599 : model1 loss : 0.437187 model2 loss : 0.021681
[11:54:29.396] iteration 21600 : model1 loss : 0.440455 model2 loss : 0.020923
[11:54:29.565] iteration 21601 : model1 loss : 0.436191 model2 loss : 0.019551
[11:54:29.734] iteration 21602 : model1 loss : 0.433573 model2 loss : 0.019273
[11:54:29.902] iteration 21603 : model1 loss : 0.441874 model2 loss : 0.018712
[11:54:30.070] iteration 21604 : model1 loss : 0.439476 model2 loss : 0.019279
[11:54:30.238] iteration 21605 : model1 loss : 0.437225 model2 loss : 0.021628
[11:54:30.404] iteration 21606 : model1 loss : 0.440161 model2 loss : 0.023138
[11:54:30.575] iteration 21607 : model1 loss : 0.439383 model2 loss : 0.020302
[11:54:30.743] iteration 21608 : model1 loss : 0.437493 model2 loss : 0.022266
[11:54:30.915] iteration 21609 : model1 loss : 0.444059 model2 loss : 0.020787
[11:54:31.083] iteration 21610 : model1 loss : 0.437372 model2 loss : 0.023694
[11:54:31.252] iteration 21611 : model1 loss : 0.437264 model2 loss : 0.021548
[11:54:31.420] iteration 21612 : model1 loss : 0.442656 model2 loss : 0.023138
[11:54:31.588] iteration 21613 : model1 loss : 0.435975 model2 loss : 0.019604
[11:54:31.755] iteration 21614 : model1 loss : 0.440636 model2 loss : 0.022443
[11:54:31.924] iteration 21615 : model1 loss : 0.437165 model2 loss : 0.019331
[11:54:33.821] iteration 21616 : model1 loss : 0.444837 model2 loss : 0.020287
[11:54:33.990] iteration 21617 : model1 loss : 0.440115 model2 loss : 0.019271
[11:54:34.162] iteration 21618 : model1 loss : 0.437856 model2 loss : 0.021690
[11:54:34.330] iteration 21619 : model1 loss : 0.437871 model2 loss : 0.020484
[11:54:34.503] iteration 21620 : model1 loss : 0.439474 model2 loss : 0.021940
[11:54:34.670] iteration 21621 : model1 loss : 0.437908 model2 loss : 0.020463
[11:54:34.840] iteration 21622 : model1 loss : 0.438348 model2 loss : 0.019180
[11:54:35.008] iteration 21623 : model1 loss : 0.438589 model2 loss : 0.023271
[11:54:35.176] iteration 21624 : model1 loss : 0.439930 model2 loss : 0.022981
[11:54:35.345] iteration 21625 : model1 loss : 0.436684 model2 loss : 0.020183
[11:54:35.515] iteration 21626 : model1 loss : 0.442026 model2 loss : 0.021860
[11:54:35.682] iteration 21627 : model1 loss : 0.441578 model2 loss : 0.021144
[11:54:35.855] iteration 21628 : model1 loss : 0.442361 model2 loss : 0.022279
[11:54:36.023] iteration 21629 : model1 loss : 0.439641 model2 loss : 0.020574
[11:54:36.191] iteration 21630 : model1 loss : 0.439145 model2 loss : 0.022942
[11:54:36.357] iteration 21631 : model1 loss : 0.439313 model2 loss : 0.022133
[11:54:36.528] iteration 21632 : model1 loss : 0.442589 model2 loss : 0.022774
[11:54:36.697] iteration 21633 : model1 loss : 0.443919 model2 loss : 0.023812
[11:54:36.871] iteration 21634 : model1 loss : 0.433914 model2 loss : 0.020208
[11:54:37.038] iteration 21635 : model1 loss : 0.436302 model2 loss : 0.019195
[11:54:37.210] iteration 21636 : model1 loss : 0.437441 model2 loss : 0.020082
[11:54:37.378] iteration 21637 : model1 loss : 0.436228 model2 loss : 0.021163
[11:54:37.548] iteration 21638 : model1 loss : 0.436685 model2 loss : 0.019673
[11:54:37.714] iteration 21639 : model1 loss : 0.435083 model2 loss : 0.023103
[11:54:37.885] iteration 21640 : model1 loss : 0.440325 model2 loss : 0.020075
[11:54:38.052] iteration 21641 : model1 loss : 0.438280 model2 loss : 0.020435
[11:54:38.223] iteration 21642 : model1 loss : 0.438532 model2 loss : 0.017888
[11:54:38.391] iteration 21643 : model1 loss : 0.439564 model2 loss : 0.019363
[11:54:38.560] iteration 21644 : model1 loss : 0.438606 model2 loss : 0.021375
[11:54:38.730] iteration 21645 : model1 loss : 0.438169 model2 loss : 0.020017
[11:54:38.899] iteration 21646 : model1 loss : 0.436171 model2 loss : 0.021375
[11:54:39.065] iteration 21647 : model1 loss : 0.437695 model2 loss : 0.020596
[11:54:39.236] iteration 21648 : model1 loss : 0.440288 model2 loss : 0.018584
[11:54:41.169] iteration 21649 : model1 loss : 0.435889 model2 loss : 0.019949
[11:54:41.338] iteration 21650 : model1 loss : 0.440942 model2 loss : 0.020839
[11:54:41.512] iteration 21651 : model1 loss : 0.438154 model2 loss : 0.018216
[11:54:41.678] iteration 21652 : model1 loss : 0.437461 model2 loss : 0.020031
[11:54:41.846] iteration 21653 : model1 loss : 0.438841 model2 loss : 0.022816
[11:54:42.014] iteration 21654 : model1 loss : 0.436252 model2 loss : 0.019321
[11:54:42.183] iteration 21655 : model1 loss : 0.439160 model2 loss : 0.019506
[11:54:42.351] iteration 21656 : model1 loss : 0.439452 model2 loss : 0.021751
[11:54:42.522] iteration 21657 : model1 loss : 0.443216 model2 loss : 0.021149
[11:54:42.691] iteration 21658 : model1 loss : 0.441746 model2 loss : 0.019457
[11:54:42.860] iteration 21659 : model1 loss : 0.441629 model2 loss : 0.021976
[11:54:43.028] iteration 21660 : model1 loss : 0.441897 model2 loss : 0.022424
[11:54:43.197] iteration 21661 : model1 loss : 0.436604 model2 loss : 0.021859
[11:54:43.364] iteration 21662 : model1 loss : 0.437328 model2 loss : 0.019926
[11:54:43.540] iteration 21663 : model1 loss : 0.435118 model2 loss : 0.023213
[11:54:43.706] iteration 21664 : model1 loss : 0.445843 model2 loss : 0.024051
[11:54:43.875] iteration 21665 : model1 loss : 0.437843 model2 loss : 0.020058
[11:54:44.045] iteration 21666 : model1 loss : 0.438586 model2 loss : 0.018537
[11:54:44.215] iteration 21667 : model1 loss : 0.438786 model2 loss : 0.019275
[11:54:44.383] iteration 21668 : model1 loss : 0.445507 model2 loss : 0.021460
[11:54:44.554] iteration 21669 : model1 loss : 0.439580 model2 loss : 0.023139
[11:54:44.722] iteration 21670 : model1 loss : 0.434749 model2 loss : 0.019129
[11:54:44.894] iteration 21671 : model1 loss : 0.439667 model2 loss : 0.020734
[11:54:45.062] iteration 21672 : model1 loss : 0.435278 model2 loss : 0.020414
[11:54:45.231] iteration 21673 : model1 loss : 0.437019 model2 loss : 0.019229
[11:54:45.399] iteration 21674 : model1 loss : 0.433496 model2 loss : 0.020983
[11:54:45.569] iteration 21675 : model1 loss : 0.434308 model2 loss : 0.019323
[11:54:45.739] iteration 21676 : model1 loss : 0.439773 model2 loss : 0.024175
[11:54:45.913] iteration 21677 : model1 loss : 0.441444 model2 loss : 0.022806
[11:54:46.080] iteration 21678 : model1 loss : 0.441537 model2 loss : 0.022294
[11:54:46.251] iteration 21679 : model1 loss : 0.435402 model2 loss : 0.020413
[11:54:46.418] iteration 21680 : model1 loss : 0.440596 model2 loss : 0.020617
[11:54:46.594] iteration 21681 : model1 loss : 0.440834 model2 loss : 0.020471
[11:54:48.501] iteration 21682 : model1 loss : 0.443902 model2 loss : 0.024125
[11:54:48.670] iteration 21683 : model1 loss : 0.436772 model2 loss : 0.022110
[11:54:48.841] iteration 21684 : model1 loss : 0.441040 model2 loss : 0.022484
[11:54:49.009] iteration 21685 : model1 loss : 0.438372 model2 loss : 0.019421
[11:54:49.179] iteration 21686 : model1 loss : 0.440782 model2 loss : 0.020080
[11:54:49.347] iteration 21687 : model1 loss : 0.436538 model2 loss : 0.019043
[11:54:49.519] iteration 21688 : model1 loss : 0.438529 model2 loss : 0.018957
[11:54:49.686] iteration 21689 : model1 loss : 0.441476 model2 loss : 0.021197
[11:54:49.856] iteration 21690 : model1 loss : 0.440257 model2 loss : 0.021191
[11:54:50.025] iteration 21691 : model1 loss : 0.443516 model2 loss : 0.020477
[11:54:50.195] iteration 21692 : model1 loss : 0.437750 model2 loss : 0.021738
[11:54:50.361] iteration 21693 : model1 loss : 0.434689 model2 loss : 0.021410
[11:54:50.533] iteration 21694 : model1 loss : 0.440172 model2 loss : 0.020662
[11:54:50.700] iteration 21695 : model1 loss : 0.436397 model2 loss : 0.019617
[11:54:50.872] iteration 21696 : model1 loss : 0.439525 model2 loss : 0.022559
[11:54:51.038] iteration 21697 : model1 loss : 0.441482 model2 loss : 0.022249
[11:54:51.207] iteration 21698 : model1 loss : 0.438104 model2 loss : 0.020734
[11:54:51.375] iteration 21699 : model1 loss : 0.436313 model2 loss : 0.021372
[11:54:51.542] iteration 21700 : model1 loss : 0.439501 model2 loss : 0.019439
[11:54:51.710] iteration 21701 : model1 loss : 0.441278 model2 loss : 0.022195
[11:54:51.879] iteration 21702 : model1 loss : 0.440713 model2 loss : 0.024398
[11:54:52.048] iteration 21703 : model1 loss : 0.438450 model2 loss : 0.022029
[11:54:52.218] iteration 21704 : model1 loss : 0.441281 model2 loss : 0.021219
[11:54:52.387] iteration 21705 : model1 loss : 0.440473 model2 loss : 0.019297
[11:54:52.555] iteration 21706 : model1 loss : 0.439059 model2 loss : 0.022220
[11:54:52.723] iteration 21707 : model1 loss : 0.438680 model2 loss : 0.021125
[11:54:52.893] iteration 21708 : model1 loss : 0.437622 model2 loss : 0.020751
[11:54:53.062] iteration 21709 : model1 loss : 0.435322 model2 loss : 0.020793
[11:54:53.230] iteration 21710 : model1 loss : 0.442050 model2 loss : 0.021095
[11:54:53.398] iteration 21711 : model1 loss : 0.439051 model2 loss : 0.021762
[11:54:53.567] iteration 21712 : model1 loss : 0.440988 model2 loss : 0.021878
[11:54:53.734] iteration 21713 : model1 loss : 0.438349 model2 loss : 0.021960
[11:54:53.902] iteration 21714 : model1 loss : 0.433087 model2 loss : 0.018193
[11:54:55.823] iteration 21715 : model1 loss : 0.439460 model2 loss : 0.020371
[11:54:55.992] iteration 21716 : model1 loss : 0.437262 model2 loss : 0.019295
[11:54:56.163] iteration 21717 : model1 loss : 0.439754 model2 loss : 0.019891
[11:54:56.331] iteration 21718 : model1 loss : 0.443289 model2 loss : 0.024322
[11:54:56.501] iteration 21719 : model1 loss : 0.435206 model2 loss : 0.019266
[11:54:56.670] iteration 21720 : model1 loss : 0.439731 model2 loss : 0.021490
[11:54:56.840] iteration 21721 : model1 loss : 0.441554 model2 loss : 0.022784
[11:54:57.006] iteration 21722 : model1 loss : 0.440635 model2 loss : 0.023042
[11:54:57.177] iteration 21723 : model1 loss : 0.436990 model2 loss : 0.020631
[11:54:57.343] iteration 21724 : model1 loss : 0.436393 model2 loss : 0.021628
[11:54:57.516] iteration 21725 : model1 loss : 0.442083 model2 loss : 0.021913
[11:54:57.683] iteration 21726 : model1 loss : 0.437109 model2 loss : 0.022546
[11:54:57.851] iteration 21727 : model1 loss : 0.443059 model2 loss : 0.023030
[11:54:58.019] iteration 21728 : model1 loss : 0.437755 model2 loss : 0.022458
[11:54:58.188] iteration 21729 : model1 loss : 0.437827 model2 loss : 0.020650
[11:54:58.357] iteration 21730 : model1 loss : 0.438176 model2 loss : 0.020406
[11:54:58.529] iteration 21731 : model1 loss : 0.446530 model2 loss : 0.022054
[11:54:58.695] iteration 21732 : model1 loss : 0.446530 model2 loss : 0.023252
[11:54:58.864] iteration 21733 : model1 loss : 0.438344 model2 loss : 0.020570
[11:54:59.031] iteration 21734 : model1 loss : 0.441530 model2 loss : 0.021415
[11:54:59.202] iteration 21735 : model1 loss : 0.440851 model2 loss : 0.021456
[11:54:59.370] iteration 21736 : model1 loss : 0.435029 model2 loss : 0.017762
[11:54:59.541] iteration 21737 : model1 loss : 0.435173 model2 loss : 0.019960
[11:54:59.709] iteration 21738 : model1 loss : 0.436869 model2 loss : 0.019310
[11:54:59.878] iteration 21739 : model1 loss : 0.437750 model2 loss : 0.020493
[11:55:00.044] iteration 21740 : model1 loss : 0.432000 model2 loss : 0.019828
[11:55:00.212] iteration 21741 : model1 loss : 0.442042 model2 loss : 0.024359
[11:55:00.381] iteration 21742 : model1 loss : 0.440686 model2 loss : 0.024853
[11:55:00.553] iteration 21743 : model1 loss : 0.439866 model2 loss : 0.021293
[11:55:00.721] iteration 21744 : model1 loss : 0.439216 model2 loss : 0.020646
[11:55:00.894] iteration 21745 : model1 loss : 0.441683 model2 loss : 0.022102
[11:55:01.059] iteration 21746 : model1 loss : 0.434431 model2 loss : 0.020270
[11:55:01.229] iteration 21747 : model1 loss : 0.437135 model2 loss : 0.020001
[11:55:03.142] iteration 21748 : model1 loss : 0.443570 model2 loss : 0.023813
[11:55:03.312] iteration 21749 : model1 loss : 0.437025 model2 loss : 0.020186
[11:55:03.482] iteration 21750 : model1 loss : 0.439613 model2 loss : 0.017874
[11:55:03.648] iteration 21751 : model1 loss : 0.441843 model2 loss : 0.022810
[11:55:03.817] iteration 21752 : model1 loss : 0.440670 model2 loss : 0.021614
[11:55:03.983] iteration 21753 : model1 loss : 0.443387 model2 loss : 0.020430
[11:55:04.153] iteration 21754 : model1 loss : 0.439861 model2 loss : 0.021983
[11:55:04.321] iteration 21755 : model1 loss : 0.434998 model2 loss : 0.022145
[11:55:04.492] iteration 21756 : model1 loss : 0.442842 model2 loss : 0.024542
[11:55:04.659] iteration 21757 : model1 loss : 0.438268 model2 loss : 0.017802
[11:55:04.830] iteration 21758 : model1 loss : 0.438780 model2 loss : 0.021371
[11:55:04.999] iteration 21759 : model1 loss : 0.439320 model2 loss : 0.020030
[11:55:05.168] iteration 21760 : model1 loss : 0.437509 model2 loss : 0.020445
[11:55:05.337] iteration 21761 : model1 loss : 0.442082 model2 loss : 0.025474
[11:55:05.510] iteration 21762 : model1 loss : 0.437863 model2 loss : 0.021056
[11:55:05.677] iteration 21763 : model1 loss : 0.440686 model2 loss : 0.021696
[11:55:05.848] iteration 21764 : model1 loss : 0.438804 model2 loss : 0.022356
[11:55:06.015] iteration 21765 : model1 loss : 0.437721 model2 loss : 0.022363
[11:55:06.184] iteration 21766 : model1 loss : 0.438982 model2 loss : 0.020995
[11:55:06.351] iteration 21767 : model1 loss : 0.438964 model2 loss : 0.022974
[11:55:06.523] iteration 21768 : model1 loss : 0.436894 model2 loss : 0.019040
[11:55:06.693] iteration 21769 : model1 loss : 0.433443 model2 loss : 0.018371
[11:55:06.864] iteration 21770 : model1 loss : 0.443418 model2 loss : 0.019357
[11:55:07.030] iteration 21771 : model1 loss : 0.433244 model2 loss : 0.020308
[11:55:07.197] iteration 21772 : model1 loss : 0.435598 model2 loss : 0.019764
[11:55:07.363] iteration 21773 : model1 loss : 0.436084 model2 loss : 0.020942
[11:55:07.532] iteration 21774 : model1 loss : 0.441687 model2 loss : 0.022738
[11:55:07.700] iteration 21775 : model1 loss : 0.439694 model2 loss : 0.021756
[11:55:07.870] iteration 21776 : model1 loss : 0.436159 model2 loss : 0.020019
[11:55:08.037] iteration 21777 : model1 loss : 0.436007 model2 loss : 0.019885
[11:55:08.207] iteration 21778 : model1 loss : 0.439202 model2 loss : 0.021662
[11:55:08.373] iteration 21779 : model1 loss : 0.440208 model2 loss : 0.022269
[11:55:08.542] iteration 21780 : model1 loss : 0.441661 model2 loss : 0.022098
[11:55:10.476] iteration 21781 : model1 loss : 0.437429 model2 loss : 0.018930
[11:55:10.647] iteration 21782 : model1 loss : 0.438021 model2 loss : 0.021783
[11:55:10.817] iteration 21783 : model1 loss : 0.437318 model2 loss : 0.020055
[11:55:10.988] iteration 21784 : model1 loss : 0.438826 model2 loss : 0.021699
[11:55:11.157] iteration 21785 : model1 loss : 0.438610 model2 loss : 0.020153
[11:55:11.325] iteration 21786 : model1 loss : 0.440905 model2 loss : 0.021664
[11:55:11.493] iteration 21787 : model1 loss : 0.439101 model2 loss : 0.021465
[11:55:11.662] iteration 21788 : model1 loss : 0.443381 model2 loss : 0.022884
[11:55:11.831] iteration 21789 : model1 loss : 0.442356 model2 loss : 0.020965
[11:55:11.998] iteration 21790 : model1 loss : 0.441962 model2 loss : 0.023081
[11:55:12.168] iteration 21791 : model1 loss : 0.437673 model2 loss : 0.019581
[11:55:12.336] iteration 21792 : model1 loss : 0.439710 model2 loss : 0.021465
[11:55:12.508] iteration 21793 : model1 loss : 0.440427 model2 loss : 0.020035
[11:55:12.675] iteration 21794 : model1 loss : 0.438724 model2 loss : 0.022035
[11:55:12.845] iteration 21795 : model1 loss : 0.438887 model2 loss : 0.021116
[11:55:13.014] iteration 21796 : model1 loss : 0.444323 model2 loss : 0.023654
[11:55:13.183] iteration 21797 : model1 loss : 0.440510 model2 loss : 0.021223
[11:55:13.351] iteration 21798 : model1 loss : 0.441708 model2 loss : 0.021250
[11:55:13.526] iteration 21799 : model1 loss : 0.444006 model2 loss : 0.023697
[11:55:13.694] iteration 21800 : model1 loss : 0.437375 model2 loss : 0.020456
[11:55:13.863] iteration 21801 : model1 loss : 0.439075 model2 loss : 0.022392
[11:55:14.032] iteration 21802 : model1 loss : 0.438829 model2 loss : 0.019815
[11:55:14.203] iteration 21803 : model1 loss : 0.436160 model2 loss : 0.016851
[11:55:14.371] iteration 21804 : model1 loss : 0.437916 model2 loss : 0.020283
[11:55:14.544] iteration 21805 : model1 loss : 0.438385 model2 loss : 0.018929
[11:55:14.710] iteration 21806 : model1 loss : 0.440292 model2 loss : 0.021054
[11:55:14.878] iteration 21807 : model1 loss : 0.437262 model2 loss : 0.019680
[11:55:15.046] iteration 21808 : model1 loss : 0.434726 model2 loss : 0.021578
[11:55:15.216] iteration 21809 : model1 loss : 0.436025 model2 loss : 0.020430
[11:55:15.384] iteration 21810 : model1 loss : 0.434748 model2 loss : 0.019417
[11:55:15.552] iteration 21811 : model1 loss : 0.436233 model2 loss : 0.021429
[11:55:15.717] iteration 21812 : model1 loss : 0.435803 model2 loss : 0.019563
[11:55:15.890] iteration 21813 : model1 loss : 0.438348 model2 loss : 0.020646
[11:55:17.819] iteration 21814 : model1 loss : 0.437414 model2 loss : 0.020408
[11:55:17.986] iteration 21815 : model1 loss : 0.436011 model2 loss : 0.020059
[11:55:18.155] iteration 21816 : model1 loss : 0.440943 model2 loss : 0.022562
[11:55:18.321] iteration 21817 : model1 loss : 0.439221 model2 loss : 0.022343
[11:55:18.499] iteration 21818 : model1 loss : 0.440263 model2 loss : 0.021084
[11:55:18.667] iteration 21819 : model1 loss : 0.440538 model2 loss : 0.021070
[11:55:18.838] iteration 21820 : model1 loss : 0.438572 model2 loss : 0.020261
[11:55:19.010] iteration 21821 : model1 loss : 0.434918 model2 loss : 0.020213
[11:55:19.179] iteration 21822 : model1 loss : 0.438248 model2 loss : 0.020887
[11:55:19.346] iteration 21823 : model1 loss : 0.439487 model2 loss : 0.019952
[11:55:19.518] iteration 21824 : model1 loss : 0.436757 model2 loss : 0.020318
[11:55:19.686] iteration 21825 : model1 loss : 0.439795 model2 loss : 0.022284
[11:55:19.857] iteration 21826 : model1 loss : 0.440410 model2 loss : 0.022191
[11:55:20.026] iteration 21827 : model1 loss : 0.440918 model2 loss : 0.022419
[11:55:20.196] iteration 21828 : model1 loss : 0.439712 model2 loss : 0.019778
[11:55:20.364] iteration 21829 : model1 loss : 0.436337 model2 loss : 0.021398
[11:55:20.534] iteration 21830 : model1 loss : 0.435862 model2 loss : 0.020145
[11:55:20.703] iteration 21831 : model1 loss : 0.442268 model2 loss : 0.021987
[11:55:20.877] iteration 21832 : model1 loss : 0.437729 model2 loss : 0.018633
[11:55:21.044] iteration 21833 : model1 loss : 0.439091 model2 loss : 0.019831
[11:55:21.212] iteration 21834 : model1 loss : 0.441442 model2 loss : 0.022299
[11:55:21.380] iteration 21835 : model1 loss : 0.439046 model2 loss : 0.022209
[11:55:21.550] iteration 21836 : model1 loss : 0.438451 model2 loss : 0.019720
[11:55:21.718] iteration 21837 : model1 loss : 0.438488 model2 loss : 0.019972
[11:55:21.888] iteration 21838 : model1 loss : 0.437384 model2 loss : 0.019832
[11:55:22.057] iteration 21839 : model1 loss : 0.440529 model2 loss : 0.023386
[11:55:22.224] iteration 21840 : model1 loss : 0.439984 model2 loss : 0.020744
[11:55:22.390] iteration 21841 : model1 loss : 0.436346 model2 loss : 0.021459
[11:55:22.562] iteration 21842 : model1 loss : 0.440230 model2 loss : 0.021578
[11:55:22.732] iteration 21843 : model1 loss : 0.437934 model2 loss : 0.019179
[11:55:22.917] iteration 21844 : model1 loss : 0.440683 model2 loss : 0.020970
[11:55:23.082] iteration 21845 : model1 loss : 0.443022 model2 loss : 0.025793
[11:55:23.252] iteration 21846 : model1 loss : 0.439805 model2 loss : 0.020494
[11:55:25.186] iteration 21847 : model1 loss : 0.436222 model2 loss : 0.019737
[11:55:25.354] iteration 21848 : model1 loss : 0.437773 model2 loss : 0.018086
[11:55:25.529] iteration 21849 : model1 loss : 0.439030 model2 loss : 0.021910
[11:55:25.696] iteration 21850 : model1 loss : 0.436203 model2 loss : 0.020510
[11:55:25.864] iteration 21851 : model1 loss : 0.436555 model2 loss : 0.020598
[11:55:26.031] iteration 21852 : model1 loss : 0.438630 model2 loss : 0.020596
[11:55:26.202] iteration 21853 : model1 loss : 0.442309 model2 loss : 0.021979
[11:55:26.370] iteration 21854 : model1 loss : 0.442012 model2 loss : 0.022177
[11:55:26.542] iteration 21855 : model1 loss : 0.438628 model2 loss : 0.019417
[11:55:26.708] iteration 21856 : model1 loss : 0.441115 model2 loss : 0.021081
[11:55:26.878] iteration 21857 : model1 loss : 0.434069 model2 loss : 0.021483
[11:55:27.046] iteration 21858 : model1 loss : 0.441186 model2 loss : 0.023393
[11:55:27.214] iteration 21859 : model1 loss : 0.443876 model2 loss : 0.019724
[11:55:27.381] iteration 21860 : model1 loss : 0.439976 model2 loss : 0.023629
[11:55:27.552] iteration 21861 : model1 loss : 0.439407 model2 loss : 0.019359
[11:55:27.720] iteration 21862 : model1 loss : 0.438961 model2 loss : 0.020995
[11:55:27.890] iteration 21863 : model1 loss : 0.434971 model2 loss : 0.017780
[11:55:28.059] iteration 21864 : model1 loss : 0.441981 model2 loss : 0.023580
[11:55:28.227] iteration 21865 : model1 loss : 0.441000 model2 loss : 0.019610
[11:55:28.394] iteration 21866 : model1 loss : 0.438590 model2 loss : 0.021634
[11:55:28.564] iteration 21867 : model1 loss : 0.439630 model2 loss : 0.022124
[11:55:28.731] iteration 21868 : model1 loss : 0.438083 model2 loss : 0.019958
[11:55:28.900] iteration 21869 : model1 loss : 0.441915 model2 loss : 0.021765
[11:55:29.068] iteration 21870 : model1 loss : 0.437955 model2 loss : 0.019718
[11:55:29.237] iteration 21871 : model1 loss : 0.441208 model2 loss : 0.023976
[11:55:29.404] iteration 21872 : model1 loss : 0.437369 model2 loss : 0.019917
[11:55:29.585] iteration 21873 : model1 loss : 0.440265 model2 loss : 0.020825
[11:55:29.751] iteration 21874 : model1 loss : 0.437938 model2 loss : 0.021932
[11:55:29.923] iteration 21875 : model1 loss : 0.436132 model2 loss : 0.019900
[11:55:30.090] iteration 21876 : model1 loss : 0.435218 model2 loss : 0.019815
[11:55:30.260] iteration 21877 : model1 loss : 0.438596 model2 loss : 0.020516
[11:55:30.428] iteration 21878 : model1 loss : 0.439316 model2 loss : 0.020477
[11:55:30.596] iteration 21879 : model1 loss : 0.437026 model2 loss : 0.021831
[11:55:32.520] iteration 21880 : model1 loss : 0.439160 model2 loss : 0.021993
[11:55:32.688] iteration 21881 : model1 loss : 0.442061 model2 loss : 0.019718
[11:55:32.856] iteration 21882 : model1 loss : 0.440596 model2 loss : 0.021846
[11:55:33.025] iteration 21883 : model1 loss : 0.442809 model2 loss : 0.021146
[11:55:33.195] iteration 21884 : model1 loss : 0.439151 model2 loss : 0.022462
[11:55:33.363] iteration 21885 : model1 loss : 0.440591 model2 loss : 0.021600
[11:55:33.538] iteration 21886 : model1 loss : 0.435873 model2 loss : 0.021605
[11:55:33.704] iteration 21887 : model1 loss : 0.440137 model2 loss : 0.021098
[11:55:33.873] iteration 21888 : model1 loss : 0.439733 model2 loss : 0.020809
[11:55:34.042] iteration 21889 : model1 loss : 0.436345 model2 loss : 0.019880
[11:55:34.210] iteration 21890 : model1 loss : 0.437253 model2 loss : 0.020514
[11:55:34.377] iteration 21891 : model1 loss : 0.440313 model2 loss : 0.021396
[11:55:34.546] iteration 21892 : model1 loss : 0.436862 model2 loss : 0.019191
[11:55:34.713] iteration 21893 : model1 loss : 0.440022 model2 loss : 0.019688
[11:55:34.882] iteration 21894 : model1 loss : 0.440767 model2 loss : 0.019560
[11:55:35.051] iteration 21895 : model1 loss : 0.439819 model2 loss : 0.021659
[11:55:35.221] iteration 21896 : model1 loss : 0.442677 model2 loss : 0.024167
[11:55:35.389] iteration 21897 : model1 loss : 0.435330 model2 loss : 0.017976
[11:55:35.558] iteration 21898 : model1 loss : 0.439110 model2 loss : 0.023355
[11:55:35.727] iteration 21899 : model1 loss : 0.439568 model2 loss : 0.020747
[11:55:35.897] iteration 21900 : model1 loss : 0.439727 model2 loss : 0.019166
[11:55:36.065] iteration 21901 : model1 loss : 0.444009 model2 loss : 0.028848
[11:55:36.233] iteration 21902 : model1 loss : 0.435684 model2 loss : 0.020833
[11:55:36.400] iteration 21903 : model1 loss : 0.435894 model2 loss : 0.018968
[11:55:36.571] iteration 21904 : model1 loss : 0.438983 model2 loss : 0.022552
[11:55:36.738] iteration 21905 : model1 loss : 0.438541 model2 loss : 0.020238
[11:55:36.908] iteration 21906 : model1 loss : 0.444038 model2 loss : 0.021017
[11:55:37.075] iteration 21907 : model1 loss : 0.441289 model2 loss : 0.019622
[11:55:37.245] iteration 21908 : model1 loss : 0.434273 model2 loss : 0.019665
[11:55:37.414] iteration 21909 : model1 loss : 0.433590 model2 loss : 0.019633
[11:55:37.583] iteration 21910 : model1 loss : 0.440383 model2 loss : 0.021705
[11:55:37.750] iteration 21911 : model1 loss : 0.441242 model2 loss : 0.023966
[11:55:37.918] iteration 21912 : model1 loss : 0.438234 model2 loss : 0.020999
[11:55:39.829] iteration 21913 : model1 loss : 0.439491 model2 loss : 0.021925
[11:55:40.000] iteration 21914 : model1 loss : 0.435474 model2 loss : 0.020921
[11:55:40.170] iteration 21915 : model1 loss : 0.440255 model2 loss : 0.024752
[11:55:40.338] iteration 21916 : model1 loss : 0.432366 model2 loss : 0.019480
[11:55:40.512] iteration 21917 : model1 loss : 0.440801 model2 loss : 0.022705
[11:55:40.677] iteration 21918 : model1 loss : 0.443537 model2 loss : 0.022703
[11:55:40.848] iteration 21919 : model1 loss : 0.438082 model2 loss : 0.019510
[11:55:41.014] iteration 21920 : model1 loss : 0.440453 model2 loss : 0.019156
[11:55:41.185] iteration 21921 : model1 loss : 0.437840 model2 loss : 0.018348
[11:55:41.353] iteration 21922 : model1 loss : 0.436897 model2 loss : 0.019571
[11:55:41.526] iteration 21923 : model1 loss : 0.436262 model2 loss : 0.021373
[11:55:41.692] iteration 21924 : model1 loss : 0.440279 model2 loss : 0.018736
[11:55:41.861] iteration 21925 : model1 loss : 0.438256 model2 loss : 0.022680
[11:55:42.030] iteration 21926 : model1 loss : 0.438760 model2 loss : 0.020238
[11:55:42.197] iteration 21927 : model1 loss : 0.442742 model2 loss : 0.021516
[11:55:42.365] iteration 21928 : model1 loss : 0.438081 model2 loss : 0.024872
[11:55:42.535] iteration 21929 : model1 loss : 0.436348 model2 loss : 0.021031
[11:55:42.703] iteration 21930 : model1 loss : 0.441298 model2 loss : 0.022935
[11:55:42.873] iteration 21931 : model1 loss : 0.443215 model2 loss : 0.022208
[11:55:43.043] iteration 21932 : model1 loss : 0.443025 model2 loss : 0.023234
[11:55:43.212] iteration 21933 : model1 loss : 0.434658 model2 loss : 0.016387
[11:55:43.379] iteration 21934 : model1 loss : 0.438735 model2 loss : 0.023206
[11:55:43.566] iteration 21935 : model1 loss : 0.437603 model2 loss : 0.018123
[11:55:43.733] iteration 21936 : model1 loss : 0.437202 model2 loss : 0.023117
[11:55:43.903] iteration 21937 : model1 loss : 0.437769 model2 loss : 0.018465
[11:55:44.075] iteration 21938 : model1 loss : 0.437746 model2 loss : 0.019310
[11:55:44.244] iteration 21939 : model1 loss : 0.444145 model2 loss : 0.023323
[11:55:44.411] iteration 21940 : model1 loss : 0.437664 model2 loss : 0.020122
[11:55:44.581] iteration 21941 : model1 loss : 0.439528 model2 loss : 0.020524
[11:55:44.749] iteration 21942 : model1 loss : 0.436601 model2 loss : 0.019925
[11:55:44.919] iteration 21943 : model1 loss : 0.440419 model2 loss : 0.021932
[11:55:45.087] iteration 21944 : model1 loss : 0.442812 model2 loss : 0.022392
[11:55:45.253] iteration 21945 : model1 loss : 0.436069 model2 loss : 0.020828
[11:55:47.190] iteration 21946 : model1 loss : 0.442970 model2 loss : 0.022083
[11:55:47.359] iteration 21947 : model1 loss : 0.436611 model2 loss : 0.021144
[11:55:47.535] iteration 21948 : model1 loss : 0.439741 model2 loss : 0.021803
[11:55:47.701] iteration 21949 : model1 loss : 0.441597 model2 loss : 0.021930
[11:55:47.872] iteration 21950 : model1 loss : 0.437689 model2 loss : 0.020700
[11:55:48.042] iteration 21951 : model1 loss : 0.434721 model2 loss : 0.019888
[11:55:48.211] iteration 21952 : model1 loss : 0.436720 model2 loss : 0.018898
[11:55:48.377] iteration 21953 : model1 loss : 0.441101 model2 loss : 0.022043
[11:55:48.547] iteration 21954 : model1 loss : 0.435880 model2 loss : 0.020760
[11:55:48.714] iteration 21955 : model1 loss : 0.438796 model2 loss : 0.022118
[11:55:48.883] iteration 21956 : model1 loss : 0.445639 model2 loss : 0.022142
[11:55:49.054] iteration 21957 : model1 loss : 0.440198 model2 loss : 0.019091
[11:55:49.224] iteration 21958 : model1 loss : 0.436848 model2 loss : 0.021716
[11:55:49.391] iteration 21959 : model1 loss : 0.437601 model2 loss : 0.019801
[11:55:49.560] iteration 21960 : model1 loss : 0.442998 model2 loss : 0.027041
[11:55:49.727] iteration 21961 : model1 loss : 0.437542 model2 loss : 0.020810
[11:55:49.898] iteration 21962 : model1 loss : 0.438727 model2 loss : 0.022863
[11:55:50.068] iteration 21963 : model1 loss : 0.434616 model2 loss : 0.019806
[11:55:50.239] iteration 21964 : model1 loss : 0.441346 model2 loss : 0.020754
[11:55:50.407] iteration 21965 : model1 loss : 0.442545 model2 loss : 0.023559
[11:55:50.575] iteration 21966 : model1 loss : 0.438805 model2 loss : 0.020186
[11:55:50.743] iteration 21967 : model1 loss : 0.440235 model2 loss : 0.021981
[11:55:50.914] iteration 21968 : model1 loss : 0.441708 model2 loss : 0.021417
[11:55:51.081] iteration 21969 : model1 loss : 0.436446 model2 loss : 0.019196
[11:55:51.250] iteration 21970 : model1 loss : 0.437446 model2 loss : 0.019979
[11:55:51.416] iteration 21971 : model1 loss : 0.443137 model2 loss : 0.024122
[11:55:51.586] iteration 21972 : model1 loss : 0.438670 model2 loss : 0.018457
[11:55:51.754] iteration 21973 : model1 loss : 0.434877 model2 loss : 0.020065
[11:55:51.924] iteration 21974 : model1 loss : 0.439972 model2 loss : 0.023469
[11:55:52.093] iteration 21975 : model1 loss : 0.438095 model2 loss : 0.020244
[11:55:52.260] iteration 21976 : model1 loss : 0.436966 model2 loss : 0.023098
[11:55:52.428] iteration 21977 : model1 loss : 0.441088 model2 loss : 0.020720
[11:55:52.595] iteration 21978 : model1 loss : 0.436565 model2 loss : 0.019371
[11:55:54.497] iteration 21979 : model1 loss : 0.432962 model2 loss : 0.021251
[11:55:54.666] iteration 21980 : model1 loss : 0.440981 model2 loss : 0.018870
[11:55:54.837] iteration 21981 : model1 loss : 0.439298 model2 loss : 0.023043
[11:55:55.005] iteration 21982 : model1 loss : 0.438800 model2 loss : 0.020736
[11:55:55.174] iteration 21983 : model1 loss : 0.438091 model2 loss : 0.021071
[11:55:55.342] iteration 21984 : model1 loss : 0.434425 model2 loss : 0.020411
[11:55:55.511] iteration 21985 : model1 loss : 0.442846 model2 loss : 0.021390
[11:55:55.678] iteration 21986 : model1 loss : 0.435273 model2 loss : 0.020078
[11:55:55.847] iteration 21987 : model1 loss : 0.441099 model2 loss : 0.019942
[11:55:56.014] iteration 21988 : model1 loss : 0.439706 model2 loss : 0.021568
[11:55:56.184] iteration 21989 : model1 loss : 0.437915 model2 loss : 0.021109
[11:55:56.351] iteration 21990 : model1 loss : 0.443075 model2 loss : 0.021277
[11:55:56.525] iteration 21991 : model1 loss : 0.436363 model2 loss : 0.019717
[11:55:56.693] iteration 21992 : model1 loss : 0.441238 model2 loss : 0.019028
[11:55:56.864] iteration 21993 : model1 loss : 0.438038 model2 loss : 0.020462
[11:55:57.031] iteration 21994 : model1 loss : 0.442088 model2 loss : 0.022842
[11:55:57.202] iteration 21995 : model1 loss : 0.438132 model2 loss : 0.020593
[11:55:57.372] iteration 21996 : model1 loss : 0.436795 model2 loss : 0.021532
[11:55:57.542] iteration 21997 : model1 loss : 0.440204 model2 loss : 0.024088
[11:55:57.711] iteration 21998 : model1 loss : 0.439106 model2 loss : 0.020027
[11:55:57.882] iteration 21999 : model1 loss : 0.437075 model2 loss : 0.019909
[11:55:58.050] iteration 22000 : model1 loss : 0.436515 model2 loss : 0.020675
[11:56:06.370] iteration 22000 : model1_mean_dice : 0.902299 model1_mean_hd95 : 2.990038
[11:56:14.711] iteration 22000 : model2_mean_dice : 0.897095 model2_mean_hd95 : 1.926740
[11:56:14.888] iteration 22001 : model1 loss : 0.436044 model2 loss : 0.020523
[11:56:15.063] iteration 22002 : model1 loss : 0.441627 model2 loss : 0.022391
[11:56:15.229] iteration 22003 : model1 loss : 0.440041 model2 loss : 0.020294
[11:56:15.397] iteration 22004 : model1 loss : 0.444742 model2 loss : 0.024268
[11:56:15.564] iteration 22005 : model1 loss : 0.437902 model2 loss : 0.018456
[11:56:15.731] iteration 22006 : model1 loss : 0.438478 model2 loss : 0.021466
[11:56:15.909] iteration 22007 : model1 loss : 0.437647 model2 loss : 0.018149
[11:56:16.078] iteration 22008 : model1 loss : 0.441477 model2 loss : 0.021365
[11:56:16.243] iteration 22009 : model1 loss : 0.438249 model2 loss : 0.019424
[11:56:16.411] iteration 22010 : model1 loss : 0.437959 model2 loss : 0.021929
[11:56:16.577] iteration 22011 : model1 loss : 0.440178 model2 loss : 0.021876
[11:56:18.494] iteration 22012 : model1 loss : 0.442684 model2 loss : 0.022111
[11:56:18.660] iteration 22013 : model1 loss : 0.441347 model2 loss : 0.019519
[11:56:18.828] iteration 22014 : model1 loss : 0.436721 model2 loss : 0.021612
[11:56:18.994] iteration 22015 : model1 loss : 0.439163 model2 loss : 0.020778
[11:56:19.163] iteration 22016 : model1 loss : 0.437534 model2 loss : 0.020264
[11:56:19.329] iteration 22017 : model1 loss : 0.441386 model2 loss : 0.022783
[11:56:19.499] iteration 22018 : model1 loss : 0.438734 model2 loss : 0.021103
[11:56:19.665] iteration 22019 : model1 loss : 0.435052 model2 loss : 0.019361
[11:56:19.834] iteration 22020 : model1 loss : 0.438500 model2 loss : 0.020561
[11:56:19.999] iteration 22021 : model1 loss : 0.440077 model2 loss : 0.020010
[11:56:20.171] iteration 22022 : model1 loss : 0.437386 model2 loss : 0.019054
[11:56:20.336] iteration 22023 : model1 loss : 0.436978 model2 loss : 0.019067
[11:56:20.505] iteration 22024 : model1 loss : 0.433663 model2 loss : 0.020381
[11:56:20.671] iteration 22025 : model1 loss : 0.438692 model2 loss : 0.021803
[11:56:20.838] iteration 22026 : model1 loss : 0.441281 model2 loss : 0.021412
[11:56:21.004] iteration 22027 : model1 loss : 0.435115 model2 loss : 0.021619
[11:56:21.173] iteration 22028 : model1 loss : 0.438242 model2 loss : 0.020310
[11:56:21.338] iteration 22029 : model1 loss : 0.438545 model2 loss : 0.020862
[11:56:21.508] iteration 22030 : model1 loss : 0.441780 model2 loss : 0.018807
[11:56:21.673] iteration 22031 : model1 loss : 0.442132 model2 loss : 0.022123
[11:56:21.842] iteration 22032 : model1 loss : 0.444931 model2 loss : 0.021744
[11:56:22.008] iteration 22033 : model1 loss : 0.438314 model2 loss : 0.021068
[11:56:22.179] iteration 22034 : model1 loss : 0.435224 model2 loss : 0.020522
[11:56:22.345] iteration 22035 : model1 loss : 0.442009 model2 loss : 0.022061
[11:56:22.516] iteration 22036 : model1 loss : 0.436620 model2 loss : 0.019290
[11:56:22.684] iteration 22037 : model1 loss : 0.436263 model2 loss : 0.020135
[11:56:22.853] iteration 22038 : model1 loss : 0.440611 model2 loss : 0.024075
[11:56:23.020] iteration 22039 : model1 loss : 0.441271 model2 loss : 0.022898
[11:56:23.189] iteration 22040 : model1 loss : 0.439214 model2 loss : 0.021383
[11:56:23.356] iteration 22041 : model1 loss : 0.439898 model2 loss : 0.023662
[11:56:23.530] iteration 22042 : model1 loss : 0.439003 model2 loss : 0.021434
[11:56:23.695] iteration 22043 : model1 loss : 0.436167 model2 loss : 0.018567
[11:56:23.863] iteration 22044 : model1 loss : 0.441335 model2 loss : 0.018209
[11:56:25.796] iteration 22045 : model1 loss : 0.438812 model2 loss : 0.022185
[11:56:25.964] iteration 22046 : model1 loss : 0.435745 model2 loss : 0.020718
[11:56:26.135] iteration 22047 : model1 loss : 0.441612 model2 loss : 0.024217
[11:56:26.301] iteration 22048 : model1 loss : 0.440140 model2 loss : 0.020939
[11:56:26.471] iteration 22049 : model1 loss : 0.439906 model2 loss : 0.023954
[11:56:26.637] iteration 22050 : model1 loss : 0.439841 model2 loss : 0.021483
[11:56:26.806] iteration 22051 : model1 loss : 0.437725 model2 loss : 0.020828
[11:56:26.973] iteration 22052 : model1 loss : 0.441562 model2 loss : 0.018774
[11:56:27.141] iteration 22053 : model1 loss : 0.438233 model2 loss : 0.019705
[11:56:27.307] iteration 22054 : model1 loss : 0.438425 model2 loss : 0.018749
[11:56:27.475] iteration 22055 : model1 loss : 0.437999 model2 loss : 0.020296
[11:56:27.641] iteration 22056 : model1 loss : 0.439176 model2 loss : 0.017653
[11:56:27.809] iteration 22057 : model1 loss : 0.435232 model2 loss : 0.019915
[11:56:27.974] iteration 22058 : model1 loss : 0.437955 model2 loss : 0.021980
[11:56:28.143] iteration 22059 : model1 loss : 0.439342 model2 loss : 0.021662
[11:56:28.308] iteration 22060 : model1 loss : 0.436846 model2 loss : 0.020479
[11:56:28.478] iteration 22061 : model1 loss : 0.438710 model2 loss : 0.022068
[11:56:28.644] iteration 22062 : model1 loss : 0.438556 model2 loss : 0.019098
[11:56:28.812] iteration 22063 : model1 loss : 0.435062 model2 loss : 0.020174
[11:56:28.980] iteration 22064 : model1 loss : 0.442441 model2 loss : 0.022511
[11:56:29.147] iteration 22065 : model1 loss : 0.439784 model2 loss : 0.019839
[11:56:29.314] iteration 22066 : model1 loss : 0.441699 model2 loss : 0.020453
[11:56:29.481] iteration 22067 : model1 loss : 0.442412 model2 loss : 0.020997
[11:56:29.648] iteration 22068 : model1 loss : 0.436669 model2 loss : 0.018496
[11:56:29.816] iteration 22069 : model1 loss : 0.437254 model2 loss : 0.019829
[11:56:29.984] iteration 22070 : model1 loss : 0.433329 model2 loss : 0.018890
[11:56:30.154] iteration 22071 : model1 loss : 0.440574 model2 loss : 0.021359
[11:56:30.321] iteration 22072 : model1 loss : 0.436795 model2 loss : 0.019683
[11:56:30.490] iteration 22073 : model1 loss : 0.435650 model2 loss : 0.021503
[11:56:30.655] iteration 22074 : model1 loss : 0.438281 model2 loss : 0.020168
[11:56:30.822] iteration 22075 : model1 loss : 0.442249 model2 loss : 0.023630
[11:56:30.988] iteration 22076 : model1 loss : 0.444204 model2 loss : 0.022495
[11:56:31.155] iteration 22077 : model1 loss : 0.440760 model2 loss : 0.021672
[11:56:33.102] iteration 22078 : model1 loss : 0.437458 model2 loss : 0.017928
[11:56:33.273] iteration 22079 : model1 loss : 0.438480 model2 loss : 0.018129
[11:56:33.443] iteration 22080 : model1 loss : 0.435272 model2 loss : 0.021084
[11:56:33.608] iteration 22081 : model1 loss : 0.438532 model2 loss : 0.020084
[11:56:33.777] iteration 22082 : model1 loss : 0.434927 model2 loss : 0.020776
[11:56:33.943] iteration 22083 : model1 loss : 0.437129 model2 loss : 0.020494
[11:56:34.110] iteration 22084 : model1 loss : 0.438792 model2 loss : 0.019185
[11:56:34.277] iteration 22085 : model1 loss : 0.443315 model2 loss : 0.020611
[11:56:34.445] iteration 22086 : model1 loss : 0.439468 model2 loss : 0.019692
[11:56:34.613] iteration 22087 : model1 loss : 0.440207 model2 loss : 0.018436
[11:56:34.782] iteration 22088 : model1 loss : 0.436725 model2 loss : 0.019003
[11:56:34.950] iteration 22089 : model1 loss : 0.438029 model2 loss : 0.022478
[11:56:35.118] iteration 22090 : model1 loss : 0.441785 model2 loss : 0.020472
[11:56:35.284] iteration 22091 : model1 loss : 0.439044 model2 loss : 0.020697
[11:56:35.452] iteration 22092 : model1 loss : 0.437618 model2 loss : 0.020783
[11:56:35.617] iteration 22093 : model1 loss : 0.439274 model2 loss : 0.024337
[11:56:35.785] iteration 22094 : model1 loss : 0.436669 model2 loss : 0.018200
[11:56:35.955] iteration 22095 : model1 loss : 0.441621 model2 loss : 0.023346
[11:56:36.123] iteration 22096 : model1 loss : 0.440404 model2 loss : 0.019021
[11:56:36.290] iteration 22097 : model1 loss : 0.444780 model2 loss : 0.022632
[11:56:36.458] iteration 22098 : model1 loss : 0.441567 model2 loss : 0.021340
[11:56:36.624] iteration 22099 : model1 loss : 0.438702 model2 loss : 0.020375
[11:56:36.793] iteration 22100 : model1 loss : 0.434432 model2 loss : 0.018820
[11:56:36.960] iteration 22101 : model1 loss : 0.442269 model2 loss : 0.022782
[11:56:37.131] iteration 22102 : model1 loss : 0.437499 model2 loss : 0.021956
[11:56:37.298] iteration 22103 : model1 loss : 0.439520 model2 loss : 0.021071
[11:56:37.467] iteration 22104 : model1 loss : 0.437814 model2 loss : 0.020502
[11:56:37.634] iteration 22105 : model1 loss : 0.438087 model2 loss : 0.018959
[11:56:37.801] iteration 22106 : model1 loss : 0.438443 model2 loss : 0.020098
[11:56:37.967] iteration 22107 : model1 loss : 0.441455 model2 loss : 0.019935
[11:56:38.134] iteration 22108 : model1 loss : 0.439189 model2 loss : 0.022376
[11:56:38.313] iteration 22109 : model1 loss : 0.438380 model2 loss : 0.024252
[11:56:38.478] iteration 22110 : model1 loss : 0.437499 model2 loss : 0.021402
[11:56:40.383] iteration 22111 : model1 loss : 0.441142 model2 loss : 0.021947
[11:56:40.550] iteration 22112 : model1 loss : 0.442801 model2 loss : 0.023529
[11:56:40.721] iteration 22113 : model1 loss : 0.444176 model2 loss : 0.021160
[11:56:40.889] iteration 22114 : model1 loss : 0.434880 model2 loss : 0.019822
[11:56:41.057] iteration 22115 : model1 loss : 0.438860 model2 loss : 0.019079
[11:56:41.228] iteration 22116 : model1 loss : 0.439084 model2 loss : 0.018575
[11:56:41.397] iteration 22117 : model1 loss : 0.434856 model2 loss : 0.019614
[11:56:41.564] iteration 22118 : model1 loss : 0.438971 model2 loss : 0.019007
[11:56:41.731] iteration 22119 : model1 loss : 0.433320 model2 loss : 0.021641
[11:56:41.897] iteration 22120 : model1 loss : 0.437135 model2 loss : 0.019543
[11:56:42.066] iteration 22121 : model1 loss : 0.440199 model2 loss : 0.022507
[11:56:42.232] iteration 22122 : model1 loss : 0.441085 model2 loss : 0.022317
[11:56:42.401] iteration 22123 : model1 loss : 0.435827 model2 loss : 0.019871
[11:56:42.567] iteration 22124 : model1 loss : 0.435885 model2 loss : 0.018404
[11:56:42.734] iteration 22125 : model1 loss : 0.440127 model2 loss : 0.023212
[11:56:42.901] iteration 22126 : model1 loss : 0.438932 model2 loss : 0.021144
[11:56:43.071] iteration 22127 : model1 loss : 0.443082 model2 loss : 0.024578
[11:56:43.237] iteration 22128 : model1 loss : 0.435422 model2 loss : 0.019158
[11:56:43.408] iteration 22129 : model1 loss : 0.440450 model2 loss : 0.023312
[11:56:43.575] iteration 22130 : model1 loss : 0.437849 model2 loss : 0.019999
[11:56:43.743] iteration 22131 : model1 loss : 0.440736 model2 loss : 0.020497
[11:56:43.910] iteration 22132 : model1 loss : 0.438351 model2 loss : 0.020170
[11:56:44.078] iteration 22133 : model1 loss : 0.445071 model2 loss : 0.023154
[11:56:44.246] iteration 22134 : model1 loss : 0.440391 model2 loss : 0.021085
[11:56:44.415] iteration 22135 : model1 loss : 0.443258 model2 loss : 0.023198
[11:56:44.583] iteration 22136 : model1 loss : 0.435944 model2 loss : 0.018638
[11:56:44.751] iteration 22137 : model1 loss : 0.437407 model2 loss : 0.020952
[11:56:44.918] iteration 22138 : model1 loss : 0.439175 model2 loss : 0.019070
[11:56:45.088] iteration 22139 : model1 loss : 0.436704 model2 loss : 0.018516
[11:56:45.254] iteration 22140 : model1 loss : 0.435493 model2 loss : 0.020421
[11:56:45.421] iteration 22141 : model1 loss : 0.439935 model2 loss : 0.021704
[11:56:45.587] iteration 22142 : model1 loss : 0.443444 model2 loss : 0.023721
[11:56:45.755] iteration 22143 : model1 loss : 0.436931 model2 loss : 0.019273
[11:56:47.683] iteration 22144 : model1 loss : 0.436578 model2 loss : 0.019299
[11:56:47.848] iteration 22145 : model1 loss : 0.433968 model2 loss : 0.019507
[11:56:48.016] iteration 22146 : model1 loss : 0.443615 model2 loss : 0.023471
[11:56:48.185] iteration 22147 : model1 loss : 0.436599 model2 loss : 0.019819
[11:56:48.355] iteration 22148 : model1 loss : 0.442312 model2 loss : 0.020173
[11:56:48.522] iteration 22149 : model1 loss : 0.439773 model2 loss : 0.020823
[11:56:48.691] iteration 22150 : model1 loss : 0.440608 model2 loss : 0.019249
[11:56:48.857] iteration 22151 : model1 loss : 0.438065 model2 loss : 0.018556
[11:56:49.027] iteration 22152 : model1 loss : 0.443365 model2 loss : 0.023329
[11:56:49.196] iteration 22153 : model1 loss : 0.438005 model2 loss : 0.018531
[11:56:49.364] iteration 22154 : model1 loss : 0.435063 model2 loss : 0.018168
[11:56:49.537] iteration 22155 : model1 loss : 0.438419 model2 loss : 0.020398
[11:56:49.705] iteration 22156 : model1 loss : 0.436358 model2 loss : 0.017134
[11:56:49.870] iteration 22157 : model1 loss : 0.438986 model2 loss : 0.019425
[11:56:50.040] iteration 22158 : model1 loss : 0.442797 model2 loss : 0.021784
[11:56:50.208] iteration 22159 : model1 loss : 0.438018 model2 loss : 0.021499
[11:56:50.375] iteration 22160 : model1 loss : 0.434928 model2 loss : 0.021675
[11:56:50.543] iteration 22161 : model1 loss : 0.436745 model2 loss : 0.019484
[11:56:50.711] iteration 22162 : model1 loss : 0.439821 model2 loss : 0.022101
[11:56:50.878] iteration 22163 : model1 loss : 0.445603 model2 loss : 0.024576
[11:56:51.046] iteration 22164 : model1 loss : 0.440061 model2 loss : 0.022100
[11:56:51.213] iteration 22165 : model1 loss : 0.433766 model2 loss : 0.019605
[11:56:51.384] iteration 22166 : model1 loss : 0.437557 model2 loss : 0.019698
[11:56:51.551] iteration 22167 : model1 loss : 0.442999 model2 loss : 0.021640
[11:56:51.719] iteration 22168 : model1 loss : 0.438907 model2 loss : 0.021884
[11:56:51.885] iteration 22169 : model1 loss : 0.437069 model2 loss : 0.021518
[11:56:52.053] iteration 22170 : model1 loss : 0.439285 model2 loss : 0.020652
[11:56:52.221] iteration 22171 : model1 loss : 0.440449 model2 loss : 0.021512
[11:56:52.388] iteration 22172 : model1 loss : 0.438240 model2 loss : 0.020886
[11:56:52.556] iteration 22173 : model1 loss : 0.441396 model2 loss : 0.018780
[11:56:52.745] iteration 22174 : model1 loss : 0.438823 model2 loss : 0.021440
[11:56:52.910] iteration 22175 : model1 loss : 0.440638 model2 loss : 0.021285
[11:56:53.079] iteration 22176 : model1 loss : 0.437820 model2 loss : 0.020479
[11:56:55.003] iteration 22177 : model1 loss : 0.437422 model2 loss : 0.021582
[11:56:55.177] iteration 22178 : model1 loss : 0.441329 model2 loss : 0.021680
[11:56:55.347] iteration 22179 : model1 loss : 0.440283 model2 loss : 0.021096
[11:56:55.516] iteration 22180 : model1 loss : 0.435547 model2 loss : 0.019128
[11:56:55.686] iteration 22181 : model1 loss : 0.442000 model2 loss : 0.021511
[11:56:55.852] iteration 22182 : model1 loss : 0.437643 model2 loss : 0.021065
[11:56:56.020] iteration 22183 : model1 loss : 0.441022 model2 loss : 0.022313
[11:56:56.188] iteration 22184 : model1 loss : 0.437406 model2 loss : 0.019030
[11:56:56.357] iteration 22185 : model1 loss : 0.440729 model2 loss : 0.019358
[11:56:56.537] iteration 22186 : model1 loss : 0.436165 model2 loss : 0.019178
[11:56:56.704] iteration 22187 : model1 loss : 0.437260 model2 loss : 0.018857
[11:56:56.871] iteration 22188 : model1 loss : 0.439298 model2 loss : 0.022672
[11:56:57.040] iteration 22189 : model1 loss : 0.437868 model2 loss : 0.021347
[11:56:57.210] iteration 22190 : model1 loss : 0.438731 model2 loss : 0.020568
[11:56:57.378] iteration 22191 : model1 loss : 0.437583 model2 loss : 0.019587
[11:56:57.547] iteration 22192 : model1 loss : 0.439805 model2 loss : 0.019899
[11:56:57.714] iteration 22193 : model1 loss : 0.437662 model2 loss : 0.018423
[11:56:57.881] iteration 22194 : model1 loss : 0.443007 model2 loss : 0.023677
[11:56:58.049] iteration 22195 : model1 loss : 0.437985 model2 loss : 0.020387
[11:56:58.219] iteration 22196 : model1 loss : 0.443748 model2 loss : 0.021231
[11:56:58.390] iteration 22197 : model1 loss : 0.438992 model2 loss : 0.020465
[11:56:58.559] iteration 22198 : model1 loss : 0.442521 model2 loss : 0.023412
[11:56:58.730] iteration 22199 : model1 loss : 0.438156 model2 loss : 0.020492
[11:56:58.897] iteration 22200 : model1 loss : 0.434979 model2 loss : 0.021183
[11:56:59.066] iteration 22201 : model1 loss : 0.444889 model2 loss : 0.024213
[11:56:59.233] iteration 22202 : model1 loss : 0.438058 model2 loss : 0.021094
[11:56:59.401] iteration 22203 : model1 loss : 0.435087 model2 loss : 0.021170
[11:56:59.566] iteration 22204 : model1 loss : 0.436293 model2 loss : 0.019018
[11:56:59.734] iteration 22205 : model1 loss : 0.439460 model2 loss : 0.022188
[11:56:59.901] iteration 22206 : model1 loss : 0.437705 model2 loss : 0.019567
[11:57:00.068] iteration 22207 : model1 loss : 0.435620 model2 loss : 0.018557
[11:57:00.234] iteration 22208 : model1 loss : 0.438248 model2 loss : 0.020037
[11:57:00.400] iteration 22209 : model1 loss : 0.439148 model2 loss : 0.022071
[11:57:02.324] iteration 22210 : model1 loss : 0.442234 model2 loss : 0.020743
[11:57:02.490] iteration 22211 : model1 loss : 0.440635 model2 loss : 0.021332
[11:57:02.662] iteration 22212 : model1 loss : 0.438154 model2 loss : 0.024577
[11:57:02.830] iteration 22213 : model1 loss : 0.439354 model2 loss : 0.021802
[11:57:02.999] iteration 22214 : model1 loss : 0.437243 model2 loss : 0.018360
[11:57:03.168] iteration 22215 : model1 loss : 0.439345 model2 loss : 0.019167
[11:57:03.335] iteration 22216 : model1 loss : 0.434275 model2 loss : 0.019829
[11:57:03.504] iteration 22217 : model1 loss : 0.440772 model2 loss : 0.019838
[11:57:03.672] iteration 22218 : model1 loss : 0.437761 model2 loss : 0.022234
[11:57:03.838] iteration 22219 : model1 loss : 0.442654 model2 loss : 0.023034
[11:57:04.005] iteration 22220 : model1 loss : 0.440458 model2 loss : 0.022420
[11:57:04.172] iteration 22221 : model1 loss : 0.435355 model2 loss : 0.018207
[11:57:04.341] iteration 22222 : model1 loss : 0.439496 model2 loss : 0.021594
[11:57:04.524] iteration 22223 : model1 loss : 0.437907 model2 loss : 0.019346
[11:57:04.694] iteration 22224 : model1 loss : 0.435993 model2 loss : 0.018523
[11:57:04.861] iteration 22225 : model1 loss : 0.441882 model2 loss : 0.024760
[11:57:05.031] iteration 22226 : model1 loss : 0.438006 model2 loss : 0.020016
[11:57:05.202] iteration 22227 : model1 loss : 0.435435 model2 loss : 0.021953
[11:57:05.371] iteration 22228 : model1 loss : 0.438736 model2 loss : 0.023503
[11:57:05.539] iteration 22229 : model1 loss : 0.439157 model2 loss : 0.020423
[11:57:05.708] iteration 22230 : model1 loss : 0.440435 model2 loss : 0.018260
[11:57:05.877] iteration 22231 : model1 loss : 0.442683 model2 loss : 0.020743
[11:57:06.045] iteration 22232 : model1 loss : 0.432990 model2 loss : 0.018344
[11:57:06.212] iteration 22233 : model1 loss : 0.434731 model2 loss : 0.020187
[11:57:06.380] iteration 22234 : model1 loss : 0.442429 model2 loss : 0.022937
[11:57:06.549] iteration 22235 : model1 loss : 0.439177 model2 loss : 0.019946
[11:57:06.717] iteration 22236 : model1 loss : 0.441662 model2 loss : 0.022513
[11:57:06.884] iteration 22237 : model1 loss : 0.437703 model2 loss : 0.019688
[11:57:07.053] iteration 22238 : model1 loss : 0.439830 model2 loss : 0.024109
[11:57:07.222] iteration 22239 : model1 loss : 0.435703 model2 loss : 0.021312
[11:57:07.405] iteration 22240 : model1 loss : 0.438796 model2 loss : 0.021457
[11:57:07.570] iteration 22241 : model1 loss : 0.437064 model2 loss : 0.020941
[11:57:07.740] iteration 22242 : model1 loss : 0.444680 model2 loss : 0.024814
[11:57:09.648] iteration 22243 : model1 loss : 0.441129 model2 loss : 0.020574
[11:57:09.814] iteration 22244 : model1 loss : 0.437792 model2 loss : 0.021581
[11:57:09.984] iteration 22245 : model1 loss : 0.436068 model2 loss : 0.018748
[11:57:10.150] iteration 22246 : model1 loss : 0.437063 model2 loss : 0.021712
[11:57:10.319] iteration 22247 : model1 loss : 0.430242 model2 loss : 0.019601
[11:57:10.486] iteration 22248 : model1 loss : 0.440459 model2 loss : 0.022340
[11:57:10.655] iteration 22249 : model1 loss : 0.441439 model2 loss : 0.020587
[11:57:10.824] iteration 22250 : model1 loss : 0.437117 model2 loss : 0.020862
[11:57:10.995] iteration 22251 : model1 loss : 0.448665 model2 loss : 0.029256
[11:57:11.160] iteration 22252 : model1 loss : 0.438446 model2 loss : 0.021355
[11:57:11.330] iteration 22253 : model1 loss : 0.436236 model2 loss : 0.021851
[11:57:11.499] iteration 22254 : model1 loss : 0.436738 model2 loss : 0.023174
[11:57:11.669] iteration 22255 : model1 loss : 0.438448 model2 loss : 0.021007
[11:57:11.835] iteration 22256 : model1 loss : 0.437686 model2 loss : 0.020851
[11:57:12.005] iteration 22257 : model1 loss : 0.438962 model2 loss : 0.019799
[11:57:12.172] iteration 22258 : model1 loss : 0.439249 model2 loss : 0.019939
[11:57:12.341] iteration 22259 : model1 loss : 0.436678 model2 loss : 0.018662
[11:57:12.510] iteration 22260 : model1 loss : 0.433446 model2 loss : 0.017572
[11:57:12.679] iteration 22261 : model1 loss : 0.441997 model2 loss : 0.020727
[11:57:12.847] iteration 22262 : model1 loss : 0.437991 model2 loss : 0.023510
[11:57:13.014] iteration 22263 : model1 loss : 0.444226 model2 loss : 0.024565
[11:57:13.182] iteration 22264 : model1 loss : 0.441664 model2 loss : 0.020691
[11:57:13.351] iteration 22265 : model1 loss : 0.439747 model2 loss : 0.020960
[11:57:13.519] iteration 22266 : model1 loss : 0.440445 model2 loss : 0.022873
[11:57:13.689] iteration 22267 : model1 loss : 0.440441 model2 loss : 0.019816
[11:57:13.856] iteration 22268 : model1 loss : 0.437955 model2 loss : 0.020150
[11:57:14.025] iteration 22269 : model1 loss : 0.439751 model2 loss : 0.023154
[11:57:14.195] iteration 22270 : model1 loss : 0.435916 model2 loss : 0.023704
[11:57:14.364] iteration 22271 : model1 loss : 0.439682 model2 loss : 0.022989
[11:57:14.533] iteration 22272 : model1 loss : 0.438379 model2 loss : 0.020870
[11:57:14.701] iteration 22273 : model1 loss : 0.443069 model2 loss : 0.021970
[11:57:14.866] iteration 22274 : model1 loss : 0.442466 model2 loss : 0.020304
[11:57:15.036] iteration 22275 : model1 loss : 0.441735 model2 loss : 0.019087
[11:57:17.016] iteration 22276 : model1 loss : 0.436842 model2 loss : 0.019098
[11:57:17.185] iteration 22277 : model1 loss : 0.438887 model2 loss : 0.021919
[11:57:17.355] iteration 22278 : model1 loss : 0.440019 model2 loss : 0.019242
[11:57:17.524] iteration 22279 : model1 loss : 0.440133 model2 loss : 0.020535
[11:57:17.692] iteration 22280 : model1 loss : 0.439780 model2 loss : 0.020849
[11:57:17.859] iteration 22281 : model1 loss : 0.438949 model2 loss : 0.019676
[11:57:18.027] iteration 22282 : model1 loss : 0.440775 model2 loss : 0.022156
[11:57:18.196] iteration 22283 : model1 loss : 0.434334 model2 loss : 0.021252
[11:57:18.365] iteration 22284 : model1 loss : 0.441643 model2 loss : 0.022017
[11:57:18.534] iteration 22285 : model1 loss : 0.439678 model2 loss : 0.020290
[11:57:18.701] iteration 22286 : model1 loss : 0.441062 model2 loss : 0.021310
[11:57:18.869] iteration 22287 : model1 loss : 0.440845 model2 loss : 0.020196
[11:57:19.037] iteration 22288 : model1 loss : 0.437758 model2 loss : 0.023723
[11:57:19.205] iteration 22289 : model1 loss : 0.438824 model2 loss : 0.020897
[11:57:19.373] iteration 22290 : model1 loss : 0.442263 model2 loss : 0.021108
[11:57:19.540] iteration 22291 : model1 loss : 0.443602 model2 loss : 0.020601
[11:57:19.711] iteration 22292 : model1 loss : 0.439429 model2 loss : 0.024313
[11:57:19.876] iteration 22293 : model1 loss : 0.440762 model2 loss : 0.020649
[11:57:20.046] iteration 22294 : model1 loss : 0.437323 model2 loss : 0.020947
[11:57:20.214] iteration 22295 : model1 loss : 0.439666 model2 loss : 0.020670
[11:57:20.380] iteration 22296 : model1 loss : 0.441647 model2 loss : 0.023600
[11:57:20.547] iteration 22297 : model1 loss : 0.440063 model2 loss : 0.021302
[11:57:20.715] iteration 22298 : model1 loss : 0.437201 model2 loss : 0.019451
[11:57:20.885] iteration 22299 : model1 loss : 0.438640 model2 loss : 0.018186
[11:57:21.051] iteration 22300 : model1 loss : 0.437794 model2 loss : 0.019204
[11:57:21.221] iteration 22301 : model1 loss : 0.436798 model2 loss : 0.021608
[11:57:21.389] iteration 22302 : model1 loss : 0.439215 model2 loss : 0.021429
[11:57:21.556] iteration 22303 : model1 loss : 0.431506 model2 loss : 0.020686
[11:57:21.724] iteration 22304 : model1 loss : 0.439312 model2 loss : 0.021143
[11:57:21.888] iteration 22305 : model1 loss : 0.437241 model2 loss : 0.020901
[11:57:22.058] iteration 22306 : model1 loss : 0.441277 model2 loss : 0.018258
[11:57:22.224] iteration 22307 : model1 loss : 0.439586 model2 loss : 0.020883
[11:57:22.390] iteration 22308 : model1 loss : 0.434122 model2 loss : 0.019484
[11:57:24.315] iteration 22309 : model1 loss : 0.441922 model2 loss : 0.023152
[11:57:24.484] iteration 22310 : model1 loss : 0.439273 model2 loss : 0.021267
[11:57:24.657] iteration 22311 : model1 loss : 0.433826 model2 loss : 0.018591
[11:57:24.824] iteration 22312 : model1 loss : 0.442703 model2 loss : 0.019058
[11:57:24.995] iteration 22313 : model1 loss : 0.433476 model2 loss : 0.020895
[11:57:25.160] iteration 22314 : model1 loss : 0.438640 model2 loss : 0.020453
[11:57:25.330] iteration 22315 : model1 loss : 0.440138 model2 loss : 0.020658
[11:57:25.498] iteration 22316 : model1 loss : 0.438336 model2 loss : 0.019042
[11:57:25.667] iteration 22317 : model1 loss : 0.437627 model2 loss : 0.020225
[11:57:25.835] iteration 22318 : model1 loss : 0.438818 model2 loss : 0.018641
[11:57:26.001] iteration 22319 : model1 loss : 0.436415 model2 loss : 0.019245
[11:57:26.168] iteration 22320 : model1 loss : 0.437579 model2 loss : 0.021415
[11:57:26.336] iteration 22321 : model1 loss : 0.440244 model2 loss : 0.019205
[11:57:26.506] iteration 22322 : model1 loss : 0.433984 model2 loss : 0.018701
[11:57:26.675] iteration 22323 : model1 loss : 0.441405 model2 loss : 0.020928
[11:57:26.844] iteration 22324 : model1 loss : 0.434579 model2 loss : 0.020462
[11:57:27.013] iteration 22325 : model1 loss : 0.438143 model2 loss : 0.020480
[11:57:27.179] iteration 22326 : model1 loss : 0.440822 model2 loss : 0.021025
[11:57:27.348] iteration 22327 : model1 loss : 0.437070 model2 loss : 0.021771
[11:57:27.520] iteration 22328 : model1 loss : 0.441659 model2 loss : 0.021116
[11:57:27.689] iteration 22329 : model1 loss : 0.443087 model2 loss : 0.022555
[11:57:27.856] iteration 22330 : model1 loss : 0.433644 model2 loss : 0.019850
[11:57:28.026] iteration 22331 : model1 loss : 0.437822 model2 loss : 0.020090
[11:57:28.192] iteration 22332 : model1 loss : 0.441148 model2 loss : 0.021385
[11:57:28.361] iteration 22333 : model1 loss : 0.442309 model2 loss : 0.021117
[11:57:28.529] iteration 22334 : model1 loss : 0.442965 model2 loss : 0.024699
[11:57:28.698] iteration 22335 : model1 loss : 0.440585 model2 loss : 0.022044
[11:57:28.864] iteration 22336 : model1 loss : 0.440928 model2 loss : 0.023580
[11:57:29.034] iteration 22337 : model1 loss : 0.437182 model2 loss : 0.020436
[11:57:29.201] iteration 22338 : model1 loss : 0.435554 model2 loss : 0.019785
[11:57:29.370] iteration 22339 : model1 loss : 0.439718 model2 loss : 0.021206
[11:57:29.536] iteration 22340 : model1 loss : 0.439928 model2 loss : 0.018770
[11:57:29.702] iteration 22341 : model1 loss : 0.446388 model2 loss : 0.026063
[11:57:31.637] iteration 22342 : model1 loss : 0.441606 model2 loss : 0.020030
[11:57:31.807] iteration 22343 : model1 loss : 0.441028 model2 loss : 0.020617
[11:57:31.977] iteration 22344 : model1 loss : 0.440480 model2 loss : 0.020386
[11:57:32.144] iteration 22345 : model1 loss : 0.441981 model2 loss : 0.020729
[11:57:32.311] iteration 22346 : model1 loss : 0.440535 model2 loss : 0.021008
[11:57:32.477] iteration 22347 : model1 loss : 0.434548 model2 loss : 0.020505
[11:57:32.649] iteration 22348 : model1 loss : 0.435599 model2 loss : 0.022660
[11:57:32.815] iteration 22349 : model1 loss : 0.441658 model2 loss : 0.021277
[11:57:32.984] iteration 22350 : model1 loss : 0.437458 model2 loss : 0.021357
[11:57:33.152] iteration 22351 : model1 loss : 0.441276 model2 loss : 0.022200
[11:57:33.319] iteration 22352 : model1 loss : 0.440117 model2 loss : 0.019711
[11:57:33.485] iteration 22353 : model1 loss : 0.443466 model2 loss : 0.022719
[11:57:33.655] iteration 22354 : model1 loss : 0.438399 model2 loss : 0.021060
[11:57:33.823] iteration 22355 : model1 loss : 0.440972 model2 loss : 0.017963
[11:57:33.994] iteration 22356 : model1 loss : 0.435694 model2 loss : 0.019692
[11:57:34.162] iteration 22357 : model1 loss : 0.436468 model2 loss : 0.019824
[11:57:34.330] iteration 22358 : model1 loss : 0.441177 model2 loss : 0.023292
[11:57:34.498] iteration 22359 : model1 loss : 0.438533 model2 loss : 0.020430
[11:57:34.664] iteration 22360 : model1 loss : 0.436436 model2 loss : 0.019612
[11:57:34.831] iteration 22361 : model1 loss : 0.433824 model2 loss : 0.019081
[11:57:35.000] iteration 22362 : model1 loss : 0.443802 model2 loss : 0.023686
[11:57:35.167] iteration 22363 : model1 loss : 0.436975 model2 loss : 0.022115
[11:57:35.335] iteration 22364 : model1 loss : 0.439423 model2 loss : 0.021688
[11:57:35.504] iteration 22365 : model1 loss : 0.441928 model2 loss : 0.020520
[11:57:35.672] iteration 22366 : model1 loss : 0.437368 model2 loss : 0.021139
[11:57:35.839] iteration 22367 : model1 loss : 0.441933 model2 loss : 0.022121
[11:57:36.008] iteration 22368 : model1 loss : 0.436810 model2 loss : 0.019687
[11:57:36.175] iteration 22369 : model1 loss : 0.436958 model2 loss : 0.020408
[11:57:36.344] iteration 22370 : model1 loss : 0.441930 model2 loss : 0.025297
[11:57:36.517] iteration 22371 : model1 loss : 0.442127 model2 loss : 0.021896
[11:57:36.686] iteration 22372 : model1 loss : 0.436818 model2 loss : 0.018945
[11:57:36.853] iteration 22373 : model1 loss : 0.438487 model2 loss : 0.019616
[11:57:37.020] iteration 22374 : model1 loss : 0.439594 model2 loss : 0.022740
[11:57:38.940] iteration 22375 : model1 loss : 0.436696 model2 loss : 0.020760
[11:57:39.107] iteration 22376 : model1 loss : 0.442167 model2 loss : 0.021149
[11:57:39.292] iteration 22377 : model1 loss : 0.437571 model2 loss : 0.021433
[11:57:39.459] iteration 22378 : model1 loss : 0.440551 model2 loss : 0.023263
[11:57:39.625] iteration 22379 : model1 loss : 0.437885 model2 loss : 0.018547
[11:57:39.793] iteration 22380 : model1 loss : 0.436137 model2 loss : 0.020867
[11:57:39.961] iteration 22381 : model1 loss : 0.438902 model2 loss : 0.020931
[11:57:40.130] iteration 22382 : model1 loss : 0.439558 model2 loss : 0.019311
[11:57:40.302] iteration 22383 : model1 loss : 0.440666 model2 loss : 0.021289
[11:57:40.468] iteration 22384 : model1 loss : 0.442294 model2 loss : 0.021284
[11:57:40.637] iteration 22385 : model1 loss : 0.443229 model2 loss : 0.022760
[11:57:40.805] iteration 22386 : model1 loss : 0.437173 model2 loss : 0.022318
[11:57:40.976] iteration 22387 : model1 loss : 0.436195 model2 loss : 0.020207
[11:57:41.144] iteration 22388 : model1 loss : 0.437020 model2 loss : 0.017892
[11:57:41.317] iteration 22389 : model1 loss : 0.438838 model2 loss : 0.018798
[11:57:41.484] iteration 22390 : model1 loss : 0.439373 model2 loss : 0.019729
[11:57:41.654] iteration 22391 : model1 loss : 0.438633 model2 loss : 0.021649
[11:57:41.821] iteration 22392 : model1 loss : 0.440042 model2 loss : 0.021925
[11:57:41.991] iteration 22393 : model1 loss : 0.436658 model2 loss : 0.019508
[11:57:42.157] iteration 22394 : model1 loss : 0.438325 model2 loss : 0.018700
[11:57:42.327] iteration 22395 : model1 loss : 0.438699 model2 loss : 0.020309
[11:57:42.496] iteration 22396 : model1 loss : 0.436459 model2 loss : 0.019420
[11:57:42.665] iteration 22397 : model1 loss : 0.439621 model2 loss : 0.017821
[11:57:42.833] iteration 22398 : model1 loss : 0.438328 model2 loss : 0.017996
[11:57:43.003] iteration 22399 : model1 loss : 0.433003 model2 loss : 0.019772
[11:57:43.171] iteration 22400 : model1 loss : 0.443033 model2 loss : 0.022750
[11:57:43.340] iteration 22401 : model1 loss : 0.442592 model2 loss : 0.019781
[11:57:43.511] iteration 22402 : model1 loss : 0.439940 model2 loss : 0.021237
[11:57:43.679] iteration 22403 : model1 loss : 0.438057 model2 loss : 0.019495
[11:57:43.844] iteration 22404 : model1 loss : 0.439389 model2 loss : 0.020681
[11:57:44.014] iteration 22405 : model1 loss : 0.439789 model2 loss : 0.018110
[11:57:44.178] iteration 22406 : model1 loss : 0.441160 model2 loss : 0.021072
[11:57:44.349] iteration 22407 : model1 loss : 0.438915 model2 loss : 0.019620
[11:57:46.265] iteration 22408 : model1 loss : 0.442209 model2 loss : 0.020273
[11:57:46.437] iteration 22409 : model1 loss : 0.440898 model2 loss : 0.020156
[11:57:46.607] iteration 22410 : model1 loss : 0.435501 model2 loss : 0.021881
[11:57:46.775] iteration 22411 : model1 loss : 0.442756 model2 loss : 0.020625
[11:57:46.944] iteration 22412 : model1 loss : 0.436761 model2 loss : 0.019226
[11:57:47.111] iteration 22413 : model1 loss : 0.441275 model2 loss : 0.021319
[11:57:47.281] iteration 22414 : model1 loss : 0.432193 model2 loss : 0.021004
[11:57:47.448] iteration 22415 : model1 loss : 0.442534 model2 loss : 0.022607
[11:57:47.617] iteration 22416 : model1 loss : 0.440224 model2 loss : 0.019403
[11:57:47.785] iteration 22417 : model1 loss : 0.438755 model2 loss : 0.021658
[11:57:47.953] iteration 22418 : model1 loss : 0.445904 model2 loss : 0.027099
[11:57:48.120] iteration 22419 : model1 loss : 0.436702 model2 loss : 0.019087
[11:57:48.288] iteration 22420 : model1 loss : 0.441638 model2 loss : 0.025060
[11:57:48.455] iteration 22421 : model1 loss : 0.439449 model2 loss : 0.020328
[11:57:48.623] iteration 22422 : model1 loss : 0.432745 model2 loss : 0.019376
[11:57:48.789] iteration 22423 : model1 loss : 0.443251 model2 loss : 0.023807
[11:57:48.962] iteration 22424 : model1 loss : 0.435914 model2 loss : 0.018478
[11:57:49.129] iteration 22425 : model1 loss : 0.436043 model2 loss : 0.018744
[11:57:49.299] iteration 22426 : model1 loss : 0.442367 model2 loss : 0.021681
[11:57:49.465] iteration 22427 : model1 loss : 0.436239 model2 loss : 0.019740
[11:57:49.633] iteration 22428 : model1 loss : 0.437988 model2 loss : 0.021803
[11:57:49.799] iteration 22429 : model1 loss : 0.437817 model2 loss : 0.020809
[11:57:49.968] iteration 22430 : model1 loss : 0.440912 model2 loss : 0.020610
[11:57:50.136] iteration 22431 : model1 loss : 0.442248 model2 loss : 0.023464
[11:57:50.308] iteration 22432 : model1 loss : 0.438245 model2 loss : 0.021726
[11:57:50.477] iteration 22433 : model1 loss : 0.443243 model2 loss : 0.020220
[11:57:50.646] iteration 22434 : model1 loss : 0.436371 model2 loss : 0.021419
[11:57:50.812] iteration 22435 : model1 loss : 0.434560 model2 loss : 0.019557
[11:57:50.982] iteration 22436 : model1 loss : 0.434292 model2 loss : 0.020865
[11:57:51.151] iteration 22437 : model1 loss : 0.437045 model2 loss : 0.018166
[11:57:51.323] iteration 22438 : model1 loss : 0.441003 model2 loss : 0.021759
[11:57:51.490] iteration 22439 : model1 loss : 0.440775 model2 loss : 0.021577
[11:57:51.657] iteration 22440 : model1 loss : 0.437843 model2 loss : 0.019657
[11:57:53.592] iteration 22441 : model1 loss : 0.439854 model2 loss : 0.021334
[11:57:53.760] iteration 22442 : model1 loss : 0.438658 model2 loss : 0.019914
[11:57:53.929] iteration 22443 : model1 loss : 0.442223 model2 loss : 0.021609
[11:57:54.096] iteration 22444 : model1 loss : 0.434623 model2 loss : 0.023607
[11:57:54.263] iteration 22445 : model1 loss : 0.436276 model2 loss : 0.017775
[11:57:54.430] iteration 22446 : model1 loss : 0.435740 model2 loss : 0.019481
[11:57:54.603] iteration 22447 : model1 loss : 0.441116 model2 loss : 0.020834
[11:57:54.771] iteration 22448 : model1 loss : 0.437792 model2 loss : 0.021506
[11:57:54.940] iteration 22449 : model1 loss : 0.433576 model2 loss : 0.019729
[11:57:55.106] iteration 22450 : model1 loss : 0.441143 model2 loss : 0.022617
[11:57:55.275] iteration 22451 : model1 loss : 0.438450 model2 loss : 0.020538
[11:57:55.442] iteration 22452 : model1 loss : 0.438587 model2 loss : 0.019924
[11:57:55.625] iteration 22453 : model1 loss : 0.442330 model2 loss : 0.022563
[11:57:55.791] iteration 22454 : model1 loss : 0.440896 model2 loss : 0.018218
[11:57:55.960] iteration 22455 : model1 loss : 0.443203 model2 loss : 0.022329
[11:57:56.127] iteration 22456 : model1 loss : 0.440863 model2 loss : 0.018872
[11:57:56.295] iteration 22457 : model1 loss : 0.439203 model2 loss : 0.019066
[11:57:56.463] iteration 22458 : model1 loss : 0.440278 model2 loss : 0.020619
[11:57:56.631] iteration 22459 : model1 loss : 0.440603 model2 loss : 0.019977
[11:57:56.810] iteration 22460 : model1 loss : 0.439918 model2 loss : 0.020815
[11:57:56.980] iteration 22461 : model1 loss : 0.440010 model2 loss : 0.019709
[11:57:57.149] iteration 22462 : model1 loss : 0.435068 model2 loss : 0.019877
[11:57:57.317] iteration 22463 : model1 loss : 0.442350 model2 loss : 0.023959
[11:57:57.484] iteration 22464 : model1 loss : 0.436215 model2 loss : 0.019264
[11:57:57.653] iteration 22465 : model1 loss : 0.434473 model2 loss : 0.019590
[11:57:57.819] iteration 22466 : model1 loss : 0.442126 model2 loss : 0.022359
[11:57:57.989] iteration 22467 : model1 loss : 0.439141 model2 loss : 0.021722
[11:57:58.155] iteration 22468 : model1 loss : 0.441495 model2 loss : 0.021456
[11:57:58.324] iteration 22469 : model1 loss : 0.439308 model2 loss : 0.020145
[11:57:58.493] iteration 22470 : model1 loss : 0.437046 model2 loss : 0.021875
[11:57:58.662] iteration 22471 : model1 loss : 0.437840 model2 loss : 0.022447
[11:57:58.826] iteration 22472 : model1 loss : 0.441498 model2 loss : 0.021441
[11:57:58.993] iteration 22473 : model1 loss : 0.437990 model2 loss : 0.020787
[11:58:00.908] iteration 22474 : model1 loss : 0.439844 model2 loss : 0.019544
[11:58:01.074] iteration 22475 : model1 loss : 0.437341 model2 loss : 0.021571
[11:58:01.245] iteration 22476 : model1 loss : 0.444551 model2 loss : 0.023567
[11:58:01.415] iteration 22477 : model1 loss : 0.442468 model2 loss : 0.020709
[11:58:01.583] iteration 22478 : model1 loss : 0.438822 model2 loss : 0.018118
[11:58:01.754] iteration 22479 : model1 loss : 0.442795 model2 loss : 0.021390
[11:58:01.921] iteration 22480 : model1 loss : 0.442571 model2 loss : 0.019018
[11:58:02.088] iteration 22481 : model1 loss : 0.438871 model2 loss : 0.017798
[11:58:02.258] iteration 22482 : model1 loss : 0.436957 model2 loss : 0.020534
[11:58:02.425] iteration 22483 : model1 loss : 0.435856 model2 loss : 0.021321
[11:58:02.595] iteration 22484 : model1 loss : 0.441880 model2 loss : 0.021847
[11:58:02.761] iteration 22485 : model1 loss : 0.431747 model2 loss : 0.020474
[11:58:02.931] iteration 22486 : model1 loss : 0.438175 model2 loss : 0.019210
[11:58:03.098] iteration 22487 : model1 loss : 0.437305 model2 loss : 0.021255
[11:58:03.267] iteration 22488 : model1 loss : 0.442681 model2 loss : 0.018948
[11:58:03.437] iteration 22489 : model1 loss : 0.440172 model2 loss : 0.020664
[11:58:03.606] iteration 22490 : model1 loss : 0.441439 model2 loss : 0.021605
[11:58:03.776] iteration 22491 : model1 loss : 0.436980 model2 loss : 0.020406
[11:58:03.949] iteration 22492 : model1 loss : 0.439184 model2 loss : 0.021639
[11:58:04.118] iteration 22493 : model1 loss : 0.438890 model2 loss : 0.018888
[11:58:04.286] iteration 22494 : model1 loss : 0.436863 model2 loss : 0.020674
[11:58:04.453] iteration 22495 : model1 loss : 0.435098 model2 loss : 0.020652
[11:58:04.622] iteration 22496 : model1 loss : 0.440637 model2 loss : 0.020536
[11:58:04.788] iteration 22497 : model1 loss : 0.440492 model2 loss : 0.023695
[11:58:04.959] iteration 22498 : model1 loss : 0.439410 model2 loss : 0.019860
[11:58:05.126] iteration 22499 : model1 loss : 0.439705 model2 loss : 0.018975
[11:58:05.297] iteration 22500 : model1 loss : 0.437962 model2 loss : 0.021587
[11:58:05.465] iteration 22501 : model1 loss : 0.438622 model2 loss : 0.020081
[11:58:05.635] iteration 22502 : model1 loss : 0.436262 model2 loss : 0.020093
[11:58:05.803] iteration 22503 : model1 loss : 0.436880 model2 loss : 0.020037
[11:58:05.972] iteration 22504 : model1 loss : 0.442839 model2 loss : 0.020651
[11:58:06.138] iteration 22505 : model1 loss : 0.437291 model2 loss : 0.021862
[11:58:06.306] iteration 22506 : model1 loss : 0.437890 model2 loss : 0.020705
[11:58:08.240] iteration 22507 : model1 loss : 0.435286 model2 loss : 0.018644
[11:58:08.410] iteration 22508 : model1 loss : 0.440566 model2 loss : 0.019978
[11:58:08.579] iteration 22509 : model1 loss : 0.436691 model2 loss : 0.020460
[11:58:08.746] iteration 22510 : model1 loss : 0.437950 model2 loss : 0.021033
[11:58:08.916] iteration 22511 : model1 loss : 0.443035 model2 loss : 0.020500
[11:58:09.083] iteration 22512 : model1 loss : 0.441509 model2 loss : 0.021146
[11:58:09.251] iteration 22513 : model1 loss : 0.440000 model2 loss : 0.022315
[11:58:09.420] iteration 22514 : model1 loss : 0.441718 model2 loss : 0.022819
[11:58:09.592] iteration 22515 : model1 loss : 0.438851 model2 loss : 0.018747
[11:58:09.758] iteration 22516 : model1 loss : 0.438585 model2 loss : 0.020017
[11:58:09.927] iteration 22517 : model1 loss : 0.439351 model2 loss : 0.018608
[11:58:10.093] iteration 22518 : model1 loss : 0.441465 model2 loss : 0.020144
[11:58:10.261] iteration 22519 : model1 loss : 0.435232 model2 loss : 0.019422
[11:58:10.428] iteration 22520 : model1 loss : 0.437879 model2 loss : 0.022287
[11:58:10.598] iteration 22521 : model1 loss : 0.440995 model2 loss : 0.021157
[11:58:10.763] iteration 22522 : model1 loss : 0.433739 model2 loss : 0.019007
[11:58:10.941] iteration 22523 : model1 loss : 0.437235 model2 loss : 0.020512
[11:58:11.108] iteration 22524 : model1 loss : 0.437006 model2 loss : 0.022357
[11:58:11.278] iteration 22525 : model1 loss : 0.436680 model2 loss : 0.021833
[11:58:11.444] iteration 22526 : model1 loss : 0.440250 model2 loss : 0.020398
[11:58:11.613] iteration 22527 : model1 loss : 0.438774 model2 loss : 0.016910
[11:58:11.778] iteration 22528 : model1 loss : 0.438616 model2 loss : 0.019950
[11:58:11.948] iteration 22529 : model1 loss : 0.444134 model2 loss : 0.022489
[11:58:12.115] iteration 22530 : model1 loss : 0.441334 model2 loss : 0.021434
[11:58:12.287] iteration 22531 : model1 loss : 0.442181 model2 loss : 0.019957
[11:58:12.454] iteration 22532 : model1 loss : 0.434507 model2 loss : 0.021061
[11:58:12.622] iteration 22533 : model1 loss : 0.438113 model2 loss : 0.018675
[11:58:12.788] iteration 22534 : model1 loss : 0.443831 model2 loss : 0.023252
[11:58:12.959] iteration 22535 : model1 loss : 0.435491 model2 loss : 0.020282
[11:58:13.127] iteration 22536 : model1 loss : 0.439014 model2 loss : 0.020168
[11:58:13.297] iteration 22537 : model1 loss : 0.440430 model2 loss : 0.018429
[11:58:13.463] iteration 22538 : model1 loss : 0.439840 model2 loss : 0.022086
[11:58:13.632] iteration 22539 : model1 loss : 0.440476 model2 loss : 0.021092
[11:58:15.540] iteration 22540 : model1 loss : 0.438728 model2 loss : 0.019177
[11:58:15.708] iteration 22541 : model1 loss : 0.438626 model2 loss : 0.019418
[11:58:15.882] iteration 22542 : model1 loss : 0.442279 model2 loss : 0.021589
[11:58:16.049] iteration 22543 : model1 loss : 0.434213 model2 loss : 0.019528
[11:58:16.218] iteration 22544 : model1 loss : 0.439188 model2 loss : 0.021065
[11:58:16.385] iteration 22545 : model1 loss : 0.438324 model2 loss : 0.019311
[11:58:16.554] iteration 22546 : model1 loss : 0.441548 model2 loss : 0.020361
[11:58:16.720] iteration 22547 : model1 loss : 0.437487 model2 loss : 0.022279
[11:58:16.891] iteration 22548 : model1 loss : 0.438802 model2 loss : 0.020247
[11:58:17.058] iteration 22549 : model1 loss : 0.441947 model2 loss : 0.022170
[11:58:17.224] iteration 22550 : model1 loss : 0.440234 model2 loss : 0.018551
[11:58:17.390] iteration 22551 : model1 loss : 0.443026 model2 loss : 0.020821
[11:58:17.561] iteration 22552 : model1 loss : 0.439519 model2 loss : 0.020087
[11:58:17.729] iteration 22553 : model1 loss : 0.440092 model2 loss : 0.020460
[11:58:17.899] iteration 22554 : model1 loss : 0.440565 model2 loss : 0.019513
[11:58:18.067] iteration 22555 : model1 loss : 0.439956 model2 loss : 0.021079
[11:58:18.238] iteration 22556 : model1 loss : 0.440854 model2 loss : 0.020838
[11:58:18.405] iteration 22557 : model1 loss : 0.437342 model2 loss : 0.022583
[11:58:18.575] iteration 22558 : model1 loss : 0.440295 model2 loss : 0.020963
[11:58:18.742] iteration 22559 : model1 loss : 0.438709 model2 loss : 0.023112
[11:58:18.911] iteration 22560 : model1 loss : 0.439603 model2 loss : 0.019758
[11:58:19.079] iteration 22561 : model1 loss : 0.435987 model2 loss : 0.020153
[11:58:19.250] iteration 22562 : model1 loss : 0.438919 model2 loss : 0.019300
[11:58:19.421] iteration 22563 : model1 loss : 0.440874 model2 loss : 0.022025
[11:58:19.592] iteration 22564 : model1 loss : 0.440188 model2 loss : 0.022206
[11:58:19.758] iteration 22565 : model1 loss : 0.436360 model2 loss : 0.024345
[11:58:19.926] iteration 22566 : model1 loss : 0.438612 model2 loss : 0.022205
[11:58:20.093] iteration 22567 : model1 loss : 0.434978 model2 loss : 0.017317
[11:58:20.264] iteration 22568 : model1 loss : 0.442019 model2 loss : 0.021245
[11:58:20.437] iteration 22569 : model1 loss : 0.437180 model2 loss : 0.020081
[11:58:20.606] iteration 22570 : model1 loss : 0.443404 model2 loss : 0.020297
[11:58:20.772] iteration 22571 : model1 loss : 0.431684 model2 loss : 0.018994
[11:58:20.947] iteration 22572 : model1 loss : 0.439493 model2 loss : 0.022528
[11:58:22.862] iteration 22573 : model1 loss : 0.433870 model2 loss : 0.020281
[11:58:23.033] iteration 22574 : model1 loss : 0.436201 model2 loss : 0.020039
[11:58:23.204] iteration 22575 : model1 loss : 0.440506 model2 loss : 0.023452
[11:58:23.372] iteration 22576 : model1 loss : 0.439850 model2 loss : 0.020675
[11:58:23.543] iteration 22577 : model1 loss : 0.438271 model2 loss : 0.019410
[11:58:23.711] iteration 22578 : model1 loss : 0.438388 model2 loss : 0.021313
[11:58:23.882] iteration 22579 : model1 loss : 0.442559 model2 loss : 0.018288
[11:58:24.048] iteration 22580 : model1 loss : 0.436874 model2 loss : 0.017267
[11:58:24.218] iteration 22581 : model1 loss : 0.436643 model2 loss : 0.019566
[11:58:24.384] iteration 22582 : model1 loss : 0.443578 model2 loss : 0.024873
[11:58:24.554] iteration 22583 : model1 loss : 0.435547 model2 loss : 0.019101
[11:58:24.723] iteration 22584 : model1 loss : 0.439882 model2 loss : 0.020194
[11:58:24.892] iteration 22585 : model1 loss : 0.438630 model2 loss : 0.021176
[11:58:25.060] iteration 22586 : model1 loss : 0.432370 model2 loss : 0.019661
[11:58:25.231] iteration 22587 : model1 loss : 0.439401 model2 loss : 0.021401
[11:58:25.398] iteration 22588 : model1 loss : 0.437913 model2 loss : 0.019586
[11:58:25.568] iteration 22589 : model1 loss : 0.439149 model2 loss : 0.020219
[11:58:25.735] iteration 22590 : model1 loss : 0.438929 model2 loss : 0.021469
[11:58:25.906] iteration 22591 : model1 loss : 0.440395 model2 loss : 0.022590
[11:58:26.085] iteration 22592 : model1 loss : 0.436770 model2 loss : 0.019839
[11:58:26.259] iteration 22593 : model1 loss : 0.439673 model2 loss : 0.022502
[11:58:26.430] iteration 22594 : model1 loss : 0.441155 model2 loss : 0.022923
[11:58:26.599] iteration 22595 : model1 loss : 0.443382 model2 loss : 0.020979
[11:58:26.768] iteration 22596 : model1 loss : 0.444221 model2 loss : 0.020588
[11:58:26.936] iteration 22597 : model1 loss : 0.438636 model2 loss : 0.020092
[11:58:27.104] iteration 22598 : model1 loss : 0.435296 model2 loss : 0.022184
[11:58:27.273] iteration 22599 : model1 loss : 0.441132 model2 loss : 0.020759
[11:58:27.443] iteration 22600 : model1 loss : 0.440459 model2 loss : 0.022671
[11:58:27.615] iteration 22601 : model1 loss : 0.440895 model2 loss : 0.020462
[11:58:27.784] iteration 22602 : model1 loss : 0.438087 model2 loss : 0.018771
[11:58:27.953] iteration 22603 : model1 loss : 0.441724 model2 loss : 0.018181
[11:58:28.121] iteration 22604 : model1 loss : 0.440381 model2 loss : 0.020662
[11:58:28.290] iteration 22605 : model1 loss : 0.437848 model2 loss : 0.018719
[11:58:30.198] iteration 22606 : model1 loss : 0.434851 model2 loss : 0.018910
[11:58:30.365] iteration 22607 : model1 loss : 0.436186 model2 loss : 0.019022
[11:58:30.537] iteration 22608 : model1 loss : 0.437246 model2 loss : 0.020011
[11:58:30.705] iteration 22609 : model1 loss : 0.442114 model2 loss : 0.022338
[11:58:30.875] iteration 22610 : model1 loss : 0.439602 model2 loss : 0.020022
[11:58:31.043] iteration 22611 : model1 loss : 0.442036 model2 loss : 0.020083
[11:58:31.211] iteration 22612 : model1 loss : 0.437593 model2 loss : 0.021198
[11:58:31.379] iteration 22613 : model1 loss : 0.439987 model2 loss : 0.019775
[11:58:31.548] iteration 22614 : model1 loss : 0.439183 model2 loss : 0.020522
[11:58:31.716] iteration 22615 : model1 loss : 0.439149 model2 loss : 0.020898
[11:58:31.884] iteration 22616 : model1 loss : 0.444754 model2 loss : 0.025366
[11:58:32.050] iteration 22617 : model1 loss : 0.441745 model2 loss : 0.020967
[11:58:32.218] iteration 22618 : model1 loss : 0.436440 model2 loss : 0.017886
[11:58:32.384] iteration 22619 : model1 loss : 0.438762 model2 loss : 0.022117
[11:58:32.553] iteration 22620 : model1 loss : 0.436878 model2 loss : 0.021340
[11:58:32.723] iteration 22621 : model1 loss : 0.443691 model2 loss : 0.022862
[11:58:32.892] iteration 22622 : model1 loss : 0.432803 model2 loss : 0.020157
[11:58:33.061] iteration 22623 : model1 loss : 0.437376 model2 loss : 0.020560
[11:58:33.232] iteration 22624 : model1 loss : 0.440854 model2 loss : 0.021202
[11:58:33.400] iteration 22625 : model1 loss : 0.437265 model2 loss : 0.019718
[11:58:33.571] iteration 22626 : model1 loss : 0.445418 model2 loss : 0.019852
[11:58:33.738] iteration 22627 : model1 loss : 0.438184 model2 loss : 0.019910
[11:58:33.907] iteration 22628 : model1 loss : 0.440180 model2 loss : 0.018941
[11:58:34.074] iteration 22629 : model1 loss : 0.437367 model2 loss : 0.020939
[11:58:34.244] iteration 22630 : model1 loss : 0.435229 model2 loss : 0.017039
[11:58:34.414] iteration 22631 : model1 loss : 0.437567 model2 loss : 0.019813
[11:58:34.583] iteration 22632 : model1 loss : 0.440588 model2 loss : 0.020381
[11:58:34.752] iteration 22633 : model1 loss : 0.442770 model2 loss : 0.021995
[11:58:34.922] iteration 22634 : model1 loss : 0.439926 model2 loss : 0.021343
[11:58:35.090] iteration 22635 : model1 loss : 0.436601 model2 loss : 0.022118
[11:58:35.258] iteration 22636 : model1 loss : 0.437925 model2 loss : 0.019531
[11:58:35.423] iteration 22637 : model1 loss : 0.438768 model2 loss : 0.019956
[11:58:35.593] iteration 22638 : model1 loss : 0.442036 model2 loss : 0.020080
[11:58:37.519] iteration 22639 : model1 loss : 0.438822 model2 loss : 0.021891
[11:58:37.686] iteration 22640 : model1 loss : 0.440647 model2 loss : 0.021762
[11:58:37.858] iteration 22641 : model1 loss : 0.438948 model2 loss : 0.019988
[11:58:38.024] iteration 22642 : model1 loss : 0.438183 model2 loss : 0.019638
[11:58:38.194] iteration 22643 : model1 loss : 0.442366 model2 loss : 0.021209
[11:58:38.361] iteration 22644 : model1 loss : 0.436550 model2 loss : 0.020114
[11:58:38.531] iteration 22645 : model1 loss : 0.439141 model2 loss : 0.020634
[11:58:38.700] iteration 22646 : model1 loss : 0.439519 model2 loss : 0.020462
[11:58:38.869] iteration 22647 : model1 loss : 0.437086 model2 loss : 0.018492
[11:58:39.038] iteration 22648 : model1 loss : 0.437658 model2 loss : 0.019256
[11:58:39.225] iteration 22649 : model1 loss : 0.441764 model2 loss : 0.020537
[11:58:39.393] iteration 22650 : model1 loss : 0.434443 model2 loss : 0.019200
[11:58:39.562] iteration 22651 : model1 loss : 0.438397 model2 loss : 0.020090
[11:58:39.729] iteration 22652 : model1 loss : 0.442110 model2 loss : 0.020785
[11:58:39.898] iteration 22653 : model1 loss : 0.440083 model2 loss : 0.020452
[11:58:40.064] iteration 22654 : model1 loss : 0.440997 model2 loss : 0.024844
[11:58:40.236] iteration 22655 : model1 loss : 0.438456 model2 loss : 0.018503
[11:58:40.405] iteration 22656 : model1 loss : 0.440581 model2 loss : 0.023804
[11:58:40.574] iteration 22657 : model1 loss : 0.439376 model2 loss : 0.020589
[11:58:40.741] iteration 22658 : model1 loss : 0.436315 model2 loss : 0.019713
[11:58:40.913] iteration 22659 : model1 loss : 0.441046 model2 loss : 0.021016
[11:58:41.081] iteration 22660 : model1 loss : 0.443138 model2 loss : 0.017474
[11:58:41.253] iteration 22661 : model1 loss : 0.439438 model2 loss : 0.020703
[11:58:41.424] iteration 22662 : model1 loss : 0.432154 model2 loss : 0.020125
[11:58:41.594] iteration 22663 : model1 loss : 0.444451 model2 loss : 0.020583
[11:58:41.761] iteration 22664 : model1 loss : 0.441408 model2 loss : 0.021147
[11:58:41.930] iteration 22665 : model1 loss : 0.441975 model2 loss : 0.022805
[11:58:42.099] iteration 22666 : model1 loss : 0.440338 model2 loss : 0.020628
[11:58:42.267] iteration 22667 : model1 loss : 0.440026 model2 loss : 0.019328
[11:58:42.438] iteration 22668 : model1 loss : 0.437867 model2 loss : 0.022564
[11:58:42.606] iteration 22669 : model1 loss : 0.435556 model2 loss : 0.019700
[11:58:42.772] iteration 22670 : model1 loss : 0.437541 model2 loss : 0.019855
[11:58:42.941] iteration 22671 : model1 loss : 0.439309 model2 loss : 0.021921
[11:58:44.862] iteration 22672 : model1 loss : 0.437766 model2 loss : 0.019005
[11:58:45.029] iteration 22673 : model1 loss : 0.433512 model2 loss : 0.020576
[11:58:45.199] iteration 22674 : model1 loss : 0.440171 model2 loss : 0.021178
[11:58:45.366] iteration 22675 : model1 loss : 0.437293 model2 loss : 0.022022
[11:58:45.541] iteration 22676 : model1 loss : 0.436408 model2 loss : 0.019181
[11:58:45.710] iteration 22677 : model1 loss : 0.436600 model2 loss : 0.019799
[11:58:45.880] iteration 22678 : model1 loss : 0.439917 model2 loss : 0.021462
[11:58:46.046] iteration 22679 : model1 loss : 0.438527 model2 loss : 0.020160
[11:58:46.214] iteration 22680 : model1 loss : 0.437113 model2 loss : 0.020707
[11:58:46.382] iteration 22681 : model1 loss : 0.437899 model2 loss : 0.020150
[11:58:46.552] iteration 22682 : model1 loss : 0.442640 model2 loss : 0.019970
[11:58:46.727] iteration 22683 : model1 loss : 0.436361 model2 loss : 0.018981
[11:58:46.895] iteration 22684 : model1 loss : 0.438621 model2 loss : 0.019187
[11:58:47.062] iteration 22685 : model1 loss : 0.441161 model2 loss : 0.020426
[11:58:47.232] iteration 22686 : model1 loss : 0.439759 model2 loss : 0.021413
[11:58:47.399] iteration 22687 : model1 loss : 0.436098 model2 loss : 0.021137
[11:58:47.569] iteration 22688 : model1 loss : 0.443257 model2 loss : 0.019717
[11:58:47.735] iteration 22689 : model1 loss : 0.440447 model2 loss : 0.021038
[11:58:47.906] iteration 22690 : model1 loss : 0.442016 model2 loss : 0.020578
[11:58:48.073] iteration 22691 : model1 loss : 0.437971 model2 loss : 0.019645
[11:58:48.242] iteration 22692 : model1 loss : 0.437207 model2 loss : 0.018629
[11:58:48.411] iteration 22693 : model1 loss : 0.436042 model2 loss : 0.020328
[11:58:48.580] iteration 22694 : model1 loss : 0.439673 model2 loss : 0.019085
[11:58:48.747] iteration 22695 : model1 loss : 0.440967 model2 loss : 0.023836
[11:58:48.916] iteration 22696 : model1 loss : 0.437185 model2 loss : 0.019881
[11:58:49.082] iteration 22697 : model1 loss : 0.438781 model2 loss : 0.021012
[11:58:49.252] iteration 22698 : model1 loss : 0.440616 model2 loss : 0.019534
[11:58:49.423] iteration 22699 : model1 loss : 0.443768 model2 loss : 0.022481
[11:58:49.592] iteration 22700 : model1 loss : 0.440860 model2 loss : 0.020576
[11:58:49.759] iteration 22701 : model1 loss : 0.438534 model2 loss : 0.020152
[11:58:49.927] iteration 22702 : model1 loss : 0.440739 model2 loss : 0.019554
[11:58:50.094] iteration 22703 : model1 loss : 0.439882 model2 loss : 0.018677
[11:58:50.262] iteration 22704 : model1 loss : 0.442997 model2 loss : 0.022959
[11:58:52.227] iteration 22705 : model1 loss : 0.442347 model2 loss : 0.022124
[11:58:52.398] iteration 22706 : model1 loss : 0.435182 model2 loss : 0.020375
[11:58:52.567] iteration 22707 : model1 loss : 0.439850 model2 loss : 0.020779
[11:58:52.733] iteration 22708 : model1 loss : 0.433551 model2 loss : 0.019380
[11:58:52.903] iteration 22709 : model1 loss : 0.436512 model2 loss : 0.020869
[11:58:53.071] iteration 22710 : model1 loss : 0.438252 model2 loss : 0.019875
[11:58:53.240] iteration 22711 : model1 loss : 0.438792 model2 loss : 0.020321
[11:58:53.408] iteration 22712 : model1 loss : 0.440212 model2 loss : 0.021391
[11:58:53.577] iteration 22713 : model1 loss : 0.436018 model2 loss : 0.019772
[11:58:53.744] iteration 22714 : model1 loss : 0.442644 model2 loss : 0.020497
[11:58:53.911] iteration 22715 : model1 loss : 0.441459 model2 loss : 0.021204
[11:58:54.080] iteration 22716 : model1 loss : 0.441588 model2 loss : 0.020486
[11:58:54.248] iteration 22717 : model1 loss : 0.441055 model2 loss : 0.021373
[11:58:54.416] iteration 22718 : model1 loss : 0.439925 model2 loss : 0.021741
[11:58:54.586] iteration 22719 : model1 loss : 0.442008 model2 loss : 0.021602
[11:58:54.753] iteration 22720 : model1 loss : 0.439031 model2 loss : 0.021057
[11:58:54.919] iteration 22721 : model1 loss : 0.440569 model2 loss : 0.021598
[11:58:55.089] iteration 22722 : model1 loss : 0.436799 model2 loss : 0.020567
[11:58:55.257] iteration 22723 : model1 loss : 0.437463 model2 loss : 0.021179
[11:58:55.428] iteration 22724 : model1 loss : 0.437092 model2 loss : 0.021330
[11:58:55.600] iteration 22725 : model1 loss : 0.440734 model2 loss : 0.018446
[11:58:55.768] iteration 22726 : model1 loss : 0.439648 model2 loss : 0.019086
[11:58:55.942] iteration 22727 : model1 loss : 0.444598 model2 loss : 0.026889
[11:58:56.112] iteration 22728 : model1 loss : 0.436893 model2 loss : 0.020054
[11:58:56.280] iteration 22729 : model1 loss : 0.437288 model2 loss : 0.020623
[11:58:56.449] iteration 22730 : model1 loss : 0.438439 model2 loss : 0.019356
[11:58:56.618] iteration 22731 : model1 loss : 0.442742 model2 loss : 0.025068
[11:58:56.785] iteration 22732 : model1 loss : 0.438001 model2 loss : 0.019358
[11:58:56.954] iteration 22733 : model1 loss : 0.441334 model2 loss : 0.021220
[11:58:57.122] iteration 22734 : model1 loss : 0.437751 model2 loss : 0.021219
[11:58:57.290] iteration 22735 : model1 loss : 0.440159 model2 loss : 0.025519
[11:58:57.460] iteration 22736 : model1 loss : 0.440301 model2 loss : 0.021936
[11:58:57.628] iteration 22737 : model1 loss : 0.440077 model2 loss : 0.021941
[11:58:59.549] iteration 22738 : model1 loss : 0.441125 model2 loss : 0.021899
[11:58:59.717] iteration 22739 : model1 loss : 0.437982 model2 loss : 0.022397
[11:58:59.887] iteration 22740 : model1 loss : 0.437016 model2 loss : 0.019248
[11:59:00.054] iteration 22741 : model1 loss : 0.436716 model2 loss : 0.021472
[11:59:00.223] iteration 22742 : model1 loss : 0.441878 model2 loss : 0.021888
[11:59:00.389] iteration 22743 : model1 loss : 0.436315 model2 loss : 0.020660
[11:59:00.561] iteration 22744 : model1 loss : 0.436781 model2 loss : 0.018131
[11:59:00.730] iteration 22745 : model1 loss : 0.441834 model2 loss : 0.020107
[11:59:00.902] iteration 22746 : model1 loss : 0.441172 model2 loss : 0.024215
[11:59:01.069] iteration 22747 : model1 loss : 0.444359 model2 loss : 0.021808
[11:59:01.239] iteration 22748 : model1 loss : 0.436678 model2 loss : 0.018494
[11:59:01.405] iteration 22749 : model1 loss : 0.439491 model2 loss : 0.020069
[11:59:01.573] iteration 22750 : model1 loss : 0.441465 model2 loss : 0.020300
[11:59:01.740] iteration 22751 : model1 loss : 0.437937 model2 loss : 0.018416
[11:59:01.910] iteration 22752 : model1 loss : 0.443345 model2 loss : 0.023387
[11:59:02.077] iteration 22753 : model1 loss : 0.439553 model2 loss : 0.019884
[11:59:02.246] iteration 22754 : model1 loss : 0.437031 model2 loss : 0.021173
[11:59:02.414] iteration 22755 : model1 loss : 0.438617 model2 loss : 0.022085
[11:59:02.582] iteration 22756 : model1 loss : 0.440493 model2 loss : 0.020103
[11:59:02.749] iteration 22757 : model1 loss : 0.437395 model2 loss : 0.020532
[11:59:02.920] iteration 22758 : model1 loss : 0.444442 model2 loss : 0.021146
[11:59:03.089] iteration 22759 : model1 loss : 0.444038 model2 loss : 0.024504
[11:59:03.257] iteration 22760 : model1 loss : 0.437131 model2 loss : 0.018141
[11:59:03.424] iteration 22761 : model1 loss : 0.432731 model2 loss : 0.019663
[11:59:03.593] iteration 22762 : model1 loss : 0.445175 model2 loss : 0.023306
[11:59:03.761] iteration 22763 : model1 loss : 0.435756 model2 loss : 0.020511
[11:59:03.928] iteration 22764 : model1 loss : 0.440753 model2 loss : 0.023399
[11:59:04.098] iteration 22765 : model1 loss : 0.433616 model2 loss : 0.019441
[11:59:04.269] iteration 22766 : model1 loss : 0.439832 model2 loss : 0.018821
[11:59:04.447] iteration 22767 : model1 loss : 0.442200 model2 loss : 0.019677
[11:59:04.617] iteration 22768 : model1 loss : 0.433849 model2 loss : 0.018782
[11:59:04.784] iteration 22769 : model1 loss : 0.440016 model2 loss : 0.020758
[11:59:04.953] iteration 22770 : model1 loss : 0.437996 model2 loss : 0.018140
[11:59:06.849] iteration 22771 : model1 loss : 0.441159 model2 loss : 0.021302
[11:59:07.030] iteration 22772 : model1 loss : 0.438962 model2 loss : 0.019550
[11:59:07.200] iteration 22773 : model1 loss : 0.432574 model2 loss : 0.018335
[11:59:07.366] iteration 22774 : model1 loss : 0.436233 model2 loss : 0.018939
[11:59:07.537] iteration 22775 : model1 loss : 0.438686 model2 loss : 0.019254
[11:59:07.703] iteration 22776 : model1 loss : 0.442866 model2 loss : 0.022974
[11:59:07.872] iteration 22777 : model1 loss : 0.439279 model2 loss : 0.019129
[11:59:08.040] iteration 22778 : model1 loss : 0.440717 model2 loss : 0.019389
[11:59:08.210] iteration 22779 : model1 loss : 0.438740 model2 loss : 0.018489
[11:59:08.377] iteration 22780 : model1 loss : 0.438433 model2 loss : 0.019018
[11:59:08.551] iteration 22781 : model1 loss : 0.443630 model2 loss : 0.021178
[11:59:08.718] iteration 22782 : model1 loss : 0.436167 model2 loss : 0.019448
[11:59:08.889] iteration 22783 : model1 loss : 0.435161 model2 loss : 0.019369
[11:59:09.057] iteration 22784 : model1 loss : 0.441674 model2 loss : 0.021277
[11:59:09.227] iteration 22785 : model1 loss : 0.436630 model2 loss : 0.021163
[11:59:09.393] iteration 22786 : model1 loss : 0.434302 model2 loss : 0.019815
[11:59:09.563] iteration 22787 : model1 loss : 0.434930 model2 loss : 0.021595
[11:59:09.729] iteration 22788 : model1 loss : 0.439998 model2 loss : 0.022253
[11:59:09.899] iteration 22789 : model1 loss : 0.437370 model2 loss : 0.020420
[11:59:10.067] iteration 22790 : model1 loss : 0.440862 model2 loss : 0.022291
[11:59:10.234] iteration 22791 : model1 loss : 0.441356 model2 loss : 0.023824
[11:59:10.403] iteration 22792 : model1 loss : 0.440801 model2 loss : 0.021948
[11:59:10.572] iteration 22793 : model1 loss : 0.440303 model2 loss : 0.023149
[11:59:10.739] iteration 22794 : model1 loss : 0.436599 model2 loss : 0.019040
[11:59:10.910] iteration 22795 : model1 loss : 0.436378 model2 loss : 0.020539
[11:59:11.076] iteration 22796 : model1 loss : 0.439705 model2 loss : 0.022973
[11:59:11.245] iteration 22797 : model1 loss : 0.439804 model2 loss : 0.017812
[11:59:11.414] iteration 22798 : model1 loss : 0.439660 model2 loss : 0.019826
[11:59:11.583] iteration 22799 : model1 loss : 0.442480 model2 loss : 0.021060
[11:59:11.751] iteration 22800 : model1 loss : 0.438158 model2 loss : 0.021326
[11:59:11.920] iteration 22801 : model1 loss : 0.444534 model2 loss : 0.021542
[11:59:12.086] iteration 22802 : model1 loss : 0.444238 model2 loss : 0.022482
[11:59:12.255] iteration 22803 : model1 loss : 0.439840 model2 loss : 0.020237
[11:59:14.175] iteration 22804 : model1 loss : 0.438134 model2 loss : 0.020562
[11:59:14.346] iteration 22805 : model1 loss : 0.443722 model2 loss : 0.021325
[11:59:14.520] iteration 22806 : model1 loss : 0.438547 model2 loss : 0.020248
[11:59:14.688] iteration 22807 : model1 loss : 0.437606 model2 loss : 0.022349
[11:59:14.858] iteration 22808 : model1 loss : 0.440470 model2 loss : 0.019155
[11:59:15.024] iteration 22809 : model1 loss : 0.441749 model2 loss : 0.020696
[11:59:15.195] iteration 22810 : model1 loss : 0.440030 model2 loss : 0.018816
[11:59:15.362] iteration 22811 : model1 loss : 0.439616 model2 loss : 0.021574
[11:59:15.533] iteration 22812 : model1 loss : 0.437180 model2 loss : 0.020673
[11:59:15.701] iteration 22813 : model1 loss : 0.439893 model2 loss : 0.019195
[11:59:15.871] iteration 22814 : model1 loss : 0.438146 model2 loss : 0.019637
[11:59:16.037] iteration 22815 : model1 loss : 0.440415 model2 loss : 0.016873
[11:59:16.208] iteration 22816 : model1 loss : 0.439276 model2 loss : 0.021767
[11:59:16.376] iteration 22817 : model1 loss : 0.434150 model2 loss : 0.021135
[11:59:16.546] iteration 22818 : model1 loss : 0.439208 model2 loss : 0.022468
[11:59:16.714] iteration 22819 : model1 loss : 0.437492 model2 loss : 0.021195
[11:59:16.883] iteration 22820 : model1 loss : 0.436395 model2 loss : 0.020153
[11:59:17.049] iteration 22821 : model1 loss : 0.437126 model2 loss : 0.019847
[11:59:17.220] iteration 22822 : model1 loss : 0.442042 model2 loss : 0.024505
[11:59:17.386] iteration 22823 : model1 loss : 0.442777 model2 loss : 0.017871
[11:59:17.558] iteration 22824 : model1 loss : 0.442271 model2 loss : 0.022832
[11:59:17.725] iteration 22825 : model1 loss : 0.438693 model2 loss : 0.021009
[11:59:17.895] iteration 22826 : model1 loss : 0.438008 model2 loss : 0.021178
[11:59:18.064] iteration 22827 : model1 loss : 0.438938 model2 loss : 0.021390
[11:59:18.234] iteration 22828 : model1 loss : 0.437734 model2 loss : 0.018789
[11:59:18.402] iteration 22829 : model1 loss : 0.437573 model2 loss : 0.019041
[11:59:18.572] iteration 22830 : model1 loss : 0.439129 model2 loss : 0.021704
[11:59:18.740] iteration 22831 : model1 loss : 0.437364 model2 loss : 0.020575
[11:59:18.909] iteration 22832 : model1 loss : 0.436628 model2 loss : 0.020569
[11:59:19.078] iteration 22833 : model1 loss : 0.438263 model2 loss : 0.023915
[11:59:19.247] iteration 22834 : model1 loss : 0.437187 model2 loss : 0.019956
[11:59:19.415] iteration 22835 : model1 loss : 0.443120 model2 loss : 0.020191
[11:59:19.582] iteration 22836 : model1 loss : 0.443094 model2 loss : 0.022504
[11:59:21.511] iteration 22837 : model1 loss : 0.438362 model2 loss : 0.020823
[11:59:21.681] iteration 22838 : model1 loss : 0.440641 model2 loss : 0.021291
[11:59:21.852] iteration 22839 : model1 loss : 0.438593 model2 loss : 0.024336
[11:59:22.020] iteration 22840 : model1 loss : 0.441963 model2 loss : 0.021855
[11:59:22.191] iteration 22841 : model1 loss : 0.436898 model2 loss : 0.019220
[11:59:22.361] iteration 22842 : model1 loss : 0.441406 model2 loss : 0.020954
[11:59:22.534] iteration 22843 : model1 loss : 0.440344 model2 loss : 0.021822
[11:59:22.703] iteration 22844 : model1 loss : 0.439041 model2 loss : 0.019579
[11:59:22.898] iteration 22845 : model1 loss : 0.438535 model2 loss : 0.020155
[11:59:23.066] iteration 22846 : model1 loss : 0.438907 model2 loss : 0.019784
[11:59:23.236] iteration 22847 : model1 loss : 0.438742 model2 loss : 0.022360
[11:59:23.404] iteration 22848 : model1 loss : 0.436049 model2 loss : 0.020219
[11:59:23.576] iteration 22849 : model1 loss : 0.440492 model2 loss : 0.022248
[11:59:23.745] iteration 22850 : model1 loss : 0.441583 model2 loss : 0.019530
[11:59:23.915] iteration 22851 : model1 loss : 0.441989 model2 loss : 0.020311
[11:59:24.084] iteration 22852 : model1 loss : 0.440722 model2 loss : 0.021608
[11:59:24.255] iteration 22853 : model1 loss : 0.440573 model2 loss : 0.024121
[11:59:24.423] iteration 22854 : model1 loss : 0.438427 model2 loss : 0.020403
[11:59:24.593] iteration 22855 : model1 loss : 0.437657 model2 loss : 0.021430
[11:59:24.760] iteration 22856 : model1 loss : 0.439153 model2 loss : 0.021592
[11:59:24.929] iteration 22857 : model1 loss : 0.435460 model2 loss : 0.019438
[11:59:25.099] iteration 22858 : model1 loss : 0.440327 model2 loss : 0.020193
[11:59:25.266] iteration 22859 : model1 loss : 0.437895 model2 loss : 0.019688
[11:59:25.433] iteration 22860 : model1 loss : 0.439047 model2 loss : 0.019723
[11:59:25.601] iteration 22861 : model1 loss : 0.437945 model2 loss : 0.019708
[11:59:25.769] iteration 22862 : model1 loss : 0.437734 model2 loss : 0.019441
[11:59:25.942] iteration 22863 : model1 loss : 0.435546 model2 loss : 0.019175
[11:59:26.110] iteration 22864 : model1 loss : 0.440631 model2 loss : 0.022291
[11:59:26.281] iteration 22865 : model1 loss : 0.438170 model2 loss : 0.018087
[11:59:26.450] iteration 22866 : model1 loss : 0.443318 model2 loss : 0.025218
[11:59:26.621] iteration 22867 : model1 loss : 0.437338 model2 loss : 0.020251
[11:59:26.787] iteration 22868 : model1 loss : 0.437144 model2 loss : 0.019691
[11:59:26.957] iteration 22869 : model1 loss : 0.442088 model2 loss : 0.018227
[11:59:28.870] iteration 22870 : model1 loss : 0.441173 model2 loss : 0.021273
[11:59:29.037] iteration 22871 : model1 loss : 0.440984 model2 loss : 0.020553
[11:59:29.209] iteration 22872 : model1 loss : 0.442734 model2 loss : 0.021847
[11:59:29.377] iteration 22873 : model1 loss : 0.438615 model2 loss : 0.020498
[11:59:29.563] iteration 22874 : model1 loss : 0.433407 model2 loss : 0.018361
[11:59:29.732] iteration 22875 : model1 loss : 0.439722 model2 loss : 0.017899
[11:59:29.899] iteration 22876 : model1 loss : 0.434416 model2 loss : 0.021914
[11:59:30.068] iteration 22877 : model1 loss : 0.440390 model2 loss : 0.020661
[11:59:30.239] iteration 22878 : model1 loss : 0.437165 model2 loss : 0.019968
[11:59:30.407] iteration 22879 : model1 loss : 0.435693 model2 loss : 0.020826
[11:59:30.579] iteration 22880 : model1 loss : 0.438224 model2 loss : 0.022525
[11:59:30.747] iteration 22881 : model1 loss : 0.436577 model2 loss : 0.018549
[11:59:30.919] iteration 22882 : model1 loss : 0.440117 model2 loss : 0.021415
[11:59:31.095] iteration 22883 : model1 loss : 0.441807 model2 loss : 0.020839
[11:59:31.267] iteration 22884 : model1 loss : 0.446594 model2 loss : 0.030508
[11:59:31.435] iteration 22885 : model1 loss : 0.440182 model2 loss : 0.020593
[11:59:31.605] iteration 22886 : model1 loss : 0.435085 model2 loss : 0.019025
[11:59:31.774] iteration 22887 : model1 loss : 0.434600 model2 loss : 0.021078
[11:59:31.945] iteration 22888 : model1 loss : 0.441432 model2 loss : 0.022275
[11:59:32.115] iteration 22889 : model1 loss : 0.440777 model2 loss : 0.021405
[11:59:32.282] iteration 22890 : model1 loss : 0.441920 model2 loss : 0.020737
[11:59:32.453] iteration 22891 : model1 loss : 0.440065 model2 loss : 0.021139
[11:59:32.623] iteration 22892 : model1 loss : 0.437445 model2 loss : 0.023681
[11:59:32.790] iteration 22893 : model1 loss : 0.441047 model2 loss : 0.020429
[11:59:32.962] iteration 22894 : model1 loss : 0.439443 model2 loss : 0.025096
[11:59:33.129] iteration 22895 : model1 loss : 0.441982 model2 loss : 0.027731
[11:59:33.302] iteration 22896 : model1 loss : 0.438968 model2 loss : 0.022238
[11:59:33.473] iteration 22897 : model1 loss : 0.439203 model2 loss : 0.020865
[11:59:33.651] iteration 22898 : model1 loss : 0.442654 model2 loss : 0.024405
[11:59:33.817] iteration 22899 : model1 loss : 0.440073 model2 loss : 0.023051
[11:59:33.988] iteration 22900 : model1 loss : 0.440924 model2 loss : 0.024436
[11:59:34.156] iteration 22901 : model1 loss : 0.440074 model2 loss : 0.028761
[11:59:34.324] iteration 22902 : model1 loss : 0.438004 model2 loss : 0.021044
[11:59:36.296] iteration 22903 : model1 loss : 0.440302 model2 loss : 0.023338
[11:59:36.466] iteration 22904 : model1 loss : 0.438897 model2 loss : 0.020326
[11:59:36.637] iteration 22905 : model1 loss : 0.441419 model2 loss : 0.024617
[11:59:36.805] iteration 22906 : model1 loss : 0.439026 model2 loss : 0.022804
[11:59:36.975] iteration 22907 : model1 loss : 0.440923 model2 loss : 0.021469
[11:59:37.142] iteration 22908 : model1 loss : 0.439512 model2 loss : 0.025505
[11:59:37.308] iteration 22909 : model1 loss : 0.438905 model2 loss : 0.030897
[11:59:37.475] iteration 22910 : model1 loss : 0.442667 model2 loss : 0.021942
[11:59:37.644] iteration 22911 : model1 loss : 0.440151 model2 loss : 0.021161
[11:59:37.811] iteration 22912 : model1 loss : 0.442873 model2 loss : 0.020939
[11:59:37.979] iteration 22913 : model1 loss : 0.443686 model2 loss : 0.022545
[11:59:38.148] iteration 22914 : model1 loss : 0.438337 model2 loss : 0.023459
[11:59:38.316] iteration 22915 : model1 loss : 0.437681 model2 loss : 0.020445
[11:59:38.484] iteration 22916 : model1 loss : 0.440081 model2 loss : 0.021505
[11:59:38.652] iteration 22917 : model1 loss : 0.439348 model2 loss : 0.020053
[11:59:38.821] iteration 22918 : model1 loss : 0.435195 model2 loss : 0.022177
[11:59:38.990] iteration 22919 : model1 loss : 0.438980 model2 loss : 0.022744
[11:59:39.180] iteration 22920 : model1 loss : 0.443886 model2 loss : 0.024531
[11:59:39.350] iteration 22921 : model1 loss : 0.435933 model2 loss : 0.020911
[11:59:39.521] iteration 22922 : model1 loss : 0.442914 model2 loss : 0.021717
[11:59:39.690] iteration 22923 : model1 loss : 0.438445 model2 loss : 0.025221
[11:59:39.858] iteration 22924 : model1 loss : 0.437306 model2 loss : 0.022628
[11:59:40.027] iteration 22925 : model1 loss : 0.436661 model2 loss : 0.019946
[11:59:40.196] iteration 22926 : model1 loss : 0.437292 model2 loss : 0.023222
[11:59:40.367] iteration 22927 : model1 loss : 0.442933 model2 loss : 0.028258
[11:59:40.537] iteration 22928 : model1 loss : 0.434108 model2 loss : 0.021355
[11:59:40.707] iteration 22929 : model1 loss : 0.437193 model2 loss : 0.019492
[11:59:40.875] iteration 22930 : model1 loss : 0.443505 model2 loss : 0.022838
[11:59:41.044] iteration 22931 : model1 loss : 0.440604 model2 loss : 0.021983
[11:59:41.212] iteration 22932 : model1 loss : 0.437567 model2 loss : 0.019083
[11:59:41.380] iteration 22933 : model1 loss : 0.437679 model2 loss : 0.021417
[11:59:41.549] iteration 22934 : model1 loss : 0.440928 model2 loss : 0.020544
[11:59:41.717] iteration 22935 : model1 loss : 0.436080 model2 loss : 0.019637
[11:59:43.636] iteration 22936 : model1 loss : 0.434685 model2 loss : 0.020853
[11:59:43.804] iteration 22937 : model1 loss : 0.436142 model2 loss : 0.019046
[11:59:43.973] iteration 22938 : model1 loss : 0.446089 model2 loss : 0.022291
[11:59:44.141] iteration 22939 : model1 loss : 0.435791 model2 loss : 0.020592
[11:59:44.312] iteration 22940 : model1 loss : 0.437420 model2 loss : 0.018799
[11:59:44.479] iteration 22941 : model1 loss : 0.437451 model2 loss : 0.022507
[11:59:44.647] iteration 22942 : model1 loss : 0.440114 model2 loss : 0.021187
[11:59:44.813] iteration 22943 : model1 loss : 0.439413 model2 loss : 0.023822
[11:59:45.006] iteration 22944 : model1 loss : 0.433852 model2 loss : 0.018555
[11:59:45.174] iteration 22945 : model1 loss : 0.437734 model2 loss : 0.022595
[11:59:45.344] iteration 22946 : model1 loss : 0.439783 model2 loss : 0.021206
[11:59:45.514] iteration 22947 : model1 loss : 0.441731 model2 loss : 0.018578
[11:59:45.682] iteration 22948 : model1 loss : 0.437288 model2 loss : 0.019341
[11:59:45.848] iteration 22949 : model1 loss : 0.440009 model2 loss : 0.020739
[11:59:46.018] iteration 22950 : model1 loss : 0.439417 model2 loss : 0.021606
[11:59:46.184] iteration 22951 : model1 loss : 0.442645 model2 loss : 0.020717
[11:59:46.353] iteration 22952 : model1 loss : 0.441181 model2 loss : 0.021621
[11:59:46.522] iteration 22953 : model1 loss : 0.440451 model2 loss : 0.021536
[11:59:46.692] iteration 22954 : model1 loss : 0.438459 model2 loss : 0.023386
[11:59:46.858] iteration 22955 : model1 loss : 0.440795 model2 loss : 0.019789
[11:59:47.027] iteration 22956 : model1 loss : 0.438509 model2 loss : 0.019184
[11:59:47.194] iteration 22957 : model1 loss : 0.442622 model2 loss : 0.021934
[11:59:47.363] iteration 22958 : model1 loss : 0.440384 model2 loss : 0.019776
[11:59:47.535] iteration 22959 : model1 loss : 0.437282 model2 loss : 0.018868
[11:59:47.704] iteration 22960 : model1 loss : 0.441842 model2 loss : 0.022922
[11:59:47.872] iteration 22961 : model1 loss : 0.437355 model2 loss : 0.021206
[11:59:48.040] iteration 22962 : model1 loss : 0.434016 model2 loss : 0.020929
[11:59:48.207] iteration 22963 : model1 loss : 0.439797 model2 loss : 0.021902
[11:59:48.378] iteration 22964 : model1 loss : 0.435771 model2 loss : 0.019574
[11:59:48.550] iteration 22965 : model1 loss : 0.443660 model2 loss : 0.023231
[11:59:48.719] iteration 22966 : model1 loss : 0.442072 model2 loss : 0.021395
[11:59:48.885] iteration 22967 : model1 loss : 0.444336 model2 loss : 0.023827
[11:59:49.052] iteration 22968 : model1 loss : 0.442385 model2 loss : 0.025109
[11:59:50.984] iteration 22969 : model1 loss : 0.436793 model2 loss : 0.019842
[11:59:51.152] iteration 22970 : model1 loss : 0.438914 model2 loss : 0.020392
[11:59:51.323] iteration 22971 : model1 loss : 0.444183 model2 loss : 0.023137
[11:59:51.491] iteration 22972 : model1 loss : 0.439433 model2 loss : 0.023518
[11:59:51.665] iteration 22973 : model1 loss : 0.430677 model2 loss : 0.021451
[11:59:51.833] iteration 22974 : model1 loss : 0.436480 model2 loss : 0.020877
[11:59:52.004] iteration 22975 : model1 loss : 0.438891 model2 loss : 0.021803
[11:59:52.170] iteration 22976 : model1 loss : 0.436299 model2 loss : 0.022191
[11:59:52.341] iteration 22977 : model1 loss : 0.441312 model2 loss : 0.023322
[11:59:52.509] iteration 22978 : model1 loss : 0.444091 model2 loss : 0.023036
[11:59:52.678] iteration 22979 : model1 loss : 0.440019 model2 loss : 0.022456
[11:59:52.847] iteration 22980 : model1 loss : 0.436149 model2 loss : 0.019635
[11:59:53.017] iteration 22981 : model1 loss : 0.438064 model2 loss : 0.019614
[11:59:53.184] iteration 22982 : model1 loss : 0.440819 model2 loss : 0.020553
[11:59:53.354] iteration 22983 : model1 loss : 0.437325 model2 loss : 0.019308
[11:59:53.524] iteration 22984 : model1 loss : 0.440391 model2 loss : 0.023130
[11:59:53.694] iteration 22985 : model1 loss : 0.441314 model2 loss : 0.021259
[11:59:53.861] iteration 22986 : model1 loss : 0.436692 model2 loss : 0.020353
[11:59:54.031] iteration 22987 : model1 loss : 0.439516 model2 loss : 0.018998
[11:59:54.199] iteration 22988 : model1 loss : 0.442030 model2 loss : 0.021313
[11:59:54.369] iteration 22989 : model1 loss : 0.438068 model2 loss : 0.020218
[11:59:54.540] iteration 22990 : model1 loss : 0.437153 model2 loss : 0.020714
[11:59:54.708] iteration 22991 : model1 loss : 0.444376 model2 loss : 0.022049
[11:59:54.875] iteration 22992 : model1 loss : 0.435245 model2 loss : 0.019177
[11:59:55.045] iteration 22993 : model1 loss : 0.442140 model2 loss : 0.025044
[11:59:55.210] iteration 22994 : model1 loss : 0.443791 model2 loss : 0.020340
[11:59:55.380] iteration 22995 : model1 loss : 0.440142 model2 loss : 0.018992
[11:59:55.546] iteration 22996 : model1 loss : 0.441434 model2 loss : 0.020851
[11:59:55.714] iteration 22997 : model1 loss : 0.439408 model2 loss : 0.020145
[11:59:55.884] iteration 22998 : model1 loss : 0.435461 model2 loss : 0.019608
[11:59:56.055] iteration 22999 : model1 loss : 0.439326 model2 loss : 0.019494
[11:59:56.223] iteration 23000 : model1 loss : 0.440354 model2 loss : 0.019767
[12:00:04.511] iteration 23000 : model1_mean_dice : 0.899496 model1_mean_hd95 : 3.228765
[12:00:12.800] iteration 23000 : model2_mean_dice : 0.892212 model2_mean_hd95 : 2.237594
[12:00:12.972] iteration 23001 : model1 loss : 0.439135 model2 loss : 0.021057
[12:00:14.897] iteration 23002 : model1 loss : 0.440184 model2 loss : 0.022571
[12:00:15.068] iteration 23003 : model1 loss : 0.436046 model2 loss : 0.018223
[12:00:15.239] iteration 23004 : model1 loss : 0.434154 model2 loss : 0.019921
[12:00:15.407] iteration 23005 : model1 loss : 0.442053 model2 loss : 0.022525
[12:00:15.575] iteration 23006 : model1 loss : 0.436590 model2 loss : 0.019926
[12:00:15.741] iteration 23007 : model1 loss : 0.443489 model2 loss : 0.020457
[12:00:15.909] iteration 23008 : model1 loss : 0.440444 model2 loss : 0.018992
[12:00:16.075] iteration 23009 : model1 loss : 0.435680 model2 loss : 0.019369
[12:00:16.243] iteration 23010 : model1 loss : 0.444059 model2 loss : 0.023147
[12:00:16.411] iteration 23011 : model1 loss : 0.437639 model2 loss : 0.022175
[12:00:16.580] iteration 23012 : model1 loss : 0.440136 model2 loss : 0.020510
[12:00:16.748] iteration 23013 : model1 loss : 0.437962 model2 loss : 0.019597
[12:00:16.918] iteration 23014 : model1 loss : 0.440765 model2 loss : 0.020108
[12:00:17.084] iteration 23015 : model1 loss : 0.439128 model2 loss : 0.022074
[12:00:17.252] iteration 23016 : model1 loss : 0.440471 model2 loss : 0.020679
[12:00:17.420] iteration 23017 : model1 loss : 0.438654 model2 loss : 0.020437
[12:00:17.586] iteration 23018 : model1 loss : 0.438835 model2 loss : 0.020228
[12:00:17.754] iteration 23019 : model1 loss : 0.438925 model2 loss : 0.020109
[12:00:17.922] iteration 23020 : model1 loss : 0.437734 model2 loss : 0.021755
[12:00:18.091] iteration 23021 : model1 loss : 0.435741 model2 loss : 0.019108
[12:00:18.259] iteration 23022 : model1 loss : 0.439840 model2 loss : 0.019793
[12:00:18.427] iteration 23023 : model1 loss : 0.444402 model2 loss : 0.024254
[12:00:18.597] iteration 23024 : model1 loss : 0.437380 model2 loss : 0.021694
[12:00:18.766] iteration 23025 : model1 loss : 0.441803 model2 loss : 0.020016
[12:00:18.935] iteration 23026 : model1 loss : 0.443989 model2 loss : 0.022167
[12:00:19.101] iteration 23027 : model1 loss : 0.436171 model2 loss : 0.018571
[12:00:19.270] iteration 23028 : model1 loss : 0.439141 model2 loss : 0.020905
[12:00:19.437] iteration 23029 : model1 loss : 0.437763 model2 loss : 0.021266
[12:00:19.604] iteration 23030 : model1 loss : 0.440572 model2 loss : 0.019071
[12:00:19.771] iteration 23031 : model1 loss : 0.435955 model2 loss : 0.022153
[12:00:19.941] iteration 23032 : model1 loss : 0.439562 model2 loss : 0.021524
[12:00:20.107] iteration 23033 : model1 loss : 0.444103 model2 loss : 0.022555
[12:00:20.274] iteration 23034 : model1 loss : 0.439456 model2 loss : 0.022590
[12:00:22.206] iteration 23035 : model1 loss : 0.437239 model2 loss : 0.021583
[12:00:22.372] iteration 23036 : model1 loss : 0.439181 model2 loss : 0.020015
[12:00:22.542] iteration 23037 : model1 loss : 0.437411 model2 loss : 0.019729
[12:00:22.710] iteration 23038 : model1 loss : 0.435549 model2 loss : 0.020559
[12:00:22.878] iteration 23039 : model1 loss : 0.439934 model2 loss : 0.022420
[12:00:23.044] iteration 23040 : model1 loss : 0.439995 model2 loss : 0.021074
[12:00:23.215] iteration 23041 : model1 loss : 0.435893 model2 loss : 0.019363
[12:00:23.383] iteration 23042 : model1 loss : 0.437741 model2 loss : 0.019692
[12:00:23.551] iteration 23043 : model1 loss : 0.441767 model2 loss : 0.020032
[12:00:23.721] iteration 23044 : model1 loss : 0.440648 model2 loss : 0.020696
[12:00:23.890] iteration 23045 : model1 loss : 0.439725 model2 loss : 0.021385
[12:00:24.057] iteration 23046 : model1 loss : 0.443011 model2 loss : 0.022892
[12:00:24.227] iteration 23047 : model1 loss : 0.442189 model2 loss : 0.023062
[12:00:24.393] iteration 23048 : model1 loss : 0.439339 model2 loss : 0.020153
[12:00:24.563] iteration 23049 : model1 loss : 0.438934 model2 loss : 0.020684
[12:00:24.733] iteration 23050 : model1 loss : 0.440359 model2 loss : 0.020913
[12:00:24.902] iteration 23051 : model1 loss : 0.441624 model2 loss : 0.018307
[12:00:25.067] iteration 23052 : model1 loss : 0.437252 model2 loss : 0.017757
[12:00:25.235] iteration 23053 : model1 loss : 0.439543 model2 loss : 0.021276
[12:00:25.401] iteration 23054 : model1 loss : 0.440019 model2 loss : 0.018234
[12:00:25.571] iteration 23055 : model1 loss : 0.438232 model2 loss : 0.018166
[12:00:25.739] iteration 23056 : model1 loss : 0.437696 model2 loss : 0.020839
[12:00:25.909] iteration 23057 : model1 loss : 0.439553 model2 loss : 0.018138
[12:00:26.076] iteration 23058 : model1 loss : 0.438503 model2 loss : 0.020475
[12:00:26.243] iteration 23059 : model1 loss : 0.440732 model2 loss : 0.021593
[12:00:26.408] iteration 23060 : model1 loss : 0.443872 model2 loss : 0.020072
[12:00:26.576] iteration 23061 : model1 loss : 0.437508 model2 loss : 0.020849
[12:00:26.742] iteration 23062 : model1 loss : 0.437086 model2 loss : 0.021758
[12:00:26.912] iteration 23063 : model1 loss : 0.441777 model2 loss : 0.021151
[12:00:27.079] iteration 23064 : model1 loss : 0.438790 model2 loss : 0.021525
[12:00:27.260] iteration 23065 : model1 loss : 0.441168 model2 loss : 0.021112
[12:00:27.426] iteration 23066 : model1 loss : 0.439931 model2 loss : 0.020841
[12:00:27.593] iteration 23067 : model1 loss : 0.440093 model2 loss : 0.021366
[12:00:29.550] iteration 23068 : model1 loss : 0.440011 model2 loss : 0.020867
[12:00:29.725] iteration 23069 : model1 loss : 0.441661 model2 loss : 0.020938
[12:00:29.894] iteration 23070 : model1 loss : 0.438915 model2 loss : 0.021919
[12:00:30.061] iteration 23071 : model1 loss : 0.439936 model2 loss : 0.021652
[12:00:30.228] iteration 23072 : model1 loss : 0.438229 model2 loss : 0.021466
[12:00:30.394] iteration 23073 : model1 loss : 0.437865 model2 loss : 0.017551
[12:00:30.565] iteration 23074 : model1 loss : 0.440450 model2 loss : 0.019566
[12:00:30.737] iteration 23075 : model1 loss : 0.438816 model2 loss : 0.018829
[12:00:30.906] iteration 23076 : model1 loss : 0.436868 model2 loss : 0.020704
[12:00:31.074] iteration 23077 : model1 loss : 0.441767 model2 loss : 0.022381
[12:00:31.241] iteration 23078 : model1 loss : 0.439110 model2 loss : 0.021620
[12:00:31.409] iteration 23079 : model1 loss : 0.438078 model2 loss : 0.020927
[12:00:31.578] iteration 23080 : model1 loss : 0.445069 model2 loss : 0.025257
[12:00:31.748] iteration 23081 : model1 loss : 0.436479 model2 loss : 0.020684
[12:00:31.917] iteration 23082 : model1 loss : 0.439675 model2 loss : 0.021321
[12:00:32.085] iteration 23083 : model1 loss : 0.442635 model2 loss : 0.022430
[12:00:32.255] iteration 23084 : model1 loss : 0.441667 model2 loss : 0.022571
[12:00:32.423] iteration 23085 : model1 loss : 0.439838 model2 loss : 0.020663
[12:00:32.593] iteration 23086 : model1 loss : 0.442384 model2 loss : 0.020791
[12:00:32.762] iteration 23087 : model1 loss : 0.435243 model2 loss : 0.021704
[12:00:32.932] iteration 23088 : model1 loss : 0.442931 model2 loss : 0.021541
[12:00:33.099] iteration 23089 : model1 loss : 0.441661 model2 loss : 0.019947
[12:00:33.269] iteration 23090 : model1 loss : 0.438827 model2 loss : 0.020619
[12:00:33.437] iteration 23091 : model1 loss : 0.437071 model2 loss : 0.020763
[12:00:33.604] iteration 23092 : model1 loss : 0.443779 model2 loss : 0.020975
[12:00:33.771] iteration 23093 : model1 loss : 0.436086 model2 loss : 0.020318
[12:00:33.940] iteration 23094 : model1 loss : 0.438056 model2 loss : 0.020947
[12:00:34.107] iteration 23095 : model1 loss : 0.440939 model2 loss : 0.022497
[12:00:34.277] iteration 23096 : model1 loss : 0.436608 model2 loss : 0.017773
[12:00:34.445] iteration 23097 : model1 loss : 0.440270 model2 loss : 0.022425
[12:00:34.614] iteration 23098 : model1 loss : 0.435820 model2 loss : 0.019134
[12:00:34.780] iteration 23099 : model1 loss : 0.435782 model2 loss : 0.018558
[12:00:34.948] iteration 23100 : model1 loss : 0.437150 model2 loss : 0.020415
[12:00:36.898] iteration 23101 : model1 loss : 0.441088 model2 loss : 0.021101
[12:00:37.064] iteration 23102 : model1 loss : 0.440379 model2 loss : 0.019122
[12:00:37.235] iteration 23103 : model1 loss : 0.440601 model2 loss : 0.021109
[12:00:37.401] iteration 23104 : model1 loss : 0.440452 model2 loss : 0.021723
[12:00:37.573] iteration 23105 : model1 loss : 0.439872 model2 loss : 0.020940
[12:00:37.745] iteration 23106 : model1 loss : 0.438750 model2 loss : 0.019627
[12:00:37.915] iteration 23107 : model1 loss : 0.439468 model2 loss : 0.022583
[12:00:38.083] iteration 23108 : model1 loss : 0.437624 model2 loss : 0.020485
[12:00:38.252] iteration 23109 : model1 loss : 0.440320 model2 loss : 0.021923
[12:00:38.418] iteration 23110 : model1 loss : 0.438053 model2 loss : 0.021684
[12:00:38.586] iteration 23111 : model1 loss : 0.442615 model2 loss : 0.021469
[12:00:38.755] iteration 23112 : model1 loss : 0.437033 model2 loss : 0.019654
[12:00:38.925] iteration 23113 : model1 loss : 0.442958 model2 loss : 0.020952
[12:00:39.093] iteration 23114 : model1 loss : 0.441665 model2 loss : 0.020527
[12:00:39.263] iteration 23115 : model1 loss : 0.439173 model2 loss : 0.019438
[12:00:39.428] iteration 23116 : model1 loss : 0.432915 model2 loss : 0.019296
[12:00:39.596] iteration 23117 : model1 loss : 0.436099 model2 loss : 0.021888
[12:00:39.763] iteration 23118 : model1 loss : 0.436960 model2 loss : 0.021136
[12:00:39.932] iteration 23119 : model1 loss : 0.437658 model2 loss : 0.020115
[12:00:40.098] iteration 23120 : model1 loss : 0.436747 model2 loss : 0.019116
[12:00:40.267] iteration 23121 : model1 loss : 0.439000 model2 loss : 0.020311
[12:00:40.433] iteration 23122 : model1 loss : 0.437371 model2 loss : 0.021395
[12:00:40.604] iteration 23123 : model1 loss : 0.441435 model2 loss : 0.018486
[12:00:40.773] iteration 23124 : model1 loss : 0.443692 model2 loss : 0.021588
[12:00:40.945] iteration 23125 : model1 loss : 0.436085 model2 loss : 0.019164
[12:00:41.112] iteration 23126 : model1 loss : 0.435343 model2 loss : 0.017790
[12:00:41.281] iteration 23127 : model1 loss : 0.438448 model2 loss : 0.019341
[12:00:41.449] iteration 23128 : model1 loss : 0.438199 model2 loss : 0.020851
[12:00:41.618] iteration 23129 : model1 loss : 0.438526 model2 loss : 0.019958
[12:00:41.785] iteration 23130 : model1 loss : 0.444121 model2 loss : 0.019990
[12:00:41.956] iteration 23131 : model1 loss : 0.442551 model2 loss : 0.019874
[12:00:42.121] iteration 23132 : model1 loss : 0.441638 model2 loss : 0.019232
[12:00:42.288] iteration 23133 : model1 loss : 0.443097 model2 loss : 0.021757
[12:00:44.188] iteration 23134 : model1 loss : 0.441823 model2 loss : 0.020623
[12:00:44.354] iteration 23135 : model1 loss : 0.438422 model2 loss : 0.020910
[12:00:44.527] iteration 23136 : model1 loss : 0.438282 model2 loss : 0.020840
[12:00:44.694] iteration 23137 : model1 loss : 0.438955 model2 loss : 0.018728
[12:00:44.863] iteration 23138 : model1 loss : 0.440209 model2 loss : 0.021043
[12:00:45.030] iteration 23139 : model1 loss : 0.442516 model2 loss : 0.021841
[12:00:45.199] iteration 23140 : model1 loss : 0.442525 model2 loss : 0.019619
[12:00:45.368] iteration 23141 : model1 loss : 0.443869 model2 loss : 0.022375
[12:00:45.538] iteration 23142 : model1 loss : 0.439631 model2 loss : 0.019928
[12:00:45.704] iteration 23143 : model1 loss : 0.442433 model2 loss : 0.018821
[12:00:45.874] iteration 23144 : model1 loss : 0.440138 model2 loss : 0.021578
[12:00:46.040] iteration 23145 : model1 loss : 0.436004 model2 loss : 0.020431
[12:00:46.208] iteration 23146 : model1 loss : 0.441435 model2 loss : 0.021553
[12:00:46.373] iteration 23147 : model1 loss : 0.435397 model2 loss : 0.019219
[12:00:46.545] iteration 23148 : model1 loss : 0.441065 model2 loss : 0.021450
[12:00:46.711] iteration 23149 : model1 loss : 0.437120 model2 loss : 0.021839
[12:00:46.880] iteration 23150 : model1 loss : 0.437028 model2 loss : 0.019771
[12:00:47.046] iteration 23151 : model1 loss : 0.441479 model2 loss : 0.021510
[12:00:47.215] iteration 23152 : model1 loss : 0.442276 model2 loss : 0.020482
[12:00:47.383] iteration 23153 : model1 loss : 0.436993 model2 loss : 0.021332
[12:00:47.553] iteration 23154 : model1 loss : 0.439351 model2 loss : 0.022133
[12:00:47.721] iteration 23155 : model1 loss : 0.433414 model2 loss : 0.019971
[12:00:47.891] iteration 23156 : model1 loss : 0.435970 model2 loss : 0.021426
[12:00:48.058] iteration 23157 : model1 loss : 0.438834 model2 loss : 0.020416
[12:00:48.227] iteration 23158 : model1 loss : 0.442529 model2 loss : 0.021502
[12:00:48.398] iteration 23159 : model1 loss : 0.437254 model2 loss : 0.017965
[12:00:48.566] iteration 23160 : model1 loss : 0.443061 model2 loss : 0.021611
[12:00:48.736] iteration 23161 : model1 loss : 0.442203 model2 loss : 0.022920
[12:00:48.907] iteration 23162 : model1 loss : 0.437587 model2 loss : 0.019153
[12:00:49.074] iteration 23163 : model1 loss : 0.436764 model2 loss : 0.017699
[12:00:49.246] iteration 23164 : model1 loss : 0.443471 model2 loss : 0.021135
[12:00:49.411] iteration 23165 : model1 loss : 0.436255 model2 loss : 0.021870
[12:00:49.580] iteration 23166 : model1 loss : 0.436941 model2 loss : 0.022014
[12:00:51.532] iteration 23167 : model1 loss : 0.441431 model2 loss : 0.022108
[12:00:51.703] iteration 23168 : model1 loss : 0.437106 model2 loss : 0.024270
[12:00:51.873] iteration 23169 : model1 loss : 0.440026 model2 loss : 0.021478
[12:00:52.040] iteration 23170 : model1 loss : 0.437901 model2 loss : 0.018570
[12:00:52.211] iteration 23171 : model1 loss : 0.437648 model2 loss : 0.017889
[12:00:52.386] iteration 23172 : model1 loss : 0.435761 model2 loss : 0.019616
[12:00:52.556] iteration 23173 : model1 loss : 0.443456 model2 loss : 0.022870
[12:00:52.726] iteration 23174 : model1 loss : 0.437370 model2 loss : 0.019955
[12:00:52.896] iteration 23175 : model1 loss : 0.438195 model2 loss : 0.018758
[12:00:53.065] iteration 23176 : model1 loss : 0.442029 model2 loss : 0.020364
[12:00:53.235] iteration 23177 : model1 loss : 0.446117 model2 loss : 0.024192
[12:00:53.403] iteration 23178 : model1 loss : 0.441348 model2 loss : 0.022268
[12:00:53.574] iteration 23179 : model1 loss : 0.440557 model2 loss : 0.020036
[12:00:53.743] iteration 23180 : model1 loss : 0.439080 model2 loss : 0.021892
[12:00:53.913] iteration 23181 : model1 loss : 0.432976 model2 loss : 0.018678
[12:00:54.082] iteration 23182 : model1 loss : 0.436436 model2 loss : 0.024423
[12:00:54.251] iteration 23183 : model1 loss : 0.441144 model2 loss : 0.020301
[12:00:54.419] iteration 23184 : model1 loss : 0.434660 model2 loss : 0.017970
[12:00:54.591] iteration 23185 : model1 loss : 0.436902 model2 loss : 0.019831
[12:00:54.763] iteration 23186 : model1 loss : 0.438755 model2 loss : 0.022703
[12:00:54.932] iteration 23187 : model1 loss : 0.442457 model2 loss : 0.021900
[12:00:55.099] iteration 23188 : model1 loss : 0.443925 model2 loss : 0.022215
[12:00:55.268] iteration 23189 : model1 loss : 0.440156 model2 loss : 0.021254
[12:00:55.436] iteration 23190 : model1 loss : 0.439550 model2 loss : 0.021947
[12:00:55.605] iteration 23191 : model1 loss : 0.437506 model2 loss : 0.021599
[12:00:55.777] iteration 23192 : model1 loss : 0.444511 model2 loss : 0.022086
[12:00:55.951] iteration 23193 : model1 loss : 0.437086 model2 loss : 0.022028
[12:00:56.118] iteration 23194 : model1 loss : 0.444433 model2 loss : 0.022557
[12:00:56.288] iteration 23195 : model1 loss : 0.437476 model2 loss : 0.018195
[12:00:56.456] iteration 23196 : model1 loss : 0.435984 model2 loss : 0.020404
[12:00:56.625] iteration 23197 : model1 loss : 0.439214 model2 loss : 0.020805
[12:00:56.792] iteration 23198 : model1 loss : 0.439816 model2 loss : 0.022599
[12:00:56.961] iteration 23199 : model1 loss : 0.437273 model2 loss : 0.025282
[12:00:58.892] iteration 23200 : model1 loss : 0.440211 model2 loss : 0.021353
[12:00:59.061] iteration 23201 : model1 loss : 0.439622 model2 loss : 0.021283
[12:00:59.231] iteration 23202 : model1 loss : 0.439823 model2 loss : 0.019239
[12:00:59.398] iteration 23203 : model1 loss : 0.437606 model2 loss : 0.019583
[12:00:59.567] iteration 23204 : model1 loss : 0.439795 model2 loss : 0.022378
[12:00:59.735] iteration 23205 : model1 loss : 0.435178 model2 loss : 0.023142
[12:00:59.902] iteration 23206 : model1 loss : 0.438019 model2 loss : 0.021476
[12:01:00.070] iteration 23207 : model1 loss : 0.437253 model2 loss : 0.019215
[12:01:00.238] iteration 23208 : model1 loss : 0.436921 model2 loss : 0.022134
[12:01:00.405] iteration 23209 : model1 loss : 0.443067 model2 loss : 0.021029
[12:01:00.577] iteration 23210 : model1 loss : 0.433276 model2 loss : 0.022418
[12:01:00.747] iteration 23211 : model1 loss : 0.437411 model2 loss : 0.020066
[12:01:00.918] iteration 23212 : model1 loss : 0.442355 model2 loss : 0.024742
[12:01:01.083] iteration 23213 : model1 loss : 0.437438 model2 loss : 0.021015
[12:01:01.255] iteration 23214 : model1 loss : 0.438290 model2 loss : 0.019504
[12:01:01.421] iteration 23215 : model1 loss : 0.435385 model2 loss : 0.019193
[12:01:01.591] iteration 23216 : model1 loss : 0.442486 model2 loss : 0.019417
[12:01:01.759] iteration 23217 : model1 loss : 0.438359 model2 loss : 0.019600
[12:01:01.930] iteration 23218 : model1 loss : 0.437002 model2 loss : 0.022316
[12:01:02.099] iteration 23219 : model1 loss : 0.438009 model2 loss : 0.022512
[12:01:02.269] iteration 23220 : model1 loss : 0.440563 model2 loss : 0.023415
[12:01:02.437] iteration 23221 : model1 loss : 0.437387 model2 loss : 0.018692
[12:01:02.607] iteration 23222 : model1 loss : 0.440051 model2 loss : 0.021008
[12:01:02.775] iteration 23223 : model1 loss : 0.439777 model2 loss : 0.020458
[12:01:02.946] iteration 23224 : model1 loss : 0.442840 model2 loss : 0.022494
[12:01:03.114] iteration 23225 : model1 loss : 0.443041 model2 loss : 0.019992
[12:01:03.284] iteration 23226 : model1 loss : 0.441089 model2 loss : 0.021216
[12:01:03.451] iteration 23227 : model1 loss : 0.444755 model2 loss : 0.023610
[12:01:03.620] iteration 23228 : model1 loss : 0.437976 model2 loss : 0.018598
[12:01:03.787] iteration 23229 : model1 loss : 0.440593 model2 loss : 0.020450
[12:01:03.955] iteration 23230 : model1 loss : 0.444452 model2 loss : 0.021266
[12:01:04.122] iteration 23231 : model1 loss : 0.438114 model2 loss : 0.019846
[12:01:04.290] iteration 23232 : model1 loss : 0.438240 model2 loss : 0.019497
[12:01:06.253] iteration 23233 : model1 loss : 0.443555 model2 loss : 0.020591
[12:01:06.419] iteration 23234 : model1 loss : 0.435591 model2 loss : 0.021805
[12:01:06.590] iteration 23235 : model1 loss : 0.435320 model2 loss : 0.020078
[12:01:06.758] iteration 23236 : model1 loss : 0.435403 model2 loss : 0.021694
[12:01:06.927] iteration 23237 : model1 loss : 0.435233 model2 loss : 0.020419
[12:01:07.093] iteration 23238 : model1 loss : 0.437025 model2 loss : 0.020922
[12:01:07.262] iteration 23239 : model1 loss : 0.440834 model2 loss : 0.021208
[12:01:07.427] iteration 23240 : model1 loss : 0.438851 model2 loss : 0.019480
[12:01:07.596] iteration 23241 : model1 loss : 0.438501 model2 loss : 0.021941
[12:01:07.763] iteration 23242 : model1 loss : 0.440005 model2 loss : 0.021956
[12:01:07.931] iteration 23243 : model1 loss : 0.437274 model2 loss : 0.017626
[12:01:08.098] iteration 23244 : model1 loss : 0.443045 model2 loss : 0.020757
[12:01:08.266] iteration 23245 : model1 loss : 0.440007 model2 loss : 0.020904
[12:01:08.432] iteration 23246 : model1 loss : 0.439886 model2 loss : 0.020360
[12:01:08.602] iteration 23247 : model1 loss : 0.436187 model2 loss : 0.017401
[12:01:08.768] iteration 23248 : model1 loss : 0.442976 model2 loss : 0.020636
[12:01:08.937] iteration 23249 : model1 loss : 0.444647 model2 loss : 0.023192
[12:01:09.103] iteration 23250 : model1 loss : 0.437847 model2 loss : 0.019817
[12:01:09.273] iteration 23251 : model1 loss : 0.437565 model2 loss : 0.018710
[12:01:09.440] iteration 23252 : model1 loss : 0.440636 model2 loss : 0.020363
[12:01:09.608] iteration 23253 : model1 loss : 0.438522 model2 loss : 0.020588
[12:01:09.774] iteration 23254 : model1 loss : 0.440982 model2 loss : 0.021412
[12:01:09.943] iteration 23255 : model1 loss : 0.435350 model2 loss : 0.019838
[12:01:10.110] iteration 23256 : model1 loss : 0.438763 model2 loss : 0.019218
[12:01:10.278] iteration 23257 : model1 loss : 0.438795 model2 loss : 0.021211
[12:01:10.447] iteration 23258 : model1 loss : 0.445295 model2 loss : 0.022516
[12:01:10.616] iteration 23259 : model1 loss : 0.440041 model2 loss : 0.020344
[12:01:10.784] iteration 23260 : model1 loss : 0.439698 model2 loss : 0.020564
[12:01:10.954] iteration 23261 : model1 loss : 0.439547 model2 loss : 0.021737
[12:01:11.121] iteration 23262 : model1 loss : 0.440839 model2 loss : 0.020006
[12:01:11.291] iteration 23263 : model1 loss : 0.439713 model2 loss : 0.021696
[12:01:11.456] iteration 23264 : model1 loss : 0.440112 model2 loss : 0.020635
[12:01:11.624] iteration 23265 : model1 loss : 0.442314 model2 loss : 0.023536
[12:01:13.547] iteration 23266 : model1 loss : 0.438884 model2 loss : 0.022023
[12:01:13.716] iteration 23267 : model1 loss : 0.436184 model2 loss : 0.018172
[12:01:13.887] iteration 23268 : model1 loss : 0.439454 model2 loss : 0.020725
[12:01:14.054] iteration 23269 : model1 loss : 0.435007 model2 loss : 0.019915
[12:01:14.222] iteration 23270 : model1 loss : 0.439513 model2 loss : 0.020369
[12:01:14.389] iteration 23271 : model1 loss : 0.439403 model2 loss : 0.019353
[12:01:14.559] iteration 23272 : model1 loss : 0.440810 model2 loss : 0.021795
[12:01:14.727] iteration 23273 : model1 loss : 0.443784 model2 loss : 0.023863
[12:01:14.897] iteration 23274 : model1 loss : 0.438422 model2 loss : 0.021408
[12:01:15.063] iteration 23275 : model1 loss : 0.445240 model2 loss : 0.024141
[12:01:15.234] iteration 23276 : model1 loss : 0.438568 model2 loss : 0.019098
[12:01:15.401] iteration 23277 : model1 loss : 0.442688 model2 loss : 0.022771
[12:01:15.569] iteration 23278 : model1 loss : 0.438320 model2 loss : 0.021406
[12:01:15.737] iteration 23279 : model1 loss : 0.437741 model2 loss : 0.021341
[12:01:15.912] iteration 23280 : model1 loss : 0.443935 model2 loss : 0.020127
[12:01:16.079] iteration 23281 : model1 loss : 0.435166 model2 loss : 0.019652
[12:01:16.247] iteration 23282 : model1 loss : 0.438774 model2 loss : 0.020351
[12:01:16.413] iteration 23283 : model1 loss : 0.436909 model2 loss : 0.019758
[12:01:16.585] iteration 23284 : model1 loss : 0.440843 model2 loss : 0.022117
[12:01:16.752] iteration 23285 : model1 loss : 0.443254 model2 loss : 0.020737
[12:01:16.923] iteration 23286 : model1 loss : 0.439991 model2 loss : 0.022321
[12:01:17.091] iteration 23287 : model1 loss : 0.444079 model2 loss : 0.023378
[12:01:17.262] iteration 23288 : model1 loss : 0.439235 model2 loss : 0.018143
[12:01:17.429] iteration 23289 : model1 loss : 0.437976 model2 loss : 0.020698
[12:01:17.597] iteration 23290 : model1 loss : 0.437567 model2 loss : 0.020468
[12:01:17.765] iteration 23291 : model1 loss : 0.438021 model2 loss : 0.021186
[12:01:17.935] iteration 23292 : model1 loss : 0.434385 model2 loss : 0.020706
[12:01:18.102] iteration 23293 : model1 loss : 0.438213 model2 loss : 0.021390
[12:01:18.285] iteration 23294 : model1 loss : 0.438215 model2 loss : 0.018017
[12:01:18.452] iteration 23295 : model1 loss : 0.441497 model2 loss : 0.022594
[12:01:18.621] iteration 23296 : model1 loss : 0.440359 model2 loss : 0.018856
[12:01:18.790] iteration 23297 : model1 loss : 0.435928 model2 loss : 0.019190
[12:01:18.957] iteration 23298 : model1 loss : 0.437580 model2 loss : 0.017162
[12:01:20.917] iteration 23299 : model1 loss : 0.437460 model2 loss : 0.019143
[12:01:21.086] iteration 23300 : model1 loss : 0.436428 model2 loss : 0.017901
[12:01:21.274] iteration 23301 : model1 loss : 0.443906 model2 loss : 0.023997
[12:01:21.441] iteration 23302 : model1 loss : 0.439770 model2 loss : 0.019187
[12:01:21.611] iteration 23303 : model1 loss : 0.442494 model2 loss : 0.020296
[12:01:21.780] iteration 23304 : model1 loss : 0.438306 model2 loss : 0.022245
[12:01:21.951] iteration 23305 : model1 loss : 0.442156 model2 loss : 0.023575
[12:01:22.118] iteration 23306 : model1 loss : 0.435506 model2 loss : 0.019165
[12:01:22.289] iteration 23307 : model1 loss : 0.442098 model2 loss : 0.020686
[12:01:22.454] iteration 23308 : model1 loss : 0.441831 model2 loss : 0.022612
[12:01:22.622] iteration 23309 : model1 loss : 0.437054 model2 loss : 0.020872
[12:01:22.790] iteration 23310 : model1 loss : 0.437653 model2 loss : 0.019693
[12:01:22.957] iteration 23311 : model1 loss : 0.436499 model2 loss : 0.018864
[12:01:23.125] iteration 23312 : model1 loss : 0.439502 model2 loss : 0.020566
[12:01:23.292] iteration 23313 : model1 loss : 0.438859 model2 loss : 0.019817
[12:01:23.459] iteration 23314 : model1 loss : 0.436079 model2 loss : 0.021607
[12:01:23.629] iteration 23315 : model1 loss : 0.442649 model2 loss : 0.021172
[12:01:23.796] iteration 23316 : model1 loss : 0.438221 model2 loss : 0.021482
[12:01:23.966] iteration 23317 : model1 loss : 0.437725 model2 loss : 0.019527
[12:01:24.133] iteration 23318 : model1 loss : 0.441095 model2 loss : 0.022188
[12:01:24.303] iteration 23319 : model1 loss : 0.440242 model2 loss : 0.019815
[12:01:24.470] iteration 23320 : model1 loss : 0.438793 model2 loss : 0.020445
[12:01:24.639] iteration 23321 : model1 loss : 0.439096 model2 loss : 0.021094
[12:01:24.805] iteration 23322 : model1 loss : 0.437788 model2 loss : 0.020275
[12:01:24.974] iteration 23323 : model1 loss : 0.439256 model2 loss : 0.019513
[12:01:25.142] iteration 23324 : model1 loss : 0.436545 model2 loss : 0.018980
[12:01:25.310] iteration 23325 : model1 loss : 0.437712 model2 loss : 0.019061
[12:01:25.478] iteration 23326 : model1 loss : 0.438618 model2 loss : 0.021028
[12:01:25.648] iteration 23327 : model1 loss : 0.439608 model2 loss : 0.021769
[12:01:25.816] iteration 23328 : model1 loss : 0.441229 model2 loss : 0.021012
[12:01:25.987] iteration 23329 : model1 loss : 0.443361 model2 loss : 0.022545
[12:01:26.152] iteration 23330 : model1 loss : 0.441850 model2 loss : 0.019666
[12:01:26.319] iteration 23331 : model1 loss : 0.435542 model2 loss : 0.017902
[12:01:28.224] iteration 23332 : model1 loss : 0.435549 model2 loss : 0.017259
[12:01:28.391] iteration 23333 : model1 loss : 0.441598 model2 loss : 0.021756
[12:01:28.561] iteration 23334 : model1 loss : 0.438638 model2 loss : 0.018737
[12:01:28.727] iteration 23335 : model1 loss : 0.439181 model2 loss : 0.020686
[12:01:28.896] iteration 23336 : model1 loss : 0.439764 model2 loss : 0.022146
[12:01:29.062] iteration 23337 : model1 loss : 0.435373 model2 loss : 0.018741
[12:01:29.231] iteration 23338 : model1 loss : 0.438031 model2 loss : 0.020269
[12:01:29.397] iteration 23339 : model1 loss : 0.437546 model2 loss : 0.020722
[12:01:29.568] iteration 23340 : model1 loss : 0.438108 model2 loss : 0.017308
[12:01:29.735] iteration 23341 : model1 loss : 0.435338 model2 loss : 0.019202
[12:01:29.906] iteration 23342 : model1 loss : 0.440132 model2 loss : 0.021791
[12:01:30.073] iteration 23343 : model1 loss : 0.435985 model2 loss : 0.018413
[12:01:30.242] iteration 23344 : model1 loss : 0.437470 model2 loss : 0.020161
[12:01:30.409] iteration 23345 : model1 loss : 0.437965 model2 loss : 0.019949
[12:01:30.579] iteration 23346 : model1 loss : 0.443355 model2 loss : 0.021242
[12:01:30.747] iteration 23347 : model1 loss : 0.438832 model2 loss : 0.019850
[12:01:30.919] iteration 23348 : model1 loss : 0.441908 model2 loss : 0.024175
[12:01:31.086] iteration 23349 : model1 loss : 0.441413 model2 loss : 0.019761
[12:01:31.255] iteration 23350 : model1 loss : 0.443778 model2 loss : 0.023503
[12:01:31.422] iteration 23351 : model1 loss : 0.444103 model2 loss : 0.021968
[12:01:31.591] iteration 23352 : model1 loss : 0.438537 model2 loss : 0.021153
[12:01:31.758] iteration 23353 : model1 loss : 0.439601 model2 loss : 0.018875
[12:01:31.929] iteration 23354 : model1 loss : 0.435842 model2 loss : 0.019106
[12:01:32.096] iteration 23355 : model1 loss : 0.439903 model2 loss : 0.022021
[12:01:32.266] iteration 23356 : model1 loss : 0.437934 model2 loss : 0.019111
[12:01:32.433] iteration 23357 : model1 loss : 0.441844 model2 loss : 0.021579
[12:01:32.603] iteration 23358 : model1 loss : 0.441541 model2 loss : 0.023565
[12:01:32.769] iteration 23359 : model1 loss : 0.439141 model2 loss : 0.019750
[12:01:32.942] iteration 23360 : model1 loss : 0.440184 model2 loss : 0.020310
[12:01:33.111] iteration 23361 : model1 loss : 0.439664 model2 loss : 0.019842
[12:01:33.280] iteration 23362 : model1 loss : 0.437217 model2 loss : 0.020910
[12:01:33.446] iteration 23363 : model1 loss : 0.437308 model2 loss : 0.019344
[12:01:33.613] iteration 23364 : model1 loss : 0.441143 model2 loss : 0.022048
[12:01:35.520] iteration 23365 : model1 loss : 0.441382 model2 loss : 0.021575
[12:01:35.693] iteration 23366 : model1 loss : 0.437345 model2 loss : 0.020017
[12:01:35.864] iteration 23367 : model1 loss : 0.437410 model2 loss : 0.021359
[12:01:36.031] iteration 23368 : model1 loss : 0.439074 model2 loss : 0.018048
[12:01:36.201] iteration 23369 : model1 loss : 0.434720 model2 loss : 0.019389
[12:01:36.370] iteration 23370 : model1 loss : 0.440921 model2 loss : 0.023802
[12:01:36.541] iteration 23371 : model1 loss : 0.441445 model2 loss : 0.019227
[12:01:36.710] iteration 23372 : model1 loss : 0.436363 model2 loss : 0.019799
[12:01:36.879] iteration 23373 : model1 loss : 0.439476 model2 loss : 0.021764
[12:01:37.046] iteration 23374 : model1 loss : 0.440962 model2 loss : 0.023055
[12:01:37.215] iteration 23375 : model1 loss : 0.435606 model2 loss : 0.019017
[12:01:37.383] iteration 23376 : model1 loss : 0.440142 model2 loss : 0.023074
[12:01:37.552] iteration 23377 : model1 loss : 0.442323 model2 loss : 0.022815
[12:01:37.720] iteration 23378 : model1 loss : 0.436636 model2 loss : 0.018172
[12:01:37.888] iteration 23379 : model1 loss : 0.440203 model2 loss : 0.022379
[12:01:38.056] iteration 23380 : model1 loss : 0.438953 model2 loss : 0.019459
[12:01:38.225] iteration 23381 : model1 loss : 0.438915 model2 loss : 0.020599
[12:01:38.392] iteration 23382 : model1 loss : 0.445092 model2 loss : 0.022972
[12:01:38.563] iteration 23383 : model1 loss : 0.440374 model2 loss : 0.021548
[12:01:38.731] iteration 23384 : model1 loss : 0.439508 model2 loss : 0.020219
[12:01:38.903] iteration 23385 : model1 loss : 0.436349 model2 loss : 0.018411
[12:01:39.072] iteration 23386 : model1 loss : 0.443801 model2 loss : 0.021448
[12:01:39.243] iteration 23387 : model1 loss : 0.436268 model2 loss : 0.020347
[12:01:39.411] iteration 23388 : model1 loss : 0.435554 model2 loss : 0.020663
[12:01:39.580] iteration 23389 : model1 loss : 0.436872 model2 loss : 0.022153
[12:01:39.756] iteration 23390 : model1 loss : 0.440123 model2 loss : 0.021179
[12:01:39.930] iteration 23391 : model1 loss : 0.438501 model2 loss : 0.018879
[12:01:40.097] iteration 23392 : model1 loss : 0.436966 model2 loss : 0.020966
[12:01:40.267] iteration 23393 : model1 loss : 0.443100 model2 loss : 0.022663
[12:01:40.432] iteration 23394 : model1 loss : 0.442605 model2 loss : 0.021233
[12:01:40.602] iteration 23395 : model1 loss : 0.440577 model2 loss : 0.018795
[12:01:40.767] iteration 23396 : model1 loss : 0.440535 model2 loss : 0.020424
[12:01:40.943] iteration 23397 : model1 loss : 0.438775 model2 loss : 0.021479
[12:01:42.832] iteration 23398 : model1 loss : 0.439754 model2 loss : 0.018114
[12:01:43.000] iteration 23399 : model1 loss : 0.438730 model2 loss : 0.018785
[12:01:43.168] iteration 23400 : model1 loss : 0.441304 model2 loss : 0.020104
[12:01:43.351] iteration 23401 : model1 loss : 0.437689 model2 loss : 0.019897
[12:01:43.525] iteration 23402 : model1 loss : 0.433748 model2 loss : 0.018468
[12:01:43.693] iteration 23403 : model1 loss : 0.438532 model2 loss : 0.021267
[12:01:43.863] iteration 23404 : model1 loss : 0.436413 model2 loss : 0.019146
[12:01:44.031] iteration 23405 : model1 loss : 0.434691 model2 loss : 0.018497
[12:01:44.199] iteration 23406 : model1 loss : 0.436255 model2 loss : 0.018715
[12:01:44.366] iteration 23407 : model1 loss : 0.438134 model2 loss : 0.019855
[12:01:44.534] iteration 23408 : model1 loss : 0.439963 model2 loss : 0.023228
[12:01:44.701] iteration 23409 : model1 loss : 0.440251 model2 loss : 0.019756
[12:01:44.872] iteration 23410 : model1 loss : 0.438149 model2 loss : 0.019127
[12:01:45.038] iteration 23411 : model1 loss : 0.441336 model2 loss : 0.018931
[12:01:45.218] iteration 23412 : model1 loss : 0.440104 model2 loss : 0.020053
[12:01:45.384] iteration 23413 : model1 loss : 0.439591 model2 loss : 0.021100
[12:01:45.555] iteration 23414 : model1 loss : 0.441324 model2 loss : 0.019859
[12:01:45.721] iteration 23415 : model1 loss : 0.438014 model2 loss : 0.019660
[12:01:45.892] iteration 23416 : model1 loss : 0.443872 model2 loss : 0.023779
[12:01:46.059] iteration 23417 : model1 loss : 0.437966 model2 loss : 0.017646
[12:01:46.231] iteration 23418 : model1 loss : 0.434633 model2 loss : 0.020244
[12:01:46.397] iteration 23419 : model1 loss : 0.441876 model2 loss : 0.019075
[12:01:46.568] iteration 23420 : model1 loss : 0.446358 model2 loss : 0.023696
[12:01:46.737] iteration 23421 : model1 loss : 0.437725 model2 loss : 0.019297
[12:01:46.907] iteration 23422 : model1 loss : 0.441517 model2 loss : 0.019464
[12:01:47.074] iteration 23423 : model1 loss : 0.440904 model2 loss : 0.019769
[12:01:47.245] iteration 23424 : model1 loss : 0.439006 model2 loss : 0.022349
[12:01:47.413] iteration 23425 : model1 loss : 0.445142 model2 loss : 0.022617
[12:01:47.581] iteration 23426 : model1 loss : 0.441304 model2 loss : 0.025283
[12:01:47.749] iteration 23427 : model1 loss : 0.438732 model2 loss : 0.021889
[12:01:47.920] iteration 23428 : model1 loss : 0.439539 model2 loss : 0.020642
[12:01:48.085] iteration 23429 : model1 loss : 0.433138 model2 loss : 0.020373
[12:01:48.254] iteration 23430 : model1 loss : 0.440577 model2 loss : 0.021575
[12:01:50.164] iteration 23431 : model1 loss : 0.443393 model2 loss : 0.020237
[12:01:50.334] iteration 23432 : model1 loss : 0.441928 model2 loss : 0.022799
[12:01:50.508] iteration 23433 : model1 loss : 0.438256 model2 loss : 0.019832
[12:01:50.676] iteration 23434 : model1 loss : 0.441327 model2 loss : 0.021478
[12:01:50.846] iteration 23435 : model1 loss : 0.441296 model2 loss : 0.021655
[12:01:51.022] iteration 23436 : model1 loss : 0.436929 model2 loss : 0.021270
[12:01:51.192] iteration 23437 : model1 loss : 0.437459 model2 loss : 0.019012
[12:01:51.361] iteration 23438 : model1 loss : 0.439140 model2 loss : 0.019255
[12:01:51.531] iteration 23439 : model1 loss : 0.439508 model2 loss : 0.019157
[12:01:51.698] iteration 23440 : model1 loss : 0.435959 model2 loss : 0.019142
[12:01:51.868] iteration 23441 : model1 loss : 0.444267 model2 loss : 0.021761
[12:01:52.036] iteration 23442 : model1 loss : 0.439289 model2 loss : 0.019758
[12:01:52.207] iteration 23443 : model1 loss : 0.442136 model2 loss : 0.022773
[12:01:52.381] iteration 23444 : model1 loss : 0.434589 model2 loss : 0.017887
[12:01:52.551] iteration 23445 : model1 loss : 0.441324 model2 loss : 0.018904
[12:01:52.719] iteration 23446 : model1 loss : 0.447738 model2 loss : 0.021013
[12:01:52.891] iteration 23447 : model1 loss : 0.435503 model2 loss : 0.019211
[12:01:53.057] iteration 23448 : model1 loss : 0.438363 model2 loss : 0.020917
[12:01:53.226] iteration 23449 : model1 loss : 0.437667 model2 loss : 0.020408
[12:01:53.392] iteration 23450 : model1 loss : 0.438821 model2 loss : 0.023339
[12:01:53.562] iteration 23451 : model1 loss : 0.445550 model2 loss : 0.024351
[12:01:53.730] iteration 23452 : model1 loss : 0.439229 model2 loss : 0.020864
[12:01:53.901] iteration 23453 : model1 loss : 0.433971 model2 loss : 0.019579
[12:01:54.069] iteration 23454 : model1 loss : 0.439054 model2 loss : 0.021239
[12:01:54.238] iteration 23455 : model1 loss : 0.437740 model2 loss : 0.020608
[12:01:54.404] iteration 23456 : model1 loss : 0.438058 model2 loss : 0.020735
[12:01:54.574] iteration 23457 : model1 loss : 0.439528 model2 loss : 0.018652
[12:01:54.741] iteration 23458 : model1 loss : 0.438092 model2 loss : 0.018555
[12:01:54.908] iteration 23459 : model1 loss : 0.440269 model2 loss : 0.022356
[12:01:55.077] iteration 23460 : model1 loss : 0.436292 model2 loss : 0.021169
[12:01:55.246] iteration 23461 : model1 loss : 0.439374 model2 loss : 0.019467
[12:01:55.413] iteration 23462 : model1 loss : 0.439354 model2 loss : 0.021480
[12:01:55.580] iteration 23463 : model1 loss : 0.435970 model2 loss : 0.020685
[12:01:57.528] iteration 23464 : model1 loss : 0.437744 model2 loss : 0.022128
[12:01:57.695] iteration 23465 : model1 loss : 0.438908 model2 loss : 0.019549
[12:01:57.865] iteration 23466 : model1 loss : 0.439777 model2 loss : 0.017993
[12:01:58.033] iteration 23467 : model1 loss : 0.441800 model2 loss : 0.020550
[12:01:58.201] iteration 23468 : model1 loss : 0.438652 model2 loss : 0.019094
[12:01:58.370] iteration 23469 : model1 loss : 0.439031 model2 loss : 0.021349
[12:01:58.540] iteration 23470 : model1 loss : 0.442098 model2 loss : 0.020196
[12:01:58.706] iteration 23471 : model1 loss : 0.440815 model2 loss : 0.020809
[12:01:58.877] iteration 23472 : model1 loss : 0.441452 model2 loss : 0.021256
[12:01:59.043] iteration 23473 : model1 loss : 0.437268 model2 loss : 0.019756
[12:01:59.212] iteration 23474 : model1 loss : 0.437303 model2 loss : 0.019416
[12:01:59.381] iteration 23475 : model1 loss : 0.441402 model2 loss : 0.022038
[12:01:59.549] iteration 23476 : model1 loss : 0.438576 model2 loss : 0.020213
[12:01:59.716] iteration 23477 : model1 loss : 0.436717 model2 loss : 0.019749
[12:01:59.886] iteration 23478 : model1 loss : 0.439285 model2 loss : 0.022789
[12:02:00.053] iteration 23479 : model1 loss : 0.437672 model2 loss : 0.021644
[12:02:00.223] iteration 23480 : model1 loss : 0.446678 model2 loss : 0.023294
[12:02:00.391] iteration 23481 : model1 loss : 0.445324 model2 loss : 0.022218
[12:02:00.561] iteration 23482 : model1 loss : 0.435692 model2 loss : 0.018632
[12:02:00.730] iteration 23483 : model1 loss : 0.436029 model2 loss : 0.018447
[12:02:00.905] iteration 23484 : model1 loss : 0.442035 model2 loss : 0.020867
[12:02:01.073] iteration 23485 : model1 loss : 0.443550 model2 loss : 0.021329
[12:02:01.242] iteration 23486 : model1 loss : 0.435083 model2 loss : 0.019484
[12:02:01.409] iteration 23487 : model1 loss : 0.441254 model2 loss : 0.021368
[12:02:01.578] iteration 23488 : model1 loss : 0.442761 model2 loss : 0.020689
[12:02:01.745] iteration 23489 : model1 loss : 0.434782 model2 loss : 0.020515
[12:02:01.915] iteration 23490 : model1 loss : 0.437558 model2 loss : 0.020923
[12:02:02.082] iteration 23491 : model1 loss : 0.435684 model2 loss : 0.021532
[12:02:02.251] iteration 23492 : model1 loss : 0.442456 model2 loss : 0.022338
[12:02:02.417] iteration 23493 : model1 loss : 0.439926 model2 loss : 0.020284
[12:02:02.588] iteration 23494 : model1 loss : 0.440312 model2 loss : 0.019527
[12:02:02.754] iteration 23495 : model1 loss : 0.437397 model2 loss : 0.022095
[12:02:02.923] iteration 23496 : model1 loss : 0.434454 model2 loss : 0.019406
[12:02:04.846] iteration 23497 : model1 loss : 0.440036 model2 loss : 0.019217
[12:02:05.019] iteration 23498 : model1 loss : 0.443971 model2 loss : 0.023279
[12:02:05.189] iteration 23499 : model1 loss : 0.438921 model2 loss : 0.019423
[12:02:05.357] iteration 23500 : model1 loss : 0.441005 model2 loss : 0.019719
[12:02:05.525] iteration 23501 : model1 loss : 0.436829 model2 loss : 0.020060
[12:02:05.695] iteration 23502 : model1 loss : 0.434602 model2 loss : 0.019926
[12:02:05.865] iteration 23503 : model1 loss : 0.440351 model2 loss : 0.020474
[12:02:06.032] iteration 23504 : model1 loss : 0.433569 model2 loss : 0.022469
[12:02:06.202] iteration 23505 : model1 loss : 0.441170 model2 loss : 0.021532
[12:02:06.368] iteration 23506 : model1 loss : 0.440639 model2 loss : 0.020902
[12:02:06.540] iteration 23507 : model1 loss : 0.439803 model2 loss : 0.018915
[12:02:06.707] iteration 23508 : model1 loss : 0.436200 model2 loss : 0.020010
[12:02:06.876] iteration 23509 : model1 loss : 0.436386 model2 loss : 0.019232
[12:02:07.041] iteration 23510 : model1 loss : 0.441449 model2 loss : 0.020056
[12:02:07.210] iteration 23511 : model1 loss : 0.440644 model2 loss : 0.020358
[12:02:07.377] iteration 23512 : model1 loss : 0.440612 model2 loss : 0.021811
[12:02:07.547] iteration 23513 : model1 loss : 0.435430 model2 loss : 0.020527
[12:02:07.713] iteration 23514 : model1 loss : 0.438830 model2 loss : 0.020370
[12:02:07.881] iteration 23515 : model1 loss : 0.438800 model2 loss : 0.022074
[12:02:08.049] iteration 23516 : model1 loss : 0.439049 model2 loss : 0.019383
[12:02:08.218] iteration 23517 : model1 loss : 0.437888 model2 loss : 0.018699
[12:02:08.385] iteration 23518 : model1 loss : 0.439728 model2 loss : 0.021324
[12:02:08.556] iteration 23519 : model1 loss : 0.442308 model2 loss : 0.021798
[12:02:08.724] iteration 23520 : model1 loss : 0.438176 model2 loss : 0.018590
[12:02:08.893] iteration 23521 : model1 loss : 0.435440 model2 loss : 0.020501
[12:02:09.058] iteration 23522 : model1 loss : 0.441199 model2 loss : 0.018847
[12:02:09.229] iteration 23523 : model1 loss : 0.440016 model2 loss : 0.017424
[12:02:09.397] iteration 23524 : model1 loss : 0.441018 model2 loss : 0.020814
[12:02:09.565] iteration 23525 : model1 loss : 0.442278 model2 loss : 0.020043
[12:02:09.734] iteration 23526 : model1 loss : 0.435676 model2 loss : 0.019632
[12:02:09.905] iteration 23527 : model1 loss : 0.441087 model2 loss : 0.023010
[12:02:10.070] iteration 23528 : model1 loss : 0.440023 model2 loss : 0.021448
[12:02:10.240] iteration 23529 : model1 loss : 0.442579 model2 loss : 0.020963
[12:02:12.165] iteration 23530 : model1 loss : 0.443118 model2 loss : 0.021887
[12:02:12.332] iteration 23531 : model1 loss : 0.435830 model2 loss : 0.018968
[12:02:12.506] iteration 23532 : model1 loss : 0.442203 model2 loss : 0.020160
[12:02:12.673] iteration 23533 : model1 loss : 0.438827 model2 loss : 0.021389
[12:02:12.842] iteration 23534 : model1 loss : 0.443572 model2 loss : 0.019562
[12:02:13.010] iteration 23535 : model1 loss : 0.437735 model2 loss : 0.018778
[12:02:13.179] iteration 23536 : model1 loss : 0.437529 model2 loss : 0.019136
[12:02:13.349] iteration 23537 : model1 loss : 0.440077 model2 loss : 0.020231
[12:02:13.520] iteration 23538 : model1 loss : 0.439147 model2 loss : 0.020353
[12:02:13.688] iteration 23539 : model1 loss : 0.438694 model2 loss : 0.021246
[12:02:13.859] iteration 23540 : model1 loss : 0.441696 model2 loss : 0.020250
[12:02:14.026] iteration 23541 : model1 loss : 0.439223 model2 loss : 0.019317
[12:02:14.195] iteration 23542 : model1 loss : 0.437029 model2 loss : 0.018806
[12:02:14.362] iteration 23543 : model1 loss : 0.437516 model2 loss : 0.018027
[12:02:14.534] iteration 23544 : model1 loss : 0.435727 model2 loss : 0.021214
[12:02:14.703] iteration 23545 : model1 loss : 0.438761 model2 loss : 0.021836
[12:02:14.873] iteration 23546 : model1 loss : 0.444610 model2 loss : 0.020833
[12:02:15.041] iteration 23547 : model1 loss : 0.438275 model2 loss : 0.021414
[12:02:15.212] iteration 23548 : model1 loss : 0.437618 model2 loss : 0.019661
[12:02:15.378] iteration 23549 : model1 loss : 0.438554 model2 loss : 0.021444
[12:02:15.548] iteration 23550 : model1 loss : 0.438852 model2 loss : 0.019903
[12:02:15.715] iteration 23551 : model1 loss : 0.442362 model2 loss : 0.020536
[12:02:15.887] iteration 23552 : model1 loss : 0.437971 model2 loss : 0.019205
[12:02:16.054] iteration 23553 : model1 loss : 0.441908 model2 loss : 0.019684
[12:02:16.224] iteration 23554 : model1 loss : 0.438224 model2 loss : 0.020875
[12:02:16.392] iteration 23555 : model1 loss : 0.440856 model2 loss : 0.021407
[12:02:16.563] iteration 23556 : model1 loss : 0.440533 model2 loss : 0.021442
[12:02:16.732] iteration 23557 : model1 loss : 0.441993 model2 loss : 0.021546
[12:02:16.901] iteration 23558 : model1 loss : 0.435318 model2 loss : 0.021524
[12:02:17.067] iteration 23559 : model1 loss : 0.441477 model2 loss : 0.021566
[12:02:17.240] iteration 23560 : model1 loss : 0.435494 model2 loss : 0.019928
[12:02:17.405] iteration 23561 : model1 loss : 0.440144 model2 loss : 0.022675
[12:02:17.574] iteration 23562 : model1 loss : 0.435100 model2 loss : 0.020139
[12:02:19.480] iteration 23563 : model1 loss : 0.442552 model2 loss : 0.020647
[12:02:19.648] iteration 23564 : model1 loss : 0.437269 model2 loss : 0.019321
[12:02:19.818] iteration 23565 : model1 loss : 0.433467 model2 loss : 0.020668
[12:02:19.984] iteration 23566 : model1 loss : 0.437197 model2 loss : 0.020012
[12:02:20.156] iteration 23567 : model1 loss : 0.441790 model2 loss : 0.025804
[12:02:20.322] iteration 23568 : model1 loss : 0.442650 model2 loss : 0.019436
[12:02:20.491] iteration 23569 : model1 loss : 0.439258 model2 loss : 0.021841
[12:02:20.659] iteration 23570 : model1 loss : 0.440689 model2 loss : 0.021172
[12:02:20.830] iteration 23571 : model1 loss : 0.444653 model2 loss : 0.023017
[12:02:21.001] iteration 23572 : model1 loss : 0.439516 model2 loss : 0.019962
[12:02:21.170] iteration 23573 : model1 loss : 0.442739 model2 loss : 0.021758
[12:02:21.336] iteration 23574 : model1 loss : 0.437551 model2 loss : 0.021397
[12:02:21.507] iteration 23575 : model1 loss : 0.439179 model2 loss : 0.019545
[12:02:21.673] iteration 23576 : model1 loss : 0.437474 model2 loss : 0.018517
[12:02:21.842] iteration 23577 : model1 loss : 0.439642 model2 loss : 0.021225
[12:02:22.010] iteration 23578 : model1 loss : 0.440236 model2 loss : 0.023764
[12:02:22.177] iteration 23579 : model1 loss : 0.442184 model2 loss : 0.020274
[12:02:22.347] iteration 23580 : model1 loss : 0.438343 model2 loss : 0.020914
[12:02:22.518] iteration 23581 : model1 loss : 0.440130 model2 loss : 0.018908
[12:02:22.686] iteration 23582 : model1 loss : 0.439508 model2 loss : 0.017427
[12:02:22.856] iteration 23583 : model1 loss : 0.443801 model2 loss : 0.021492
[12:02:23.025] iteration 23584 : model1 loss : 0.437929 model2 loss : 0.020303
[12:02:23.194] iteration 23585 : model1 loss : 0.439037 model2 loss : 0.020872
[12:02:23.362] iteration 23586 : model1 loss : 0.437755 model2 loss : 0.018177
[12:02:23.541] iteration 23587 : model1 loss : 0.440652 model2 loss : 0.021253
[12:02:23.709] iteration 23588 : model1 loss : 0.439082 model2 loss : 0.020475
[12:02:23.882] iteration 23589 : model1 loss : 0.438168 model2 loss : 0.020682
[12:02:24.049] iteration 23590 : model1 loss : 0.442299 model2 loss : 0.021725
[12:02:24.220] iteration 23591 : model1 loss : 0.441565 model2 loss : 0.023162
[12:02:24.388] iteration 23592 : model1 loss : 0.437206 model2 loss : 0.019812
[12:02:24.557] iteration 23593 : model1 loss : 0.434290 model2 loss : 0.018453
[12:02:24.723] iteration 23594 : model1 loss : 0.434692 model2 loss : 0.018635
[12:02:24.892] iteration 23595 : model1 loss : 0.436712 model2 loss : 0.019810
[12:02:26.815] iteration 23596 : model1 loss : 0.437158 model2 loss : 0.020848
[12:02:26.984] iteration 23597 : model1 loss : 0.436911 model2 loss : 0.019870
[12:02:27.155] iteration 23598 : model1 loss : 0.441565 model2 loss : 0.021494
[12:02:27.322] iteration 23599 : model1 loss : 0.440346 model2 loss : 0.017253
[12:02:27.493] iteration 23600 : model1 loss : 0.439548 model2 loss : 0.021524
[12:02:27.660] iteration 23601 : model1 loss : 0.440629 model2 loss : 0.022302
[12:02:27.830] iteration 23602 : model1 loss : 0.435487 model2 loss : 0.020375
[12:02:27.997] iteration 23603 : model1 loss : 0.440486 model2 loss : 0.021279
[12:02:28.165] iteration 23604 : model1 loss : 0.443472 model2 loss : 0.023155
[12:02:28.331] iteration 23605 : model1 loss : 0.446549 model2 loss : 0.023742
[12:02:28.501] iteration 23606 : model1 loss : 0.441470 model2 loss : 0.022690
[12:02:28.668] iteration 23607 : model1 loss : 0.440563 model2 loss : 0.022099
[12:02:28.839] iteration 23608 : model1 loss : 0.436260 model2 loss : 0.018522
[12:02:29.008] iteration 23609 : model1 loss : 0.435622 model2 loss : 0.017700
[12:02:29.177] iteration 23610 : model1 loss : 0.441276 model2 loss : 0.019954
[12:02:29.343] iteration 23611 : model1 loss : 0.436244 model2 loss : 0.020055
[12:02:29.515] iteration 23612 : model1 loss : 0.441347 model2 loss : 0.020205
[12:02:29.683] iteration 23613 : model1 loss : 0.442148 model2 loss : 0.019569
[12:02:29.853] iteration 23614 : model1 loss : 0.441612 model2 loss : 0.020154
[12:02:30.026] iteration 23615 : model1 loss : 0.441264 model2 loss : 0.020160
[12:02:30.197] iteration 23616 : model1 loss : 0.438849 model2 loss : 0.021484
[12:02:30.364] iteration 23617 : model1 loss : 0.438707 model2 loss : 0.020496
[12:02:30.535] iteration 23618 : model1 loss : 0.441824 model2 loss : 0.021280
[12:02:30.703] iteration 23619 : model1 loss : 0.439051 model2 loss : 0.021536
[12:02:30.873] iteration 23620 : model1 loss : 0.438246 model2 loss : 0.020529
[12:02:31.042] iteration 23621 : model1 loss : 0.434054 model2 loss : 0.018517
[12:02:31.216] iteration 23622 : model1 loss : 0.442124 model2 loss : 0.020998
[12:02:31.383] iteration 23623 : model1 loss : 0.437253 model2 loss : 0.020356
[12:02:31.553] iteration 23624 : model1 loss : 0.435500 model2 loss : 0.019647
[12:02:31.721] iteration 23625 : model1 loss : 0.438138 model2 loss : 0.018471
[12:02:31.889] iteration 23626 : model1 loss : 0.438678 model2 loss : 0.021154
[12:02:32.053] iteration 23627 : model1 loss : 0.437524 model2 loss : 0.019836
[12:02:32.221] iteration 23628 : model1 loss : 0.436777 model2 loss : 0.018433
[12:02:34.123] iteration 23629 : model1 loss : 0.439360 model2 loss : 0.021396
[12:02:34.289] iteration 23630 : model1 loss : 0.438417 model2 loss : 0.018434
[12:02:34.460] iteration 23631 : model1 loss : 0.443251 model2 loss : 0.023775
[12:02:34.626] iteration 23632 : model1 loss : 0.436873 model2 loss : 0.020216
[12:02:34.795] iteration 23633 : model1 loss : 0.437831 model2 loss : 0.019424
[12:02:34.963] iteration 23634 : model1 loss : 0.436958 model2 loss : 0.020697
[12:02:35.131] iteration 23635 : model1 loss : 0.440478 model2 loss : 0.018984
[12:02:35.302] iteration 23636 : model1 loss : 0.438556 model2 loss : 0.020379
[12:02:35.470] iteration 23637 : model1 loss : 0.438661 model2 loss : 0.021801
[12:02:35.640] iteration 23638 : model1 loss : 0.443051 model2 loss : 0.022466
[12:02:35.810] iteration 23639 : model1 loss : 0.438031 model2 loss : 0.020699
[12:02:35.978] iteration 23640 : model1 loss : 0.438548 model2 loss : 0.020339
[12:02:36.147] iteration 23641 : model1 loss : 0.435982 model2 loss : 0.020836
[12:02:36.316] iteration 23642 : model1 loss : 0.438636 model2 loss : 0.020325
[12:02:36.486] iteration 23643 : model1 loss : 0.438812 model2 loss : 0.019731
[12:02:36.654] iteration 23644 : model1 loss : 0.437127 model2 loss : 0.018518
[12:02:36.824] iteration 23645 : model1 loss : 0.439242 model2 loss : 0.019630
[12:02:36.991] iteration 23646 : model1 loss : 0.439921 model2 loss : 0.019549
[12:02:37.159] iteration 23647 : model1 loss : 0.438469 model2 loss : 0.020460
[12:02:37.327] iteration 23648 : model1 loss : 0.438860 model2 loss : 0.018877
[12:02:37.503] iteration 23649 : model1 loss : 0.438868 model2 loss : 0.021006
[12:02:37.670] iteration 23650 : model1 loss : 0.439099 model2 loss : 0.019768
[12:02:37.839] iteration 23651 : model1 loss : 0.440634 model2 loss : 0.019277
[12:02:38.007] iteration 23652 : model1 loss : 0.440981 model2 loss : 0.021289
[12:02:38.176] iteration 23653 : model1 loss : 0.436677 model2 loss : 0.018452
[12:02:38.343] iteration 23654 : model1 loss : 0.438043 model2 loss : 0.021045
[12:02:38.515] iteration 23655 : model1 loss : 0.440550 model2 loss : 0.019243
[12:02:38.683] iteration 23656 : model1 loss : 0.442881 model2 loss : 0.021213
[12:02:38.851] iteration 23657 : model1 loss : 0.445708 model2 loss : 0.022052
[12:02:39.022] iteration 23658 : model1 loss : 0.442475 model2 loss : 0.019859
[12:02:39.194] iteration 23659 : model1 loss : 0.439657 model2 loss : 0.018343
[12:02:39.363] iteration 23660 : model1 loss : 0.439529 model2 loss : 0.018422
[12:02:39.533] iteration 23661 : model1 loss : 0.439985 model2 loss : 0.018885
[12:02:41.450] iteration 23662 : model1 loss : 0.441408 model2 loss : 0.026274
[12:02:41.620] iteration 23663 : model1 loss : 0.442396 model2 loss : 0.022749
[12:02:41.790] iteration 23664 : model1 loss : 0.441645 model2 loss : 0.024911
[12:02:41.956] iteration 23665 : model1 loss : 0.437663 model2 loss : 0.020590
[12:02:42.124] iteration 23666 : model1 loss : 0.445526 model2 loss : 0.024089
[12:02:42.292] iteration 23667 : model1 loss : 0.440015 model2 loss : 0.019836
[12:02:42.462] iteration 23668 : model1 loss : 0.440135 model2 loss : 0.021452
[12:02:42.631] iteration 23669 : model1 loss : 0.438509 model2 loss : 0.019316
[12:02:42.800] iteration 23670 : model1 loss : 0.440252 model2 loss : 0.020348
[12:02:42.967] iteration 23671 : model1 loss : 0.437005 model2 loss : 0.019951
[12:02:43.138] iteration 23672 : model1 loss : 0.443459 model2 loss : 0.020664
[12:02:43.306] iteration 23673 : model1 loss : 0.435043 model2 loss : 0.021446
[12:02:43.475] iteration 23674 : model1 loss : 0.432159 model2 loss : 0.021475
[12:02:43.643] iteration 23675 : model1 loss : 0.436035 model2 loss : 0.019841
[12:02:43.813] iteration 23676 : model1 loss : 0.437447 model2 loss : 0.018379
[12:02:43.979] iteration 23677 : model1 loss : 0.439806 model2 loss : 0.021298
[12:02:44.148] iteration 23678 : model1 loss : 0.445439 model2 loss : 0.022906
[12:02:44.315] iteration 23679 : model1 loss : 0.440522 model2 loss : 0.019734
[12:02:44.485] iteration 23680 : model1 loss : 0.441080 model2 loss : 0.018120
[12:02:44.652] iteration 23681 : model1 loss : 0.440403 model2 loss : 0.017229
[12:02:44.822] iteration 23682 : model1 loss : 0.440989 model2 loss : 0.019375
[12:02:44.989] iteration 23683 : model1 loss : 0.435635 model2 loss : 0.021673
[12:02:45.158] iteration 23684 : model1 loss : 0.436063 model2 loss : 0.018442
[12:02:45.325] iteration 23685 : model1 loss : 0.443957 model2 loss : 0.026125
[12:02:45.496] iteration 23686 : model1 loss : 0.441451 model2 loss : 0.022232
[12:02:45.663] iteration 23687 : model1 loss : 0.436113 model2 loss : 0.020719
[12:02:45.833] iteration 23688 : model1 loss : 0.441723 model2 loss : 0.020844
[12:02:46.002] iteration 23689 : model1 loss : 0.442239 model2 loss : 0.018379
[12:02:46.170] iteration 23690 : model1 loss : 0.438605 model2 loss : 0.020239
[12:02:46.339] iteration 23691 : model1 loss : 0.433517 model2 loss : 0.019011
[12:02:46.509] iteration 23692 : model1 loss : 0.441631 model2 loss : 0.022476
[12:02:46.675] iteration 23693 : model1 loss : 0.437197 model2 loss : 0.017174
[12:02:46.843] iteration 23694 : model1 loss : 0.440496 model2 loss : 0.021943
[12:02:48.751] iteration 23695 : model1 loss : 0.439858 model2 loss : 0.020879
[12:02:48.919] iteration 23696 : model1 loss : 0.442777 model2 loss : 0.019166
[12:02:49.087] iteration 23697 : model1 loss : 0.434330 model2 loss : 0.018832
[12:02:49.254] iteration 23698 : model1 loss : 0.443999 model2 loss : 0.021954
[12:02:49.422] iteration 23699 : model1 loss : 0.439838 model2 loss : 0.021248
[12:02:49.589] iteration 23700 : model1 loss : 0.438092 model2 loss : 0.020391
[12:02:49.757] iteration 23701 : model1 loss : 0.438406 model2 loss : 0.021153
[12:02:49.925] iteration 23702 : model1 loss : 0.445359 model2 loss : 0.023074
[12:02:50.097] iteration 23703 : model1 loss : 0.440691 model2 loss : 0.019793
[12:02:50.265] iteration 23704 : model1 loss : 0.438641 model2 loss : 0.019852
[12:02:50.434] iteration 23705 : model1 loss : 0.438167 model2 loss : 0.018409
[12:02:50.602] iteration 23706 : model1 loss : 0.437469 model2 loss : 0.020025
[12:02:50.772] iteration 23707 : model1 loss : 0.441359 model2 loss : 0.020449
[12:02:50.957] iteration 23708 : model1 loss : 0.439900 model2 loss : 0.020638
[12:02:51.130] iteration 23709 : model1 loss : 0.443131 model2 loss : 0.021699
[12:02:51.297] iteration 23710 : model1 loss : 0.440214 model2 loss : 0.020504
[12:02:51.467] iteration 23711 : model1 loss : 0.440490 model2 loss : 0.020659
[12:02:51.634] iteration 23712 : model1 loss : 0.442145 model2 loss : 0.021958
[12:02:51.803] iteration 23713 : model1 loss : 0.443734 model2 loss : 0.022016
[12:02:51.970] iteration 23714 : model1 loss : 0.437509 model2 loss : 0.019360
[12:02:52.139] iteration 23715 : model1 loss : 0.437146 model2 loss : 0.018574
[12:02:52.306] iteration 23716 : model1 loss : 0.441551 model2 loss : 0.020062
[12:02:52.475] iteration 23717 : model1 loss : 0.441177 model2 loss : 0.021024
[12:02:52.642] iteration 23718 : model1 loss : 0.438135 model2 loss : 0.021564
[12:02:52.813] iteration 23719 : model1 loss : 0.439396 model2 loss : 0.017602
[12:02:52.978] iteration 23720 : model1 loss : 0.438280 model2 loss : 0.021380
[12:02:53.147] iteration 23721 : model1 loss : 0.437011 model2 loss : 0.019913
[12:02:53.313] iteration 23722 : model1 loss : 0.441000 model2 loss : 0.022378
[12:02:53.484] iteration 23723 : model1 loss : 0.437789 model2 loss : 0.019173
[12:02:53.650] iteration 23724 : model1 loss : 0.439993 model2 loss : 0.020461
[12:02:53.822] iteration 23725 : model1 loss : 0.436041 model2 loss : 0.019108
[12:02:53.987] iteration 23726 : model1 loss : 0.435414 model2 loss : 0.018721
[12:02:54.155] iteration 23727 : model1 loss : 0.434409 model2 loss : 0.019490
[12:02:56.072] iteration 23728 : model1 loss : 0.433914 model2 loss : 0.018244
[12:02:56.238] iteration 23729 : model1 loss : 0.441097 model2 loss : 0.021246
[12:02:56.408] iteration 23730 : model1 loss : 0.438985 model2 loss : 0.019604
[12:02:56.575] iteration 23731 : model1 loss : 0.440801 model2 loss : 0.020057
[12:02:56.743] iteration 23732 : model1 loss : 0.440456 model2 loss : 0.020526
[12:02:56.910] iteration 23733 : model1 loss : 0.438663 model2 loss : 0.021315
[12:02:57.083] iteration 23734 : model1 loss : 0.441158 model2 loss : 0.019621
[12:02:57.250] iteration 23735 : model1 loss : 0.434363 model2 loss : 0.019850
[12:02:57.419] iteration 23736 : model1 loss : 0.442921 model2 loss : 0.021477
[12:02:57.585] iteration 23737 : model1 loss : 0.435067 model2 loss : 0.019333
[12:02:57.755] iteration 23738 : model1 loss : 0.439529 model2 loss : 0.021223
[12:02:57.921] iteration 23739 : model1 loss : 0.441248 model2 loss : 0.020478
[12:02:58.094] iteration 23740 : model1 loss : 0.439932 model2 loss : 0.021272
[12:02:58.273] iteration 23741 : model1 loss : 0.438597 model2 loss : 0.021587
[12:02:58.443] iteration 23742 : model1 loss : 0.441078 model2 loss : 0.022250
[12:02:58.611] iteration 23743 : model1 loss : 0.438260 model2 loss : 0.020205
[12:02:58.780] iteration 23744 : model1 loss : 0.441847 model2 loss : 0.018572
[12:02:58.947] iteration 23745 : model1 loss : 0.438852 model2 loss : 0.019381
[12:02:59.119] iteration 23746 : model1 loss : 0.439284 model2 loss : 0.020712
[12:02:59.286] iteration 23747 : model1 loss : 0.432955 model2 loss : 0.019453
[12:02:59.454] iteration 23748 : model1 loss : 0.435786 model2 loss : 0.020190
[12:02:59.621] iteration 23749 : model1 loss : 0.440207 model2 loss : 0.020946
[12:02:59.790] iteration 23750 : model1 loss : 0.441446 model2 loss : 0.022220
[12:02:59.958] iteration 23751 : model1 loss : 0.438699 model2 loss : 0.019308
[12:03:00.131] iteration 23752 : model1 loss : 0.440244 model2 loss : 0.018552
[12:03:00.299] iteration 23753 : model1 loss : 0.442557 model2 loss : 0.021368
[12:03:00.468] iteration 23754 : model1 loss : 0.441236 model2 loss : 0.020858
[12:03:00.635] iteration 23755 : model1 loss : 0.441267 model2 loss : 0.023550
[12:03:00.805] iteration 23756 : model1 loss : 0.441036 model2 loss : 0.020628
[12:03:00.974] iteration 23757 : model1 loss : 0.439234 model2 loss : 0.018966
[12:03:01.144] iteration 23758 : model1 loss : 0.441982 model2 loss : 0.020984
[12:03:01.311] iteration 23759 : model1 loss : 0.436850 model2 loss : 0.019385
[12:03:01.479] iteration 23760 : model1 loss : 0.444253 model2 loss : 0.018818
[12:03:03.381] iteration 23761 : model1 loss : 0.433807 model2 loss : 0.019916
[12:03:03.554] iteration 23762 : model1 loss : 0.444201 model2 loss : 0.019505
[12:03:03.725] iteration 23763 : model1 loss : 0.438387 model2 loss : 0.020160
[12:03:03.893] iteration 23764 : model1 loss : 0.437426 model2 loss : 0.020153
[12:03:04.063] iteration 23765 : model1 loss : 0.433218 model2 loss : 0.019502
[12:03:04.229] iteration 23766 : model1 loss : 0.441812 model2 loss : 0.021686
[12:03:04.399] iteration 23767 : model1 loss : 0.441032 model2 loss : 0.018425
[12:03:04.566] iteration 23768 : model1 loss : 0.439986 model2 loss : 0.019250
[12:03:04.737] iteration 23769 : model1 loss : 0.441789 model2 loss : 0.019105
[12:03:04.905] iteration 23770 : model1 loss : 0.435407 model2 loss : 0.019771
[12:03:05.076] iteration 23771 : model1 loss : 0.440249 model2 loss : 0.022447
[12:03:05.243] iteration 23772 : model1 loss : 0.440001 model2 loss : 0.019420
[12:03:05.414] iteration 23773 : model1 loss : 0.439212 model2 loss : 0.019825
[12:03:05.580] iteration 23774 : model1 loss : 0.440146 model2 loss : 0.019815
[12:03:05.751] iteration 23775 : model1 loss : 0.439993 model2 loss : 0.018676
[12:03:05.922] iteration 23776 : model1 loss : 0.442354 model2 loss : 0.020834
[12:03:06.092] iteration 23777 : model1 loss : 0.435068 model2 loss : 0.020327
[12:03:06.260] iteration 23778 : model1 loss : 0.438860 model2 loss : 0.019018
[12:03:06.430] iteration 23779 : model1 loss : 0.439326 model2 loss : 0.020276
[12:03:06.597] iteration 23780 : model1 loss : 0.437059 model2 loss : 0.019853
[12:03:06.767] iteration 23781 : model1 loss : 0.434162 model2 loss : 0.020380
[12:03:06.935] iteration 23782 : model1 loss : 0.441966 model2 loss : 0.020256
[12:03:07.104] iteration 23783 : model1 loss : 0.440812 model2 loss : 0.021943
[12:03:07.271] iteration 23784 : model1 loss : 0.446146 model2 loss : 0.022789
[12:03:07.441] iteration 23785 : model1 loss : 0.438448 model2 loss : 0.021652
[12:03:07.608] iteration 23786 : model1 loss : 0.444902 model2 loss : 0.019595
[12:03:07.777] iteration 23787 : model1 loss : 0.439773 model2 loss : 0.017802
[12:03:07.946] iteration 23788 : model1 loss : 0.439272 model2 loss : 0.020088
[12:03:08.120] iteration 23789 : model1 loss : 0.436655 model2 loss : 0.018808
[12:03:08.289] iteration 23790 : model1 loss : 0.442045 model2 loss : 0.023401
[12:03:08.458] iteration 23791 : model1 loss : 0.441261 model2 loss : 0.019691
[12:03:08.624] iteration 23792 : model1 loss : 0.436632 model2 loss : 0.020233
[12:03:08.793] iteration 23793 : model1 loss : 0.438416 model2 loss : 0.020833
[12:03:10.697] iteration 23794 : model1 loss : 0.433694 model2 loss : 0.017500
[12:03:10.865] iteration 23795 : model1 loss : 0.441767 model2 loss : 0.022438
[12:03:11.036] iteration 23796 : model1 loss : 0.437835 model2 loss : 0.020310
[12:03:11.203] iteration 23797 : model1 loss : 0.441813 model2 loss : 0.019223
[12:03:11.374] iteration 23798 : model1 loss : 0.436180 model2 loss : 0.018060
[12:03:11.542] iteration 23799 : model1 loss : 0.440934 model2 loss : 0.021305
[12:03:11.710] iteration 23800 : model1 loss : 0.442436 model2 loss : 0.020053
[12:03:11.878] iteration 23801 : model1 loss : 0.442573 model2 loss : 0.018540
[12:03:12.048] iteration 23802 : model1 loss : 0.437627 model2 loss : 0.019782
[12:03:12.215] iteration 23803 : model1 loss : 0.436819 model2 loss : 0.021480
[12:03:12.384] iteration 23804 : model1 loss : 0.443499 model2 loss : 0.023444
[12:03:12.552] iteration 23805 : model1 loss : 0.437572 model2 loss : 0.017889
[12:03:12.722] iteration 23806 : model1 loss : 0.440351 model2 loss : 0.019931
[12:03:12.888] iteration 23807 : model1 loss : 0.438909 model2 loss : 0.020565
[12:03:13.058] iteration 23808 : model1 loss : 0.436011 model2 loss : 0.019108
[12:03:13.226] iteration 23809 : model1 loss : 0.439265 model2 loss : 0.017896
[12:03:13.395] iteration 23810 : model1 loss : 0.437710 model2 loss : 0.019853
[12:03:13.563] iteration 23811 : model1 loss : 0.439399 model2 loss : 0.021297
[12:03:13.732] iteration 23812 : model1 loss : 0.439473 model2 loss : 0.023999
[12:03:13.898] iteration 23813 : model1 loss : 0.437463 model2 loss : 0.021117
[12:03:14.066] iteration 23814 : model1 loss : 0.440798 model2 loss : 0.021874
[12:03:14.234] iteration 23815 : model1 loss : 0.441670 model2 loss : 0.017588
[12:03:14.403] iteration 23816 : model1 loss : 0.433943 model2 loss : 0.019605
[12:03:14.571] iteration 23817 : model1 loss : 0.438702 model2 loss : 0.018937
[12:03:14.743] iteration 23818 : model1 loss : 0.441056 model2 loss : 0.019996
[12:03:14.911] iteration 23819 : model1 loss : 0.438177 model2 loss : 0.018108
[12:03:15.080] iteration 23820 : model1 loss : 0.441457 model2 loss : 0.022340
[12:03:15.246] iteration 23821 : model1 loss : 0.443062 model2 loss : 0.021770
[12:03:15.417] iteration 23822 : model1 loss : 0.436992 model2 loss : 0.019637
[12:03:15.586] iteration 23823 : model1 loss : 0.440152 model2 loss : 0.020090
[12:03:15.755] iteration 23824 : model1 loss : 0.443514 model2 loss : 0.020909
[12:03:15.926] iteration 23825 : model1 loss : 0.438249 model2 loss : 0.017899
[12:03:16.095] iteration 23826 : model1 loss : 0.440344 model2 loss : 0.021204
[12:03:17.996] iteration 23827 : model1 loss : 0.437373 model2 loss : 0.020034
[12:03:18.164] iteration 23828 : model1 loss : 0.438253 model2 loss : 0.017039
[12:03:18.336] iteration 23829 : model1 loss : 0.439279 model2 loss : 0.020034
[12:03:18.505] iteration 23830 : model1 loss : 0.439787 model2 loss : 0.020529
[12:03:18.675] iteration 23831 : model1 loss : 0.440164 model2 loss : 0.019593
[12:03:18.844] iteration 23832 : model1 loss : 0.443387 model2 loss : 0.021983
[12:03:19.015] iteration 23833 : model1 loss : 0.438865 model2 loss : 0.020099
[12:03:19.184] iteration 23834 : model1 loss : 0.434209 model2 loss : 0.019347
[12:03:19.354] iteration 23835 : model1 loss : 0.441524 model2 loss : 0.020660
[12:03:19.523] iteration 23836 : model1 loss : 0.438319 model2 loss : 0.022550
[12:03:19.693] iteration 23837 : model1 loss : 0.442411 model2 loss : 0.020001
[12:03:19.860] iteration 23838 : model1 loss : 0.432315 model2 loss : 0.018575
[12:03:20.029] iteration 23839 : model1 loss : 0.441510 model2 loss : 0.019057
[12:03:20.197] iteration 23840 : model1 loss : 0.439830 model2 loss : 0.019067
[12:03:20.369] iteration 23841 : model1 loss : 0.442636 model2 loss : 0.021918
[12:03:20.537] iteration 23842 : model1 loss : 0.441107 model2 loss : 0.021113
[12:03:20.707] iteration 23843 : model1 loss : 0.444219 model2 loss : 0.023174
[12:03:20.878] iteration 23844 : model1 loss : 0.441818 model2 loss : 0.023647
[12:03:21.046] iteration 23845 : model1 loss : 0.440527 model2 loss : 0.021442
[12:03:21.214] iteration 23846 : model1 loss : 0.440870 model2 loss : 0.022753
[12:03:21.381] iteration 23847 : model1 loss : 0.437151 model2 loss : 0.022935
[12:03:21.547] iteration 23848 : model1 loss : 0.440145 model2 loss : 0.019559
[12:03:21.716] iteration 23849 : model1 loss : 0.438348 model2 loss : 0.018235
[12:03:21.886] iteration 23850 : model1 loss : 0.440107 model2 loss : 0.021837
[12:03:22.056] iteration 23851 : model1 loss : 0.439999 model2 loss : 0.019582
[12:03:22.225] iteration 23852 : model1 loss : 0.436535 model2 loss : 0.018885
[12:03:22.393] iteration 23853 : model1 loss : 0.440000 model2 loss : 0.022277
[12:03:22.563] iteration 23854 : model1 loss : 0.441653 model2 loss : 0.021398
[12:03:22.732] iteration 23855 : model1 loss : 0.434321 model2 loss : 0.021300
[12:03:22.898] iteration 23856 : model1 loss : 0.440090 model2 loss : 0.023552
[12:03:23.069] iteration 23857 : model1 loss : 0.432337 model2 loss : 0.020153
[12:03:23.235] iteration 23858 : model1 loss : 0.440002 model2 loss : 0.024397
[12:03:23.404] iteration 23859 : model1 loss : 0.444748 model2 loss : 0.020962
[12:03:25.339] iteration 23860 : model1 loss : 0.434310 model2 loss : 0.018014
[12:03:25.513] iteration 23861 : model1 loss : 0.441236 model2 loss : 0.023137
[12:03:25.684] iteration 23862 : model1 loss : 0.445299 model2 loss : 0.023494
[12:03:25.853] iteration 23863 : model1 loss : 0.437321 model2 loss : 0.020050
[12:03:26.022] iteration 23864 : model1 loss : 0.435958 model2 loss : 0.017957
[12:03:26.191] iteration 23865 : model1 loss : 0.440780 model2 loss : 0.020524
[12:03:26.360] iteration 23866 : model1 loss : 0.437889 model2 loss : 0.018214
[12:03:26.529] iteration 23867 : model1 loss : 0.441215 model2 loss : 0.021132
[12:03:26.698] iteration 23868 : model1 loss : 0.442072 model2 loss : 0.020452
[12:03:26.866] iteration 23869 : model1 loss : 0.440887 model2 loss : 0.018928
[12:03:27.037] iteration 23870 : model1 loss : 0.438394 model2 loss : 0.019624
[12:03:27.207] iteration 23871 : model1 loss : 0.439015 model2 loss : 0.021606
[12:03:27.375] iteration 23872 : model1 loss : 0.435947 model2 loss : 0.021530
[12:03:27.547] iteration 23873 : model1 loss : 0.442590 model2 loss : 0.022017
[12:03:27.716] iteration 23874 : model1 loss : 0.441133 model2 loss : 0.022601
[12:03:27.885] iteration 23875 : model1 loss : 0.439144 model2 loss : 0.021158
[12:03:28.056] iteration 23876 : model1 loss : 0.435762 model2 loss : 0.019426
[12:03:28.225] iteration 23877 : model1 loss : 0.443313 model2 loss : 0.020032
[12:03:28.393] iteration 23878 : model1 loss : 0.444497 model2 loss : 0.022472
[12:03:28.559] iteration 23879 : model1 loss : 0.440077 model2 loss : 0.021478
[12:03:28.728] iteration 23880 : model1 loss : 0.442101 model2 loss : 0.019802
[12:03:28.897] iteration 23881 : model1 loss : 0.434535 model2 loss : 0.017828
[12:03:29.068] iteration 23882 : model1 loss : 0.442449 model2 loss : 0.021203
[12:03:29.235] iteration 23883 : model1 loss : 0.439932 model2 loss : 0.020355
[12:03:29.405] iteration 23884 : model1 loss : 0.442874 model2 loss : 0.022150
[12:03:29.570] iteration 23885 : model1 loss : 0.437468 model2 loss : 0.020231
[12:03:29.741] iteration 23886 : model1 loss : 0.438760 model2 loss : 0.018409
[12:03:29.908] iteration 23887 : model1 loss : 0.444754 model2 loss : 0.022607
[12:03:30.078] iteration 23888 : model1 loss : 0.436791 model2 loss : 0.019741
[12:03:30.246] iteration 23889 : model1 loss : 0.438053 model2 loss : 0.020649
[12:03:30.415] iteration 23890 : model1 loss : 0.438324 model2 loss : 0.019093
[12:03:30.582] iteration 23891 : model1 loss : 0.438585 model2 loss : 0.020597
[12:03:30.749] iteration 23892 : model1 loss : 0.433547 model2 loss : 0.019412
[12:03:32.694] iteration 23893 : model1 loss : 0.435036 model2 loss : 0.019790
[12:03:32.864] iteration 23894 : model1 loss : 0.442396 model2 loss : 0.021394
[12:03:33.034] iteration 23895 : model1 loss : 0.443501 model2 loss : 0.020761
[12:03:33.201] iteration 23896 : model1 loss : 0.439307 model2 loss : 0.020599
[12:03:33.373] iteration 23897 : model1 loss : 0.437157 model2 loss : 0.019367
[12:03:33.541] iteration 23898 : model1 loss : 0.439799 model2 loss : 0.020773
[12:03:33.710] iteration 23899 : model1 loss : 0.434860 model2 loss : 0.018757
[12:03:33.878] iteration 23900 : model1 loss : 0.439103 model2 loss : 0.018441
[12:03:34.049] iteration 23901 : model1 loss : 0.435857 model2 loss : 0.019204
[12:03:34.224] iteration 23902 : model1 loss : 0.435757 model2 loss : 0.019083
[12:03:34.395] iteration 23903 : model1 loss : 0.436502 model2 loss : 0.019733
[12:03:34.563] iteration 23904 : model1 loss : 0.435898 model2 loss : 0.019474
[12:03:34.733] iteration 23905 : model1 loss : 0.443879 model2 loss : 0.022454
[12:03:34.902] iteration 23906 : model1 loss : 0.438678 model2 loss : 0.020936
[12:03:35.072] iteration 23907 : model1 loss : 0.442368 model2 loss : 0.018135
[12:03:35.239] iteration 23908 : model1 loss : 0.442887 model2 loss : 0.021651
[12:03:35.416] iteration 23909 : model1 loss : 0.439864 model2 loss : 0.019943
[12:03:35.584] iteration 23910 : model1 loss : 0.440375 model2 loss : 0.021084
[12:03:35.752] iteration 23911 : model1 loss : 0.435843 model2 loss : 0.018372
[12:03:35.923] iteration 23912 : model1 loss : 0.444017 model2 loss : 0.020771
[12:03:36.092] iteration 23913 : model1 loss : 0.442756 model2 loss : 0.021696
[12:03:36.260] iteration 23914 : model1 loss : 0.441905 model2 loss : 0.022668
[12:03:36.431] iteration 23915 : model1 loss : 0.443323 model2 loss : 0.020515
[12:03:36.598] iteration 23916 : model1 loss : 0.435361 model2 loss : 0.020536
[12:03:36.767] iteration 23917 : model1 loss : 0.442143 model2 loss : 0.020998
[12:03:36.934] iteration 23918 : model1 loss : 0.441384 model2 loss : 0.019802
[12:03:37.104] iteration 23919 : model1 loss : 0.441905 model2 loss : 0.022226
[12:03:37.272] iteration 23920 : model1 loss : 0.434665 model2 loss : 0.020141
[12:03:37.443] iteration 23921 : model1 loss : 0.442438 model2 loss : 0.023819
[12:03:37.611] iteration 23922 : model1 loss : 0.436287 model2 loss : 0.016884
[12:03:37.780] iteration 23923 : model1 loss : 0.436125 model2 loss : 0.019085
[12:03:37.946] iteration 23924 : model1 loss : 0.441139 model2 loss : 0.021198
[12:03:38.114] iteration 23925 : model1 loss : 0.439732 model2 loss : 0.020337
[12:03:40.026] iteration 23926 : model1 loss : 0.440475 model2 loss : 0.021352
[12:03:40.194] iteration 23927 : model1 loss : 0.439898 model2 loss : 0.021211
[12:03:40.365] iteration 23928 : model1 loss : 0.441599 model2 loss : 0.021389
[12:03:40.537] iteration 23929 : model1 loss : 0.438180 model2 loss : 0.020243
[12:03:40.706] iteration 23930 : model1 loss : 0.436688 model2 loss : 0.019228
[12:03:40.876] iteration 23931 : model1 loss : 0.442888 model2 loss : 0.019712
[12:03:41.050] iteration 23932 : model1 loss : 0.442811 model2 loss : 0.020222
[12:03:41.218] iteration 23933 : model1 loss : 0.439722 model2 loss : 0.020297
[12:03:41.388] iteration 23934 : model1 loss : 0.442133 model2 loss : 0.019755
[12:03:41.555] iteration 23935 : model1 loss : 0.439303 model2 loss : 0.020871
[12:03:41.726] iteration 23936 : model1 loss : 0.440617 model2 loss : 0.020931
[12:03:41.895] iteration 23937 : model1 loss : 0.437713 model2 loss : 0.020191
[12:03:42.067] iteration 23938 : model1 loss : 0.439683 model2 loss : 0.019118
[12:03:42.236] iteration 23939 : model1 loss : 0.434707 model2 loss : 0.018898
[12:03:42.412] iteration 23940 : model1 loss : 0.437085 model2 loss : 0.018039
[12:03:42.579] iteration 23941 : model1 loss : 0.440060 model2 loss : 0.021767
[12:03:42.748] iteration 23942 : model1 loss : 0.437313 model2 loss : 0.020847
[12:03:42.917] iteration 23943 : model1 loss : 0.444523 model2 loss : 0.022688
[12:03:43.089] iteration 23944 : model1 loss : 0.436999 model2 loss : 0.019550
[12:03:43.256] iteration 23945 : model1 loss : 0.435609 model2 loss : 0.020355
[12:03:43.425] iteration 23946 : model1 loss : 0.444643 model2 loss : 0.022606
[12:03:43.595] iteration 23947 : model1 loss : 0.444531 model2 loss : 0.017720
[12:03:43.766] iteration 23948 : model1 loss : 0.439920 model2 loss : 0.019941
[12:03:43.934] iteration 23949 : model1 loss : 0.445518 model2 loss : 0.024537
[12:03:44.104] iteration 23950 : model1 loss : 0.435083 model2 loss : 0.018986
[12:03:44.271] iteration 23951 : model1 loss : 0.439165 model2 loss : 0.018737
[12:03:44.441] iteration 23952 : model1 loss : 0.434602 model2 loss : 0.020149
[12:03:44.611] iteration 23953 : model1 loss : 0.442147 model2 loss : 0.022040
[12:03:44.780] iteration 23954 : model1 loss : 0.438799 model2 loss : 0.020622
[12:03:44.947] iteration 23955 : model1 loss : 0.438543 model2 loss : 0.018059
[12:03:45.118] iteration 23956 : model1 loss : 0.439842 model2 loss : 0.020764
[12:03:45.285] iteration 23957 : model1 loss : 0.436978 model2 loss : 0.019079
[12:03:45.453] iteration 23958 : model1 loss : 0.437948 model2 loss : 0.019663
[12:03:47.361] iteration 23959 : model1 loss : 0.440377 model2 loss : 0.022549
[12:03:47.532] iteration 23960 : model1 loss : 0.440894 model2 loss : 0.021872
[12:03:47.704] iteration 23961 : model1 loss : 0.438191 model2 loss : 0.018102
[12:03:47.870] iteration 23962 : model1 loss : 0.439766 model2 loss : 0.021435
[12:03:48.041] iteration 23963 : model1 loss : 0.440033 model2 loss : 0.019838
[12:03:48.213] iteration 23964 : model1 loss : 0.443846 model2 loss : 0.021392
[12:03:48.384] iteration 23965 : model1 loss : 0.434273 model2 loss : 0.019124
[12:03:48.556] iteration 23966 : model1 loss : 0.437558 model2 loss : 0.018228
[12:03:48.726] iteration 23967 : model1 loss : 0.434137 model2 loss : 0.019900
[12:03:48.894] iteration 23968 : model1 loss : 0.441306 model2 loss : 0.019696
[12:03:49.064] iteration 23969 : model1 loss : 0.439630 model2 loss : 0.018056
[12:03:49.235] iteration 23970 : model1 loss : 0.441211 model2 loss : 0.020128
[12:03:49.404] iteration 23971 : model1 loss : 0.445168 model2 loss : 0.022867
[12:03:49.574] iteration 23972 : model1 loss : 0.441231 model2 loss : 0.020189
[12:03:49.745] iteration 23973 : model1 loss : 0.438553 model2 loss : 0.018992
[12:03:49.914] iteration 23974 : model1 loss : 0.441759 model2 loss : 0.020982
[12:03:50.084] iteration 23975 : model1 loss : 0.440526 model2 loss : 0.020831
[12:03:50.251] iteration 23976 : model1 loss : 0.440049 model2 loss : 0.020354
[12:03:50.421] iteration 23977 : model1 loss : 0.442867 model2 loss : 0.021477
[12:03:50.589] iteration 23978 : model1 loss : 0.438213 model2 loss : 0.019451
[12:03:50.759] iteration 23979 : model1 loss : 0.438864 model2 loss : 0.017402
[12:03:50.929] iteration 23980 : model1 loss : 0.438593 model2 loss : 0.020151
[12:03:51.097] iteration 23981 : model1 loss : 0.435101 model2 loss : 0.019320
[12:03:51.264] iteration 23982 : model1 loss : 0.435849 model2 loss : 0.018012
[12:03:51.433] iteration 23983 : model1 loss : 0.441204 model2 loss : 0.021404
[12:03:51.599] iteration 23984 : model1 loss : 0.444948 model2 loss : 0.021782
[12:03:51.769] iteration 23985 : model1 loss : 0.436029 model2 loss : 0.019323
[12:03:51.936] iteration 23986 : model1 loss : 0.441278 model2 loss : 0.021645
[12:03:52.103] iteration 23987 : model1 loss : 0.436837 model2 loss : 0.019305
[12:03:52.271] iteration 23988 : model1 loss : 0.436045 model2 loss : 0.021579
[12:03:52.440] iteration 23989 : model1 loss : 0.441171 model2 loss : 0.021179
[12:03:52.605] iteration 23990 : model1 loss : 0.436380 model2 loss : 0.019070
[12:03:52.775] iteration 23991 : model1 loss : 0.440176 model2 loss : 0.018977
[12:03:54.682] iteration 23992 : model1 loss : 0.443892 model2 loss : 0.022822
[12:03:54.849] iteration 23993 : model1 loss : 0.442123 model2 loss : 0.019035
[12:03:55.016] iteration 23994 : model1 loss : 0.437051 model2 loss : 0.020184
[12:03:55.184] iteration 23995 : model1 loss : 0.442434 model2 loss : 0.021701
[12:03:55.354] iteration 23996 : model1 loss : 0.437661 model2 loss : 0.023460
[12:03:55.524] iteration 23997 : model1 loss : 0.440577 model2 loss : 0.018524
[12:03:55.694] iteration 23998 : model1 loss : 0.440560 model2 loss : 0.020734
[12:03:55.862] iteration 23999 : model1 loss : 0.440066 model2 loss : 0.021211
[12:03:56.031] iteration 24000 : model1 loss : 0.437990 model2 loss : 0.018808
[12:04:04.287] iteration 24000 : model1_mean_dice : 0.902914 model1_mean_hd95 : 3.270720
[12:04:12.555] iteration 24000 : model2_mean_dice : 0.898217 model2_mean_hd95 : 2.091026
[12:04:12.576] save model1 to ../model/ACDC/EVILv1_kl0.5_tau0.25_21_1337/unet\model1_iter_24000.pth
[12:04:12.595] save model2 to ../model/ACDC/EVILv1_kl0.5_tau0.25_21_1337/unet\model2_iter_24000.pth
[12:04:12.770] iteration 24001 : model1 loss : 0.438208 model2 loss : 0.020518
[12:04:12.946] iteration 24002 : model1 loss : 0.438918 model2 loss : 0.018439
[12:04:13.115] iteration 24003 : model1 loss : 0.441363 model2 loss : 0.020260
[12:04:13.282] iteration 24004 : model1 loss : 0.435722 model2 loss : 0.020020
[12:04:13.449] iteration 24005 : model1 loss : 0.441401 model2 loss : 0.020577
[12:04:13.615] iteration 24006 : model1 loss : 0.440326 model2 loss : 0.020764
[12:04:13.784] iteration 24007 : model1 loss : 0.438390 model2 loss : 0.022310
[12:04:13.951] iteration 24008 : model1 loss : 0.436129 model2 loss : 0.021646
[12:04:14.117] iteration 24009 : model1 loss : 0.438115 model2 loss : 0.018081
[12:04:14.284] iteration 24010 : model1 loss : 0.434085 model2 loss : 0.017927
[12:04:14.452] iteration 24011 : model1 loss : 0.442953 model2 loss : 0.020623
[12:04:14.617] iteration 24012 : model1 loss : 0.438095 model2 loss : 0.020586
[12:04:14.784] iteration 24013 : model1 loss : 0.438077 model2 loss : 0.020052
[12:04:14.951] iteration 24014 : model1 loss : 0.434836 model2 loss : 0.016948
[12:04:15.120] iteration 24015 : model1 loss : 0.443107 model2 loss : 0.022851
[12:04:15.286] iteration 24016 : model1 loss : 0.440881 model2 loss : 0.019134
[12:04:15.455] iteration 24017 : model1 loss : 0.439706 model2 loss : 0.023037
[12:04:15.622] iteration 24018 : model1 loss : 0.443378 model2 loss : 0.022162
[12:04:15.790] iteration 24019 : model1 loss : 0.435103 model2 loss : 0.022382
[12:04:15.958] iteration 24020 : model1 loss : 0.444050 model2 loss : 0.020751
[12:04:16.126] iteration 24021 : model1 loss : 0.441699 model2 loss : 0.020716
[12:04:16.303] iteration 24022 : model1 loss : 0.444815 model2 loss : 0.019346
[12:04:16.470] iteration 24023 : model1 loss : 0.434476 model2 loss : 0.018772
[12:04:16.634] iteration 24024 : model1 loss : 0.442418 model2 loss : 0.020619
[12:04:18.549] iteration 24025 : model1 loss : 0.442763 model2 loss : 0.023394
[12:04:18.715] iteration 24026 : model1 loss : 0.439928 model2 loss : 0.020258
[12:04:18.888] iteration 24027 : model1 loss : 0.438309 model2 loss : 0.019549
[12:04:19.056] iteration 24028 : model1 loss : 0.438363 model2 loss : 0.020518
[12:04:19.229] iteration 24029 : model1 loss : 0.440121 model2 loss : 0.018729
[12:04:19.395] iteration 24030 : model1 loss : 0.436767 model2 loss : 0.020743
[12:04:19.562] iteration 24031 : model1 loss : 0.441366 model2 loss : 0.024715
[12:04:19.731] iteration 24032 : model1 loss : 0.446891 model2 loss : 0.021603
[12:04:19.900] iteration 24033 : model1 loss : 0.437325 model2 loss : 0.019433
[12:04:20.067] iteration 24034 : model1 loss : 0.437453 model2 loss : 0.023612
[12:04:20.239] iteration 24035 : model1 loss : 0.439348 model2 loss : 0.019671
[12:04:20.404] iteration 24036 : model1 loss : 0.441182 model2 loss : 0.019063
[12:04:20.574] iteration 24037 : model1 loss : 0.440131 model2 loss : 0.021515
[12:04:20.741] iteration 24038 : model1 loss : 0.445498 model2 loss : 0.021578
[12:04:20.912] iteration 24039 : model1 loss : 0.439371 model2 loss : 0.022131
[12:04:21.077] iteration 24040 : model1 loss : 0.438096 model2 loss : 0.019821
[12:04:21.251] iteration 24041 : model1 loss : 0.437789 model2 loss : 0.019501
[12:04:21.418] iteration 24042 : model1 loss : 0.442003 model2 loss : 0.021762
[12:04:21.587] iteration 24043 : model1 loss : 0.441437 model2 loss : 0.021872
[12:04:21.753] iteration 24044 : model1 loss : 0.441100 model2 loss : 0.020947
[12:04:21.924] iteration 24045 : model1 loss : 0.440216 model2 loss : 0.020814
[12:04:22.092] iteration 24046 : model1 loss : 0.434387 model2 loss : 0.021526
[12:04:22.263] iteration 24047 : model1 loss : 0.445410 model2 loss : 0.022455
[12:04:22.428] iteration 24048 : model1 loss : 0.433998 model2 loss : 0.019674
[12:04:22.595] iteration 24049 : model1 loss : 0.440132 model2 loss : 0.021635
[12:04:22.763] iteration 24050 : model1 loss : 0.439083 model2 loss : 0.019742
[12:04:22.932] iteration 24051 : model1 loss : 0.438736 model2 loss : 0.020768
[12:04:23.100] iteration 24052 : model1 loss : 0.440649 model2 loss : 0.020329
[12:04:23.268] iteration 24053 : model1 loss : 0.440364 model2 loss : 0.020996
[12:04:23.436] iteration 24054 : model1 loss : 0.435726 model2 loss : 0.018833
[12:04:23.604] iteration 24055 : model1 loss : 0.441342 model2 loss : 0.022677
[12:04:23.770] iteration 24056 : model1 loss : 0.439126 model2 loss : 0.019989
[12:04:23.938] iteration 24057 : model1 loss : 0.441833 model2 loss : 0.020046
[12:04:25.841] iteration 24058 : model1 loss : 0.441225 model2 loss : 0.021823
[12:04:26.010] iteration 24059 : model1 loss : 0.436986 model2 loss : 0.021812
[12:04:26.181] iteration 24060 : model1 loss : 0.441622 model2 loss : 0.020902
[12:04:26.346] iteration 24061 : model1 loss : 0.437651 model2 loss : 0.019211
[12:04:26.517] iteration 24062 : model1 loss : 0.440146 model2 loss : 0.018746
[12:04:26.684] iteration 24063 : model1 loss : 0.438100 model2 loss : 0.020641
[12:04:26.852] iteration 24064 : model1 loss : 0.442828 model2 loss : 0.020071
[12:04:27.018] iteration 24065 : model1 loss : 0.440159 model2 loss : 0.020720
[12:04:27.188] iteration 24066 : model1 loss : 0.437267 model2 loss : 0.019909
[12:04:27.355] iteration 24067 : model1 loss : 0.439382 model2 loss : 0.020204
[12:04:27.527] iteration 24068 : model1 loss : 0.438701 model2 loss : 0.019554
[12:04:27.693] iteration 24069 : model1 loss : 0.436584 model2 loss : 0.019425
[12:04:27.863] iteration 24070 : model1 loss : 0.440194 model2 loss : 0.019411
[12:04:28.030] iteration 24071 : model1 loss : 0.440676 model2 loss : 0.019852
[12:04:28.199] iteration 24072 : model1 loss : 0.442267 model2 loss : 0.019362
[12:04:28.365] iteration 24073 : model1 loss : 0.439246 model2 loss : 0.019941
[12:04:28.535] iteration 24074 : model1 loss : 0.437723 model2 loss : 0.016851
[12:04:28.701] iteration 24075 : model1 loss : 0.437327 model2 loss : 0.019157
[12:04:28.876] iteration 24076 : model1 loss : 0.440142 model2 loss : 0.019288
[12:04:29.041] iteration 24077 : model1 loss : 0.444051 model2 loss : 0.022663
[12:04:29.212] iteration 24078 : model1 loss : 0.437669 model2 loss : 0.018652
[12:04:29.380] iteration 24079 : model1 loss : 0.440514 model2 loss : 0.022941
[12:04:29.550] iteration 24080 : model1 loss : 0.435980 model2 loss : 0.020773
[12:04:29.717] iteration 24081 : model1 loss : 0.436199 model2 loss : 0.020151
[12:04:29.884] iteration 24082 : model1 loss : 0.443510 model2 loss : 0.018690
[12:04:30.053] iteration 24083 : model1 loss : 0.441984 model2 loss : 0.021361
[12:04:30.225] iteration 24084 : model1 loss : 0.440320 model2 loss : 0.021824
[12:04:30.391] iteration 24085 : model1 loss : 0.436354 model2 loss : 0.017503
[12:04:30.560] iteration 24086 : model1 loss : 0.443856 model2 loss : 0.021875
[12:04:30.727] iteration 24087 : model1 loss : 0.445094 model2 loss : 0.021540
[12:04:30.898] iteration 24088 : model1 loss : 0.439820 model2 loss : 0.019764
[12:04:31.064] iteration 24089 : model1 loss : 0.438455 model2 loss : 0.021148
[12:04:31.232] iteration 24090 : model1 loss : 0.436089 model2 loss : 0.020167
[12:04:33.156] iteration 24091 : model1 loss : 0.441495 model2 loss : 0.016874
[12:04:33.321] iteration 24092 : model1 loss : 0.436276 model2 loss : 0.020682
[12:04:33.492] iteration 24093 : model1 loss : 0.443458 model2 loss : 0.018519
[12:04:33.658] iteration 24094 : model1 loss : 0.439965 model2 loss : 0.020371
[12:04:33.827] iteration 24095 : model1 loss : 0.440221 model2 loss : 0.022306
[12:04:33.994] iteration 24096 : model1 loss : 0.437237 model2 loss : 0.017727
[12:04:34.162] iteration 24097 : model1 loss : 0.436531 model2 loss : 0.020201
[12:04:34.331] iteration 24098 : model1 loss : 0.439082 model2 loss : 0.018495
[12:04:34.502] iteration 24099 : model1 loss : 0.440636 model2 loss : 0.022787
[12:04:34.670] iteration 24100 : model1 loss : 0.438458 model2 loss : 0.019333
[12:04:34.840] iteration 24101 : model1 loss : 0.438849 model2 loss : 0.020772
[12:04:35.007] iteration 24102 : model1 loss : 0.439227 model2 loss : 0.019559
[12:04:35.177] iteration 24103 : model1 loss : 0.439783 model2 loss : 0.019906
[12:04:35.344] iteration 24104 : model1 loss : 0.439093 model2 loss : 0.021550
[12:04:35.519] iteration 24105 : model1 loss : 0.442623 model2 loss : 0.020723
[12:04:35.685] iteration 24106 : model1 loss : 0.439030 model2 loss : 0.022181
[12:04:35.853] iteration 24107 : model1 loss : 0.437007 model2 loss : 0.021160
[12:04:36.019] iteration 24108 : model1 loss : 0.441009 model2 loss : 0.020991
[12:04:36.190] iteration 24109 : model1 loss : 0.439212 model2 loss : 0.019355
[12:04:36.356] iteration 24110 : model1 loss : 0.439928 model2 loss : 0.020791
[12:04:36.528] iteration 24111 : model1 loss : 0.440303 model2 loss : 0.019379
[12:04:36.694] iteration 24112 : model1 loss : 0.437343 model2 loss : 0.019471
[12:04:36.862] iteration 24113 : model1 loss : 0.435045 model2 loss : 0.017965
[12:04:37.032] iteration 24114 : model1 loss : 0.437296 model2 loss : 0.018026
[12:04:37.203] iteration 24115 : model1 loss : 0.438805 model2 loss : 0.020057
[12:04:37.370] iteration 24116 : model1 loss : 0.438500 model2 loss : 0.020356
[12:04:37.543] iteration 24117 : model1 loss : 0.437624 model2 loss : 0.018431
[12:04:37.710] iteration 24118 : model1 loss : 0.441312 model2 loss : 0.021507
[12:04:37.878] iteration 24119 : model1 loss : 0.441466 model2 loss : 0.021766
[12:04:38.046] iteration 24120 : model1 loss : 0.439863 model2 loss : 0.018556
[12:04:38.216] iteration 24121 : model1 loss : 0.441716 model2 loss : 0.018813
[12:04:38.382] iteration 24122 : model1 loss : 0.439892 model2 loss : 0.019962
[12:04:38.549] iteration 24123 : model1 loss : 0.440709 model2 loss : 0.019997
[12:04:40.442] iteration 24124 : model1 loss : 0.442216 model2 loss : 0.021871
[12:04:40.617] iteration 24125 : model1 loss : 0.438103 model2 loss : 0.019486
[12:04:40.788] iteration 24126 : model1 loss : 0.441530 model2 loss : 0.021260
[12:04:40.956] iteration 24127 : model1 loss : 0.439876 model2 loss : 0.021722
[12:04:41.127] iteration 24128 : model1 loss : 0.437940 model2 loss : 0.021504
[12:04:41.295] iteration 24129 : model1 loss : 0.439717 model2 loss : 0.020308
[12:04:41.462] iteration 24130 : model1 loss : 0.439482 model2 loss : 0.021241
[12:04:41.629] iteration 24131 : model1 loss : 0.442553 model2 loss : 0.020225
[12:04:41.796] iteration 24132 : model1 loss : 0.440558 model2 loss : 0.018772
[12:04:41.964] iteration 24133 : model1 loss : 0.438298 model2 loss : 0.021409
[12:04:42.131] iteration 24134 : model1 loss : 0.444498 model2 loss : 0.020965
[12:04:42.297] iteration 24135 : model1 loss : 0.444840 model2 loss : 0.022470
[12:04:42.465] iteration 24136 : model1 loss : 0.435416 model2 loss : 0.019353
[12:04:42.632] iteration 24137 : model1 loss : 0.440695 model2 loss : 0.019189
[12:04:42.801] iteration 24138 : model1 loss : 0.440443 model2 loss : 0.018528
[12:04:42.968] iteration 24139 : model1 loss : 0.439239 model2 loss : 0.018899
[12:04:43.137] iteration 24140 : model1 loss : 0.439874 model2 loss : 0.020805
[12:04:43.306] iteration 24141 : model1 loss : 0.439638 model2 loss : 0.019141
[12:04:43.474] iteration 24142 : model1 loss : 0.435142 model2 loss : 0.018543
[12:04:43.640] iteration 24143 : model1 loss : 0.437964 model2 loss : 0.019225
[12:04:43.814] iteration 24144 : model1 loss : 0.437907 model2 loss : 0.019040
[12:04:43.982] iteration 24145 : model1 loss : 0.438137 model2 loss : 0.017447
[12:04:44.150] iteration 24146 : model1 loss : 0.443361 model2 loss : 0.019026
[12:04:44.318] iteration 24147 : model1 loss : 0.437167 model2 loss : 0.019229
[12:04:44.487] iteration 24148 : model1 loss : 0.436564 model2 loss : 0.018366
[12:04:44.654] iteration 24149 : model1 loss : 0.440202 model2 loss : 0.019747
[12:04:44.823] iteration 24150 : model1 loss : 0.437519 model2 loss : 0.016757
[12:04:44.988] iteration 24151 : model1 loss : 0.436724 model2 loss : 0.017043
[12:04:45.157] iteration 24152 : model1 loss : 0.437305 model2 loss : 0.020140
[12:04:45.325] iteration 24153 : model1 loss : 0.439162 model2 loss : 0.021598
[12:04:45.493] iteration 24154 : model1 loss : 0.439863 model2 loss : 0.020435
[12:04:45.660] iteration 24155 : model1 loss : 0.440671 model2 loss : 0.020699
[12:04:45.827] iteration 24156 : model1 loss : 0.438592 model2 loss : 0.018072
[12:04:47.734] iteration 24157 : model1 loss : 0.442671 model2 loss : 0.021783
[12:04:47.906] iteration 24158 : model1 loss : 0.439080 model2 loss : 0.019543
[12:04:48.076] iteration 24159 : model1 loss : 0.439669 model2 loss : 0.022279
[12:04:48.244] iteration 24160 : model1 loss : 0.434481 model2 loss : 0.017163
[12:04:48.412] iteration 24161 : model1 loss : 0.438202 model2 loss : 0.018129
[12:04:48.580] iteration 24162 : model1 loss : 0.440980 model2 loss : 0.020451
[12:04:48.749] iteration 24163 : model1 loss : 0.441296 model2 loss : 0.020543
[12:04:48.917] iteration 24164 : model1 loss : 0.444388 model2 loss : 0.020152
[12:04:49.087] iteration 24165 : model1 loss : 0.437436 model2 loss : 0.020793
[12:04:49.254] iteration 24166 : model1 loss : 0.439511 model2 loss : 0.020437
[12:04:49.422] iteration 24167 : model1 loss : 0.445036 model2 loss : 0.025977
[12:04:49.589] iteration 24168 : model1 loss : 0.442989 model2 loss : 0.017302
[12:04:49.758] iteration 24169 : model1 loss : 0.434213 model2 loss : 0.019086
[12:04:49.924] iteration 24170 : model1 loss : 0.442008 model2 loss : 0.018016
[12:04:50.094] iteration 24171 : model1 loss : 0.436972 model2 loss : 0.021194
[12:04:50.267] iteration 24172 : model1 loss : 0.438346 model2 loss : 0.022453
[12:04:50.436] iteration 24173 : model1 loss : 0.438327 model2 loss : 0.020007
[12:04:50.602] iteration 24174 : model1 loss : 0.439402 model2 loss : 0.021718
[12:04:50.769] iteration 24175 : model1 loss : 0.445305 model2 loss : 0.021938
[12:04:50.941] iteration 24176 : model1 loss : 0.436303 model2 loss : 0.019366
[12:04:51.111] iteration 24177 : model1 loss : 0.444691 model2 loss : 0.022639
[12:04:51.283] iteration 24178 : model1 loss : 0.441543 model2 loss : 0.024030
[12:04:51.452] iteration 24179 : model1 loss : 0.436149 model2 loss : 0.017971
[12:04:51.619] iteration 24180 : model1 loss : 0.436266 model2 loss : 0.018755
[12:04:51.789] iteration 24181 : model1 loss : 0.438507 model2 loss : 0.019745
[12:04:51.955] iteration 24182 : model1 loss : 0.438861 model2 loss : 0.019113
[12:04:52.123] iteration 24183 : model1 loss : 0.440582 model2 loss : 0.021634
[12:04:52.291] iteration 24184 : model1 loss : 0.441363 model2 loss : 0.019882
[12:04:52.460] iteration 24185 : model1 loss : 0.439945 model2 loss : 0.021298
[12:04:52.626] iteration 24186 : model1 loss : 0.436177 model2 loss : 0.021688
[12:04:52.794] iteration 24187 : model1 loss : 0.441054 model2 loss : 0.019657
[12:04:52.961] iteration 24188 : model1 loss : 0.435685 model2 loss : 0.017347
[12:04:53.129] iteration 24189 : model1 loss : 0.438701 model2 loss : 0.019089
[12:04:55.042] iteration 24190 : model1 loss : 0.438674 model2 loss : 0.020058
[12:04:55.208] iteration 24191 : model1 loss : 0.441506 model2 loss : 0.021251
[12:04:55.376] iteration 24192 : model1 loss : 0.441310 model2 loss : 0.021624
[12:04:55.543] iteration 24193 : model1 loss : 0.439438 model2 loss : 0.022031
[12:04:55.711] iteration 24194 : model1 loss : 0.437712 model2 loss : 0.021443
[12:04:55.879] iteration 24195 : model1 loss : 0.439989 model2 loss : 0.019194
[12:04:56.048] iteration 24196 : model1 loss : 0.442595 model2 loss : 0.023536
[12:04:56.215] iteration 24197 : model1 loss : 0.439538 model2 loss : 0.021369
[12:04:56.384] iteration 24198 : model1 loss : 0.439737 model2 loss : 0.020027
[12:04:56.551] iteration 24199 : model1 loss : 0.441426 model2 loss : 0.020309
[12:04:56.719] iteration 24200 : model1 loss : 0.437198 model2 loss : 0.021445
[12:04:56.887] iteration 24201 : model1 loss : 0.442358 model2 loss : 0.023819
[12:04:57.055] iteration 24202 : model1 loss : 0.442007 model2 loss : 0.022036
[12:04:57.223] iteration 24203 : model1 loss : 0.438680 model2 loss : 0.019638
[12:04:57.392] iteration 24204 : model1 loss : 0.435252 model2 loss : 0.016844
[12:04:57.559] iteration 24205 : model1 loss : 0.444745 model2 loss : 0.019920
[12:04:57.729] iteration 24206 : model1 loss : 0.440198 model2 loss : 0.022699
[12:04:57.896] iteration 24207 : model1 loss : 0.438493 model2 loss : 0.018596
[12:04:58.062] iteration 24208 : model1 loss : 0.436027 model2 loss : 0.021422
[12:04:58.228] iteration 24209 : model1 loss : 0.436404 model2 loss : 0.019670
[12:04:58.397] iteration 24210 : model1 loss : 0.433231 model2 loss : 0.018604
[12:04:58.563] iteration 24211 : model1 loss : 0.440132 model2 loss : 0.020899
[12:04:58.732] iteration 24212 : model1 loss : 0.439404 model2 loss : 0.018575
[12:04:58.900] iteration 24213 : model1 loss : 0.437829 model2 loss : 0.019984
[12:04:59.071] iteration 24214 : model1 loss : 0.438950 model2 loss : 0.019257
[12:04:59.237] iteration 24215 : model1 loss : 0.443133 model2 loss : 0.019375
[12:04:59.407] iteration 24216 : model1 loss : 0.443404 model2 loss : 0.021049
[12:04:59.574] iteration 24217 : model1 loss : 0.436866 model2 loss : 0.020983
[12:04:59.743] iteration 24218 : model1 loss : 0.440197 model2 loss : 0.023010
[12:04:59.908] iteration 24219 : model1 loss : 0.437810 model2 loss : 0.019002
[12:05:00.077] iteration 24220 : model1 loss : 0.439338 model2 loss : 0.020162
[12:05:00.245] iteration 24221 : model1 loss : 0.443453 model2 loss : 0.022888
[12:05:00.412] iteration 24222 : model1 loss : 0.439104 model2 loss : 0.020827
[12:05:02.329] iteration 24223 : model1 loss : 0.437119 model2 loss : 0.018669
[12:05:02.497] iteration 24224 : model1 loss : 0.444772 model2 loss : 0.023551
[12:05:02.667] iteration 24225 : model1 loss : 0.435694 model2 loss : 0.021469
[12:05:02.833] iteration 24226 : model1 loss : 0.438407 model2 loss : 0.021625
[12:05:03.002] iteration 24227 : model1 loss : 0.439731 model2 loss : 0.019327
[12:05:03.171] iteration 24228 : model1 loss : 0.443077 model2 loss : 0.020580
[12:05:03.340] iteration 24229 : model1 loss : 0.440563 model2 loss : 0.019888
[12:05:03.507] iteration 24230 : model1 loss : 0.444430 model2 loss : 0.023660
[12:05:03.677] iteration 24231 : model1 loss : 0.438845 model2 loss : 0.018537
[12:05:03.842] iteration 24232 : model1 loss : 0.441099 model2 loss : 0.020407
[12:05:04.012] iteration 24233 : model1 loss : 0.438724 model2 loss : 0.017381
[12:05:04.179] iteration 24234 : model1 loss : 0.439148 model2 loss : 0.020315
[12:05:04.349] iteration 24235 : model1 loss : 0.443602 model2 loss : 0.022265
[12:05:04.518] iteration 24236 : model1 loss : 0.436877 model2 loss : 0.019498
[12:05:04.685] iteration 24237 : model1 loss : 0.439030 model2 loss : 0.021862
[12:05:04.853] iteration 24238 : model1 loss : 0.436429 model2 loss : 0.021352
[12:05:05.023] iteration 24239 : model1 loss : 0.437576 model2 loss : 0.019903
[12:05:05.191] iteration 24240 : model1 loss : 0.442945 model2 loss : 0.020527
[12:05:05.358] iteration 24241 : model1 loss : 0.441526 model2 loss : 0.022073
[12:05:05.526] iteration 24242 : model1 loss : 0.440792 model2 loss : 0.019928
[12:05:05.695] iteration 24243 : model1 loss : 0.441201 model2 loss : 0.018951
[12:05:05.862] iteration 24244 : model1 loss : 0.435025 model2 loss : 0.018927
[12:05:06.032] iteration 24245 : model1 loss : 0.441753 model2 loss : 0.022093
[12:05:06.198] iteration 24246 : model1 loss : 0.437943 model2 loss : 0.020961
[12:05:06.367] iteration 24247 : model1 loss : 0.436764 model2 loss : 0.020168
[12:05:06.534] iteration 24248 : model1 loss : 0.437519 model2 loss : 0.020945
[12:05:06.703] iteration 24249 : model1 loss : 0.435860 model2 loss : 0.020716
[12:05:06.870] iteration 24250 : model1 loss : 0.441346 model2 loss : 0.019621
[12:05:07.038] iteration 24251 : model1 loss : 0.436766 model2 loss : 0.019115
[12:05:07.204] iteration 24252 : model1 loss : 0.440774 model2 loss : 0.017484
[12:05:07.371] iteration 24253 : model1 loss : 0.439082 model2 loss : 0.020306
[12:05:07.537] iteration 24254 : model1 loss : 0.440201 model2 loss : 0.016260
[12:05:07.703] iteration 24255 : model1 loss : 0.440722 model2 loss : 0.020058
[12:05:09.638] iteration 24256 : model1 loss : 0.440778 model2 loss : 0.018152
[12:05:09.811] iteration 24257 : model1 loss : 0.437314 model2 loss : 0.019578
[12:05:09.985] iteration 24258 : model1 loss : 0.438927 model2 loss : 0.018460
[12:05:10.154] iteration 24259 : model1 loss : 0.436078 model2 loss : 0.021488
[12:05:10.321] iteration 24260 : model1 loss : 0.438885 model2 loss : 0.019165
[12:05:10.493] iteration 24261 : model1 loss : 0.438546 model2 loss : 0.021649
[12:05:10.661] iteration 24262 : model1 loss : 0.435777 model2 loss : 0.017909
[12:05:10.829] iteration 24263 : model1 loss : 0.438812 model2 loss : 0.020380
[12:05:10.997] iteration 24264 : model1 loss : 0.441900 model2 loss : 0.020318
[12:05:11.164] iteration 24265 : model1 loss : 0.440634 model2 loss : 0.021380
[12:05:11.342] iteration 24266 : model1 loss : 0.441656 model2 loss : 0.018348
[12:05:11.513] iteration 24267 : model1 loss : 0.429845 model2 loss : 0.018226
[12:05:11.683] iteration 24268 : model1 loss : 0.442139 model2 loss : 0.021729
[12:05:11.850] iteration 24269 : model1 loss : 0.438548 model2 loss : 0.019871
[12:05:12.021] iteration 24270 : model1 loss : 0.438840 model2 loss : 0.019336
[12:05:12.187] iteration 24271 : model1 loss : 0.441587 model2 loss : 0.022806
[12:05:12.357] iteration 24272 : model1 loss : 0.442054 model2 loss : 0.023011
[12:05:12.528] iteration 24273 : model1 loss : 0.441505 model2 loss : 0.020274
[12:05:12.697] iteration 24274 : model1 loss : 0.437787 model2 loss : 0.020402
[12:05:12.866] iteration 24275 : model1 loss : 0.443412 model2 loss : 0.022828
[12:05:13.036] iteration 24276 : model1 loss : 0.440303 model2 loss : 0.023289
[12:05:13.205] iteration 24277 : model1 loss : 0.437837 model2 loss : 0.018303
[12:05:13.374] iteration 24278 : model1 loss : 0.438613 model2 loss : 0.018966
[12:05:13.542] iteration 24279 : model1 loss : 0.438178 model2 loss : 0.018583
[12:05:13.710] iteration 24280 : model1 loss : 0.440811 model2 loss : 0.019432
[12:05:13.878] iteration 24281 : model1 loss : 0.443110 model2 loss : 0.021211
[12:05:14.047] iteration 24282 : model1 loss : 0.441935 model2 loss : 0.021052
[12:05:14.214] iteration 24283 : model1 loss : 0.436091 model2 loss : 0.020388
[12:05:14.382] iteration 24284 : model1 loss : 0.436272 model2 loss : 0.020097
[12:05:14.550] iteration 24285 : model1 loss : 0.438346 model2 loss : 0.020619
[12:05:14.720] iteration 24286 : model1 loss : 0.444860 model2 loss : 0.022840
[12:05:14.886] iteration 24287 : model1 loss : 0.441509 model2 loss : 0.023374
[12:05:15.055] iteration 24288 : model1 loss : 0.439514 model2 loss : 0.020635
[12:05:16.974] iteration 24289 : model1 loss : 0.437630 model2 loss : 0.018138
[12:05:17.141] iteration 24290 : model1 loss : 0.442037 model2 loss : 0.019829
[12:05:17.311] iteration 24291 : model1 loss : 0.439861 model2 loss : 0.019108
[12:05:17.478] iteration 24292 : model1 loss : 0.439454 model2 loss : 0.019591
[12:05:17.648] iteration 24293 : model1 loss : 0.437712 model2 loss : 0.017251
[12:05:17.816] iteration 24294 : model1 loss : 0.437134 model2 loss : 0.021472
[12:05:17.986] iteration 24295 : model1 loss : 0.440989 model2 loss : 0.020096
[12:05:18.153] iteration 24296 : model1 loss : 0.440849 model2 loss : 0.020223
[12:05:18.322] iteration 24297 : model1 loss : 0.437637 model2 loss : 0.019775
[12:05:18.491] iteration 24298 : model1 loss : 0.439737 model2 loss : 0.019276
[12:05:18.658] iteration 24299 : model1 loss : 0.442057 model2 loss : 0.021646
[12:05:18.826] iteration 24300 : model1 loss : 0.437754 model2 loss : 0.020831
[12:05:18.994] iteration 24301 : model1 loss : 0.440646 model2 loss : 0.022058
[12:05:19.165] iteration 24302 : model1 loss : 0.438475 model2 loss : 0.023681
[12:05:19.333] iteration 24303 : model1 loss : 0.442257 model2 loss : 0.020160
[12:05:19.503] iteration 24304 : model1 loss : 0.439408 model2 loss : 0.020061
[12:05:19.673] iteration 24305 : model1 loss : 0.441811 model2 loss : 0.020328
[12:05:19.845] iteration 24306 : model1 loss : 0.441484 model2 loss : 0.022889
[12:05:20.017] iteration 24307 : model1 loss : 0.440547 model2 loss : 0.018501
[12:05:20.183] iteration 24308 : model1 loss : 0.438496 model2 loss : 0.019100
[12:05:20.352] iteration 24309 : model1 loss : 0.438605 model2 loss : 0.018675
[12:05:20.521] iteration 24310 : model1 loss : 0.436129 model2 loss : 0.021844
[12:05:20.690] iteration 24311 : model1 loss : 0.437495 model2 loss : 0.019238
[12:05:20.859] iteration 24312 : model1 loss : 0.447125 model2 loss : 0.021732
[12:05:21.029] iteration 24313 : model1 loss : 0.437871 model2 loss : 0.018219
[12:05:21.198] iteration 24314 : model1 loss : 0.442216 model2 loss : 0.021967
[12:05:21.366] iteration 24315 : model1 loss : 0.440071 model2 loss : 0.019685
[12:05:21.535] iteration 24316 : model1 loss : 0.437947 model2 loss : 0.019340
[12:05:21.706] iteration 24317 : model1 loss : 0.439223 model2 loss : 0.021144
[12:05:21.874] iteration 24318 : model1 loss : 0.436639 model2 loss : 0.019334
[12:05:22.044] iteration 24319 : model1 loss : 0.440818 model2 loss : 0.018555
[12:05:22.213] iteration 24320 : model1 loss : 0.434560 model2 loss : 0.019088
[12:05:22.381] iteration 24321 : model1 loss : 0.439054 model2 loss : 0.022766
[12:05:24.268] iteration 24322 : model1 loss : 0.445512 model2 loss : 0.023437
[12:05:24.435] iteration 24323 : model1 loss : 0.436506 model2 loss : 0.019017
[12:05:24.607] iteration 24324 : model1 loss : 0.440897 model2 loss : 0.019716
[12:05:24.774] iteration 24325 : model1 loss : 0.435490 model2 loss : 0.022394
[12:05:24.944] iteration 24326 : model1 loss : 0.435098 model2 loss : 0.019488
[12:05:25.111] iteration 24327 : model1 loss : 0.439155 model2 loss : 0.018958
[12:05:25.283] iteration 24328 : model1 loss : 0.437448 model2 loss : 0.020955
[12:05:25.450] iteration 24329 : model1 loss : 0.440648 model2 loss : 0.020332
[12:05:25.619] iteration 24330 : model1 loss : 0.439222 model2 loss : 0.018105
[12:05:25.786] iteration 24331 : model1 loss : 0.443593 model2 loss : 0.019819
[12:05:25.959] iteration 24332 : model1 loss : 0.438567 model2 loss : 0.018620
[12:05:26.126] iteration 24333 : model1 loss : 0.441046 model2 loss : 0.019774
[12:05:26.300] iteration 24334 : model1 loss : 0.441149 model2 loss : 0.020743
[12:05:26.468] iteration 24335 : model1 loss : 0.442350 model2 loss : 0.020221
[12:05:26.638] iteration 24336 : model1 loss : 0.440363 model2 loss : 0.020564
[12:05:26.806] iteration 24337 : model1 loss : 0.434588 model2 loss : 0.018562
[12:05:26.973] iteration 24338 : model1 loss : 0.443732 model2 loss : 0.019057
[12:05:27.142] iteration 24339 : model1 loss : 0.433578 model2 loss : 0.018328
[12:05:27.314] iteration 24340 : model1 loss : 0.442986 model2 loss : 0.020144
[12:05:27.481] iteration 24341 : model1 loss : 0.442727 model2 loss : 0.021480
[12:05:27.650] iteration 24342 : model1 loss : 0.443160 model2 loss : 0.017777
[12:05:27.819] iteration 24343 : model1 loss : 0.437267 model2 loss : 0.019780
[12:05:27.986] iteration 24344 : model1 loss : 0.439462 model2 loss : 0.020421
[12:05:28.154] iteration 24345 : model1 loss : 0.432527 model2 loss : 0.018041
[12:05:28.326] iteration 24346 : model1 loss : 0.438711 model2 loss : 0.019178
[12:05:28.496] iteration 24347 : model1 loss : 0.438377 model2 loss : 0.019389
[12:05:28.664] iteration 24348 : model1 loss : 0.439744 model2 loss : 0.021493
[12:05:28.844] iteration 24349 : model1 loss : 0.441837 model2 loss : 0.019163
[12:05:29.014] iteration 24350 : model1 loss : 0.438728 model2 loss : 0.021233
[12:05:29.183] iteration 24351 : model1 loss : 0.435425 model2 loss : 0.019768
[12:05:29.354] iteration 24352 : model1 loss : 0.436692 model2 loss : 0.018058
[12:05:29.521] iteration 24353 : model1 loss : 0.444350 model2 loss : 0.020563
[12:05:29.689] iteration 24354 : model1 loss : 0.440559 model2 loss : 0.019470
[12:05:31.624] iteration 24355 : model1 loss : 0.446157 model2 loss : 0.025355
[12:05:31.791] iteration 24356 : model1 loss : 0.438340 model2 loss : 0.022671
[12:05:31.961] iteration 24357 : model1 loss : 0.438604 model2 loss : 0.020295
[12:05:32.128] iteration 24358 : model1 loss : 0.443910 model2 loss : 0.023796
[12:05:32.296] iteration 24359 : model1 loss : 0.437228 model2 loss : 0.021565
[12:05:32.465] iteration 24360 : model1 loss : 0.443167 model2 loss : 0.018392
[12:05:32.634] iteration 24361 : model1 loss : 0.437832 model2 loss : 0.018454
[12:05:32.801] iteration 24362 : model1 loss : 0.439926 model2 loss : 0.019288
[12:05:32.971] iteration 24363 : model1 loss : 0.433348 model2 loss : 0.018927
[12:05:33.139] iteration 24364 : model1 loss : 0.445372 model2 loss : 0.024630
[12:05:33.312] iteration 24365 : model1 loss : 0.439685 model2 loss : 0.019654
[12:05:33.477] iteration 24366 : model1 loss : 0.442615 model2 loss : 0.023261
[12:05:33.645] iteration 24367 : model1 loss : 0.437487 model2 loss : 0.017131
[12:05:33.809] iteration 24368 : model1 loss : 0.442054 model2 loss : 0.022663
[12:05:33.979] iteration 24369 : model1 loss : 0.440619 model2 loss : 0.021058
[12:05:34.147] iteration 24370 : model1 loss : 0.440992 model2 loss : 0.019853
[12:05:34.319] iteration 24371 : model1 loss : 0.440236 model2 loss : 0.023084
[12:05:34.485] iteration 24372 : model1 loss : 0.434841 model2 loss : 0.019518
[12:05:34.672] iteration 24373 : model1 loss : 0.444702 model2 loss : 0.020178
[12:05:34.837] iteration 24374 : model1 loss : 0.435008 model2 loss : 0.020128
[12:05:35.006] iteration 24375 : model1 loss : 0.436244 model2 loss : 0.019515
[12:05:35.175] iteration 24376 : model1 loss : 0.439596 model2 loss : 0.018421
[12:05:35.344] iteration 24377 : model1 loss : 0.439142 model2 loss : 0.018721
[12:05:35.514] iteration 24378 : model1 loss : 0.437349 model2 loss : 0.015992
[12:05:35.683] iteration 24379 : model1 loss : 0.438513 model2 loss : 0.020366
[12:05:35.852] iteration 24380 : model1 loss : 0.439622 model2 loss : 0.019951
[12:05:36.022] iteration 24381 : model1 loss : 0.440873 model2 loss : 0.021188
[12:05:36.190] iteration 24382 : model1 loss : 0.438078 model2 loss : 0.020100
[12:05:36.358] iteration 24383 : model1 loss : 0.436993 model2 loss : 0.019727
[12:05:36.527] iteration 24384 : model1 loss : 0.442265 model2 loss : 0.020160
[12:05:36.698] iteration 24385 : model1 loss : 0.437875 model2 loss : 0.020788
[12:05:36.866] iteration 24386 : model1 loss : 0.439964 model2 loss : 0.018522
[12:05:37.035] iteration 24387 : model1 loss : 0.439745 model2 loss : 0.019842
[12:05:38.942] iteration 24388 : model1 loss : 0.437588 model2 loss : 0.021167
[12:05:39.111] iteration 24389 : model1 loss : 0.438122 model2 loss : 0.020509
[12:05:39.281] iteration 24390 : model1 loss : 0.435093 model2 loss : 0.018408
[12:05:39.448] iteration 24391 : model1 loss : 0.442598 model2 loss : 0.020876
[12:05:39.615] iteration 24392 : model1 loss : 0.441053 model2 loss : 0.021169
[12:05:39.781] iteration 24393 : model1 loss : 0.438668 model2 loss : 0.020528
[12:05:39.952] iteration 24394 : model1 loss : 0.437855 model2 loss : 0.018229
[12:05:40.120] iteration 24395 : model1 loss : 0.441694 model2 loss : 0.024828
[12:05:40.289] iteration 24396 : model1 loss : 0.440054 model2 loss : 0.019419
[12:05:40.456] iteration 24397 : model1 loss : 0.438582 model2 loss : 0.018690
[12:05:40.626] iteration 24398 : model1 loss : 0.445213 model2 loss : 0.019681
[12:05:40.792] iteration 24399 : model1 loss : 0.439804 model2 loss : 0.018025
[12:05:40.961] iteration 24400 : model1 loss : 0.435755 model2 loss : 0.018584
[12:05:41.129] iteration 24401 : model1 loss : 0.437990 model2 loss : 0.020153
[12:05:41.300] iteration 24402 : model1 loss : 0.439943 model2 loss : 0.021867
[12:05:41.466] iteration 24403 : model1 loss : 0.435249 model2 loss : 0.018951
[12:05:41.637] iteration 24404 : model1 loss : 0.446329 model2 loss : 0.021570
[12:05:41.805] iteration 24405 : model1 loss : 0.436635 model2 loss : 0.019972
[12:05:41.972] iteration 24406 : model1 loss : 0.440907 model2 loss : 0.021023
[12:05:42.140] iteration 24407 : model1 loss : 0.434781 model2 loss : 0.019118
[12:05:42.310] iteration 24408 : model1 loss : 0.441175 model2 loss : 0.020011
[12:05:42.478] iteration 24409 : model1 loss : 0.439527 model2 loss : 0.020191
[12:05:42.646] iteration 24410 : model1 loss : 0.442246 model2 loss : 0.022151
[12:05:42.812] iteration 24411 : model1 loss : 0.437894 model2 loss : 0.018671
[12:05:42.981] iteration 24412 : model1 loss : 0.441451 model2 loss : 0.022179
[12:05:43.148] iteration 24413 : model1 loss : 0.441252 model2 loss : 0.021031
[12:05:43.317] iteration 24414 : model1 loss : 0.441383 model2 loss : 0.018775
[12:05:43.484] iteration 24415 : model1 loss : 0.437552 model2 loss : 0.019596
[12:05:43.653] iteration 24416 : model1 loss : 0.439193 model2 loss : 0.020197
[12:05:43.819] iteration 24417 : model1 loss : 0.438976 model2 loss : 0.019865
[12:05:43.988] iteration 24418 : model1 loss : 0.439750 model2 loss : 0.021904
[12:05:44.154] iteration 24419 : model1 loss : 0.444834 model2 loss : 0.021098
[12:05:44.321] iteration 24420 : model1 loss : 0.439726 model2 loss : 0.019567
[12:05:46.263] iteration 24421 : model1 loss : 0.443353 model2 loss : 0.022924
[12:05:46.432] iteration 24422 : model1 loss : 0.436446 model2 loss : 0.019022
[12:05:46.618] iteration 24423 : model1 loss : 0.439462 model2 loss : 0.019307
[12:05:46.783] iteration 24424 : model1 loss : 0.441354 model2 loss : 0.021969
[12:05:46.953] iteration 24425 : model1 loss : 0.441088 model2 loss : 0.020082
[12:05:47.119] iteration 24426 : model1 loss : 0.443432 model2 loss : 0.020524
[12:05:47.291] iteration 24427 : model1 loss : 0.440947 model2 loss : 0.019170
[12:05:47.460] iteration 24428 : model1 loss : 0.443882 model2 loss : 0.022671
[12:05:47.629] iteration 24429 : model1 loss : 0.435259 model2 loss : 0.019430
[12:05:47.796] iteration 24430 : model1 loss : 0.437795 model2 loss : 0.021945
[12:05:47.966] iteration 24431 : model1 loss : 0.440818 model2 loss : 0.018900
[12:05:48.135] iteration 24432 : model1 loss : 0.441406 model2 loss : 0.019918
[12:05:48.304] iteration 24433 : model1 loss : 0.438146 model2 loss : 0.018617
[12:05:48.471] iteration 24434 : model1 loss : 0.440021 model2 loss : 0.021072
[12:05:48.638] iteration 24435 : model1 loss : 0.434195 model2 loss : 0.017268
[12:05:48.803] iteration 24436 : model1 loss : 0.439262 model2 loss : 0.019586
[12:05:48.973] iteration 24437 : model1 loss : 0.438251 model2 loss : 0.019092
[12:05:49.140] iteration 24438 : model1 loss : 0.439875 model2 loss : 0.019285
[12:05:49.309] iteration 24439 : model1 loss : 0.438878 model2 loss : 0.020376
[12:05:49.476] iteration 24440 : model1 loss : 0.437826 model2 loss : 0.019794
[12:05:49.647] iteration 24441 : model1 loss : 0.442818 model2 loss : 0.024241
[12:05:49.814] iteration 24442 : model1 loss : 0.438223 model2 loss : 0.018579
[12:05:49.982] iteration 24443 : model1 loss : 0.441846 model2 loss : 0.019369
[12:05:50.149] iteration 24444 : model1 loss : 0.442885 model2 loss : 0.023651
[12:05:50.318] iteration 24445 : model1 loss : 0.434112 model2 loss : 0.020889
[12:05:50.487] iteration 24446 : model1 loss : 0.437852 model2 loss : 0.021285
[12:05:50.655] iteration 24447 : model1 loss : 0.434636 model2 loss : 0.019011
[12:05:50.822] iteration 24448 : model1 loss : 0.438519 model2 loss : 0.022253
[12:05:50.991] iteration 24449 : model1 loss : 0.439871 model2 loss : 0.020684
[12:05:51.157] iteration 24450 : model1 loss : 0.440107 model2 loss : 0.020201
[12:05:51.327] iteration 24451 : model1 loss : 0.440905 model2 loss : 0.020145
[12:05:51.492] iteration 24452 : model1 loss : 0.438691 model2 loss : 0.019393
[12:05:51.662] iteration 24453 : model1 loss : 0.439930 model2 loss : 0.019084
[12:05:53.563] iteration 24454 : model1 loss : 0.443773 model2 loss : 0.021965
[12:05:53.731] iteration 24455 : model1 loss : 0.440195 model2 loss : 0.022359
[12:05:53.901] iteration 24456 : model1 loss : 0.440006 model2 loss : 0.019056
[12:05:54.067] iteration 24457 : model1 loss : 0.440504 model2 loss : 0.019741
[12:05:54.238] iteration 24458 : model1 loss : 0.435823 model2 loss : 0.020731
[12:05:54.404] iteration 24459 : model1 loss : 0.437172 model2 loss : 0.018546
[12:05:54.572] iteration 24460 : model1 loss : 0.437326 model2 loss : 0.021062
[12:05:54.740] iteration 24461 : model1 loss : 0.438273 model2 loss : 0.020471
[12:05:54.909] iteration 24462 : model1 loss : 0.444868 model2 loss : 0.022970
[12:05:55.077] iteration 24463 : model1 loss : 0.440342 model2 loss : 0.019773
[12:05:55.245] iteration 24464 : model1 loss : 0.436381 model2 loss : 0.018074
[12:05:55.413] iteration 24465 : model1 loss : 0.439114 model2 loss : 0.019652
[12:05:55.587] iteration 24466 : model1 loss : 0.439545 model2 loss : 0.021528
[12:05:55.754] iteration 24467 : model1 loss : 0.435351 model2 loss : 0.019205
[12:05:55.926] iteration 24468 : model1 loss : 0.437709 model2 loss : 0.018442
[12:05:56.094] iteration 24469 : model1 loss : 0.443400 model2 loss : 0.019425
[12:05:56.264] iteration 24470 : model1 loss : 0.439930 model2 loss : 0.020187
[12:05:56.431] iteration 24471 : model1 loss : 0.442197 model2 loss : 0.021091
[12:05:56.599] iteration 24472 : model1 loss : 0.437764 model2 loss : 0.020860
[12:05:56.767] iteration 24473 : model1 loss : 0.438519 model2 loss : 0.018454
[12:05:56.935] iteration 24474 : model1 loss : 0.442232 model2 loss : 0.020647
[12:05:57.102] iteration 24475 : model1 loss : 0.436929 model2 loss : 0.020443
[12:05:57.274] iteration 24476 : model1 loss : 0.436130 model2 loss : 0.017651
[12:05:57.440] iteration 24477 : model1 loss : 0.443483 model2 loss : 0.022994
[12:05:57.610] iteration 24478 : model1 loss : 0.442349 model2 loss : 0.021086
[12:05:57.779] iteration 24479 : model1 loss : 0.439307 model2 loss : 0.022879
[12:05:57.948] iteration 24480 : model1 loss : 0.440175 model2 loss : 0.019047
[12:05:58.117] iteration 24481 : model1 loss : 0.437940 model2 loss : 0.021165
[12:05:58.287] iteration 24482 : model1 loss : 0.438727 model2 loss : 0.019663
[12:05:58.455] iteration 24483 : model1 loss : 0.441451 model2 loss : 0.018896
[12:05:58.624] iteration 24484 : model1 loss : 0.436554 model2 loss : 0.017663
[12:05:58.790] iteration 24485 : model1 loss : 0.438885 model2 loss : 0.019387
[12:05:58.961] iteration 24486 : model1 loss : 0.442278 model2 loss : 0.020096
[12:06:00.927] iteration 24487 : model1 loss : 0.439551 model2 loss : 0.019951
[12:06:01.099] iteration 24488 : model1 loss : 0.439066 model2 loss : 0.018450
[12:06:01.269] iteration 24489 : model1 loss : 0.438894 model2 loss : 0.020900
[12:06:01.436] iteration 24490 : model1 loss : 0.437581 model2 loss : 0.020844
[12:06:01.606] iteration 24491 : model1 loss : 0.435396 model2 loss : 0.018075
[12:06:01.773] iteration 24492 : model1 loss : 0.442936 model2 loss : 0.016418
[12:06:01.943] iteration 24493 : model1 loss : 0.438194 model2 loss : 0.019390
[12:06:02.111] iteration 24494 : model1 loss : 0.441059 model2 loss : 0.020854
[12:06:02.280] iteration 24495 : model1 loss : 0.440071 model2 loss : 0.020368
[12:06:02.449] iteration 24496 : model1 loss : 0.436556 model2 loss : 0.019707
[12:06:02.618] iteration 24497 : model1 loss : 0.438984 model2 loss : 0.017701
[12:06:02.784] iteration 24498 : model1 loss : 0.439602 model2 loss : 0.018792
[12:06:02.953] iteration 24499 : model1 loss : 0.443143 model2 loss : 0.022337
[12:06:03.122] iteration 24500 : model1 loss : 0.433405 model2 loss : 0.017109
[12:06:03.293] iteration 24501 : model1 loss : 0.439720 model2 loss : 0.019932
[12:06:03.460] iteration 24502 : model1 loss : 0.439014 model2 loss : 0.021461
[12:06:03.630] iteration 24503 : model1 loss : 0.443296 model2 loss : 0.021929
[12:06:03.796] iteration 24504 : model1 loss : 0.440745 model2 loss : 0.019242
[12:06:03.965] iteration 24505 : model1 loss : 0.436618 model2 loss : 0.019640
[12:06:04.131] iteration 24506 : model1 loss : 0.444728 model2 loss : 0.020137
[12:06:04.301] iteration 24507 : model1 loss : 0.446040 model2 loss : 0.025336
[12:06:04.470] iteration 24508 : model1 loss : 0.433347 model2 loss : 0.019442
[12:06:04.640] iteration 24509 : model1 loss : 0.440481 model2 loss : 0.020155
[12:06:04.807] iteration 24510 : model1 loss : 0.440449 model2 loss : 0.020855
[12:06:04.975] iteration 24511 : model1 loss : 0.436788 model2 loss : 0.020924
[12:06:05.143] iteration 24512 : model1 loss : 0.438734 model2 loss : 0.019460
[12:06:05.312] iteration 24513 : model1 loss : 0.440125 model2 loss : 0.020008
[12:06:05.479] iteration 24514 : model1 loss : 0.443250 model2 loss : 0.019441
[12:06:05.648] iteration 24515 : model1 loss : 0.437080 model2 loss : 0.019276
[12:06:05.815] iteration 24516 : model1 loss : 0.441475 model2 loss : 0.020087
[12:06:05.985] iteration 24517 : model1 loss : 0.436873 model2 loss : 0.021336
[12:06:06.149] iteration 24518 : model1 loss : 0.441831 model2 loss : 0.021068
[12:06:06.318] iteration 24519 : model1 loss : 0.441881 model2 loss : 0.017458
[12:06:08.227] iteration 24520 : model1 loss : 0.438114 model2 loss : 0.021368
[12:06:08.394] iteration 24521 : model1 loss : 0.440349 model2 loss : 0.018107
[12:06:08.566] iteration 24522 : model1 loss : 0.436692 model2 loss : 0.018895
[12:06:08.733] iteration 24523 : model1 loss : 0.444611 model2 loss : 0.020091
[12:06:08.900] iteration 24524 : model1 loss : 0.437875 model2 loss : 0.019289
[12:06:09.068] iteration 24525 : model1 loss : 0.439713 model2 loss : 0.019451
[12:06:09.238] iteration 24526 : model1 loss : 0.444576 model2 loss : 0.022284
[12:06:09.408] iteration 24527 : model1 loss : 0.439269 model2 loss : 0.018905
[12:06:09.576] iteration 24528 : model1 loss : 0.443073 model2 loss : 0.019491
[12:06:09.741] iteration 24529 : model1 loss : 0.439032 model2 loss : 0.021120
[12:06:09.912] iteration 24530 : model1 loss : 0.438354 model2 loss : 0.020620
[12:06:10.080] iteration 24531 : model1 loss : 0.440726 model2 loss : 0.019553
[12:06:10.249] iteration 24532 : model1 loss : 0.438279 model2 loss : 0.019947
[12:06:10.418] iteration 24533 : model1 loss : 0.442715 model2 loss : 0.022636
[12:06:10.589] iteration 24534 : model1 loss : 0.438684 model2 loss : 0.019011
[12:06:10.755] iteration 24535 : model1 loss : 0.436157 model2 loss : 0.019076
[12:06:10.927] iteration 24536 : model1 loss : 0.436766 model2 loss : 0.019540
[12:06:11.095] iteration 24537 : model1 loss : 0.438658 model2 loss : 0.019650
[12:06:11.265] iteration 24538 : model1 loss : 0.439933 model2 loss : 0.019127
[12:06:11.435] iteration 24539 : model1 loss : 0.437252 model2 loss : 0.019362
[12:06:11.604] iteration 24540 : model1 loss : 0.442110 model2 loss : 0.017800
[12:06:11.771] iteration 24541 : model1 loss : 0.435993 model2 loss : 0.019944
[12:06:11.941] iteration 24542 : model1 loss : 0.440439 model2 loss : 0.022037
[12:06:12.108] iteration 24543 : model1 loss : 0.442997 model2 loss : 0.022496
[12:06:12.278] iteration 24544 : model1 loss : 0.443861 model2 loss : 0.023137
[12:06:12.448] iteration 24545 : model1 loss : 0.438510 model2 loss : 0.019148
[12:06:12.618] iteration 24546 : model1 loss : 0.438520 model2 loss : 0.019453
[12:06:12.784] iteration 24547 : model1 loss : 0.444342 model2 loss : 0.022125
[12:06:12.953] iteration 24548 : model1 loss : 0.440114 model2 loss : 0.020327
[12:06:13.121] iteration 24549 : model1 loss : 0.436690 model2 loss : 0.019961
[12:06:13.291] iteration 24550 : model1 loss : 0.440182 model2 loss : 0.020446
[12:06:13.474] iteration 24551 : model1 loss : 0.437528 model2 loss : 0.022878
[12:06:13.644] iteration 24552 : model1 loss : 0.435424 model2 loss : 0.018928
[12:06:15.545] iteration 24553 : model1 loss : 0.441248 model2 loss : 0.020983
[12:06:15.711] iteration 24554 : model1 loss : 0.441163 model2 loss : 0.019248
[12:06:15.882] iteration 24555 : model1 loss : 0.440330 model2 loss : 0.021893
[12:06:16.048] iteration 24556 : model1 loss : 0.444038 model2 loss : 0.021406
[12:06:16.216] iteration 24557 : model1 loss : 0.432266 model2 loss : 0.017639
[12:06:16.382] iteration 24558 : model1 loss : 0.439511 model2 loss : 0.021275
[12:06:16.552] iteration 24559 : model1 loss : 0.436631 model2 loss : 0.018723
[12:06:16.717] iteration 24560 : model1 loss : 0.439872 model2 loss : 0.019537
[12:06:16.888] iteration 24561 : model1 loss : 0.440097 model2 loss : 0.018703
[12:06:17.056] iteration 24562 : model1 loss : 0.440903 model2 loss : 0.019799
[12:06:17.224] iteration 24563 : model1 loss : 0.439210 model2 loss : 0.021076
[12:06:17.391] iteration 24564 : model1 loss : 0.439154 model2 loss : 0.017617
[12:06:17.559] iteration 24565 : model1 loss : 0.437883 model2 loss : 0.019464
[12:06:17.740] iteration 24566 : model1 loss : 0.436582 model2 loss : 0.017763
[12:06:17.909] iteration 24567 : model1 loss : 0.441813 model2 loss : 0.021184
[12:06:18.076] iteration 24568 : model1 loss : 0.436261 model2 loss : 0.019103
[12:06:18.247] iteration 24569 : model1 loss : 0.439699 model2 loss : 0.020205
[12:06:18.414] iteration 24570 : model1 loss : 0.435145 model2 loss : 0.018025
[12:06:18.583] iteration 24571 : model1 loss : 0.442041 model2 loss : 0.022817
[12:06:18.750] iteration 24572 : model1 loss : 0.439953 model2 loss : 0.020914
[12:06:18.918] iteration 24573 : model1 loss : 0.439303 model2 loss : 0.018853
[12:06:19.085] iteration 24574 : model1 loss : 0.440518 model2 loss : 0.019654
[12:06:19.255] iteration 24575 : model1 loss : 0.440716 model2 loss : 0.017501
[12:06:19.423] iteration 24576 : model1 loss : 0.439812 model2 loss : 0.019304
[12:06:19.591] iteration 24577 : model1 loss : 0.437974 model2 loss : 0.019788
[12:06:19.759] iteration 24578 : model1 loss : 0.447297 model2 loss : 0.022916
[12:06:19.928] iteration 24579 : model1 loss : 0.439932 model2 loss : 0.018630
[12:06:20.095] iteration 24580 : model1 loss : 0.442678 model2 loss : 0.021485
[12:06:20.265] iteration 24581 : model1 loss : 0.435143 model2 loss : 0.018696
[12:06:20.433] iteration 24582 : model1 loss : 0.440990 model2 loss : 0.019219
[12:06:20.601] iteration 24583 : model1 loss : 0.437040 model2 loss : 0.020215
[12:06:20.766] iteration 24584 : model1 loss : 0.439434 model2 loss : 0.019973
[12:06:20.940] iteration 24585 : model1 loss : 0.439194 model2 loss : 0.020926
[12:06:22.864] iteration 24586 : model1 loss : 0.441148 model2 loss : 0.021541
[12:06:23.033] iteration 24587 : model1 loss : 0.441121 model2 loss : 0.018092
[12:06:23.202] iteration 24588 : model1 loss : 0.437683 model2 loss : 0.019977
[12:06:23.370] iteration 24589 : model1 loss : 0.437071 model2 loss : 0.017411
[12:06:23.539] iteration 24590 : model1 loss : 0.439562 model2 loss : 0.016433
[12:06:23.707] iteration 24591 : model1 loss : 0.440479 model2 loss : 0.017462
[12:06:23.876] iteration 24592 : model1 loss : 0.436605 model2 loss : 0.020672
[12:06:24.042] iteration 24593 : model1 loss : 0.439064 model2 loss : 0.022751
[12:06:24.211] iteration 24594 : model1 loss : 0.439901 model2 loss : 0.019210
[12:06:24.378] iteration 24595 : model1 loss : 0.436649 model2 loss : 0.019430
[12:06:24.550] iteration 24596 : model1 loss : 0.437222 model2 loss : 0.018805
[12:06:24.716] iteration 24597 : model1 loss : 0.439809 model2 loss : 0.018110
[12:06:24.883] iteration 24598 : model1 loss : 0.441795 model2 loss : 0.021446
[12:06:25.051] iteration 24599 : model1 loss : 0.437983 model2 loss : 0.019653
[12:06:25.222] iteration 24600 : model1 loss : 0.441810 model2 loss : 0.020638
[12:06:25.392] iteration 24601 : model1 loss : 0.437723 model2 loss : 0.019918
[12:06:25.560] iteration 24602 : model1 loss : 0.437408 model2 loss : 0.018514
[12:06:25.725] iteration 24603 : model1 loss : 0.440734 model2 loss : 0.022017
[12:06:25.897] iteration 24604 : model1 loss : 0.435788 model2 loss : 0.019626
[12:06:26.063] iteration 24605 : model1 loss : 0.440009 model2 loss : 0.020459
[12:06:26.233] iteration 24606 : model1 loss : 0.443254 model2 loss : 0.020071
[12:06:26.402] iteration 24607 : model1 loss : 0.441112 model2 loss : 0.019213
[12:06:26.571] iteration 24608 : model1 loss : 0.439195 model2 loss : 0.019483
[12:06:26.737] iteration 24609 : model1 loss : 0.440338 model2 loss : 0.022470
[12:06:26.906] iteration 24610 : model1 loss : 0.440320 model2 loss : 0.020442
[12:06:27.073] iteration 24611 : model1 loss : 0.436413 model2 loss : 0.021839
[12:06:27.241] iteration 24612 : model1 loss : 0.443509 model2 loss : 0.019567
[12:06:27.415] iteration 24613 : model1 loss : 0.439110 model2 loss : 0.020789
[12:06:27.587] iteration 24614 : model1 loss : 0.445200 model2 loss : 0.022027
[12:06:27.755] iteration 24615 : model1 loss : 0.442777 model2 loss : 0.019630
[12:06:27.924] iteration 24616 : model1 loss : 0.435768 model2 loss : 0.019265
[12:06:28.091] iteration 24617 : model1 loss : 0.442245 model2 loss : 0.019407
[12:06:28.260] iteration 24618 : model1 loss : 0.439839 model2 loss : 0.018237
[12:06:30.208] iteration 24619 : model1 loss : 0.436856 model2 loss : 0.020308
[12:06:30.378] iteration 24620 : model1 loss : 0.439945 model2 loss : 0.017890
[12:06:30.549] iteration 24621 : model1 loss : 0.439546 model2 loss : 0.019260
[12:06:30.716] iteration 24622 : model1 loss : 0.436780 model2 loss : 0.020450
[12:06:30.886] iteration 24623 : model1 loss : 0.437974 model2 loss : 0.016916
[12:06:31.054] iteration 24624 : model1 loss : 0.443705 model2 loss : 0.019652
[12:06:31.224] iteration 24625 : model1 loss : 0.442204 model2 loss : 0.019337
[12:06:31.394] iteration 24626 : model1 loss : 0.439590 model2 loss : 0.020602
[12:06:31.564] iteration 24627 : model1 loss : 0.438344 model2 loss : 0.020534
[12:06:31.732] iteration 24628 : model1 loss : 0.441630 model2 loss : 0.021744
[12:06:31.900] iteration 24629 : model1 loss : 0.440660 model2 loss : 0.021084
[12:06:32.066] iteration 24630 : model1 loss : 0.441797 model2 loss : 0.021557
[12:06:32.236] iteration 24631 : model1 loss : 0.439492 model2 loss : 0.019342
[12:06:32.405] iteration 24632 : model1 loss : 0.439647 model2 loss : 0.021024
[12:06:32.573] iteration 24633 : model1 loss : 0.440990 model2 loss : 0.019411
[12:06:32.741] iteration 24634 : model1 loss : 0.437228 model2 loss : 0.020474
[12:06:32.909] iteration 24635 : model1 loss : 0.439043 model2 loss : 0.020686
[12:06:33.078] iteration 24636 : model1 loss : 0.432651 model2 loss : 0.018030
[12:06:33.247] iteration 24637 : model1 loss : 0.437970 model2 loss : 0.017435
[12:06:33.416] iteration 24638 : model1 loss : 0.442112 model2 loss : 0.022191
[12:06:33.586] iteration 24639 : model1 loss : 0.445183 model2 loss : 0.022994
[12:06:33.751] iteration 24640 : model1 loss : 0.439778 model2 loss : 0.020710
[12:06:33.920] iteration 24641 : model1 loss : 0.441717 model2 loss : 0.019818
[12:06:34.088] iteration 24642 : model1 loss : 0.440526 model2 loss : 0.021198
[12:06:34.261] iteration 24643 : model1 loss : 0.438201 model2 loss : 0.019750
[12:06:34.427] iteration 24644 : model1 loss : 0.438044 model2 loss : 0.021042
[12:06:34.598] iteration 24645 : model1 loss : 0.442157 model2 loss : 0.021286
[12:06:34.765] iteration 24646 : model1 loss : 0.438855 model2 loss : 0.019886
[12:06:34.938] iteration 24647 : model1 loss : 0.441605 model2 loss : 0.020330
[12:06:35.107] iteration 24648 : model1 loss : 0.438303 model2 loss : 0.018408
[12:06:35.276] iteration 24649 : model1 loss : 0.434686 model2 loss : 0.018969
[12:06:35.442] iteration 24650 : model1 loss : 0.436968 model2 loss : 0.019471
[12:06:35.609] iteration 24651 : model1 loss : 0.442717 model2 loss : 0.020405
[12:06:37.541] iteration 24652 : model1 loss : 0.440146 model2 loss : 0.020367
[12:06:37.713] iteration 24653 : model1 loss : 0.438602 model2 loss : 0.022355
[12:06:37.884] iteration 24654 : model1 loss : 0.443111 model2 loss : 0.020875
[12:06:38.050] iteration 24655 : model1 loss : 0.439412 model2 loss : 0.021396
[12:06:38.218] iteration 24656 : model1 loss : 0.436667 model2 loss : 0.018832
[12:06:38.385] iteration 24657 : model1 loss : 0.437676 model2 loss : 0.019093
[12:06:38.558] iteration 24658 : model1 loss : 0.442405 model2 loss : 0.021913
[12:06:38.726] iteration 24659 : model1 loss : 0.443010 model2 loss : 0.019375
[12:06:38.893] iteration 24660 : model1 loss : 0.442604 model2 loss : 0.019039
[12:06:39.059] iteration 24661 : model1 loss : 0.439248 model2 loss : 0.018746
[12:06:39.229] iteration 24662 : model1 loss : 0.439224 model2 loss : 0.019304
[12:06:39.395] iteration 24663 : model1 loss : 0.439020 model2 loss : 0.017887
[12:06:39.565] iteration 24664 : model1 loss : 0.442286 model2 loss : 0.019038
[12:06:39.731] iteration 24665 : model1 loss : 0.438596 model2 loss : 0.021579
[12:06:39.902] iteration 24666 : model1 loss : 0.437335 model2 loss : 0.021983
[12:06:40.068] iteration 24667 : model1 loss : 0.435535 model2 loss : 0.018887
[12:06:40.236] iteration 24668 : model1 loss : 0.439049 model2 loss : 0.019622
[12:06:40.404] iteration 24669 : model1 loss : 0.445274 model2 loss : 0.020683
[12:06:40.576] iteration 24670 : model1 loss : 0.441520 model2 loss : 0.021737
[12:06:40.743] iteration 24671 : model1 loss : 0.438489 model2 loss : 0.020787
[12:06:40.914] iteration 24672 : model1 loss : 0.439069 model2 loss : 0.019570
[12:06:41.080] iteration 24673 : model1 loss : 0.437090 model2 loss : 0.021162
[12:06:41.249] iteration 24674 : model1 loss : 0.438664 model2 loss : 0.018542
[12:06:41.416] iteration 24675 : model1 loss : 0.441810 model2 loss : 0.019251
[12:06:41.586] iteration 24676 : model1 loss : 0.439881 model2 loss : 0.019031
[12:06:41.754] iteration 24677 : model1 loss : 0.441286 model2 loss : 0.022349
[12:06:41.923] iteration 24678 : model1 loss : 0.441883 model2 loss : 0.020353
[12:06:42.091] iteration 24679 : model1 loss : 0.441001 model2 loss : 0.021538
[12:06:42.262] iteration 24680 : model1 loss : 0.437850 model2 loss : 0.019515
[12:06:42.430] iteration 24681 : model1 loss : 0.439255 model2 loss : 0.021380
[12:06:42.599] iteration 24682 : model1 loss : 0.438446 model2 loss : 0.018947
[12:06:42.765] iteration 24683 : model1 loss : 0.437064 model2 loss : 0.017672
[12:06:42.933] iteration 24684 : model1 loss : 0.436522 model2 loss : 0.017367
[12:06:44.862] iteration 24685 : model1 loss : 0.442785 model2 loss : 0.020653
[12:06:45.030] iteration 24686 : model1 loss : 0.436320 model2 loss : 0.018212
[12:06:45.201] iteration 24687 : model1 loss : 0.441060 model2 loss : 0.021615
[12:06:45.370] iteration 24688 : model1 loss : 0.439832 model2 loss : 0.018586
[12:06:45.546] iteration 24689 : model1 loss : 0.443257 model2 loss : 0.021705
[12:06:45.714] iteration 24690 : model1 loss : 0.441315 model2 loss : 0.016152
[12:06:45.885] iteration 24691 : model1 loss : 0.437804 model2 loss : 0.019800
[12:06:46.054] iteration 24692 : model1 loss : 0.437263 model2 loss : 0.019190
[12:06:46.223] iteration 24693 : model1 loss : 0.441734 model2 loss : 0.019861
[12:06:46.390] iteration 24694 : model1 loss : 0.443593 model2 loss : 0.020704
[12:06:46.572] iteration 24695 : model1 loss : 0.442487 model2 loss : 0.021430
[12:06:46.739] iteration 24696 : model1 loss : 0.442129 model2 loss : 0.022471
[12:06:46.908] iteration 24697 : model1 loss : 0.438854 model2 loss : 0.018737
[12:06:47.075] iteration 24698 : model1 loss : 0.443996 model2 loss : 0.026773
[12:06:47.245] iteration 24699 : model1 loss : 0.438489 model2 loss : 0.020323
[12:06:47.413] iteration 24700 : model1 loss : 0.439806 model2 loss : 0.019183
[12:06:47.584] iteration 24701 : model1 loss : 0.437852 model2 loss : 0.018905
[12:06:47.751] iteration 24702 : model1 loss : 0.436413 model2 loss : 0.021389
[12:06:47.921] iteration 24703 : model1 loss : 0.436877 model2 loss : 0.020174
[12:06:48.090] iteration 24704 : model1 loss : 0.434022 model2 loss : 0.020849
[12:06:48.258] iteration 24705 : model1 loss : 0.439989 model2 loss : 0.023027
[12:06:48.426] iteration 24706 : model1 loss : 0.438943 model2 loss : 0.019968
[12:06:48.598] iteration 24707 : model1 loss : 0.440123 model2 loss : 0.020204
[12:06:48.766] iteration 24708 : model1 loss : 0.440773 model2 loss : 0.020364
[12:06:48.934] iteration 24709 : model1 loss : 0.441647 model2 loss : 0.022329
[12:06:49.102] iteration 24710 : model1 loss : 0.436192 model2 loss : 0.019932
[12:06:49.272] iteration 24711 : model1 loss : 0.443109 model2 loss : 0.023907
[12:06:49.438] iteration 24712 : model1 loss : 0.440440 model2 loss : 0.021697
[12:06:49.610] iteration 24713 : model1 loss : 0.439749 model2 loss : 0.020741
[12:06:49.778] iteration 24714 : model1 loss : 0.435690 model2 loss : 0.018168
[12:06:49.946] iteration 24715 : model1 loss : 0.439324 model2 loss : 0.018935
[12:06:50.112] iteration 24716 : model1 loss : 0.438358 model2 loss : 0.020078
[12:06:50.281] iteration 24717 : model1 loss : 0.441863 model2 loss : 0.020644
[12:06:52.246] iteration 24718 : model1 loss : 0.443573 model2 loss : 0.022175
[12:06:52.414] iteration 24719 : model1 loss : 0.437757 model2 loss : 0.018623
[12:06:52.588] iteration 24720 : model1 loss : 0.442118 model2 loss : 0.021126
[12:06:52.755] iteration 24721 : model1 loss : 0.441765 model2 loss : 0.021376
[12:06:52.924] iteration 24722 : model1 loss : 0.437874 model2 loss : 0.018220
[12:06:53.091] iteration 24723 : model1 loss : 0.439737 model2 loss : 0.019880
[12:06:53.258] iteration 24724 : model1 loss : 0.444100 model2 loss : 0.022031
[12:06:53.426] iteration 24725 : model1 loss : 0.436209 model2 loss : 0.018295
[12:06:53.596] iteration 24726 : model1 loss : 0.441539 model2 loss : 0.020531
[12:06:53.763] iteration 24727 : model1 loss : 0.440898 model2 loss : 0.020498
[12:06:53.932] iteration 24728 : model1 loss : 0.436142 model2 loss : 0.020105
[12:06:54.100] iteration 24729 : model1 loss : 0.433384 model2 loss : 0.018934
[12:06:54.271] iteration 24730 : model1 loss : 0.439906 model2 loss : 0.018937
[12:06:54.439] iteration 24731 : model1 loss : 0.439912 model2 loss : 0.019828
[12:06:54.608] iteration 24732 : model1 loss : 0.442871 model2 loss : 0.020649
[12:06:54.776] iteration 24733 : model1 loss : 0.436610 model2 loss : 0.021420
[12:06:54.944] iteration 24734 : model1 loss : 0.441147 model2 loss : 0.020021
[12:06:55.111] iteration 24735 : model1 loss : 0.440245 model2 loss : 0.018751
[12:06:55.282] iteration 24736 : model1 loss : 0.437846 model2 loss : 0.019630
[12:06:55.450] iteration 24737 : model1 loss : 0.442058 model2 loss : 0.017999
[12:06:55.619] iteration 24738 : model1 loss : 0.433512 model2 loss : 0.019647
[12:06:55.785] iteration 24739 : model1 loss : 0.435072 model2 loss : 0.016805
[12:06:55.956] iteration 24740 : model1 loss : 0.437881 model2 loss : 0.020531
[12:06:56.123] iteration 24741 : model1 loss : 0.439929 model2 loss : 0.021737
[12:06:56.294] iteration 24742 : model1 loss : 0.444506 model2 loss : 0.019285
[12:06:56.460] iteration 24743 : model1 loss : 0.442377 model2 loss : 0.023773
[12:06:56.629] iteration 24744 : model1 loss : 0.436333 model2 loss : 0.022351
[12:06:56.797] iteration 24745 : model1 loss : 0.439041 model2 loss : 0.019413
[12:06:56.966] iteration 24746 : model1 loss : 0.441460 model2 loss : 0.019310
[12:06:57.133] iteration 24747 : model1 loss : 0.440116 model2 loss : 0.020855
[12:06:57.302] iteration 24748 : model1 loss : 0.438943 model2 loss : 0.019924
[12:06:57.466] iteration 24749 : model1 loss : 0.442021 model2 loss : 0.017232
[12:06:57.634] iteration 24750 : model1 loss : 0.441293 model2 loss : 0.020671
[12:06:59.575] iteration 24751 : model1 loss : 0.433783 model2 loss : 0.018469
[12:06:59.742] iteration 24752 : model1 loss : 0.443367 model2 loss : 0.021656
[12:06:59.912] iteration 24753 : model1 loss : 0.437266 model2 loss : 0.019350
[12:07:00.078] iteration 24754 : model1 loss : 0.437121 model2 loss : 0.020370
[12:07:00.248] iteration 24755 : model1 loss : 0.440793 model2 loss : 0.019105
[12:07:00.418] iteration 24756 : model1 loss : 0.444090 model2 loss : 0.023096
[12:07:00.586] iteration 24757 : model1 loss : 0.444663 model2 loss : 0.019452
[12:07:00.753] iteration 24758 : model1 loss : 0.436650 model2 loss : 0.018168
[12:07:00.925] iteration 24759 : model1 loss : 0.435998 model2 loss : 0.018856
[12:07:01.091] iteration 24760 : model1 loss : 0.439316 model2 loss : 0.020431
[12:07:01.260] iteration 24761 : model1 loss : 0.441540 model2 loss : 0.021247
[12:07:01.428] iteration 24762 : model1 loss : 0.438572 model2 loss : 0.020629
[12:07:01.600] iteration 24763 : model1 loss : 0.442426 model2 loss : 0.021358
[12:07:01.766] iteration 24764 : model1 loss : 0.440615 model2 loss : 0.020593
[12:07:01.935] iteration 24765 : model1 loss : 0.444591 model2 loss : 0.019818
[12:07:02.102] iteration 24766 : model1 loss : 0.440530 model2 loss : 0.020638
[12:07:02.272] iteration 24767 : model1 loss : 0.438187 model2 loss : 0.018555
[12:07:02.439] iteration 24768 : model1 loss : 0.442580 model2 loss : 0.020669
[12:07:02.611] iteration 24769 : model1 loss : 0.440835 model2 loss : 0.020127
[12:07:02.778] iteration 24770 : model1 loss : 0.436702 model2 loss : 0.019792
[12:07:02.947] iteration 24771 : model1 loss : 0.438230 model2 loss : 0.019552
[12:07:03.115] iteration 24772 : model1 loss : 0.438686 model2 loss : 0.019271
[12:07:03.284] iteration 24773 : model1 loss : 0.437502 model2 loss : 0.018883
[12:07:03.452] iteration 24774 : model1 loss : 0.442769 model2 loss : 0.021300
[12:07:03.624] iteration 24775 : model1 loss : 0.439716 model2 loss : 0.019115
[12:07:03.791] iteration 24776 : model1 loss : 0.435954 model2 loss : 0.018839
[12:07:03.960] iteration 24777 : model1 loss : 0.438977 model2 loss : 0.020172
[12:07:04.128] iteration 24778 : model1 loss : 0.443338 model2 loss : 0.021048
[12:07:04.298] iteration 24779 : model1 loss : 0.438593 model2 loss : 0.019195
[12:07:04.465] iteration 24780 : model1 loss : 0.440014 model2 loss : 0.020977
[12:07:04.636] iteration 24781 : model1 loss : 0.435694 model2 loss : 0.019477
[12:07:04.802] iteration 24782 : model1 loss : 0.441756 model2 loss : 0.020962
[12:07:04.970] iteration 24783 : model1 loss : 0.435281 model2 loss : 0.017604
[12:07:06.902] iteration 24784 : model1 loss : 0.438169 model2 loss : 0.018655
[12:07:07.071] iteration 24785 : model1 loss : 0.441246 model2 loss : 0.020817
[12:07:07.241] iteration 24786 : model1 loss : 0.441517 model2 loss : 0.020160
[12:07:07.415] iteration 24787 : model1 loss : 0.437503 model2 loss : 0.019993
[12:07:07.589] iteration 24788 : model1 loss : 0.441463 model2 loss : 0.018036
[12:07:07.755] iteration 24789 : model1 loss : 0.443387 model2 loss : 0.021698
[12:07:07.922] iteration 24790 : model1 loss : 0.444749 model2 loss : 0.022615
[12:07:08.088] iteration 24791 : model1 loss : 0.442691 model2 loss : 0.021573
[12:07:08.260] iteration 24792 : model1 loss : 0.440523 model2 loss : 0.020256
[12:07:08.428] iteration 24793 : model1 loss : 0.443917 model2 loss : 0.019974
[12:07:08.599] iteration 24794 : model1 loss : 0.437300 model2 loss : 0.019487
[12:07:08.766] iteration 24795 : model1 loss : 0.440181 model2 loss : 0.020079
[12:07:08.936] iteration 24796 : model1 loss : 0.441000 model2 loss : 0.020390
[12:07:09.105] iteration 24797 : model1 loss : 0.438119 model2 loss : 0.018111
[12:07:09.275] iteration 24798 : model1 loss : 0.440287 model2 loss : 0.020192
[12:07:09.444] iteration 24799 : model1 loss : 0.434896 model2 loss : 0.017637
[12:07:09.618] iteration 24800 : model1 loss : 0.436553 model2 loss : 0.017191
[12:07:09.785] iteration 24801 : model1 loss : 0.436956 model2 loss : 0.019484
[12:07:09.956] iteration 24802 : model1 loss : 0.440373 model2 loss : 0.021371
[12:07:10.124] iteration 24803 : model1 loss : 0.439110 model2 loss : 0.018655
[12:07:10.293] iteration 24804 : model1 loss : 0.438194 model2 loss : 0.021489
[12:07:10.462] iteration 24805 : model1 loss : 0.438149 model2 loss : 0.017761
[12:07:10.634] iteration 24806 : model1 loss : 0.444999 model2 loss : 0.025100
[12:07:10.799] iteration 24807 : model1 loss : 0.439351 model2 loss : 0.019699
[12:07:10.973] iteration 24808 : model1 loss : 0.437712 model2 loss : 0.022793
[12:07:11.140] iteration 24809 : model1 loss : 0.438516 model2 loss : 0.019619
[12:07:11.309] iteration 24810 : model1 loss : 0.436790 model2 loss : 0.019598
[12:07:11.475] iteration 24811 : model1 loss : 0.437857 model2 loss : 0.020565
[12:07:11.647] iteration 24812 : model1 loss : 0.437943 model2 loss : 0.021793
[12:07:11.815] iteration 24813 : model1 loss : 0.442200 model2 loss : 0.019699
[12:07:11.983] iteration 24814 : model1 loss : 0.440084 model2 loss : 0.019319
[12:07:12.149] iteration 24815 : model1 loss : 0.437102 model2 loss : 0.020189
[12:07:12.318] iteration 24816 : model1 loss : 0.442042 model2 loss : 0.020808
[12:07:14.268] iteration 24817 : model1 loss : 0.440814 model2 loss : 0.021017
[12:07:14.434] iteration 24818 : model1 loss : 0.441986 model2 loss : 0.019871
[12:07:14.603] iteration 24819 : model1 loss : 0.440298 model2 loss : 0.019998
[12:07:14.770] iteration 24820 : model1 loss : 0.439795 model2 loss : 0.019200
[12:07:14.940] iteration 24821 : model1 loss : 0.444909 model2 loss : 0.022466
[12:07:15.108] iteration 24822 : model1 loss : 0.441007 model2 loss : 0.020010
[12:07:15.277] iteration 24823 : model1 loss : 0.443267 model2 loss : 0.022085
[12:07:15.444] iteration 24824 : model1 loss : 0.435516 model2 loss : 0.019585
[12:07:15.613] iteration 24825 : model1 loss : 0.439284 model2 loss : 0.017680
[12:07:15.780] iteration 24826 : model1 loss : 0.439316 model2 loss : 0.019166
[12:07:15.953] iteration 24827 : model1 loss : 0.437439 model2 loss : 0.018400
[12:07:16.121] iteration 24828 : model1 loss : 0.438108 model2 loss : 0.017244
[12:07:16.290] iteration 24829 : model1 loss : 0.439288 model2 loss : 0.017819
[12:07:16.456] iteration 24830 : model1 loss : 0.439476 model2 loss : 0.020740
[12:07:16.625] iteration 24831 : model1 loss : 0.445150 model2 loss : 0.022545
[12:07:16.793] iteration 24832 : model1 loss : 0.439284 model2 loss : 0.019797
[12:07:16.961] iteration 24833 : model1 loss : 0.441514 model2 loss : 0.021816
[12:07:17.128] iteration 24834 : model1 loss : 0.436496 model2 loss : 0.021266
[12:07:17.297] iteration 24835 : model1 loss : 0.437440 model2 loss : 0.019376
[12:07:17.465] iteration 24836 : model1 loss : 0.440828 model2 loss : 0.020304
[12:07:17.636] iteration 24837 : model1 loss : 0.436109 model2 loss : 0.018670
[12:07:17.804] iteration 24838 : model1 loss : 0.438101 model2 loss : 0.018380
[12:07:17.983] iteration 24839 : model1 loss : 0.434522 model2 loss : 0.020391
[12:07:18.150] iteration 24840 : model1 loss : 0.442852 model2 loss : 0.018809
[12:07:18.320] iteration 24841 : model1 loss : 0.435562 model2 loss : 0.017107
[12:07:18.488] iteration 24842 : model1 loss : 0.440140 model2 loss : 0.019462
[12:07:18.663] iteration 24843 : model1 loss : 0.435541 model2 loss : 0.017514
[12:07:18.830] iteration 24844 : model1 loss : 0.438348 model2 loss : 0.019682
[12:07:18.999] iteration 24845 : model1 loss : 0.437074 model2 loss : 0.019617
[12:07:19.166] iteration 24846 : model1 loss : 0.441833 model2 loss : 0.022808
[12:07:19.335] iteration 24847 : model1 loss : 0.443185 model2 loss : 0.020956
[12:07:19.502] iteration 24848 : model1 loss : 0.441202 model2 loss : 0.018337
[12:07:19.670] iteration 24849 : model1 loss : 0.445692 model2 loss : 0.022482
[12:07:21.603] iteration 24850 : model1 loss : 0.439882 model2 loss : 0.020480
[12:07:21.771] iteration 24851 : model1 loss : 0.440442 model2 loss : 0.021239
[12:07:21.939] iteration 24852 : model1 loss : 0.440876 model2 loss : 0.023013
[12:07:22.124] iteration 24853 : model1 loss : 0.440500 model2 loss : 0.019655
[12:07:22.291] iteration 24854 : model1 loss : 0.439334 model2 loss : 0.018483
[12:07:22.458] iteration 24855 : model1 loss : 0.440384 model2 loss : 0.020563
[12:07:22.629] iteration 24856 : model1 loss : 0.438465 model2 loss : 0.018011
[12:07:22.795] iteration 24857 : model1 loss : 0.436699 model2 loss : 0.019859
[12:07:22.966] iteration 24858 : model1 loss : 0.438744 model2 loss : 0.019387
[12:07:23.132] iteration 24859 : model1 loss : 0.442124 model2 loss : 0.020122
[12:07:23.301] iteration 24860 : model1 loss : 0.440244 model2 loss : 0.019441
[12:07:23.467] iteration 24861 : model1 loss : 0.442012 model2 loss : 0.022370
[12:07:23.638] iteration 24862 : model1 loss : 0.441213 model2 loss : 0.020475
[12:07:23.804] iteration 24863 : model1 loss : 0.437728 model2 loss : 0.018047
[12:07:23.977] iteration 24864 : model1 loss : 0.435911 model2 loss : 0.018164
[12:07:24.147] iteration 24865 : model1 loss : 0.437572 model2 loss : 0.018898
[12:07:24.316] iteration 24866 : model1 loss : 0.441565 model2 loss : 0.020993
[12:07:24.482] iteration 24867 : model1 loss : 0.440729 model2 loss : 0.022216
[12:07:24.655] iteration 24868 : model1 loss : 0.437489 model2 loss : 0.016917
[12:07:24.821] iteration 24869 : model1 loss : 0.440989 model2 loss : 0.019780
[12:07:24.989] iteration 24870 : model1 loss : 0.440642 model2 loss : 0.021912
[12:07:25.159] iteration 24871 : model1 loss : 0.438099 model2 loss : 0.022422
[12:07:25.328] iteration 24872 : model1 loss : 0.436848 model2 loss : 0.020166
[12:07:25.494] iteration 24873 : model1 loss : 0.441832 model2 loss : 0.019773
[12:07:25.667] iteration 24874 : model1 loss : 0.438319 model2 loss : 0.022009
[12:07:25.834] iteration 24875 : model1 loss : 0.439335 model2 loss : 0.021092
[12:07:26.001] iteration 24876 : model1 loss : 0.436106 model2 loss : 0.019407
[12:07:26.170] iteration 24877 : model1 loss : 0.440078 model2 loss : 0.019874
[12:07:26.340] iteration 24878 : model1 loss : 0.443052 model2 loss : 0.023125
[12:07:26.510] iteration 24879 : model1 loss : 0.441277 model2 loss : 0.020397
[12:07:26.684] iteration 24880 : model1 loss : 0.442449 model2 loss : 0.022586
[12:07:26.850] iteration 24881 : model1 loss : 0.439714 model2 loss : 0.018891
[12:07:27.017] iteration 24882 : model1 loss : 0.437616 model2 loss : 0.018412
[12:07:28.936] iteration 24883 : model1 loss : 0.440568 model2 loss : 0.018317
[12:07:29.101] iteration 24884 : model1 loss : 0.437673 model2 loss : 0.019971
[12:07:29.272] iteration 24885 : model1 loss : 0.442154 model2 loss : 0.022998
[12:07:29.439] iteration 24886 : model1 loss : 0.438717 model2 loss : 0.019316
[12:07:29.609] iteration 24887 : model1 loss : 0.441160 model2 loss : 0.020472
[12:07:29.776] iteration 24888 : model1 loss : 0.444686 model2 loss : 0.023603
[12:07:29.945] iteration 24889 : model1 loss : 0.435982 model2 loss : 0.019175
[12:07:30.112] iteration 24890 : model1 loss : 0.441615 model2 loss : 0.019155
[12:07:30.280] iteration 24891 : model1 loss : 0.438882 model2 loss : 0.020440
[12:07:30.448] iteration 24892 : model1 loss : 0.435832 model2 loss : 0.020563
[12:07:30.618] iteration 24893 : model1 loss : 0.443618 model2 loss : 0.019725
[12:07:30.785] iteration 24894 : model1 loss : 0.439789 model2 loss : 0.018748
[12:07:30.956] iteration 24895 : model1 loss : 0.438323 model2 loss : 0.019740
[12:07:31.122] iteration 24896 : model1 loss : 0.439813 model2 loss : 0.022294
[12:07:31.292] iteration 24897 : model1 loss : 0.439492 model2 loss : 0.019802
[12:07:31.459] iteration 24898 : model1 loss : 0.438814 model2 loss : 0.018020
[12:07:31.631] iteration 24899 : model1 loss : 0.439881 model2 loss : 0.018713
[12:07:31.797] iteration 24900 : model1 loss : 0.439134 model2 loss : 0.022271
[12:07:31.967] iteration 24901 : model1 loss : 0.438228 model2 loss : 0.018630
[12:07:32.133] iteration 24902 : model1 loss : 0.438406 model2 loss : 0.018358
[12:07:32.325] iteration 24903 : model1 loss : 0.439696 model2 loss : 0.019502
[12:07:32.495] iteration 24904 : model1 loss : 0.437802 model2 loss : 0.020250
[12:07:32.667] iteration 24905 : model1 loss : 0.437857 model2 loss : 0.018889
[12:07:32.834] iteration 24906 : model1 loss : 0.438837 model2 loss : 0.021492
[12:07:33.002] iteration 24907 : model1 loss : 0.439505 model2 loss : 0.022767
[12:07:33.169] iteration 24908 : model1 loss : 0.440470 model2 loss : 0.020589
[12:07:33.339] iteration 24909 : model1 loss : 0.440876 model2 loss : 0.020587
[12:07:33.508] iteration 24910 : model1 loss : 0.438735 model2 loss : 0.020411
[12:07:33.682] iteration 24911 : model1 loss : 0.438635 model2 loss : 0.018107
[12:07:33.849] iteration 24912 : model1 loss : 0.441873 model2 loss : 0.020593
[12:07:34.016] iteration 24913 : model1 loss : 0.441056 model2 loss : 0.019068
[12:07:34.182] iteration 24914 : model1 loss : 0.441398 model2 loss : 0.020582
[12:07:34.349] iteration 24915 : model1 loss : 0.435578 model2 loss : 0.020043
[12:07:36.284] iteration 24916 : model1 loss : 0.436343 model2 loss : 0.019488
[12:07:36.450] iteration 24917 : model1 loss : 0.442643 model2 loss : 0.020803
[12:07:36.620] iteration 24918 : model1 loss : 0.442621 model2 loss : 0.022045
[12:07:36.787] iteration 24919 : model1 loss : 0.436560 model2 loss : 0.021151
[12:07:36.956] iteration 24920 : model1 loss : 0.437643 model2 loss : 0.019203
[12:07:37.124] iteration 24921 : model1 loss : 0.440995 model2 loss : 0.021393
[12:07:37.292] iteration 24922 : model1 loss : 0.442095 model2 loss : 0.019443
[12:07:37.459] iteration 24923 : model1 loss : 0.437555 model2 loss : 0.019988
[12:07:37.630] iteration 24924 : model1 loss : 0.437432 model2 loss : 0.019859
[12:07:37.798] iteration 24925 : model1 loss : 0.438732 model2 loss : 0.020914
[12:07:37.966] iteration 24926 : model1 loss : 0.438170 model2 loss : 0.019334
[12:07:38.133] iteration 24927 : model1 loss : 0.439332 model2 loss : 0.020902
[12:07:38.301] iteration 24928 : model1 loss : 0.444262 model2 loss : 0.022760
[12:07:38.468] iteration 24929 : model1 loss : 0.439429 model2 loss : 0.020939
[12:07:38.639] iteration 24930 : model1 loss : 0.439010 model2 loss : 0.020467
[12:07:38.809] iteration 24931 : model1 loss : 0.440893 model2 loss : 0.019799
[12:07:38.976] iteration 24932 : model1 loss : 0.440697 model2 loss : 0.019677
[12:07:39.144] iteration 24933 : model1 loss : 0.434264 model2 loss : 0.016856
[12:07:39.312] iteration 24934 : model1 loss : 0.436949 model2 loss : 0.017262
[12:07:39.481] iteration 24935 : model1 loss : 0.439936 model2 loss : 0.021618
[12:07:39.651] iteration 24936 : model1 loss : 0.439133 model2 loss : 0.017631
[12:07:39.819] iteration 24937 : model1 loss : 0.439026 model2 loss : 0.020228
[12:07:39.993] iteration 24938 : model1 loss : 0.437158 model2 loss : 0.021503
[12:07:40.160] iteration 24939 : model1 loss : 0.442122 model2 loss : 0.021547
[12:07:40.332] iteration 24940 : model1 loss : 0.443378 model2 loss : 0.019571
[12:07:40.500] iteration 24941 : model1 loss : 0.436442 model2 loss : 0.018285
[12:07:40.688] iteration 24942 : model1 loss : 0.444680 model2 loss : 0.022097
[12:07:40.856] iteration 24943 : model1 loss : 0.441411 model2 loss : 0.019523
[12:07:41.025] iteration 24944 : model1 loss : 0.438396 model2 loss : 0.019109
[12:07:41.193] iteration 24945 : model1 loss : 0.443581 model2 loss : 0.024565
[12:07:41.363] iteration 24946 : model1 loss : 0.444908 model2 loss : 0.021443
[12:07:41.534] iteration 24947 : model1 loss : 0.436415 model2 loss : 0.020809
[12:07:41.705] iteration 24948 : model1 loss : 0.441766 model2 loss : 0.021638
[12:07:43.607] iteration 24949 : model1 loss : 0.443516 model2 loss : 0.021018
[12:07:43.776] iteration 24950 : model1 loss : 0.440609 model2 loss : 0.018719
[12:07:43.950] iteration 24951 : model1 loss : 0.443739 model2 loss : 0.019734
[12:07:44.116] iteration 24952 : model1 loss : 0.437555 model2 loss : 0.020899
[12:07:44.286] iteration 24953 : model1 loss : 0.445349 model2 loss : 0.023556
[12:07:44.454] iteration 24954 : model1 loss : 0.443624 model2 loss : 0.021230
[12:07:44.622] iteration 24955 : model1 loss : 0.438735 model2 loss : 0.019904
[12:07:44.793] iteration 24956 : model1 loss : 0.437434 model2 loss : 0.020027
[12:07:44.962] iteration 24957 : model1 loss : 0.440832 model2 loss : 0.020602
[12:07:45.130] iteration 24958 : model1 loss : 0.437620 model2 loss : 0.021486
[12:07:45.299] iteration 24959 : model1 loss : 0.438012 model2 loss : 0.018842
[12:07:45.466] iteration 24960 : model1 loss : 0.438751 model2 loss : 0.020921
[12:07:45.636] iteration 24961 : model1 loss : 0.441723 model2 loss : 0.020171
[12:07:45.804] iteration 24962 : model1 loss : 0.443157 model2 loss : 0.021220
[12:07:45.974] iteration 24963 : model1 loss : 0.441184 model2 loss : 0.018307
[12:07:46.140] iteration 24964 : model1 loss : 0.438069 model2 loss : 0.020854
[12:07:46.310] iteration 24965 : model1 loss : 0.438467 model2 loss : 0.018992
[12:07:46.477] iteration 24966 : model1 loss : 0.435626 model2 loss : 0.019298
[12:07:46.647] iteration 24967 : model1 loss : 0.440938 model2 loss : 0.020785
[12:07:46.814] iteration 24968 : model1 loss : 0.434298 model2 loss : 0.018245
[12:07:46.984] iteration 24969 : model1 loss : 0.441460 model2 loss : 0.020345
[12:07:47.153] iteration 24970 : model1 loss : 0.441948 model2 loss : 0.019235
[12:07:47.322] iteration 24971 : model1 loss : 0.442446 model2 loss : 0.022608
[12:07:47.492] iteration 24972 : model1 loss : 0.438623 model2 loss : 0.018660
[12:07:47.663] iteration 24973 : model1 loss : 0.436454 model2 loss : 0.020737
[12:07:47.830] iteration 24974 : model1 loss : 0.437730 model2 loss : 0.019428
[12:07:47.998] iteration 24975 : model1 loss : 0.439542 model2 loss : 0.020972
[12:07:48.166] iteration 24976 : model1 loss : 0.438154 model2 loss : 0.020887
[12:07:48.335] iteration 24977 : model1 loss : 0.440895 model2 loss : 0.017301
[12:07:48.503] iteration 24978 : model1 loss : 0.440744 model2 loss : 0.018539
[12:07:48.676] iteration 24979 : model1 loss : 0.441260 model2 loss : 0.021601
[12:07:48.843] iteration 24980 : model1 loss : 0.435828 model2 loss : 0.018439
[12:07:49.012] iteration 24981 : model1 loss : 0.436632 model2 loss : 0.019400
[12:07:50.930] iteration 24982 : model1 loss : 0.443096 model2 loss : 0.021724
[12:07:51.099] iteration 24983 : model1 loss : 0.438479 model2 loss : 0.018985
[12:07:51.271] iteration 24984 : model1 loss : 0.436828 model2 loss : 0.017892
[12:07:51.438] iteration 24985 : model1 loss : 0.437335 model2 loss : 0.020335
[12:07:51.608] iteration 24986 : model1 loss : 0.436973 model2 loss : 0.018508
[12:07:51.778] iteration 24987 : model1 loss : 0.439307 model2 loss : 0.021802
[12:07:51.946] iteration 24988 : model1 loss : 0.439461 model2 loss : 0.018628
[12:07:52.116] iteration 24989 : model1 loss : 0.439268 model2 loss : 0.020457
[12:07:52.285] iteration 24990 : model1 loss : 0.436776 model2 loss : 0.019081
[12:07:52.454] iteration 24991 : model1 loss : 0.440664 model2 loss : 0.019915
[12:07:52.626] iteration 24992 : model1 loss : 0.438734 model2 loss : 0.020593
[12:07:52.801] iteration 24993 : model1 loss : 0.441919 model2 loss : 0.020994
[12:07:52.970] iteration 24994 : model1 loss : 0.436237 model2 loss : 0.020216
[12:07:53.138] iteration 24995 : model1 loss : 0.439563 model2 loss : 0.020381
[12:07:53.306] iteration 24996 : model1 loss : 0.439939 model2 loss : 0.020111
[12:07:53.472] iteration 24997 : model1 loss : 0.437833 model2 loss : 0.020286
[12:07:53.642] iteration 24998 : model1 loss : 0.440027 model2 loss : 0.020307
[12:07:53.812] iteration 24999 : model1 loss : 0.437123 model2 loss : 0.019138
[12:07:53.983] iteration 25000 : model1 loss : 0.440028 model2 loss : 0.020467
[12:08:02.253] iteration 25000 : model1_mean_dice : 0.898133 model1_mean_hd95 : 3.497477
[12:08:10.553] iteration 25000 : model2_mean_dice : 0.895540 model2_mean_hd95 : 2.145432
[12:08:10.729] iteration 25001 : model1 loss : 0.441425 model2 loss : 0.021120
[12:08:10.907] iteration 25002 : model1 loss : 0.438700 model2 loss : 0.018410
[12:08:11.073] iteration 25003 : model1 loss : 0.441806 model2 loss : 0.019540
[12:08:11.243] iteration 25004 : model1 loss : 0.440659 model2 loss : 0.020463
[12:08:11.409] iteration 25005 : model1 loss : 0.442650 model2 loss : 0.019862
[12:08:11.580] iteration 25006 : model1 loss : 0.443043 model2 loss : 0.017595
[12:08:11.747] iteration 25007 : model1 loss : 0.444007 model2 loss : 0.020359
[12:08:11.916] iteration 25008 : model1 loss : 0.440426 model2 loss : 0.020390
[12:08:12.082] iteration 25009 : model1 loss : 0.438977 model2 loss : 0.021205
[12:08:12.250] iteration 25010 : model1 loss : 0.438852 model2 loss : 0.018875
[12:08:12.418] iteration 25011 : model1 loss : 0.441165 model2 loss : 0.022123
[12:08:12.587] iteration 25012 : model1 loss : 0.439217 model2 loss : 0.018875
[12:08:12.754] iteration 25013 : model1 loss : 0.440391 model2 loss : 0.020446
[12:08:12.922] iteration 25014 : model1 loss : 0.439041 model2 loss : 0.018968
[12:08:14.849] iteration 25015 : model1 loss : 0.439822 model2 loss : 0.019663
[12:08:15.020] iteration 25016 : model1 loss : 0.442880 model2 loss : 0.020304
[12:08:15.191] iteration 25017 : model1 loss : 0.437823 model2 loss : 0.016932
[12:08:15.358] iteration 25018 : model1 loss : 0.440562 model2 loss : 0.019730
[12:08:15.533] iteration 25019 : model1 loss : 0.438981 model2 loss : 0.019374
[12:08:15.701] iteration 25020 : model1 loss : 0.441671 model2 loss : 0.019591
[12:08:15.873] iteration 25021 : model1 loss : 0.442406 model2 loss : 0.021187
[12:08:16.038] iteration 25022 : model1 loss : 0.441834 model2 loss : 0.019364
[12:08:16.208] iteration 25023 : model1 loss : 0.440689 model2 loss : 0.018369
[12:08:16.375] iteration 25024 : model1 loss : 0.439444 model2 loss : 0.020261
[12:08:16.545] iteration 25025 : model1 loss : 0.438179 model2 loss : 0.017601
[12:08:16.712] iteration 25026 : model1 loss : 0.438305 model2 loss : 0.021978
[12:08:16.884] iteration 25027 : model1 loss : 0.436600 model2 loss : 0.018968
[12:08:17.054] iteration 25028 : model1 loss : 0.446734 model2 loss : 0.019459
[12:08:17.221] iteration 25029 : model1 loss : 0.436213 model2 loss : 0.019028
[12:08:17.388] iteration 25030 : model1 loss : 0.439878 model2 loss : 0.018552
[12:08:17.556] iteration 25031 : model1 loss : 0.443178 model2 loss : 0.021854
[12:08:17.723] iteration 25032 : model1 loss : 0.438967 model2 loss : 0.019627
[12:08:17.896] iteration 25033 : model1 loss : 0.441970 model2 loss : 0.019063
[12:08:18.063] iteration 25034 : model1 loss : 0.441356 model2 loss : 0.021378
[12:08:18.233] iteration 25035 : model1 loss : 0.435607 model2 loss : 0.018241
[12:08:18.402] iteration 25036 : model1 loss : 0.442892 model2 loss : 0.022219
[12:08:18.572] iteration 25037 : model1 loss : 0.441301 model2 loss : 0.018075
[12:08:18.741] iteration 25038 : model1 loss : 0.439466 model2 loss : 0.022828
[12:08:18.914] iteration 25039 : model1 loss : 0.436954 model2 loss : 0.018965
[12:08:19.082] iteration 25040 : model1 loss : 0.440716 model2 loss : 0.021025
[12:08:19.252] iteration 25041 : model1 loss : 0.437942 model2 loss : 0.019629
[12:08:19.417] iteration 25042 : model1 loss : 0.435245 model2 loss : 0.016805
[12:08:19.587] iteration 25043 : model1 loss : 0.435665 model2 loss : 0.021239
[12:08:19.753] iteration 25044 : model1 loss : 0.442784 model2 loss : 0.021038
[12:08:19.924] iteration 25045 : model1 loss : 0.438466 model2 loss : 0.018411
[12:08:20.088] iteration 25046 : model1 loss : 0.437550 model2 loss : 0.019184
[12:08:20.257] iteration 25047 : model1 loss : 0.436000 model2 loss : 0.019411
[12:08:22.191] iteration 25048 : model1 loss : 0.439063 model2 loss : 0.021245
[12:08:22.361] iteration 25049 : model1 loss : 0.442181 model2 loss : 0.018220
[12:08:22.532] iteration 25050 : model1 loss : 0.444504 model2 loss : 0.019756
[12:08:22.699] iteration 25051 : model1 loss : 0.436294 model2 loss : 0.021146
[12:08:22.868] iteration 25052 : model1 loss : 0.439147 model2 loss : 0.017834
[12:08:23.035] iteration 25053 : model1 loss : 0.441613 model2 loss : 0.021108
[12:08:23.205] iteration 25054 : model1 loss : 0.441270 model2 loss : 0.020254
[12:08:23.371] iteration 25055 : model1 loss : 0.438859 model2 loss : 0.019465
[12:08:23.544] iteration 25056 : model1 loss : 0.436988 model2 loss : 0.019653
[12:08:23.712] iteration 25057 : model1 loss : 0.439305 model2 loss : 0.018399
[12:08:23.883] iteration 25058 : model1 loss : 0.439213 model2 loss : 0.019024
[12:08:24.050] iteration 25059 : model1 loss : 0.442286 model2 loss : 0.021028
[12:08:24.219] iteration 25060 : model1 loss : 0.438262 model2 loss : 0.018063
[12:08:24.388] iteration 25061 : model1 loss : 0.439063 model2 loss : 0.021830
[12:08:24.558] iteration 25062 : model1 loss : 0.442371 model2 loss : 0.022135
[12:08:24.726] iteration 25063 : model1 loss : 0.437729 model2 loss : 0.019108
[12:08:24.897] iteration 25064 : model1 loss : 0.447177 model2 loss : 0.025210
[12:08:25.065] iteration 25065 : model1 loss : 0.439820 model2 loss : 0.020918
[12:08:25.233] iteration 25066 : model1 loss : 0.437849 model2 loss : 0.018694
[12:08:25.399] iteration 25067 : model1 loss : 0.441345 model2 loss : 0.020373
[12:08:25.569] iteration 25068 : model1 loss : 0.439258 model2 loss : 0.020339
[12:08:25.735] iteration 25069 : model1 loss : 0.436693 model2 loss : 0.019734
[12:08:25.906] iteration 25070 : model1 loss : 0.445059 model2 loss : 0.020062
[12:08:26.073] iteration 25071 : model1 loss : 0.434776 model2 loss : 0.018536
[12:08:26.243] iteration 25072 : model1 loss : 0.437147 model2 loss : 0.020262
[12:08:26.410] iteration 25073 : model1 loss : 0.440342 model2 loss : 0.021579
[12:08:26.579] iteration 25074 : model1 loss : 0.442203 model2 loss : 0.019832
[12:08:26.766] iteration 25075 : model1 loss : 0.438365 model2 loss : 0.020067
[12:08:26.938] iteration 25076 : model1 loss : 0.437779 model2 loss : 0.019244
[12:08:27.106] iteration 25077 : model1 loss : 0.441524 model2 loss : 0.017134
[12:08:27.274] iteration 25078 : model1 loss : 0.437277 model2 loss : 0.018620
[12:08:27.439] iteration 25079 : model1 loss : 0.441640 model2 loss : 0.019717
[12:08:27.608] iteration 25080 : model1 loss : 0.438823 model2 loss : 0.018979
[12:08:29.494] iteration 25081 : model1 loss : 0.438960 model2 loss : 0.017671
[12:08:29.664] iteration 25082 : model1 loss : 0.441798 model2 loss : 0.018724
[12:08:29.835] iteration 25083 : model1 loss : 0.441035 model2 loss : 0.020904
[12:08:30.001] iteration 25084 : model1 loss : 0.444039 model2 loss : 0.020158
[12:08:30.171] iteration 25085 : model1 loss : 0.441017 model2 loss : 0.021425
[12:08:30.339] iteration 25086 : model1 loss : 0.442556 model2 loss : 0.020171
[12:08:30.516] iteration 25087 : model1 loss : 0.438824 model2 loss : 0.021090
[12:08:30.683] iteration 25088 : model1 loss : 0.438062 model2 loss : 0.021953
[12:08:30.852] iteration 25089 : model1 loss : 0.436700 model2 loss : 0.020310
[12:08:31.020] iteration 25090 : model1 loss : 0.437195 model2 loss : 0.018045
[12:08:31.188] iteration 25091 : model1 loss : 0.437690 model2 loss : 0.019557
[12:08:31.356] iteration 25092 : model1 loss : 0.440685 model2 loss : 0.019613
[12:08:31.526] iteration 25093 : model1 loss : 0.437615 model2 loss : 0.018213
[12:08:31.693] iteration 25094 : model1 loss : 0.444311 model2 loss : 0.022631
[12:08:31.861] iteration 25095 : model1 loss : 0.435315 model2 loss : 0.019200
[12:08:32.027] iteration 25096 : model1 loss : 0.439906 model2 loss : 0.021437
[12:08:32.196] iteration 25097 : model1 loss : 0.438260 model2 loss : 0.018096
[12:08:32.362] iteration 25098 : model1 loss : 0.441737 model2 loss : 0.021754
[12:08:32.534] iteration 25099 : model1 loss : 0.442081 model2 loss : 0.020143
[12:08:32.700] iteration 25100 : model1 loss : 0.438056 model2 loss : 0.022412
[12:08:32.870] iteration 25101 : model1 loss : 0.439121 model2 loss : 0.018916
[12:08:33.039] iteration 25102 : model1 loss : 0.438848 model2 loss : 0.018475
[12:08:33.207] iteration 25103 : model1 loss : 0.440230 model2 loss : 0.021697
[12:08:33.372] iteration 25104 : model1 loss : 0.436832 model2 loss : 0.018477
[12:08:33.540] iteration 25105 : model1 loss : 0.439731 model2 loss : 0.019121
[12:08:33.706] iteration 25106 : model1 loss : 0.440978 model2 loss : 0.019011
[12:08:33.884] iteration 25107 : model1 loss : 0.437836 model2 loss : 0.018662
[12:08:34.050] iteration 25108 : model1 loss : 0.439741 model2 loss : 0.018775
[12:08:34.219] iteration 25109 : model1 loss : 0.442568 model2 loss : 0.022751
[12:08:34.386] iteration 25110 : model1 loss : 0.442039 model2 loss : 0.019076
[12:08:34.555] iteration 25111 : model1 loss : 0.439470 model2 loss : 0.021471
[12:08:34.721] iteration 25112 : model1 loss : 0.441658 model2 loss : 0.023970
[12:08:34.888] iteration 25113 : model1 loss : 0.438211 model2 loss : 0.020560
[12:08:36.844] iteration 25114 : model1 loss : 0.443132 model2 loss : 0.021176
[12:08:37.011] iteration 25115 : model1 loss : 0.436234 model2 loss : 0.019053
[12:08:37.184] iteration 25116 : model1 loss : 0.440365 model2 loss : 0.018545
[12:08:37.364] iteration 25117 : model1 loss : 0.445322 model2 loss : 0.022786
[12:08:37.534] iteration 25118 : model1 loss : 0.443731 model2 loss : 0.021460
[12:08:37.704] iteration 25119 : model1 loss : 0.438335 model2 loss : 0.020185
[12:08:37.873] iteration 25120 : model1 loss : 0.439283 model2 loss : 0.019537
[12:08:38.038] iteration 25121 : model1 loss : 0.443574 model2 loss : 0.020088
[12:08:38.207] iteration 25122 : model1 loss : 0.441178 model2 loss : 0.020827
[12:08:38.375] iteration 25123 : model1 loss : 0.440393 model2 loss : 0.019587
[12:08:38.545] iteration 25124 : model1 loss : 0.440040 model2 loss : 0.018389
[12:08:38.711] iteration 25125 : model1 loss : 0.438886 model2 loss : 0.021080
[12:08:38.881] iteration 25126 : model1 loss : 0.437772 model2 loss : 0.019281
[12:08:39.048] iteration 25127 : model1 loss : 0.439613 model2 loss : 0.018513
[12:08:39.215] iteration 25128 : model1 loss : 0.434539 model2 loss : 0.018571
[12:08:39.386] iteration 25129 : model1 loss : 0.436387 model2 loss : 0.020617
[12:08:39.557] iteration 25130 : model1 loss : 0.441043 model2 loss : 0.018577
[12:08:39.725] iteration 25131 : model1 loss : 0.440712 model2 loss : 0.022136
[12:08:39.895] iteration 25132 : model1 loss : 0.442620 model2 loss : 0.018837
[12:08:40.063] iteration 25133 : model1 loss : 0.440130 model2 loss : 0.019588
[12:08:40.232] iteration 25134 : model1 loss : 0.440444 model2 loss : 0.017065
[12:08:40.400] iteration 25135 : model1 loss : 0.436645 model2 loss : 0.017558
[12:08:40.571] iteration 25136 : model1 loss : 0.440461 model2 loss : 0.018481
[12:08:40.740] iteration 25137 : model1 loss : 0.438582 model2 loss : 0.018834
[12:08:40.913] iteration 25138 : model1 loss : 0.440941 model2 loss : 0.019781
[12:08:41.079] iteration 25139 : model1 loss : 0.434570 model2 loss : 0.018440
[12:08:41.246] iteration 25140 : model1 loss : 0.438283 model2 loss : 0.018465
[12:08:41.414] iteration 25141 : model1 loss : 0.441970 model2 loss : 0.020188
[12:08:41.584] iteration 25142 : model1 loss : 0.440497 model2 loss : 0.019473
[12:08:41.751] iteration 25143 : model1 loss : 0.440939 model2 loss : 0.021047
[12:08:41.921] iteration 25144 : model1 loss : 0.438935 model2 loss : 0.018578
[12:08:42.088] iteration 25145 : model1 loss : 0.439952 model2 loss : 0.019457
[12:08:42.256] iteration 25146 : model1 loss : 0.433103 model2 loss : 0.018257
[12:08:44.148] iteration 25147 : model1 loss : 0.442296 model2 loss : 0.019785
[12:08:44.314] iteration 25148 : model1 loss : 0.439596 model2 loss : 0.021731
[12:08:44.483] iteration 25149 : model1 loss : 0.438057 model2 loss : 0.020215
[12:08:44.651] iteration 25150 : model1 loss : 0.443291 model2 loss : 0.020338
[12:08:44.837] iteration 25151 : model1 loss : 0.439555 model2 loss : 0.021241
[12:08:45.003] iteration 25152 : model1 loss : 0.440049 model2 loss : 0.018367
[12:08:45.173] iteration 25153 : model1 loss : 0.438668 model2 loss : 0.019346
[12:08:45.340] iteration 25154 : model1 loss : 0.438322 model2 loss : 0.018910
[12:08:45.512] iteration 25155 : model1 loss : 0.436773 model2 loss : 0.017762
[12:08:45.678] iteration 25156 : model1 loss : 0.444473 model2 loss : 0.018263
[12:08:45.848] iteration 25157 : model1 loss : 0.439910 model2 loss : 0.022613
[12:08:46.017] iteration 25158 : model1 loss : 0.440983 model2 loss : 0.021037
[12:08:46.184] iteration 25159 : model1 loss : 0.443911 model2 loss : 0.021015
[12:08:46.352] iteration 25160 : model1 loss : 0.441381 model2 loss : 0.019216
[12:08:46.528] iteration 25161 : model1 loss : 0.440325 model2 loss : 0.019145
[12:08:46.697] iteration 25162 : model1 loss : 0.436804 model2 loss : 0.018097
[12:08:46.866] iteration 25163 : model1 loss : 0.438895 model2 loss : 0.022092
[12:08:47.033] iteration 25164 : model1 loss : 0.438538 model2 loss : 0.019107
[12:08:47.200] iteration 25165 : model1 loss : 0.440139 model2 loss : 0.018864
[12:08:47.366] iteration 25166 : model1 loss : 0.436280 model2 loss : 0.019595
[12:08:47.536] iteration 25167 : model1 loss : 0.438602 model2 loss : 0.019378
[12:08:47.705] iteration 25168 : model1 loss : 0.441500 model2 loss : 0.021695
[12:08:47.875] iteration 25169 : model1 loss : 0.439047 model2 loss : 0.017987
[12:08:48.043] iteration 25170 : model1 loss : 0.440484 model2 loss : 0.020390
[12:08:48.212] iteration 25171 : model1 loss : 0.437723 model2 loss : 0.017365
[12:08:48.378] iteration 25172 : model1 loss : 0.443651 model2 loss : 0.021089
[12:08:48.549] iteration 25173 : model1 loss : 0.441966 model2 loss : 0.019380
[12:08:48.717] iteration 25174 : model1 loss : 0.439112 model2 loss : 0.018238
[12:08:48.889] iteration 25175 : model1 loss : 0.434932 model2 loss : 0.020482
[12:08:49.056] iteration 25176 : model1 loss : 0.441358 model2 loss : 0.019886
[12:08:49.225] iteration 25177 : model1 loss : 0.436273 model2 loss : 0.018832
[12:08:49.391] iteration 25178 : model1 loss : 0.437934 model2 loss : 0.019178
[12:08:49.561] iteration 25179 : model1 loss : 0.440138 model2 loss : 0.022558
[12:08:51.470] iteration 25180 : model1 loss : 0.434010 model2 loss : 0.018307
[12:08:51.637] iteration 25181 : model1 loss : 0.436548 model2 loss : 0.019012
[12:08:51.808] iteration 25182 : model1 loss : 0.437687 model2 loss : 0.021822
[12:08:51.978] iteration 25183 : model1 loss : 0.437754 model2 loss : 0.021626
[12:08:52.148] iteration 25184 : model1 loss : 0.441737 model2 loss : 0.019800
[12:08:52.316] iteration 25185 : model1 loss : 0.447233 model2 loss : 0.023144
[12:08:52.487] iteration 25186 : model1 loss : 0.440074 model2 loss : 0.017883
[12:08:52.652] iteration 25187 : model1 loss : 0.440562 model2 loss : 0.019478
[12:08:52.820] iteration 25188 : model1 loss : 0.439381 model2 loss : 0.019132
[12:08:52.989] iteration 25189 : model1 loss : 0.439966 model2 loss : 0.020775
[12:08:53.157] iteration 25190 : model1 loss : 0.439441 model2 loss : 0.019927
[12:08:53.324] iteration 25191 : model1 loss : 0.439251 model2 loss : 0.020689
[12:08:53.493] iteration 25192 : model1 loss : 0.439240 model2 loss : 0.021292
[12:08:53.661] iteration 25193 : model1 loss : 0.438245 model2 loss : 0.017993
[12:08:53.831] iteration 25194 : model1 loss : 0.433338 model2 loss : 0.020598
[12:08:53.997] iteration 25195 : model1 loss : 0.443575 model2 loss : 0.023372
[12:08:54.166] iteration 25196 : model1 loss : 0.442364 model2 loss : 0.022103
[12:08:54.333] iteration 25197 : model1 loss : 0.442115 model2 loss : 0.019559
[12:08:54.504] iteration 25198 : model1 loss : 0.437417 model2 loss : 0.017139
[12:08:54.671] iteration 25199 : model1 loss : 0.440444 model2 loss : 0.018563
[12:08:54.842] iteration 25200 : model1 loss : 0.438120 model2 loss : 0.018130
[12:08:55.008] iteration 25201 : model1 loss : 0.440213 model2 loss : 0.019781
[12:08:55.177] iteration 25202 : model1 loss : 0.441233 model2 loss : 0.023409
[12:08:55.345] iteration 25203 : model1 loss : 0.437594 model2 loss : 0.017775
[12:08:55.517] iteration 25204 : model1 loss : 0.441139 model2 loss : 0.017232
[12:08:55.683] iteration 25205 : model1 loss : 0.444925 model2 loss : 0.019885
[12:08:55.853] iteration 25206 : model1 loss : 0.440580 model2 loss : 0.022210
[12:08:56.022] iteration 25207 : model1 loss : 0.435467 model2 loss : 0.019596
[12:08:56.189] iteration 25208 : model1 loss : 0.439567 model2 loss : 0.019866
[12:08:56.357] iteration 25209 : model1 loss : 0.440256 model2 loss : 0.018942
[12:08:56.527] iteration 25210 : model1 loss : 0.436147 model2 loss : 0.017716
[12:08:56.693] iteration 25211 : model1 loss : 0.439890 model2 loss : 0.021685
[12:08:56.860] iteration 25212 : model1 loss : 0.445508 model2 loss : 0.018030
[12:08:58.766] iteration 25213 : model1 loss : 0.442707 model2 loss : 0.020081
[12:08:58.931] iteration 25214 : model1 loss : 0.436628 model2 loss : 0.020115
[12:08:59.101] iteration 25215 : model1 loss : 0.436118 model2 loss : 0.018408
[12:08:59.270] iteration 25216 : model1 loss : 0.443543 model2 loss : 0.022115
[12:08:59.438] iteration 25217 : model1 loss : 0.439755 model2 loss : 0.018297
[12:08:59.605] iteration 25218 : model1 loss : 0.443819 model2 loss : 0.019582
[12:08:59.774] iteration 25219 : model1 loss : 0.440888 model2 loss : 0.020497
[12:08:59.944] iteration 25220 : model1 loss : 0.439588 model2 loss : 0.019189
[12:09:00.114] iteration 25221 : model1 loss : 0.444365 model2 loss : 0.021668
[12:09:00.281] iteration 25222 : model1 loss : 0.440615 model2 loss : 0.018885
[12:09:00.450] iteration 25223 : model1 loss : 0.439752 model2 loss : 0.019886
[12:09:00.617] iteration 25224 : model1 loss : 0.438013 model2 loss : 0.019854
[12:09:00.789] iteration 25225 : model1 loss : 0.439117 model2 loss : 0.019359
[12:09:00.958] iteration 25226 : model1 loss : 0.437200 model2 loss : 0.018894
[12:09:01.128] iteration 25227 : model1 loss : 0.438022 model2 loss : 0.019255
[12:09:01.293] iteration 25228 : model1 loss : 0.443379 model2 loss : 0.022238
[12:09:01.463] iteration 25229 : model1 loss : 0.436310 model2 loss : 0.020225
[12:09:01.631] iteration 25230 : model1 loss : 0.436612 model2 loss : 0.019070
[12:09:01.800] iteration 25231 : model1 loss : 0.439156 model2 loss : 0.019756
[12:09:01.972] iteration 25232 : model1 loss : 0.442891 model2 loss : 0.019788
[12:09:02.143] iteration 25233 : model1 loss : 0.439361 model2 loss : 0.017857
[12:09:02.311] iteration 25234 : model1 loss : 0.439927 model2 loss : 0.019537
[12:09:02.481] iteration 25235 : model1 loss : 0.437765 model2 loss : 0.020205
[12:09:02.648] iteration 25236 : model1 loss : 0.437196 model2 loss : 0.018851
[12:09:02.819] iteration 25237 : model1 loss : 0.438512 model2 loss : 0.019711
[12:09:02.990] iteration 25238 : model1 loss : 0.439825 model2 loss : 0.020878
[12:09:03.160] iteration 25239 : model1 loss : 0.444390 model2 loss : 0.024585
[12:09:03.325] iteration 25240 : model1 loss : 0.439308 model2 loss : 0.020464
[12:09:03.495] iteration 25241 : model1 loss : 0.435905 model2 loss : 0.020394
[12:09:03.662] iteration 25242 : model1 loss : 0.441958 model2 loss : 0.019619
[12:09:03.832] iteration 25243 : model1 loss : 0.438070 model2 loss : 0.019984
[12:09:03.999] iteration 25244 : model1 loss : 0.444349 model2 loss : 0.023363
[12:09:04.179] iteration 25245 : model1 loss : 0.440176 model2 loss : 0.018104
[12:09:06.137] iteration 25246 : model1 loss : 0.442348 model2 loss : 0.022545
[12:09:06.308] iteration 25247 : model1 loss : 0.439796 model2 loss : 0.019880
[12:09:06.479] iteration 25248 : model1 loss : 0.441168 model2 loss : 0.020651
[12:09:06.647] iteration 25249 : model1 loss : 0.436616 model2 loss : 0.019593
[12:09:06.818] iteration 25250 : model1 loss : 0.439175 model2 loss : 0.021083
[12:09:06.987] iteration 25251 : model1 loss : 0.437544 model2 loss : 0.021504
[12:09:07.154] iteration 25252 : model1 loss : 0.444571 model2 loss : 0.022167
[12:09:07.324] iteration 25253 : model1 loss : 0.440976 model2 loss : 0.020692
[12:09:07.495] iteration 25254 : model1 loss : 0.438404 model2 loss : 0.017941
[12:09:07.662] iteration 25255 : model1 loss : 0.440483 model2 loss : 0.018293
[12:09:07.831] iteration 25256 : model1 loss : 0.441540 model2 loss : 0.020872
[12:09:08.000] iteration 25257 : model1 loss : 0.437853 model2 loss : 0.018105
[12:09:08.170] iteration 25258 : model1 loss : 0.441404 model2 loss : 0.019836
[12:09:08.337] iteration 25259 : model1 loss : 0.434878 model2 loss : 0.018696
[12:09:08.510] iteration 25260 : model1 loss : 0.442463 model2 loss : 0.022939
[12:09:08.677] iteration 25261 : model1 loss : 0.440591 model2 loss : 0.019488
[12:09:08.846] iteration 25262 : model1 loss : 0.442191 model2 loss : 0.020371
[12:09:09.012] iteration 25263 : model1 loss : 0.443673 model2 loss : 0.020439
[12:09:09.180] iteration 25264 : model1 loss : 0.435901 model2 loss : 0.020483
[12:09:09.347] iteration 25265 : model1 loss : 0.438948 model2 loss : 0.019554
[12:09:09.519] iteration 25266 : model1 loss : 0.440287 model2 loss : 0.020513
[12:09:09.686] iteration 25267 : model1 loss : 0.440214 model2 loss : 0.020542
[12:09:09.855] iteration 25268 : model1 loss : 0.445713 model2 loss : 0.021784
[12:09:10.025] iteration 25269 : model1 loss : 0.437579 model2 loss : 0.017194
[12:09:10.192] iteration 25270 : model1 loss : 0.435159 model2 loss : 0.018583
[12:09:10.362] iteration 25271 : model1 loss : 0.439333 model2 loss : 0.019964
[12:09:10.531] iteration 25272 : model1 loss : 0.445626 model2 loss : 0.022189
[12:09:10.698] iteration 25273 : model1 loss : 0.438492 model2 loss : 0.020908
[12:09:10.867] iteration 25274 : model1 loss : 0.437725 model2 loss : 0.019762
[12:09:11.035] iteration 25275 : model1 loss : 0.440052 model2 loss : 0.020822
[12:09:11.205] iteration 25276 : model1 loss : 0.436883 model2 loss : 0.017515
[12:09:11.372] iteration 25277 : model1 loss : 0.436677 model2 loss : 0.019195
[12:09:11.540] iteration 25278 : model1 loss : 0.440959 model2 loss : 0.021925
[12:09:13.458] iteration 25279 : model1 loss : 0.437455 model2 loss : 0.020297
[12:09:13.624] iteration 25280 : model1 loss : 0.439683 model2 loss : 0.019020
[12:09:13.793] iteration 25281 : model1 loss : 0.444417 model2 loss : 0.021676
[12:09:13.961] iteration 25282 : model1 loss : 0.439062 model2 loss : 0.019917
[12:09:14.129] iteration 25283 : model1 loss : 0.437463 model2 loss : 0.018956
[12:09:14.296] iteration 25284 : model1 loss : 0.439033 model2 loss : 0.019700
[12:09:14.465] iteration 25285 : model1 loss : 0.442389 model2 loss : 0.018058
[12:09:14.632] iteration 25286 : model1 loss : 0.438378 model2 loss : 0.018273
[12:09:14.802] iteration 25287 : model1 loss : 0.438005 model2 loss : 0.021045
[12:09:14.969] iteration 25288 : model1 loss : 0.434831 model2 loss : 0.020895
[12:09:15.137] iteration 25289 : model1 loss : 0.440443 model2 loss : 0.020218
[12:09:15.303] iteration 25290 : model1 loss : 0.437572 model2 loss : 0.021196
[12:09:15.473] iteration 25291 : model1 loss : 0.443112 model2 loss : 0.020480
[12:09:15.641] iteration 25292 : model1 loss : 0.442161 model2 loss : 0.020487
[12:09:15.810] iteration 25293 : model1 loss : 0.441599 model2 loss : 0.021902
[12:09:15.979] iteration 25294 : model1 loss : 0.440437 model2 loss : 0.020367
[12:09:16.150] iteration 25295 : model1 loss : 0.438736 model2 loss : 0.018466
[12:09:16.316] iteration 25296 : model1 loss : 0.436280 model2 loss : 0.020514
[12:09:16.485] iteration 25297 : model1 loss : 0.438415 model2 loss : 0.019420
[12:09:16.652] iteration 25298 : model1 loss : 0.436909 model2 loss : 0.019744
[12:09:16.824] iteration 25299 : model1 loss : 0.439219 model2 loss : 0.018419
[12:09:16.992] iteration 25300 : model1 loss : 0.441783 model2 loss : 0.020589
[12:09:17.161] iteration 25301 : model1 loss : 0.440610 model2 loss : 0.019498
[12:09:17.329] iteration 25302 : model1 loss : 0.446687 model2 loss : 0.022939
[12:09:17.498] iteration 25303 : model1 loss : 0.443855 model2 loss : 0.020364
[12:09:17.667] iteration 25304 : model1 loss : 0.438321 model2 loss : 0.019278
[12:09:17.845] iteration 25305 : model1 loss : 0.438420 model2 loss : 0.019121
[12:09:18.012] iteration 25306 : model1 loss : 0.440189 model2 loss : 0.019630
[12:09:18.180] iteration 25307 : model1 loss : 0.441859 model2 loss : 0.021909
[12:09:18.347] iteration 25308 : model1 loss : 0.437877 model2 loss : 0.020934
[12:09:18.518] iteration 25309 : model1 loss : 0.438671 model2 loss : 0.018794
[12:09:18.684] iteration 25310 : model1 loss : 0.439003 model2 loss : 0.021232
[12:09:18.852] iteration 25311 : model1 loss : 0.439877 model2 loss : 0.020108
[12:09:20.793] iteration 25312 : model1 loss : 0.436158 model2 loss : 0.016109
[12:09:20.964] iteration 25313 : model1 loss : 0.436732 model2 loss : 0.020667
[12:09:21.133] iteration 25314 : model1 loss : 0.438496 model2 loss : 0.018143
[12:09:21.303] iteration 25315 : model1 loss : 0.437442 model2 loss : 0.018773
[12:09:21.472] iteration 25316 : model1 loss : 0.438144 model2 loss : 0.020490
[12:09:21.640] iteration 25317 : model1 loss : 0.434787 model2 loss : 0.018793
[12:09:21.811] iteration 25318 : model1 loss : 0.433339 model2 loss : 0.019494
[12:09:21.979] iteration 25319 : model1 loss : 0.442166 model2 loss : 0.020669
[12:09:22.147] iteration 25320 : model1 loss : 0.437514 model2 loss : 0.020153
[12:09:22.313] iteration 25321 : model1 loss : 0.437437 model2 loss : 0.019303
[12:09:22.482] iteration 25322 : model1 loss : 0.438237 model2 loss : 0.018747
[12:09:22.648] iteration 25323 : model1 loss : 0.444003 model2 loss : 0.022949
[12:09:22.817] iteration 25324 : model1 loss : 0.441578 model2 loss : 0.020270
[12:09:22.984] iteration 25325 : model1 loss : 0.441212 model2 loss : 0.020281
[12:09:23.152] iteration 25326 : model1 loss : 0.445522 model2 loss : 0.019909
[12:09:23.320] iteration 25327 : model1 loss : 0.437618 model2 loss : 0.020055
[12:09:23.491] iteration 25328 : model1 loss : 0.442165 model2 loss : 0.019412
[12:09:23.659] iteration 25329 : model1 loss : 0.445219 model2 loss : 0.018402
[12:09:23.828] iteration 25330 : model1 loss : 0.437348 model2 loss : 0.019951
[12:09:23.996] iteration 25331 : model1 loss : 0.444542 model2 loss : 0.022209
[12:09:24.164] iteration 25332 : model1 loss : 0.443871 model2 loss : 0.021150
[12:09:24.330] iteration 25333 : model1 loss : 0.440017 model2 loss : 0.021718
[12:09:24.500] iteration 25334 : model1 loss : 0.442320 model2 loss : 0.020678
[12:09:24.667] iteration 25335 : model1 loss : 0.438566 model2 loss : 0.022644
[12:09:24.836] iteration 25336 : model1 loss : 0.442298 model2 loss : 0.018726
[12:09:25.002] iteration 25337 : model1 loss : 0.437156 model2 loss : 0.020096
[12:09:25.170] iteration 25338 : model1 loss : 0.441360 model2 loss : 0.020022
[12:09:25.335] iteration 25339 : model1 loss : 0.439854 model2 loss : 0.019403
[12:09:25.509] iteration 25340 : model1 loss : 0.436312 model2 loss : 0.018917
[12:09:25.675] iteration 25341 : model1 loss : 0.437000 model2 loss : 0.018989
[12:09:25.845] iteration 25342 : model1 loss : 0.440483 model2 loss : 0.018664
[12:09:26.011] iteration 25343 : model1 loss : 0.441725 model2 loss : 0.020434
[12:09:26.181] iteration 25344 : model1 loss : 0.441231 model2 loss : 0.020244
[12:09:28.083] iteration 25345 : model1 loss : 0.443458 model2 loss : 0.020856
[12:09:28.250] iteration 25346 : model1 loss : 0.436512 model2 loss : 0.017976
[12:09:28.420] iteration 25347 : model1 loss : 0.443469 model2 loss : 0.020261
[12:09:28.588] iteration 25348 : model1 loss : 0.444487 model2 loss : 0.022686
[12:09:28.759] iteration 25349 : model1 loss : 0.437247 model2 loss : 0.018827
[12:09:28.927] iteration 25350 : model1 loss : 0.441913 model2 loss : 0.019839
[12:09:29.097] iteration 25351 : model1 loss : 0.440946 model2 loss : 0.020172
[12:09:29.265] iteration 25352 : model1 loss : 0.434390 model2 loss : 0.019937
[12:09:29.433] iteration 25353 : model1 loss : 0.442237 model2 loss : 0.021652
[12:09:29.600] iteration 25354 : model1 loss : 0.439771 model2 loss : 0.020992
[12:09:29.770] iteration 25355 : model1 loss : 0.438884 model2 loss : 0.017960
[12:09:29.938] iteration 25356 : model1 loss : 0.438276 model2 loss : 0.018729
[12:09:30.107] iteration 25357 : model1 loss : 0.439138 model2 loss : 0.018881
[12:09:30.275] iteration 25358 : model1 loss : 0.437675 model2 loss : 0.018955
[12:09:30.444] iteration 25359 : model1 loss : 0.439997 model2 loss : 0.020050
[12:09:30.610] iteration 25360 : model1 loss : 0.434444 model2 loss : 0.018120
[12:09:30.780] iteration 25361 : model1 loss : 0.441783 model2 loss : 0.019955
[12:09:30.953] iteration 25362 : model1 loss : 0.441074 model2 loss : 0.021097
[12:09:31.124] iteration 25363 : model1 loss : 0.435770 model2 loss : 0.019871
[12:09:31.291] iteration 25364 : model1 loss : 0.438870 model2 loss : 0.017850
[12:09:31.459] iteration 25365 : model1 loss : 0.435837 model2 loss : 0.018926
[12:09:31.626] iteration 25366 : model1 loss : 0.442101 model2 loss : 0.021885
[12:09:31.794] iteration 25367 : model1 loss : 0.434884 model2 loss : 0.019688
[12:09:31.962] iteration 25368 : model1 loss : 0.444474 model2 loss : 0.022436
[12:09:32.136] iteration 25369 : model1 loss : 0.441097 model2 loss : 0.020561
[12:09:32.303] iteration 25370 : model1 loss : 0.444503 model2 loss : 0.020795
[12:09:32.470] iteration 25371 : model1 loss : 0.438998 model2 loss : 0.019141
[12:09:32.637] iteration 25372 : model1 loss : 0.436938 model2 loss : 0.019367
[12:09:32.806] iteration 25373 : model1 loss : 0.438992 model2 loss : 0.019274
[12:09:32.972] iteration 25374 : model1 loss : 0.439235 model2 loss : 0.018927
[12:09:33.145] iteration 25375 : model1 loss : 0.441496 model2 loss : 0.019841
[12:09:33.309] iteration 25376 : model1 loss : 0.440232 model2 loss : 0.019908
[12:09:33.477] iteration 25377 : model1 loss : 0.440875 model2 loss : 0.020706
[12:09:35.379] iteration 25378 : model1 loss : 0.439657 model2 loss : 0.019971
[12:09:35.546] iteration 25379 : model1 loss : 0.436341 model2 loss : 0.021266
[12:09:35.717] iteration 25380 : model1 loss : 0.439593 model2 loss : 0.020417
[12:09:35.888] iteration 25381 : model1 loss : 0.442552 model2 loss : 0.022500
[12:09:36.057] iteration 25382 : model1 loss : 0.442012 model2 loss : 0.020905
[12:09:36.226] iteration 25383 : model1 loss : 0.439508 model2 loss : 0.019881
[12:09:36.394] iteration 25384 : model1 loss : 0.439763 model2 loss : 0.020286
[12:09:36.560] iteration 25385 : model1 loss : 0.437067 model2 loss : 0.018980
[12:09:36.731] iteration 25386 : model1 loss : 0.439761 model2 loss : 0.018368
[12:09:36.898] iteration 25387 : model1 loss : 0.439027 model2 loss : 0.019243
[12:09:37.071] iteration 25388 : model1 loss : 0.440759 model2 loss : 0.021415
[12:09:37.238] iteration 25389 : model1 loss : 0.437674 model2 loss : 0.019004
[12:09:37.407] iteration 25390 : model1 loss : 0.440136 model2 loss : 0.020285
[12:09:37.574] iteration 25391 : model1 loss : 0.439471 model2 loss : 0.018645
[12:09:37.744] iteration 25392 : model1 loss : 0.441600 model2 loss : 0.021866
[12:09:37.911] iteration 25393 : model1 loss : 0.442119 model2 loss : 0.019392
[12:09:38.083] iteration 25394 : model1 loss : 0.435496 model2 loss : 0.019791
[12:09:38.249] iteration 25395 : model1 loss : 0.440951 model2 loss : 0.018549
[12:09:38.419] iteration 25396 : model1 loss : 0.436464 model2 loss : 0.018631
[12:09:38.587] iteration 25397 : model1 loss : 0.438673 model2 loss : 0.020616
[12:09:38.755] iteration 25398 : model1 loss : 0.442832 model2 loss : 0.020936
[12:09:38.923] iteration 25399 : model1 loss : 0.443013 model2 loss : 0.023466
[12:09:39.091] iteration 25400 : model1 loss : 0.438100 model2 loss : 0.018397
[12:09:39.260] iteration 25401 : model1 loss : 0.437912 model2 loss : 0.017791
[12:09:39.428] iteration 25402 : model1 loss : 0.437474 model2 loss : 0.020920
[12:09:39.595] iteration 25403 : model1 loss : 0.441572 model2 loss : 0.020037
[12:09:39.765] iteration 25404 : model1 loss : 0.444225 model2 loss : 0.019831
[12:09:39.931] iteration 25405 : model1 loss : 0.440992 model2 loss : 0.017745
[12:09:40.099] iteration 25406 : model1 loss : 0.437562 model2 loss : 0.017501
[12:09:40.266] iteration 25407 : model1 loss : 0.441944 model2 loss : 0.022663
[12:09:40.438] iteration 25408 : model1 loss : 0.431632 model2 loss : 0.018364
[12:09:40.605] iteration 25409 : model1 loss : 0.444102 model2 loss : 0.020967
[12:09:40.778] iteration 25410 : model1 loss : 0.440054 model2 loss : 0.018303
[12:09:42.733] iteration 25411 : model1 loss : 0.444058 model2 loss : 0.021493
[12:09:42.902] iteration 25412 : model1 loss : 0.437533 model2 loss : 0.021591
[12:09:43.074] iteration 25413 : model1 loss : 0.433894 model2 loss : 0.017768
[12:09:43.241] iteration 25414 : model1 loss : 0.435766 model2 loss : 0.019521
[12:09:43.412] iteration 25415 : model1 loss : 0.440326 model2 loss : 0.020062
[12:09:43.579] iteration 25416 : model1 loss : 0.435639 model2 loss : 0.018697
[12:09:43.747] iteration 25417 : model1 loss : 0.440359 model2 loss : 0.020879
[12:09:43.916] iteration 25418 : model1 loss : 0.442590 model2 loss : 0.020250
[12:09:44.084] iteration 25419 : model1 loss : 0.443347 model2 loss : 0.020845
[12:09:44.251] iteration 25420 : model1 loss : 0.440715 model2 loss : 0.018957
[12:09:44.420] iteration 25421 : model1 loss : 0.446512 model2 loss : 0.022554
[12:09:44.588] iteration 25422 : model1 loss : 0.438458 model2 loss : 0.018246
[12:09:44.757] iteration 25423 : model1 loss : 0.442483 model2 loss : 0.020831
[12:09:44.923] iteration 25424 : model1 loss : 0.439640 model2 loss : 0.018598
[12:09:45.092] iteration 25425 : model1 loss : 0.437918 model2 loss : 0.018427
[12:09:45.259] iteration 25426 : model1 loss : 0.440246 model2 loss : 0.018946
[12:09:45.435] iteration 25427 : model1 loss : 0.436227 model2 loss : 0.021207
[12:09:45.601] iteration 25428 : model1 loss : 0.438115 model2 loss : 0.019848
[12:09:45.771] iteration 25429 : model1 loss : 0.441778 model2 loss : 0.019456
[12:09:45.945] iteration 25430 : model1 loss : 0.439565 model2 loss : 0.022022
[12:09:46.114] iteration 25431 : model1 loss : 0.436430 model2 loss : 0.019284
[12:09:46.281] iteration 25432 : model1 loss : 0.440865 model2 loss : 0.020144
[12:09:46.451] iteration 25433 : model1 loss : 0.439797 model2 loss : 0.020551
[12:09:46.619] iteration 25434 : model1 loss : 0.440880 model2 loss : 0.019694
[12:09:46.789] iteration 25435 : model1 loss : 0.438872 model2 loss : 0.017847
[12:09:46.957] iteration 25436 : model1 loss : 0.439496 model2 loss : 0.022108
[12:09:47.129] iteration 25437 : model1 loss : 0.437398 model2 loss : 0.020198
[12:09:47.297] iteration 25438 : model1 loss : 0.440444 model2 loss : 0.020638
[12:09:47.468] iteration 25439 : model1 loss : 0.434563 model2 loss : 0.020282
[12:09:47.634] iteration 25440 : model1 loss : 0.439608 model2 loss : 0.018593
[12:09:47.805] iteration 25441 : model1 loss : 0.444573 model2 loss : 0.018135
[12:09:47.974] iteration 25442 : model1 loss : 0.443444 model2 loss : 0.020918
[12:09:48.143] iteration 25443 : model1 loss : 0.442150 model2 loss : 0.018245
[12:09:50.082] iteration 25444 : model1 loss : 0.439950 model2 loss : 0.019553
[12:09:50.251] iteration 25445 : model1 loss : 0.434696 model2 loss : 0.020165
[12:09:50.420] iteration 25446 : model1 loss : 0.438817 model2 loss : 0.018077
[12:09:50.586] iteration 25447 : model1 loss : 0.446110 model2 loss : 0.022907
[12:09:50.756] iteration 25448 : model1 loss : 0.439324 model2 loss : 0.019307
[12:09:50.925] iteration 25449 : model1 loss : 0.443182 model2 loss : 0.022421
[12:09:51.093] iteration 25450 : model1 loss : 0.445543 model2 loss : 0.021609
[12:09:51.259] iteration 25451 : model1 loss : 0.437062 model2 loss : 0.019871
[12:09:51.428] iteration 25452 : model1 loss : 0.437566 model2 loss : 0.020813
[12:09:51.595] iteration 25453 : model1 loss : 0.435715 model2 loss : 0.019706
[12:09:51.763] iteration 25454 : model1 loss : 0.441281 model2 loss : 0.018353
[12:09:51.933] iteration 25455 : model1 loss : 0.434406 model2 loss : 0.017514
[12:09:52.101] iteration 25456 : model1 loss : 0.442450 model2 loss : 0.020153
[12:09:52.269] iteration 25457 : model1 loss : 0.441145 model2 loss : 0.017878
[12:09:52.439] iteration 25458 : model1 loss : 0.440907 model2 loss : 0.021588
[12:09:52.605] iteration 25459 : model1 loss : 0.441448 model2 loss : 0.019918
[12:09:52.773] iteration 25460 : model1 loss : 0.439910 model2 loss : 0.020186
[12:09:52.943] iteration 25461 : model1 loss : 0.438884 model2 loss : 0.017693
[12:09:53.115] iteration 25462 : model1 loss : 0.438969 model2 loss : 0.019546
[12:09:53.281] iteration 25463 : model1 loss : 0.440653 model2 loss : 0.019120
[12:09:53.451] iteration 25464 : model1 loss : 0.437292 model2 loss : 0.019250
[12:09:53.618] iteration 25465 : model1 loss : 0.440328 model2 loss : 0.018416
[12:09:53.788] iteration 25466 : model1 loss : 0.439634 model2 loss : 0.019886
[12:09:53.955] iteration 25467 : model1 loss : 0.438748 model2 loss : 0.019334
[12:09:54.125] iteration 25468 : model1 loss : 0.439994 model2 loss : 0.017975
[12:09:54.290] iteration 25469 : model1 loss : 0.438268 model2 loss : 0.020480
[12:09:54.458] iteration 25470 : model1 loss : 0.439006 model2 loss : 0.020119
[12:09:54.625] iteration 25471 : model1 loss : 0.442127 model2 loss : 0.020847
[12:09:54.798] iteration 25472 : model1 loss : 0.440486 model2 loss : 0.019941
[12:09:54.967] iteration 25473 : model1 loss : 0.438290 model2 loss : 0.017570
[12:09:55.139] iteration 25474 : model1 loss : 0.439694 model2 loss : 0.017136
[12:09:55.303] iteration 25475 : model1 loss : 0.436790 model2 loss : 0.018217
[12:09:55.470] iteration 25476 : model1 loss : 0.443194 model2 loss : 0.020489
[12:09:57.378] iteration 25477 : model1 loss : 0.443283 model2 loss : 0.021219
[12:09:57.550] iteration 25478 : model1 loss : 0.433347 model2 loss : 0.017642
[12:09:57.720] iteration 25479 : model1 loss : 0.445539 model2 loss : 0.024904
[12:09:57.886] iteration 25480 : model1 loss : 0.440967 model2 loss : 0.019843
[12:09:58.057] iteration 25481 : model1 loss : 0.435254 model2 loss : 0.018797
[12:09:58.225] iteration 25482 : model1 loss : 0.441133 model2 loss : 0.020731
[12:09:58.391] iteration 25483 : model1 loss : 0.441895 model2 loss : 0.020366
[12:09:58.559] iteration 25484 : model1 loss : 0.436541 model2 loss : 0.018666
[12:09:58.728] iteration 25485 : model1 loss : 0.437772 model2 loss : 0.018872
[12:09:58.895] iteration 25486 : model1 loss : 0.435226 model2 loss : 0.018258
[12:09:59.065] iteration 25487 : model1 loss : 0.444455 model2 loss : 0.022158
[12:09:59.232] iteration 25488 : model1 loss : 0.437772 model2 loss : 0.017715
[12:09:59.402] iteration 25489 : model1 loss : 0.444163 model2 loss : 0.020141
[12:09:59.567] iteration 25490 : model1 loss : 0.440503 model2 loss : 0.018265
[12:09:59.736] iteration 25491 : model1 loss : 0.438987 model2 loss : 0.023238
[12:09:59.902] iteration 25492 : model1 loss : 0.440538 model2 loss : 0.020016
[12:10:00.073] iteration 25493 : model1 loss : 0.435105 model2 loss : 0.017160
[12:10:00.240] iteration 25494 : model1 loss : 0.437982 model2 loss : 0.017446
[12:10:00.409] iteration 25495 : model1 loss : 0.438115 model2 loss : 0.018735
[12:10:00.577] iteration 25496 : model1 loss : 0.437724 model2 loss : 0.019890
[12:10:00.747] iteration 25497 : model1 loss : 0.439267 model2 loss : 0.020699
[12:10:00.917] iteration 25498 : model1 loss : 0.438601 model2 loss : 0.020563
[12:10:01.086] iteration 25499 : model1 loss : 0.440256 model2 loss : 0.021835
[12:10:01.253] iteration 25500 : model1 loss : 0.446028 model2 loss : 0.021087
[12:10:01.421] iteration 25501 : model1 loss : 0.441094 model2 loss : 0.021420
[12:10:01.589] iteration 25502 : model1 loss : 0.438928 model2 loss : 0.019342
[12:10:01.758] iteration 25503 : model1 loss : 0.442914 model2 loss : 0.020454
[12:10:01.926] iteration 25504 : model1 loss : 0.442724 model2 loss : 0.020625
[12:10:02.097] iteration 25505 : model1 loss : 0.446528 model2 loss : 0.020992
[12:10:02.264] iteration 25506 : model1 loss : 0.438790 model2 loss : 0.019459
[12:10:02.433] iteration 25507 : model1 loss : 0.440427 model2 loss : 0.018883
[12:10:02.599] iteration 25508 : model1 loss : 0.435180 model2 loss : 0.017798
[12:10:02.767] iteration 25509 : model1 loss : 0.441315 model2 loss : 0.016859
[12:10:04.698] iteration 25510 : model1 loss : 0.440647 model2 loss : 0.019725
[12:10:04.864] iteration 25511 : model1 loss : 0.443507 model2 loss : 0.022321
[12:10:05.034] iteration 25512 : model1 loss : 0.436915 model2 loss : 0.020102
[12:10:05.202] iteration 25513 : model1 loss : 0.441433 model2 loss : 0.017653
[12:10:05.371] iteration 25514 : model1 loss : 0.436562 model2 loss : 0.018098
[12:10:05.540] iteration 25515 : model1 loss : 0.442759 model2 loss : 0.021018
[12:10:05.710] iteration 25516 : model1 loss : 0.441031 model2 loss : 0.021455
[12:10:05.880] iteration 25517 : model1 loss : 0.438682 model2 loss : 0.019396
[12:10:06.050] iteration 25518 : model1 loss : 0.439307 model2 loss : 0.020466
[12:10:06.218] iteration 25519 : model1 loss : 0.438328 model2 loss : 0.017671
[12:10:06.388] iteration 25520 : model1 loss : 0.437814 model2 loss : 0.019541
[12:10:06.555] iteration 25521 : model1 loss : 0.444807 model2 loss : 0.019436
[12:10:06.724] iteration 25522 : model1 loss : 0.443617 model2 loss : 0.020682
[12:10:06.892] iteration 25523 : model1 loss : 0.438127 model2 loss : 0.019219
[12:10:07.060] iteration 25524 : model1 loss : 0.442815 model2 loss : 0.018886
[12:10:07.228] iteration 25525 : model1 loss : 0.439309 model2 loss : 0.020002
[12:10:07.397] iteration 25526 : model1 loss : 0.440017 model2 loss : 0.020531
[12:10:07.564] iteration 25527 : model1 loss : 0.442538 model2 loss : 0.020072
[12:10:07.733] iteration 25528 : model1 loss : 0.436923 model2 loss : 0.017989
[12:10:07.901] iteration 25529 : model1 loss : 0.441997 model2 loss : 0.019988
[12:10:08.070] iteration 25530 : model1 loss : 0.438935 model2 loss : 0.020459
[12:10:08.238] iteration 25531 : model1 loss : 0.437248 model2 loss : 0.019900
[12:10:08.407] iteration 25532 : model1 loss : 0.442323 model2 loss : 0.020059
[12:10:08.574] iteration 25533 : model1 loss : 0.440106 model2 loss : 0.020317
[12:10:08.741] iteration 25534 : model1 loss : 0.441081 model2 loss : 0.019691
[12:10:08.909] iteration 25535 : model1 loss : 0.437960 model2 loss : 0.019302
[12:10:09.078] iteration 25536 : model1 loss : 0.434001 model2 loss : 0.017379
[12:10:09.244] iteration 25537 : model1 loss : 0.443747 model2 loss : 0.020047
[12:10:09.412] iteration 25538 : model1 loss : 0.436464 model2 loss : 0.019382
[12:10:09.580] iteration 25539 : model1 loss : 0.442854 model2 loss : 0.020483
[12:10:09.748] iteration 25540 : model1 loss : 0.436681 model2 loss : 0.020747
[12:10:09.917] iteration 25541 : model1 loss : 0.435102 model2 loss : 0.018071
[12:10:10.086] iteration 25542 : model1 loss : 0.441421 model2 loss : 0.022364
[12:10:12.007] iteration 25543 : model1 loss : 0.444808 model2 loss : 0.019678
[12:10:12.174] iteration 25544 : model1 loss : 0.439498 model2 loss : 0.018039
[12:10:12.343] iteration 25545 : model1 loss : 0.438161 model2 loss : 0.020371
[12:10:12.516] iteration 25546 : model1 loss : 0.445229 model2 loss : 0.021877
[12:10:12.684] iteration 25547 : model1 loss : 0.437063 model2 loss : 0.020569
[12:10:12.852] iteration 25548 : model1 loss : 0.441002 model2 loss : 0.019236
[12:10:13.024] iteration 25549 : model1 loss : 0.439916 model2 loss : 0.018091
[12:10:13.193] iteration 25550 : model1 loss : 0.438304 model2 loss : 0.020298
[12:10:13.363] iteration 25551 : model1 loss : 0.438366 model2 loss : 0.019100
[12:10:13.531] iteration 25552 : model1 loss : 0.444846 model2 loss : 0.021279
[12:10:13.704] iteration 25553 : model1 loss : 0.440064 model2 loss : 0.018372
[12:10:13.874] iteration 25554 : model1 loss : 0.438498 model2 loss : 0.017317
[12:10:14.044] iteration 25555 : model1 loss : 0.433986 model2 loss : 0.017687
[12:10:14.215] iteration 25556 : model1 loss : 0.441093 model2 loss : 0.020944
[12:10:14.382] iteration 25557 : model1 loss : 0.438840 model2 loss : 0.020939
[12:10:14.549] iteration 25558 : model1 loss : 0.436587 model2 loss : 0.017941
[12:10:14.719] iteration 25559 : model1 loss : 0.438793 model2 loss : 0.019928
[12:10:14.887] iteration 25560 : model1 loss : 0.442332 model2 loss : 0.020126
[12:10:15.058] iteration 25561 : model1 loss : 0.443290 model2 loss : 0.020298
[12:10:15.229] iteration 25562 : model1 loss : 0.437088 model2 loss : 0.018522
[12:10:15.398] iteration 25563 : model1 loss : 0.440574 model2 loss : 0.018326
[12:10:15.566] iteration 25564 : model1 loss : 0.437506 model2 loss : 0.021127
[12:10:15.735] iteration 25565 : model1 loss : 0.439782 model2 loss : 0.021034
[12:10:15.904] iteration 25566 : model1 loss : 0.440522 model2 loss : 0.019624
[12:10:16.073] iteration 25567 : model1 loss : 0.445290 model2 loss : 0.023871
[12:10:16.240] iteration 25568 : model1 loss : 0.442189 model2 loss : 0.019575
[12:10:16.408] iteration 25569 : model1 loss : 0.442210 model2 loss : 0.019414
[12:10:16.576] iteration 25570 : model1 loss : 0.439126 model2 loss : 0.021283
[12:10:16.745] iteration 25571 : model1 loss : 0.437135 model2 loss : 0.019400
[12:10:16.912] iteration 25572 : model1 loss : 0.438740 model2 loss : 0.020314
[12:10:17.082] iteration 25573 : model1 loss : 0.440128 model2 loss : 0.020023
[12:10:17.248] iteration 25574 : model1 loss : 0.435969 model2 loss : 0.019027
[12:10:17.417] iteration 25575 : model1 loss : 0.438659 model2 loss : 0.018739
[12:10:19.355] iteration 25576 : model1 loss : 0.434753 model2 loss : 0.019694
[12:10:19.526] iteration 25577 : model1 loss : 0.437733 model2 loss : 0.019678
[12:10:19.694] iteration 25578 : model1 loss : 0.440638 model2 loss : 0.018652
[12:10:19.861] iteration 25579 : model1 loss : 0.444659 model2 loss : 0.022483
[12:10:20.033] iteration 25580 : model1 loss : 0.441515 model2 loss : 0.021572
[12:10:20.206] iteration 25581 : model1 loss : 0.444997 model2 loss : 0.024009
[12:10:20.376] iteration 25582 : model1 loss : 0.441198 model2 loss : 0.021224
[12:10:20.541] iteration 25583 : model1 loss : 0.437702 model2 loss : 0.020744
[12:10:20.711] iteration 25584 : model1 loss : 0.443158 model2 loss : 0.018261
[12:10:20.879] iteration 25585 : model1 loss : 0.439161 model2 loss : 0.019854
[12:10:21.047] iteration 25586 : model1 loss : 0.443713 model2 loss : 0.021313
[12:10:21.220] iteration 25587 : model1 loss : 0.443834 model2 loss : 0.020750
[12:10:21.388] iteration 25588 : model1 loss : 0.443593 model2 loss : 0.021716
[12:10:21.554] iteration 25589 : model1 loss : 0.437558 model2 loss : 0.017917
[12:10:21.725] iteration 25590 : model1 loss : 0.443381 model2 loss : 0.022720
[12:10:21.890] iteration 25591 : model1 loss : 0.435561 model2 loss : 0.019352
[12:10:22.061] iteration 25592 : model1 loss : 0.441190 model2 loss : 0.020410
[12:10:22.228] iteration 25593 : model1 loss : 0.440311 model2 loss : 0.020820
[12:10:22.398] iteration 25594 : model1 loss : 0.441143 model2 loss : 0.020758
[12:10:22.566] iteration 25595 : model1 loss : 0.440870 model2 loss : 0.020802
[12:10:22.737] iteration 25596 : model1 loss : 0.442061 model2 loss : 0.019448
[12:10:22.904] iteration 25597 : model1 loss : 0.439124 model2 loss : 0.020540
[12:10:23.075] iteration 25598 : model1 loss : 0.441294 model2 loss : 0.019630
[12:10:23.241] iteration 25599 : model1 loss : 0.438957 model2 loss : 0.021613
[12:10:23.409] iteration 25600 : model1 loss : 0.436083 model2 loss : 0.019823
[12:10:23.575] iteration 25601 : model1 loss : 0.432680 model2 loss : 0.018184
[12:10:23.745] iteration 25602 : model1 loss : 0.440074 model2 loss : 0.019655
[12:10:23.912] iteration 25603 : model1 loss : 0.441688 model2 loss : 0.020866
[12:10:24.083] iteration 25604 : model1 loss : 0.436933 model2 loss : 0.018427
[12:10:24.251] iteration 25605 : model1 loss : 0.437372 model2 loss : 0.020405
[12:10:24.419] iteration 25606 : model1 loss : 0.437386 model2 loss : 0.019602
[12:10:24.585] iteration 25607 : model1 loss : 0.435189 model2 loss : 0.018996
[12:10:24.752] iteration 25608 : model1 loss : 0.440935 model2 loss : 0.022611
[12:10:26.705] iteration 25609 : model1 loss : 0.436961 model2 loss : 0.019920
[12:10:26.875] iteration 25610 : model1 loss : 0.436919 model2 loss : 0.018936
[12:10:27.046] iteration 25611 : model1 loss : 0.444538 model2 loss : 0.020307
[12:10:27.215] iteration 25612 : model1 loss : 0.441246 model2 loss : 0.019918
[12:10:27.386] iteration 25613 : model1 loss : 0.440870 model2 loss : 0.020536
[12:10:27.553] iteration 25614 : model1 loss : 0.439491 model2 loss : 0.021665
[12:10:27.724] iteration 25615 : model1 loss : 0.439478 model2 loss : 0.020464
[12:10:27.890] iteration 25616 : model1 loss : 0.438913 model2 loss : 0.017723
[12:10:28.060] iteration 25617 : model1 loss : 0.443442 model2 loss : 0.022080
[12:10:28.228] iteration 25618 : model1 loss : 0.438289 model2 loss : 0.020308
[12:10:28.397] iteration 25619 : model1 loss : 0.440194 model2 loss : 0.020637
[12:10:28.564] iteration 25620 : model1 loss : 0.445447 model2 loss : 0.020721
[12:10:28.732] iteration 25621 : model1 loss : 0.437111 model2 loss : 0.020656
[12:10:28.900] iteration 25622 : model1 loss : 0.440649 model2 loss : 0.020310
[12:10:29.071] iteration 25623 : model1 loss : 0.439188 model2 loss : 0.020270
[12:10:29.239] iteration 25624 : model1 loss : 0.439370 model2 loss : 0.017698
[12:10:29.408] iteration 25625 : model1 loss : 0.441534 model2 loss : 0.018206
[12:10:29.575] iteration 25626 : model1 loss : 0.441669 model2 loss : 0.020782
[12:10:29.745] iteration 25627 : model1 loss : 0.439763 model2 loss : 0.019118
[12:10:29.913] iteration 25628 : model1 loss : 0.439455 model2 loss : 0.018691
[12:10:30.083] iteration 25629 : model1 loss : 0.440645 model2 loss : 0.019549
[12:10:30.251] iteration 25630 : model1 loss : 0.437491 model2 loss : 0.017692
[12:10:30.420] iteration 25631 : model1 loss : 0.439941 model2 loss : 0.020050
[12:10:30.588] iteration 25632 : model1 loss : 0.438664 model2 loss : 0.020187
[12:10:30.758] iteration 25633 : model1 loss : 0.440706 model2 loss : 0.019074
[12:10:30.928] iteration 25634 : model1 loss : 0.438330 model2 loss : 0.018323
[12:10:31.100] iteration 25635 : model1 loss : 0.438107 model2 loss : 0.019772
[12:10:31.267] iteration 25636 : model1 loss : 0.438069 model2 loss : 0.018789
[12:10:31.436] iteration 25637 : model1 loss : 0.441365 model2 loss : 0.020491
[12:10:31.601] iteration 25638 : model1 loss : 0.440201 model2 loss : 0.019689
[12:10:31.771] iteration 25639 : model1 loss : 0.439169 model2 loss : 0.021313
[12:10:31.937] iteration 25640 : model1 loss : 0.440811 model2 loss : 0.021004
[12:10:32.107] iteration 25641 : model1 loss : 0.436543 model2 loss : 0.019741
[12:10:34.043] iteration 25642 : model1 loss : 0.440673 model2 loss : 0.019501
[12:10:34.211] iteration 25643 : model1 loss : 0.442282 model2 loss : 0.021489
[12:10:34.382] iteration 25644 : model1 loss : 0.442227 model2 loss : 0.020806
[12:10:34.550] iteration 25645 : model1 loss : 0.436368 model2 loss : 0.019837
[12:10:34.717] iteration 25646 : model1 loss : 0.441951 model2 loss : 0.021452
[12:10:34.886] iteration 25647 : model1 loss : 0.441474 model2 loss : 0.020132
[12:10:35.055] iteration 25648 : model1 loss : 0.437521 model2 loss : 0.019453
[12:10:35.226] iteration 25649 : model1 loss : 0.440027 model2 loss : 0.020068
[12:10:35.393] iteration 25650 : model1 loss : 0.437230 model2 loss : 0.019990
[12:10:35.560] iteration 25651 : model1 loss : 0.435456 model2 loss : 0.019466
[12:10:35.728] iteration 25652 : model1 loss : 0.441641 model2 loss : 0.019208
[12:10:35.897] iteration 25653 : model1 loss : 0.442168 model2 loss : 0.021645
[12:10:36.067] iteration 25654 : model1 loss : 0.440939 model2 loss : 0.019127
[12:10:36.235] iteration 25655 : model1 loss : 0.443343 model2 loss : 0.021924
[12:10:36.404] iteration 25656 : model1 loss : 0.438174 model2 loss : 0.018182
[12:10:36.570] iteration 25657 : model1 loss : 0.437364 model2 loss : 0.021093
[12:10:36.739] iteration 25658 : model1 loss : 0.441996 model2 loss : 0.018749
[12:10:36.907] iteration 25659 : model1 loss : 0.440563 model2 loss : 0.019464
[12:10:37.076] iteration 25660 : model1 loss : 0.441569 model2 loss : 0.016971
[12:10:37.245] iteration 25661 : model1 loss : 0.440411 model2 loss : 0.021621
[12:10:37.414] iteration 25662 : model1 loss : 0.439041 model2 loss : 0.021772
[12:10:37.580] iteration 25663 : model1 loss : 0.440457 model2 loss : 0.021702
[12:10:37.749] iteration 25664 : model1 loss : 0.441304 model2 loss : 0.019269
[12:10:37.916] iteration 25665 : model1 loss : 0.437844 model2 loss : 0.019510
[12:10:38.086] iteration 25666 : model1 loss : 0.436372 model2 loss : 0.019601
[12:10:38.253] iteration 25667 : model1 loss : 0.437975 model2 loss : 0.018410
[12:10:38.423] iteration 25668 : model1 loss : 0.437727 model2 loss : 0.020154
[12:10:38.591] iteration 25669 : model1 loss : 0.442890 model2 loss : 0.019032
[12:10:38.760] iteration 25670 : model1 loss : 0.442045 model2 loss : 0.021093
[12:10:38.928] iteration 25671 : model1 loss : 0.442141 model2 loss : 0.022518
[12:10:39.098] iteration 25672 : model1 loss : 0.439882 model2 loss : 0.022615
[12:10:39.274] iteration 25673 : model1 loss : 0.438663 model2 loss : 0.018678
[12:10:39.441] iteration 25674 : model1 loss : 0.437771 model2 loss : 0.020505
[12:10:41.358] iteration 25675 : model1 loss : 0.441162 model2 loss : 0.021933
[12:10:41.527] iteration 25676 : model1 loss : 0.443352 model2 loss : 0.021999
[12:10:41.696] iteration 25677 : model1 loss : 0.441378 model2 loss : 0.019139
[12:10:41.865] iteration 25678 : model1 loss : 0.436401 model2 loss : 0.019046
[12:10:42.034] iteration 25679 : model1 loss : 0.437027 model2 loss : 0.017912
[12:10:42.203] iteration 25680 : model1 loss : 0.439704 model2 loss : 0.018507
[12:10:42.372] iteration 25681 : model1 loss : 0.443484 model2 loss : 0.022566
[12:10:42.542] iteration 25682 : model1 loss : 0.437301 model2 loss : 0.019224
[12:10:42.710] iteration 25683 : model1 loss : 0.439277 model2 loss : 0.021504
[12:10:42.879] iteration 25684 : model1 loss : 0.439116 model2 loss : 0.019740
[12:10:43.048] iteration 25685 : model1 loss : 0.438418 model2 loss : 0.019514
[12:10:43.219] iteration 25686 : model1 loss : 0.435456 model2 loss : 0.020095
[12:10:43.388] iteration 25687 : model1 loss : 0.443228 model2 loss : 0.020159
[12:10:43.555] iteration 25688 : model1 loss : 0.440041 model2 loss : 0.020854
[12:10:43.726] iteration 25689 : model1 loss : 0.436074 model2 loss : 0.017928
[12:10:43.893] iteration 25690 : model1 loss : 0.441585 model2 loss : 0.019756
[12:10:44.062] iteration 25691 : model1 loss : 0.439971 model2 loss : 0.019971
[12:10:44.232] iteration 25692 : model1 loss : 0.438920 model2 loss : 0.018446
[12:10:44.399] iteration 25693 : model1 loss : 0.439818 model2 loss : 0.020257
[12:10:44.567] iteration 25694 : model1 loss : 0.442163 model2 loss : 0.019317
[12:10:44.735] iteration 25695 : model1 loss : 0.439890 model2 loss : 0.021353
[12:10:44.902] iteration 25696 : model1 loss : 0.435464 model2 loss : 0.020276
[12:10:45.074] iteration 25697 : model1 loss : 0.443257 model2 loss : 0.020169
[12:10:45.244] iteration 25698 : model1 loss : 0.444483 model2 loss : 0.023284
[12:10:45.414] iteration 25699 : model1 loss : 0.436476 model2 loss : 0.020713
[12:10:45.582] iteration 25700 : model1 loss : 0.442300 model2 loss : 0.019428
[12:10:45.751] iteration 25701 : model1 loss : 0.438736 model2 loss : 0.020437
[12:10:45.922] iteration 25702 : model1 loss : 0.437218 model2 loss : 0.018701
[12:10:46.091] iteration 25703 : model1 loss : 0.440858 model2 loss : 0.019950
[12:10:46.258] iteration 25704 : model1 loss : 0.442833 model2 loss : 0.020360
[12:10:46.427] iteration 25705 : model1 loss : 0.440862 model2 loss : 0.017004
[12:10:46.596] iteration 25706 : model1 loss : 0.441865 model2 loss : 0.021498
[12:10:46.764] iteration 25707 : model1 loss : 0.440347 model2 loss : 0.020944
[12:10:48.728] iteration 25708 : model1 loss : 0.438910 model2 loss : 0.019422
[12:10:48.896] iteration 25709 : model1 loss : 0.441848 model2 loss : 0.019915
[12:10:49.069] iteration 25710 : model1 loss : 0.438992 model2 loss : 0.020930
[12:10:49.238] iteration 25711 : model1 loss : 0.439590 model2 loss : 0.020311
[12:10:49.409] iteration 25712 : model1 loss : 0.435867 model2 loss : 0.019705
[12:10:49.578] iteration 25713 : model1 loss : 0.440645 model2 loss : 0.020922
[12:10:49.749] iteration 25714 : model1 loss : 0.441500 model2 loss : 0.021690
[12:10:49.916] iteration 25715 : model1 loss : 0.440760 model2 loss : 0.020234
[12:10:50.088] iteration 25716 : model1 loss : 0.436651 model2 loss : 0.019463
[12:10:50.256] iteration 25717 : model1 loss : 0.444807 model2 loss : 0.022168
[12:10:50.425] iteration 25718 : model1 loss : 0.442406 model2 loss : 0.021393
[12:10:50.594] iteration 25719 : model1 loss : 0.437770 model2 loss : 0.018492
[12:10:50.762] iteration 25720 : model1 loss : 0.441716 model2 loss : 0.019370
[12:10:50.931] iteration 25721 : model1 loss : 0.436850 model2 loss : 0.019850
[12:10:51.101] iteration 25722 : model1 loss : 0.440363 model2 loss : 0.018953
[12:10:51.269] iteration 25723 : model1 loss : 0.437642 model2 loss : 0.018968
[12:10:51.461] iteration 25724 : model1 loss : 0.440096 model2 loss : 0.020065
[12:10:51.629] iteration 25725 : model1 loss : 0.439473 model2 loss : 0.020118
[12:10:51.801] iteration 25726 : model1 loss : 0.438496 model2 loss : 0.018699
[12:10:51.968] iteration 25727 : model1 loss : 0.436786 model2 loss : 0.020043
[12:10:52.137] iteration 25728 : model1 loss : 0.437702 model2 loss : 0.017730
[12:10:52.305] iteration 25729 : model1 loss : 0.435794 model2 loss : 0.018694
[12:10:52.475] iteration 25730 : model1 loss : 0.442756 model2 loss : 0.021318
[12:10:52.641] iteration 25731 : model1 loss : 0.442961 model2 loss : 0.018786
[12:10:52.810] iteration 25732 : model1 loss : 0.438451 model2 loss : 0.019513
[12:10:52.978] iteration 25733 : model1 loss : 0.439071 model2 loss : 0.018340
[12:10:53.165] iteration 25734 : model1 loss : 0.440211 model2 loss : 0.017508
[12:10:53.332] iteration 25735 : model1 loss : 0.443327 model2 loss : 0.019922
[12:10:53.506] iteration 25736 : model1 loss : 0.438943 model2 loss : 0.018281
[12:10:53.673] iteration 25737 : model1 loss : 0.442609 model2 loss : 0.021191
[12:10:53.844] iteration 25738 : model1 loss : 0.438944 model2 loss : 0.019335
[12:10:54.010] iteration 25739 : model1 loss : 0.440773 model2 loss : 0.022737
[12:10:54.179] iteration 25740 : model1 loss : 0.442294 model2 loss : 0.018209
[12:10:56.116] iteration 25741 : model1 loss : 0.440140 model2 loss : 0.019147
[12:10:56.286] iteration 25742 : model1 loss : 0.439708 model2 loss : 0.017990
[12:10:56.456] iteration 25743 : model1 loss : 0.436251 model2 loss : 0.018639
[12:10:56.623] iteration 25744 : model1 loss : 0.443050 model2 loss : 0.019796
[12:10:56.791] iteration 25745 : model1 loss : 0.442542 model2 loss : 0.020185
[12:10:56.958] iteration 25746 : model1 loss : 0.438584 model2 loss : 0.020200
[12:10:57.126] iteration 25747 : model1 loss : 0.438361 model2 loss : 0.020215
[12:10:57.294] iteration 25748 : model1 loss : 0.435005 model2 loss : 0.018167
[12:10:57.462] iteration 25749 : model1 loss : 0.436793 model2 loss : 0.019230
[12:10:57.631] iteration 25750 : model1 loss : 0.439510 model2 loss : 0.021647
[12:10:57.801] iteration 25751 : model1 loss : 0.440863 model2 loss : 0.018649
[12:10:57.968] iteration 25752 : model1 loss : 0.444362 model2 loss : 0.023058
[12:10:58.137] iteration 25753 : model1 loss : 0.436150 model2 loss : 0.019148
[12:10:58.304] iteration 25754 : model1 loss : 0.438764 model2 loss : 0.022190
[12:10:58.472] iteration 25755 : model1 loss : 0.446031 model2 loss : 0.019987
[12:10:58.639] iteration 25756 : model1 loss : 0.435057 model2 loss : 0.019541
[12:10:58.810] iteration 25757 : model1 loss : 0.436813 model2 loss : 0.020038
[12:10:58.978] iteration 25758 : model1 loss : 0.444857 model2 loss : 0.019777
[12:10:59.148] iteration 25759 : model1 loss : 0.443033 model2 loss : 0.019313
[12:10:59.314] iteration 25760 : model1 loss : 0.437392 model2 loss : 0.019524
[12:10:59.482] iteration 25761 : model1 loss : 0.444501 model2 loss : 0.019601
[12:10:59.650] iteration 25762 : model1 loss : 0.441652 model2 loss : 0.022389
[12:10:59.818] iteration 25763 : model1 loss : 0.436653 model2 loss : 0.019944
[12:10:59.986] iteration 25764 : model1 loss : 0.441430 model2 loss : 0.019584
[12:11:00.160] iteration 25765 : model1 loss : 0.438300 model2 loss : 0.018626
[12:11:00.327] iteration 25766 : model1 loss : 0.439632 model2 loss : 0.019675
[12:11:00.498] iteration 25767 : model1 loss : 0.437234 model2 loss : 0.017837
[12:11:00.667] iteration 25768 : model1 loss : 0.441570 model2 loss : 0.018899
[12:11:00.835] iteration 25769 : model1 loss : 0.436838 model2 loss : 0.017785
[12:11:01.003] iteration 25770 : model1 loss : 0.440107 model2 loss : 0.019284
[12:11:01.174] iteration 25771 : model1 loss : 0.440985 model2 loss : 0.019231
[12:11:01.339] iteration 25772 : model1 loss : 0.441062 model2 loss : 0.018861
[12:11:01.510] iteration 25773 : model1 loss : 0.440940 model2 loss : 0.020010
[12:11:03.404] iteration 25774 : model1 loss : 0.440635 model2 loss : 0.018279
[12:11:03.572] iteration 25775 : model1 loss : 0.436420 model2 loss : 0.018668
[12:11:03.741] iteration 25776 : model1 loss : 0.436305 model2 loss : 0.018636
[12:11:03.907] iteration 25777 : model1 loss : 0.441939 model2 loss : 0.020572
[12:11:04.077] iteration 25778 : model1 loss : 0.438665 model2 loss : 0.020286
[12:11:04.247] iteration 25779 : model1 loss : 0.442663 model2 loss : 0.019939
[12:11:04.417] iteration 25780 : model1 loss : 0.443346 model2 loss : 0.017428
[12:11:04.584] iteration 25781 : model1 loss : 0.434474 model2 loss : 0.019714
[12:11:04.753] iteration 25782 : model1 loss : 0.437034 model2 loss : 0.019512
[12:11:04.922] iteration 25783 : model1 loss : 0.436447 model2 loss : 0.018978
[12:11:05.090] iteration 25784 : model1 loss : 0.438856 model2 loss : 0.020339
[12:11:05.260] iteration 25785 : model1 loss : 0.439523 model2 loss : 0.022305
[12:11:05.431] iteration 25786 : model1 loss : 0.442686 model2 loss : 0.020648
[12:11:05.599] iteration 25787 : model1 loss : 0.439530 model2 loss : 0.019364
[12:11:05.768] iteration 25788 : model1 loss : 0.438253 model2 loss : 0.018249
[12:11:05.939] iteration 25789 : model1 loss : 0.440337 model2 loss : 0.020389
[12:11:06.110] iteration 25790 : model1 loss : 0.436923 model2 loss : 0.019691
[12:11:06.278] iteration 25791 : model1 loss : 0.440038 model2 loss : 0.021595
[12:11:06.447] iteration 25792 : model1 loss : 0.437978 model2 loss : 0.020375
[12:11:06.614] iteration 25793 : model1 loss : 0.439069 model2 loss : 0.018784
[12:11:06.784] iteration 25794 : model1 loss : 0.443813 model2 loss : 0.021253
[12:11:06.955] iteration 25795 : model1 loss : 0.438840 model2 loss : 0.017924
[12:11:07.125] iteration 25796 : model1 loss : 0.436962 model2 loss : 0.019522
[12:11:07.293] iteration 25797 : model1 loss : 0.441976 model2 loss : 0.020060
[12:11:07.463] iteration 25798 : model1 loss : 0.439218 model2 loss : 0.019031
[12:11:07.630] iteration 25799 : model1 loss : 0.440789 model2 loss : 0.019893
[12:11:07.797] iteration 25800 : model1 loss : 0.447160 model2 loss : 0.022388
[12:11:07.964] iteration 25801 : model1 loss : 0.442939 model2 loss : 0.020065
[12:11:08.134] iteration 25802 : model1 loss : 0.439114 model2 loss : 0.020278
[12:11:08.302] iteration 25803 : model1 loss : 0.440723 model2 loss : 0.021051
[12:11:08.473] iteration 25804 : model1 loss : 0.442525 model2 loss : 0.019962
[12:11:08.640] iteration 25805 : model1 loss : 0.436010 model2 loss : 0.019477
[12:11:08.809] iteration 25806 : model1 loss : 0.444278 model2 loss : 0.021305
[12:11:10.739] iteration 25807 : model1 loss : 0.440593 model2 loss : 0.019703
[12:11:10.909] iteration 25808 : model1 loss : 0.433302 model2 loss : 0.017649
[12:11:11.078] iteration 25809 : model1 loss : 0.442866 model2 loss : 0.020734
[12:11:11.249] iteration 25810 : model1 loss : 0.437056 model2 loss : 0.020463
[12:11:11.418] iteration 25811 : model1 loss : 0.437291 model2 loss : 0.020999
[12:11:11.584] iteration 25812 : model1 loss : 0.442380 model2 loss : 0.020365
[12:11:11.753] iteration 25813 : model1 loss : 0.441866 model2 loss : 0.018682
[12:11:11.923] iteration 25814 : model1 loss : 0.434533 model2 loss : 0.019000
[12:11:12.095] iteration 25815 : model1 loss : 0.434897 model2 loss : 0.019067
[12:11:12.262] iteration 25816 : model1 loss : 0.441659 model2 loss : 0.021939
[12:11:12.430] iteration 25817 : model1 loss : 0.438699 model2 loss : 0.020699
[12:11:12.596] iteration 25818 : model1 loss : 0.438610 model2 loss : 0.018519
[12:11:12.764] iteration 25819 : model1 loss : 0.438648 model2 loss : 0.019224
[12:11:12.933] iteration 25820 : model1 loss : 0.444209 model2 loss : 0.021688
[12:11:13.102] iteration 25821 : model1 loss : 0.439951 model2 loss : 0.018828
[12:11:13.270] iteration 25822 : model1 loss : 0.438375 model2 loss : 0.018486
[12:11:13.438] iteration 25823 : model1 loss : 0.437533 model2 loss : 0.020587
[12:11:13.603] iteration 25824 : model1 loss : 0.442230 model2 loss : 0.019047
[12:11:13.777] iteration 25825 : model1 loss : 0.444546 model2 loss : 0.020996
[12:11:13.943] iteration 25826 : model1 loss : 0.437667 model2 loss : 0.018894
[12:11:14.113] iteration 25827 : model1 loss : 0.440706 model2 loss : 0.018862
[12:11:14.281] iteration 25828 : model1 loss : 0.439429 model2 loss : 0.018504
[12:11:14.450] iteration 25829 : model1 loss : 0.442727 model2 loss : 0.024556
[12:11:14.617] iteration 25830 : model1 loss : 0.439423 model2 loss : 0.018560
[12:11:14.786] iteration 25831 : model1 loss : 0.439466 model2 loss : 0.019822
[12:11:14.954] iteration 25832 : model1 loss : 0.444907 model2 loss : 0.021145
[12:11:15.124] iteration 25833 : model1 loss : 0.440843 model2 loss : 0.019266
[12:11:15.292] iteration 25834 : model1 loss : 0.442395 model2 loss : 0.021082
[12:11:15.462] iteration 25835 : model1 loss : 0.436814 model2 loss : 0.019381
[12:11:15.629] iteration 25836 : model1 loss : 0.438588 model2 loss : 0.017954
[12:11:15.797] iteration 25837 : model1 loss : 0.443256 model2 loss : 0.019640
[12:11:15.964] iteration 25838 : model1 loss : 0.441149 model2 loss : 0.018940
[12:11:16.132] iteration 25839 : model1 loss : 0.441513 model2 loss : 0.019614
[12:11:18.033] iteration 25840 : model1 loss : 0.437882 model2 loss : 0.018483
[12:11:18.200] iteration 25841 : model1 loss : 0.440377 model2 loss : 0.020591
[12:11:18.371] iteration 25842 : model1 loss : 0.443717 model2 loss : 0.019985
[12:11:18.539] iteration 25843 : model1 loss : 0.441302 model2 loss : 0.019587
[12:11:18.707] iteration 25844 : model1 loss : 0.437341 model2 loss : 0.020666
[12:11:18.875] iteration 25845 : model1 loss : 0.435237 model2 loss : 0.020767
[12:11:19.043] iteration 25846 : model1 loss : 0.438475 model2 loss : 0.020467
[12:11:19.214] iteration 25847 : model1 loss : 0.439733 model2 loss : 0.019025
[12:11:19.380] iteration 25848 : model1 loss : 0.434631 model2 loss : 0.020001
[12:11:19.550] iteration 25849 : model1 loss : 0.441048 model2 loss : 0.018946
[12:11:19.717] iteration 25850 : model1 loss : 0.439845 model2 loss : 0.022201
[12:11:19.884] iteration 25851 : model1 loss : 0.440801 model2 loss : 0.021006
[12:11:20.053] iteration 25852 : model1 loss : 0.439713 model2 loss : 0.020171
[12:11:20.221] iteration 25853 : model1 loss : 0.441104 model2 loss : 0.019695
[12:11:20.391] iteration 25854 : model1 loss : 0.443205 model2 loss : 0.019446
[12:11:20.558] iteration 25855 : model1 loss : 0.442216 model2 loss : 0.021794
[12:11:20.727] iteration 25856 : model1 loss : 0.439186 model2 loss : 0.018234
[12:11:20.895] iteration 25857 : model1 loss : 0.441318 model2 loss : 0.019329
[12:11:21.064] iteration 25858 : model1 loss : 0.434576 model2 loss : 0.019566
[12:11:21.233] iteration 25859 : model1 loss : 0.440468 model2 loss : 0.019902
[12:11:21.402] iteration 25860 : model1 loss : 0.441255 model2 loss : 0.018714
[12:11:21.570] iteration 25861 : model1 loss : 0.437747 model2 loss : 0.019592
[12:11:21.740] iteration 25862 : model1 loss : 0.438874 model2 loss : 0.020694
[12:11:21.908] iteration 25863 : model1 loss : 0.441110 model2 loss : 0.019171
[12:11:22.078] iteration 25864 : model1 loss : 0.437610 model2 loss : 0.019114
[12:11:22.261] iteration 25865 : model1 loss : 0.437816 model2 loss : 0.019739
[12:11:22.431] iteration 25866 : model1 loss : 0.440743 model2 loss : 0.019881
[12:11:22.599] iteration 25867 : model1 loss : 0.442314 model2 loss : 0.017987
[12:11:22.767] iteration 25868 : model1 loss : 0.435991 model2 loss : 0.018260
[12:11:22.935] iteration 25869 : model1 loss : 0.443394 model2 loss : 0.023244
[12:11:23.106] iteration 25870 : model1 loss : 0.440602 model2 loss : 0.018475
[12:11:23.274] iteration 25871 : model1 loss : 0.441627 model2 loss : 0.021848
[12:11:23.442] iteration 25872 : model1 loss : 0.443931 model2 loss : 0.020413
[12:11:25.356] iteration 25873 : model1 loss : 0.444359 model2 loss : 0.021414
[12:11:25.524] iteration 25874 : model1 loss : 0.441664 model2 loss : 0.020676
[12:11:25.693] iteration 25875 : model1 loss : 0.443255 model2 loss : 0.021397
[12:11:25.861] iteration 25876 : model1 loss : 0.438646 model2 loss : 0.018714
[12:11:26.032] iteration 25877 : model1 loss : 0.442908 model2 loss : 0.021758
[12:11:26.199] iteration 25878 : model1 loss : 0.442557 model2 loss : 0.022244
[12:11:26.368] iteration 25879 : model1 loss : 0.434471 model2 loss : 0.018660
[12:11:26.535] iteration 25880 : model1 loss : 0.441981 model2 loss : 0.018275
[12:11:26.705] iteration 25881 : model1 loss : 0.436933 model2 loss : 0.019701
[12:11:26.872] iteration 25882 : model1 loss : 0.440916 model2 loss : 0.018652
[12:11:27.040] iteration 25883 : model1 loss : 0.438299 model2 loss : 0.018316
[12:11:27.210] iteration 25884 : model1 loss : 0.440556 model2 loss : 0.017288
[12:11:27.376] iteration 25885 : model1 loss : 0.442395 model2 loss : 0.020734
[12:11:27.554] iteration 25886 : model1 loss : 0.441512 model2 loss : 0.022454
[12:11:27.723] iteration 25887 : model1 loss : 0.440088 model2 loss : 0.019377
[12:11:27.890] iteration 25888 : model1 loss : 0.440029 model2 loss : 0.021097
[12:11:28.061] iteration 25889 : model1 loss : 0.437932 model2 loss : 0.018261
[12:11:28.231] iteration 25890 : model1 loss : 0.437183 model2 loss : 0.019891
[12:11:28.399] iteration 25891 : model1 loss : 0.438517 model2 loss : 0.017482
[12:11:28.568] iteration 25892 : model1 loss : 0.439253 model2 loss : 0.018346
[12:11:28.737] iteration 25893 : model1 loss : 0.439561 model2 loss : 0.018538
[12:11:28.904] iteration 25894 : model1 loss : 0.438846 model2 loss : 0.019790
[12:11:29.075] iteration 25895 : model1 loss : 0.441213 model2 loss : 0.018742
[12:11:29.243] iteration 25896 : model1 loss : 0.441735 model2 loss : 0.019083
[12:11:29.415] iteration 25897 : model1 loss : 0.436389 model2 loss : 0.018684
[12:11:29.580] iteration 25898 : model1 loss : 0.438078 model2 loss : 0.019415
[12:11:29.751] iteration 25899 : model1 loss : 0.441510 model2 loss : 0.021392
[12:11:29.921] iteration 25900 : model1 loss : 0.436828 model2 loss : 0.018515
[12:11:30.092] iteration 25901 : model1 loss : 0.441472 model2 loss : 0.019825
[12:11:30.262] iteration 25902 : model1 loss : 0.445251 model2 loss : 0.020900
[12:11:30.430] iteration 25903 : model1 loss : 0.437003 model2 loss : 0.020675
[12:11:30.597] iteration 25904 : model1 loss : 0.437193 model2 loss : 0.018007
[12:11:30.767] iteration 25905 : model1 loss : 0.437600 model2 loss : 0.017720
[12:11:32.697] iteration 25906 : model1 loss : 0.436241 model2 loss : 0.019861
[12:11:32.869] iteration 25907 : model1 loss : 0.443558 model2 loss : 0.020488
[12:11:33.040] iteration 25908 : model1 loss : 0.436187 model2 loss : 0.020222
[12:11:33.210] iteration 25909 : model1 loss : 0.443203 model2 loss : 0.021919
[12:11:33.377] iteration 25910 : model1 loss : 0.435882 model2 loss : 0.018147
[12:11:33.544] iteration 25911 : model1 loss : 0.440789 model2 loss : 0.018198
[12:11:33.711] iteration 25912 : model1 loss : 0.438748 model2 loss : 0.018512
[12:11:33.877] iteration 25913 : model1 loss : 0.444316 model2 loss : 0.021277
[12:11:34.048] iteration 25914 : model1 loss : 0.441822 model2 loss : 0.018692
[12:11:34.215] iteration 25915 : model1 loss : 0.434300 model2 loss : 0.018311
[12:11:34.385] iteration 25916 : model1 loss : 0.437992 model2 loss : 0.019507
[12:11:34.552] iteration 25917 : model1 loss : 0.439718 model2 loss : 0.018897
[12:11:34.721] iteration 25918 : model1 loss : 0.441733 model2 loss : 0.020714
[12:11:34.887] iteration 25919 : model1 loss : 0.437263 model2 loss : 0.019323
[12:11:35.058] iteration 25920 : model1 loss : 0.440652 model2 loss : 0.018043
[12:11:35.228] iteration 25921 : model1 loss : 0.447275 model2 loss : 0.025210
[12:11:35.396] iteration 25922 : model1 loss : 0.436785 model2 loss : 0.018751
[12:11:35.564] iteration 25923 : model1 loss : 0.438186 model2 loss : 0.020292
[12:11:35.733] iteration 25924 : model1 loss : 0.441212 model2 loss : 0.019068
[12:11:35.902] iteration 25925 : model1 loss : 0.439295 model2 loss : 0.020047
[12:11:36.073] iteration 25926 : model1 loss : 0.439780 model2 loss : 0.020207
[12:11:36.242] iteration 25927 : model1 loss : 0.439899 model2 loss : 0.020621
[12:11:36.410] iteration 25928 : model1 loss : 0.444033 model2 loss : 0.023272
[12:11:36.577] iteration 25929 : model1 loss : 0.440457 model2 loss : 0.019838
[12:11:36.748] iteration 25930 : model1 loss : 0.435129 model2 loss : 0.020938
[12:11:36.915] iteration 25931 : model1 loss : 0.438961 model2 loss : 0.018735
[12:11:37.084] iteration 25932 : model1 loss : 0.439531 model2 loss : 0.018567
[12:11:37.255] iteration 25933 : model1 loss : 0.442984 model2 loss : 0.020822
[12:11:37.424] iteration 25934 : model1 loss : 0.438274 model2 loss : 0.021132
[12:11:37.592] iteration 25935 : model1 loss : 0.442332 model2 loss : 0.019135
[12:11:37.763] iteration 25936 : model1 loss : 0.442301 model2 loss : 0.019651
[12:11:37.930] iteration 25937 : model1 loss : 0.435957 model2 loss : 0.017680
[12:11:38.099] iteration 25938 : model1 loss : 0.443230 model2 loss : 0.021336
[12:11:40.025] iteration 25939 : model1 loss : 0.440453 model2 loss : 0.018757
[12:11:40.193] iteration 25940 : model1 loss : 0.443949 model2 loss : 0.022115
[12:11:40.365] iteration 25941 : model1 loss : 0.443278 model2 loss : 0.021949
[12:11:40.535] iteration 25942 : model1 loss : 0.443231 model2 loss : 0.021195
[12:11:40.705] iteration 25943 : model1 loss : 0.438316 model2 loss : 0.020484
[12:11:40.874] iteration 25944 : model1 loss : 0.443322 model2 loss : 0.020344
[12:11:41.044] iteration 25945 : model1 loss : 0.442231 model2 loss : 0.019368
[12:11:41.213] iteration 25946 : model1 loss : 0.444810 model2 loss : 0.020299
[12:11:41.382] iteration 25947 : model1 loss : 0.435506 model2 loss : 0.018816
[12:11:41.550] iteration 25948 : model1 loss : 0.439296 model2 loss : 0.018890
[12:11:41.721] iteration 25949 : model1 loss : 0.442661 model2 loss : 0.019615
[12:11:41.890] iteration 25950 : model1 loss : 0.434929 model2 loss : 0.017923
[12:11:42.062] iteration 25951 : model1 loss : 0.437778 model2 loss : 0.020415
[12:11:42.232] iteration 25952 : model1 loss : 0.435730 model2 loss : 0.017598
[12:11:42.402] iteration 25953 : model1 loss : 0.439311 model2 loss : 0.017275
[12:11:42.570] iteration 25954 : model1 loss : 0.437027 model2 loss : 0.019131
[12:11:42.740] iteration 25955 : model1 loss : 0.441104 model2 loss : 0.020648
[12:11:42.907] iteration 25956 : model1 loss : 0.439985 model2 loss : 0.021000
[12:11:43.078] iteration 25957 : model1 loss : 0.436846 model2 loss : 0.018400
[12:11:43.248] iteration 25958 : model1 loss : 0.443972 model2 loss : 0.022943
[12:11:43.417] iteration 25959 : model1 loss : 0.439274 model2 loss : 0.018983
[12:11:43.584] iteration 25960 : model1 loss : 0.440894 model2 loss : 0.019934
[12:11:43.753] iteration 25961 : model1 loss : 0.439349 model2 loss : 0.021264
[12:11:43.922] iteration 25962 : model1 loss : 0.442837 model2 loss : 0.020030
[12:11:44.091] iteration 25963 : model1 loss : 0.439568 model2 loss : 0.017560
[12:11:44.259] iteration 25964 : model1 loss : 0.440128 model2 loss : 0.019212
[12:11:44.434] iteration 25965 : model1 loss : 0.436889 model2 loss : 0.017305
[12:11:44.601] iteration 25966 : model1 loss : 0.441687 model2 loss : 0.017148
[12:11:44.771] iteration 25967 : model1 loss : 0.436092 model2 loss : 0.019948
[12:11:44.940] iteration 25968 : model1 loss : 0.439628 model2 loss : 0.018842
[12:11:45.110] iteration 25969 : model1 loss : 0.442631 model2 loss : 0.019720
[12:11:45.277] iteration 25970 : model1 loss : 0.439355 model2 loss : 0.018643
[12:11:45.446] iteration 25971 : model1 loss : 0.435558 model2 loss : 0.021306
[12:11:47.355] iteration 25972 : model1 loss : 0.444208 model2 loss : 0.019251
[12:11:47.531] iteration 25973 : model1 loss : 0.438894 model2 loss : 0.020741
[12:11:47.704] iteration 25974 : model1 loss : 0.441801 model2 loss : 0.022206
[12:11:47.873] iteration 25975 : model1 loss : 0.439698 model2 loss : 0.020357
[12:11:48.044] iteration 25976 : model1 loss : 0.440459 model2 loss : 0.017783
[12:11:48.212] iteration 25977 : model1 loss : 0.436768 model2 loss : 0.019717
[12:11:48.383] iteration 25978 : model1 loss : 0.439714 model2 loss : 0.019314
[12:11:48.550] iteration 25979 : model1 loss : 0.438806 model2 loss : 0.017168
[12:11:48.719] iteration 25980 : model1 loss : 0.435082 model2 loss : 0.019092
[12:11:48.888] iteration 25981 : model1 loss : 0.438459 model2 loss : 0.019549
[12:11:49.059] iteration 25982 : model1 loss : 0.439780 model2 loss : 0.019447
[12:11:49.228] iteration 25983 : model1 loss : 0.443514 model2 loss : 0.019510
[12:11:49.397] iteration 25984 : model1 loss : 0.444864 model2 loss : 0.021936
[12:11:49.565] iteration 25985 : model1 loss : 0.439413 model2 loss : 0.018755
[12:11:49.736] iteration 25986 : model1 loss : 0.437216 model2 loss : 0.021008
[12:11:49.905] iteration 25987 : model1 loss : 0.442806 model2 loss : 0.020128
[12:11:50.075] iteration 25988 : model1 loss : 0.442620 model2 loss : 0.018352
[12:11:50.244] iteration 25989 : model1 loss : 0.441847 model2 loss : 0.020776
[12:11:50.414] iteration 25990 : model1 loss : 0.439435 model2 loss : 0.018019
[12:11:50.583] iteration 25991 : model1 loss : 0.444425 model2 loss : 0.023575
[12:11:50.751] iteration 25992 : model1 loss : 0.438336 model2 loss : 0.020127
[12:11:50.920] iteration 25993 : model1 loss : 0.441563 model2 loss : 0.020379
[12:11:51.091] iteration 25994 : model1 loss : 0.438772 model2 loss : 0.020145
[12:11:51.258] iteration 25995 : model1 loss : 0.436691 model2 loss : 0.019048
[12:11:51.429] iteration 25996 : model1 loss : 0.436265 model2 loss : 0.019368
[12:11:51.596] iteration 25997 : model1 loss : 0.443241 model2 loss : 0.018863
[12:11:51.766] iteration 25998 : model1 loss : 0.440518 model2 loss : 0.016587
[12:11:51.934] iteration 25999 : model1 loss : 0.437336 model2 loss : 0.018819
[12:11:52.104] iteration 26000 : model1 loss : 0.441405 model2 loss : 0.019191
[12:12:00.439] iteration 26000 : model1_mean_dice : 0.900719 model1_mean_hd95 : 3.329449
[12:12:08.682] iteration 26000 : model2_mean_dice : 0.898335 model2_mean_hd95 : 2.157125
[12:12:08.859] iteration 26001 : model1 loss : 0.436316 model2 loss : 0.019808
[12:12:09.034] iteration 26002 : model1 loss : 0.440682 model2 loss : 0.020243
[12:12:09.199] iteration 26003 : model1 loss : 0.438068 model2 loss : 0.019932
[12:12:09.367] iteration 26004 : model1 loss : 0.440837 model2 loss : 0.019771
[12:12:11.314] iteration 26005 : model1 loss : 0.437519 model2 loss : 0.017318
[12:12:11.486] iteration 26006 : model1 loss : 0.440238 model2 loss : 0.018708
[12:12:11.657] iteration 26007 : model1 loss : 0.439512 model2 loss : 0.021228
[12:12:11.822] iteration 26008 : model1 loss : 0.439281 model2 loss : 0.019291
[12:12:11.991] iteration 26009 : model1 loss : 0.438354 model2 loss : 0.018789
[12:12:12.158] iteration 26010 : model1 loss : 0.436147 model2 loss : 0.017366
[12:12:12.331] iteration 26011 : model1 loss : 0.438210 model2 loss : 0.018428
[12:12:12.500] iteration 26012 : model1 loss : 0.439378 model2 loss : 0.020393
[12:12:12.668] iteration 26013 : model1 loss : 0.443456 model2 loss : 0.021116
[12:12:12.835] iteration 26014 : model1 loss : 0.436941 model2 loss : 0.019950
[12:12:13.004] iteration 26015 : model1 loss : 0.439812 model2 loss : 0.017958
[12:12:13.174] iteration 26016 : model1 loss : 0.434236 model2 loss : 0.018339
[12:12:13.348] iteration 26017 : model1 loss : 0.443376 model2 loss : 0.020930
[12:12:13.515] iteration 26018 : model1 loss : 0.442936 model2 loss : 0.020852
[12:12:13.685] iteration 26019 : model1 loss : 0.441370 model2 loss : 0.017433
[12:12:13.853] iteration 26020 : model1 loss : 0.440321 model2 loss : 0.018571
[12:12:14.021] iteration 26021 : model1 loss : 0.437333 model2 loss : 0.018539
[12:12:14.189] iteration 26022 : model1 loss : 0.435471 model2 loss : 0.019981
[12:12:14.362] iteration 26023 : model1 loss : 0.443266 model2 loss : 0.022113
[12:12:14.530] iteration 26024 : model1 loss : 0.437507 model2 loss : 0.017029
[12:12:14.701] iteration 26025 : model1 loss : 0.441735 model2 loss : 0.018303
[12:12:14.869] iteration 26026 : model1 loss : 0.434835 model2 loss : 0.018985
[12:12:15.038] iteration 26027 : model1 loss : 0.438812 model2 loss : 0.018522
[12:12:15.206] iteration 26028 : model1 loss : 0.440775 model2 loss : 0.019732
[12:12:15.377] iteration 26029 : model1 loss : 0.443414 model2 loss : 0.023281
[12:12:15.545] iteration 26030 : model1 loss : 0.439069 model2 loss : 0.019050
[12:12:15.714] iteration 26031 : model1 loss : 0.443811 model2 loss : 0.022797
[12:12:15.883] iteration 26032 : model1 loss : 0.440160 model2 loss : 0.019713
[12:12:16.053] iteration 26033 : model1 loss : 0.443960 model2 loss : 0.020398
[12:12:16.223] iteration 26034 : model1 loss : 0.443568 model2 loss : 0.022679
[12:12:16.391] iteration 26035 : model1 loss : 0.440216 model2 loss : 0.019987
[12:12:16.558] iteration 26036 : model1 loss : 0.438053 model2 loss : 0.019292
[12:12:16.727] iteration 26037 : model1 loss : 0.443679 model2 loss : 0.017979
[12:12:18.638] iteration 26038 : model1 loss : 0.444151 model2 loss : 0.018882
[12:12:18.804] iteration 26039 : model1 loss : 0.439625 model2 loss : 0.016896
[12:12:18.978] iteration 26040 : model1 loss : 0.442726 model2 loss : 0.021843
[12:12:19.146] iteration 26041 : model1 loss : 0.447079 model2 loss : 0.021889
[12:12:19.317] iteration 26042 : model1 loss : 0.439559 model2 loss : 0.020779
[12:12:19.484] iteration 26043 : model1 loss : 0.440421 model2 loss : 0.018010
[12:12:19.655] iteration 26044 : model1 loss : 0.435238 model2 loss : 0.019212
[12:12:19.844] iteration 26045 : model1 loss : 0.442625 model2 loss : 0.020631
[12:12:20.014] iteration 26046 : model1 loss : 0.435914 model2 loss : 0.018338
[12:12:20.181] iteration 26047 : model1 loss : 0.441737 model2 loss : 0.019491
[12:12:20.351] iteration 26048 : model1 loss : 0.435540 model2 loss : 0.018977
[12:12:20.520] iteration 26049 : model1 loss : 0.438840 model2 loss : 0.018269
[12:12:20.688] iteration 26050 : model1 loss : 0.440653 model2 loss : 0.018883
[12:12:20.854] iteration 26051 : model1 loss : 0.438273 model2 loss : 0.018477
[12:12:21.023] iteration 26052 : model1 loss : 0.436628 model2 loss : 0.018150
[12:12:21.191] iteration 26053 : model1 loss : 0.436386 model2 loss : 0.019184
[12:12:21.363] iteration 26054 : model1 loss : 0.439699 model2 loss : 0.019058
[12:12:21.531] iteration 26055 : model1 loss : 0.441503 model2 loss : 0.019178
[12:12:21.702] iteration 26056 : model1 loss : 0.443362 model2 loss : 0.018761
[12:12:21.868] iteration 26057 : model1 loss : 0.444921 model2 loss : 0.023369
[12:12:22.036] iteration 26058 : model1 loss : 0.438126 model2 loss : 0.020473
[12:12:22.206] iteration 26059 : model1 loss : 0.439598 model2 loss : 0.019287
[12:12:22.376] iteration 26060 : model1 loss : 0.443280 model2 loss : 0.020031
[12:12:22.544] iteration 26061 : model1 loss : 0.433763 model2 loss : 0.017684
[12:12:22.713] iteration 26062 : model1 loss : 0.443642 model2 loss : 0.019411
[12:12:22.881] iteration 26063 : model1 loss : 0.437515 model2 loss : 0.017927
[12:12:23.049] iteration 26064 : model1 loss : 0.435080 model2 loss : 0.019236
[12:12:23.217] iteration 26065 : model1 loss : 0.442123 model2 loss : 0.020713
[12:12:23.389] iteration 26066 : model1 loss : 0.439385 model2 loss : 0.020761
[12:12:23.559] iteration 26067 : model1 loss : 0.439935 model2 loss : 0.019793
[12:12:23.727] iteration 26068 : model1 loss : 0.437116 model2 loss : 0.019283
[12:12:23.896] iteration 26069 : model1 loss : 0.436013 model2 loss : 0.017327
[12:12:24.063] iteration 26070 : model1 loss : 0.443042 model2 loss : 0.020875
[12:12:25.978] iteration 26071 : model1 loss : 0.441787 model2 loss : 0.020378
[12:12:26.149] iteration 26072 : model1 loss : 0.444887 model2 loss : 0.022547
[12:12:26.321] iteration 26073 : model1 loss : 0.444897 model2 loss : 0.020119
[12:12:26.488] iteration 26074 : model1 loss : 0.441053 model2 loss : 0.019982
[12:12:26.656] iteration 26075 : model1 loss : 0.443146 model2 loss : 0.019317
[12:12:26.836] iteration 26076 : model1 loss : 0.439047 model2 loss : 0.018622
[12:12:27.006] iteration 26077 : model1 loss : 0.442962 model2 loss : 0.020384
[12:12:27.175] iteration 26078 : model1 loss : 0.439582 model2 loss : 0.021175
[12:12:27.346] iteration 26079 : model1 loss : 0.441396 model2 loss : 0.020475
[12:12:27.514] iteration 26080 : model1 loss : 0.439294 model2 loss : 0.021650
[12:12:27.683] iteration 26081 : model1 loss : 0.438875 model2 loss : 0.020252
[12:12:27.851] iteration 26082 : model1 loss : 0.442845 model2 loss : 0.021821
[12:12:28.019] iteration 26083 : model1 loss : 0.439747 model2 loss : 0.018766
[12:12:28.186] iteration 26084 : model1 loss : 0.445384 model2 loss : 0.017785
[12:12:28.358] iteration 26085 : model1 loss : 0.436665 model2 loss : 0.019073
[12:12:28.530] iteration 26086 : model1 loss : 0.436138 model2 loss : 0.018038
[12:12:28.700] iteration 26087 : model1 loss : 0.439900 model2 loss : 0.019242
[12:12:28.868] iteration 26088 : model1 loss : 0.440438 model2 loss : 0.018214
[12:12:29.042] iteration 26089 : model1 loss : 0.439764 model2 loss : 0.019356
[12:12:29.212] iteration 26090 : model1 loss : 0.442422 model2 loss : 0.020162
[12:12:29.380] iteration 26091 : model1 loss : 0.440422 model2 loss : 0.019967
[12:12:29.549] iteration 26092 : model1 loss : 0.437077 model2 loss : 0.018967
[12:12:29.736] iteration 26093 : model1 loss : 0.436635 model2 loss : 0.017877
[12:12:29.902] iteration 26094 : model1 loss : 0.440307 model2 loss : 0.017349
[12:12:30.073] iteration 26095 : model1 loss : 0.441631 model2 loss : 0.019871
[12:12:30.241] iteration 26096 : model1 loss : 0.437714 model2 loss : 0.019198
[12:12:30.411] iteration 26097 : model1 loss : 0.436652 model2 loss : 0.018192
[12:12:30.577] iteration 26098 : model1 loss : 0.436470 model2 loss : 0.019395
[12:12:30.747] iteration 26099 : model1 loss : 0.438255 model2 loss : 0.018917
[12:12:30.936] iteration 26100 : model1 loss : 0.436690 model2 loss : 0.017904
[12:12:31.107] iteration 26101 : model1 loss : 0.443446 model2 loss : 0.021768
[12:12:31.275] iteration 26102 : model1 loss : 0.435430 model2 loss : 0.019801
[12:12:31.444] iteration 26103 : model1 loss : 0.435743 model2 loss : 0.019873
[12:12:33.345] iteration 26104 : model1 loss : 0.436103 model2 loss : 0.019503
[12:12:33.514] iteration 26105 : model1 loss : 0.441472 model2 loss : 0.019830
[12:12:33.686] iteration 26106 : model1 loss : 0.445099 model2 loss : 0.020081
[12:12:33.851] iteration 26107 : model1 loss : 0.440088 model2 loss : 0.021661
[12:12:34.020] iteration 26108 : model1 loss : 0.432950 model2 loss : 0.018751
[12:12:34.187] iteration 26109 : model1 loss : 0.438163 model2 loss : 0.020046
[12:12:34.357] iteration 26110 : model1 loss : 0.442803 model2 loss : 0.019041
[12:12:34.526] iteration 26111 : model1 loss : 0.444960 model2 loss : 0.022213
[12:12:34.698] iteration 26112 : model1 loss : 0.441458 model2 loss : 0.020360
[12:12:34.863] iteration 26113 : model1 loss : 0.444936 model2 loss : 0.021429
[12:12:35.033] iteration 26114 : model1 loss : 0.441786 model2 loss : 0.019969
[12:12:35.199] iteration 26115 : model1 loss : 0.438033 model2 loss : 0.018091
[12:12:35.372] iteration 26116 : model1 loss : 0.439216 model2 loss : 0.019912
[12:12:35.538] iteration 26117 : model1 loss : 0.445289 model2 loss : 0.020545
[12:12:35.708] iteration 26118 : model1 loss : 0.438807 model2 loss : 0.020257
[12:12:35.878] iteration 26119 : model1 loss : 0.435913 model2 loss : 0.020537
[12:12:36.047] iteration 26120 : model1 loss : 0.443926 model2 loss : 0.019555
[12:12:36.217] iteration 26121 : model1 loss : 0.443971 model2 loss : 0.020281
[12:12:36.390] iteration 26122 : model1 loss : 0.441427 model2 loss : 0.020767
[12:12:36.556] iteration 26123 : model1 loss : 0.441232 model2 loss : 0.020350
[12:12:36.726] iteration 26124 : model1 loss : 0.438556 model2 loss : 0.019593
[12:12:36.892] iteration 26125 : model1 loss : 0.437500 model2 loss : 0.021464
[12:12:37.062] iteration 26126 : model1 loss : 0.435061 model2 loss : 0.017118
[12:12:37.231] iteration 26127 : model1 loss : 0.438680 model2 loss : 0.021381
[12:12:37.404] iteration 26128 : model1 loss : 0.434641 model2 loss : 0.018090
[12:12:37.571] iteration 26129 : model1 loss : 0.442606 model2 loss : 0.019006
[12:12:37.740] iteration 26130 : model1 loss : 0.438311 model2 loss : 0.017473
[12:12:37.905] iteration 26131 : model1 loss : 0.439568 model2 loss : 0.019216
[12:12:38.075] iteration 26132 : model1 loss : 0.439733 model2 loss : 0.019725
[12:12:38.242] iteration 26133 : model1 loss : 0.437816 model2 loss : 0.017716
[12:12:38.410] iteration 26134 : model1 loss : 0.442024 model2 loss : 0.020799
[12:12:38.576] iteration 26135 : model1 loss : 0.439586 model2 loss : 0.022767
[12:12:38.742] iteration 26136 : model1 loss : 0.439516 model2 loss : 0.018929
[12:12:40.658] iteration 26137 : model1 loss : 0.440397 model2 loss : 0.020202
[12:12:40.833] iteration 26138 : model1 loss : 0.438310 model2 loss : 0.019338
[12:12:41.005] iteration 26139 : model1 loss : 0.442732 model2 loss : 0.021449
[12:12:41.173] iteration 26140 : model1 loss : 0.439081 model2 loss : 0.020326
[12:12:41.345] iteration 26141 : model1 loss : 0.436841 model2 loss : 0.017690
[12:12:41.513] iteration 26142 : model1 loss : 0.438887 model2 loss : 0.017771
[12:12:41.680] iteration 26143 : model1 loss : 0.436426 model2 loss : 0.020690
[12:12:41.850] iteration 26144 : model1 loss : 0.439202 model2 loss : 0.019281
[12:12:42.020] iteration 26145 : model1 loss : 0.437785 model2 loss : 0.021337
[12:12:42.189] iteration 26146 : model1 loss : 0.438655 model2 loss : 0.020533
[12:12:42.360] iteration 26147 : model1 loss : 0.439701 model2 loss : 0.019472
[12:12:42.534] iteration 26148 : model1 loss : 0.445063 model2 loss : 0.017878
[12:12:42.704] iteration 26149 : model1 loss : 0.439276 model2 loss : 0.018684
[12:12:42.874] iteration 26150 : model1 loss : 0.439738 model2 loss : 0.020550
[12:12:43.044] iteration 26151 : model1 loss : 0.442930 model2 loss : 0.020238
[12:12:43.212] iteration 26152 : model1 loss : 0.441896 model2 loss : 0.018846
[12:12:43.385] iteration 26153 : model1 loss : 0.439327 model2 loss : 0.018412
[12:12:43.550] iteration 26154 : model1 loss : 0.442958 model2 loss : 0.018874
[12:12:43.720] iteration 26155 : model1 loss : 0.437897 model2 loss : 0.019990
[12:12:43.887] iteration 26156 : model1 loss : 0.443845 model2 loss : 0.022111
[12:12:44.055] iteration 26157 : model1 loss : 0.440257 model2 loss : 0.020680
[12:12:44.223] iteration 26158 : model1 loss : 0.442247 model2 loss : 0.020045
[12:12:44.392] iteration 26159 : model1 loss : 0.440964 model2 loss : 0.017135
[12:12:44.560] iteration 26160 : model1 loss : 0.438185 model2 loss : 0.016974
[12:12:44.729] iteration 26161 : model1 loss : 0.441811 model2 loss : 0.021253
[12:12:44.895] iteration 26162 : model1 loss : 0.442077 model2 loss : 0.021486
[12:12:45.065] iteration 26163 : model1 loss : 0.437368 model2 loss : 0.019111
[12:12:45.233] iteration 26164 : model1 loss : 0.438497 model2 loss : 0.021234
[12:12:45.401] iteration 26165 : model1 loss : 0.436298 model2 loss : 0.019815
[12:12:45.569] iteration 26166 : model1 loss : 0.437732 model2 loss : 0.019648
[12:12:45.736] iteration 26167 : model1 loss : 0.440018 model2 loss : 0.020677
[12:12:45.904] iteration 26168 : model1 loss : 0.438702 model2 loss : 0.018723
[12:12:46.071] iteration 26169 : model1 loss : 0.446245 model2 loss : 0.022044
[12:12:47.982] iteration 26170 : model1 loss : 0.445630 model2 loss : 0.021204
[12:12:48.148] iteration 26171 : model1 loss : 0.439515 model2 loss : 0.018402
[12:12:48.318] iteration 26172 : model1 loss : 0.437179 model2 loss : 0.020314
[12:12:48.486] iteration 26173 : model1 loss : 0.441323 model2 loss : 0.018583
[12:12:48.656] iteration 26174 : model1 loss : 0.439075 model2 loss : 0.017578
[12:12:48.822] iteration 26175 : model1 loss : 0.437975 model2 loss : 0.016668
[12:12:48.993] iteration 26176 : model1 loss : 0.439008 model2 loss : 0.017546
[12:12:49.163] iteration 26177 : model1 loss : 0.441512 model2 loss : 0.022072
[12:12:49.333] iteration 26178 : model1 loss : 0.437087 model2 loss : 0.017273
[12:12:49.501] iteration 26179 : model1 loss : 0.440907 model2 loss : 0.020745
[12:12:49.669] iteration 26180 : model1 loss : 0.443007 model2 loss : 0.019768
[12:12:49.838] iteration 26181 : model1 loss : 0.438596 model2 loss : 0.018887
[12:12:50.008] iteration 26182 : model1 loss : 0.440914 model2 loss : 0.019309
[12:12:50.174] iteration 26183 : model1 loss : 0.441752 model2 loss : 0.021147
[12:12:50.344] iteration 26184 : model1 loss : 0.443184 model2 loss : 0.020459
[12:12:50.516] iteration 26185 : model1 loss : 0.442226 model2 loss : 0.019974
[12:12:50.686] iteration 26186 : model1 loss : 0.436307 model2 loss : 0.016954
[12:12:50.853] iteration 26187 : model1 loss : 0.437476 model2 loss : 0.020207
[12:12:51.023] iteration 26188 : model1 loss : 0.440328 model2 loss : 0.020281
[12:12:51.190] iteration 26189 : model1 loss : 0.439778 model2 loss : 0.019960
[12:12:51.360] iteration 26190 : model1 loss : 0.438728 model2 loss : 0.017908
[12:12:51.532] iteration 26191 : model1 loss : 0.436535 model2 loss : 0.018135
[12:12:51.701] iteration 26192 : model1 loss : 0.439797 model2 loss : 0.020014
[12:12:51.868] iteration 26193 : model1 loss : 0.435491 model2 loss : 0.017957
[12:12:52.038] iteration 26194 : model1 loss : 0.438053 model2 loss : 0.019105
[12:12:52.202] iteration 26195 : model1 loss : 0.438948 model2 loss : 0.018699
[12:12:52.373] iteration 26196 : model1 loss : 0.438415 model2 loss : 0.019443
[12:12:52.538] iteration 26197 : model1 loss : 0.442281 model2 loss : 0.018791
[12:12:52.708] iteration 26198 : model1 loss : 0.440004 model2 loss : 0.019783
[12:12:52.874] iteration 26199 : model1 loss : 0.442331 model2 loss : 0.020399
[12:12:53.042] iteration 26200 : model1 loss : 0.440978 model2 loss : 0.021194
[12:12:53.209] iteration 26201 : model1 loss : 0.439927 model2 loss : 0.020629
[12:12:53.378] iteration 26202 : model1 loss : 0.442850 model2 loss : 0.018738
[12:12:55.307] iteration 26203 : model1 loss : 0.441541 model2 loss : 0.018476
[12:12:55.473] iteration 26204 : model1 loss : 0.436452 model2 loss : 0.020059
[12:12:55.642] iteration 26205 : model1 loss : 0.441343 model2 loss : 0.021150
[12:12:55.809] iteration 26206 : model1 loss : 0.443385 model2 loss : 0.021074
[12:12:55.977] iteration 26207 : model1 loss : 0.436712 model2 loss : 0.018689
[12:12:56.147] iteration 26208 : model1 loss : 0.444118 model2 loss : 0.021514
[12:12:56.315] iteration 26209 : model1 loss : 0.439623 model2 loss : 0.020096
[12:12:56.482] iteration 26210 : model1 loss : 0.441444 model2 loss : 0.020929
[12:12:56.650] iteration 26211 : model1 loss : 0.440043 model2 loss : 0.017839
[12:12:56.817] iteration 26212 : model1 loss : 0.440141 model2 loss : 0.018574
[12:12:56.988] iteration 26213 : model1 loss : 0.440908 model2 loss : 0.020688
[12:12:57.155] iteration 26214 : model1 loss : 0.437338 model2 loss : 0.019255
[12:12:57.325] iteration 26215 : model1 loss : 0.437823 model2 loss : 0.018183
[12:12:57.494] iteration 26216 : model1 loss : 0.438217 model2 loss : 0.019618
[12:12:57.664] iteration 26217 : model1 loss : 0.444631 model2 loss : 0.020684
[12:12:57.830] iteration 26218 : model1 loss : 0.437858 model2 loss : 0.016804
[12:12:57.999] iteration 26219 : model1 loss : 0.441358 model2 loss : 0.019745
[12:12:58.168] iteration 26220 : model1 loss : 0.441525 model2 loss : 0.021418
[12:12:58.338] iteration 26221 : model1 loss : 0.441243 model2 loss : 0.020282
[12:12:58.508] iteration 26222 : model1 loss : 0.442701 model2 loss : 0.019608
[12:12:58.677] iteration 26223 : model1 loss : 0.436679 model2 loss : 0.019175
[12:12:58.844] iteration 26224 : model1 loss : 0.437605 model2 loss : 0.016512
[12:12:59.014] iteration 26225 : model1 loss : 0.438467 model2 loss : 0.017884
[12:12:59.180] iteration 26226 : model1 loss : 0.440929 model2 loss : 0.019555
[12:12:59.352] iteration 26227 : model1 loss : 0.441881 model2 loss : 0.019739
[12:12:59.525] iteration 26228 : model1 loss : 0.435741 model2 loss : 0.017579
[12:12:59.694] iteration 26229 : model1 loss : 0.439099 model2 loss : 0.017732
[12:12:59.863] iteration 26230 : model1 loss : 0.436702 model2 loss : 0.020098
[12:13:00.032] iteration 26231 : model1 loss : 0.436279 model2 loss : 0.019033
[12:13:00.202] iteration 26232 : model1 loss : 0.442687 model2 loss : 0.017918
[12:13:00.372] iteration 26233 : model1 loss : 0.440841 model2 loss : 0.022489
[12:13:00.538] iteration 26234 : model1 loss : 0.443006 model2 loss : 0.019099
[12:13:00.708] iteration 26235 : model1 loss : 0.436886 model2 loss : 0.021180
[12:13:02.696] iteration 26236 : model1 loss : 0.440377 model2 loss : 0.021124
[12:13:02.862] iteration 26237 : model1 loss : 0.440632 model2 loss : 0.020152
[12:13:03.031] iteration 26238 : model1 loss : 0.438839 model2 loss : 0.020975
[12:13:03.196] iteration 26239 : model1 loss : 0.440212 model2 loss : 0.019642
[12:13:03.364] iteration 26240 : model1 loss : 0.437437 model2 loss : 0.017436
[12:13:03.533] iteration 26241 : model1 loss : 0.440609 model2 loss : 0.019519
[12:13:03.701] iteration 26242 : model1 loss : 0.439396 model2 loss : 0.018636
[12:13:03.868] iteration 26243 : model1 loss : 0.440344 model2 loss : 0.021202
[12:13:04.037] iteration 26244 : model1 loss : 0.442562 model2 loss : 0.018133
[12:13:04.205] iteration 26245 : model1 loss : 0.437547 model2 loss : 0.019851
[12:13:04.375] iteration 26246 : model1 loss : 0.440185 model2 loss : 0.017237
[12:13:04.543] iteration 26247 : model1 loss : 0.437119 model2 loss : 0.018567
[12:13:04.712] iteration 26248 : model1 loss : 0.438914 model2 loss : 0.020099
[12:13:04.879] iteration 26249 : model1 loss : 0.442106 model2 loss : 0.017808
[12:13:05.050] iteration 26250 : model1 loss : 0.435410 model2 loss : 0.018280
[12:13:05.217] iteration 26251 : model1 loss : 0.438800 model2 loss : 0.019215
[12:13:05.387] iteration 26252 : model1 loss : 0.437011 model2 loss : 0.020159
[12:13:05.555] iteration 26253 : model1 loss : 0.436577 model2 loss : 0.017257
[12:13:05.725] iteration 26254 : model1 loss : 0.437478 model2 loss : 0.019166
[12:13:05.895] iteration 26255 : model1 loss : 0.443832 model2 loss : 0.019762
[12:13:06.064] iteration 26256 : model1 loss : 0.439057 model2 loss : 0.019187
[12:13:06.232] iteration 26257 : model1 loss : 0.440161 model2 loss : 0.020375
[12:13:06.402] iteration 26258 : model1 loss : 0.442641 model2 loss : 0.019341
[12:13:06.569] iteration 26259 : model1 loss : 0.440137 model2 loss : 0.019341
[12:13:06.737] iteration 26260 : model1 loss : 0.444076 model2 loss : 0.018742
[12:13:06.905] iteration 26261 : model1 loss : 0.438752 model2 loss : 0.021365
[12:13:07.073] iteration 26262 : model1 loss : 0.444776 model2 loss : 0.020243
[12:13:07.241] iteration 26263 : model1 loss : 0.441177 model2 loss : 0.020376
[12:13:07.427] iteration 26264 : model1 loss : 0.442533 model2 loss : 0.019736
[12:13:07.594] iteration 26265 : model1 loss : 0.435275 model2 loss : 0.020663
[12:13:07.764] iteration 26266 : model1 loss : 0.436932 model2 loss : 0.017903
[12:13:07.930] iteration 26267 : model1 loss : 0.436536 model2 loss : 0.018739
[12:13:08.098] iteration 26268 : model1 loss : 0.447578 model2 loss : 0.021299
[12:13:10.045] iteration 26269 : model1 loss : 0.435097 model2 loss : 0.018885
[12:13:10.216] iteration 26270 : model1 loss : 0.436977 model2 loss : 0.016712
[12:13:10.387] iteration 26271 : model1 loss : 0.438617 model2 loss : 0.018401
[12:13:10.554] iteration 26272 : model1 loss : 0.435431 model2 loss : 0.018236
[12:13:10.723] iteration 26273 : model1 loss : 0.438620 model2 loss : 0.016818
[12:13:10.892] iteration 26274 : model1 loss : 0.437967 model2 loss : 0.017520
[12:13:11.062] iteration 26275 : model1 loss : 0.439875 model2 loss : 0.019062
[12:13:11.229] iteration 26276 : model1 loss : 0.438818 model2 loss : 0.019753
[12:13:11.400] iteration 26277 : model1 loss : 0.435722 model2 loss : 0.017869
[12:13:11.567] iteration 26278 : model1 loss : 0.442114 model2 loss : 0.018234
[12:13:11.736] iteration 26279 : model1 loss : 0.440820 model2 loss : 0.021598
[12:13:11.904] iteration 26280 : model1 loss : 0.442088 model2 loss : 0.017853
[12:13:12.074] iteration 26281 : model1 loss : 0.437669 model2 loss : 0.018069
[12:13:12.241] iteration 26282 : model1 loss : 0.439995 model2 loss : 0.020057
[12:13:12.410] iteration 26283 : model1 loss : 0.439432 model2 loss : 0.020148
[12:13:12.577] iteration 26284 : model1 loss : 0.443348 model2 loss : 0.021715
[12:13:12.746] iteration 26285 : model1 loss : 0.437435 model2 loss : 0.018668
[12:13:12.912] iteration 26286 : model1 loss : 0.443514 model2 loss : 0.019877
[12:13:13.082] iteration 26287 : model1 loss : 0.444924 model2 loss : 0.021216
[12:13:13.251] iteration 26288 : model1 loss : 0.436284 model2 loss : 0.018112
[12:13:13.422] iteration 26289 : model1 loss : 0.443786 model2 loss : 0.019636
[12:13:13.589] iteration 26290 : model1 loss : 0.439467 model2 loss : 0.020117
[12:13:13.758] iteration 26291 : model1 loss : 0.438746 model2 loss : 0.020608
[12:13:13.924] iteration 26292 : model1 loss : 0.445017 model2 loss : 0.018781
[12:13:14.090] iteration 26293 : model1 loss : 0.439682 model2 loss : 0.019969
[12:13:14.256] iteration 26294 : model1 loss : 0.444668 model2 loss : 0.019205
[12:13:14.426] iteration 26295 : model1 loss : 0.442419 model2 loss : 0.021235
[12:13:14.594] iteration 26296 : model1 loss : 0.442410 model2 loss : 0.021000
[12:13:14.763] iteration 26297 : model1 loss : 0.440624 model2 loss : 0.018579
[12:13:14.929] iteration 26298 : model1 loss : 0.438523 model2 loss : 0.019164
[12:13:15.101] iteration 26299 : model1 loss : 0.440272 model2 loss : 0.019013
[12:13:15.268] iteration 26300 : model1 loss : 0.438365 model2 loss : 0.017934
[12:13:15.436] iteration 26301 : model1 loss : 0.437320 model2 loss : 0.020415
[12:13:17.370] iteration 26302 : model1 loss : 0.440712 model2 loss : 0.017342
[12:13:17.540] iteration 26303 : model1 loss : 0.438616 model2 loss : 0.017451
[12:13:17.711] iteration 26304 : model1 loss : 0.438190 model2 loss : 0.017595
[12:13:17.878] iteration 26305 : model1 loss : 0.438805 model2 loss : 0.020698
[12:13:18.047] iteration 26306 : model1 loss : 0.438309 model2 loss : 0.018368
[12:13:18.232] iteration 26307 : model1 loss : 0.442231 model2 loss : 0.020958
[12:13:18.403] iteration 26308 : model1 loss : 0.438181 model2 loss : 0.018678
[12:13:18.571] iteration 26309 : model1 loss : 0.441074 model2 loss : 0.019185
[12:13:18.739] iteration 26310 : model1 loss : 0.437537 model2 loss : 0.017672
[12:13:18.906] iteration 26311 : model1 loss : 0.443721 model2 loss : 0.019446
[12:13:19.077] iteration 26312 : model1 loss : 0.437350 model2 loss : 0.020979
[12:13:19.244] iteration 26313 : model1 loss : 0.436804 model2 loss : 0.019906
[12:13:19.415] iteration 26314 : model1 loss : 0.445855 model2 loss : 0.022624
[12:13:19.582] iteration 26315 : model1 loss : 0.441212 model2 loss : 0.018891
[12:13:19.750] iteration 26316 : model1 loss : 0.439753 model2 loss : 0.018459
[12:13:19.916] iteration 26317 : model1 loss : 0.442185 model2 loss : 0.019891
[12:13:20.086] iteration 26318 : model1 loss : 0.440459 model2 loss : 0.022072
[12:13:20.252] iteration 26319 : model1 loss : 0.437217 model2 loss : 0.017783
[12:13:20.420] iteration 26320 : model1 loss : 0.439292 model2 loss : 0.021497
[12:13:20.589] iteration 26321 : model1 loss : 0.442911 model2 loss : 0.018994
[12:13:20.757] iteration 26322 : model1 loss : 0.437184 model2 loss : 0.017013
[12:13:20.929] iteration 26323 : model1 loss : 0.439270 model2 loss : 0.018164
[12:13:21.097] iteration 26324 : model1 loss : 0.440411 model2 loss : 0.019640
[12:13:21.263] iteration 26325 : model1 loss : 0.438513 model2 loss : 0.018080
[12:13:21.452] iteration 26326 : model1 loss : 0.441872 model2 loss : 0.020781
[12:13:21.618] iteration 26327 : model1 loss : 0.442615 model2 loss : 0.019925
[12:13:21.786] iteration 26328 : model1 loss : 0.439971 model2 loss : 0.018236
[12:13:21.951] iteration 26329 : model1 loss : 0.438374 model2 loss : 0.019116
[12:13:22.122] iteration 26330 : model1 loss : 0.441678 model2 loss : 0.021672
[12:13:22.290] iteration 26331 : model1 loss : 0.437995 model2 loss : 0.019202
[12:13:22.461] iteration 26332 : model1 loss : 0.439108 model2 loss : 0.017912
[12:13:22.628] iteration 26333 : model1 loss : 0.434658 model2 loss : 0.017285
[12:13:22.796] iteration 26334 : model1 loss : 0.444038 model2 loss : 0.020633
[12:13:24.701] iteration 26335 : model1 loss : 0.438136 model2 loss : 0.018941
[12:13:24.871] iteration 26336 : model1 loss : 0.444819 model2 loss : 0.021275
[12:13:25.043] iteration 26337 : model1 loss : 0.444218 model2 loss : 0.018959
[12:13:25.211] iteration 26338 : model1 loss : 0.436455 model2 loss : 0.017778
[12:13:25.381] iteration 26339 : model1 loss : 0.441833 model2 loss : 0.018739
[12:13:25.549] iteration 26340 : model1 loss : 0.437643 model2 loss : 0.020141
[12:13:25.718] iteration 26341 : model1 loss : 0.440530 model2 loss : 0.018605
[12:13:25.887] iteration 26342 : model1 loss : 0.442096 model2 loss : 0.020613
[12:13:26.056] iteration 26343 : model1 loss : 0.438212 model2 loss : 0.018792
[12:13:26.222] iteration 26344 : model1 loss : 0.438207 model2 loss : 0.020090
[12:13:26.392] iteration 26345 : model1 loss : 0.438954 model2 loss : 0.019439
[12:13:26.563] iteration 26346 : model1 loss : 0.438185 model2 loss : 0.018832
[12:13:26.741] iteration 26347 : model1 loss : 0.439233 model2 loss : 0.019990
[12:13:26.907] iteration 26348 : model1 loss : 0.438536 model2 loss : 0.018773
[12:13:27.076] iteration 26349 : model1 loss : 0.440777 model2 loss : 0.017753
[12:13:27.243] iteration 26350 : model1 loss : 0.438458 model2 loss : 0.019475
[12:13:27.412] iteration 26351 : model1 loss : 0.442580 model2 loss : 0.019538
[12:13:27.578] iteration 26352 : model1 loss : 0.439725 model2 loss : 0.018331
[12:13:27.749] iteration 26353 : model1 loss : 0.441576 model2 loss : 0.016861
[12:13:27.916] iteration 26354 : model1 loss : 0.443893 model2 loss : 0.022542
[12:13:28.086] iteration 26355 : model1 loss : 0.441937 model2 loss : 0.019518
[12:13:28.254] iteration 26356 : model1 loss : 0.435628 model2 loss : 0.018182
[12:13:28.423] iteration 26357 : model1 loss : 0.443964 model2 loss : 0.017880
[12:13:28.591] iteration 26358 : model1 loss : 0.437004 model2 loss : 0.019781
[12:13:28.762] iteration 26359 : model1 loss : 0.438080 model2 loss : 0.019529
[12:13:28.930] iteration 26360 : model1 loss : 0.442285 model2 loss : 0.019567
[12:13:29.099] iteration 26361 : model1 loss : 0.439971 model2 loss : 0.018129
[12:13:29.267] iteration 26362 : model1 loss : 0.443823 model2 loss : 0.018946
[12:13:29.437] iteration 26363 : model1 loss : 0.441885 model2 loss : 0.020032
[12:13:29.605] iteration 26364 : model1 loss : 0.440799 model2 loss : 0.017429
[12:13:29.774] iteration 26365 : model1 loss : 0.438859 model2 loss : 0.018654
[12:13:29.940] iteration 26366 : model1 loss : 0.436587 model2 loss : 0.019326
[12:13:30.115] iteration 26367 : model1 loss : 0.434261 model2 loss : 0.017795
[12:13:32.090] iteration 26368 : model1 loss : 0.440980 model2 loss : 0.020528
[12:13:32.258] iteration 26369 : model1 loss : 0.444327 model2 loss : 0.020465
[12:13:32.428] iteration 26370 : model1 loss : 0.437994 model2 loss : 0.017355
[12:13:32.595] iteration 26371 : model1 loss : 0.433338 model2 loss : 0.019053
[12:13:32.763] iteration 26372 : model1 loss : 0.441785 model2 loss : 0.019027
[12:13:32.931] iteration 26373 : model1 loss : 0.439317 model2 loss : 0.018687
[12:13:33.100] iteration 26374 : model1 loss : 0.441479 model2 loss : 0.017974
[12:13:33.266] iteration 26375 : model1 loss : 0.441945 model2 loss : 0.021332
[12:13:33.439] iteration 26376 : model1 loss : 0.443177 model2 loss : 0.021618
[12:13:33.605] iteration 26377 : model1 loss : 0.443875 model2 loss : 0.019588
[12:13:33.773] iteration 26378 : model1 loss : 0.436880 model2 loss : 0.018420
[12:13:33.938] iteration 26379 : model1 loss : 0.435951 model2 loss : 0.018596
[12:13:34.106] iteration 26380 : model1 loss : 0.441267 model2 loss : 0.020468
[12:13:34.273] iteration 26381 : model1 loss : 0.441578 model2 loss : 0.019249
[12:13:34.442] iteration 26382 : model1 loss : 0.434479 model2 loss : 0.016886
[12:13:34.609] iteration 26383 : model1 loss : 0.440902 model2 loss : 0.018134
[12:13:34.784] iteration 26384 : model1 loss : 0.439868 model2 loss : 0.019144
[12:13:34.952] iteration 26385 : model1 loss : 0.438803 model2 loss : 0.017908
[12:13:35.122] iteration 26386 : model1 loss : 0.435472 model2 loss : 0.020405
[12:13:35.289] iteration 26387 : model1 loss : 0.443504 model2 loss : 0.019692
[12:13:35.459] iteration 26388 : model1 loss : 0.438936 model2 loss : 0.018204
[12:13:35.627] iteration 26389 : model1 loss : 0.442292 model2 loss : 0.018979
[12:13:35.796] iteration 26390 : model1 loss : 0.442600 model2 loss : 0.019444
[12:13:35.965] iteration 26391 : model1 loss : 0.438149 model2 loss : 0.019785
[12:13:36.133] iteration 26392 : model1 loss : 0.441396 model2 loss : 0.018911
[12:13:36.299] iteration 26393 : model1 loss : 0.439162 model2 loss : 0.019566
[12:13:36.471] iteration 26394 : model1 loss : 0.439807 model2 loss : 0.018527
[12:13:36.640] iteration 26395 : model1 loss : 0.443531 model2 loss : 0.020653
[12:13:36.810] iteration 26396 : model1 loss : 0.436274 model2 loss : 0.019409
[12:13:36.975] iteration 26397 : model1 loss : 0.437189 model2 loss : 0.017336
[12:13:37.146] iteration 26398 : model1 loss : 0.443774 model2 loss : 0.020141
[12:13:37.312] iteration 26399 : model1 loss : 0.437994 model2 loss : 0.017119
[12:13:37.479] iteration 26400 : model1 loss : 0.440757 model2 loss : 0.020431
[12:13:39.387] iteration 26401 : model1 loss : 0.435861 model2 loss : 0.018122
[12:13:39.559] iteration 26402 : model1 loss : 0.436533 model2 loss : 0.017713
[12:13:39.731] iteration 26403 : model1 loss : 0.438122 model2 loss : 0.019432
[12:13:39.898] iteration 26404 : model1 loss : 0.441543 model2 loss : 0.021247
[12:13:40.068] iteration 26405 : model1 loss : 0.443765 model2 loss : 0.017684
[12:13:40.237] iteration 26406 : model1 loss : 0.435296 model2 loss : 0.017175
[12:13:40.407] iteration 26407 : model1 loss : 0.441112 model2 loss : 0.020705
[12:13:40.575] iteration 26408 : model1 loss : 0.437319 model2 loss : 0.018734
[12:13:40.746] iteration 26409 : model1 loss : 0.437930 model2 loss : 0.019005
[12:13:40.914] iteration 26410 : model1 loss : 0.443562 model2 loss : 0.019309
[12:13:41.083] iteration 26411 : model1 loss : 0.439287 model2 loss : 0.020529
[12:13:41.252] iteration 26412 : model1 loss : 0.437913 model2 loss : 0.018117
[12:13:41.423] iteration 26413 : model1 loss : 0.440251 model2 loss : 0.018851
[12:13:41.590] iteration 26414 : model1 loss : 0.441032 model2 loss : 0.021811
[12:13:41.759] iteration 26415 : model1 loss : 0.440109 model2 loss : 0.017918
[12:13:41.926] iteration 26416 : model1 loss : 0.439326 model2 loss : 0.018990
[12:13:42.096] iteration 26417 : model1 loss : 0.441504 model2 loss : 0.017589
[12:13:42.264] iteration 26418 : model1 loss : 0.438831 model2 loss : 0.018463
[12:13:42.435] iteration 26419 : model1 loss : 0.438817 model2 loss : 0.020393
[12:13:42.604] iteration 26420 : model1 loss : 0.444537 model2 loss : 0.019837
[12:13:42.773] iteration 26421 : model1 loss : 0.442506 model2 loss : 0.021095
[12:13:42.941] iteration 26422 : model1 loss : 0.436271 model2 loss : 0.019512
[12:13:43.112] iteration 26423 : model1 loss : 0.441025 model2 loss : 0.021218
[12:13:43.280] iteration 26424 : model1 loss : 0.442655 model2 loss : 0.020511
[12:13:43.449] iteration 26425 : model1 loss : 0.444977 model2 loss : 0.022164
[12:13:43.615] iteration 26426 : model1 loss : 0.438979 model2 loss : 0.017886
[12:13:43.784] iteration 26427 : model1 loss : 0.444653 model2 loss : 0.019241
[12:13:43.954] iteration 26428 : model1 loss : 0.436886 model2 loss : 0.018713
[12:13:44.125] iteration 26429 : model1 loss : 0.442512 model2 loss : 0.018896
[12:13:44.292] iteration 26430 : model1 loss : 0.445882 model2 loss : 0.024458
[12:13:44.463] iteration 26431 : model1 loss : 0.439343 model2 loss : 0.018017
[12:13:44.631] iteration 26432 : model1 loss : 0.437633 model2 loss : 0.020156
[12:13:44.798] iteration 26433 : model1 loss : 0.435921 model2 loss : 0.020578
[12:13:46.723] iteration 26434 : model1 loss : 0.441991 model2 loss : 0.020571
[12:13:46.892] iteration 26435 : model1 loss : 0.439081 model2 loss : 0.020819
[12:13:47.063] iteration 26436 : model1 loss : 0.441841 model2 loss : 0.020701
[12:13:47.229] iteration 26437 : model1 loss : 0.440963 model2 loss : 0.018922
[12:13:47.400] iteration 26438 : model1 loss : 0.434665 model2 loss : 0.019127
[12:13:47.567] iteration 26439 : model1 loss : 0.441323 model2 loss : 0.020902
[12:13:47.739] iteration 26440 : model1 loss : 0.442801 model2 loss : 0.020991
[12:13:47.907] iteration 26441 : model1 loss : 0.440127 model2 loss : 0.017717
[12:13:48.079] iteration 26442 : model1 loss : 0.434615 model2 loss : 0.019142
[12:13:48.247] iteration 26443 : model1 loss : 0.436229 model2 loss : 0.018205
[12:13:48.416] iteration 26444 : model1 loss : 0.440551 model2 loss : 0.018523
[12:13:48.585] iteration 26445 : model1 loss : 0.440262 model2 loss : 0.019377
[12:13:48.755] iteration 26446 : model1 loss : 0.439730 model2 loss : 0.020066
[12:13:48.923] iteration 26447 : model1 loss : 0.437919 model2 loss : 0.018828
[12:13:49.092] iteration 26448 : model1 loss : 0.436600 model2 loss : 0.017279
[12:13:49.260] iteration 26449 : model1 loss : 0.438070 model2 loss : 0.018957
[12:13:49.430] iteration 26450 : model1 loss : 0.440585 model2 loss : 0.018404
[12:13:49.598] iteration 26451 : model1 loss : 0.436074 model2 loss : 0.019140
[12:13:49.768] iteration 26452 : model1 loss : 0.440836 model2 loss : 0.016564
[12:13:49.934] iteration 26453 : model1 loss : 0.442666 model2 loss : 0.020964
[12:13:50.103] iteration 26454 : model1 loss : 0.442340 model2 loss : 0.020543
[12:13:50.272] iteration 26455 : model1 loss : 0.444946 model2 loss : 0.021345
[12:13:50.441] iteration 26456 : model1 loss : 0.439170 model2 loss : 0.018457
[12:13:50.609] iteration 26457 : model1 loss : 0.439485 model2 loss : 0.020241
[12:13:50.777] iteration 26458 : model1 loss : 0.442634 model2 loss : 0.019512
[12:13:50.948] iteration 26459 : model1 loss : 0.440587 model2 loss : 0.019041
[12:13:51.118] iteration 26460 : model1 loss : 0.446902 model2 loss : 0.019892
[12:13:51.285] iteration 26461 : model1 loss : 0.445719 model2 loss : 0.023083
[12:13:51.456] iteration 26462 : model1 loss : 0.437933 model2 loss : 0.016812
[12:13:51.623] iteration 26463 : model1 loss : 0.436990 model2 loss : 0.018140
[12:13:51.794] iteration 26464 : model1 loss : 0.439941 model2 loss : 0.019645
[12:13:51.961] iteration 26465 : model1 loss : 0.442588 model2 loss : 0.020014
[12:13:52.132] iteration 26466 : model1 loss : 0.438729 model2 loss : 0.017903
[12:13:54.079] iteration 26467 : model1 loss : 0.439274 model2 loss : 0.018456
[12:13:54.250] iteration 26468 : model1 loss : 0.434301 model2 loss : 0.018141
[12:13:54.420] iteration 26469 : model1 loss : 0.443380 model2 loss : 0.019353
[12:13:54.587] iteration 26470 : model1 loss : 0.440360 model2 loss : 0.016270
[12:13:54.755] iteration 26471 : model1 loss : 0.438492 model2 loss : 0.021465
[12:13:54.921] iteration 26472 : model1 loss : 0.439373 model2 loss : 0.017015
[12:13:55.090] iteration 26473 : model1 loss : 0.438896 model2 loss : 0.017401
[12:13:55.258] iteration 26474 : model1 loss : 0.444523 model2 loss : 0.020647
[12:13:55.428] iteration 26475 : model1 loss : 0.435688 model2 loss : 0.020574
[12:13:55.595] iteration 26476 : model1 loss : 0.437769 model2 loss : 0.019434
[12:13:55.764] iteration 26477 : model1 loss : 0.441617 model2 loss : 0.019483
[12:13:55.933] iteration 26478 : model1 loss : 0.442330 model2 loss : 0.018137
[12:13:56.103] iteration 26479 : model1 loss : 0.437834 model2 loss : 0.019695
[12:13:56.270] iteration 26480 : model1 loss : 0.438173 model2 loss : 0.018857
[12:13:56.440] iteration 26481 : model1 loss : 0.444039 model2 loss : 0.021859
[12:13:56.609] iteration 26482 : model1 loss : 0.440201 model2 loss : 0.020279
[12:13:56.778] iteration 26483 : model1 loss : 0.441141 model2 loss : 0.019189
[12:13:56.947] iteration 26484 : model1 loss : 0.439524 model2 loss : 0.019065
[12:13:57.117] iteration 26485 : model1 loss : 0.443420 model2 loss : 0.021929
[12:13:57.285] iteration 26486 : model1 loss : 0.436921 model2 loss : 0.019053
[12:13:57.454] iteration 26487 : model1 loss : 0.439288 model2 loss : 0.018545
[12:13:57.622] iteration 26488 : model1 loss : 0.441351 model2 loss : 0.021394
[12:13:57.793] iteration 26489 : model1 loss : 0.445344 model2 loss : 0.021672
[12:13:57.959] iteration 26490 : model1 loss : 0.440438 model2 loss : 0.020209
[12:13:58.129] iteration 26491 : model1 loss : 0.441165 model2 loss : 0.018455
[12:13:58.294] iteration 26492 : model1 loss : 0.437455 model2 loss : 0.016693
[12:13:58.465] iteration 26493 : model1 loss : 0.442642 model2 loss : 0.019710
[12:13:58.632] iteration 26494 : model1 loss : 0.435648 model2 loss : 0.018753
[12:13:58.800] iteration 26495 : model1 loss : 0.438076 model2 loss : 0.020583
[12:13:58.968] iteration 26496 : model1 loss : 0.440548 model2 loss : 0.019758
[12:13:59.137] iteration 26497 : model1 loss : 0.440093 model2 loss : 0.019777
[12:13:59.302] iteration 26498 : model1 loss : 0.436619 model2 loss : 0.017643
[12:13:59.471] iteration 26499 : model1 loss : 0.442209 model2 loss : 0.020481
[12:14:01.392] iteration 26500 : model1 loss : 0.445262 model2 loss : 0.021785
[12:14:01.561] iteration 26501 : model1 loss : 0.436970 model2 loss : 0.019381
[12:14:01.732] iteration 26502 : model1 loss : 0.438873 model2 loss : 0.018784
[12:14:01.898] iteration 26503 : model1 loss : 0.443962 model2 loss : 0.019816
[12:14:02.067] iteration 26504 : model1 loss : 0.440097 model2 loss : 0.018228
[12:14:02.234] iteration 26505 : model1 loss : 0.442559 model2 loss : 0.021659
[12:14:02.404] iteration 26506 : model1 loss : 0.439113 model2 loss : 0.017954
[12:14:02.571] iteration 26507 : model1 loss : 0.434180 model2 loss : 0.017486
[12:14:02.740] iteration 26508 : model1 loss : 0.443888 model2 loss : 0.019170
[12:14:02.907] iteration 26509 : model1 loss : 0.437428 model2 loss : 0.017882
[12:14:03.076] iteration 26510 : model1 loss : 0.439113 model2 loss : 0.018404
[12:14:03.245] iteration 26511 : model1 loss : 0.432158 model2 loss : 0.019350
[12:14:03.414] iteration 26512 : model1 loss : 0.440287 model2 loss : 0.020342
[12:14:03.582] iteration 26513 : model1 loss : 0.443480 model2 loss : 0.020595
[12:14:03.752] iteration 26514 : model1 loss : 0.439050 model2 loss : 0.017908
[12:14:03.921] iteration 26515 : model1 loss : 0.438478 model2 loss : 0.019414
[12:14:04.089] iteration 26516 : model1 loss : 0.439763 model2 loss : 0.020361
[12:14:04.256] iteration 26517 : model1 loss : 0.438299 model2 loss : 0.019862
[12:14:04.425] iteration 26518 : model1 loss : 0.441937 model2 loss : 0.019785
[12:14:04.594] iteration 26519 : model1 loss : 0.442982 model2 loss : 0.018777
[12:14:04.764] iteration 26520 : model1 loss : 0.440343 model2 loss : 0.019367
[12:14:04.931] iteration 26521 : model1 loss : 0.439545 model2 loss : 0.018927
[12:14:05.098] iteration 26522 : model1 loss : 0.441189 model2 loss : 0.017960
[12:14:05.265] iteration 26523 : model1 loss : 0.441292 model2 loss : 0.019173
[12:14:05.434] iteration 26524 : model1 loss : 0.439167 model2 loss : 0.019532
[12:14:05.602] iteration 26525 : model1 loss : 0.439644 model2 loss : 0.018388
[12:14:05.772] iteration 26526 : model1 loss : 0.437113 model2 loss : 0.019648
[12:14:05.941] iteration 26527 : model1 loss : 0.437867 model2 loss : 0.018095
[12:14:06.110] iteration 26528 : model1 loss : 0.443218 model2 loss : 0.020248
[12:14:06.276] iteration 26529 : model1 loss : 0.442601 model2 loss : 0.020606
[12:14:06.447] iteration 26530 : model1 loss : 0.438375 model2 loss : 0.019407
[12:14:06.612] iteration 26531 : model1 loss : 0.443876 model2 loss : 0.020615
[12:14:06.781] iteration 26532 : model1 loss : 0.440233 model2 loss : 0.020840
[12:14:08.697] iteration 26533 : model1 loss : 0.440189 model2 loss : 0.019198
[12:14:08.866] iteration 26534 : model1 loss : 0.440217 model2 loss : 0.017835
[12:14:09.035] iteration 26535 : model1 loss : 0.442783 model2 loss : 0.022157
[12:14:09.201] iteration 26536 : model1 loss : 0.435775 model2 loss : 0.018568
[12:14:09.370] iteration 26537 : model1 loss : 0.441735 model2 loss : 0.019617
[12:14:09.547] iteration 26538 : model1 loss : 0.436348 model2 loss : 0.018612
[12:14:09.716] iteration 26539 : model1 loss : 0.437145 model2 loss : 0.017608
[12:14:09.882] iteration 26540 : model1 loss : 0.440172 model2 loss : 0.017072
[12:14:10.050] iteration 26541 : model1 loss : 0.438567 model2 loss : 0.020240
[12:14:10.217] iteration 26542 : model1 loss : 0.437704 model2 loss : 0.017034
[12:14:10.387] iteration 26543 : model1 loss : 0.440550 model2 loss : 0.020297
[12:14:10.556] iteration 26544 : model1 loss : 0.444737 model2 loss : 0.022779
[12:14:10.726] iteration 26545 : model1 loss : 0.437954 model2 loss : 0.018587
[12:14:10.895] iteration 26546 : model1 loss : 0.435897 model2 loss : 0.018272
[12:14:11.062] iteration 26547 : model1 loss : 0.441173 model2 loss : 0.017182
[12:14:11.230] iteration 26548 : model1 loss : 0.440047 model2 loss : 0.019974
[12:14:11.401] iteration 26549 : model1 loss : 0.438412 model2 loss : 0.017154
[12:14:11.569] iteration 26550 : model1 loss : 0.439910 model2 loss : 0.020376
[12:14:11.738] iteration 26551 : model1 loss : 0.439470 model2 loss : 0.018896
[12:14:11.905] iteration 26552 : model1 loss : 0.443574 model2 loss : 0.018279
[12:14:12.076] iteration 26553 : model1 loss : 0.440617 model2 loss : 0.018297
[12:14:12.246] iteration 26554 : model1 loss : 0.442704 model2 loss : 0.019746
[12:14:12.415] iteration 26555 : model1 loss : 0.441605 model2 loss : 0.020844
[12:14:12.583] iteration 26556 : model1 loss : 0.441738 model2 loss : 0.022355
[12:14:12.751] iteration 26557 : model1 loss : 0.440658 model2 loss : 0.018799
[12:14:12.918] iteration 26558 : model1 loss : 0.439889 model2 loss : 0.018613
[12:14:13.088] iteration 26559 : model1 loss : 0.440087 model2 loss : 0.018693
[12:14:13.256] iteration 26560 : model1 loss : 0.442620 model2 loss : 0.019560
[12:14:13.423] iteration 26561 : model1 loss : 0.436200 model2 loss : 0.019055
[12:14:13.590] iteration 26562 : model1 loss : 0.439899 model2 loss : 0.018995
[12:14:13.759] iteration 26563 : model1 loss : 0.438742 model2 loss : 0.019710
[12:14:13.924] iteration 26564 : model1 loss : 0.441536 model2 loss : 0.019521
[12:14:14.092] iteration 26565 : model1 loss : 0.435650 model2 loss : 0.020339
[12:14:16.030] iteration 26566 : model1 loss : 0.433722 model2 loss : 0.019080
[12:14:16.196] iteration 26567 : model1 loss : 0.438157 model2 loss : 0.020112
[12:14:16.364] iteration 26568 : model1 loss : 0.438860 model2 loss : 0.019849
[12:14:16.535] iteration 26569 : model1 loss : 0.439757 model2 loss : 0.019323
[12:14:16.704] iteration 26570 : model1 loss : 0.440424 model2 loss : 0.019969
[12:14:16.871] iteration 26571 : model1 loss : 0.435913 model2 loss : 0.018526
[12:14:17.040] iteration 26572 : model1 loss : 0.436656 model2 loss : 0.018063
[12:14:17.208] iteration 26573 : model1 loss : 0.442338 model2 loss : 0.021309
[12:14:17.378] iteration 26574 : model1 loss : 0.441713 model2 loss : 0.017539
[12:14:17.551] iteration 26575 : model1 loss : 0.439970 model2 loss : 0.019709
[12:14:17.719] iteration 26576 : model1 loss : 0.444248 model2 loss : 0.019631
[12:14:17.888] iteration 26577 : model1 loss : 0.440353 model2 loss : 0.018763
[12:14:18.057] iteration 26578 : model1 loss : 0.440377 model2 loss : 0.019201
[12:14:18.225] iteration 26579 : model1 loss : 0.442487 model2 loss : 0.020382
[12:14:18.396] iteration 26580 : model1 loss : 0.438821 model2 loss : 0.019627
[12:14:18.566] iteration 26581 : model1 loss : 0.436046 model2 loss : 0.019183
[12:14:18.734] iteration 26582 : model1 loss : 0.437894 model2 loss : 0.020155
[12:14:18.904] iteration 26583 : model1 loss : 0.440106 model2 loss : 0.020707
[12:14:19.072] iteration 26584 : model1 loss : 0.440229 model2 loss : 0.018584
[12:14:19.237] iteration 26585 : model1 loss : 0.443438 model2 loss : 0.021126
[12:14:19.407] iteration 26586 : model1 loss : 0.441462 model2 loss : 0.020476
[12:14:19.576] iteration 26587 : model1 loss : 0.440208 model2 loss : 0.019395
[12:14:19.743] iteration 26588 : model1 loss : 0.442121 model2 loss : 0.021434
[12:14:19.910] iteration 26589 : model1 loss : 0.444715 model2 loss : 0.021357
[12:14:20.079] iteration 26590 : model1 loss : 0.438096 model2 loss : 0.017976
[12:14:20.247] iteration 26591 : model1 loss : 0.439816 model2 loss : 0.017554
[12:14:20.416] iteration 26592 : model1 loss : 0.444716 model2 loss : 0.020638
[12:14:20.585] iteration 26593 : model1 loss : 0.438793 model2 loss : 0.020281
[12:14:20.754] iteration 26594 : model1 loss : 0.444803 model2 loss : 0.021193
[12:14:20.923] iteration 26595 : model1 loss : 0.437557 model2 loss : 0.017843
[12:14:21.093] iteration 26596 : model1 loss : 0.444771 model2 loss : 0.022768
[12:14:21.259] iteration 26597 : model1 loss : 0.435959 model2 loss : 0.018036
[12:14:21.425] iteration 26598 : model1 loss : 0.436138 model2 loss : 0.017199
[12:14:23.371] iteration 26599 : model1 loss : 0.439746 model2 loss : 0.018433
[12:14:23.537] iteration 26600 : model1 loss : 0.440855 model2 loss : 0.020116
[12:14:23.708] iteration 26601 : model1 loss : 0.443251 model2 loss : 0.021094
[12:14:23.876] iteration 26602 : model1 loss : 0.439135 model2 loss : 0.019976
[12:14:24.046] iteration 26603 : model1 loss : 0.435306 model2 loss : 0.020384
[12:14:24.213] iteration 26604 : model1 loss : 0.438597 model2 loss : 0.017176
[12:14:24.386] iteration 26605 : model1 loss : 0.438576 model2 loss : 0.020208
[12:14:24.555] iteration 26606 : model1 loss : 0.443597 model2 loss : 0.020309
[12:14:24.724] iteration 26607 : model1 loss : 0.435808 model2 loss : 0.019400
[12:14:24.892] iteration 26608 : model1 loss : 0.443995 model2 loss : 0.021156
[12:14:25.061] iteration 26609 : model1 loss : 0.437720 model2 loss : 0.018869
[12:14:25.227] iteration 26610 : model1 loss : 0.442275 model2 loss : 0.018893
[12:14:25.397] iteration 26611 : model1 loss : 0.437553 model2 loss : 0.019194
[12:14:25.565] iteration 26612 : model1 loss : 0.437628 model2 loss : 0.018729
[12:14:25.734] iteration 26613 : model1 loss : 0.440365 model2 loss : 0.019846
[12:14:25.903] iteration 26614 : model1 loss : 0.441352 model2 loss : 0.020787
[12:14:26.072] iteration 26615 : model1 loss : 0.443591 model2 loss : 0.021368
[12:14:26.240] iteration 26616 : model1 loss : 0.437640 model2 loss : 0.018531
[12:14:26.408] iteration 26617 : model1 loss : 0.439368 model2 loss : 0.019727
[12:14:26.580] iteration 26618 : model1 loss : 0.440315 model2 loss : 0.018659
[12:14:26.750] iteration 26619 : model1 loss : 0.439527 model2 loss : 0.021281
[12:14:26.920] iteration 26620 : model1 loss : 0.445419 model2 loss : 0.020528
[12:14:27.089] iteration 26621 : model1 loss : 0.436807 model2 loss : 0.017975
[12:14:27.255] iteration 26622 : model1 loss : 0.440584 model2 loss : 0.017031
[12:14:27.425] iteration 26623 : model1 loss : 0.438736 model2 loss : 0.019583
[12:14:27.595] iteration 26624 : model1 loss : 0.440359 model2 loss : 0.018914
[12:14:27.765] iteration 26625 : model1 loss : 0.439013 model2 loss : 0.020385
[12:14:27.932] iteration 26626 : model1 loss : 0.438852 model2 loss : 0.018916
[12:14:28.101] iteration 26627 : model1 loss : 0.442395 model2 loss : 0.020460
[12:14:28.270] iteration 26628 : model1 loss : 0.442978 model2 loss : 0.020750
[12:14:28.441] iteration 26629 : model1 loss : 0.442403 model2 loss : 0.020540
[12:14:28.630] iteration 26630 : model1 loss : 0.439385 model2 loss : 0.016907
[12:14:28.798] iteration 26631 : model1 loss : 0.438818 model2 loss : 0.018672
[12:14:30.734] iteration 26632 : model1 loss : 0.441449 model2 loss : 0.018527
[12:14:30.903] iteration 26633 : model1 loss : 0.443094 model2 loss : 0.019783
[12:14:31.074] iteration 26634 : model1 loss : 0.441394 model2 loss : 0.018919
[12:14:31.240] iteration 26635 : model1 loss : 0.435174 model2 loss : 0.018035
[12:14:31.410] iteration 26636 : model1 loss : 0.443120 model2 loss : 0.018531
[12:14:31.580] iteration 26637 : model1 loss : 0.444144 model2 loss : 0.021444
[12:14:31.750] iteration 26638 : model1 loss : 0.440777 model2 loss : 0.019321
[12:14:31.917] iteration 26639 : model1 loss : 0.443793 model2 loss : 0.019332
[12:14:32.086] iteration 26640 : model1 loss : 0.438015 model2 loss : 0.019389
[12:14:32.255] iteration 26641 : model1 loss : 0.440201 model2 loss : 0.019508
[12:14:32.423] iteration 26642 : model1 loss : 0.436156 model2 loss : 0.020313
[12:14:32.594] iteration 26643 : model1 loss : 0.438805 model2 loss : 0.020539
[12:14:32.764] iteration 26644 : model1 loss : 0.443222 model2 loss : 0.019590
[12:14:32.931] iteration 26645 : model1 loss : 0.438826 model2 loss : 0.020847
[12:14:33.100] iteration 26646 : model1 loss : 0.440171 model2 loss : 0.019407
[12:14:33.268] iteration 26647 : model1 loss : 0.444960 model2 loss : 0.023477
[12:14:33.435] iteration 26648 : model1 loss : 0.437647 model2 loss : 0.017864
[12:14:33.606] iteration 26649 : model1 loss : 0.442765 model2 loss : 0.018167
[12:14:33.773] iteration 26650 : model1 loss : 0.440106 model2 loss : 0.021942
[12:14:33.940] iteration 26651 : model1 loss : 0.442332 model2 loss : 0.018454
[12:14:34.109] iteration 26652 : model1 loss : 0.437948 model2 loss : 0.018909
[12:14:34.278] iteration 26653 : model1 loss : 0.437922 model2 loss : 0.018046
[12:14:34.449] iteration 26654 : model1 loss : 0.437381 model2 loss : 0.017621
[12:14:34.616] iteration 26655 : model1 loss : 0.435621 model2 loss : 0.018791
[12:14:34.786] iteration 26656 : model1 loss : 0.441522 model2 loss : 0.019443
[12:14:34.954] iteration 26657 : model1 loss : 0.436942 model2 loss : 0.018214
[12:14:35.122] iteration 26658 : model1 loss : 0.438787 model2 loss : 0.016981
[12:14:35.290] iteration 26659 : model1 loss : 0.441497 model2 loss : 0.019850
[12:14:35.460] iteration 26660 : model1 loss : 0.443390 model2 loss : 0.020490
[12:14:35.626] iteration 26661 : model1 loss : 0.440519 model2 loss : 0.019094
[12:14:35.811] iteration 26662 : model1 loss : 0.439030 model2 loss : 0.022235
[12:14:35.978] iteration 26663 : model1 loss : 0.434860 model2 loss : 0.018889
[12:14:36.145] iteration 26664 : model1 loss : 0.438561 model2 loss : 0.019850
[12:14:38.065] iteration 26665 : model1 loss : 0.443333 model2 loss : 0.021078
[12:14:38.234] iteration 26666 : model1 loss : 0.436510 model2 loss : 0.018426
[12:14:38.405] iteration 26667 : model1 loss : 0.444998 model2 loss : 0.021185
[12:14:38.572] iteration 26668 : model1 loss : 0.438725 model2 loss : 0.019305
[12:14:38.754] iteration 26669 : model1 loss : 0.438854 model2 loss : 0.020838
[12:14:38.920] iteration 26670 : model1 loss : 0.441476 model2 loss : 0.018964
[12:14:39.090] iteration 26671 : model1 loss : 0.440919 model2 loss : 0.018603
[12:14:39.256] iteration 26672 : model1 loss : 0.439739 model2 loss : 0.019925
[12:14:39.426] iteration 26673 : model1 loss : 0.438991 model2 loss : 0.017148
[12:14:39.596] iteration 26674 : model1 loss : 0.437485 model2 loss : 0.017785
[12:14:39.764] iteration 26675 : model1 loss : 0.441437 model2 loss : 0.020098
[12:14:39.929] iteration 26676 : model1 loss : 0.434535 model2 loss : 0.019064
[12:14:40.098] iteration 26677 : model1 loss : 0.443922 model2 loss : 0.021035
[12:14:40.273] iteration 26678 : model1 loss : 0.441338 model2 loss : 0.019573
[12:14:40.441] iteration 26679 : model1 loss : 0.445070 model2 loss : 0.020175
[12:14:40.610] iteration 26680 : model1 loss : 0.439071 model2 loss : 0.020362
[12:14:40.781] iteration 26681 : model1 loss : 0.442797 model2 loss : 0.019550
[12:14:40.951] iteration 26682 : model1 loss : 0.442030 model2 loss : 0.023807
[12:14:41.120] iteration 26683 : model1 loss : 0.438773 model2 loss : 0.019633
[12:14:41.287] iteration 26684 : model1 loss : 0.438898 model2 loss : 0.020016
[12:14:41.458] iteration 26685 : model1 loss : 0.441875 model2 loss : 0.017102
[12:14:41.626] iteration 26686 : model1 loss : 0.443960 model2 loss : 0.018774
[12:14:41.795] iteration 26687 : model1 loss : 0.438709 model2 loss : 0.019328
[12:14:41.963] iteration 26688 : model1 loss : 0.441307 model2 loss : 0.018228
[12:14:42.132] iteration 26689 : model1 loss : 0.437618 model2 loss : 0.018701
[12:14:42.299] iteration 26690 : model1 loss : 0.438786 model2 loss : 0.017815
[12:14:42.470] iteration 26691 : model1 loss : 0.441443 model2 loss : 0.020851
[12:14:42.637] iteration 26692 : model1 loss : 0.437121 model2 loss : 0.017161
[12:14:42.807] iteration 26693 : model1 loss : 0.436563 model2 loss : 0.017780
[12:14:42.985] iteration 26694 : model1 loss : 0.438246 model2 loss : 0.019339
[12:14:43.152] iteration 26695 : model1 loss : 0.439181 model2 loss : 0.018899
[12:14:43.319] iteration 26696 : model1 loss : 0.440634 model2 loss : 0.019797
[12:14:43.489] iteration 26697 : model1 loss : 0.437175 model2 loss : 0.019275
[12:14:45.406] iteration 26698 : model1 loss : 0.441018 model2 loss : 0.019641
[12:14:45.572] iteration 26699 : model1 loss : 0.440685 model2 loss : 0.021264
[12:14:45.742] iteration 26700 : model1 loss : 0.438083 model2 loss : 0.015681
[12:14:45.911] iteration 26701 : model1 loss : 0.439182 model2 loss : 0.017424
[12:14:46.078] iteration 26702 : model1 loss : 0.443825 model2 loss : 0.018974
[12:14:46.245] iteration 26703 : model1 loss : 0.436303 model2 loss : 0.017813
[12:14:46.413] iteration 26704 : model1 loss : 0.438525 model2 loss : 0.021160
[12:14:46.583] iteration 26705 : model1 loss : 0.437198 model2 loss : 0.018470
[12:14:46.752] iteration 26706 : model1 loss : 0.437559 model2 loss : 0.018477
[12:14:46.918] iteration 26707 : model1 loss : 0.441332 model2 loss : 0.018513
[12:14:47.089] iteration 26708 : model1 loss : 0.435728 model2 loss : 0.017834
[12:14:47.257] iteration 26709 : model1 loss : 0.441052 model2 loss : 0.019391
[12:14:47.427] iteration 26710 : model1 loss : 0.443274 model2 loss : 0.021239
[12:14:47.597] iteration 26711 : model1 loss : 0.440177 model2 loss : 0.018115
[12:14:47.766] iteration 26712 : model1 loss : 0.439470 model2 loss : 0.019180
[12:14:47.932] iteration 26713 : model1 loss : 0.436801 model2 loss : 0.017662
[12:14:48.101] iteration 26714 : model1 loss : 0.439842 model2 loss : 0.018687
[12:14:48.269] iteration 26715 : model1 loss : 0.441364 model2 loss : 0.020696
[12:14:48.440] iteration 26716 : model1 loss : 0.439362 model2 loss : 0.018544
[12:14:48.610] iteration 26717 : model1 loss : 0.436770 model2 loss : 0.018925
[12:14:48.779] iteration 26718 : model1 loss : 0.440139 model2 loss : 0.018807
[12:14:48.946] iteration 26719 : model1 loss : 0.439405 model2 loss : 0.018173
[12:14:49.114] iteration 26720 : model1 loss : 0.436858 model2 loss : 0.018530
[12:14:49.282] iteration 26721 : model1 loss : 0.442863 model2 loss : 0.021267
[12:14:49.450] iteration 26722 : model1 loss : 0.444170 model2 loss : 0.019892
[12:14:49.616] iteration 26723 : model1 loss : 0.441270 model2 loss : 0.017288
[12:14:49.784] iteration 26724 : model1 loss : 0.437985 model2 loss : 0.019919
[12:14:49.952] iteration 26725 : model1 loss : 0.439203 model2 loss : 0.018291
[12:14:50.121] iteration 26726 : model1 loss : 0.441310 model2 loss : 0.019468
[12:14:50.288] iteration 26727 : model1 loss : 0.444249 model2 loss : 0.021452
[12:14:50.458] iteration 26728 : model1 loss : 0.439173 model2 loss : 0.016586
[12:14:50.622] iteration 26729 : model1 loss : 0.442989 model2 loss : 0.019770
[12:14:50.790] iteration 26730 : model1 loss : 0.438185 model2 loss : 0.019103
[12:14:52.728] iteration 26731 : model1 loss : 0.440417 model2 loss : 0.021296
[12:14:52.896] iteration 26732 : model1 loss : 0.440873 model2 loss : 0.017476
[12:14:53.068] iteration 26733 : model1 loss : 0.442384 model2 loss : 0.020873
[12:14:53.236] iteration 26734 : model1 loss : 0.438969 model2 loss : 0.020806
[12:14:53.406] iteration 26735 : model1 loss : 0.438622 model2 loss : 0.019036
[12:14:53.575] iteration 26736 : model1 loss : 0.440636 model2 loss : 0.019056
[12:14:53.744] iteration 26737 : model1 loss : 0.444335 model2 loss : 0.020064
[12:14:53.909] iteration 26738 : model1 loss : 0.442083 model2 loss : 0.019354
[12:14:54.079] iteration 26739 : model1 loss : 0.439987 model2 loss : 0.019379
[12:14:54.246] iteration 26740 : model1 loss : 0.437088 model2 loss : 0.020036
[12:14:54.417] iteration 26741 : model1 loss : 0.442186 model2 loss : 0.019204
[12:14:54.587] iteration 26742 : model1 loss : 0.442090 model2 loss : 0.018296
[12:14:54.757] iteration 26743 : model1 loss : 0.437601 model2 loss : 0.017877
[12:14:54.924] iteration 26744 : model1 loss : 0.438969 model2 loss : 0.018105
[12:14:55.093] iteration 26745 : model1 loss : 0.439799 model2 loss : 0.017707
[12:14:55.260] iteration 26746 : model1 loss : 0.438176 model2 loss : 0.017350
[12:14:55.430] iteration 26747 : model1 loss : 0.442007 model2 loss : 0.018385
[12:14:55.602] iteration 26748 : model1 loss : 0.438946 model2 loss : 0.019746
[12:14:55.771] iteration 26749 : model1 loss : 0.443025 model2 loss : 0.018186
[12:14:55.941] iteration 26750 : model1 loss : 0.441608 model2 loss : 0.019642
[12:14:56.111] iteration 26751 : model1 loss : 0.441471 model2 loss : 0.019108
[12:14:56.281] iteration 26752 : model1 loss : 0.438364 model2 loss : 0.020223
[12:14:56.453] iteration 26753 : model1 loss : 0.439532 model2 loss : 0.017769
[12:14:56.621] iteration 26754 : model1 loss : 0.437463 model2 loss : 0.018695
[12:14:56.789] iteration 26755 : model1 loss : 0.440060 model2 loss : 0.020355
[12:14:56.954] iteration 26756 : model1 loss : 0.436888 model2 loss : 0.018756
[12:14:57.125] iteration 26757 : model1 loss : 0.437600 model2 loss : 0.018641
[12:14:57.291] iteration 26758 : model1 loss : 0.437059 model2 loss : 0.019124
[12:14:57.462] iteration 26759 : model1 loss : 0.445271 model2 loss : 0.020453
[12:14:57.629] iteration 26760 : model1 loss : 0.436138 model2 loss : 0.018896
[12:14:57.797] iteration 26761 : model1 loss : 0.441467 model2 loss : 0.019386
[12:14:57.964] iteration 26762 : model1 loss : 0.440379 model2 loss : 0.018325
[12:14:58.134] iteration 26763 : model1 loss : 0.438876 model2 loss : 0.018691
[12:15:00.028] iteration 26764 : model1 loss : 0.434115 model2 loss : 0.018896
[12:15:00.196] iteration 26765 : model1 loss : 0.439594 model2 loss : 0.018643
[12:15:00.367] iteration 26766 : model1 loss : 0.440971 model2 loss : 0.017907
[12:15:00.538] iteration 26767 : model1 loss : 0.440525 model2 loss : 0.020084
[12:15:00.709] iteration 26768 : model1 loss : 0.441785 model2 loss : 0.017623
[12:15:00.881] iteration 26769 : model1 loss : 0.441511 model2 loss : 0.019971
[12:15:01.051] iteration 26770 : model1 loss : 0.440143 model2 loss : 0.019255
[12:15:01.219] iteration 26771 : model1 loss : 0.438519 model2 loss : 0.017001
[12:15:01.388] iteration 26772 : model1 loss : 0.436146 model2 loss : 0.017586
[12:15:01.559] iteration 26773 : model1 loss : 0.440260 model2 loss : 0.019844
[12:15:01.728] iteration 26774 : model1 loss : 0.440713 model2 loss : 0.020752
[12:15:01.894] iteration 26775 : model1 loss : 0.437321 model2 loss : 0.017441
[12:15:02.065] iteration 26776 : model1 loss : 0.440981 model2 loss : 0.019855
[12:15:02.233] iteration 26777 : model1 loss : 0.437469 model2 loss : 0.018136
[12:15:02.404] iteration 26778 : model1 loss : 0.438891 model2 loss : 0.018119
[12:15:02.572] iteration 26779 : model1 loss : 0.443127 model2 loss : 0.020218
[12:15:02.742] iteration 26780 : model1 loss : 0.442634 model2 loss : 0.022542
[12:15:02.909] iteration 26781 : model1 loss : 0.441832 model2 loss : 0.018923
[12:15:03.080] iteration 26782 : model1 loss : 0.438367 model2 loss : 0.018808
[12:15:03.249] iteration 26783 : model1 loss : 0.444193 model2 loss : 0.020427
[12:15:03.419] iteration 26784 : model1 loss : 0.441804 model2 loss : 0.020935
[12:15:03.591] iteration 26785 : model1 loss : 0.439743 model2 loss : 0.017595
[12:15:03.759] iteration 26786 : model1 loss : 0.440091 model2 loss : 0.019198
[12:15:03.934] iteration 26787 : model1 loss : 0.443182 model2 loss : 0.019631
[12:15:04.105] iteration 26788 : model1 loss : 0.437455 model2 loss : 0.019112
[12:15:04.274] iteration 26789 : model1 loss : 0.439106 model2 loss : 0.019134
[12:15:04.445] iteration 26790 : model1 loss : 0.441375 model2 loss : 0.020057
[12:15:04.615] iteration 26791 : model1 loss : 0.439746 model2 loss : 0.018882
[12:15:04.784] iteration 26792 : model1 loss : 0.442960 model2 loss : 0.020207
[12:15:04.952] iteration 26793 : model1 loss : 0.436901 model2 loss : 0.019110
[12:15:05.122] iteration 26794 : model1 loss : 0.445295 model2 loss : 0.020964
[12:15:05.289] iteration 26795 : model1 loss : 0.439887 model2 loss : 0.017168
[12:15:05.460] iteration 26796 : model1 loss : 0.434577 model2 loss : 0.017860
[12:15:07.396] iteration 26797 : model1 loss : 0.440761 model2 loss : 0.019635
[12:15:07.564] iteration 26798 : model1 loss : 0.442903 model2 loss : 0.020797
[12:15:07.734] iteration 26799 : model1 loss : 0.438403 model2 loss : 0.019307
[12:15:07.900] iteration 26800 : model1 loss : 0.438919 model2 loss : 0.019005
[12:15:08.070] iteration 26801 : model1 loss : 0.441717 model2 loss : 0.021924
[12:15:08.238] iteration 26802 : model1 loss : 0.435811 model2 loss : 0.018534
[12:15:08.408] iteration 26803 : model1 loss : 0.442045 model2 loss : 0.020943
[12:15:08.576] iteration 26804 : model1 loss : 0.436470 model2 loss : 0.019209
[12:15:08.745] iteration 26805 : model1 loss : 0.443030 model2 loss : 0.020344
[12:15:08.912] iteration 26806 : model1 loss : 0.439365 model2 loss : 0.016909
[12:15:09.079] iteration 26807 : model1 loss : 0.435768 model2 loss : 0.018593
[12:15:09.248] iteration 26808 : model1 loss : 0.443051 model2 loss : 0.020220
[12:15:09.418] iteration 26809 : model1 loss : 0.439054 model2 loss : 0.021150
[12:15:09.588] iteration 26810 : model1 loss : 0.438757 model2 loss : 0.019933
[12:15:09.756] iteration 26811 : model1 loss : 0.441259 model2 loss : 0.020469
[12:15:09.926] iteration 26812 : model1 loss : 0.440722 model2 loss : 0.019041
[12:15:10.096] iteration 26813 : model1 loss : 0.444194 model2 loss : 0.021419
[12:15:10.265] iteration 26814 : model1 loss : 0.438687 model2 loss : 0.018758
[12:15:10.435] iteration 26815 : model1 loss : 0.438171 model2 loss : 0.018272
[12:15:10.604] iteration 26816 : model1 loss : 0.439990 model2 loss : 0.021341
[12:15:10.775] iteration 26817 : model1 loss : 0.443452 model2 loss : 0.019525
[12:15:10.944] iteration 26818 : model1 loss : 0.438080 model2 loss : 0.019568
[12:15:11.114] iteration 26819 : model1 loss : 0.440706 model2 loss : 0.020082
[12:15:11.282] iteration 26820 : model1 loss : 0.441704 model2 loss : 0.018484
[12:15:11.453] iteration 26821 : model1 loss : 0.439470 model2 loss : 0.017639
[12:15:11.619] iteration 26822 : model1 loss : 0.441941 model2 loss : 0.019125
[12:15:11.789] iteration 26823 : model1 loss : 0.443002 model2 loss : 0.021629
[12:15:11.959] iteration 26824 : model1 loss : 0.439023 model2 loss : 0.016977
[12:15:12.129] iteration 26825 : model1 loss : 0.434442 model2 loss : 0.019865
[12:15:12.298] iteration 26826 : model1 loss : 0.439417 model2 loss : 0.020635
[12:15:12.469] iteration 26827 : model1 loss : 0.444137 model2 loss : 0.019388
[12:15:12.635] iteration 26828 : model1 loss : 0.440710 model2 loss : 0.018244
[12:15:12.803] iteration 26829 : model1 loss : 0.436084 model2 loss : 0.017790
[12:15:14.744] iteration 26830 : model1 loss : 0.446672 model2 loss : 0.019889
[12:15:14.912] iteration 26831 : model1 loss : 0.435159 model2 loss : 0.018996
[12:15:15.084] iteration 26832 : model1 loss : 0.437721 model2 loss : 0.017446
[12:15:15.251] iteration 26833 : model1 loss : 0.440195 model2 loss : 0.018749
[12:15:15.422] iteration 26834 : model1 loss : 0.440062 model2 loss : 0.019144
[12:15:15.592] iteration 26835 : model1 loss : 0.439161 model2 loss : 0.019016
[12:15:15.761] iteration 26836 : model1 loss : 0.441072 model2 loss : 0.021601
[12:15:15.930] iteration 26837 : model1 loss : 0.439371 model2 loss : 0.020704
[12:15:16.099] iteration 26838 : model1 loss : 0.442727 model2 loss : 0.018071
[12:15:16.273] iteration 26839 : model1 loss : 0.444845 model2 loss : 0.022073
[12:15:16.443] iteration 26840 : model1 loss : 0.441316 model2 loss : 0.016731
[12:15:16.614] iteration 26841 : model1 loss : 0.441131 model2 loss : 0.016967
[12:15:16.784] iteration 26842 : model1 loss : 0.440303 model2 loss : 0.018910
[12:15:16.950] iteration 26843 : model1 loss : 0.438940 model2 loss : 0.022132
[12:15:17.121] iteration 26844 : model1 loss : 0.442235 model2 loss : 0.021299
[12:15:17.289] iteration 26845 : model1 loss : 0.438012 model2 loss : 0.018548
[12:15:17.459] iteration 26846 : model1 loss : 0.438014 model2 loss : 0.017063
[12:15:17.626] iteration 26847 : model1 loss : 0.436731 model2 loss : 0.018110
[12:15:17.795] iteration 26848 : model1 loss : 0.443254 model2 loss : 0.021275
[12:15:17.964] iteration 26849 : model1 loss : 0.439141 model2 loss : 0.019998
[12:15:18.134] iteration 26850 : model1 loss : 0.440620 model2 loss : 0.019474
[12:15:18.303] iteration 26851 : model1 loss : 0.435504 model2 loss : 0.018225
[12:15:18.474] iteration 26852 : model1 loss : 0.442048 model2 loss : 0.018890
[12:15:18.643] iteration 26853 : model1 loss : 0.441111 model2 loss : 0.021489
[12:15:18.813] iteration 26854 : model1 loss : 0.437911 model2 loss : 0.019028
[12:15:18.981] iteration 26855 : model1 loss : 0.436554 model2 loss : 0.020898
[12:15:19.150] iteration 26856 : model1 loss : 0.443457 model2 loss : 0.019374
[12:15:19.318] iteration 26857 : model1 loss : 0.434714 model2 loss : 0.018112
[12:15:19.492] iteration 26858 : model1 loss : 0.437569 model2 loss : 0.019285
[12:15:19.661] iteration 26859 : model1 loss : 0.443734 model2 loss : 0.022278
[12:15:19.830] iteration 26860 : model1 loss : 0.442708 model2 loss : 0.019738
[12:15:19.996] iteration 26861 : model1 loss : 0.439089 model2 loss : 0.019573
[12:15:20.163] iteration 26862 : model1 loss : 0.441761 model2 loss : 0.018906
[12:15:22.109] iteration 26863 : model1 loss : 0.444914 model2 loss : 0.018719
[12:15:22.281] iteration 26864 : model1 loss : 0.441155 model2 loss : 0.019724
[12:15:22.452] iteration 26865 : model1 loss : 0.437902 model2 loss : 0.019874
[12:15:22.620] iteration 26866 : model1 loss : 0.439944 model2 loss : 0.017743
[12:15:22.790] iteration 26867 : model1 loss : 0.442169 model2 loss : 0.020014
[12:15:22.956] iteration 26868 : model1 loss : 0.436744 model2 loss : 0.016597
[12:15:23.127] iteration 26869 : model1 loss : 0.443552 model2 loss : 0.019055
[12:15:23.297] iteration 26870 : model1 loss : 0.439910 model2 loss : 0.019985
[12:15:23.468] iteration 26871 : model1 loss : 0.437961 model2 loss : 0.017687
[12:15:23.637] iteration 26872 : model1 loss : 0.441808 model2 loss : 0.018968
[12:15:23.805] iteration 26873 : model1 loss : 0.435807 model2 loss : 0.018179
[12:15:23.972] iteration 26874 : model1 loss : 0.442096 model2 loss : 0.021312
[12:15:24.144] iteration 26875 : model1 loss : 0.442928 model2 loss : 0.019148
[12:15:24.313] iteration 26876 : model1 loss : 0.441390 model2 loss : 0.020545
[12:15:24.484] iteration 26877 : model1 loss : 0.443746 model2 loss : 0.020661
[12:15:24.651] iteration 26878 : model1 loss : 0.444162 model2 loss : 0.022179
[12:15:24.819] iteration 26879 : model1 loss : 0.440266 model2 loss : 0.020927
[12:15:24.986] iteration 26880 : model1 loss : 0.444580 model2 loss : 0.017842
[12:15:25.155] iteration 26881 : model1 loss : 0.439487 model2 loss : 0.019531
[12:15:25.324] iteration 26882 : model1 loss : 0.438655 model2 loss : 0.019313
[12:15:25.498] iteration 26883 : model1 loss : 0.437333 model2 loss : 0.018949
[12:15:25.666] iteration 26884 : model1 loss : 0.437121 model2 loss : 0.018479
[12:15:25.834] iteration 26885 : model1 loss : 0.439823 model2 loss : 0.018973
[12:15:26.003] iteration 26886 : model1 loss : 0.438545 model2 loss : 0.018030
[12:15:26.174] iteration 26887 : model1 loss : 0.438005 model2 loss : 0.020061
[12:15:26.343] iteration 26888 : model1 loss : 0.443314 model2 loss : 0.020775
[12:15:26.541] iteration 26889 : model1 loss : 0.441060 model2 loss : 0.018431
[12:15:26.708] iteration 26890 : model1 loss : 0.436826 model2 loss : 0.018079
[12:15:26.878] iteration 26891 : model1 loss : 0.437812 model2 loss : 0.020008
[12:15:27.046] iteration 26892 : model1 loss : 0.437814 model2 loss : 0.018179
[12:15:27.216] iteration 26893 : model1 loss : 0.438530 model2 loss : 0.020211
[12:15:27.383] iteration 26894 : model1 loss : 0.440481 model2 loss : 0.018493
[12:15:27.551] iteration 26895 : model1 loss : 0.436412 model2 loss : 0.018940
[12:15:29.470] iteration 26896 : model1 loss : 0.446289 model2 loss : 0.020861
[12:15:29.638] iteration 26897 : model1 loss : 0.435500 model2 loss : 0.016561
[12:15:29.809] iteration 26898 : model1 loss : 0.435891 model2 loss : 0.018429
[12:15:29.979] iteration 26899 : model1 loss : 0.434808 model2 loss : 0.020352
[12:15:30.147] iteration 26900 : model1 loss : 0.439894 model2 loss : 0.017469
[12:15:30.316] iteration 26901 : model1 loss : 0.438211 model2 loss : 0.021438
[12:15:30.485] iteration 26902 : model1 loss : 0.442899 model2 loss : 0.019810
[12:15:30.654] iteration 26903 : model1 loss : 0.444802 model2 loss : 0.021490
[12:15:30.823] iteration 26904 : model1 loss : 0.439835 model2 loss : 0.018766
[12:15:30.990] iteration 26905 : model1 loss : 0.441357 model2 loss : 0.018290
[12:15:31.159] iteration 26906 : model1 loss : 0.443352 model2 loss : 0.022668
[12:15:31.324] iteration 26907 : model1 loss : 0.437762 model2 loss : 0.018658
[12:15:31.496] iteration 26908 : model1 loss : 0.441733 model2 loss : 0.017870
[12:15:31.662] iteration 26909 : model1 loss : 0.440734 model2 loss : 0.019682
[12:15:31.831] iteration 26910 : model1 loss : 0.444028 model2 loss : 0.020764
[12:15:31.998] iteration 26911 : model1 loss : 0.439106 model2 loss : 0.018285
[12:15:32.168] iteration 26912 : model1 loss : 0.442691 model2 loss : 0.019725
[12:15:32.338] iteration 26913 : model1 loss : 0.436860 model2 loss : 0.018365
[12:15:32.512] iteration 26914 : model1 loss : 0.444811 model2 loss : 0.022367
[12:15:32.680] iteration 26915 : model1 loss : 0.438723 model2 loss : 0.017980
[12:15:32.848] iteration 26916 : model1 loss : 0.439665 model2 loss : 0.018455
[12:15:33.018] iteration 26917 : model1 loss : 0.445174 model2 loss : 0.021367
[12:15:33.190] iteration 26918 : model1 loss : 0.438804 model2 loss : 0.020267
[12:15:33.358] iteration 26919 : model1 loss : 0.437426 model2 loss : 0.020271
[12:15:33.531] iteration 26920 : model1 loss : 0.440094 model2 loss : 0.019478
[12:15:33.700] iteration 26921 : model1 loss : 0.443674 model2 loss : 0.019303
[12:15:33.870] iteration 26922 : model1 loss : 0.440658 model2 loss : 0.022094
[12:15:34.036] iteration 26923 : model1 loss : 0.440099 model2 loss : 0.017953
[12:15:34.207] iteration 26924 : model1 loss : 0.438643 model2 loss : 0.017639
[12:15:34.376] iteration 26925 : model1 loss : 0.438863 model2 loss : 0.020463
[12:15:34.550] iteration 26926 : model1 loss : 0.439670 model2 loss : 0.018365
[12:15:34.715] iteration 26927 : model1 loss : 0.437536 model2 loss : 0.018986
[12:15:34.882] iteration 26928 : model1 loss : 0.436249 model2 loss : 0.018689
[12:15:36.811] iteration 26929 : model1 loss : 0.445222 model2 loss : 0.020811
[12:15:36.983] iteration 26930 : model1 loss : 0.436738 model2 loss : 0.019213
[12:15:37.153] iteration 26931 : model1 loss : 0.443337 model2 loss : 0.018322
[12:15:37.321] iteration 26932 : model1 loss : 0.441019 model2 loss : 0.021341
[12:15:37.494] iteration 26933 : model1 loss : 0.440924 model2 loss : 0.020160
[12:15:37.666] iteration 26934 : model1 loss : 0.440880 model2 loss : 0.019035
[12:15:37.834] iteration 26935 : model1 loss : 0.438914 model2 loss : 0.018863
[12:15:38.000] iteration 26936 : model1 loss : 0.440177 model2 loss : 0.019943
[12:15:38.170] iteration 26937 : model1 loss : 0.441019 model2 loss : 0.018998
[12:15:38.339] iteration 26938 : model1 loss : 0.434354 model2 loss : 0.017506
[12:15:38.512] iteration 26939 : model1 loss : 0.432774 model2 loss : 0.016625
[12:15:38.681] iteration 26940 : model1 loss : 0.439138 model2 loss : 0.019212
[12:15:38.848] iteration 26941 : model1 loss : 0.439947 model2 loss : 0.018905
[12:15:39.022] iteration 26942 : model1 loss : 0.434893 model2 loss : 0.019004
[12:15:39.193] iteration 26943 : model1 loss : 0.441260 model2 loss : 0.018883
[12:15:39.362] iteration 26944 : model1 loss : 0.439333 model2 loss : 0.019306
[12:15:39.535] iteration 26945 : model1 loss : 0.440111 model2 loss : 0.019165
[12:15:39.700] iteration 26946 : model1 loss : 0.440310 model2 loss : 0.018486
[12:15:39.869] iteration 26947 : model1 loss : 0.439011 model2 loss : 0.017650
[12:15:40.038] iteration 26948 : model1 loss : 0.440679 model2 loss : 0.019255
[12:15:40.207] iteration 26949 : model1 loss : 0.440327 model2 loss : 0.020783
[12:15:40.375] iteration 26950 : model1 loss : 0.441546 model2 loss : 0.020651
[12:15:40.545] iteration 26951 : model1 loss : 0.437806 model2 loss : 0.019932
[12:15:40.712] iteration 26952 : model1 loss : 0.440186 model2 loss : 0.019151
[12:15:40.880] iteration 26953 : model1 loss : 0.443576 model2 loss : 0.018398
[12:15:41.048] iteration 26954 : model1 loss : 0.441752 model2 loss : 0.020323
[12:15:41.217] iteration 26955 : model1 loss : 0.440203 model2 loss : 0.020653
[12:15:41.386] iteration 26956 : model1 loss : 0.444101 model2 loss : 0.019035
[12:15:41.558] iteration 26957 : model1 loss : 0.439111 model2 loss : 0.017716
[12:15:41.726] iteration 26958 : model1 loss : 0.439345 model2 loss : 0.019688
[12:15:41.897] iteration 26959 : model1 loss : 0.445316 model2 loss : 0.020860
[12:15:42.062] iteration 26960 : model1 loss : 0.440621 model2 loss : 0.022606
[12:15:42.238] iteration 26961 : model1 loss : 0.440260 model2 loss : 0.018698
[12:15:44.157] iteration 26962 : model1 loss : 0.439286 model2 loss : 0.020475
[12:15:44.326] iteration 26963 : model1 loss : 0.440176 model2 loss : 0.019526
[12:15:44.497] iteration 26964 : model1 loss : 0.436784 model2 loss : 0.020615
[12:15:44.666] iteration 26965 : model1 loss : 0.441126 model2 loss : 0.021283
[12:15:44.836] iteration 26966 : model1 loss : 0.439541 model2 loss : 0.018440
[12:15:45.002] iteration 26967 : model1 loss : 0.440706 model2 loss : 0.020844
[12:15:45.174] iteration 26968 : model1 loss : 0.443304 model2 loss : 0.019816
[12:15:45.342] iteration 26969 : model1 loss : 0.445677 model2 loss : 0.016791
[12:15:45.516] iteration 26970 : model1 loss : 0.441534 model2 loss : 0.019052
[12:15:45.687] iteration 26971 : model1 loss : 0.438078 model2 loss : 0.019494
[12:15:45.856] iteration 26972 : model1 loss : 0.441334 model2 loss : 0.018604
[12:15:46.023] iteration 26973 : model1 loss : 0.438578 model2 loss : 0.018531
[12:15:46.193] iteration 26974 : model1 loss : 0.438463 model2 loss : 0.017972
[12:15:46.363] iteration 26975 : model1 loss : 0.438057 model2 loss : 0.018750
[12:15:46.535] iteration 26976 : model1 loss : 0.441837 model2 loss : 0.019299
[12:15:46.702] iteration 26977 : model1 loss : 0.441534 model2 loss : 0.019347
[12:15:46.872] iteration 26978 : model1 loss : 0.439746 model2 loss : 0.020083
[12:15:47.041] iteration 26979 : model1 loss : 0.435066 model2 loss : 0.016988
[12:15:47.210] iteration 26980 : model1 loss : 0.441926 model2 loss : 0.020088
[12:15:47.379] iteration 26981 : model1 loss : 0.436671 model2 loss : 0.018541
[12:15:47.552] iteration 26982 : model1 loss : 0.441435 model2 loss : 0.020486
[12:15:47.719] iteration 26983 : model1 loss : 0.443034 model2 loss : 0.021752
[12:15:47.888] iteration 26984 : model1 loss : 0.441103 model2 loss : 0.021481
[12:15:48.056] iteration 26985 : model1 loss : 0.439343 model2 loss : 0.017330
[12:15:48.227] iteration 26986 : model1 loss : 0.437163 model2 loss : 0.018275
[12:15:48.396] iteration 26987 : model1 loss : 0.440167 model2 loss : 0.019137
[12:15:48.568] iteration 26988 : model1 loss : 0.437714 model2 loss : 0.019244
[12:15:48.734] iteration 26989 : model1 loss : 0.438194 model2 loss : 0.020168
[12:15:48.902] iteration 26990 : model1 loss : 0.442171 model2 loss : 0.018869
[12:15:49.070] iteration 26991 : model1 loss : 0.434485 model2 loss : 0.020461
[12:15:49.238] iteration 26992 : model1 loss : 0.441340 model2 loss : 0.019147
[12:15:49.406] iteration 26993 : model1 loss : 0.443076 model2 loss : 0.019585
[12:15:49.579] iteration 26994 : model1 loss : 0.440502 model2 loss : 0.019190
[12:15:51.514] iteration 26995 : model1 loss : 0.443107 model2 loss : 0.019274
[12:15:51.685] iteration 26996 : model1 loss : 0.439774 model2 loss : 0.019282
[12:15:51.855] iteration 26997 : model1 loss : 0.439469 model2 loss : 0.019438
[12:15:52.023] iteration 26998 : model1 loss : 0.438474 model2 loss : 0.020095
[12:15:52.192] iteration 26999 : model1 loss : 0.438971 model2 loss : 0.020629
[12:15:52.360] iteration 27000 : model1 loss : 0.441757 model2 loss : 0.020343
[12:16:00.594] iteration 27000 : model1_mean_dice : 0.900966 model1_mean_hd95 : 3.460730
[12:16:08.906] iteration 27000 : model2_mean_dice : 0.898139 model2_mean_hd95 : 1.990859
[12:16:08.929] save model1 to ../model/ACDC/EVILv1_kl0.5_tau0.25_21_1337/unet\model1_iter_27000.pth
[12:16:08.948] save model2 to ../model/ACDC/EVILv1_kl0.5_tau0.25_21_1337/unet\model2_iter_27000.pth
[12:16:09.123] iteration 27001 : model1 loss : 0.439346 model2 loss : 0.019154
[12:16:09.293] iteration 27002 : model1 loss : 0.439116 model2 loss : 0.018747
[12:16:09.463] iteration 27003 : model1 loss : 0.439694 model2 loss : 0.017734
[12:16:09.632] iteration 27004 : model1 loss : 0.442693 model2 loss : 0.019383
[12:16:09.801] iteration 27005 : model1 loss : 0.440231 model2 loss : 0.020323
[12:16:09.972] iteration 27006 : model1 loss : 0.439637 model2 loss : 0.019141
[12:16:10.140] iteration 27007 : model1 loss : 0.436706 model2 loss : 0.016976
[12:16:10.307] iteration 27008 : model1 loss : 0.441926 model2 loss : 0.021053
[12:16:10.477] iteration 27009 : model1 loss : 0.437458 model2 loss : 0.017599
[12:16:10.643] iteration 27010 : model1 loss : 0.435454 model2 loss : 0.017554
[12:16:10.812] iteration 27011 : model1 loss : 0.438309 model2 loss : 0.018181
[12:16:10.978] iteration 27012 : model1 loss : 0.440978 model2 loss : 0.019979
[12:16:11.147] iteration 27013 : model1 loss : 0.437511 model2 loss : 0.020137
[12:16:11.312] iteration 27014 : model1 loss : 0.436304 model2 loss : 0.018264
[12:16:11.481] iteration 27015 : model1 loss : 0.440914 model2 loss : 0.018860
[12:16:11.649] iteration 27016 : model1 loss : 0.442402 model2 loss : 0.021790
[12:16:11.817] iteration 27017 : model1 loss : 0.444495 model2 loss : 0.019874
[12:16:11.985] iteration 27018 : model1 loss : 0.439158 model2 loss : 0.018764
[12:16:12.154] iteration 27019 : model1 loss : 0.440722 model2 loss : 0.017940
[12:16:12.322] iteration 27020 : model1 loss : 0.439213 model2 loss : 0.018898
[12:16:12.491] iteration 27021 : model1 loss : 0.439291 model2 loss : 0.018336
[12:16:12.659] iteration 27022 : model1 loss : 0.447036 model2 loss : 0.023523
[12:16:12.828] iteration 27023 : model1 loss : 0.442348 model2 loss : 0.017222
[12:16:12.994] iteration 27024 : model1 loss : 0.440660 model2 loss : 0.018898
[12:16:13.187] iteration 27025 : model1 loss : 0.442523 model2 loss : 0.019028
[12:16:13.352] iteration 27026 : model1 loss : 0.439772 model2 loss : 0.020618
[12:16:13.525] iteration 27027 : model1 loss : 0.439305 model2 loss : 0.019343
[12:16:15.450] iteration 27028 : model1 loss : 0.439406 model2 loss : 0.019674
[12:16:15.620] iteration 27029 : model1 loss : 0.437301 model2 loss : 0.021141
[12:16:15.795] iteration 27030 : model1 loss : 0.442116 model2 loss : 0.018445
[12:16:15.962] iteration 27031 : model1 loss : 0.443657 model2 loss : 0.019672
[12:16:16.131] iteration 27032 : model1 loss : 0.438871 model2 loss : 0.020395
[12:16:16.297] iteration 27033 : model1 loss : 0.441849 model2 loss : 0.019262
[12:16:16.468] iteration 27034 : model1 loss : 0.433256 model2 loss : 0.017924
[12:16:16.635] iteration 27035 : model1 loss : 0.442466 model2 loss : 0.018754
[12:16:16.807] iteration 27036 : model1 loss : 0.438309 model2 loss : 0.018327
[12:16:16.972] iteration 27037 : model1 loss : 0.437123 model2 loss : 0.017715
[12:16:17.140] iteration 27038 : model1 loss : 0.442374 model2 loss : 0.020056
[12:16:17.307] iteration 27039 : model1 loss : 0.439703 model2 loss : 0.020353
[12:16:17.475] iteration 27040 : model1 loss : 0.434789 model2 loss : 0.019278
[12:16:17.641] iteration 27041 : model1 loss : 0.436018 model2 loss : 0.016568
[12:16:17.810] iteration 27042 : model1 loss : 0.444226 model2 loss : 0.023405
[12:16:17.976] iteration 27043 : model1 loss : 0.444221 model2 loss : 0.022760
[12:16:18.145] iteration 27044 : model1 loss : 0.442516 model2 loss : 0.019549
[12:16:18.312] iteration 27045 : model1 loss : 0.438214 model2 loss : 0.018672
[12:16:18.481] iteration 27046 : model1 loss : 0.438957 model2 loss : 0.019809
[12:16:18.649] iteration 27047 : model1 loss : 0.444360 model2 loss : 0.018971
[12:16:18.821] iteration 27048 : model1 loss : 0.439492 model2 loss : 0.018930
[12:16:18.988] iteration 27049 : model1 loss : 0.445160 model2 loss : 0.021632
[12:16:19.157] iteration 27050 : model1 loss : 0.440137 model2 loss : 0.017713
[12:16:19.324] iteration 27051 : model1 loss : 0.442275 model2 loss : 0.019720
[12:16:19.493] iteration 27052 : model1 loss : 0.440352 model2 loss : 0.018099
[12:16:19.659] iteration 27053 : model1 loss : 0.439564 model2 loss : 0.018223
[12:16:19.828] iteration 27054 : model1 loss : 0.437853 model2 loss : 0.018210
[12:16:19.994] iteration 27055 : model1 loss : 0.433004 model2 loss : 0.017797
[12:16:20.164] iteration 27056 : model1 loss : 0.435017 model2 loss : 0.018804
[12:16:20.329] iteration 27057 : model1 loss : 0.438219 model2 loss : 0.018270
[12:16:20.504] iteration 27058 : model1 loss : 0.448702 model2 loss : 0.023176
[12:16:20.668] iteration 27059 : model1 loss : 0.444217 model2 loss : 0.020615
[12:16:20.836] iteration 27060 : model1 loss : 0.439481 model2 loss : 0.019343
[12:16:22.748] iteration 27061 : model1 loss : 0.436547 model2 loss : 0.019867
[12:16:22.915] iteration 27062 : model1 loss : 0.443091 model2 loss : 0.018631
[12:16:23.084] iteration 27063 : model1 loss : 0.439759 model2 loss : 0.018892
[12:16:23.251] iteration 27064 : model1 loss : 0.440975 model2 loss : 0.019262
[12:16:23.420] iteration 27065 : model1 loss : 0.438122 model2 loss : 0.019159
[12:16:23.595] iteration 27066 : model1 loss : 0.439774 model2 loss : 0.019394
[12:16:23.764] iteration 27067 : model1 loss : 0.439166 model2 loss : 0.019206
[12:16:23.933] iteration 27068 : model1 loss : 0.437707 model2 loss : 0.019373
[12:16:24.101] iteration 27069 : model1 loss : 0.444442 model2 loss : 0.020439
[12:16:24.269] iteration 27070 : model1 loss : 0.444992 model2 loss : 0.024417
[12:16:24.436] iteration 27071 : model1 loss : 0.442515 model2 loss : 0.019046
[12:16:24.603] iteration 27072 : model1 loss : 0.437970 model2 loss : 0.019396
[12:16:24.775] iteration 27073 : model1 loss : 0.440641 model2 loss : 0.018931
[12:16:24.942] iteration 27074 : model1 loss : 0.439557 model2 loss : 0.019462
[12:16:25.110] iteration 27075 : model1 loss : 0.436575 model2 loss : 0.020383
[12:16:25.276] iteration 27076 : model1 loss : 0.438941 model2 loss : 0.019361
[12:16:25.445] iteration 27077 : model1 loss : 0.440834 model2 loss : 0.021951
[12:16:25.611] iteration 27078 : model1 loss : 0.437537 model2 loss : 0.018426
[12:16:25.781] iteration 27079 : model1 loss : 0.441087 model2 loss : 0.021122
[12:16:25.960] iteration 27080 : model1 loss : 0.440584 model2 loss : 0.021063
[12:16:26.128] iteration 27081 : model1 loss : 0.440781 model2 loss : 0.021812
[12:16:26.295] iteration 27082 : model1 loss : 0.440137 model2 loss : 0.017775
[12:16:26.463] iteration 27083 : model1 loss : 0.440951 model2 loss : 0.018675
[12:16:26.631] iteration 27084 : model1 loss : 0.441408 model2 loss : 0.020510
[12:16:26.803] iteration 27085 : model1 loss : 0.442689 model2 loss : 0.018809
[12:16:26.969] iteration 27086 : model1 loss : 0.436868 model2 loss : 0.019140
[12:16:27.140] iteration 27087 : model1 loss : 0.441527 model2 loss : 0.018603
[12:16:27.306] iteration 27088 : model1 loss : 0.439522 model2 loss : 0.019635
[12:16:27.473] iteration 27089 : model1 loss : 0.439688 model2 loss : 0.016955
[12:16:27.640] iteration 27090 : model1 loss : 0.439194 model2 loss : 0.017484
[12:16:27.809] iteration 27091 : model1 loss : 0.443129 model2 loss : 0.020590
[12:16:27.974] iteration 27092 : model1 loss : 0.440595 model2 loss : 0.020404
[12:16:28.142] iteration 27093 : model1 loss : 0.436643 model2 loss : 0.016354
[12:16:30.062] iteration 27094 : model1 loss : 0.440126 model2 loss : 0.020041
[12:16:30.232] iteration 27095 : model1 loss : 0.444388 model2 loss : 0.022157
[12:16:30.403] iteration 27096 : model1 loss : 0.439804 model2 loss : 0.020567
[12:16:30.569] iteration 27097 : model1 loss : 0.440632 model2 loss : 0.021391
[12:16:30.740] iteration 27098 : model1 loss : 0.441053 model2 loss : 0.020489
[12:16:30.909] iteration 27099 : model1 loss : 0.443197 model2 loss : 0.019896
[12:16:31.078] iteration 27100 : model1 loss : 0.436896 model2 loss : 0.018787
[12:16:31.247] iteration 27101 : model1 loss : 0.443875 model2 loss : 0.019834
[12:16:31.416] iteration 27102 : model1 loss : 0.438877 model2 loss : 0.018180
[12:16:31.584] iteration 27103 : model1 loss : 0.442244 model2 loss : 0.019189
[12:16:31.753] iteration 27104 : model1 loss : 0.443620 model2 loss : 0.019737
[12:16:31.918] iteration 27105 : model1 loss : 0.433023 model2 loss : 0.019583
[12:16:32.086] iteration 27106 : model1 loss : 0.436751 model2 loss : 0.018902
[12:16:32.251] iteration 27107 : model1 loss : 0.442080 model2 loss : 0.019712
[12:16:32.419] iteration 27108 : model1 loss : 0.436990 model2 loss : 0.017924
[12:16:32.586] iteration 27109 : model1 loss : 0.437758 model2 loss : 0.018855
[12:16:32.755] iteration 27110 : model1 loss : 0.441285 model2 loss : 0.018541
[12:16:32.922] iteration 27111 : model1 loss : 0.437947 model2 loss : 0.018505
[12:16:33.092] iteration 27112 : model1 loss : 0.436292 model2 loss : 0.018106
[12:16:33.260] iteration 27113 : model1 loss : 0.441967 model2 loss : 0.019479
[12:16:33.431] iteration 27114 : model1 loss : 0.439309 model2 loss : 0.018865
[12:16:33.600] iteration 27115 : model1 loss : 0.439118 model2 loss : 0.019665
[12:16:33.770] iteration 27116 : model1 loss : 0.445998 model2 loss : 0.020536
[12:16:33.935] iteration 27117 : model1 loss : 0.436726 model2 loss : 0.018078
[12:16:34.108] iteration 27118 : model1 loss : 0.439009 model2 loss : 0.017879
[12:16:34.273] iteration 27119 : model1 loss : 0.437539 model2 loss : 0.018249
[12:16:34.441] iteration 27120 : model1 loss : 0.441400 model2 loss : 0.020190
[12:16:34.609] iteration 27121 : model1 loss : 0.441075 model2 loss : 0.019356
[12:16:34.781] iteration 27122 : model1 loss : 0.442375 model2 loss : 0.020192
[12:16:34.948] iteration 27123 : model1 loss : 0.444843 model2 loss : 0.019336
[12:16:35.118] iteration 27124 : model1 loss : 0.440242 model2 loss : 0.017654
[12:16:35.283] iteration 27125 : model1 loss : 0.440406 model2 loss : 0.016986
[12:16:35.451] iteration 27126 : model1 loss : 0.439171 model2 loss : 0.019070
[12:16:37.364] iteration 27127 : model1 loss : 0.440572 model2 loss : 0.017950
[12:16:37.535] iteration 27128 : model1 loss : 0.437139 model2 loss : 0.016370
[12:16:37.704] iteration 27129 : model1 loss : 0.441959 model2 loss : 0.019402
[12:16:37.870] iteration 27130 : model1 loss : 0.442207 model2 loss : 0.017437
[12:16:38.036] iteration 27131 : model1 loss : 0.438738 model2 loss : 0.018650
[12:16:38.204] iteration 27132 : model1 loss : 0.438334 model2 loss : 0.020325
[12:16:38.371] iteration 27133 : model1 loss : 0.440978 model2 loss : 0.020696
[12:16:38.538] iteration 27134 : model1 loss : 0.441422 model2 loss : 0.018456
[12:16:38.710] iteration 27135 : model1 loss : 0.439906 model2 loss : 0.021158
[12:16:38.877] iteration 27136 : model1 loss : 0.438723 model2 loss : 0.020845
[12:16:39.046] iteration 27137 : model1 loss : 0.438417 model2 loss : 0.017515
[12:16:39.214] iteration 27138 : model1 loss : 0.441338 model2 loss : 0.017456
[12:16:39.382] iteration 27139 : model1 loss : 0.442048 model2 loss : 0.018251
[12:16:39.549] iteration 27140 : model1 loss : 0.437055 model2 loss : 0.018284
[12:16:39.719] iteration 27141 : model1 loss : 0.440793 model2 loss : 0.017125
[12:16:39.885] iteration 27142 : model1 loss : 0.441066 model2 loss : 0.017815
[12:16:40.054] iteration 27143 : model1 loss : 0.440182 model2 loss : 0.019272
[12:16:40.223] iteration 27144 : model1 loss : 0.445804 model2 loss : 0.020436
[12:16:40.391] iteration 27145 : model1 loss : 0.439101 model2 loss : 0.018437
[12:16:40.558] iteration 27146 : model1 loss : 0.442044 model2 loss : 0.018786
[12:16:40.730] iteration 27147 : model1 loss : 0.443053 model2 loss : 0.019174
[12:16:40.899] iteration 27148 : model1 loss : 0.439937 model2 loss : 0.019005
[12:16:41.067] iteration 27149 : model1 loss : 0.441327 model2 loss : 0.019090
[12:16:41.233] iteration 27150 : model1 loss : 0.443615 model2 loss : 0.019736
[12:16:41.402] iteration 27151 : model1 loss : 0.441327 model2 loss : 0.020628
[12:16:41.571] iteration 27152 : model1 loss : 0.434076 model2 loss : 0.019208
[12:16:41.740] iteration 27153 : model1 loss : 0.442251 model2 loss : 0.021697
[12:16:41.915] iteration 27154 : model1 loss : 0.439664 model2 loss : 0.018033
[12:16:42.084] iteration 27155 : model1 loss : 0.434658 model2 loss : 0.018361
[12:16:42.250] iteration 27156 : model1 loss : 0.440944 model2 loss : 0.020915
[12:16:42.419] iteration 27157 : model1 loss : 0.439928 model2 loss : 0.017410
[12:16:42.585] iteration 27158 : model1 loss : 0.439294 model2 loss : 0.020014
[12:16:42.752] iteration 27159 : model1 loss : 0.435279 model2 loss : 0.019279
[12:16:44.666] iteration 27160 : model1 loss : 0.440499 model2 loss : 0.019366
[12:16:44.838] iteration 27161 : model1 loss : 0.434089 model2 loss : 0.017969
[12:16:45.007] iteration 27162 : model1 loss : 0.441610 model2 loss : 0.017684
[12:16:45.175] iteration 27163 : model1 loss : 0.439537 model2 loss : 0.017557
[12:16:45.343] iteration 27164 : model1 loss : 0.441361 model2 loss : 0.015256
[12:16:45.514] iteration 27165 : model1 loss : 0.442910 model2 loss : 0.020706
[12:16:45.685] iteration 27166 : model1 loss : 0.441512 model2 loss : 0.016920
[12:16:45.854] iteration 27167 : model1 loss : 0.443434 model2 loss : 0.019439
[12:16:46.022] iteration 27168 : model1 loss : 0.438724 model2 loss : 0.019633
[12:16:46.187] iteration 27169 : model1 loss : 0.441326 model2 loss : 0.019459
[12:16:46.359] iteration 27170 : model1 loss : 0.440918 model2 loss : 0.021559
[12:16:46.528] iteration 27171 : model1 loss : 0.438810 model2 loss : 0.018070
[12:16:46.697] iteration 27172 : model1 loss : 0.439503 model2 loss : 0.018393
[12:16:46.864] iteration 27173 : model1 loss : 0.439130 model2 loss : 0.019749
[12:16:47.036] iteration 27174 : model1 loss : 0.441942 model2 loss : 0.018992
[12:16:47.203] iteration 27175 : model1 loss : 0.438345 model2 loss : 0.017532
[12:16:47.371] iteration 27176 : model1 loss : 0.441133 model2 loss : 0.018650
[12:16:47.545] iteration 27177 : model1 loss : 0.438382 model2 loss : 0.018349
[12:16:47.714] iteration 27178 : model1 loss : 0.440834 model2 loss : 0.018341
[12:16:47.885] iteration 27179 : model1 loss : 0.434596 model2 loss : 0.018557
[12:16:48.054] iteration 27180 : model1 loss : 0.441113 model2 loss : 0.019371
[12:16:48.221] iteration 27181 : model1 loss : 0.444788 model2 loss : 0.022302
[12:16:48.391] iteration 27182 : model1 loss : 0.440810 model2 loss : 0.020155
[12:16:48.558] iteration 27183 : model1 loss : 0.438078 model2 loss : 0.018072
[12:16:48.728] iteration 27184 : model1 loss : 0.438340 model2 loss : 0.020071
[12:16:48.893] iteration 27185 : model1 loss : 0.436837 model2 loss : 0.017169
[12:16:49.062] iteration 27186 : model1 loss : 0.443251 model2 loss : 0.021131
[12:16:49.229] iteration 27187 : model1 loss : 0.439064 model2 loss : 0.018612
[12:16:49.398] iteration 27188 : model1 loss : 0.439745 model2 loss : 0.019496
[12:16:49.566] iteration 27189 : model1 loss : 0.437159 model2 loss : 0.019132
[12:16:49.736] iteration 27190 : model1 loss : 0.438435 model2 loss : 0.018506
[12:16:49.902] iteration 27191 : model1 loss : 0.439243 model2 loss : 0.019183
[12:16:50.070] iteration 27192 : model1 loss : 0.441686 model2 loss : 0.018306
[12:16:51.980] iteration 27193 : model1 loss : 0.437335 model2 loss : 0.018251
[12:16:52.148] iteration 27194 : model1 loss : 0.442682 model2 loss : 0.019751
[12:16:52.317] iteration 27195 : model1 loss : 0.440574 model2 loss : 0.019118
[12:16:52.482] iteration 27196 : model1 loss : 0.439588 model2 loss : 0.020642
[12:16:52.653] iteration 27197 : model1 loss : 0.440482 model2 loss : 0.020065
[12:16:52.821] iteration 27198 : model1 loss : 0.439702 model2 loss : 0.018710
[12:16:52.988] iteration 27199 : model1 loss : 0.442489 model2 loss : 0.020773
[12:16:53.155] iteration 27200 : model1 loss : 0.439250 model2 loss : 0.017270
[12:16:53.324] iteration 27201 : model1 loss : 0.437405 model2 loss : 0.017653
[12:16:53.491] iteration 27202 : model1 loss : 0.443301 model2 loss : 0.017383
[12:16:53.661] iteration 27203 : model1 loss : 0.442873 model2 loss : 0.018416
[12:16:53.830] iteration 27204 : model1 loss : 0.442375 model2 loss : 0.020643
[12:16:54.001] iteration 27205 : model1 loss : 0.439682 model2 loss : 0.017170
[12:16:54.168] iteration 27206 : model1 loss : 0.440130 model2 loss : 0.019202
[12:16:54.336] iteration 27207 : model1 loss : 0.440557 model2 loss : 0.018970
[12:16:54.506] iteration 27208 : model1 loss : 0.438893 model2 loss : 0.017601
[12:16:54.675] iteration 27209 : model1 loss : 0.439843 model2 loss : 0.019718
[12:16:54.845] iteration 27210 : model1 loss : 0.441638 model2 loss : 0.021002
[12:16:55.014] iteration 27211 : model1 loss : 0.438719 model2 loss : 0.017351
[12:16:55.180] iteration 27212 : model1 loss : 0.441139 model2 loss : 0.018920
[12:16:55.348] iteration 27213 : model1 loss : 0.441801 model2 loss : 0.018734
[12:16:55.517] iteration 27214 : model1 loss : 0.437138 model2 loss : 0.017835
[12:16:55.685] iteration 27215 : model1 loss : 0.436971 model2 loss : 0.019765
[12:16:55.854] iteration 27216 : model1 loss : 0.439619 model2 loss : 0.016946
[12:16:56.046] iteration 27217 : model1 loss : 0.439122 model2 loss : 0.019384
[12:16:56.211] iteration 27218 : model1 loss : 0.437245 model2 loss : 0.018809
[12:16:56.379] iteration 27219 : model1 loss : 0.439754 model2 loss : 0.020158
[12:16:56.546] iteration 27220 : model1 loss : 0.437668 model2 loss : 0.021181
[12:16:56.715] iteration 27221 : model1 loss : 0.440598 model2 loss : 0.019454
[12:16:56.883] iteration 27222 : model1 loss : 0.434882 model2 loss : 0.018362
[12:16:57.052] iteration 27223 : model1 loss : 0.438971 model2 loss : 0.020153
[12:16:57.219] iteration 27224 : model1 loss : 0.447904 model2 loss : 0.023369
[12:16:57.387] iteration 27225 : model1 loss : 0.443586 model2 loss : 0.021852
[12:16:59.316] iteration 27226 : model1 loss : 0.442520 model2 loss : 0.019277
[12:16:59.485] iteration 27227 : model1 loss : 0.437514 model2 loss : 0.019192
[12:16:59.654] iteration 27228 : model1 loss : 0.442342 model2 loss : 0.019341
[12:16:59.822] iteration 27229 : model1 loss : 0.435544 model2 loss : 0.016805
[12:16:59.991] iteration 27230 : model1 loss : 0.436320 model2 loss : 0.018491
[12:17:00.158] iteration 27231 : model1 loss : 0.443015 model2 loss : 0.020946
[12:17:00.329] iteration 27232 : model1 loss : 0.440190 model2 loss : 0.020652
[12:17:00.502] iteration 27233 : model1 loss : 0.442158 model2 loss : 0.018526
[12:17:00.672] iteration 27234 : model1 loss : 0.440749 model2 loss : 0.020598
[12:17:00.840] iteration 27235 : model1 loss : 0.442953 model2 loss : 0.018711
[12:17:01.008] iteration 27236 : model1 loss : 0.440480 model2 loss : 0.020594
[12:17:01.175] iteration 27237 : model1 loss : 0.439608 model2 loss : 0.019810
[12:17:01.352] iteration 27238 : model1 loss : 0.435819 model2 loss : 0.018632
[12:17:01.521] iteration 27239 : model1 loss : 0.436974 model2 loss : 0.018833
[12:17:01.688] iteration 27240 : model1 loss : 0.442231 model2 loss : 0.018762
[12:17:01.857] iteration 27241 : model1 loss : 0.434112 model2 loss : 0.017576
[12:17:02.024] iteration 27242 : model1 loss : 0.442733 model2 loss : 0.020027
[12:17:02.191] iteration 27243 : model1 loss : 0.441970 model2 loss : 0.017631
[12:17:02.360] iteration 27244 : model1 loss : 0.444271 model2 loss : 0.018921
[12:17:02.531] iteration 27245 : model1 loss : 0.436365 model2 loss : 0.019840
[12:17:02.700] iteration 27246 : model1 loss : 0.443328 model2 loss : 0.021883
[12:17:02.871] iteration 27247 : model1 loss : 0.439208 model2 loss : 0.018625
[12:17:03.041] iteration 27248 : model1 loss : 0.436878 model2 loss : 0.018261
[12:17:03.207] iteration 27249 : model1 loss : 0.439723 model2 loss : 0.019154
[12:17:03.377] iteration 27250 : model1 loss : 0.437953 model2 loss : 0.019161
[12:17:03.543] iteration 27251 : model1 loss : 0.436752 model2 loss : 0.017927
[12:17:03.711] iteration 27252 : model1 loss : 0.444994 model2 loss : 0.020011
[12:17:03.881] iteration 27253 : model1 loss : 0.441704 model2 loss : 0.023030
[12:17:04.050] iteration 27254 : model1 loss : 0.440206 model2 loss : 0.020514
[12:17:04.218] iteration 27255 : model1 loss : 0.440526 model2 loss : 0.018429
[12:17:04.388] iteration 27256 : model1 loss : 0.444219 model2 loss : 0.019201
[12:17:04.553] iteration 27257 : model1 loss : 0.440604 model2 loss : 0.018559
[12:17:04.721] iteration 27258 : model1 loss : 0.441266 model2 loss : 0.021216
[12:17:06.685] iteration 27259 : model1 loss : 0.439314 model2 loss : 0.018185
[12:17:06.857] iteration 27260 : model1 loss : 0.438810 model2 loss : 0.019761
[12:17:07.027] iteration 27261 : model1 loss : 0.445208 model2 loss : 0.020658
[12:17:07.194] iteration 27262 : model1 loss : 0.443273 model2 loss : 0.021432
[12:17:07.363] iteration 27263 : model1 loss : 0.437696 model2 loss : 0.017381
[12:17:07.532] iteration 27264 : model1 loss : 0.439667 model2 loss : 0.017518
[12:17:07.711] iteration 27265 : model1 loss : 0.439540 model2 loss : 0.018278
[12:17:07.877] iteration 27266 : model1 loss : 0.439761 model2 loss : 0.023777
[12:17:08.046] iteration 27267 : model1 loss : 0.443217 model2 loss : 0.016924
[12:17:08.212] iteration 27268 : model1 loss : 0.435196 model2 loss : 0.019134
[12:17:08.379] iteration 27269 : model1 loss : 0.443453 model2 loss : 0.021534
[12:17:08.546] iteration 27270 : model1 loss : 0.442650 model2 loss : 0.021967
[12:17:08.714] iteration 27271 : model1 loss : 0.441858 model2 loss : 0.017342
[12:17:08.884] iteration 27272 : model1 loss : 0.435957 model2 loss : 0.017860
[12:17:09.051] iteration 27273 : model1 loss : 0.440888 model2 loss : 0.019703
[12:17:09.219] iteration 27274 : model1 loss : 0.440926 model2 loss : 0.017598
[12:17:09.389] iteration 27275 : model1 loss : 0.445414 model2 loss : 0.020058
[12:17:09.556] iteration 27276 : model1 loss : 0.443737 model2 loss : 0.022002
[12:17:09.725] iteration 27277 : model1 loss : 0.443083 model2 loss : 0.019571
[12:17:09.894] iteration 27278 : model1 loss : 0.439712 model2 loss : 0.019531
[12:17:10.063] iteration 27279 : model1 loss : 0.438876 model2 loss : 0.017471
[12:17:10.231] iteration 27280 : model1 loss : 0.438921 model2 loss : 0.017719
[12:17:10.401] iteration 27281 : model1 loss : 0.440905 model2 loss : 0.018863
[12:17:10.569] iteration 27282 : model1 loss : 0.438186 model2 loss : 0.020129
[12:17:10.736] iteration 27283 : model1 loss : 0.437377 model2 loss : 0.019095
[12:17:10.910] iteration 27284 : model1 loss : 0.437652 model2 loss : 0.020328
[12:17:11.078] iteration 27285 : model1 loss : 0.438002 model2 loss : 0.019759
[12:17:11.246] iteration 27286 : model1 loss : 0.442217 model2 loss : 0.019008
[12:17:11.416] iteration 27287 : model1 loss : 0.436170 model2 loss : 0.019099
[12:17:11.584] iteration 27288 : model1 loss : 0.438855 model2 loss : 0.017273
[12:17:11.754] iteration 27289 : model1 loss : 0.440483 model2 loss : 0.018355
[12:17:11.922] iteration 27290 : model1 loss : 0.440523 model2 loss : 0.018580
[12:17:12.091] iteration 27291 : model1 loss : 0.438524 model2 loss : 0.017955
[12:17:14.011] iteration 27292 : model1 loss : 0.440856 model2 loss : 0.017618
[12:17:14.178] iteration 27293 : model1 loss : 0.441644 model2 loss : 0.019303
[12:17:14.347] iteration 27294 : model1 loss : 0.438662 model2 loss : 0.016429
[12:17:14.516] iteration 27295 : model1 loss : 0.443496 model2 loss : 0.021815
[12:17:14.683] iteration 27296 : model1 loss : 0.437185 model2 loss : 0.016382
[12:17:14.851] iteration 27297 : model1 loss : 0.442995 model2 loss : 0.023483
[12:17:15.020] iteration 27298 : model1 loss : 0.438423 model2 loss : 0.019099
[12:17:15.186] iteration 27299 : model1 loss : 0.439037 model2 loss : 0.017527
[12:17:15.355] iteration 27300 : model1 loss : 0.441123 model2 loss : 0.019750
[12:17:15.526] iteration 27301 : model1 loss : 0.439385 model2 loss : 0.018892
[12:17:15.695] iteration 27302 : model1 loss : 0.445258 model2 loss : 0.019120
[12:17:15.862] iteration 27303 : model1 loss : 0.441690 model2 loss : 0.018028
[12:17:16.031] iteration 27304 : model1 loss : 0.438829 model2 loss : 0.018556
[12:17:16.197] iteration 27305 : model1 loss : 0.437375 model2 loss : 0.019368
[12:17:16.364] iteration 27306 : model1 loss : 0.436388 model2 loss : 0.017499
[12:17:16.531] iteration 27307 : model1 loss : 0.441486 model2 loss : 0.016520
[12:17:16.701] iteration 27308 : model1 loss : 0.441882 model2 loss : 0.017889
[12:17:16.869] iteration 27309 : model1 loss : 0.434725 model2 loss : 0.019622
[12:17:17.039] iteration 27310 : model1 loss : 0.441939 model2 loss : 0.019083
[12:17:17.206] iteration 27311 : model1 loss : 0.440993 model2 loss : 0.017396
[12:17:17.374] iteration 27312 : model1 loss : 0.438427 model2 loss : 0.019035
[12:17:17.541] iteration 27313 : model1 loss : 0.437095 model2 loss : 0.020185
[12:17:17.711] iteration 27314 : model1 loss : 0.439826 model2 loss : 0.020852
[12:17:17.877] iteration 27315 : model1 loss : 0.437804 model2 loss : 0.017451
[12:17:18.047] iteration 27316 : model1 loss : 0.447187 model2 loss : 0.023432
[12:17:18.213] iteration 27317 : model1 loss : 0.439657 model2 loss : 0.020827
[12:17:18.384] iteration 27318 : model1 loss : 0.443711 model2 loss : 0.019523
[12:17:18.551] iteration 27319 : model1 loss : 0.437750 model2 loss : 0.020762
[12:17:18.720] iteration 27320 : model1 loss : 0.438999 model2 loss : 0.021589
[12:17:18.888] iteration 27321 : model1 loss : 0.434733 model2 loss : 0.018900
[12:17:19.056] iteration 27322 : model1 loss : 0.445461 model2 loss : 0.022958
[12:17:19.221] iteration 27323 : model1 loss : 0.443120 model2 loss : 0.020598
[12:17:19.388] iteration 27324 : model1 loss : 0.439092 model2 loss : 0.017733
[12:17:21.336] iteration 27325 : model1 loss : 0.437952 model2 loss : 0.018522
[12:17:21.505] iteration 27326 : model1 loss : 0.441424 model2 loss : 0.018531
[12:17:21.674] iteration 27327 : model1 loss : 0.442495 model2 loss : 0.020060
[12:17:21.840] iteration 27328 : model1 loss : 0.441578 model2 loss : 0.019846
[12:17:22.009] iteration 27329 : model1 loss : 0.439399 model2 loss : 0.022287
[12:17:22.176] iteration 27330 : model1 loss : 0.436295 model2 loss : 0.017828
[12:17:22.355] iteration 27331 : model1 loss : 0.436282 model2 loss : 0.017996
[12:17:22.527] iteration 27332 : model1 loss : 0.438620 model2 loss : 0.017462
[12:17:22.696] iteration 27333 : model1 loss : 0.442181 model2 loss : 0.020396
[12:17:22.866] iteration 27334 : model1 loss : 0.442953 model2 loss : 0.019369
[12:17:23.035] iteration 27335 : model1 loss : 0.439121 model2 loss : 0.018122
[12:17:23.203] iteration 27336 : model1 loss : 0.440585 model2 loss : 0.015175
[12:17:23.373] iteration 27337 : model1 loss : 0.441337 model2 loss : 0.019383
[12:17:23.544] iteration 27338 : model1 loss : 0.443653 model2 loss : 0.018356
[12:17:23.713] iteration 27339 : model1 loss : 0.438650 model2 loss : 0.018938
[12:17:23.883] iteration 27340 : model1 loss : 0.441108 model2 loss : 0.019980
[12:17:24.051] iteration 27341 : model1 loss : 0.443514 model2 loss : 0.021501
[12:17:24.218] iteration 27342 : model1 loss : 0.438697 model2 loss : 0.020503
[12:17:24.386] iteration 27343 : model1 loss : 0.440804 model2 loss : 0.020657
[12:17:24.551] iteration 27344 : model1 loss : 0.436790 model2 loss : 0.019700
[12:17:24.719] iteration 27345 : model1 loss : 0.440130 model2 loss : 0.018787
[12:17:24.886] iteration 27346 : model1 loss : 0.438557 model2 loss : 0.020261
[12:17:25.055] iteration 27347 : model1 loss : 0.441485 model2 loss : 0.017470
[12:17:25.223] iteration 27348 : model1 loss : 0.441014 model2 loss : 0.018706
[12:17:25.393] iteration 27349 : model1 loss : 0.442881 model2 loss : 0.022066
[12:17:25.560] iteration 27350 : model1 loss : 0.439477 model2 loss : 0.019596
[12:17:25.727] iteration 27351 : model1 loss : 0.438390 model2 loss : 0.019270
[12:17:25.895] iteration 27352 : model1 loss : 0.441738 model2 loss : 0.019956
[12:17:26.063] iteration 27353 : model1 loss : 0.441169 model2 loss : 0.018880
[12:17:26.230] iteration 27354 : model1 loss : 0.443950 model2 loss : 0.023706
[12:17:26.400] iteration 27355 : model1 loss : 0.434123 model2 loss : 0.018734
[12:17:26.567] iteration 27356 : model1 loss : 0.433039 model2 loss : 0.016851
[12:17:26.733] iteration 27357 : model1 loss : 0.440807 model2 loss : 0.019280
[12:17:28.688] iteration 27358 : model1 loss : 0.438987 model2 loss : 0.018510
[12:17:28.857] iteration 27359 : model1 loss : 0.437948 model2 loss : 0.018297
[12:17:29.029] iteration 27360 : model1 loss : 0.437066 model2 loss : 0.020258
[12:17:29.195] iteration 27361 : model1 loss : 0.440576 model2 loss : 0.018302
[12:17:29.364] iteration 27362 : model1 loss : 0.442079 model2 loss : 0.018994
[12:17:29.531] iteration 27363 : model1 loss : 0.439669 model2 loss : 0.019824
[12:17:29.702] iteration 27364 : model1 loss : 0.435819 model2 loss : 0.017975
[12:17:29.869] iteration 27365 : model1 loss : 0.442943 model2 loss : 0.019565
[12:17:30.038] iteration 27366 : model1 loss : 0.441011 model2 loss : 0.020834
[12:17:30.206] iteration 27367 : model1 loss : 0.439603 model2 loss : 0.019554
[12:17:30.372] iteration 27368 : model1 loss : 0.438694 model2 loss : 0.019438
[12:17:30.540] iteration 27369 : model1 loss : 0.434599 model2 loss : 0.016014
[12:17:30.711] iteration 27370 : model1 loss : 0.439204 model2 loss : 0.018689
[12:17:30.879] iteration 27371 : model1 loss : 0.439505 model2 loss : 0.019306
[12:17:31.049] iteration 27372 : model1 loss : 0.440858 model2 loss : 0.020541
[12:17:31.215] iteration 27373 : model1 loss : 0.440801 model2 loss : 0.019190
[12:17:31.385] iteration 27374 : model1 loss : 0.437897 model2 loss : 0.018207
[12:17:31.553] iteration 27375 : model1 loss : 0.441176 model2 loss : 0.020502
[12:17:31.723] iteration 27376 : model1 loss : 0.438581 model2 loss : 0.017535
[12:17:31.889] iteration 27377 : model1 loss : 0.444759 model2 loss : 0.021593
[12:17:32.058] iteration 27378 : model1 loss : 0.442689 model2 loss : 0.022587
[12:17:32.226] iteration 27379 : model1 loss : 0.439899 model2 loss : 0.017677
[12:17:32.395] iteration 27380 : model1 loss : 0.438071 model2 loss : 0.020842
[12:17:32.563] iteration 27381 : model1 loss : 0.441345 model2 loss : 0.019080
[12:17:32.731] iteration 27382 : model1 loss : 0.444347 model2 loss : 0.021659
[12:17:32.899] iteration 27383 : model1 loss : 0.442067 model2 loss : 0.019388
[12:17:33.068] iteration 27384 : model1 loss : 0.444272 model2 loss : 0.021945
[12:17:33.236] iteration 27385 : model1 loss : 0.441124 model2 loss : 0.018342
[12:17:33.404] iteration 27386 : model1 loss : 0.436316 model2 loss : 0.020337
[12:17:33.572] iteration 27387 : model1 loss : 0.442812 model2 loss : 0.017783
[12:17:33.741] iteration 27388 : model1 loss : 0.442973 model2 loss : 0.020805
[12:17:33.909] iteration 27389 : model1 loss : 0.441492 model2 loss : 0.019602
[12:17:34.077] iteration 27390 : model1 loss : 0.432931 model2 loss : 0.017137
[12:17:36.027] iteration 27391 : model1 loss : 0.438667 model2 loss : 0.017896
[12:17:36.200] iteration 27392 : model1 loss : 0.437659 model2 loss : 0.018754
[12:17:36.368] iteration 27393 : model1 loss : 0.442397 model2 loss : 0.019739
[12:17:36.536] iteration 27394 : model1 loss : 0.441129 model2 loss : 0.018138
[12:17:36.704] iteration 27395 : model1 loss : 0.440194 model2 loss : 0.019668
[12:17:36.872] iteration 27396 : model1 loss : 0.440189 model2 loss : 0.021102
[12:17:37.040] iteration 27397 : model1 loss : 0.440367 model2 loss : 0.018583
[12:17:37.207] iteration 27398 : model1 loss : 0.439080 model2 loss : 0.019627
[12:17:37.376] iteration 27399 : model1 loss : 0.443165 model2 loss : 0.017056
[12:17:37.543] iteration 27400 : model1 loss : 0.442950 model2 loss : 0.018852
[12:17:37.711] iteration 27401 : model1 loss : 0.438725 model2 loss : 0.019641
[12:17:37.877] iteration 27402 : model1 loss : 0.438371 model2 loss : 0.018706
[12:17:38.046] iteration 27403 : model1 loss : 0.437920 model2 loss : 0.017977
[12:17:38.214] iteration 27404 : model1 loss : 0.443069 model2 loss : 0.018381
[12:17:38.383] iteration 27405 : model1 loss : 0.439860 model2 loss : 0.018118
[12:17:38.551] iteration 27406 : model1 loss : 0.435866 model2 loss : 0.018275
[12:17:38.719] iteration 27407 : model1 loss : 0.437914 model2 loss : 0.019086
[12:17:38.886] iteration 27408 : model1 loss : 0.436423 model2 loss : 0.016406
[12:17:39.055] iteration 27409 : model1 loss : 0.445270 model2 loss : 0.019587
[12:17:39.222] iteration 27410 : model1 loss : 0.442026 model2 loss : 0.019355
[12:17:39.389] iteration 27411 : model1 loss : 0.437564 model2 loss : 0.017739
[12:17:39.556] iteration 27412 : model1 loss : 0.438376 model2 loss : 0.018988
[12:17:39.726] iteration 27413 : model1 loss : 0.439541 model2 loss : 0.018893
[12:17:39.891] iteration 27414 : model1 loss : 0.440404 model2 loss : 0.018016
[12:17:40.061] iteration 27415 : model1 loss : 0.437261 model2 loss : 0.019792
[12:17:40.228] iteration 27416 : model1 loss : 0.440000 model2 loss : 0.021190
[12:17:40.397] iteration 27417 : model1 loss : 0.445022 model2 loss : 0.020281
[12:17:40.565] iteration 27418 : model1 loss : 0.442726 model2 loss : 0.022064
[12:17:40.733] iteration 27419 : model1 loss : 0.440170 model2 loss : 0.019294
[12:17:40.904] iteration 27420 : model1 loss : 0.437738 model2 loss : 0.017888
[12:17:41.071] iteration 27421 : model1 loss : 0.443968 model2 loss : 0.020987
[12:17:41.238] iteration 27422 : model1 loss : 0.440938 model2 loss : 0.018638
[12:17:41.404] iteration 27423 : model1 loss : 0.436389 model2 loss : 0.019907
[12:17:43.295] iteration 27424 : model1 loss : 0.438751 model2 loss : 0.017731
[12:17:43.464] iteration 27425 : model1 loss : 0.442126 model2 loss : 0.018608
[12:17:43.634] iteration 27426 : model1 loss : 0.439786 model2 loss : 0.019640
[12:17:43.802] iteration 27427 : model1 loss : 0.438840 model2 loss : 0.018179
[12:17:43.971] iteration 27428 : model1 loss : 0.436301 model2 loss : 0.018841
[12:17:44.137] iteration 27429 : model1 loss : 0.434652 model2 loss : 0.020290
[12:17:44.306] iteration 27430 : model1 loss : 0.436646 model2 loss : 0.019581
[12:17:44.474] iteration 27431 : model1 loss : 0.437292 model2 loss : 0.018066
[12:17:44.642] iteration 27432 : model1 loss : 0.445867 model2 loss : 0.021542
[12:17:44.809] iteration 27433 : model1 loss : 0.443599 model2 loss : 0.021835
[12:17:44.977] iteration 27434 : model1 loss : 0.441137 model2 loss : 0.018572
[12:17:45.144] iteration 27435 : model1 loss : 0.442908 model2 loss : 0.019479
[12:17:45.312] iteration 27436 : model1 loss : 0.444563 model2 loss : 0.019981
[12:17:45.480] iteration 27437 : model1 loss : 0.441045 model2 loss : 0.020287
[12:17:45.648] iteration 27438 : model1 loss : 0.441189 model2 loss : 0.021108
[12:17:45.815] iteration 27439 : model1 loss : 0.442172 model2 loss : 0.018942
[12:17:45.988] iteration 27440 : model1 loss : 0.438891 model2 loss : 0.018805
[12:17:46.156] iteration 27441 : model1 loss : 0.443395 model2 loss : 0.019216
[12:17:46.325] iteration 27442 : model1 loss : 0.443853 model2 loss : 0.021928
[12:17:46.493] iteration 27443 : model1 loss : 0.436889 model2 loss : 0.020230
[12:17:46.664] iteration 27444 : model1 loss : 0.442279 model2 loss : 0.020643
[12:17:46.833] iteration 27445 : model1 loss : 0.439356 model2 loss : 0.018337
[12:17:47.002] iteration 27446 : model1 loss : 0.443103 model2 loss : 0.020495
[12:17:47.170] iteration 27447 : model1 loss : 0.437383 model2 loss : 0.019666
[12:17:47.342] iteration 27448 : model1 loss : 0.439835 model2 loss : 0.017435
[12:17:47.513] iteration 27449 : model1 loss : 0.443262 model2 loss : 0.018329
[12:17:47.682] iteration 27450 : model1 loss : 0.440610 model2 loss : 0.016980
[12:17:47.849] iteration 27451 : model1 loss : 0.434149 model2 loss : 0.018163
[12:17:48.022] iteration 27452 : model1 loss : 0.440544 model2 loss : 0.020219
[12:17:48.189] iteration 27453 : model1 loss : 0.435809 model2 loss : 0.018014
[12:17:48.359] iteration 27454 : model1 loss : 0.436339 model2 loss : 0.018830
[12:17:48.528] iteration 27455 : model1 loss : 0.445474 model2 loss : 0.018995
[12:17:48.697] iteration 27456 : model1 loss : 0.438155 model2 loss : 0.019891
[12:17:50.612] iteration 27457 : model1 loss : 0.439358 model2 loss : 0.018500
[12:17:50.781] iteration 27458 : model1 loss : 0.438704 model2 loss : 0.019675
[12:17:50.954] iteration 27459 : model1 loss : 0.442063 model2 loss : 0.018557
[12:17:51.121] iteration 27460 : model1 loss : 0.437226 model2 loss : 0.021235
[12:17:51.289] iteration 27461 : model1 loss : 0.441260 model2 loss : 0.019282
[12:17:51.456] iteration 27462 : model1 loss : 0.447245 model2 loss : 0.022128
[12:17:51.626] iteration 27463 : model1 loss : 0.438041 model2 loss : 0.019101
[12:17:51.793] iteration 27464 : model1 loss : 0.434365 model2 loss : 0.016408
[12:17:51.963] iteration 27465 : model1 loss : 0.443606 model2 loss : 0.020103
[12:17:52.130] iteration 27466 : model1 loss : 0.442987 model2 loss : 0.018924
[12:17:52.300] iteration 27467 : model1 loss : 0.435664 model2 loss : 0.017187
[12:17:52.467] iteration 27468 : model1 loss : 0.439735 model2 loss : 0.020674
[12:17:52.634] iteration 27469 : model1 loss : 0.442813 model2 loss : 0.020891
[12:17:52.805] iteration 27470 : model1 loss : 0.441151 model2 loss : 0.019978
[12:17:52.973] iteration 27471 : model1 loss : 0.441543 model2 loss : 0.019415
[12:17:53.141] iteration 27472 : model1 loss : 0.442631 model2 loss : 0.021185
[12:17:53.309] iteration 27473 : model1 loss : 0.434879 model2 loss : 0.017962
[12:17:53.477] iteration 27474 : model1 loss : 0.435913 model2 loss : 0.017988
[12:17:53.647] iteration 27475 : model1 loss : 0.438300 model2 loss : 0.017910
[12:17:53.814] iteration 27476 : model1 loss : 0.439715 model2 loss : 0.018695
[12:17:53.984] iteration 27477 : model1 loss : 0.439964 model2 loss : 0.018588
[12:17:54.150] iteration 27478 : model1 loss : 0.437526 model2 loss : 0.018400
[12:17:54.321] iteration 27479 : model1 loss : 0.439736 model2 loss : 0.018992
[12:17:54.488] iteration 27480 : model1 loss : 0.439099 model2 loss : 0.020448
[12:17:54.655] iteration 27481 : model1 loss : 0.440294 model2 loss : 0.019946
[12:17:54.822] iteration 27482 : model1 loss : 0.444214 model2 loss : 0.018638
[12:17:54.992] iteration 27483 : model1 loss : 0.443911 model2 loss : 0.019232
[12:17:55.160] iteration 27484 : model1 loss : 0.438718 model2 loss : 0.019067
[12:17:55.328] iteration 27485 : model1 loss : 0.441298 model2 loss : 0.018129
[12:17:55.496] iteration 27486 : model1 loss : 0.440858 model2 loss : 0.019029
[12:17:55.664] iteration 27487 : model1 loss : 0.441726 model2 loss : 0.018714
[12:17:55.828] iteration 27488 : model1 loss : 0.441905 model2 loss : 0.020910
[12:17:55.997] iteration 27489 : model1 loss : 0.440910 model2 loss : 0.019599
[12:17:57.867] iteration 27490 : model1 loss : 0.443955 model2 loss : 0.020115
[12:17:58.033] iteration 27491 : model1 loss : 0.437976 model2 loss : 0.015424
[12:17:58.204] iteration 27492 : model1 loss : 0.437541 model2 loss : 0.017509
[12:17:58.370] iteration 27493 : model1 loss : 0.437304 model2 loss : 0.018272
[12:17:58.541] iteration 27494 : model1 loss : 0.438733 model2 loss : 0.019576
[12:17:58.707] iteration 27495 : model1 loss : 0.439632 model2 loss : 0.018572
[12:17:58.877] iteration 27496 : model1 loss : 0.438538 model2 loss : 0.020559
[12:17:59.044] iteration 27497 : model1 loss : 0.440641 model2 loss : 0.018532
[12:17:59.214] iteration 27498 : model1 loss : 0.437577 model2 loss : 0.017546
[12:17:59.380] iteration 27499 : model1 loss : 0.442883 model2 loss : 0.020589
[12:17:59.550] iteration 27500 : model1 loss : 0.442060 model2 loss : 0.018257
[12:17:59.716] iteration 27501 : model1 loss : 0.440725 model2 loss : 0.016465
[12:17:59.885] iteration 27502 : model1 loss : 0.443242 model2 loss : 0.018707
[12:18:00.054] iteration 27503 : model1 loss : 0.439133 model2 loss : 0.017984
[12:18:00.223] iteration 27504 : model1 loss : 0.438596 model2 loss : 0.019230
[12:18:00.390] iteration 27505 : model1 loss : 0.440421 model2 loss : 0.020610
[12:18:00.561] iteration 27506 : model1 loss : 0.438842 model2 loss : 0.018821
[12:18:00.729] iteration 27507 : model1 loss : 0.437070 model2 loss : 0.019885
[12:18:00.901] iteration 27508 : model1 loss : 0.443335 model2 loss : 0.019792
[12:18:01.071] iteration 27509 : model1 loss : 0.441593 model2 loss : 0.022143
[12:18:01.240] iteration 27510 : model1 loss : 0.445481 model2 loss : 0.021182
[12:18:01.407] iteration 27511 : model1 loss : 0.441881 model2 loss : 0.019322
[12:18:01.576] iteration 27512 : model1 loss : 0.437365 model2 loss : 0.019058
[12:18:01.743] iteration 27513 : model1 loss : 0.440594 model2 loss : 0.018078
[12:18:01.912] iteration 27514 : model1 loss : 0.435780 model2 loss : 0.018377
[12:18:02.079] iteration 27515 : model1 loss : 0.440682 model2 loss : 0.018561
[12:18:02.247] iteration 27516 : model1 loss : 0.438759 model2 loss : 0.016837
[12:18:02.414] iteration 27517 : model1 loss : 0.445040 model2 loss : 0.018999
[12:18:02.584] iteration 27518 : model1 loss : 0.441011 model2 loss : 0.020759
[12:18:02.750] iteration 27519 : model1 loss : 0.440440 model2 loss : 0.019150
[12:18:02.921] iteration 27520 : model1 loss : 0.437674 model2 loss : 0.019917
[12:18:03.086] iteration 27521 : model1 loss : 0.440710 model2 loss : 0.020118
[12:18:03.253] iteration 27522 : model1 loss : 0.438941 model2 loss : 0.018684
[12:18:05.182] iteration 27523 : model1 loss : 0.438100 model2 loss : 0.018918
[12:18:05.357] iteration 27524 : model1 loss : 0.434642 model2 loss : 0.018372
[12:18:05.528] iteration 27525 : model1 loss : 0.439466 model2 loss : 0.017281
[12:18:05.695] iteration 27526 : model1 loss : 0.434307 model2 loss : 0.018384
[12:18:05.864] iteration 27527 : model1 loss : 0.441610 model2 loss : 0.019375
[12:18:06.034] iteration 27528 : model1 loss : 0.442600 model2 loss : 0.019831
[12:18:06.201] iteration 27529 : model1 loss : 0.440965 model2 loss : 0.018823
[12:18:06.369] iteration 27530 : model1 loss : 0.441321 model2 loss : 0.022160
[12:18:06.542] iteration 27531 : model1 loss : 0.440288 model2 loss : 0.018144
[12:18:06.709] iteration 27532 : model1 loss : 0.437444 model2 loss : 0.018023
[12:18:06.878] iteration 27533 : model1 loss : 0.436266 model2 loss : 0.016580
[12:18:07.049] iteration 27534 : model1 loss : 0.440429 model2 loss : 0.019072
[12:18:07.216] iteration 27535 : model1 loss : 0.440648 model2 loss : 0.018322
[12:18:07.382] iteration 27536 : model1 loss : 0.447249 model2 loss : 0.019870
[12:18:07.552] iteration 27537 : model1 loss : 0.441835 model2 loss : 0.020135
[12:18:07.721] iteration 27538 : model1 loss : 0.444393 model2 loss : 0.020813
[12:18:07.891] iteration 27539 : model1 loss : 0.439534 model2 loss : 0.019325
[12:18:08.062] iteration 27540 : model1 loss : 0.440824 model2 loss : 0.019749
[12:18:08.230] iteration 27541 : model1 loss : 0.439027 model2 loss : 0.017296
[12:18:08.395] iteration 27542 : model1 loss : 0.434530 model2 loss : 0.017298
[12:18:08.564] iteration 27543 : model1 loss : 0.441312 model2 loss : 0.018671
[12:18:08.731] iteration 27544 : model1 loss : 0.442406 model2 loss : 0.019829
[12:18:08.899] iteration 27545 : model1 loss : 0.441990 model2 loss : 0.020552
[12:18:09.069] iteration 27546 : model1 loss : 0.440648 model2 loss : 0.019189
[12:18:09.239] iteration 27547 : model1 loss : 0.440132 model2 loss : 0.019674
[12:18:09.405] iteration 27548 : model1 loss : 0.444185 model2 loss : 0.018887
[12:18:09.575] iteration 27549 : model1 loss : 0.440034 model2 loss : 0.018975
[12:18:09.741] iteration 27550 : model1 loss : 0.442115 model2 loss : 0.021417
[12:18:09.910] iteration 27551 : model1 loss : 0.439547 model2 loss : 0.019795
[12:18:10.078] iteration 27552 : model1 loss : 0.436409 model2 loss : 0.017906
[12:18:10.246] iteration 27553 : model1 loss : 0.437314 model2 loss : 0.018167
[12:18:10.414] iteration 27554 : model1 loss : 0.440232 model2 loss : 0.019817
[12:18:10.582] iteration 27555 : model1 loss : 0.440618 model2 loss : 0.018435
[12:18:12.519] iteration 27556 : model1 loss : 0.443188 model2 loss : 0.020334
[12:18:12.686] iteration 27557 : model1 loss : 0.438851 model2 loss : 0.017580
[12:18:12.856] iteration 27558 : model1 loss : 0.440984 model2 loss : 0.020375
[12:18:13.025] iteration 27559 : model1 loss : 0.437727 model2 loss : 0.018798
[12:18:13.195] iteration 27560 : model1 loss : 0.436935 model2 loss : 0.016865
[12:18:13.362] iteration 27561 : model1 loss : 0.439968 model2 loss : 0.020485
[12:18:13.532] iteration 27562 : model1 loss : 0.441282 model2 loss : 0.020339
[12:18:13.699] iteration 27563 : model1 loss : 0.442488 model2 loss : 0.020670
[12:18:13.869] iteration 27564 : model1 loss : 0.438849 model2 loss : 0.019228
[12:18:14.037] iteration 27565 : model1 loss : 0.436355 model2 loss : 0.017447
[12:18:14.206] iteration 27566 : model1 loss : 0.441022 model2 loss : 0.019280
[12:18:14.373] iteration 27567 : model1 loss : 0.437539 model2 loss : 0.018872
[12:18:14.543] iteration 27568 : model1 loss : 0.438706 model2 loss : 0.018760
[12:18:14.710] iteration 27569 : model1 loss : 0.439818 model2 loss : 0.019196
[12:18:14.881] iteration 27570 : model1 loss : 0.439116 model2 loss : 0.019893
[12:18:15.049] iteration 27571 : model1 loss : 0.438500 model2 loss : 0.016527
[12:18:15.220] iteration 27572 : model1 loss : 0.435403 model2 loss : 0.017939
[12:18:15.386] iteration 27573 : model1 loss : 0.440820 model2 loss : 0.019084
[12:18:15.557] iteration 27574 : model1 loss : 0.440363 model2 loss : 0.019377
[12:18:15.725] iteration 27575 : model1 loss : 0.434735 model2 loss : 0.018413
[12:18:15.897] iteration 27576 : model1 loss : 0.440156 model2 loss : 0.019326
[12:18:16.063] iteration 27577 : model1 loss : 0.439342 model2 loss : 0.017197
[12:18:16.232] iteration 27578 : model1 loss : 0.439820 model2 loss : 0.018153
[12:18:16.398] iteration 27579 : model1 loss : 0.438981 model2 loss : 0.019205
[12:18:16.568] iteration 27580 : model1 loss : 0.442196 model2 loss : 0.017775
[12:18:16.735] iteration 27581 : model1 loss : 0.439185 model2 loss : 0.015617
[12:18:16.904] iteration 27582 : model1 loss : 0.438297 model2 loss : 0.019955
[12:18:17.073] iteration 27583 : model1 loss : 0.444145 model2 loss : 0.019465
[12:18:17.242] iteration 27584 : model1 loss : 0.443521 model2 loss : 0.021517
[12:18:17.410] iteration 27585 : model1 loss : 0.443903 model2 loss : 0.017544
[12:18:17.579] iteration 27586 : model1 loss : 0.440899 model2 loss : 0.018360
[12:18:17.744] iteration 27587 : model1 loss : 0.440946 model2 loss : 0.017142
[12:18:17.914] iteration 27588 : model1 loss : 0.444081 model2 loss : 0.023269
[12:18:19.831] iteration 27589 : model1 loss : 0.440072 model2 loss : 0.017605
[12:18:19.996] iteration 27590 : model1 loss : 0.436274 model2 loss : 0.019057
[12:18:20.167] iteration 27591 : model1 loss : 0.443842 model2 loss : 0.023438
[12:18:20.334] iteration 27592 : model1 loss : 0.438663 model2 loss : 0.018671
[12:18:20.504] iteration 27593 : model1 loss : 0.440486 model2 loss : 0.019786
[12:18:20.671] iteration 27594 : model1 loss : 0.439958 model2 loss : 0.017102
[12:18:20.842] iteration 27595 : model1 loss : 0.437086 model2 loss : 0.019625
[12:18:21.011] iteration 27596 : model1 loss : 0.443231 model2 loss : 0.018526
[12:18:21.181] iteration 27597 : model1 loss : 0.437150 model2 loss : 0.018317
[12:18:21.347] iteration 27598 : model1 loss : 0.440930 model2 loss : 0.017784
[12:18:21.518] iteration 27599 : model1 loss : 0.441236 model2 loss : 0.019583
[12:18:21.683] iteration 27600 : model1 loss : 0.445944 model2 loss : 0.019443
[12:18:21.854] iteration 27601 : model1 loss : 0.443039 model2 loss : 0.019175
[12:18:22.022] iteration 27602 : model1 loss : 0.439060 model2 loss : 0.017036
[12:18:22.190] iteration 27603 : model1 loss : 0.440326 model2 loss : 0.019846
[12:18:22.357] iteration 27604 : model1 loss : 0.438418 model2 loss : 0.019595
[12:18:22.529] iteration 27605 : model1 loss : 0.439047 model2 loss : 0.017931
[12:18:22.697] iteration 27606 : model1 loss : 0.442169 model2 loss : 0.019408
[12:18:22.865] iteration 27607 : model1 loss : 0.433896 model2 loss : 0.017924
[12:18:23.035] iteration 27608 : model1 loss : 0.440094 model2 loss : 0.018024
[12:18:23.206] iteration 27609 : model1 loss : 0.441233 model2 loss : 0.019637
[12:18:23.373] iteration 27610 : model1 loss : 0.438555 model2 loss : 0.019529
[12:18:23.544] iteration 27611 : model1 loss : 0.439188 model2 loss : 0.017651
[12:18:23.710] iteration 27612 : model1 loss : 0.438848 model2 loss : 0.017862
[12:18:23.879] iteration 27613 : model1 loss : 0.440129 model2 loss : 0.019634
[12:18:24.049] iteration 27614 : model1 loss : 0.438224 model2 loss : 0.017902
[12:18:24.219] iteration 27615 : model1 loss : 0.440502 model2 loss : 0.020173
[12:18:24.388] iteration 27616 : model1 loss : 0.440158 model2 loss : 0.020738
[12:18:24.558] iteration 27617 : model1 loss : 0.441245 model2 loss : 0.019515
[12:18:24.723] iteration 27618 : model1 loss : 0.439291 model2 loss : 0.018893
[12:18:24.894] iteration 27619 : model1 loss : 0.440339 model2 loss : 0.016783
[12:18:25.063] iteration 27620 : model1 loss : 0.442423 model2 loss : 0.019158
[12:18:25.231] iteration 27621 : model1 loss : 0.440143 model2 loss : 0.019462
[12:18:27.171] iteration 27622 : model1 loss : 0.440868 model2 loss : 0.019693
[12:18:27.340] iteration 27623 : model1 loss : 0.443527 model2 loss : 0.019885
[12:18:27.513] iteration 27624 : model1 loss : 0.442157 model2 loss : 0.019746
[12:18:27.681] iteration 27625 : model1 loss : 0.442635 model2 loss : 0.018769
[12:18:27.852] iteration 27626 : model1 loss : 0.440442 model2 loss : 0.018599
[12:18:28.020] iteration 27627 : model1 loss : 0.440474 model2 loss : 0.018614
[12:18:28.189] iteration 27628 : model1 loss : 0.439191 model2 loss : 0.019430
[12:18:28.356] iteration 27629 : model1 loss : 0.436090 model2 loss : 0.017258
[12:18:28.527] iteration 27630 : model1 loss : 0.438784 model2 loss : 0.018426
[12:18:28.693] iteration 27631 : model1 loss : 0.439942 model2 loss : 0.018853
[12:18:28.862] iteration 27632 : model1 loss : 0.444569 model2 loss : 0.021074
[12:18:29.030] iteration 27633 : model1 loss : 0.434188 model2 loss : 0.017013
[12:18:29.199] iteration 27634 : model1 loss : 0.439776 model2 loss : 0.017477
[12:18:29.367] iteration 27635 : model1 loss : 0.445038 model2 loss : 0.022512
[12:18:29.538] iteration 27636 : model1 loss : 0.439017 model2 loss : 0.018520
[12:18:29.705] iteration 27637 : model1 loss : 0.437882 model2 loss : 0.017149
[12:18:29.875] iteration 27638 : model1 loss : 0.442508 model2 loss : 0.019816
[12:18:30.043] iteration 27639 : model1 loss : 0.440083 model2 loss : 0.018516
[12:18:30.212] iteration 27640 : model1 loss : 0.437874 model2 loss : 0.015745
[12:18:30.379] iteration 27641 : model1 loss : 0.440485 model2 loss : 0.020795
[12:18:30.550] iteration 27642 : model1 loss : 0.437717 model2 loss : 0.019926
[12:18:30.717] iteration 27643 : model1 loss : 0.437419 model2 loss : 0.018990
[12:18:30.891] iteration 27644 : model1 loss : 0.443414 model2 loss : 0.019811
[12:18:31.064] iteration 27645 : model1 loss : 0.440889 model2 loss : 0.020031
[12:18:31.232] iteration 27646 : model1 loss : 0.441734 model2 loss : 0.017045
[12:18:31.399] iteration 27647 : model1 loss : 0.440471 model2 loss : 0.017657
[12:18:31.570] iteration 27648 : model1 loss : 0.438964 model2 loss : 0.019049
[12:18:31.737] iteration 27649 : model1 loss : 0.445053 model2 loss : 0.021772
[12:18:31.906] iteration 27650 : model1 loss : 0.435346 model2 loss : 0.018032
[12:18:32.076] iteration 27651 : model1 loss : 0.439642 model2 loss : 0.019106
[12:18:32.247] iteration 27652 : model1 loss : 0.435988 model2 loss : 0.019360
[12:18:32.412] iteration 27653 : model1 loss : 0.439116 model2 loss : 0.019547
[12:18:32.580] iteration 27654 : model1 loss : 0.440454 model2 loss : 0.020326
[12:18:34.476] iteration 27655 : model1 loss : 0.437915 model2 loss : 0.018283
[12:18:34.644] iteration 27656 : model1 loss : 0.438427 model2 loss : 0.016890
[12:18:34.815] iteration 27657 : model1 loss : 0.444584 model2 loss : 0.018804
[12:18:34.982] iteration 27658 : model1 loss : 0.439068 model2 loss : 0.018005
[12:18:35.151] iteration 27659 : model1 loss : 0.437967 model2 loss : 0.018889
[12:18:35.318] iteration 27660 : model1 loss : 0.441162 model2 loss : 0.019191
[12:18:35.488] iteration 27661 : model1 loss : 0.441164 model2 loss : 0.019549
[12:18:35.657] iteration 27662 : model1 loss : 0.441351 model2 loss : 0.021615
[12:18:35.828] iteration 27663 : model1 loss : 0.442142 model2 loss : 0.020121
[12:18:35.998] iteration 27664 : model1 loss : 0.438966 model2 loss : 0.021054
[12:18:36.166] iteration 27665 : model1 loss : 0.446512 model2 loss : 0.019130
[12:18:36.333] iteration 27666 : model1 loss : 0.441349 model2 loss : 0.019678
[12:18:36.504] iteration 27667 : model1 loss : 0.439506 model2 loss : 0.019320
[12:18:36.672] iteration 27668 : model1 loss : 0.440905 model2 loss : 0.018807
[12:18:36.842] iteration 27669 : model1 loss : 0.438040 model2 loss : 0.017797
[12:18:37.012] iteration 27670 : model1 loss : 0.439439 model2 loss : 0.017820
[12:18:37.183] iteration 27671 : model1 loss : 0.438910 model2 loss : 0.018202
[12:18:37.350] iteration 27672 : model1 loss : 0.439877 model2 loss : 0.019898
[12:18:37.523] iteration 27673 : model1 loss : 0.442173 model2 loss : 0.020274
[12:18:37.689] iteration 27674 : model1 loss : 0.441262 model2 loss : 0.021701
[12:18:37.861] iteration 27675 : model1 loss : 0.438257 model2 loss : 0.018718
[12:18:38.030] iteration 27676 : model1 loss : 0.441224 model2 loss : 0.020629
[12:18:38.198] iteration 27677 : model1 loss : 0.434011 model2 loss : 0.020039
[12:18:38.366] iteration 27678 : model1 loss : 0.436452 model2 loss : 0.017921
[12:18:38.538] iteration 27679 : model1 loss : 0.440776 model2 loss : 0.019491
[12:18:38.705] iteration 27680 : model1 loss : 0.441044 model2 loss : 0.018774
[12:18:38.876] iteration 27681 : model1 loss : 0.439014 model2 loss : 0.020410
[12:18:39.045] iteration 27682 : model1 loss : 0.438442 model2 loss : 0.018201
[12:18:39.215] iteration 27683 : model1 loss : 0.438598 model2 loss : 0.019030
[12:18:39.382] iteration 27684 : model1 loss : 0.439083 model2 loss : 0.019011
[12:18:39.553] iteration 27685 : model1 loss : 0.444468 model2 loss : 0.018133
[12:18:39.718] iteration 27686 : model1 loss : 0.443467 model2 loss : 0.017620
[12:18:39.888] iteration 27687 : model1 loss : 0.440035 model2 loss : 0.019580
[12:18:41.838] iteration 27688 : model1 loss : 0.445138 model2 loss : 0.019063
[12:18:42.009] iteration 27689 : model1 loss : 0.439997 model2 loss : 0.018926
[12:18:42.178] iteration 27690 : model1 loss : 0.439085 model2 loss : 0.017706
[12:18:42.344] iteration 27691 : model1 loss : 0.437857 model2 loss : 0.018277
[12:18:42.518] iteration 27692 : model1 loss : 0.442490 model2 loss : 0.019567
[12:18:42.686] iteration 27693 : model1 loss : 0.442450 model2 loss : 0.018822
[12:18:42.858] iteration 27694 : model1 loss : 0.443885 model2 loss : 0.018558
[12:18:43.028] iteration 27695 : model1 loss : 0.437906 model2 loss : 0.020442
[12:18:43.199] iteration 27696 : model1 loss : 0.437423 model2 loss : 0.018128
[12:18:43.366] iteration 27697 : model1 loss : 0.435155 model2 loss : 0.018309
[12:18:43.537] iteration 27698 : model1 loss : 0.440032 model2 loss : 0.016721
[12:18:43.705] iteration 27699 : model1 loss : 0.438855 model2 loss : 0.018941
[12:18:43.877] iteration 27700 : model1 loss : 0.438244 model2 loss : 0.018142
[12:18:44.046] iteration 27701 : model1 loss : 0.442140 model2 loss : 0.019214
[12:18:44.215] iteration 27702 : model1 loss : 0.444125 model2 loss : 0.020985
[12:18:44.384] iteration 27703 : model1 loss : 0.441422 model2 loss : 0.019644
[12:18:44.555] iteration 27704 : model1 loss : 0.444761 model2 loss : 0.020242
[12:18:44.724] iteration 27705 : model1 loss : 0.439808 model2 loss : 0.020851
[12:18:44.896] iteration 27706 : model1 loss : 0.440039 model2 loss : 0.017711
[12:18:45.064] iteration 27707 : model1 loss : 0.443298 model2 loss : 0.022260
[12:18:45.234] iteration 27708 : model1 loss : 0.437407 model2 loss : 0.020529
[12:18:45.401] iteration 27709 : model1 loss : 0.438525 model2 loss : 0.019290
[12:18:45.569] iteration 27710 : model1 loss : 0.439155 model2 loss : 0.017441
[12:18:45.739] iteration 27711 : model1 loss : 0.437728 model2 loss : 0.017001
[12:18:45.909] iteration 27712 : model1 loss : 0.443300 model2 loss : 0.018819
[12:18:46.080] iteration 27713 : model1 loss : 0.442094 model2 loss : 0.018937
[12:18:46.249] iteration 27714 : model1 loss : 0.438635 model2 loss : 0.018425
[12:18:46.418] iteration 27715 : model1 loss : 0.441639 model2 loss : 0.019223
[12:18:46.590] iteration 27716 : model1 loss : 0.437464 model2 loss : 0.017934
[12:18:46.758] iteration 27717 : model1 loss : 0.438017 model2 loss : 0.017591
[12:18:46.928] iteration 27718 : model1 loss : 0.437142 model2 loss : 0.018856
[12:18:47.096] iteration 27719 : model1 loss : 0.435511 model2 loss : 0.019907
[12:18:47.264] iteration 27720 : model1 loss : 0.442942 model2 loss : 0.018883
[12:18:49.205] iteration 27721 : model1 loss : 0.437820 model2 loss : 0.017890
[12:18:49.377] iteration 27722 : model1 loss : 0.438956 model2 loss : 0.018305
[12:18:49.550] iteration 27723 : model1 loss : 0.442859 model2 loss : 0.019485
[12:18:49.717] iteration 27724 : model1 loss : 0.443231 model2 loss : 0.020348
[12:18:49.889] iteration 27725 : model1 loss : 0.439696 model2 loss : 0.018216
[12:18:50.059] iteration 27726 : model1 loss : 0.433706 model2 loss : 0.017713
[12:18:50.227] iteration 27727 : model1 loss : 0.440675 model2 loss : 0.017836
[12:18:50.395] iteration 27728 : model1 loss : 0.439683 model2 loss : 0.018140
[12:18:50.577] iteration 27729 : model1 loss : 0.438222 model2 loss : 0.017898
[12:18:50.743] iteration 27730 : model1 loss : 0.438978 model2 loss : 0.020010
[12:18:50.912] iteration 27731 : model1 loss : 0.435594 model2 loss : 0.019495
[12:18:51.079] iteration 27732 : model1 loss : 0.445125 model2 loss : 0.022663
[12:18:51.247] iteration 27733 : model1 loss : 0.443210 model2 loss : 0.017274
[12:18:51.414] iteration 27734 : model1 loss : 0.441445 model2 loss : 0.018893
[12:18:51.583] iteration 27735 : model1 loss : 0.444492 model2 loss : 0.020292
[12:18:51.752] iteration 27736 : model1 loss : 0.445704 model2 loss : 0.018803
[12:18:51.920] iteration 27737 : model1 loss : 0.437415 model2 loss : 0.018606
[12:18:52.087] iteration 27738 : model1 loss : 0.440380 model2 loss : 0.020328
[12:18:52.268] iteration 27739 : model1 loss : 0.437348 model2 loss : 0.019853
[12:18:52.437] iteration 27740 : model1 loss : 0.443301 model2 loss : 0.021864
[12:18:52.607] iteration 27741 : model1 loss : 0.441442 model2 loss : 0.020077
[12:18:52.774] iteration 27742 : model1 loss : 0.439825 model2 loss : 0.018740
[12:18:52.943] iteration 27743 : model1 loss : 0.437780 model2 loss : 0.019094
[12:18:53.114] iteration 27744 : model1 loss : 0.438225 model2 loss : 0.017758
[12:18:53.284] iteration 27745 : model1 loss : 0.436211 model2 loss : 0.016764
[12:18:53.451] iteration 27746 : model1 loss : 0.444500 model2 loss : 0.020183
[12:18:53.620] iteration 27747 : model1 loss : 0.438117 model2 loss : 0.019121
[12:18:53.787] iteration 27748 : model1 loss : 0.438072 model2 loss : 0.020003
[12:18:53.957] iteration 27749 : model1 loss : 0.442431 model2 loss : 0.019783
[12:18:54.126] iteration 27750 : model1 loss : 0.436132 model2 loss : 0.018857
[12:18:54.295] iteration 27751 : model1 loss : 0.440248 model2 loss : 0.020201
[12:18:54.460] iteration 27752 : model1 loss : 0.441108 model2 loss : 0.017715
[12:18:54.629] iteration 27753 : model1 loss : 0.440015 model2 loss : 0.017751
[12:18:56.561] iteration 27754 : model1 loss : 0.436537 model2 loss : 0.018355
[12:18:56.727] iteration 27755 : model1 loss : 0.442768 model2 loss : 0.019429
[12:18:56.896] iteration 27756 : model1 loss : 0.437678 model2 loss : 0.018601
[12:18:57.062] iteration 27757 : model1 loss : 0.444339 model2 loss : 0.021685
[12:18:57.235] iteration 27758 : model1 loss : 0.438381 model2 loss : 0.019232
[12:18:57.402] iteration 27759 : model1 loss : 0.437747 model2 loss : 0.018462
[12:18:57.572] iteration 27760 : model1 loss : 0.442885 model2 loss : 0.019185
[12:18:57.740] iteration 27761 : model1 loss : 0.439695 model2 loss : 0.018901
[12:18:57.910] iteration 27762 : model1 loss : 0.438068 model2 loss : 0.019115
[12:18:58.081] iteration 27763 : model1 loss : 0.442719 model2 loss : 0.017923
[12:18:58.249] iteration 27764 : model1 loss : 0.444888 model2 loss : 0.022818
[12:18:58.417] iteration 27765 : model1 loss : 0.439440 model2 loss : 0.016260
[12:18:58.586] iteration 27766 : model1 loss : 0.441123 model2 loss : 0.018280
[12:18:58.752] iteration 27767 : model1 loss : 0.440265 model2 loss : 0.018362
[12:18:58.922] iteration 27768 : model1 loss : 0.441620 model2 loss : 0.021556
[12:18:59.090] iteration 27769 : model1 loss : 0.436896 model2 loss : 0.018365
[12:18:59.261] iteration 27770 : model1 loss : 0.437724 model2 loss : 0.019556
[12:18:59.430] iteration 27771 : model1 loss : 0.445164 model2 loss : 0.021040
[12:18:59.599] iteration 27772 : model1 loss : 0.441498 model2 loss : 0.019487
[12:18:59.766] iteration 27773 : model1 loss : 0.441307 model2 loss : 0.020761
[12:18:59.936] iteration 27774 : model1 loss : 0.439692 model2 loss : 0.019396
[12:19:00.105] iteration 27775 : model1 loss : 0.436395 model2 loss : 0.017965
[12:19:00.274] iteration 27776 : model1 loss : 0.438553 model2 loss : 0.019344
[12:19:00.442] iteration 27777 : model1 loss : 0.442379 model2 loss : 0.018282
[12:19:00.616] iteration 27778 : model1 loss : 0.439686 model2 loss : 0.017723
[12:19:00.784] iteration 27779 : model1 loss : 0.442599 model2 loss : 0.021582
[12:19:00.959] iteration 27780 : model1 loss : 0.441147 model2 loss : 0.020167
[12:19:01.131] iteration 27781 : model1 loss : 0.432666 model2 loss : 0.017599
[12:19:01.302] iteration 27782 : model1 loss : 0.441875 model2 loss : 0.020516
[12:19:01.469] iteration 27783 : model1 loss : 0.440186 model2 loss : 0.018671
[12:19:01.638] iteration 27784 : model1 loss : 0.439271 model2 loss : 0.019758
[12:19:01.804] iteration 27785 : model1 loss : 0.439665 model2 loss : 0.019254
[12:19:01.972] iteration 27786 : model1 loss : 0.439822 model2 loss : 0.021348
[12:19:03.923] iteration 27787 : model1 loss : 0.444400 model2 loss : 0.019014
[12:19:04.092] iteration 27788 : model1 loss : 0.436551 model2 loss : 0.016157
[12:19:04.262] iteration 27789 : model1 loss : 0.439222 model2 loss : 0.020933
[12:19:04.429] iteration 27790 : model1 loss : 0.437831 model2 loss : 0.019108
[12:19:04.598] iteration 27791 : model1 loss : 0.439180 model2 loss : 0.018143
[12:19:04.765] iteration 27792 : model1 loss : 0.441434 model2 loss : 0.019269
[12:19:04.936] iteration 27793 : model1 loss : 0.439134 model2 loss : 0.018191
[12:19:05.103] iteration 27794 : model1 loss : 0.441847 model2 loss : 0.021565
[12:19:05.272] iteration 27795 : model1 loss : 0.445355 model2 loss : 0.022320
[12:19:05.439] iteration 27796 : model1 loss : 0.440775 model2 loss : 0.017934
[12:19:05.607] iteration 27797 : model1 loss : 0.441252 model2 loss : 0.018483
[12:19:05.775] iteration 27798 : model1 loss : 0.442712 model2 loss : 0.017732
[12:19:05.949] iteration 27799 : model1 loss : 0.435453 model2 loss : 0.019156
[12:19:06.117] iteration 27800 : model1 loss : 0.438701 model2 loss : 0.020083
[12:19:06.286] iteration 27801 : model1 loss : 0.438220 model2 loss : 0.019722
[12:19:06.452] iteration 27802 : model1 loss : 0.441582 model2 loss : 0.019340
[12:19:06.622] iteration 27803 : model1 loss : 0.439999 model2 loss : 0.017220
[12:19:06.788] iteration 27804 : model1 loss : 0.440749 model2 loss : 0.019059
[12:19:06.959] iteration 27805 : model1 loss : 0.439896 model2 loss : 0.019332
[12:19:07.130] iteration 27806 : model1 loss : 0.440603 model2 loss : 0.018355
[12:19:07.298] iteration 27807 : model1 loss : 0.444927 model2 loss : 0.020650
[12:19:07.465] iteration 27808 : model1 loss : 0.440589 model2 loss : 0.018896
[12:19:07.634] iteration 27809 : model1 loss : 0.435773 model2 loss : 0.018409
[12:19:07.801] iteration 27810 : model1 loss : 0.437970 model2 loss : 0.019088
[12:19:07.970] iteration 27811 : model1 loss : 0.441457 model2 loss : 0.016757
[12:19:08.142] iteration 27812 : model1 loss : 0.441087 model2 loss : 0.019018
[12:19:08.312] iteration 27813 : model1 loss : 0.443185 model2 loss : 0.019502
[12:19:08.479] iteration 27814 : model1 loss : 0.435144 model2 loss : 0.019657
[12:19:08.649] iteration 27815 : model1 loss : 0.440505 model2 loss : 0.018149
[12:19:08.816] iteration 27816 : model1 loss : 0.442795 model2 loss : 0.020012
[12:19:08.984] iteration 27817 : model1 loss : 0.437943 model2 loss : 0.018345
[12:19:09.153] iteration 27818 : model1 loss : 0.441289 model2 loss : 0.020552
[12:19:09.322] iteration 27819 : model1 loss : 0.439130 model2 loss : 0.020339
[12:19:11.293] iteration 27820 : model1 loss : 0.439386 model2 loss : 0.018710
[12:19:11.459] iteration 27821 : model1 loss : 0.439976 model2 loss : 0.017423
[12:19:11.629] iteration 27822 : model1 loss : 0.438428 model2 loss : 0.017757
[12:19:11.796] iteration 27823 : model1 loss : 0.441222 model2 loss : 0.019396
[12:19:11.966] iteration 27824 : model1 loss : 0.439318 model2 loss : 0.017483
[12:19:12.135] iteration 27825 : model1 loss : 0.440175 model2 loss : 0.018408
[12:19:12.304] iteration 27826 : model1 loss : 0.443166 model2 loss : 0.020135
[12:19:12.470] iteration 27827 : model1 loss : 0.436399 model2 loss : 0.017357
[12:19:12.639] iteration 27828 : model1 loss : 0.441513 model2 loss : 0.016339
[12:19:12.807] iteration 27829 : model1 loss : 0.439869 model2 loss : 0.018254
[12:19:12.980] iteration 27830 : model1 loss : 0.441448 model2 loss : 0.017773
[12:19:13.150] iteration 27831 : model1 loss : 0.435861 model2 loss : 0.017332
[12:19:13.327] iteration 27832 : model1 loss : 0.443349 model2 loss : 0.018581
[12:19:13.497] iteration 27833 : model1 loss : 0.443586 model2 loss : 0.020431
[12:19:13.667] iteration 27834 : model1 loss : 0.436336 model2 loss : 0.019261
[12:19:13.836] iteration 27835 : model1 loss : 0.439279 model2 loss : 0.019674
[12:19:14.006] iteration 27836 : model1 loss : 0.444315 model2 loss : 0.017639
[12:19:14.178] iteration 27837 : model1 loss : 0.437895 model2 loss : 0.019117
[12:19:14.348] iteration 27838 : model1 loss : 0.444244 model2 loss : 0.019971
[12:19:14.516] iteration 27839 : model1 loss : 0.440139 model2 loss : 0.020662
[12:19:14.685] iteration 27840 : model1 loss : 0.440267 model2 loss : 0.019659
[12:19:14.853] iteration 27841 : model1 loss : 0.439981 model2 loss : 0.019037
[12:19:15.022] iteration 27842 : model1 loss : 0.440724 model2 loss : 0.020375
[12:19:15.198] iteration 27843 : model1 loss : 0.441917 model2 loss : 0.019011
[12:19:15.366] iteration 27844 : model1 loss : 0.438893 model2 loss : 0.017891
[12:19:15.536] iteration 27845 : model1 loss : 0.444950 model2 loss : 0.021058
[12:19:15.704] iteration 27846 : model1 loss : 0.438821 model2 loss : 0.019499
[12:19:15.871] iteration 27847 : model1 loss : 0.434431 model2 loss : 0.017558
[12:19:16.041] iteration 27848 : model1 loss : 0.441472 model2 loss : 0.018442
[12:19:16.207] iteration 27849 : model1 loss : 0.442223 model2 loss : 0.020327
[12:19:16.377] iteration 27850 : model1 loss : 0.437314 model2 loss : 0.017735
[12:19:16.541] iteration 27851 : model1 loss : 0.440858 model2 loss : 0.020072
[12:19:16.709] iteration 27852 : model1 loss : 0.439606 model2 loss : 0.019552
[12:19:18.623] iteration 27853 : model1 loss : 0.439664 model2 loss : 0.017529
[12:19:18.793] iteration 27854 : model1 loss : 0.439886 model2 loss : 0.022364
[12:19:18.963] iteration 27855 : model1 loss : 0.440193 model2 loss : 0.019058
[12:19:19.132] iteration 27856 : model1 loss : 0.441612 model2 loss : 0.018848
[12:19:19.300] iteration 27857 : model1 loss : 0.441371 model2 loss : 0.019085
[12:19:19.466] iteration 27858 : model1 loss : 0.438405 model2 loss : 0.018576
[12:19:19.636] iteration 27859 : model1 loss : 0.442639 model2 loss : 0.020940
[12:19:19.803] iteration 27860 : model1 loss : 0.432659 model2 loss : 0.018819
[12:19:19.998] iteration 27861 : model1 loss : 0.441224 model2 loss : 0.017762
[12:19:20.166] iteration 27862 : model1 loss : 0.441659 model2 loss : 0.017492
[12:19:20.337] iteration 27863 : model1 loss : 0.440598 model2 loss : 0.019541
[12:19:20.504] iteration 27864 : model1 loss : 0.443869 model2 loss : 0.020655
[12:19:20.675] iteration 27865 : model1 loss : 0.435902 model2 loss : 0.019653
[12:19:20.842] iteration 27866 : model1 loss : 0.442862 model2 loss : 0.019318
[12:19:21.012] iteration 27867 : model1 loss : 0.440396 model2 loss : 0.018085
[12:19:21.184] iteration 27868 : model1 loss : 0.440269 model2 loss : 0.018633
[12:19:21.354] iteration 27869 : model1 loss : 0.440579 model2 loss : 0.019469
[12:19:21.522] iteration 27870 : model1 loss : 0.439671 model2 loss : 0.018350
[12:19:21.692] iteration 27871 : model1 loss : 0.441630 model2 loss : 0.018853
[12:19:21.859] iteration 27872 : model1 loss : 0.445206 model2 loss : 0.017901
[12:19:22.030] iteration 27873 : model1 loss : 0.439434 model2 loss : 0.018937
[12:19:22.201] iteration 27874 : model1 loss : 0.437284 model2 loss : 0.017826
[12:19:22.371] iteration 27875 : model1 loss : 0.441475 model2 loss : 0.018299
[12:19:22.544] iteration 27876 : model1 loss : 0.437476 model2 loss : 0.019737
[12:19:22.714] iteration 27877 : model1 loss : 0.440834 model2 loss : 0.019725
[12:19:22.884] iteration 27878 : model1 loss : 0.439118 model2 loss : 0.020917
[12:19:23.053] iteration 27879 : model1 loss : 0.439413 model2 loss : 0.017470
[12:19:23.221] iteration 27880 : model1 loss : 0.437665 model2 loss : 0.017854
[12:19:23.392] iteration 27881 : model1 loss : 0.440778 model2 loss : 0.018070
[12:19:23.560] iteration 27882 : model1 loss : 0.440983 model2 loss : 0.018612
[12:19:23.728] iteration 27883 : model1 loss : 0.438171 model2 loss : 0.017341
[12:19:23.894] iteration 27884 : model1 loss : 0.442371 model2 loss : 0.019103
[12:19:24.070] iteration 27885 : model1 loss : 0.437550 model2 loss : 0.018142
[12:19:26.021] iteration 27886 : model1 loss : 0.446125 model2 loss : 0.022226
[12:19:26.192] iteration 27887 : model1 loss : 0.438451 model2 loss : 0.018161
[12:19:26.362] iteration 27888 : model1 loss : 0.440927 model2 loss : 0.019596
[12:19:26.531] iteration 27889 : model1 loss : 0.444149 model2 loss : 0.022101
[12:19:26.700] iteration 27890 : model1 loss : 0.437315 model2 loss : 0.017901
[12:19:26.867] iteration 27891 : model1 loss : 0.438452 model2 loss : 0.018945
[12:19:27.036] iteration 27892 : model1 loss : 0.439381 model2 loss : 0.016820
[12:19:27.205] iteration 27893 : model1 loss : 0.439668 model2 loss : 0.019313
[12:19:27.376] iteration 27894 : model1 loss : 0.437333 model2 loss : 0.018266
[12:19:27.545] iteration 27895 : model1 loss : 0.438671 model2 loss : 0.017597
[12:19:27.714] iteration 27896 : model1 loss : 0.441729 model2 loss : 0.019421
[12:19:27.880] iteration 27897 : model1 loss : 0.444049 model2 loss : 0.019692
[12:19:28.051] iteration 27898 : model1 loss : 0.440596 model2 loss : 0.016231
[12:19:28.245] iteration 27899 : model1 loss : 0.442765 model2 loss : 0.017148
[12:19:28.413] iteration 27900 : model1 loss : 0.438120 model2 loss : 0.020098
[12:19:28.580] iteration 27901 : model1 loss : 0.443882 model2 loss : 0.018194
[12:19:28.750] iteration 27902 : model1 loss : 0.440386 model2 loss : 0.020268
[12:19:28.917] iteration 27903 : model1 loss : 0.436314 model2 loss : 0.023384
[12:19:29.087] iteration 27904 : model1 loss : 0.441888 model2 loss : 0.019013
[12:19:29.255] iteration 27905 : model1 loss : 0.436448 model2 loss : 0.019979
[12:19:29.426] iteration 27906 : model1 loss : 0.442609 model2 loss : 0.019861
[12:19:29.593] iteration 27907 : model1 loss : 0.437330 model2 loss : 0.018334
[12:19:29.766] iteration 27908 : model1 loss : 0.444138 model2 loss : 0.019647
[12:19:29.935] iteration 27909 : model1 loss : 0.443035 model2 loss : 0.019367
[12:19:30.104] iteration 27910 : model1 loss : 0.437847 model2 loss : 0.019441
[12:19:30.273] iteration 27911 : model1 loss : 0.434686 model2 loss : 0.017841
[12:19:30.443] iteration 27912 : model1 loss : 0.445873 model2 loss : 0.020683
[12:19:30.609] iteration 27913 : model1 loss : 0.442438 model2 loss : 0.019487
[12:19:30.778] iteration 27914 : model1 loss : 0.439723 model2 loss : 0.019888
[12:19:30.950] iteration 27915 : model1 loss : 0.442327 model2 loss : 0.019078
[12:19:31.122] iteration 27916 : model1 loss : 0.437689 model2 loss : 0.017917
[12:19:31.288] iteration 27917 : model1 loss : 0.438226 model2 loss : 0.019148
[12:19:31.454] iteration 27918 : model1 loss : 0.434196 model2 loss : 0.018106
[12:19:33.360] iteration 27919 : model1 loss : 0.442293 model2 loss : 0.019490
[12:19:33.529] iteration 27920 : model1 loss : 0.441472 model2 loss : 0.019800
[12:19:33.701] iteration 27921 : model1 loss : 0.442396 model2 loss : 0.020189
[12:19:33.867] iteration 27922 : model1 loss : 0.444742 model2 loss : 0.020343
[12:19:34.036] iteration 27923 : model1 loss : 0.433529 model2 loss : 0.018776
[12:19:34.207] iteration 27924 : model1 loss : 0.439828 model2 loss : 0.018769
[12:19:34.375] iteration 27925 : model1 loss : 0.440968 model2 loss : 0.018469
[12:19:34.544] iteration 27926 : model1 loss : 0.436820 model2 loss : 0.019057
[12:19:34.713] iteration 27927 : model1 loss : 0.445110 model2 loss : 0.020506
[12:19:34.880] iteration 27928 : model1 loss : 0.442314 model2 loss : 0.020415
[12:19:35.049] iteration 27929 : model1 loss : 0.440117 model2 loss : 0.017406
[12:19:35.222] iteration 27930 : model1 loss : 0.446658 model2 loss : 0.021204
[12:19:35.390] iteration 27931 : model1 loss : 0.439680 model2 loss : 0.018047
[12:19:35.557] iteration 27932 : model1 loss : 0.434393 model2 loss : 0.018613
[12:19:35.727] iteration 27933 : model1 loss : 0.445523 model2 loss : 0.019369
[12:19:35.895] iteration 27934 : model1 loss : 0.441577 model2 loss : 0.018804
[12:19:36.064] iteration 27935 : model1 loss : 0.445118 model2 loss : 0.023871
[12:19:36.237] iteration 27936 : model1 loss : 0.438819 model2 loss : 0.017867
[12:19:36.407] iteration 27937 : model1 loss : 0.440437 model2 loss : 0.018676
[12:19:36.576] iteration 27938 : model1 loss : 0.436328 model2 loss : 0.017993
[12:19:36.747] iteration 27939 : model1 loss : 0.434735 model2 loss : 0.017542
[12:19:36.919] iteration 27940 : model1 loss : 0.442452 model2 loss : 0.020194
[12:19:37.090] iteration 27941 : model1 loss : 0.443684 model2 loss : 0.019800
[12:19:37.257] iteration 27942 : model1 loss : 0.443856 model2 loss : 0.020948
[12:19:37.425] iteration 27943 : model1 loss : 0.440589 model2 loss : 0.019761
[12:19:37.594] iteration 27944 : model1 loss : 0.438146 model2 loss : 0.019710
[12:19:37.762] iteration 27945 : model1 loss : 0.436728 model2 loss : 0.018868
[12:19:37.929] iteration 27946 : model1 loss : 0.436038 model2 loss : 0.017281
[12:19:38.100] iteration 27947 : model1 loss : 0.435814 model2 loss : 0.018595
[12:19:38.268] iteration 27948 : model1 loss : 0.438459 model2 loss : 0.019131
[12:19:38.436] iteration 27949 : model1 loss : 0.439607 model2 loss : 0.020434
[12:19:38.604] iteration 27950 : model1 loss : 0.440696 model2 loss : 0.019236
[12:19:38.772] iteration 27951 : model1 loss : 0.438572 model2 loss : 0.019197
[12:19:40.703] iteration 27952 : model1 loss : 0.437717 model2 loss : 0.020387
[12:19:40.875] iteration 27953 : model1 loss : 0.438120 model2 loss : 0.018450
[12:19:41.047] iteration 27954 : model1 loss : 0.439346 model2 loss : 0.021448
[12:19:41.218] iteration 27955 : model1 loss : 0.440704 model2 loss : 0.016694
[12:19:41.389] iteration 27956 : model1 loss : 0.439711 model2 loss : 0.019264
[12:19:41.558] iteration 27957 : model1 loss : 0.440046 model2 loss : 0.017664
[12:19:41.727] iteration 27958 : model1 loss : 0.438666 model2 loss : 0.018005
[12:19:41.893] iteration 27959 : model1 loss : 0.441241 model2 loss : 0.020621
[12:19:42.064] iteration 27960 : model1 loss : 0.440536 model2 loss : 0.017793
[12:19:42.235] iteration 27961 : model1 loss : 0.439409 model2 loss : 0.019268
[12:19:42.407] iteration 27962 : model1 loss : 0.439849 model2 loss : 0.017665
[12:19:42.572] iteration 27963 : model1 loss : 0.441040 model2 loss : 0.018226
[12:19:42.741] iteration 27964 : model1 loss : 0.439238 model2 loss : 0.019489
[12:19:42.908] iteration 27965 : model1 loss : 0.444728 model2 loss : 0.020556
[12:19:43.080] iteration 27966 : model1 loss : 0.440202 model2 loss : 0.018698
[12:19:43.247] iteration 27967 : model1 loss : 0.435604 model2 loss : 0.019245
[12:19:43.417] iteration 27968 : model1 loss : 0.442005 model2 loss : 0.019217
[12:19:43.584] iteration 27969 : model1 loss : 0.443052 model2 loss : 0.019248
[12:19:43.753] iteration 27970 : model1 loss : 0.444324 model2 loss : 0.021410
[12:19:43.920] iteration 27971 : model1 loss : 0.441944 model2 loss : 0.018040
[12:19:44.089] iteration 27972 : model1 loss : 0.436249 model2 loss : 0.020149
[12:19:44.256] iteration 27973 : model1 loss : 0.436299 model2 loss : 0.018351
[12:19:44.427] iteration 27974 : model1 loss : 0.442997 model2 loss : 0.019921
[12:19:44.597] iteration 27975 : model1 loss : 0.439726 model2 loss : 0.018177
[12:19:44.766] iteration 27976 : model1 loss : 0.441106 model2 loss : 0.017982
[12:19:44.932] iteration 27977 : model1 loss : 0.440239 model2 loss : 0.020534
[12:19:45.101] iteration 27978 : model1 loss : 0.441330 model2 loss : 0.020776
[12:19:45.267] iteration 27979 : model1 loss : 0.436941 model2 loss : 0.019997
[12:19:45.438] iteration 27980 : model1 loss : 0.439039 model2 loss : 0.018364
[12:19:45.606] iteration 27981 : model1 loss : 0.442297 model2 loss : 0.018360
[12:19:45.775] iteration 27982 : model1 loss : 0.442390 model2 loss : 0.018607
[12:19:45.945] iteration 27983 : model1 loss : 0.442747 model2 loss : 0.018182
[12:19:46.115] iteration 27984 : model1 loss : 0.438587 model2 loss : 0.018596
[12:19:48.037] iteration 27985 : model1 loss : 0.442791 model2 loss : 0.016954
[12:19:48.204] iteration 27986 : model1 loss : 0.439720 model2 loss : 0.020426
[12:19:48.374] iteration 27987 : model1 loss : 0.441053 model2 loss : 0.018524
[12:19:48.540] iteration 27988 : model1 loss : 0.442936 model2 loss : 0.021699
[12:19:48.710] iteration 27989 : model1 loss : 0.439557 model2 loss : 0.017117
[12:19:48.877] iteration 27990 : model1 loss : 0.441622 model2 loss : 0.017573
[12:19:49.047] iteration 27991 : model1 loss : 0.438749 model2 loss : 0.019219
[12:19:49.220] iteration 27992 : model1 loss : 0.446394 model2 loss : 0.022682
[12:19:49.395] iteration 27993 : model1 loss : 0.440419 model2 loss : 0.020972
[12:19:49.562] iteration 27994 : model1 loss : 0.442587 model2 loss : 0.022682
[12:19:49.732] iteration 27995 : model1 loss : 0.440037 model2 loss : 0.016802
[12:19:49.899] iteration 27996 : model1 loss : 0.432939 model2 loss : 0.016738
[12:19:50.070] iteration 27997 : model1 loss : 0.443408 model2 loss : 0.020898
[12:19:50.241] iteration 27998 : model1 loss : 0.436292 model2 loss : 0.016549
[12:19:50.410] iteration 27999 : model1 loss : 0.441977 model2 loss : 0.019408
[12:19:50.578] iteration 28000 : model1 loss : 0.440914 model2 loss : 0.018567
[12:19:58.889] iteration 28000 : model1_mean_dice : 0.901085 model1_mean_hd95 : 3.404595
[12:20:07.236] iteration 28000 : model2_mean_dice : 0.899618 model2_mean_hd95 : 2.063269
[12:20:07.409] iteration 28001 : model1 loss : 0.438452 model2 loss : 0.018015
[12:20:07.578] iteration 28002 : model1 loss : 0.436093 model2 loss : 0.018894
[12:20:07.747] iteration 28003 : model1 loss : 0.441738 model2 loss : 0.020121
[12:20:07.916] iteration 28004 : model1 loss : 0.436703 model2 loss : 0.018545
[12:20:08.084] iteration 28005 : model1 loss : 0.447274 model2 loss : 0.020685
[12:20:08.254] iteration 28006 : model1 loss : 0.440688 model2 loss : 0.017676
[12:20:08.421] iteration 28007 : model1 loss : 0.443807 model2 loss : 0.019613
[12:20:08.588] iteration 28008 : model1 loss : 0.437576 model2 loss : 0.018152
[12:20:08.755] iteration 28009 : model1 loss : 0.435550 model2 loss : 0.020345
[12:20:08.944] iteration 28010 : model1 loss : 0.437990 model2 loss : 0.019131
[12:20:09.111] iteration 28011 : model1 loss : 0.440870 model2 loss : 0.018647
[12:20:09.286] iteration 28012 : model1 loss : 0.440310 model2 loss : 0.019062
[12:20:09.453] iteration 28013 : model1 loss : 0.438557 model2 loss : 0.018117
[12:20:09.620] iteration 28014 : model1 loss : 0.441327 model2 loss : 0.021436
[12:20:09.787] iteration 28015 : model1 loss : 0.437212 model2 loss : 0.018734
[12:20:09.959] iteration 28016 : model1 loss : 0.442057 model2 loss : 0.022669
[12:20:10.124] iteration 28017 : model1 loss : 0.437936 model2 loss : 0.017965
[12:20:12.090] iteration 28018 : model1 loss : 0.438879 model2 loss : 0.018688
[12:20:12.261] iteration 28019 : model1 loss : 0.437465 model2 loss : 0.018473
[12:20:12.432] iteration 28020 : model1 loss : 0.437448 model2 loss : 0.017767
[12:20:12.598] iteration 28021 : model1 loss : 0.439059 model2 loss : 0.019092
[12:20:12.766] iteration 28022 : model1 loss : 0.434998 model2 loss : 0.017211
[12:20:12.934] iteration 28023 : model1 loss : 0.437493 model2 loss : 0.019001
[12:20:13.101] iteration 28024 : model1 loss : 0.437218 model2 loss : 0.018567
[12:20:13.274] iteration 28025 : model1 loss : 0.441298 model2 loss : 0.019157
[12:20:13.452] iteration 28026 : model1 loss : 0.440527 model2 loss : 0.017291
[12:20:13.619] iteration 28027 : model1 loss : 0.439128 model2 loss : 0.019612
[12:20:13.788] iteration 28028 : model1 loss : 0.441306 model2 loss : 0.019154
[12:20:13.956] iteration 28029 : model1 loss : 0.437135 model2 loss : 0.021420
[12:20:14.126] iteration 28030 : model1 loss : 0.438686 model2 loss : 0.019220
[12:20:14.295] iteration 28031 : model1 loss : 0.439926 model2 loss : 0.019287
[12:20:14.464] iteration 28032 : model1 loss : 0.438492 model2 loss : 0.016221
[12:20:14.631] iteration 28033 : model1 loss : 0.444034 model2 loss : 0.018583
[12:20:14.798] iteration 28034 : model1 loss : 0.440753 model2 loss : 0.018358
[12:20:14.975] iteration 28035 : model1 loss : 0.443261 model2 loss : 0.017597
[12:20:15.144] iteration 28036 : model1 loss : 0.437964 model2 loss : 0.020200
[12:20:15.310] iteration 28037 : model1 loss : 0.441020 model2 loss : 0.019936
[12:20:15.478] iteration 28038 : model1 loss : 0.439160 model2 loss : 0.019098
[12:20:15.644] iteration 28039 : model1 loss : 0.434797 model2 loss : 0.018510
[12:20:15.814] iteration 28040 : model1 loss : 0.440577 model2 loss : 0.017302
[12:20:15.983] iteration 28041 : model1 loss : 0.445408 model2 loss : 0.019084
[12:20:16.153] iteration 28042 : model1 loss : 0.440676 model2 loss : 0.018511
[12:20:16.320] iteration 28043 : model1 loss : 0.444797 model2 loss : 0.021437
[12:20:16.490] iteration 28044 : model1 loss : 0.442867 model2 loss : 0.020958
[12:20:16.658] iteration 28045 : model1 loss : 0.439267 model2 loss : 0.019228
[12:20:16.826] iteration 28046 : model1 loss : 0.439229 model2 loss : 0.018370
[12:20:16.993] iteration 28047 : model1 loss : 0.441740 model2 loss : 0.020520
[12:20:17.164] iteration 28048 : model1 loss : 0.444053 model2 loss : 0.018207
[12:20:17.329] iteration 28049 : model1 loss : 0.442319 model2 loss : 0.018315
[12:20:17.499] iteration 28050 : model1 loss : 0.442843 model2 loss : 0.018560
[12:20:19.391] iteration 28051 : model1 loss : 0.438664 model2 loss : 0.019459
[12:20:19.558] iteration 28052 : model1 loss : 0.436854 model2 loss : 0.019309
[12:20:19.729] iteration 28053 : model1 loss : 0.443599 model2 loss : 0.020670
[12:20:19.897] iteration 28054 : model1 loss : 0.437966 model2 loss : 0.017445
[12:20:20.065] iteration 28055 : model1 loss : 0.440456 model2 loss : 0.019325
[12:20:20.233] iteration 28056 : model1 loss : 0.444517 model2 loss : 0.019327
[12:20:20.402] iteration 28057 : model1 loss : 0.441682 model2 loss : 0.018822
[12:20:20.570] iteration 28058 : model1 loss : 0.436035 model2 loss : 0.016602
[12:20:20.739] iteration 28059 : model1 loss : 0.437236 model2 loss : 0.020204
[12:20:20.907] iteration 28060 : model1 loss : 0.442001 model2 loss : 0.020557
[12:20:21.076] iteration 28061 : model1 loss : 0.437613 model2 loss : 0.018445
[12:20:21.242] iteration 28062 : model1 loss : 0.442988 model2 loss : 0.021633
[12:20:21.409] iteration 28063 : model1 loss : 0.439719 model2 loss : 0.018583
[12:20:21.578] iteration 28064 : model1 loss : 0.445414 model2 loss : 0.019076
[12:20:21.745] iteration 28065 : model1 loss : 0.440921 model2 loss : 0.019330
[12:20:21.912] iteration 28066 : model1 loss : 0.440984 model2 loss : 0.018248
[12:20:22.079] iteration 28067 : model1 loss : 0.436641 model2 loss : 0.019090
[12:20:22.250] iteration 28068 : model1 loss : 0.435658 model2 loss : 0.017660
[12:20:22.419] iteration 28069 : model1 loss : 0.435722 model2 loss : 0.019186
[12:20:22.584] iteration 28070 : model1 loss : 0.440631 model2 loss : 0.017123
[12:20:22.754] iteration 28071 : model1 loss : 0.441695 model2 loss : 0.018202
[12:20:22.920] iteration 28072 : model1 loss : 0.445384 model2 loss : 0.020048
[12:20:23.089] iteration 28073 : model1 loss : 0.441330 model2 loss : 0.018165
[12:20:23.257] iteration 28074 : model1 loss : 0.441691 model2 loss : 0.021052
[12:20:23.425] iteration 28075 : model1 loss : 0.439651 model2 loss : 0.019487
[12:20:23.592] iteration 28076 : model1 loss : 0.440265 model2 loss : 0.019309
[12:20:23.762] iteration 28077 : model1 loss : 0.442641 model2 loss : 0.019062
[12:20:23.929] iteration 28078 : model1 loss : 0.439535 model2 loss : 0.018669
[12:20:24.097] iteration 28079 : model1 loss : 0.437082 model2 loss : 0.019843
[12:20:24.282] iteration 28080 : model1 loss : 0.444971 model2 loss : 0.021452
[12:20:24.452] iteration 28081 : model1 loss : 0.437603 model2 loss : 0.018781
[12:20:24.617] iteration 28082 : model1 loss : 0.440753 model2 loss : 0.017502
[12:20:24.782] iteration 28083 : model1 loss : 0.440357 model2 loss : 0.019743
[12:20:26.710] iteration 28084 : model1 loss : 0.435301 model2 loss : 0.019305
[12:20:26.878] iteration 28085 : model1 loss : 0.443289 model2 loss : 0.021005
[12:20:27.048] iteration 28086 : model1 loss : 0.437731 model2 loss : 0.016351
[12:20:27.214] iteration 28087 : model1 loss : 0.442509 model2 loss : 0.019957
[12:20:27.384] iteration 28088 : model1 loss : 0.436934 model2 loss : 0.019414
[12:20:27.552] iteration 28089 : model1 loss : 0.434241 model2 loss : 0.017274
[12:20:27.721] iteration 28090 : model1 loss : 0.441192 model2 loss : 0.018593
[12:20:27.888] iteration 28091 : model1 loss : 0.435827 model2 loss : 0.017927
[12:20:28.057] iteration 28092 : model1 loss : 0.443756 model2 loss : 0.019082
[12:20:28.225] iteration 28093 : model1 loss : 0.441857 model2 loss : 0.019294
[12:20:28.392] iteration 28094 : model1 loss : 0.448316 model2 loss : 0.021103
[12:20:28.558] iteration 28095 : model1 loss : 0.440820 model2 loss : 0.017701
[12:20:28.724] iteration 28096 : model1 loss : 0.441090 model2 loss : 0.018831
[12:20:28.892] iteration 28097 : model1 loss : 0.442396 model2 loss : 0.021332
[12:20:29.059] iteration 28098 : model1 loss : 0.441160 model2 loss : 0.018506
[12:20:29.229] iteration 28099 : model1 loss : 0.441908 model2 loss : 0.017454
[12:20:29.398] iteration 28100 : model1 loss : 0.435787 model2 loss : 0.016758
[12:20:29.565] iteration 28101 : model1 loss : 0.436285 model2 loss : 0.018561
[12:20:29.733] iteration 28102 : model1 loss : 0.439173 model2 loss : 0.019508
[12:20:29.900] iteration 28103 : model1 loss : 0.438953 model2 loss : 0.018780
[12:20:30.070] iteration 28104 : model1 loss : 0.439727 model2 loss : 0.018750
[12:20:30.236] iteration 28105 : model1 loss : 0.438978 model2 loss : 0.019960
[12:20:30.406] iteration 28106 : model1 loss : 0.436254 model2 loss : 0.017227
[12:20:30.574] iteration 28107 : model1 loss : 0.439817 model2 loss : 0.019595
[12:20:30.745] iteration 28108 : model1 loss : 0.439775 model2 loss : 0.019090
[12:20:30.913] iteration 28109 : model1 loss : 0.435756 model2 loss : 0.017764
[12:20:31.080] iteration 28110 : model1 loss : 0.444100 model2 loss : 0.018577
[12:20:31.251] iteration 28111 : model1 loss : 0.441993 model2 loss : 0.020562
[12:20:31.419] iteration 28112 : model1 loss : 0.441251 model2 loss : 0.019369
[12:20:31.587] iteration 28113 : model1 loss : 0.444549 model2 loss : 0.020056
[12:20:31.756] iteration 28114 : model1 loss : 0.441933 model2 loss : 0.021684
[12:20:31.921] iteration 28115 : model1 loss : 0.438876 model2 loss : 0.018172
[12:20:32.089] iteration 28116 : model1 loss : 0.441818 model2 loss : 0.020194
[12:20:34.008] iteration 28117 : model1 loss : 0.442075 model2 loss : 0.020441
[12:20:34.179] iteration 28118 : model1 loss : 0.442152 model2 loss : 0.017439
[12:20:34.349] iteration 28119 : model1 loss : 0.442983 model2 loss : 0.020678
[12:20:34.519] iteration 28120 : model1 loss : 0.445192 model2 loss : 0.020104
[12:20:34.688] iteration 28121 : model1 loss : 0.439354 model2 loss : 0.018288
[12:20:34.855] iteration 28122 : model1 loss : 0.440841 model2 loss : 0.021446
[12:20:35.027] iteration 28123 : model1 loss : 0.437793 model2 loss : 0.017841
[12:20:35.194] iteration 28124 : model1 loss : 0.438753 model2 loss : 0.016503
[12:20:35.366] iteration 28125 : model1 loss : 0.443137 model2 loss : 0.021063
[12:20:35.536] iteration 28126 : model1 loss : 0.440422 model2 loss : 0.018013
[12:20:35.706] iteration 28127 : model1 loss : 0.438089 model2 loss : 0.019204
[12:20:35.872] iteration 28128 : model1 loss : 0.441466 model2 loss : 0.019566
[12:20:36.043] iteration 28129 : model1 loss : 0.442280 model2 loss : 0.017293
[12:20:36.213] iteration 28130 : model1 loss : 0.443919 model2 loss : 0.019565
[12:20:36.381] iteration 28131 : model1 loss : 0.439355 model2 loss : 0.019035
[12:20:36.554] iteration 28132 : model1 loss : 0.436043 model2 loss : 0.020551
[12:20:36.722] iteration 28133 : model1 loss : 0.438809 model2 loss : 0.019481
[12:20:36.888] iteration 28134 : model1 loss : 0.443377 model2 loss : 0.020002
[12:20:37.059] iteration 28135 : model1 loss : 0.442401 model2 loss : 0.019949
[12:20:37.228] iteration 28136 : model1 loss : 0.437633 model2 loss : 0.018533
[12:20:37.397] iteration 28137 : model1 loss : 0.437626 model2 loss : 0.017869
[12:20:37.564] iteration 28138 : model1 loss : 0.438892 model2 loss : 0.018069
[12:20:37.733] iteration 28139 : model1 loss : 0.438953 model2 loss : 0.019324
[12:20:37.898] iteration 28140 : model1 loss : 0.437085 model2 loss : 0.016337
[12:20:38.069] iteration 28141 : model1 loss : 0.439645 model2 loss : 0.017083
[12:20:38.236] iteration 28142 : model1 loss : 0.441786 model2 loss : 0.020161
[12:20:38.404] iteration 28143 : model1 loss : 0.439546 model2 loss : 0.018308
[12:20:38.570] iteration 28144 : model1 loss : 0.437575 model2 loss : 0.017590
[12:20:38.740] iteration 28145 : model1 loss : 0.436983 model2 loss : 0.019524
[12:20:38.906] iteration 28146 : model1 loss : 0.440532 model2 loss : 0.020973
[12:20:39.076] iteration 28147 : model1 loss : 0.445350 model2 loss : 0.020099
[12:20:39.242] iteration 28148 : model1 loss : 0.438070 model2 loss : 0.019137
[12:20:39.410] iteration 28149 : model1 loss : 0.437764 model2 loss : 0.019115
[12:20:41.335] iteration 28150 : model1 loss : 0.440516 model2 loss : 0.022438
[12:20:41.504] iteration 28151 : model1 loss : 0.438619 model2 loss : 0.019066
[12:20:41.675] iteration 28152 : model1 loss : 0.436655 model2 loss : 0.016961
[12:20:41.844] iteration 28153 : model1 loss : 0.438611 model2 loss : 0.017974
[12:20:42.013] iteration 28154 : model1 loss : 0.442880 model2 loss : 0.020088
[12:20:42.179] iteration 28155 : model1 loss : 0.437997 model2 loss : 0.018401
[12:20:42.348] iteration 28156 : model1 loss : 0.439124 model2 loss : 0.020151
[12:20:42.516] iteration 28157 : model1 loss : 0.436926 model2 loss : 0.019822
[12:20:42.686] iteration 28158 : model1 loss : 0.440592 model2 loss : 0.018123
[12:20:42.854] iteration 28159 : model1 loss : 0.438540 model2 loss : 0.018271
[12:20:43.024] iteration 28160 : model1 loss : 0.445639 model2 loss : 0.019971
[12:20:43.192] iteration 28161 : model1 loss : 0.436500 model2 loss : 0.017529
[12:20:43.361] iteration 28162 : model1 loss : 0.442034 model2 loss : 0.017263
[12:20:43.529] iteration 28163 : model1 loss : 0.444543 model2 loss : 0.019332
[12:20:43.697] iteration 28164 : model1 loss : 0.440547 model2 loss : 0.018280
[12:20:43.865] iteration 28165 : model1 loss : 0.440791 model2 loss : 0.019586
[12:20:44.032] iteration 28166 : model1 loss : 0.439502 model2 loss : 0.021272
[12:20:44.200] iteration 28167 : model1 loss : 0.438956 model2 loss : 0.018044
[12:20:44.370] iteration 28168 : model1 loss : 0.437406 model2 loss : 0.019549
[12:20:44.538] iteration 28169 : model1 loss : 0.443936 model2 loss : 0.018626
[12:20:44.710] iteration 28170 : model1 loss : 0.440845 model2 loss : 0.016970
[12:20:44.877] iteration 28171 : model1 loss : 0.437773 model2 loss : 0.020207
[12:20:45.046] iteration 28172 : model1 loss : 0.440417 model2 loss : 0.017723
[12:20:45.213] iteration 28173 : model1 loss : 0.439880 model2 loss : 0.017968
[12:20:45.382] iteration 28174 : model1 loss : 0.443545 model2 loss : 0.019403
[12:20:45.549] iteration 28175 : model1 loss : 0.435516 model2 loss : 0.018675
[12:20:45.719] iteration 28176 : model1 loss : 0.441429 model2 loss : 0.018658
[12:20:45.885] iteration 28177 : model1 loss : 0.443673 model2 loss : 0.020782
[12:20:46.055] iteration 28178 : model1 loss : 0.435127 model2 loss : 0.018180
[12:20:46.223] iteration 28179 : model1 loss : 0.441665 model2 loss : 0.018978
[12:20:46.391] iteration 28180 : model1 loss : 0.441996 model2 loss : 0.017229
[12:20:46.557] iteration 28181 : model1 loss : 0.442551 model2 loss : 0.019248
[12:20:46.726] iteration 28182 : model1 loss : 0.436847 model2 loss : 0.019378
[12:20:48.657] iteration 28183 : model1 loss : 0.440428 model2 loss : 0.017367
[12:20:48.830] iteration 28184 : model1 loss : 0.442731 model2 loss : 0.018737
[12:20:49.000] iteration 28185 : model1 loss : 0.441114 model2 loss : 0.017754
[12:20:49.168] iteration 28186 : model1 loss : 0.435875 model2 loss : 0.018049
[12:20:49.340] iteration 28187 : model1 loss : 0.436118 model2 loss : 0.018807
[12:20:49.511] iteration 28188 : model1 loss : 0.439635 model2 loss : 0.018899
[12:20:49.679] iteration 28189 : model1 loss : 0.438472 model2 loss : 0.018883
[12:20:49.847] iteration 28190 : model1 loss : 0.437941 model2 loss : 0.018613
[12:20:50.017] iteration 28191 : model1 loss : 0.442361 model2 loss : 0.018012
[12:20:50.184] iteration 28192 : model1 loss : 0.439190 model2 loss : 0.019127
[12:20:50.355] iteration 28193 : model1 loss : 0.439671 model2 loss : 0.018940
[12:20:50.527] iteration 28194 : model1 loss : 0.439522 model2 loss : 0.018727
[12:20:50.696] iteration 28195 : model1 loss : 0.442183 model2 loss : 0.018914
[12:20:50.862] iteration 28196 : model1 loss : 0.439495 model2 loss : 0.017671
[12:20:51.032] iteration 28197 : model1 loss : 0.438802 model2 loss : 0.019031
[12:20:51.198] iteration 28198 : model1 loss : 0.438526 model2 loss : 0.017425
[12:20:51.368] iteration 28199 : model1 loss : 0.444551 model2 loss : 0.019682
[12:20:51.539] iteration 28200 : model1 loss : 0.441536 model2 loss : 0.019447
[12:20:51.710] iteration 28201 : model1 loss : 0.437779 model2 loss : 0.017761
[12:20:51.877] iteration 28202 : model1 loss : 0.442733 model2 loss : 0.019833
[12:20:52.046] iteration 28203 : model1 loss : 0.435857 model2 loss : 0.017378
[12:20:52.214] iteration 28204 : model1 loss : 0.439352 model2 loss : 0.016226
[12:20:52.382] iteration 28205 : model1 loss : 0.441163 model2 loss : 0.018532
[12:20:52.549] iteration 28206 : model1 loss : 0.439504 model2 loss : 0.020479
[12:20:52.718] iteration 28207 : model1 loss : 0.440284 model2 loss : 0.018317
[12:20:52.883] iteration 28208 : model1 loss : 0.441982 model2 loss : 0.019615
[12:20:53.054] iteration 28209 : model1 loss : 0.445444 model2 loss : 0.019607
[12:20:53.221] iteration 28210 : model1 loss : 0.442051 model2 loss : 0.020443
[12:20:53.391] iteration 28211 : model1 loss : 0.439679 model2 loss : 0.016172
[12:20:53.558] iteration 28212 : model1 loss : 0.442867 model2 loss : 0.018548
[12:20:53.728] iteration 28213 : model1 loss : 0.437077 model2 loss : 0.020120
[12:20:53.895] iteration 28214 : model1 loss : 0.441383 model2 loss : 0.020859
[12:20:54.063] iteration 28215 : model1 loss : 0.438011 model2 loss : 0.019251
[12:20:55.999] iteration 28216 : model1 loss : 0.438362 model2 loss : 0.017564
[12:20:56.179] iteration 28217 : model1 loss : 0.448746 model2 loss : 0.021956
[12:20:56.351] iteration 28218 : model1 loss : 0.449542 model2 loss : 0.018795
[12:20:56.520] iteration 28219 : model1 loss : 0.440505 model2 loss : 0.019074
[12:20:56.689] iteration 28220 : model1 loss : 0.436514 model2 loss : 0.018205
[12:20:56.856] iteration 28221 : model1 loss : 0.438482 model2 loss : 0.019621
[12:20:57.024] iteration 28222 : model1 loss : 0.436939 model2 loss : 0.018044
[12:20:57.191] iteration 28223 : model1 loss : 0.438670 model2 loss : 0.018394
[12:20:57.360] iteration 28224 : model1 loss : 0.437629 model2 loss : 0.018109
[12:20:57.528] iteration 28225 : model1 loss : 0.435286 model2 loss : 0.017041
[12:20:57.696] iteration 28226 : model1 loss : 0.444117 model2 loss : 0.020090
[12:20:57.863] iteration 28227 : model1 loss : 0.440460 model2 loss : 0.020110
[12:20:58.030] iteration 28228 : model1 loss : 0.440477 model2 loss : 0.019454
[12:20:58.200] iteration 28229 : model1 loss : 0.440220 model2 loss : 0.017087
[12:20:58.369] iteration 28230 : model1 loss : 0.438556 model2 loss : 0.017413
[12:20:58.537] iteration 28231 : model1 loss : 0.439063 model2 loss : 0.019099
[12:20:58.702] iteration 28232 : model1 loss : 0.440706 model2 loss : 0.020212
[12:20:58.868] iteration 28233 : model1 loss : 0.439498 model2 loss : 0.020997
[12:20:59.038] iteration 28234 : model1 loss : 0.436530 model2 loss : 0.018963
[12:20:59.205] iteration 28235 : model1 loss : 0.438854 model2 loss : 0.018236
[12:20:59.375] iteration 28236 : model1 loss : 0.439437 model2 loss : 0.019797
[12:20:59.543] iteration 28237 : model1 loss : 0.439973 model2 loss : 0.019014
[12:20:59.716] iteration 28238 : model1 loss : 0.443603 model2 loss : 0.020519
[12:20:59.882] iteration 28239 : model1 loss : 0.444244 model2 loss : 0.022260
[12:21:00.052] iteration 28240 : model1 loss : 0.444498 model2 loss : 0.022317
[12:21:00.222] iteration 28241 : model1 loss : 0.440289 model2 loss : 0.020442
[12:21:00.391] iteration 28242 : model1 loss : 0.439161 model2 loss : 0.018787
[12:21:00.559] iteration 28243 : model1 loss : 0.437812 model2 loss : 0.018465
[12:21:00.731] iteration 28244 : model1 loss : 0.440576 model2 loss : 0.021334
[12:21:00.898] iteration 28245 : model1 loss : 0.440932 model2 loss : 0.019484
[12:21:01.066] iteration 28246 : model1 loss : 0.440856 model2 loss : 0.017321
[12:21:01.233] iteration 28247 : model1 loss : 0.444169 model2 loss : 0.020162
[12:21:01.400] iteration 28248 : model1 loss : 0.435680 model2 loss : 0.018317
[12:21:03.302] iteration 28249 : model1 loss : 0.441089 model2 loss : 0.017931
[12:21:03.470] iteration 28250 : model1 loss : 0.444223 model2 loss : 0.019437
[12:21:03.638] iteration 28251 : model1 loss : 0.440397 model2 loss : 0.018560
[12:21:03.804] iteration 28252 : model1 loss : 0.439159 model2 loss : 0.019139
[12:21:03.973] iteration 28253 : model1 loss : 0.439236 model2 loss : 0.019768
[12:21:04.141] iteration 28254 : model1 loss : 0.444010 model2 loss : 0.019683
[12:21:04.313] iteration 28255 : model1 loss : 0.439441 model2 loss : 0.018494
[12:21:04.482] iteration 28256 : model1 loss : 0.438504 model2 loss : 0.017220
[12:21:04.652] iteration 28257 : model1 loss : 0.440497 model2 loss : 0.017859
[12:21:04.819] iteration 28258 : model1 loss : 0.434815 model2 loss : 0.017514
[12:21:04.988] iteration 28259 : model1 loss : 0.443068 model2 loss : 0.018078
[12:21:05.156] iteration 28260 : model1 loss : 0.436669 model2 loss : 0.016658
[12:21:05.329] iteration 28261 : model1 loss : 0.436695 model2 loss : 0.018240
[12:21:05.497] iteration 28262 : model1 loss : 0.436884 model2 loss : 0.020019
[12:21:05.666] iteration 28263 : model1 loss : 0.441696 model2 loss : 0.019935
[12:21:05.834] iteration 28264 : model1 loss : 0.442610 model2 loss : 0.019770
[12:21:06.003] iteration 28265 : model1 loss : 0.437607 model2 loss : 0.016213
[12:21:06.170] iteration 28266 : model1 loss : 0.437301 model2 loss : 0.020053
[12:21:06.342] iteration 28267 : model1 loss : 0.442419 model2 loss : 0.020638
[12:21:06.512] iteration 28268 : model1 loss : 0.441143 model2 loss : 0.020566
[12:21:06.680] iteration 28269 : model1 loss : 0.438908 model2 loss : 0.020639
[12:21:06.848] iteration 28270 : model1 loss : 0.440377 model2 loss : 0.017543
[12:21:07.016] iteration 28271 : model1 loss : 0.440107 model2 loss : 0.020265
[12:21:07.184] iteration 28272 : model1 loss : 0.439271 model2 loss : 0.020928
[12:21:07.357] iteration 28273 : model1 loss : 0.439730 model2 loss : 0.019786
[12:21:07.530] iteration 28274 : model1 loss : 0.442494 model2 loss : 0.019051
[12:21:07.698] iteration 28275 : model1 loss : 0.434740 model2 loss : 0.018889
[12:21:07.866] iteration 28276 : model1 loss : 0.438737 model2 loss : 0.017995
[12:21:08.034] iteration 28277 : model1 loss : 0.443241 model2 loss : 0.021494
[12:21:08.202] iteration 28278 : model1 loss : 0.440056 model2 loss : 0.017812
[12:21:08.376] iteration 28279 : model1 loss : 0.445520 model2 loss : 0.021903
[12:21:08.544] iteration 28280 : model1 loss : 0.439660 model2 loss : 0.017314
[12:21:08.715] iteration 28281 : model1 loss : 0.441060 model2 loss : 0.017206
[12:21:10.636] iteration 28282 : model1 loss : 0.439614 model2 loss : 0.019401
[12:21:10.804] iteration 28283 : model1 loss : 0.440070 model2 loss : 0.020196
[12:21:10.975] iteration 28284 : model1 loss : 0.437073 model2 loss : 0.017727
[12:21:11.140] iteration 28285 : model1 loss : 0.444264 model2 loss : 0.020903
[12:21:11.310] iteration 28286 : model1 loss : 0.439541 model2 loss : 0.017801
[12:21:11.478] iteration 28287 : model1 loss : 0.441965 model2 loss : 0.017540
[12:21:11.648] iteration 28288 : model1 loss : 0.436585 model2 loss : 0.019648
[12:21:11.815] iteration 28289 : model1 loss : 0.437144 model2 loss : 0.017882
[12:21:11.983] iteration 28290 : model1 loss : 0.439473 model2 loss : 0.017784
[12:21:12.152] iteration 28291 : model1 loss : 0.440924 model2 loss : 0.019356
[12:21:12.325] iteration 28292 : model1 loss : 0.438721 model2 loss : 0.016128
[12:21:12.492] iteration 28293 : model1 loss : 0.438447 model2 loss : 0.017967
[12:21:12.661] iteration 28294 : model1 loss : 0.441100 model2 loss : 0.017725
[12:21:12.827] iteration 28295 : model1 loss : 0.443602 model2 loss : 0.017547
[12:21:12.998] iteration 28296 : model1 loss : 0.440643 model2 loss : 0.020933
[12:21:13.167] iteration 28297 : model1 loss : 0.441023 model2 loss : 0.019834
[12:21:13.339] iteration 28298 : model1 loss : 0.439195 model2 loss : 0.018882
[12:21:13.508] iteration 28299 : model1 loss : 0.439928 model2 loss : 0.018702
[12:21:13.676] iteration 28300 : model1 loss : 0.446437 model2 loss : 0.022618
[12:21:13.842] iteration 28301 : model1 loss : 0.437843 model2 loss : 0.016832
[12:21:14.010] iteration 28302 : model1 loss : 0.439956 model2 loss : 0.020338
[12:21:14.178] iteration 28303 : model1 loss : 0.442485 model2 loss : 0.018135
[12:21:14.352] iteration 28304 : model1 loss : 0.440677 model2 loss : 0.020757
[12:21:14.521] iteration 28305 : model1 loss : 0.439132 model2 loss : 0.017523
[12:21:14.690] iteration 28306 : model1 loss : 0.434773 model2 loss : 0.018513
[12:21:14.857] iteration 28307 : model1 loss : 0.435110 model2 loss : 0.016548
[12:21:15.030] iteration 28308 : model1 loss : 0.435741 model2 loss : 0.019077
[12:21:15.197] iteration 28309 : model1 loss : 0.446989 model2 loss : 0.022276
[12:21:15.367] iteration 28310 : model1 loss : 0.440670 model2 loss : 0.021135
[12:21:15.533] iteration 28311 : model1 loss : 0.439710 model2 loss : 0.017643
[12:21:15.705] iteration 28312 : model1 loss : 0.441565 model2 loss : 0.016604
[12:21:15.870] iteration 28313 : model1 loss : 0.446427 model2 loss : 0.022315
[12:21:16.039] iteration 28314 : model1 loss : 0.437234 model2 loss : 0.018882
[12:21:17.959] iteration 28315 : model1 loss : 0.443866 model2 loss : 0.021611
[12:21:18.127] iteration 28316 : model1 loss : 0.446293 model2 loss : 0.020784
[12:21:18.298] iteration 28317 : model1 loss : 0.441434 model2 loss : 0.019509
[12:21:18.464] iteration 28318 : model1 loss : 0.441090 model2 loss : 0.018142
[12:21:18.633] iteration 28319 : model1 loss : 0.444154 model2 loss : 0.018113
[12:21:18.800] iteration 28320 : model1 loss : 0.441619 model2 loss : 0.017640
[12:21:18.968] iteration 28321 : model1 loss : 0.441801 model2 loss : 0.021311
[12:21:19.138] iteration 28322 : model1 loss : 0.436791 model2 loss : 0.017820
[12:21:19.307] iteration 28323 : model1 loss : 0.439831 model2 loss : 0.018459
[12:21:19.475] iteration 28324 : model1 loss : 0.439011 model2 loss : 0.017719
[12:21:19.643] iteration 28325 : model1 loss : 0.444441 model2 loss : 0.019008
[12:21:19.810] iteration 28326 : model1 loss : 0.439806 model2 loss : 0.019492
[12:21:19.979] iteration 28327 : model1 loss : 0.437590 model2 loss : 0.019029
[12:21:20.146] iteration 28328 : model1 loss : 0.443171 model2 loss : 0.020096
[12:21:20.316] iteration 28329 : model1 loss : 0.437438 model2 loss : 0.019930
[12:21:20.484] iteration 28330 : model1 loss : 0.440169 model2 loss : 0.018133
[12:21:20.653] iteration 28331 : model1 loss : 0.437329 model2 loss : 0.018874
[12:21:20.822] iteration 28332 : model1 loss : 0.438766 model2 loss : 0.016951
[12:21:20.991] iteration 28333 : model1 loss : 0.438353 model2 loss : 0.020229
[12:21:21.157] iteration 28334 : model1 loss : 0.439468 model2 loss : 0.019967
[12:21:21.333] iteration 28335 : model1 loss : 0.444657 model2 loss : 0.018850
[12:21:21.503] iteration 28336 : model1 loss : 0.441709 model2 loss : 0.020106
[12:21:21.673] iteration 28337 : model1 loss : 0.436646 model2 loss : 0.018745
[12:21:21.839] iteration 28338 : model1 loss : 0.440839 model2 loss : 0.018864
[12:21:22.009] iteration 28339 : model1 loss : 0.437223 model2 loss : 0.019987
[12:21:22.178] iteration 28340 : model1 loss : 0.438409 model2 loss : 0.017078
[12:21:22.352] iteration 28341 : model1 loss : 0.443469 model2 loss : 0.021360
[12:21:22.522] iteration 28342 : model1 loss : 0.444885 model2 loss : 0.021960
[12:21:22.693] iteration 28343 : model1 loss : 0.435183 model2 loss : 0.019192
[12:21:22.858] iteration 28344 : model1 loss : 0.439654 model2 loss : 0.020409
[12:21:23.028] iteration 28345 : model1 loss : 0.437456 model2 loss : 0.018079
[12:21:23.198] iteration 28346 : model1 loss : 0.438963 model2 loss : 0.017473
[12:21:23.366] iteration 28347 : model1 loss : 0.437406 model2 loss : 0.016661
[12:21:25.276] iteration 28348 : model1 loss : 0.438430 model2 loss : 0.019255
[12:21:25.447] iteration 28349 : model1 loss : 0.439705 model2 loss : 0.019432
[12:21:25.618] iteration 28350 : model1 loss : 0.445900 model2 loss : 0.023380
[12:21:25.784] iteration 28351 : model1 loss : 0.444115 model2 loss : 0.021284
[12:21:25.960] iteration 28352 : model1 loss : 0.443923 model2 loss : 0.019881
[12:21:26.128] iteration 28353 : model1 loss : 0.442436 model2 loss : 0.019326
[12:21:26.298] iteration 28354 : model1 loss : 0.440023 model2 loss : 0.020714
[12:21:26.464] iteration 28355 : model1 loss : 0.439981 model2 loss : 0.018902
[12:21:26.633] iteration 28356 : model1 loss : 0.440548 model2 loss : 0.017368
[12:21:26.799] iteration 28357 : model1 loss : 0.439582 model2 loss : 0.017496
[12:21:26.969] iteration 28358 : model1 loss : 0.438997 model2 loss : 0.018425
[12:21:27.136] iteration 28359 : model1 loss : 0.438065 model2 loss : 0.017911
[12:21:27.305] iteration 28360 : model1 loss : 0.444485 model2 loss : 0.019627
[12:21:27.472] iteration 28361 : model1 loss : 0.434732 model2 loss : 0.017809
[12:21:27.644] iteration 28362 : model1 loss : 0.438781 model2 loss : 0.018713
[12:21:27.810] iteration 28363 : model1 loss : 0.444923 model2 loss : 0.018958
[12:21:27.980] iteration 28364 : model1 loss : 0.439131 model2 loss : 0.018517
[12:21:28.146] iteration 28365 : model1 loss : 0.438188 model2 loss : 0.017113
[12:21:28.317] iteration 28366 : model1 loss : 0.437053 model2 loss : 0.020272
[12:21:28.484] iteration 28367 : model1 loss : 0.438114 model2 loss : 0.017127
[12:21:28.655] iteration 28368 : model1 loss : 0.438451 model2 loss : 0.018678
[12:21:28.822] iteration 28369 : model1 loss : 0.437272 model2 loss : 0.018041
[12:21:28.992] iteration 28370 : model1 loss : 0.438170 model2 loss : 0.016832
[12:21:29.160] iteration 28371 : model1 loss : 0.438856 model2 loss : 0.018488
[12:21:29.331] iteration 28372 : model1 loss : 0.441708 model2 loss : 0.022069
[12:21:29.500] iteration 28373 : model1 loss : 0.437875 model2 loss : 0.017648
[12:21:29.671] iteration 28374 : model1 loss : 0.443551 model2 loss : 0.018916
[12:21:29.837] iteration 28375 : model1 loss : 0.439347 model2 loss : 0.019529
[12:21:30.005] iteration 28376 : model1 loss : 0.439869 model2 loss : 0.017474
[12:21:30.172] iteration 28377 : model1 loss : 0.442786 model2 loss : 0.018628
[12:21:30.349] iteration 28378 : model1 loss : 0.436290 model2 loss : 0.016978
[12:21:30.515] iteration 28379 : model1 loss : 0.442426 model2 loss : 0.017748
[12:21:30.684] iteration 28380 : model1 loss : 0.442028 model2 loss : 0.020673
[12:21:32.642] iteration 28381 : model1 loss : 0.441450 model2 loss : 0.018201
[12:21:32.811] iteration 28382 : model1 loss : 0.444306 model2 loss : 0.020245
[12:21:32.979] iteration 28383 : model1 loss : 0.439354 model2 loss : 0.017201
[12:21:33.145] iteration 28384 : model1 loss : 0.437753 model2 loss : 0.016784
[12:21:33.316] iteration 28385 : model1 loss : 0.441404 model2 loss : 0.019125
[12:21:33.484] iteration 28386 : model1 loss : 0.435702 model2 loss : 0.017474
[12:21:33.651] iteration 28387 : model1 loss : 0.442115 model2 loss : 0.018757
[12:21:33.821] iteration 28388 : model1 loss : 0.440712 model2 loss : 0.019320
[12:21:33.989] iteration 28389 : model1 loss : 0.447306 model2 loss : 0.021799
[12:21:34.157] iteration 28390 : model1 loss : 0.438784 model2 loss : 0.018350
[12:21:34.328] iteration 28391 : model1 loss : 0.438675 model2 loss : 0.018965
[12:21:34.496] iteration 28392 : model1 loss : 0.440822 model2 loss : 0.018639
[12:21:34.679] iteration 28393 : model1 loss : 0.438884 model2 loss : 0.017639
[12:21:34.847] iteration 28394 : model1 loss : 0.440372 model2 loss : 0.019571
[12:21:35.016] iteration 28395 : model1 loss : 0.440730 model2 loss : 0.016869
[12:21:35.184] iteration 28396 : model1 loss : 0.438767 model2 loss : 0.017929
[12:21:35.356] iteration 28397 : model1 loss : 0.444600 model2 loss : 0.021686
[12:21:35.524] iteration 28398 : model1 loss : 0.439381 model2 loss : 0.019854
[12:21:35.692] iteration 28399 : model1 loss : 0.442212 model2 loss : 0.019635
[12:21:35.859] iteration 28400 : model1 loss : 0.442360 model2 loss : 0.017952
[12:21:36.027] iteration 28401 : model1 loss : 0.438539 model2 loss : 0.019804
[12:21:36.195] iteration 28402 : model1 loss : 0.438043 model2 loss : 0.017853
[12:21:36.369] iteration 28403 : model1 loss : 0.437670 model2 loss : 0.018847
[12:21:36.538] iteration 28404 : model1 loss : 0.441352 model2 loss : 0.022868
[12:21:36.708] iteration 28405 : model1 loss : 0.438200 model2 loss : 0.019672
[12:21:36.874] iteration 28406 : model1 loss : 0.435702 model2 loss : 0.017406
[12:21:37.044] iteration 28407 : model1 loss : 0.443037 model2 loss : 0.020887
[12:21:37.214] iteration 28408 : model1 loss : 0.438819 model2 loss : 0.017542
[12:21:37.385] iteration 28409 : model1 loss : 0.439222 model2 loss : 0.018255
[12:21:37.551] iteration 28410 : model1 loss : 0.436232 model2 loss : 0.018303
[12:21:37.719] iteration 28411 : model1 loss : 0.441812 model2 loss : 0.019840
[12:21:37.885] iteration 28412 : model1 loss : 0.440081 model2 loss : 0.018872
[12:21:38.052] iteration 28413 : model1 loss : 0.441060 model2 loss : 0.016549
[12:21:39.966] iteration 28414 : model1 loss : 0.436649 model2 loss : 0.017029
[12:21:40.135] iteration 28415 : model1 loss : 0.441688 model2 loss : 0.020488
[12:21:40.307] iteration 28416 : model1 loss : 0.439924 model2 loss : 0.017605
[12:21:40.473] iteration 28417 : model1 loss : 0.438797 model2 loss : 0.018128
[12:21:40.642] iteration 28418 : model1 loss : 0.439657 model2 loss : 0.018087
[12:21:40.808] iteration 28419 : model1 loss : 0.441480 model2 loss : 0.020675
[12:21:40.977] iteration 28420 : model1 loss : 0.440912 model2 loss : 0.019794
[12:21:41.144] iteration 28421 : model1 loss : 0.440581 model2 loss : 0.018302
[12:21:41.315] iteration 28422 : model1 loss : 0.439351 model2 loss : 0.017740
[12:21:41.483] iteration 28423 : model1 loss : 0.434438 model2 loss : 0.019016
[12:21:41.652] iteration 28424 : model1 loss : 0.443049 model2 loss : 0.017796
[12:21:41.819] iteration 28425 : model1 loss : 0.442070 model2 loss : 0.021290
[12:21:41.989] iteration 28426 : model1 loss : 0.443888 model2 loss : 0.021130
[12:21:42.158] iteration 28427 : model1 loss : 0.443972 model2 loss : 0.017638
[12:21:42.327] iteration 28428 : model1 loss : 0.441754 model2 loss : 0.018660
[12:21:42.493] iteration 28429 : model1 loss : 0.439929 model2 loss : 0.018744
[12:21:42.663] iteration 28430 : model1 loss : 0.440890 model2 loss : 0.015680
[12:21:42.829] iteration 28431 : model1 loss : 0.437639 model2 loss : 0.019729
[12:21:42.999] iteration 28432 : model1 loss : 0.441826 model2 loss : 0.017592
[12:21:43.166] iteration 28433 : model1 loss : 0.441855 model2 loss : 0.019015
[12:21:43.336] iteration 28434 : model1 loss : 0.441153 model2 loss : 0.019877
[12:21:43.506] iteration 28435 : model1 loss : 0.441477 model2 loss : 0.019855
[12:21:43.674] iteration 28436 : model1 loss : 0.442077 model2 loss : 0.019738
[12:21:43.840] iteration 28437 : model1 loss : 0.434999 model2 loss : 0.017165
[12:21:44.010] iteration 28438 : model1 loss : 0.441379 model2 loss : 0.017348
[12:21:44.178] iteration 28439 : model1 loss : 0.435895 model2 loss : 0.016971
[12:21:44.347] iteration 28440 : model1 loss : 0.439502 model2 loss : 0.018941
[12:21:44.525] iteration 28441 : model1 loss : 0.436124 model2 loss : 0.018205
[12:21:44.695] iteration 28442 : model1 loss : 0.440333 model2 loss : 0.017184
[12:21:44.863] iteration 28443 : model1 loss : 0.441480 model2 loss : 0.021749
[12:21:45.032] iteration 28444 : model1 loss : 0.442339 model2 loss : 0.020418
[12:21:45.197] iteration 28445 : model1 loss : 0.438068 model2 loss : 0.019129
[12:21:45.369] iteration 28446 : model1 loss : 0.435446 model2 loss : 0.018278
[12:21:47.297] iteration 28447 : model1 loss : 0.437897 model2 loss : 0.018442
[12:21:47.465] iteration 28448 : model1 loss : 0.436899 model2 loss : 0.018722
[12:21:47.636] iteration 28449 : model1 loss : 0.440160 model2 loss : 0.019579
[12:21:47.803] iteration 28450 : model1 loss : 0.440527 model2 loss : 0.018643
[12:21:47.972] iteration 28451 : model1 loss : 0.438185 model2 loss : 0.018442
[12:21:48.139] iteration 28452 : model1 loss : 0.440216 model2 loss : 0.018528
[12:21:48.311] iteration 28453 : model1 loss : 0.438808 model2 loss : 0.018839
[12:21:48.479] iteration 28454 : model1 loss : 0.441138 model2 loss : 0.019311
[12:21:48.650] iteration 28455 : model1 loss : 0.437256 model2 loss : 0.017975
[12:21:48.818] iteration 28456 : model1 loss : 0.440363 model2 loss : 0.018547
[12:21:48.985] iteration 28457 : model1 loss : 0.441522 model2 loss : 0.016841
[12:21:49.153] iteration 28458 : model1 loss : 0.439624 model2 loss : 0.017369
[12:21:49.323] iteration 28459 : model1 loss : 0.438912 model2 loss : 0.019520
[12:21:49.491] iteration 28460 : model1 loss : 0.446136 model2 loss : 0.023147
[12:21:49.659] iteration 28461 : model1 loss : 0.442083 model2 loss : 0.018575
[12:21:49.828] iteration 28462 : model1 loss : 0.439161 model2 loss : 0.019187
[12:21:49.998] iteration 28463 : model1 loss : 0.441243 model2 loss : 0.017742
[12:21:50.165] iteration 28464 : model1 loss : 0.435650 model2 loss : 0.016107
[12:21:50.334] iteration 28465 : model1 loss : 0.439746 model2 loss : 0.019130
[12:21:50.504] iteration 28466 : model1 loss : 0.439297 model2 loss : 0.018204
[12:21:50.673] iteration 28467 : model1 loss : 0.443293 model2 loss : 0.020109
[12:21:50.840] iteration 28468 : model1 loss : 0.437314 model2 loss : 0.018191
[12:21:51.008] iteration 28469 : model1 loss : 0.436962 model2 loss : 0.016842
[12:21:51.178] iteration 28470 : model1 loss : 0.440978 model2 loss : 0.019862
[12:21:51.348] iteration 28471 : model1 loss : 0.441985 model2 loss : 0.018091
[12:21:51.517] iteration 28472 : model1 loss : 0.440508 model2 loss : 0.016953
[12:21:51.687] iteration 28473 : model1 loss : 0.442821 model2 loss : 0.021752
[12:21:51.856] iteration 28474 : model1 loss : 0.438753 model2 loss : 0.017033
[12:21:52.027] iteration 28475 : model1 loss : 0.435885 model2 loss : 0.017665
[12:21:52.192] iteration 28476 : model1 loss : 0.442283 model2 loss : 0.016636
[12:21:52.362] iteration 28477 : model1 loss : 0.444291 model2 loss : 0.018863
[12:21:52.531] iteration 28478 : model1 loss : 0.438848 model2 loss : 0.017680
[12:21:52.699] iteration 28479 : model1 loss : 0.440579 model2 loss : 0.017310
[12:21:54.605] iteration 28480 : model1 loss : 0.441697 model2 loss : 0.018347
[12:21:54.775] iteration 28481 : model1 loss : 0.442232 model2 loss : 0.019653
[12:21:54.946] iteration 28482 : model1 loss : 0.441702 model2 loss : 0.016790
[12:21:55.111] iteration 28483 : model1 loss : 0.441525 model2 loss : 0.017002
[12:21:55.285] iteration 28484 : model1 loss : 0.442184 model2 loss : 0.018155
[12:21:55.452] iteration 28485 : model1 loss : 0.440562 model2 loss : 0.018859
[12:21:55.622] iteration 28486 : model1 loss : 0.439150 model2 loss : 0.018423
[12:21:55.789] iteration 28487 : model1 loss : 0.434918 model2 loss : 0.018833
[12:21:55.963] iteration 28488 : model1 loss : 0.435597 model2 loss : 0.018022
[12:21:56.129] iteration 28489 : model1 loss : 0.438439 model2 loss : 0.018058
[12:21:56.298] iteration 28490 : model1 loss : 0.433702 model2 loss : 0.019120
[12:21:56.466] iteration 28491 : model1 loss : 0.437175 model2 loss : 0.017738
[12:21:56.636] iteration 28492 : model1 loss : 0.441029 model2 loss : 0.019861
[12:21:56.804] iteration 28493 : model1 loss : 0.440674 model2 loss : 0.019151
[12:21:56.971] iteration 28494 : model1 loss : 0.435651 model2 loss : 0.016792
[12:21:57.140] iteration 28495 : model1 loss : 0.442709 model2 loss : 0.018989
[12:21:57.309] iteration 28496 : model1 loss : 0.443829 model2 loss : 0.020672
[12:21:57.478] iteration 28497 : model1 loss : 0.442435 model2 loss : 0.018079
[12:21:57.648] iteration 28498 : model1 loss : 0.440806 model2 loss : 0.018736
[12:21:57.813] iteration 28499 : model1 loss : 0.443490 model2 loss : 0.019065
[12:21:57.983] iteration 28500 : model1 loss : 0.438508 model2 loss : 0.016788
[12:21:58.150] iteration 28501 : model1 loss : 0.442601 model2 loss : 0.020549
[12:21:58.321] iteration 28502 : model1 loss : 0.439989 model2 loss : 0.019608
[12:21:58.488] iteration 28503 : model1 loss : 0.439733 model2 loss : 0.020032
[12:21:58.659] iteration 28504 : model1 loss : 0.439552 model2 loss : 0.018431
[12:21:58.825] iteration 28505 : model1 loss : 0.439938 model2 loss : 0.018626
[12:21:58.994] iteration 28506 : model1 loss : 0.439467 model2 loss : 0.020166
[12:21:59.160] iteration 28507 : model1 loss : 0.441506 model2 loss : 0.020416
[12:21:59.330] iteration 28508 : model1 loss : 0.445629 model2 loss : 0.021090
[12:21:59.502] iteration 28509 : model1 loss : 0.440715 model2 loss : 0.017772
[12:21:59.670] iteration 28510 : model1 loss : 0.442991 model2 loss : 0.019209
[12:21:59.836] iteration 28511 : model1 loss : 0.442097 model2 loss : 0.018878
[12:22:00.003] iteration 28512 : model1 loss : 0.433251 model2 loss : 0.018310
[12:22:01.995] iteration 28513 : model1 loss : 0.440634 model2 loss : 0.019590
[12:22:02.164] iteration 28514 : model1 loss : 0.442051 model2 loss : 0.016399
[12:22:02.334] iteration 28515 : model1 loss : 0.440399 model2 loss : 0.019670
[12:22:02.503] iteration 28516 : model1 loss : 0.437690 model2 loss : 0.020386
[12:22:02.670] iteration 28517 : model1 loss : 0.434874 model2 loss : 0.017106
[12:22:02.835] iteration 28518 : model1 loss : 0.438451 model2 loss : 0.017921
[12:22:03.005] iteration 28519 : model1 loss : 0.439019 model2 loss : 0.019455
[12:22:03.174] iteration 28520 : model1 loss : 0.437700 model2 loss : 0.018102
[12:22:03.342] iteration 28521 : model1 loss : 0.436454 model2 loss : 0.020558
[12:22:03.516] iteration 28522 : model1 loss : 0.441530 model2 loss : 0.020554
[12:22:03.686] iteration 28523 : model1 loss : 0.436615 model2 loss : 0.018977
[12:22:03.856] iteration 28524 : model1 loss : 0.442572 model2 loss : 0.019759
[12:22:04.025] iteration 28525 : model1 loss : 0.443503 model2 loss : 0.019314
[12:22:04.194] iteration 28526 : model1 loss : 0.438902 model2 loss : 0.019095
[12:22:04.364] iteration 28527 : model1 loss : 0.437681 model2 loss : 0.017149
[12:22:04.531] iteration 28528 : model1 loss : 0.438332 model2 loss : 0.017792
[12:22:04.700] iteration 28529 : model1 loss : 0.443066 model2 loss : 0.020151
[12:22:04.868] iteration 28530 : model1 loss : 0.441375 model2 loss : 0.020238
[12:22:05.038] iteration 28531 : model1 loss : 0.437854 model2 loss : 0.016825
[12:22:05.207] iteration 28532 : model1 loss : 0.445756 model2 loss : 0.021470
[12:22:05.378] iteration 28533 : model1 loss : 0.443081 model2 loss : 0.017182
[12:22:05.545] iteration 28534 : model1 loss : 0.442573 model2 loss : 0.017946
[12:22:05.715] iteration 28535 : model1 loss : 0.441153 model2 loss : 0.019369
[12:22:05.882] iteration 28536 : model1 loss : 0.440052 model2 loss : 0.016716
[12:22:06.052] iteration 28537 : model1 loss : 0.438719 model2 loss : 0.019574
[12:22:06.217] iteration 28538 : model1 loss : 0.438226 model2 loss : 0.018143
[12:22:06.391] iteration 28539 : model1 loss : 0.441305 model2 loss : 0.019041
[12:22:06.559] iteration 28540 : model1 loss : 0.439726 model2 loss : 0.017448
[12:22:06.727] iteration 28541 : model1 loss : 0.434914 model2 loss : 0.017185
[12:22:06.893] iteration 28542 : model1 loss : 0.440377 model2 loss : 0.019519
[12:22:07.064] iteration 28543 : model1 loss : 0.445148 model2 loss : 0.020196
[12:22:07.230] iteration 28544 : model1 loss : 0.441722 model2 loss : 0.018878
[12:22:07.403] iteration 28545 : model1 loss : 0.441486 model2 loss : 0.017391
[12:22:09.314] iteration 28546 : model1 loss : 0.438622 model2 loss : 0.016972
[12:22:09.486] iteration 28547 : model1 loss : 0.438130 model2 loss : 0.019505
[12:22:09.656] iteration 28548 : model1 loss : 0.445113 model2 loss : 0.020965
[12:22:09.821] iteration 28549 : model1 loss : 0.439252 model2 loss : 0.017985
[12:22:09.991] iteration 28550 : model1 loss : 0.436167 model2 loss : 0.017362
[12:22:10.155] iteration 28551 : model1 loss : 0.437297 model2 loss : 0.018825
[12:22:10.325] iteration 28552 : model1 loss : 0.439852 model2 loss : 0.018042
[12:22:10.492] iteration 28553 : model1 loss : 0.437230 model2 loss : 0.019712
[12:22:10.664] iteration 28554 : model1 loss : 0.443810 model2 loss : 0.017720
[12:22:10.830] iteration 28555 : model1 loss : 0.438224 model2 loss : 0.019875
[12:22:11.000] iteration 28556 : model1 loss : 0.437899 model2 loss : 0.018770
[12:22:11.167] iteration 28557 : model1 loss : 0.438699 model2 loss : 0.018199
[12:22:11.338] iteration 28558 : model1 loss : 0.443852 model2 loss : 0.020424
[12:22:11.507] iteration 28559 : model1 loss : 0.442289 model2 loss : 0.018050
[12:22:11.677] iteration 28560 : model1 loss : 0.439549 model2 loss : 0.019114
[12:22:11.844] iteration 28561 : model1 loss : 0.445184 model2 loss : 0.018331
[12:22:12.012] iteration 28562 : model1 loss : 0.440460 model2 loss : 0.017460
[12:22:12.179] iteration 28563 : model1 loss : 0.437957 model2 loss : 0.017211
[12:22:12.348] iteration 28564 : model1 loss : 0.436476 model2 loss : 0.015638
[12:22:12.518] iteration 28565 : model1 loss : 0.440236 model2 loss : 0.018097
[12:22:12.686] iteration 28566 : model1 loss : 0.438328 model2 loss : 0.018640
[12:22:12.854] iteration 28567 : model1 loss : 0.440625 model2 loss : 0.017795
[12:22:13.024] iteration 28568 : model1 loss : 0.444265 model2 loss : 0.019468
[12:22:13.194] iteration 28569 : model1 loss : 0.438190 model2 loss : 0.020056
[12:22:13.363] iteration 28570 : model1 loss : 0.441080 model2 loss : 0.018572
[12:22:13.531] iteration 28571 : model1 loss : 0.439215 model2 loss : 0.018706
[12:22:13.698] iteration 28572 : model1 loss : 0.438570 model2 loss : 0.016515
[12:22:13.866] iteration 28573 : model1 loss : 0.437377 model2 loss : 0.017919
[12:22:14.035] iteration 28574 : model1 loss : 0.437899 model2 loss : 0.017711
[12:22:14.202] iteration 28575 : model1 loss : 0.439944 model2 loss : 0.018650
[12:22:14.369] iteration 28576 : model1 loss : 0.444678 model2 loss : 0.020880
[12:22:14.535] iteration 28577 : model1 loss : 0.442206 model2 loss : 0.020199
[12:22:14.703] iteration 28578 : model1 loss : 0.441872 model2 loss : 0.019408
[12:22:16.641] iteration 28579 : model1 loss : 0.439354 model2 loss : 0.017633
[12:22:16.809] iteration 28580 : model1 loss : 0.436389 model2 loss : 0.018975
[12:22:16.979] iteration 28581 : model1 loss : 0.440808 model2 loss : 0.018317
[12:22:17.146] iteration 28582 : model1 loss : 0.441995 model2 loss : 0.018530
[12:22:17.316] iteration 28583 : model1 loss : 0.438046 model2 loss : 0.019176
[12:22:17.485] iteration 28584 : model1 loss : 0.439422 model2 loss : 0.018066
[12:22:17.653] iteration 28585 : model1 loss : 0.438534 model2 loss : 0.018333
[12:22:17.820] iteration 28586 : model1 loss : 0.433878 model2 loss : 0.018413
[12:22:17.990] iteration 28587 : model1 loss : 0.438955 model2 loss : 0.019199
[12:22:18.156] iteration 28588 : model1 loss : 0.434576 model2 loss : 0.017984
[12:22:18.324] iteration 28589 : model1 loss : 0.438784 model2 loss : 0.017031
[12:22:18.491] iteration 28590 : model1 loss : 0.437915 model2 loss : 0.017967
[12:22:18.659] iteration 28591 : model1 loss : 0.439278 model2 loss : 0.019252
[12:22:18.825] iteration 28592 : model1 loss : 0.444267 model2 loss : 0.020702
[12:22:18.996] iteration 28593 : model1 loss : 0.440059 model2 loss : 0.018972
[12:22:19.162] iteration 28594 : model1 loss : 0.445759 model2 loss : 0.020583
[12:22:19.334] iteration 28595 : model1 loss : 0.439702 model2 loss : 0.017209
[12:22:19.503] iteration 28596 : model1 loss : 0.444698 model2 loss : 0.019334
[12:22:19.673] iteration 28597 : model1 loss : 0.440470 model2 loss : 0.020256
[12:22:19.841] iteration 28598 : model1 loss : 0.441536 model2 loss : 0.017547
[12:22:20.011] iteration 28599 : model1 loss : 0.436452 model2 loss : 0.017152
[12:22:20.179] iteration 28600 : model1 loss : 0.440312 model2 loss : 0.019105
[12:22:20.348] iteration 28601 : model1 loss : 0.436947 model2 loss : 0.019798
[12:22:20.518] iteration 28602 : model1 loss : 0.443082 model2 loss : 0.019168
[12:22:20.688] iteration 28603 : model1 loss : 0.439461 model2 loss : 0.021036
[12:22:20.856] iteration 28604 : model1 loss : 0.446416 model2 loss : 0.020022
[12:22:21.026] iteration 28605 : model1 loss : 0.440673 model2 loss : 0.020081
[12:22:21.193] iteration 28606 : model1 loss : 0.438716 model2 loss : 0.018934
[12:22:21.360] iteration 28607 : model1 loss : 0.446068 model2 loss : 0.019528
[12:22:21.531] iteration 28608 : model1 loss : 0.442908 model2 loss : 0.018980
[12:22:21.701] iteration 28609 : model1 loss : 0.440832 model2 loss : 0.017592
[12:22:21.869] iteration 28610 : model1 loss : 0.440565 model2 loss : 0.018628
[12:22:22.037] iteration 28611 : model1 loss : 0.436603 model2 loss : 0.018570
[12:22:23.945] iteration 28612 : model1 loss : 0.444665 model2 loss : 0.020221
[12:22:24.112] iteration 28613 : model1 loss : 0.441833 model2 loss : 0.016762
[12:22:24.283] iteration 28614 : model1 loss : 0.438519 model2 loss : 0.017488
[12:22:24.450] iteration 28615 : model1 loss : 0.439580 model2 loss : 0.018619
[12:22:24.620] iteration 28616 : model1 loss : 0.441929 model2 loss : 0.019586
[12:22:24.786] iteration 28617 : model1 loss : 0.443328 model2 loss : 0.021269
[12:22:24.955] iteration 28618 : model1 loss : 0.437370 model2 loss : 0.017366
[12:22:25.123] iteration 28619 : model1 loss : 0.441639 model2 loss : 0.020031
[12:22:25.292] iteration 28620 : model1 loss : 0.440378 model2 loss : 0.020231
[12:22:25.460] iteration 28621 : model1 loss : 0.438083 model2 loss : 0.020877
[12:22:25.630] iteration 28622 : model1 loss : 0.441622 model2 loss : 0.018207
[12:22:25.797] iteration 28623 : model1 loss : 0.439792 model2 loss : 0.019775
[12:22:25.971] iteration 28624 : model1 loss : 0.441724 model2 loss : 0.019900
[12:22:26.140] iteration 28625 : model1 loss : 0.436761 model2 loss : 0.019029
[12:22:26.308] iteration 28626 : model1 loss : 0.441971 model2 loss : 0.017209
[12:22:26.477] iteration 28627 : model1 loss : 0.440533 model2 loss : 0.019165
[12:22:26.647] iteration 28628 : model1 loss : 0.436860 model2 loss : 0.018155
[12:22:26.814] iteration 28629 : model1 loss : 0.442402 model2 loss : 0.020149
[12:22:26.983] iteration 28630 : model1 loss : 0.443656 model2 loss : 0.019120
[12:22:27.151] iteration 28631 : model1 loss : 0.440864 model2 loss : 0.018109
[12:22:27.319] iteration 28632 : model1 loss : 0.440468 model2 loss : 0.019987
[12:22:27.486] iteration 28633 : model1 loss : 0.442465 model2 loss : 0.018451
[12:22:27.655] iteration 28634 : model1 loss : 0.438643 model2 loss : 0.020029
[12:22:27.823] iteration 28635 : model1 loss : 0.440706 model2 loss : 0.017941
[12:22:27.992] iteration 28636 : model1 loss : 0.434920 model2 loss : 0.019551
[12:22:28.158] iteration 28637 : model1 loss : 0.439274 model2 loss : 0.019798
[12:22:28.327] iteration 28638 : model1 loss : 0.435682 model2 loss : 0.019620
[12:22:28.495] iteration 28639 : model1 loss : 0.437283 model2 loss : 0.018087
[12:22:28.665] iteration 28640 : model1 loss : 0.439770 model2 loss : 0.017322
[12:22:28.831] iteration 28641 : model1 loss : 0.440455 model2 loss : 0.019219
[12:22:29.001] iteration 28642 : model1 loss : 0.438990 model2 loss : 0.017910
[12:22:29.165] iteration 28643 : model1 loss : 0.438482 model2 loss : 0.016824
[12:22:29.334] iteration 28644 : model1 loss : 0.441919 model2 loss : 0.019989
[12:22:31.275] iteration 28645 : model1 loss : 0.442465 model2 loss : 0.019481
[12:22:31.455] iteration 28646 : model1 loss : 0.442456 model2 loss : 0.016891
[12:22:31.626] iteration 28647 : model1 loss : 0.437557 model2 loss : 0.017698
[12:22:31.792] iteration 28648 : model1 loss : 0.436576 model2 loss : 0.020024
[12:22:31.960] iteration 28649 : model1 loss : 0.438361 model2 loss : 0.017437
[12:22:32.131] iteration 28650 : model1 loss : 0.439628 model2 loss : 0.018267
[12:22:32.300] iteration 28651 : model1 loss : 0.440917 model2 loss : 0.019152
[12:22:32.467] iteration 28652 : model1 loss : 0.436940 model2 loss : 0.019249
[12:22:32.640] iteration 28653 : model1 loss : 0.439549 model2 loss : 0.018772
[12:22:32.806] iteration 28654 : model1 loss : 0.445214 model2 loss : 0.020457
[12:22:32.975] iteration 28655 : model1 loss : 0.438296 model2 loss : 0.019344
[12:22:33.142] iteration 28656 : model1 loss : 0.441544 model2 loss : 0.017417
[12:22:33.312] iteration 28657 : model1 loss : 0.440449 model2 loss : 0.018666
[12:22:33.480] iteration 28658 : model1 loss : 0.442396 model2 loss : 0.017281
[12:22:33.651] iteration 28659 : model1 loss : 0.435488 model2 loss : 0.019823
[12:22:33.819] iteration 28660 : model1 loss : 0.442777 model2 loss : 0.018897
[12:22:33.989] iteration 28661 : model1 loss : 0.439925 model2 loss : 0.017971
[12:22:34.158] iteration 28662 : model1 loss : 0.440389 model2 loss : 0.019387
[12:22:34.328] iteration 28663 : model1 loss : 0.439820 model2 loss : 0.017857
[12:22:34.497] iteration 28664 : model1 loss : 0.439337 model2 loss : 0.018008
[12:22:34.669] iteration 28665 : model1 loss : 0.441797 model2 loss : 0.021271
[12:22:34.836] iteration 28666 : model1 loss : 0.441113 model2 loss : 0.018783
[12:22:35.004] iteration 28667 : model1 loss : 0.441610 model2 loss : 0.019804
[12:22:35.171] iteration 28668 : model1 loss : 0.439562 model2 loss : 0.017695
[12:22:35.341] iteration 28669 : model1 loss : 0.440025 model2 loss : 0.018075
[12:22:35.512] iteration 28670 : model1 loss : 0.441520 model2 loss : 0.021078
[12:22:35.683] iteration 28671 : model1 loss : 0.433096 model2 loss : 0.018238
[12:22:35.848] iteration 28672 : model1 loss : 0.441958 model2 loss : 0.019395
[12:22:36.018] iteration 28673 : model1 loss : 0.438634 model2 loss : 0.016493
[12:22:36.184] iteration 28674 : model1 loss : 0.444377 model2 loss : 0.020099
[12:22:36.356] iteration 28675 : model1 loss : 0.442973 model2 loss : 0.018780
[12:22:36.522] iteration 28676 : model1 loss : 0.441237 model2 loss : 0.020700
[12:22:36.692] iteration 28677 : model1 loss : 0.439517 model2 loss : 0.018436
[12:22:38.604] iteration 28678 : model1 loss : 0.444026 model2 loss : 0.017241
[12:22:38.772] iteration 28679 : model1 loss : 0.441954 model2 loss : 0.019069
[12:22:38.942] iteration 28680 : model1 loss : 0.440021 model2 loss : 0.018146
[12:22:39.110] iteration 28681 : model1 loss : 0.440224 model2 loss : 0.021160
[12:22:39.296] iteration 28682 : model1 loss : 0.442612 model2 loss : 0.020231
[12:22:39.465] iteration 28683 : model1 loss : 0.437275 model2 loss : 0.018369
[12:22:39.635] iteration 28684 : model1 loss : 0.439997 model2 loss : 0.017892
[12:22:39.801] iteration 28685 : model1 loss : 0.439466 model2 loss : 0.018362
[12:22:39.972] iteration 28686 : model1 loss : 0.441814 model2 loss : 0.019775
[12:22:40.139] iteration 28687 : model1 loss : 0.441766 model2 loss : 0.018332
[12:22:40.310] iteration 28688 : model1 loss : 0.440771 model2 loss : 0.019560
[12:22:40.476] iteration 28689 : model1 loss : 0.442432 model2 loss : 0.017115
[12:22:40.645] iteration 28690 : model1 loss : 0.446542 model2 loss : 0.020796
[12:22:40.818] iteration 28691 : model1 loss : 0.435940 model2 loss : 0.016746
[12:22:40.990] iteration 28692 : model1 loss : 0.438012 model2 loss : 0.017996
[12:22:41.158] iteration 28693 : model1 loss : 0.436368 model2 loss : 0.018118
[12:22:41.327] iteration 28694 : model1 loss : 0.438360 model2 loss : 0.019364
[12:22:41.496] iteration 28695 : model1 loss : 0.444557 model2 loss : 0.020484
[12:22:41.664] iteration 28696 : model1 loss : 0.439995 model2 loss : 0.020925
[12:22:41.833] iteration 28697 : model1 loss : 0.441970 model2 loss : 0.018196
[12:22:42.002] iteration 28698 : model1 loss : 0.442863 model2 loss : 0.016361
[12:22:42.172] iteration 28699 : model1 loss : 0.440815 model2 loss : 0.019988
[12:22:42.342] iteration 28700 : model1 loss : 0.438471 model2 loss : 0.016692
[12:22:42.511] iteration 28701 : model1 loss : 0.442161 model2 loss : 0.017905
[12:22:42.680] iteration 28702 : model1 loss : 0.439363 model2 loss : 0.016518
[12:22:42.847] iteration 28703 : model1 loss : 0.434649 model2 loss : 0.017032
[12:22:43.018] iteration 28704 : model1 loss : 0.433156 model2 loss : 0.019018
[12:22:43.183] iteration 28705 : model1 loss : 0.443749 model2 loss : 0.020171
[12:22:43.355] iteration 28706 : model1 loss : 0.440894 model2 loss : 0.019139
[12:22:43.522] iteration 28707 : model1 loss : 0.439842 model2 loss : 0.020894
[12:22:43.689] iteration 28708 : model1 loss : 0.438814 model2 loss : 0.019450
[12:22:43.856] iteration 28709 : model1 loss : 0.436637 model2 loss : 0.019944
[12:22:44.025] iteration 28710 : model1 loss : 0.440530 model2 loss : 0.017111
[12:22:45.962] iteration 28711 : model1 loss : 0.437251 model2 loss : 0.016975
[12:22:46.129] iteration 28712 : model1 loss : 0.440770 model2 loss : 0.018354
[12:22:46.299] iteration 28713 : model1 loss : 0.437093 model2 loss : 0.016769
[12:22:46.467] iteration 28714 : model1 loss : 0.441085 model2 loss : 0.018040
[12:22:46.636] iteration 28715 : model1 loss : 0.439978 model2 loss : 0.017257
[12:22:46.804] iteration 28716 : model1 loss : 0.441217 model2 loss : 0.019252
[12:22:46.974] iteration 28717 : model1 loss : 0.441974 model2 loss : 0.018526
[12:22:47.142] iteration 28718 : model1 loss : 0.440923 model2 loss : 0.017761
[12:22:47.317] iteration 28719 : model1 loss : 0.440928 model2 loss : 0.019033
[12:22:47.486] iteration 28720 : model1 loss : 0.440515 model2 loss : 0.016414
[12:22:47.655] iteration 28721 : model1 loss : 0.437029 model2 loss : 0.017644
[12:22:47.823] iteration 28722 : model1 loss : 0.440307 model2 loss : 0.016491
[12:22:47.991] iteration 28723 : model1 loss : 0.436887 model2 loss : 0.019490
[12:22:48.160] iteration 28724 : model1 loss : 0.440016 model2 loss : 0.017650
[12:22:48.330] iteration 28725 : model1 loss : 0.434737 model2 loss : 0.019831
[12:22:48.498] iteration 28726 : model1 loss : 0.440750 model2 loss : 0.018903
[12:22:48.667] iteration 28727 : model1 loss : 0.437986 model2 loss : 0.016702
[12:22:48.836] iteration 28728 : model1 loss : 0.435727 model2 loss : 0.017917
[12:22:49.004] iteration 28729 : model1 loss : 0.441646 model2 loss : 0.021374
[12:22:49.172] iteration 28730 : model1 loss : 0.443317 model2 loss : 0.018900
[12:22:49.342] iteration 28731 : model1 loss : 0.440636 model2 loss : 0.017447
[12:22:49.513] iteration 28732 : model1 loss : 0.436631 model2 loss : 0.018351
[12:22:49.682] iteration 28733 : model1 loss : 0.442193 model2 loss : 0.019039
[12:22:49.851] iteration 28734 : model1 loss : 0.438962 model2 loss : 0.018838
[12:22:50.021] iteration 28735 : model1 loss : 0.440513 model2 loss : 0.019886
[12:22:50.189] iteration 28736 : model1 loss : 0.443718 model2 loss : 0.018908
[12:22:50.358] iteration 28737 : model1 loss : 0.438680 model2 loss : 0.016266
[12:22:50.527] iteration 28738 : model1 loss : 0.440413 model2 loss : 0.019121
[12:22:50.695] iteration 28739 : model1 loss : 0.444305 model2 loss : 0.020331
[12:22:50.862] iteration 28740 : model1 loss : 0.438615 model2 loss : 0.016883
[12:22:51.032] iteration 28741 : model1 loss : 0.443812 model2 loss : 0.018105
[12:22:51.197] iteration 28742 : model1 loss : 0.443346 model2 loss : 0.019734
[12:22:51.366] iteration 28743 : model1 loss : 0.438276 model2 loss : 0.018374
[12:22:53.338] iteration 28744 : model1 loss : 0.441435 model2 loss : 0.019817
[12:22:53.511] iteration 28745 : model1 loss : 0.435124 model2 loss : 0.017186
[12:22:53.681] iteration 28746 : model1 loss : 0.438055 model2 loss : 0.018751
[12:22:53.849] iteration 28747 : model1 loss : 0.439444 model2 loss : 0.018394
[12:22:54.017] iteration 28748 : model1 loss : 0.440551 model2 loss : 0.018503
[12:22:54.186] iteration 28749 : model1 loss : 0.441116 model2 loss : 0.018857
[12:22:54.358] iteration 28750 : model1 loss : 0.439526 model2 loss : 0.018493
[12:22:54.525] iteration 28751 : model1 loss : 0.439239 model2 loss : 0.017181
[12:22:54.695] iteration 28752 : model1 loss : 0.439496 model2 loss : 0.021248
[12:22:54.862] iteration 28753 : model1 loss : 0.443725 model2 loss : 0.020629
[12:22:55.032] iteration 28754 : model1 loss : 0.439818 model2 loss : 0.018185
[12:22:55.199] iteration 28755 : model1 loss : 0.437687 model2 loss : 0.018984
[12:22:55.369] iteration 28756 : model1 loss : 0.440335 model2 loss : 0.017368
[12:22:55.538] iteration 28757 : model1 loss : 0.434921 model2 loss : 0.016856
[12:22:55.708] iteration 28758 : model1 loss : 0.441289 model2 loss : 0.017907
[12:22:55.877] iteration 28759 : model1 loss : 0.437711 model2 loss : 0.019416
[12:22:56.047] iteration 28760 : model1 loss : 0.439146 model2 loss : 0.019004
[12:22:56.214] iteration 28761 : model1 loss : 0.437851 model2 loss : 0.018429
[12:22:56.386] iteration 28762 : model1 loss : 0.443789 model2 loss : 0.018994
[12:22:56.553] iteration 28763 : model1 loss : 0.441576 model2 loss : 0.020368
[12:22:56.723] iteration 28764 : model1 loss : 0.437575 model2 loss : 0.018279
[12:22:56.891] iteration 28765 : model1 loss : 0.439667 model2 loss : 0.018168
[12:22:57.061] iteration 28766 : model1 loss : 0.438974 model2 loss : 0.017024
[12:22:57.229] iteration 28767 : model1 loss : 0.441575 model2 loss : 0.019791
[12:22:57.400] iteration 28768 : model1 loss : 0.435647 model2 loss : 0.017163
[12:22:57.569] iteration 28769 : model1 loss : 0.442850 model2 loss : 0.019696
[12:22:57.737] iteration 28770 : model1 loss : 0.441894 model2 loss : 0.018060
[12:22:57.906] iteration 28771 : model1 loss : 0.441535 model2 loss : 0.018382
[12:22:58.075] iteration 28772 : model1 loss : 0.437697 model2 loss : 0.017548
[12:22:58.243] iteration 28773 : model1 loss : 0.445770 model2 loss : 0.019140
[12:22:58.415] iteration 28774 : model1 loss : 0.440520 model2 loss : 0.018055
[12:22:58.580] iteration 28775 : model1 loss : 0.442459 model2 loss : 0.019546
[12:22:58.749] iteration 28776 : model1 loss : 0.440952 model2 loss : 0.016957
[12:23:00.697] iteration 28777 : model1 loss : 0.437961 model2 loss : 0.018001
[12:23:00.864] iteration 28778 : model1 loss : 0.438265 model2 loss : 0.018976
[12:23:01.033] iteration 28779 : model1 loss : 0.444332 model2 loss : 0.018505
[12:23:01.202] iteration 28780 : model1 loss : 0.443594 model2 loss : 0.018105
[12:23:01.374] iteration 28781 : model1 loss : 0.442442 model2 loss : 0.019506
[12:23:01.544] iteration 28782 : model1 loss : 0.441274 model2 loss : 0.019414
[12:23:01.715] iteration 28783 : model1 loss : 0.439652 model2 loss : 0.017527
[12:23:01.883] iteration 28784 : model1 loss : 0.440598 model2 loss : 0.020391
[12:23:02.054] iteration 28785 : model1 loss : 0.440318 model2 loss : 0.017083
[12:23:02.223] iteration 28786 : model1 loss : 0.443438 model2 loss : 0.019630
[12:23:02.393] iteration 28787 : model1 loss : 0.439908 model2 loss : 0.020072
[12:23:02.559] iteration 28788 : model1 loss : 0.435240 model2 loss : 0.016184
[12:23:02.731] iteration 28789 : model1 loss : 0.440205 model2 loss : 0.020200
[12:23:02.898] iteration 28790 : model1 loss : 0.433809 model2 loss : 0.017496
[12:23:03.070] iteration 28791 : model1 loss : 0.442716 model2 loss : 0.019339
[12:23:03.239] iteration 28792 : model1 loss : 0.436872 model2 loss : 0.017004
[12:23:03.435] iteration 28793 : model1 loss : 0.436453 model2 loss : 0.016853
[12:23:03.603] iteration 28794 : model1 loss : 0.436099 model2 loss : 0.017607
[12:23:03.773] iteration 28795 : model1 loss : 0.434775 model2 loss : 0.019357
[12:23:03.940] iteration 28796 : model1 loss : 0.443011 model2 loss : 0.020663
[12:23:04.109] iteration 28797 : model1 loss : 0.444914 model2 loss : 0.019091
[12:23:04.276] iteration 28798 : model1 loss : 0.442329 model2 loss : 0.019227
[12:23:04.448] iteration 28799 : model1 loss : 0.440127 model2 loss : 0.017545
[12:23:04.616] iteration 28800 : model1 loss : 0.441991 model2 loss : 0.018605
[12:23:04.786] iteration 28801 : model1 loss : 0.437666 model2 loss : 0.018541
[12:23:04.953] iteration 28802 : model1 loss : 0.442326 model2 loss : 0.019623
[12:23:05.120] iteration 28803 : model1 loss : 0.445140 model2 loss : 0.020479
[12:23:05.287] iteration 28804 : model1 loss : 0.443177 model2 loss : 0.017116
[12:23:05.461] iteration 28805 : model1 loss : 0.441470 model2 loss : 0.019585
[12:23:05.628] iteration 28806 : model1 loss : 0.439520 model2 loss : 0.019060
[12:23:05.798] iteration 28807 : model1 loss : 0.437108 model2 loss : 0.016135
[12:23:05.966] iteration 28808 : model1 loss : 0.438334 model2 loss : 0.017257
[12:23:06.138] iteration 28809 : model1 loss : 0.438261 model2 loss : 0.017157
[12:23:08.049] iteration 28810 : model1 loss : 0.443053 model2 loss : 0.019584
[12:23:08.218] iteration 28811 : model1 loss : 0.439044 model2 loss : 0.017974
[12:23:08.388] iteration 28812 : model1 loss : 0.439101 model2 loss : 0.017742
[12:23:08.554] iteration 28813 : model1 loss : 0.439839 model2 loss : 0.019338
[12:23:08.722] iteration 28814 : model1 loss : 0.437556 model2 loss : 0.018576
[12:23:08.891] iteration 28815 : model1 loss : 0.436863 model2 loss : 0.018260
[12:23:09.061] iteration 28816 : model1 loss : 0.441321 model2 loss : 0.019162
[12:23:09.229] iteration 28817 : model1 loss : 0.443618 model2 loss : 0.019041
[12:23:09.398] iteration 28818 : model1 loss : 0.436827 model2 loss : 0.019059
[12:23:09.565] iteration 28819 : model1 loss : 0.439784 model2 loss : 0.018833
[12:23:09.734] iteration 28820 : model1 loss : 0.441083 model2 loss : 0.018927
[12:23:09.900] iteration 28821 : model1 loss : 0.440728 model2 loss : 0.019680
[12:23:10.070] iteration 28822 : model1 loss : 0.441901 model2 loss : 0.019027
[12:23:10.237] iteration 28823 : model1 loss : 0.442129 model2 loss : 0.018759
[12:23:10.408] iteration 28824 : model1 loss : 0.443660 model2 loss : 0.020332
[12:23:10.575] iteration 28825 : model1 loss : 0.440112 model2 loss : 0.017813
[12:23:10.744] iteration 28826 : model1 loss : 0.441308 model2 loss : 0.018786
[12:23:10.912] iteration 28827 : model1 loss : 0.440634 model2 loss : 0.018611
[12:23:11.080] iteration 28828 : model1 loss : 0.439505 model2 loss : 0.019785
[12:23:11.247] iteration 28829 : model1 loss : 0.444253 model2 loss : 0.018769
[12:23:11.417] iteration 28830 : model1 loss : 0.441348 model2 loss : 0.017737
[12:23:11.583] iteration 28831 : model1 loss : 0.439932 model2 loss : 0.017644
[12:23:11.751] iteration 28832 : model1 loss : 0.439300 model2 loss : 0.019512
[12:23:11.919] iteration 28833 : model1 loss : 0.438383 model2 loss : 0.018465
[12:23:12.088] iteration 28834 : model1 loss : 0.439312 model2 loss : 0.017859
[12:23:12.255] iteration 28835 : model1 loss : 0.441305 model2 loss : 0.020082
[12:23:12.425] iteration 28836 : model1 loss : 0.439824 model2 loss : 0.018419
[12:23:12.593] iteration 28837 : model1 loss : 0.437446 model2 loss : 0.019712
[12:23:12.762] iteration 28838 : model1 loss : 0.438433 model2 loss : 0.018083
[12:23:12.930] iteration 28839 : model1 loss : 0.440856 model2 loss : 0.019822
[12:23:13.100] iteration 28840 : model1 loss : 0.438957 model2 loss : 0.018374
[12:23:13.267] iteration 28841 : model1 loss : 0.434993 model2 loss : 0.017537
[12:23:13.437] iteration 28842 : model1 loss : 0.440345 model2 loss : 0.019812
[12:23:15.352] iteration 28843 : model1 loss : 0.440707 model2 loss : 0.018924
[12:23:15.522] iteration 28844 : model1 loss : 0.442988 model2 loss : 0.019232
[12:23:15.694] iteration 28845 : model1 loss : 0.437129 model2 loss : 0.017373
[12:23:15.861] iteration 28846 : model1 loss : 0.436416 model2 loss : 0.018525
[12:23:16.031] iteration 28847 : model1 loss : 0.446908 model2 loss : 0.020203
[12:23:16.199] iteration 28848 : model1 loss : 0.436354 model2 loss : 0.017744
[12:23:16.370] iteration 28849 : model1 loss : 0.442581 model2 loss : 0.019399
[12:23:16.547] iteration 28850 : model1 loss : 0.441867 model2 loss : 0.018161
[12:23:16.717] iteration 28851 : model1 loss : 0.442817 model2 loss : 0.019602
[12:23:16.883] iteration 28852 : model1 loss : 0.441338 model2 loss : 0.019364
[12:23:17.053] iteration 28853 : model1 loss : 0.441512 model2 loss : 0.019015
[12:23:17.223] iteration 28854 : model1 loss : 0.437563 model2 loss : 0.018825
[12:23:17.394] iteration 28855 : model1 loss : 0.438044 model2 loss : 0.017734
[12:23:17.560] iteration 28856 : model1 loss : 0.440080 model2 loss : 0.019207
[12:23:17.731] iteration 28857 : model1 loss : 0.436064 model2 loss : 0.017981
[12:23:17.897] iteration 28858 : model1 loss : 0.442265 model2 loss : 0.019078
[12:23:18.066] iteration 28859 : model1 loss : 0.435162 model2 loss : 0.016631
[12:23:18.235] iteration 28860 : model1 loss : 0.435769 model2 loss : 0.018896
[12:23:18.406] iteration 28861 : model1 loss : 0.437004 model2 loss : 0.020927
[12:23:18.574] iteration 28862 : model1 loss : 0.443884 model2 loss : 0.019470
[12:23:18.745] iteration 28863 : model1 loss : 0.438520 model2 loss : 0.017578
[12:23:18.913] iteration 28864 : model1 loss : 0.439272 model2 loss : 0.019825
[12:23:19.081] iteration 28865 : model1 loss : 0.438435 model2 loss : 0.017358
[12:23:19.251] iteration 28866 : model1 loss : 0.440725 model2 loss : 0.019797
[12:23:19.420] iteration 28867 : model1 loss : 0.444340 model2 loss : 0.018591
[12:23:19.588] iteration 28868 : model1 loss : 0.436011 model2 loss : 0.019191
[12:23:19.759] iteration 28869 : model1 loss : 0.445325 model2 loss : 0.020266
[12:23:19.926] iteration 28870 : model1 loss : 0.443743 model2 loss : 0.021443
[12:23:20.095] iteration 28871 : model1 loss : 0.436721 model2 loss : 0.019390
[12:23:20.262] iteration 28872 : model1 loss : 0.443456 model2 loss : 0.019807
[12:23:20.434] iteration 28873 : model1 loss : 0.443823 model2 loss : 0.019505
[12:23:20.599] iteration 28874 : model1 loss : 0.440607 model2 loss : 0.019324
[12:23:20.767] iteration 28875 : model1 loss : 0.439875 model2 loss : 0.017969
[12:23:22.827] iteration 28876 : model1 loss : 0.444072 model2 loss : 0.020832
[12:23:22.997] iteration 28877 : model1 loss : 0.441312 model2 loss : 0.020523
[12:23:23.170] iteration 28878 : model1 loss : 0.433768 model2 loss : 0.018441
[12:23:23.339] iteration 28879 : model1 loss : 0.445162 model2 loss : 0.019162
[12:23:23.515] iteration 28880 : model1 loss : 0.437507 model2 loss : 0.018417
[12:23:23.686] iteration 28881 : model1 loss : 0.437224 model2 loss : 0.018001
[12:23:23.858] iteration 28882 : model1 loss : 0.440737 model2 loss : 0.018535
[12:23:24.029] iteration 28883 : model1 loss : 0.436351 model2 loss : 0.017479
[12:23:24.201] iteration 28884 : model1 loss : 0.439956 model2 loss : 0.020558
[12:23:24.371] iteration 28885 : model1 loss : 0.444299 model2 loss : 0.021911
[12:23:24.545] iteration 28886 : model1 loss : 0.440834 model2 loss : 0.018781
[12:23:24.717] iteration 28887 : model1 loss : 0.442356 model2 loss : 0.019189
[12:23:24.888] iteration 28888 : model1 loss : 0.439279 model2 loss : 0.016428
[12:23:25.059] iteration 28889 : model1 loss : 0.442756 model2 loss : 0.017248
[12:23:25.230] iteration 28890 : model1 loss : 0.436656 model2 loss : 0.017143
[12:23:25.401] iteration 28891 : model1 loss : 0.440938 model2 loss : 0.018358
[12:23:25.580] iteration 28892 : model1 loss : 0.442068 model2 loss : 0.019725
[12:23:25.749] iteration 28893 : model1 loss : 0.435460 model2 loss : 0.020690
[12:23:25.921] iteration 28894 : model1 loss : 0.437615 model2 loss : 0.017852
[12:23:26.090] iteration 28895 : model1 loss : 0.441180 model2 loss : 0.017001
[12:23:26.261] iteration 28896 : model1 loss : 0.441720 model2 loss : 0.019457
[12:23:26.431] iteration 28897 : model1 loss : 0.438566 model2 loss : 0.018392
[12:23:26.601] iteration 28898 : model1 loss : 0.439734 model2 loss : 0.016770
[12:23:26.769] iteration 28899 : model1 loss : 0.441370 model2 loss : 0.018789
[12:23:26.941] iteration 28900 : model1 loss : 0.439450 model2 loss : 0.018894
[12:23:27.110] iteration 28901 : model1 loss : 0.440478 model2 loss : 0.019919
[12:23:27.281] iteration 28902 : model1 loss : 0.442134 model2 loss : 0.021147
[12:23:27.449] iteration 28903 : model1 loss : 0.440565 model2 loss : 0.018122
[12:23:27.621] iteration 28904 : model1 loss : 0.440895 model2 loss : 0.019145
[12:23:27.789] iteration 28905 : model1 loss : 0.443934 model2 loss : 0.016885
[12:23:27.959] iteration 28906 : model1 loss : 0.442216 model2 loss : 0.019073
[12:23:28.127] iteration 28907 : model1 loss : 0.436728 model2 loss : 0.018559
[12:23:28.296] iteration 28908 : model1 loss : 0.438019 model2 loss : 0.017212
[12:23:30.218] iteration 28909 : model1 loss : 0.443347 model2 loss : 0.018749
[12:23:30.387] iteration 28910 : model1 loss : 0.442728 model2 loss : 0.019593
[12:23:30.560] iteration 28911 : model1 loss : 0.435718 model2 loss : 0.017490
[12:23:30.728] iteration 28912 : model1 loss : 0.435873 model2 loss : 0.017268
[12:23:30.900] iteration 28913 : model1 loss : 0.442410 model2 loss : 0.019499
[12:23:31.067] iteration 28914 : model1 loss : 0.439085 model2 loss : 0.016716
[12:23:31.241] iteration 28915 : model1 loss : 0.443227 model2 loss : 0.022431
[12:23:31.411] iteration 28916 : model1 loss : 0.437668 model2 loss : 0.019485
[12:23:31.580] iteration 28917 : model1 loss : 0.439743 model2 loss : 0.019707
[12:23:31.749] iteration 28918 : model1 loss : 0.441274 model2 loss : 0.020788
[12:23:31.921] iteration 28919 : model1 loss : 0.440223 model2 loss : 0.018019
[12:23:32.089] iteration 28920 : model1 loss : 0.445234 model2 loss : 0.022180
[12:23:32.261] iteration 28921 : model1 loss : 0.439426 model2 loss : 0.018940
[12:23:32.430] iteration 28922 : model1 loss : 0.442064 model2 loss : 0.017573
[12:23:32.600] iteration 28923 : model1 loss : 0.441829 model2 loss : 0.019368
[12:23:32.768] iteration 28924 : model1 loss : 0.444667 model2 loss : 0.021571
[12:23:32.939] iteration 28925 : model1 loss : 0.437955 model2 loss : 0.018007
[12:23:33.108] iteration 28926 : model1 loss : 0.441853 model2 loss : 0.019149
[12:23:33.281] iteration 28927 : model1 loss : 0.440716 model2 loss : 0.017267
[12:23:33.450] iteration 28928 : model1 loss : 0.440200 model2 loss : 0.018475
[12:23:33.620] iteration 28929 : model1 loss : 0.443355 model2 loss : 0.020975
[12:23:33.790] iteration 28930 : model1 loss : 0.434058 model2 loss : 0.018220
[12:23:33.962] iteration 28931 : model1 loss : 0.435170 model2 loss : 0.019295
[12:23:34.132] iteration 28932 : model1 loss : 0.439809 model2 loss : 0.018947
[12:23:34.301] iteration 28933 : model1 loss : 0.443330 model2 loss : 0.019285
[12:23:34.469] iteration 28934 : model1 loss : 0.436018 model2 loss : 0.015853
[12:23:34.639] iteration 28935 : model1 loss : 0.434949 model2 loss : 0.018188
[12:23:34.809] iteration 28936 : model1 loss : 0.441714 model2 loss : 0.018779
[12:23:34.983] iteration 28937 : model1 loss : 0.442752 model2 loss : 0.018935
[12:23:35.155] iteration 28938 : model1 loss : 0.440298 model2 loss : 0.017431
[12:23:35.328] iteration 28939 : model1 loss : 0.440318 model2 loss : 0.020020
[12:23:35.496] iteration 28940 : model1 loss : 0.436166 model2 loss : 0.018105
[12:23:35.668] iteration 28941 : model1 loss : 0.442938 model2 loss : 0.018699
[12:23:37.585] iteration 28942 : model1 loss : 0.437667 model2 loss : 0.018858
[12:23:37.761] iteration 28943 : model1 loss : 0.440388 model2 loss : 0.017836
[12:23:37.932] iteration 28944 : model1 loss : 0.440410 model2 loss : 0.017925
[12:23:38.104] iteration 28945 : model1 loss : 0.443611 model2 loss : 0.018893
[12:23:38.275] iteration 28946 : model1 loss : 0.440534 model2 loss : 0.018596
[12:23:38.447] iteration 28947 : model1 loss : 0.443224 model2 loss : 0.018137
[12:23:38.619] iteration 28948 : model1 loss : 0.441318 model2 loss : 0.020086
[12:23:38.789] iteration 28949 : model1 loss : 0.443536 model2 loss : 0.019081
[12:23:38.962] iteration 28950 : model1 loss : 0.439096 model2 loss : 0.017729
[12:23:39.131] iteration 28951 : model1 loss : 0.436612 model2 loss : 0.016960
[12:23:39.302] iteration 28952 : model1 loss : 0.436983 model2 loss : 0.019561
[12:23:39.468] iteration 28953 : model1 loss : 0.442778 model2 loss : 0.019598
[12:23:39.638] iteration 28954 : model1 loss : 0.439812 model2 loss : 0.017676
[12:23:39.808] iteration 28955 : model1 loss : 0.444515 model2 loss : 0.020713
[12:23:39.980] iteration 28956 : model1 loss : 0.442549 model2 loss : 0.018718
[12:23:40.149] iteration 28957 : model1 loss : 0.442589 model2 loss : 0.018108
[12:23:40.319] iteration 28958 : model1 loss : 0.439835 model2 loss : 0.017742
[12:23:40.486] iteration 28959 : model1 loss : 0.436249 model2 loss : 0.016760
[12:23:40.660] iteration 28960 : model1 loss : 0.435828 model2 loss : 0.017426
[12:23:40.829] iteration 28961 : model1 loss : 0.440329 model2 loss : 0.017360
[12:23:41.001] iteration 28962 : model1 loss : 0.436500 model2 loss : 0.017028
[12:23:41.169] iteration 28963 : model1 loss : 0.443399 model2 loss : 0.021691
[12:23:41.340] iteration 28964 : model1 loss : 0.440942 model2 loss : 0.016994
[12:23:41.514] iteration 28965 : model1 loss : 0.441710 model2 loss : 0.018395
[12:23:41.685] iteration 28966 : model1 loss : 0.440841 model2 loss : 0.018882
[12:23:41.857] iteration 28967 : model1 loss : 0.434828 model2 loss : 0.018296
[12:23:42.028] iteration 28968 : model1 loss : 0.441340 model2 loss : 0.016011
[12:23:42.198] iteration 28969 : model1 loss : 0.441733 model2 loss : 0.020596
[12:23:42.370] iteration 28970 : model1 loss : 0.436559 model2 loss : 0.018648
[12:23:42.541] iteration 28971 : model1 loss : 0.438145 model2 loss : 0.017283
[12:23:42.711] iteration 28972 : model1 loss : 0.439454 model2 loss : 0.018288
[12:23:42.880] iteration 28973 : model1 loss : 0.438400 model2 loss : 0.018333
[12:23:43.049] iteration 28974 : model1 loss : 0.438790 model2 loss : 0.019920
[12:23:44.957] iteration 28975 : model1 loss : 0.439151 model2 loss : 0.020613
[12:23:45.127] iteration 28976 : model1 loss : 0.440410 model2 loss : 0.018715
[12:23:45.298] iteration 28977 : model1 loss : 0.439755 model2 loss : 0.018697
[12:23:45.470] iteration 28978 : model1 loss : 0.440659 model2 loss : 0.019312
[12:23:45.642] iteration 28979 : model1 loss : 0.439739 model2 loss : 0.020700
[12:23:45.809] iteration 28980 : model1 loss : 0.435428 model2 loss : 0.019117
[12:23:45.985] iteration 28981 : model1 loss : 0.446333 model2 loss : 0.018757
[12:23:46.155] iteration 28982 : model1 loss : 0.440757 model2 loss : 0.019076
[12:23:46.326] iteration 28983 : model1 loss : 0.441692 model2 loss : 0.018871
[12:23:46.494] iteration 28984 : model1 loss : 0.441589 model2 loss : 0.019347
[12:23:46.665] iteration 28985 : model1 loss : 0.441702 model2 loss : 0.017358
[12:23:46.835] iteration 28986 : model1 loss : 0.442687 model2 loss : 0.018163
[12:23:47.006] iteration 28987 : model1 loss : 0.439067 model2 loss : 0.018465
[12:23:47.174] iteration 28988 : model1 loss : 0.446684 model2 loss : 0.021323
[12:23:47.347] iteration 28989 : model1 loss : 0.442329 model2 loss : 0.019078
[12:23:47.518] iteration 28990 : model1 loss : 0.444558 model2 loss : 0.019625
[12:23:47.689] iteration 28991 : model1 loss : 0.434581 model2 loss : 0.017626
[12:23:47.858] iteration 28992 : model1 loss : 0.436227 model2 loss : 0.017439
[12:23:48.031] iteration 28993 : model1 loss : 0.438139 model2 loss : 0.018765
[12:23:48.201] iteration 28994 : model1 loss : 0.440143 model2 loss : 0.019248
[12:23:48.373] iteration 28995 : model1 loss : 0.441591 model2 loss : 0.020272
[12:23:48.543] iteration 28996 : model1 loss : 0.441390 model2 loss : 0.017713
[12:23:48.712] iteration 28997 : model1 loss : 0.442169 model2 loss : 0.020402
[12:23:48.882] iteration 28998 : model1 loss : 0.436889 model2 loss : 0.015624
[12:23:49.054] iteration 28999 : model1 loss : 0.440012 model2 loss : 0.019016
[12:23:49.227] iteration 29000 : model1 loss : 0.442345 model2 loss : 0.018136
[12:23:57.536] iteration 29000 : model1_mean_dice : 0.902068 model1_mean_hd95 : 3.274319
[12:24:05.837] iteration 29000 : model2_mean_dice : 0.899183 model2_mean_hd95 : 1.862720
[12:24:06.015] iteration 29001 : model1 loss : 0.437569 model2 loss : 0.015767
[12:24:06.183] iteration 29002 : model1 loss : 0.440466 model2 loss : 0.016270
[12:24:06.353] iteration 29003 : model1 loss : 0.438302 model2 loss : 0.018762
[12:24:06.524] iteration 29004 : model1 loss : 0.439215 model2 loss : 0.020553
[12:24:06.690] iteration 29005 : model1 loss : 0.436851 model2 loss : 0.017976
[12:24:06.857] iteration 29006 : model1 loss : 0.439947 model2 loss : 0.018464
[12:24:07.022] iteration 29007 : model1 loss : 0.439123 model2 loss : 0.019114
[12:24:08.931] iteration 29008 : model1 loss : 0.444550 model2 loss : 0.019435
[12:24:09.104] iteration 29009 : model1 loss : 0.443503 model2 loss : 0.021979
[12:24:09.275] iteration 29010 : model1 loss : 0.446715 model2 loss : 0.020351
[12:24:09.440] iteration 29011 : model1 loss : 0.440164 model2 loss : 0.018217
[12:24:09.607] iteration 29012 : model1 loss : 0.440444 model2 loss : 0.018048
[12:24:09.770] iteration 29013 : model1 loss : 0.437610 model2 loss : 0.017231
[12:24:09.940] iteration 29014 : model1 loss : 0.443757 model2 loss : 0.018527
[12:24:10.105] iteration 29015 : model1 loss : 0.437969 model2 loss : 0.019063
[12:24:10.275] iteration 29016 : model1 loss : 0.438574 model2 loss : 0.018297
[12:24:10.444] iteration 29017 : model1 loss : 0.440976 model2 loss : 0.020587
[12:24:10.613] iteration 29018 : model1 loss : 0.441277 model2 loss : 0.019368
[12:24:10.780] iteration 29019 : model1 loss : 0.434867 model2 loss : 0.020457
[12:24:10.949] iteration 29020 : model1 loss : 0.440830 model2 loss : 0.018315
[12:24:11.116] iteration 29021 : model1 loss : 0.437987 model2 loss : 0.018694
[12:24:11.285] iteration 29022 : model1 loss : 0.437773 model2 loss : 0.018343
[12:24:11.451] iteration 29023 : model1 loss : 0.440971 model2 loss : 0.019187
[12:24:11.618] iteration 29024 : model1 loss : 0.441710 model2 loss : 0.015705
[12:24:11.785] iteration 29025 : model1 loss : 0.438547 model2 loss : 0.017464
[12:24:11.956] iteration 29026 : model1 loss : 0.439255 model2 loss : 0.017791
[12:24:12.124] iteration 29027 : model1 loss : 0.441660 model2 loss : 0.020155
[12:24:12.291] iteration 29028 : model1 loss : 0.440465 model2 loss : 0.019942
[12:24:12.458] iteration 29029 : model1 loss : 0.440048 model2 loss : 0.017926
[12:24:12.625] iteration 29030 : model1 loss : 0.441872 model2 loss : 0.019197
[12:24:12.791] iteration 29031 : model1 loss : 0.440575 model2 loss : 0.016646
[12:24:12.960] iteration 29032 : model1 loss : 0.443909 model2 loss : 0.020055
[12:24:13.129] iteration 29033 : model1 loss : 0.441159 model2 loss : 0.019435
[12:24:13.298] iteration 29034 : model1 loss : 0.434903 model2 loss : 0.018385
[12:24:13.468] iteration 29035 : model1 loss : 0.434970 model2 loss : 0.018003
[12:24:13.635] iteration 29036 : model1 loss : 0.440242 model2 loss : 0.021608
[12:24:13.802] iteration 29037 : model1 loss : 0.443037 model2 loss : 0.017851
[12:24:13.970] iteration 29038 : model1 loss : 0.434520 model2 loss : 0.017525
[12:24:14.135] iteration 29039 : model1 loss : 0.436904 model2 loss : 0.018651
[12:24:14.304] iteration 29040 : model1 loss : 0.446301 model2 loss : 0.021592
[12:24:16.256] iteration 29041 : model1 loss : 0.441255 model2 loss : 0.016551
[12:24:16.425] iteration 29042 : model1 loss : 0.443730 model2 loss : 0.021257
[12:24:16.593] iteration 29043 : model1 loss : 0.439095 model2 loss : 0.016644
[12:24:16.760] iteration 29044 : model1 loss : 0.443903 model2 loss : 0.018889
[12:24:16.928] iteration 29045 : model1 loss : 0.440493 model2 loss : 0.019760
[12:24:17.095] iteration 29046 : model1 loss : 0.438835 model2 loss : 0.019237
[12:24:17.265] iteration 29047 : model1 loss : 0.440423 model2 loss : 0.018445
[12:24:17.432] iteration 29048 : model1 loss : 0.438492 model2 loss : 0.017532
[12:24:17.602] iteration 29049 : model1 loss : 0.445449 model2 loss : 0.018873
[12:24:17.769] iteration 29050 : model1 loss : 0.441592 model2 loss : 0.017586
[12:24:17.938] iteration 29051 : model1 loss : 0.442058 model2 loss : 0.019818
[12:24:18.105] iteration 29052 : model1 loss : 0.436600 model2 loss : 0.018334
[12:24:18.273] iteration 29053 : model1 loss : 0.440691 model2 loss : 0.018544
[12:24:18.439] iteration 29054 : model1 loss : 0.441041 model2 loss : 0.019331
[12:24:18.609] iteration 29055 : model1 loss : 0.437638 model2 loss : 0.018197
[12:24:18.775] iteration 29056 : model1 loss : 0.440403 model2 loss : 0.017184
[12:24:18.944] iteration 29057 : model1 loss : 0.443591 model2 loss : 0.019750
[12:24:19.110] iteration 29058 : model1 loss : 0.442294 model2 loss : 0.018851
[12:24:19.279] iteration 29059 : model1 loss : 0.437736 model2 loss : 0.017207
[12:24:19.446] iteration 29060 : model1 loss : 0.438103 model2 loss : 0.019442
[12:24:19.615] iteration 29061 : model1 loss : 0.439853 model2 loss : 0.018392
[12:24:19.784] iteration 29062 : model1 loss : 0.435443 model2 loss : 0.018170
[12:24:19.951] iteration 29063 : model1 loss : 0.440855 model2 loss : 0.017062
[12:24:20.117] iteration 29064 : model1 loss : 0.435742 model2 loss : 0.016815
[12:24:20.284] iteration 29065 : model1 loss : 0.436830 model2 loss : 0.018072
[12:24:20.452] iteration 29066 : model1 loss : 0.440031 model2 loss : 0.018573
[12:24:20.622] iteration 29067 : model1 loss : 0.439556 model2 loss : 0.018832
[12:24:20.788] iteration 29068 : model1 loss : 0.441647 model2 loss : 0.018907
[12:24:20.960] iteration 29069 : model1 loss : 0.440231 model2 loss : 0.019093
[12:24:21.126] iteration 29070 : model1 loss : 0.441467 model2 loss : 0.019250
[12:24:21.297] iteration 29071 : model1 loss : 0.436528 model2 loss : 0.017301
[12:24:21.463] iteration 29072 : model1 loss : 0.443899 model2 loss : 0.019646
[12:24:21.654] iteration 29073 : model1 loss : 0.438709 model2 loss : 0.018671
[12:24:23.583] iteration 29074 : model1 loss : 0.440378 model2 loss : 0.019189
[12:24:23.749] iteration 29075 : model1 loss : 0.441119 model2 loss : 0.018536
[12:24:23.918] iteration 29076 : model1 loss : 0.437777 model2 loss : 0.018025
[12:24:24.086] iteration 29077 : model1 loss : 0.438466 model2 loss : 0.017757
[12:24:24.257] iteration 29078 : model1 loss : 0.438685 model2 loss : 0.017850
[12:24:24.425] iteration 29079 : model1 loss : 0.442954 model2 loss : 0.020649
[12:24:24.594] iteration 29080 : model1 loss : 0.441133 model2 loss : 0.019469
[12:24:24.764] iteration 29081 : model1 loss : 0.441976 model2 loss : 0.018144
[12:24:24.933] iteration 29082 : model1 loss : 0.437669 model2 loss : 0.019588
[12:24:25.101] iteration 29083 : model1 loss : 0.437666 model2 loss : 0.019770
[12:24:25.270] iteration 29084 : model1 loss : 0.439068 model2 loss : 0.018032
[12:24:25.438] iteration 29085 : model1 loss : 0.439782 model2 loss : 0.019369
[12:24:25.607] iteration 29086 : model1 loss : 0.442827 model2 loss : 0.017601
[12:24:25.776] iteration 29087 : model1 loss : 0.440099 model2 loss : 0.016955
[12:24:25.949] iteration 29088 : model1 loss : 0.441028 model2 loss : 0.017115
[12:24:26.116] iteration 29089 : model1 loss : 0.441415 model2 loss : 0.018736
[12:24:26.288] iteration 29090 : model1 loss : 0.441252 model2 loss : 0.019655
[12:24:26.455] iteration 29091 : model1 loss : 0.444599 model2 loss : 0.019831
[12:24:26.623] iteration 29092 : model1 loss : 0.439496 model2 loss : 0.019509
[12:24:26.792] iteration 29093 : model1 loss : 0.439726 model2 loss : 0.018401
[12:24:26.961] iteration 29094 : model1 loss : 0.440158 model2 loss : 0.016624
[12:24:27.128] iteration 29095 : model1 loss : 0.440489 model2 loss : 0.016037
[12:24:27.300] iteration 29096 : model1 loss : 0.441040 model2 loss : 0.019765
[12:24:27.466] iteration 29097 : model1 loss : 0.442420 model2 loss : 0.018066
[12:24:27.635] iteration 29098 : model1 loss : 0.439981 model2 loss : 0.018899
[12:24:27.805] iteration 29099 : model1 loss : 0.441232 model2 loss : 0.018020
[12:24:27.975] iteration 29100 : model1 loss : 0.439467 model2 loss : 0.018322
[12:24:28.141] iteration 29101 : model1 loss : 0.438235 model2 loss : 0.017153
[12:24:28.314] iteration 29102 : model1 loss : 0.437615 model2 loss : 0.016124
[12:24:28.482] iteration 29103 : model1 loss : 0.438920 model2 loss : 0.017437
[12:24:28.651] iteration 29104 : model1 loss : 0.443528 model2 loss : 0.019018
[12:24:28.819] iteration 29105 : model1 loss : 0.436082 model2 loss : 0.020569
[12:24:28.984] iteration 29106 : model1 loss : 0.439235 model2 loss : 0.019944
[12:24:30.907] iteration 29107 : model1 loss : 0.439271 model2 loss : 0.016225
[12:24:31.078] iteration 29108 : model1 loss : 0.440706 model2 loss : 0.018632
[12:24:31.248] iteration 29109 : model1 loss : 0.443027 model2 loss : 0.019530
[12:24:31.415] iteration 29110 : model1 loss : 0.440704 model2 loss : 0.018382
[12:24:31.583] iteration 29111 : model1 loss : 0.435786 model2 loss : 0.016119
[12:24:31.751] iteration 29112 : model1 loss : 0.435908 model2 loss : 0.018841
[12:24:31.923] iteration 29113 : model1 loss : 0.440674 model2 loss : 0.019288
[12:24:32.092] iteration 29114 : model1 loss : 0.438084 model2 loss : 0.016702
[12:24:32.259] iteration 29115 : model1 loss : 0.437525 model2 loss : 0.017543
[12:24:32.426] iteration 29116 : model1 loss : 0.442481 model2 loss : 0.018505
[12:24:32.598] iteration 29117 : model1 loss : 0.438661 model2 loss : 0.019693
[12:24:32.766] iteration 29118 : model1 loss : 0.437806 model2 loss : 0.018653
[12:24:32.935] iteration 29119 : model1 loss : 0.441006 model2 loss : 0.020020
[12:24:33.104] iteration 29120 : model1 loss : 0.438211 model2 loss : 0.018287
[12:24:33.275] iteration 29121 : model1 loss : 0.441510 model2 loss : 0.017654
[12:24:33.443] iteration 29122 : model1 loss : 0.442476 model2 loss : 0.019620
[12:24:33.611] iteration 29123 : model1 loss : 0.439964 model2 loss : 0.017429
[12:24:33.778] iteration 29124 : model1 loss : 0.438057 model2 loss : 0.017747
[12:24:33.948] iteration 29125 : model1 loss : 0.441452 model2 loss : 0.019819
[12:24:34.114] iteration 29126 : model1 loss : 0.443516 model2 loss : 0.019814
[12:24:34.284] iteration 29127 : model1 loss : 0.439231 model2 loss : 0.018773
[12:24:34.450] iteration 29128 : model1 loss : 0.443419 model2 loss : 0.019985
[12:24:34.621] iteration 29129 : model1 loss : 0.438768 model2 loss : 0.019290
[12:24:34.787] iteration 29130 : model1 loss : 0.439042 model2 loss : 0.018344
[12:24:34.955] iteration 29131 : model1 loss : 0.443908 model2 loss : 0.021930
[12:24:35.122] iteration 29132 : model1 loss : 0.440244 model2 loss : 0.018585
[12:24:35.292] iteration 29133 : model1 loss : 0.441395 model2 loss : 0.020163
[12:24:35.460] iteration 29134 : model1 loss : 0.441007 model2 loss : 0.017994
[12:24:35.636] iteration 29135 : model1 loss : 0.440551 model2 loss : 0.020432
[12:24:35.805] iteration 29136 : model1 loss : 0.440241 model2 loss : 0.018815
[12:24:35.977] iteration 29137 : model1 loss : 0.440017 model2 loss : 0.016398
[12:24:36.143] iteration 29138 : model1 loss : 0.445749 model2 loss : 0.019129
[12:24:36.312] iteration 29139 : model1 loss : 0.435711 model2 loss : 0.017412
[12:24:38.239] iteration 29140 : model1 loss : 0.443258 model2 loss : 0.018913
[12:24:38.407] iteration 29141 : model1 loss : 0.445347 model2 loss : 0.022067
[12:24:38.577] iteration 29142 : model1 loss : 0.442519 model2 loss : 0.017865
[12:24:38.743] iteration 29143 : model1 loss : 0.439968 model2 loss : 0.019416
[12:24:38.912] iteration 29144 : model1 loss : 0.437648 model2 loss : 0.019419
[12:24:39.079] iteration 29145 : model1 loss : 0.444280 model2 loss : 0.020672
[12:24:39.250] iteration 29146 : model1 loss : 0.445086 model2 loss : 0.019519
[12:24:39.419] iteration 29147 : model1 loss : 0.441551 model2 loss : 0.019935
[12:24:39.587] iteration 29148 : model1 loss : 0.438306 model2 loss : 0.016941
[12:24:39.754] iteration 29149 : model1 loss : 0.440841 model2 loss : 0.018066
[12:24:39.926] iteration 29150 : model1 loss : 0.437052 model2 loss : 0.018935
[12:24:40.094] iteration 29151 : model1 loss : 0.437632 model2 loss : 0.017760
[12:24:40.262] iteration 29152 : model1 loss : 0.442474 model2 loss : 0.019204
[12:24:40.428] iteration 29153 : model1 loss : 0.437863 model2 loss : 0.018335
[12:24:40.599] iteration 29154 : model1 loss : 0.437919 model2 loss : 0.017968
[12:24:40.764] iteration 29155 : model1 loss : 0.439625 model2 loss : 0.017465
[12:24:40.935] iteration 29156 : model1 loss : 0.439657 model2 loss : 0.019365
[12:24:41.105] iteration 29157 : model1 loss : 0.440141 model2 loss : 0.016574
[12:24:41.274] iteration 29158 : model1 loss : 0.440299 model2 loss : 0.018947
[12:24:41.440] iteration 29159 : model1 loss : 0.435138 model2 loss : 0.017444
[12:24:41.609] iteration 29160 : model1 loss : 0.440549 model2 loss : 0.018085
[12:24:41.777] iteration 29161 : model1 loss : 0.441720 model2 loss : 0.018854
[12:24:41.955] iteration 29162 : model1 loss : 0.438262 model2 loss : 0.017921
[12:24:42.122] iteration 29163 : model1 loss : 0.438039 model2 loss : 0.018345
[12:24:42.292] iteration 29164 : model1 loss : 0.441652 model2 loss : 0.018192
[12:24:42.459] iteration 29165 : model1 loss : 0.440025 model2 loss : 0.019999
[12:24:42.629] iteration 29166 : model1 loss : 0.439048 model2 loss : 0.018518
[12:24:42.796] iteration 29167 : model1 loss : 0.443244 model2 loss : 0.020178
[12:24:42.965] iteration 29168 : model1 loss : 0.441307 model2 loss : 0.016842
[12:24:43.131] iteration 29169 : model1 loss : 0.440297 model2 loss : 0.017374
[12:24:43.302] iteration 29170 : model1 loss : 0.438501 model2 loss : 0.017576
[12:24:43.469] iteration 29171 : model1 loss : 0.439130 model2 loss : 0.017555
[12:24:43.636] iteration 29172 : model1 loss : 0.434455 model2 loss : 0.017533
[12:24:45.544] iteration 29173 : model1 loss : 0.440164 model2 loss : 0.020013
[12:24:45.717] iteration 29174 : model1 loss : 0.440334 model2 loss : 0.017582
[12:24:45.887] iteration 29175 : model1 loss : 0.442660 model2 loss : 0.018607
[12:24:46.053] iteration 29176 : model1 loss : 0.440863 model2 loss : 0.017593
[12:24:46.223] iteration 29177 : model1 loss : 0.442413 model2 loss : 0.020127
[12:24:46.389] iteration 29178 : model1 loss : 0.443871 model2 loss : 0.020763
[12:24:46.574] iteration 29179 : model1 loss : 0.436432 model2 loss : 0.017270
[12:24:46.742] iteration 29180 : model1 loss : 0.440449 model2 loss : 0.018357
[12:24:46.911] iteration 29181 : model1 loss : 0.431722 model2 loss : 0.018102
[12:24:47.079] iteration 29182 : model1 loss : 0.440170 model2 loss : 0.018949
[12:24:47.251] iteration 29183 : model1 loss : 0.439003 model2 loss : 0.015853
[12:24:47.418] iteration 29184 : model1 loss : 0.438996 model2 loss : 0.018816
[12:24:47.589] iteration 29185 : model1 loss : 0.439007 model2 loss : 0.017866
[12:24:47.756] iteration 29186 : model1 loss : 0.439349 model2 loss : 0.017004
[12:24:47.925] iteration 29187 : model1 loss : 0.442763 model2 loss : 0.018699
[12:24:48.091] iteration 29188 : model1 loss : 0.439795 model2 loss : 0.016146
[12:24:48.261] iteration 29189 : model1 loss : 0.434805 model2 loss : 0.015699
[12:24:48.427] iteration 29190 : model1 loss : 0.439772 model2 loss : 0.019153
[12:24:48.602] iteration 29191 : model1 loss : 0.442734 model2 loss : 0.018195
[12:24:48.767] iteration 29192 : model1 loss : 0.444370 model2 loss : 0.019763
[12:24:48.936] iteration 29193 : model1 loss : 0.438013 model2 loss : 0.018186
[12:24:49.105] iteration 29194 : model1 loss : 0.443820 model2 loss : 0.017742
[12:24:49.273] iteration 29195 : model1 loss : 0.441575 model2 loss : 0.021131
[12:24:49.443] iteration 29196 : model1 loss : 0.444038 model2 loss : 0.018984
[12:24:49.613] iteration 29197 : model1 loss : 0.437356 model2 loss : 0.017231
[12:24:49.781] iteration 29198 : model1 loss : 0.439902 model2 loss : 0.017672
[12:24:49.961] iteration 29199 : model1 loss : 0.434442 model2 loss : 0.016661
[12:24:50.130] iteration 29200 : model1 loss : 0.437231 model2 loss : 0.018503
[12:24:50.296] iteration 29201 : model1 loss : 0.440275 model2 loss : 0.018918
[12:24:50.463] iteration 29202 : model1 loss : 0.441498 model2 loss : 0.019188
[12:24:50.633] iteration 29203 : model1 loss : 0.437092 model2 loss : 0.016973
[12:24:50.798] iteration 29204 : model1 loss : 0.442899 model2 loss : 0.023597
[12:24:50.970] iteration 29205 : model1 loss : 0.441611 model2 loss : 0.019439
[12:24:52.896] iteration 29206 : model1 loss : 0.441424 model2 loss : 0.018708
[12:24:53.063] iteration 29207 : model1 loss : 0.438283 model2 loss : 0.018432
[12:24:53.233] iteration 29208 : model1 loss : 0.437652 model2 loss : 0.018229
[12:24:53.401] iteration 29209 : model1 loss : 0.439997 model2 loss : 0.018011
[12:24:53.576] iteration 29210 : model1 loss : 0.443580 model2 loss : 0.019459
[12:24:53.744] iteration 29211 : model1 loss : 0.442965 model2 loss : 0.019170
[12:24:53.913] iteration 29212 : model1 loss : 0.441093 model2 loss : 0.017490
[12:24:54.080] iteration 29213 : model1 loss : 0.440323 model2 loss : 0.018319
[12:24:54.250] iteration 29214 : model1 loss : 0.439323 model2 loss : 0.019290
[12:24:54.417] iteration 29215 : model1 loss : 0.442365 model2 loss : 0.018903
[12:24:54.592] iteration 29216 : model1 loss : 0.439262 model2 loss : 0.018362
[12:24:54.758] iteration 29217 : model1 loss : 0.441180 model2 loss : 0.019685
[12:24:54.928] iteration 29218 : model1 loss : 0.438467 model2 loss : 0.018143
[12:24:55.096] iteration 29219 : model1 loss : 0.436627 model2 loss : 0.017976
[12:24:55.264] iteration 29220 : model1 loss : 0.439299 model2 loss : 0.019661
[12:24:55.431] iteration 29221 : model1 loss : 0.437335 model2 loss : 0.020646
[12:24:55.604] iteration 29222 : model1 loss : 0.437776 model2 loss : 0.016705
[12:24:55.772] iteration 29223 : model1 loss : 0.440344 model2 loss : 0.016450
[12:24:55.943] iteration 29224 : model1 loss : 0.441073 model2 loss : 0.018097
[12:24:56.109] iteration 29225 : model1 loss : 0.442963 model2 loss : 0.019798
[12:24:56.279] iteration 29226 : model1 loss : 0.440005 model2 loss : 0.018464
[12:24:56.446] iteration 29227 : model1 loss : 0.441017 model2 loss : 0.018254
[12:24:56.615] iteration 29228 : model1 loss : 0.443926 model2 loss : 0.019212
[12:24:56.782] iteration 29229 : model1 loss : 0.440801 model2 loss : 0.017138
[12:24:56.953] iteration 29230 : model1 loss : 0.437108 model2 loss : 0.017164
[12:24:57.121] iteration 29231 : model1 loss : 0.440586 model2 loss : 0.017845
[12:24:57.290] iteration 29232 : model1 loss : 0.437443 model2 loss : 0.017903
[12:24:57.460] iteration 29233 : model1 loss : 0.438053 model2 loss : 0.018526
[12:24:57.630] iteration 29234 : model1 loss : 0.439963 model2 loss : 0.017256
[12:24:57.799] iteration 29235 : model1 loss : 0.440190 model2 loss : 0.017632
[12:24:57.968] iteration 29236 : model1 loss : 0.437405 model2 loss : 0.019337
[12:24:58.134] iteration 29237 : model1 loss : 0.444674 model2 loss : 0.017705
[12:24:58.302] iteration 29238 : model1 loss : 0.442825 model2 loss : 0.018954
[12:25:00.240] iteration 29239 : model1 loss : 0.436799 model2 loss : 0.017598
[12:25:00.413] iteration 29240 : model1 loss : 0.441503 model2 loss : 0.018820
[12:25:00.590] iteration 29241 : model1 loss : 0.434253 model2 loss : 0.017920
[12:25:00.755] iteration 29242 : model1 loss : 0.440730 model2 loss : 0.020578
[12:25:00.925] iteration 29243 : model1 loss : 0.432888 model2 loss : 0.015267
[12:25:01.091] iteration 29244 : model1 loss : 0.437476 model2 loss : 0.017210
[12:25:01.258] iteration 29245 : model1 loss : 0.441162 model2 loss : 0.020122
[12:25:01.428] iteration 29246 : model1 loss : 0.442762 model2 loss : 0.018801
[12:25:01.599] iteration 29247 : model1 loss : 0.438848 model2 loss : 0.016885
[12:25:01.767] iteration 29248 : model1 loss : 0.440344 model2 loss : 0.021290
[12:25:01.936] iteration 29249 : model1 loss : 0.444830 model2 loss : 0.019371
[12:25:02.102] iteration 29250 : model1 loss : 0.445385 model2 loss : 0.022153
[12:25:02.271] iteration 29251 : model1 loss : 0.443410 model2 loss : 0.019773
[12:25:02.438] iteration 29252 : model1 loss : 0.438644 model2 loss : 0.020355
[12:25:02.612] iteration 29253 : model1 loss : 0.433163 model2 loss : 0.017357
[12:25:02.779] iteration 29254 : model1 loss : 0.443465 model2 loss : 0.017982
[12:25:02.950] iteration 29255 : model1 loss : 0.446174 model2 loss : 0.017697
[12:25:03.120] iteration 29256 : model1 loss : 0.442076 model2 loss : 0.018261
[12:25:03.289] iteration 29257 : model1 loss : 0.442040 model2 loss : 0.020199
[12:25:03.458] iteration 29258 : model1 loss : 0.444371 model2 loss : 0.019062
[12:25:03.628] iteration 29259 : model1 loss : 0.440349 model2 loss : 0.017231
[12:25:03.795] iteration 29260 : model1 loss : 0.440336 model2 loss : 0.018045
[12:25:03.964] iteration 29261 : model1 loss : 0.440938 model2 loss : 0.018378
[12:25:04.132] iteration 29262 : model1 loss : 0.433688 model2 loss : 0.017780
[12:25:04.301] iteration 29263 : model1 loss : 0.435729 model2 loss : 0.018315
[12:25:04.469] iteration 29264 : model1 loss : 0.441116 model2 loss : 0.018920
[12:25:04.640] iteration 29265 : model1 loss : 0.438878 model2 loss : 0.017855
[12:25:04.808] iteration 29266 : model1 loss : 0.442497 model2 loss : 0.017913
[12:25:04.976] iteration 29267 : model1 loss : 0.440587 model2 loss : 0.018261
[12:25:05.144] iteration 29268 : model1 loss : 0.440927 model2 loss : 0.018311
[12:25:05.314] iteration 29269 : model1 loss : 0.438664 model2 loss : 0.017738
[12:25:05.479] iteration 29270 : model1 loss : 0.441841 model2 loss : 0.016027
[12:25:05.648] iteration 29271 : model1 loss : 0.438388 model2 loss : 0.017841
[12:25:07.575] iteration 29272 : model1 loss : 0.437820 model2 loss : 0.021403
[12:25:07.743] iteration 29273 : model1 loss : 0.441611 model2 loss : 0.018692
[12:25:07.914] iteration 29274 : model1 loss : 0.444399 model2 loss : 0.018311
[12:25:08.080] iteration 29275 : model1 loss : 0.438580 model2 loss : 0.019654
[12:25:08.249] iteration 29276 : model1 loss : 0.442586 model2 loss : 0.017179
[12:25:08.418] iteration 29277 : model1 loss : 0.435671 model2 loss : 0.020123
[12:25:08.591] iteration 29278 : model1 loss : 0.440982 model2 loss : 0.015187
[12:25:08.758] iteration 29279 : model1 loss : 0.439697 model2 loss : 0.020847
[12:25:08.928] iteration 29280 : model1 loss : 0.438974 model2 loss : 0.018699
[12:25:09.095] iteration 29281 : model1 loss : 0.437608 model2 loss : 0.018677
[12:25:09.262] iteration 29282 : model1 loss : 0.441495 model2 loss : 0.017157
[12:25:09.430] iteration 29283 : model1 loss : 0.440359 model2 loss : 0.018516
[12:25:09.602] iteration 29284 : model1 loss : 0.445343 model2 loss : 0.019860
[12:25:09.769] iteration 29285 : model1 loss : 0.435740 model2 loss : 0.018121
[12:25:09.938] iteration 29286 : model1 loss : 0.439919 model2 loss : 0.019381
[12:25:10.105] iteration 29287 : model1 loss : 0.436268 model2 loss : 0.017533
[12:25:10.275] iteration 29288 : model1 loss : 0.435359 model2 loss : 0.019187
[12:25:10.442] iteration 29289 : model1 loss : 0.438477 model2 loss : 0.018015
[12:25:10.611] iteration 29290 : model1 loss : 0.443039 model2 loss : 0.019069
[12:25:10.777] iteration 29291 : model1 loss : 0.440905 model2 loss : 0.016678
[12:25:10.949] iteration 29292 : model1 loss : 0.441169 model2 loss : 0.018943
[12:25:11.115] iteration 29293 : model1 loss : 0.439532 model2 loss : 0.018158
[12:25:11.287] iteration 29294 : model1 loss : 0.439642 model2 loss : 0.019532
[12:25:11.454] iteration 29295 : model1 loss : 0.439519 model2 loss : 0.017504
[12:25:11.625] iteration 29296 : model1 loss : 0.435553 model2 loss : 0.017377
[12:25:11.793] iteration 29297 : model1 loss : 0.440312 model2 loss : 0.020520
[12:25:11.964] iteration 29298 : model1 loss : 0.443320 model2 loss : 0.020078
[12:25:12.131] iteration 29299 : model1 loss : 0.436714 model2 loss : 0.018581
[12:25:12.301] iteration 29300 : model1 loss : 0.444706 model2 loss : 0.020409
[12:25:12.468] iteration 29301 : model1 loss : 0.441997 model2 loss : 0.020066
[12:25:12.639] iteration 29302 : model1 loss : 0.442339 model2 loss : 0.019104
[12:25:12.805] iteration 29303 : model1 loss : 0.440685 model2 loss : 0.018474
[12:25:12.977] iteration 29304 : model1 loss : 0.446316 model2 loss : 0.020357
[12:25:14.920] iteration 29305 : model1 loss : 0.439890 model2 loss : 0.017675
[12:25:15.093] iteration 29306 : model1 loss : 0.441526 model2 loss : 0.020131
[12:25:15.264] iteration 29307 : model1 loss : 0.439891 model2 loss : 0.018157
[12:25:15.432] iteration 29308 : model1 loss : 0.435062 model2 loss : 0.016772
[12:25:15.603] iteration 29309 : model1 loss : 0.438882 model2 loss : 0.020169
[12:25:15.772] iteration 29310 : model1 loss : 0.443682 model2 loss : 0.017665
[12:25:15.943] iteration 29311 : model1 loss : 0.440271 model2 loss : 0.018060
[12:25:16.112] iteration 29312 : model1 loss : 0.435811 model2 loss : 0.018825
[12:25:16.281] iteration 29313 : model1 loss : 0.436353 model2 loss : 0.017508
[12:25:16.449] iteration 29314 : model1 loss : 0.436167 model2 loss : 0.016637
[12:25:16.621] iteration 29315 : model1 loss : 0.446322 model2 loss : 0.020076
[12:25:16.787] iteration 29316 : model1 loss : 0.438661 model2 loss : 0.018270
[12:25:16.957] iteration 29317 : model1 loss : 0.441206 model2 loss : 0.016146
[12:25:17.124] iteration 29318 : model1 loss : 0.433993 model2 loss : 0.018223
[12:25:17.293] iteration 29319 : model1 loss : 0.437149 model2 loss : 0.019049
[12:25:17.460] iteration 29320 : model1 loss : 0.437651 model2 loss : 0.019547
[12:25:17.630] iteration 29321 : model1 loss : 0.444309 model2 loss : 0.020819
[12:25:17.799] iteration 29322 : model1 loss : 0.442382 model2 loss : 0.018020
[12:25:17.968] iteration 29323 : model1 loss : 0.439827 model2 loss : 0.018853
[12:25:18.137] iteration 29324 : model1 loss : 0.439472 model2 loss : 0.017811
[12:25:18.306] iteration 29325 : model1 loss : 0.438792 model2 loss : 0.019180
[12:25:18.474] iteration 29326 : model1 loss : 0.442514 model2 loss : 0.018484
[12:25:18.643] iteration 29327 : model1 loss : 0.441218 model2 loss : 0.019504
[12:25:18.810] iteration 29328 : model1 loss : 0.442823 model2 loss : 0.019550
[12:25:18.979] iteration 29329 : model1 loss : 0.442015 model2 loss : 0.015469
[12:25:19.148] iteration 29330 : model1 loss : 0.439632 model2 loss : 0.018563
[12:25:19.318] iteration 29331 : model1 loss : 0.444737 model2 loss : 0.020943
[12:25:19.486] iteration 29332 : model1 loss : 0.441513 model2 loss : 0.016918
[12:25:19.654] iteration 29333 : model1 loss : 0.445078 model2 loss : 0.018236
[12:25:19.822] iteration 29334 : model1 loss : 0.443391 model2 loss : 0.018508
[12:25:19.992] iteration 29335 : model1 loss : 0.437105 model2 loss : 0.018767
[12:25:20.158] iteration 29336 : model1 loss : 0.436960 model2 loss : 0.017702
[12:25:20.327] iteration 29337 : model1 loss : 0.441050 model2 loss : 0.018652
[12:25:22.293] iteration 29338 : model1 loss : 0.446818 model2 loss : 0.019286
[12:25:22.460] iteration 29339 : model1 loss : 0.443193 model2 loss : 0.020175
[12:25:22.633] iteration 29340 : model1 loss : 0.443732 model2 loss : 0.017620
[12:25:22.800] iteration 29341 : model1 loss : 0.438592 model2 loss : 0.018197
[12:25:22.968] iteration 29342 : model1 loss : 0.442233 model2 loss : 0.019307
[12:25:23.135] iteration 29343 : model1 loss : 0.438609 model2 loss : 0.017939
[12:25:23.306] iteration 29344 : model1 loss : 0.441444 model2 loss : 0.019728
[12:25:23.473] iteration 29345 : model1 loss : 0.441304 model2 loss : 0.019618
[12:25:23.643] iteration 29346 : model1 loss : 0.440411 model2 loss : 0.021128
[12:25:23.812] iteration 29347 : model1 loss : 0.440586 model2 loss : 0.017904
[12:25:23.983] iteration 29348 : model1 loss : 0.438883 model2 loss : 0.019047
[12:25:24.150] iteration 29349 : model1 loss : 0.438905 model2 loss : 0.017165
[12:25:24.320] iteration 29350 : model1 loss : 0.445456 model2 loss : 0.017988
[12:25:24.491] iteration 29351 : model1 loss : 0.435740 model2 loss : 0.017058
[12:25:24.659] iteration 29352 : model1 loss : 0.437616 model2 loss : 0.017154
[12:25:24.825] iteration 29353 : model1 loss : 0.442434 model2 loss : 0.017789
[12:25:24.995] iteration 29354 : model1 loss : 0.436974 model2 loss : 0.016258
[12:25:25.165] iteration 29355 : model1 loss : 0.434847 model2 loss : 0.016927
[12:25:25.336] iteration 29356 : model1 loss : 0.439313 model2 loss : 0.017308
[12:25:25.505] iteration 29357 : model1 loss : 0.439701 model2 loss : 0.018125
[12:25:25.673] iteration 29358 : model1 loss : 0.438271 model2 loss : 0.017623
[12:25:25.841] iteration 29359 : model1 loss : 0.438792 model2 loss : 0.019967
[12:25:26.012] iteration 29360 : model1 loss : 0.436390 model2 loss : 0.017729
[12:25:26.181] iteration 29361 : model1 loss : 0.438556 model2 loss : 0.018695
[12:25:26.352] iteration 29362 : model1 loss : 0.443354 model2 loss : 0.018318
[12:25:26.525] iteration 29363 : model1 loss : 0.441899 model2 loss : 0.019802
[12:25:26.695] iteration 29364 : model1 loss : 0.438951 model2 loss : 0.017599
[12:25:26.862] iteration 29365 : model1 loss : 0.441644 model2 loss : 0.019441
[12:25:27.033] iteration 29366 : model1 loss : 0.435433 model2 loss : 0.017184
[12:25:27.201] iteration 29367 : model1 loss : 0.440513 model2 loss : 0.020115
[12:25:27.370] iteration 29368 : model1 loss : 0.443196 model2 loss : 0.019404
[12:25:27.548] iteration 29369 : model1 loss : 0.437650 model2 loss : 0.018816
[12:25:27.718] iteration 29370 : model1 loss : 0.442584 model2 loss : 0.019462
[12:25:29.637] iteration 29371 : model1 loss : 0.438531 model2 loss : 0.019706
[12:25:29.807] iteration 29372 : model1 loss : 0.439448 model2 loss : 0.019326
[12:25:29.979] iteration 29373 : model1 loss : 0.439075 model2 loss : 0.018853
[12:25:30.147] iteration 29374 : model1 loss : 0.440275 model2 loss : 0.019957
[12:25:30.319] iteration 29375 : model1 loss : 0.442798 model2 loss : 0.019485
[12:25:30.488] iteration 29376 : model1 loss : 0.436796 model2 loss : 0.018813
[12:25:30.658] iteration 29377 : model1 loss : 0.441076 model2 loss : 0.018607
[12:25:30.824] iteration 29378 : model1 loss : 0.440338 model2 loss : 0.018996
[12:25:30.995] iteration 29379 : model1 loss : 0.443477 model2 loss : 0.020874
[12:25:31.163] iteration 29380 : model1 loss : 0.444441 model2 loss : 0.018565
[12:25:31.333] iteration 29381 : model1 loss : 0.436806 model2 loss : 0.017985
[12:25:31.502] iteration 29382 : model1 loss : 0.438760 model2 loss : 0.018698
[12:25:31.672] iteration 29383 : model1 loss : 0.436332 model2 loss : 0.016975
[12:25:31.840] iteration 29384 : model1 loss : 0.444739 model2 loss : 0.016867
[12:25:32.007] iteration 29385 : model1 loss : 0.438920 model2 loss : 0.018797
[12:25:32.176] iteration 29386 : model1 loss : 0.444122 model2 loss : 0.019284
[12:25:32.347] iteration 29387 : model1 loss : 0.438331 model2 loss : 0.020629
[12:25:32.516] iteration 29388 : model1 loss : 0.436080 model2 loss : 0.017569
[12:25:32.685] iteration 29389 : model1 loss : 0.438352 model2 loss : 0.017302
[12:25:32.852] iteration 29390 : model1 loss : 0.439665 model2 loss : 0.017543
[12:25:33.022] iteration 29391 : model1 loss : 0.438183 model2 loss : 0.019117
[12:25:33.190] iteration 29392 : model1 loss : 0.439989 model2 loss : 0.016664
[12:25:33.362] iteration 29393 : model1 loss : 0.443450 model2 loss : 0.020827
[12:25:33.530] iteration 29394 : model1 loss : 0.440245 model2 loss : 0.016996
[12:25:33.700] iteration 29395 : model1 loss : 0.445832 model2 loss : 0.018613
[12:25:33.868] iteration 29396 : model1 loss : 0.442004 model2 loss : 0.020611
[12:25:34.036] iteration 29397 : model1 loss : 0.435246 model2 loss : 0.018244
[12:25:34.205] iteration 29398 : model1 loss : 0.437512 model2 loss : 0.018305
[12:25:34.375] iteration 29399 : model1 loss : 0.439123 model2 loss : 0.017405
[12:25:34.544] iteration 29400 : model1 loss : 0.436256 model2 loss : 0.017830
[12:25:34.713] iteration 29401 : model1 loss : 0.444421 model2 loss : 0.017730
[12:25:34.878] iteration 29402 : model1 loss : 0.443482 model2 loss : 0.018302
[12:25:35.048] iteration 29403 : model1 loss : 0.439437 model2 loss : 0.017187
[12:25:37.027] iteration 29404 : model1 loss : 0.438502 model2 loss : 0.018822
[12:25:37.198] iteration 29405 : model1 loss : 0.436759 model2 loss : 0.018601
[12:25:37.371] iteration 29406 : model1 loss : 0.443351 model2 loss : 0.019072
[12:25:37.540] iteration 29407 : model1 loss : 0.440295 model2 loss : 0.017280
[12:25:37.707] iteration 29408 : model1 loss : 0.440422 model2 loss : 0.017923
[12:25:37.873] iteration 29409 : model1 loss : 0.440156 model2 loss : 0.016997
[12:25:38.043] iteration 29410 : model1 loss : 0.440040 model2 loss : 0.018316
[12:25:38.209] iteration 29411 : model1 loss : 0.443467 model2 loss : 0.019169
[12:25:38.379] iteration 29412 : model1 loss : 0.443719 model2 loss : 0.019111
[12:25:38.547] iteration 29413 : model1 loss : 0.437058 model2 loss : 0.015261
[12:25:38.716] iteration 29414 : model1 loss : 0.438780 model2 loss : 0.018887
[12:25:38.895] iteration 29415 : model1 loss : 0.437337 model2 loss : 0.017039
[12:25:39.064] iteration 29416 : model1 loss : 0.438543 model2 loss : 0.017475
[12:25:39.233] iteration 29417 : model1 loss : 0.441750 model2 loss : 0.018929
[12:25:39.402] iteration 29418 : model1 loss : 0.440179 model2 loss : 0.019480
[12:25:39.572] iteration 29419 : model1 loss : 0.445128 model2 loss : 0.018628
[12:25:39.740] iteration 29420 : model1 loss : 0.439801 model2 loss : 0.020292
[12:25:39.909] iteration 29421 : model1 loss : 0.440767 model2 loss : 0.018415
[12:25:40.080] iteration 29422 : model1 loss : 0.443728 model2 loss : 0.018955
[12:25:40.248] iteration 29423 : model1 loss : 0.439822 model2 loss : 0.019799
[12:25:40.417] iteration 29424 : model1 loss : 0.436259 model2 loss : 0.017479
[12:25:40.587] iteration 29425 : model1 loss : 0.441672 model2 loss : 0.019116
[12:25:40.757] iteration 29426 : model1 loss : 0.438191 model2 loss : 0.017076
[12:25:40.927] iteration 29427 : model1 loss : 0.445288 model2 loss : 0.020487
[12:25:41.095] iteration 29428 : model1 loss : 0.439152 model2 loss : 0.017179
[12:25:41.264] iteration 29429 : model1 loss : 0.436543 model2 loss : 0.018754
[12:25:41.434] iteration 29430 : model1 loss : 0.435621 model2 loss : 0.018503
[12:25:41.605] iteration 29431 : model1 loss : 0.442511 model2 loss : 0.018037
[12:25:41.775] iteration 29432 : model1 loss : 0.437579 model2 loss : 0.017013
[12:25:41.945] iteration 29433 : model1 loss : 0.436037 model2 loss : 0.016466
[12:25:42.117] iteration 29434 : model1 loss : 0.440270 model2 loss : 0.019525
[12:25:42.282] iteration 29435 : model1 loss : 0.443442 model2 loss : 0.018191
[12:25:42.452] iteration 29436 : model1 loss : 0.442612 model2 loss : 0.020104
[12:25:44.378] iteration 29437 : model1 loss : 0.442606 model2 loss : 0.020820
[12:25:44.545] iteration 29438 : model1 loss : 0.443859 model2 loss : 0.018398
[12:25:44.716] iteration 29439 : model1 loss : 0.439070 model2 loss : 0.017191
[12:25:44.884] iteration 29440 : model1 loss : 0.440587 model2 loss : 0.016691
[12:25:45.055] iteration 29441 : model1 loss : 0.433420 model2 loss : 0.018867
[12:25:45.224] iteration 29442 : model1 loss : 0.436913 model2 loss : 0.017527
[12:25:45.393] iteration 29443 : model1 loss : 0.441113 model2 loss : 0.018077
[12:25:45.564] iteration 29444 : model1 loss : 0.441621 model2 loss : 0.016978
[12:25:45.735] iteration 29445 : model1 loss : 0.435938 model2 loss : 0.016955
[12:25:45.904] iteration 29446 : model1 loss : 0.442853 model2 loss : 0.018031
[12:25:46.073] iteration 29447 : model1 loss : 0.438802 model2 loss : 0.018958
[12:25:46.240] iteration 29448 : model1 loss : 0.443531 model2 loss : 0.018332
[12:25:46.410] iteration 29449 : model1 loss : 0.439402 model2 loss : 0.017843
[12:25:46.581] iteration 29450 : model1 loss : 0.440176 model2 loss : 0.018235
[12:25:46.751] iteration 29451 : model1 loss : 0.443556 model2 loss : 0.019716
[12:25:46.920] iteration 29452 : model1 loss : 0.440176 model2 loss : 0.018643
[12:25:47.091] iteration 29453 : model1 loss : 0.441285 model2 loss : 0.018853
[12:25:47.257] iteration 29454 : model1 loss : 0.444666 model2 loss : 0.019775
[12:25:47.429] iteration 29455 : model1 loss : 0.442433 model2 loss : 0.019249
[12:25:47.599] iteration 29456 : model1 loss : 0.434823 model2 loss : 0.017778
[12:25:47.773] iteration 29457 : model1 loss : 0.441915 model2 loss : 0.017584
[12:25:47.940] iteration 29458 : model1 loss : 0.439654 model2 loss : 0.017202
[12:25:48.109] iteration 29459 : model1 loss : 0.438108 model2 loss : 0.018739
[12:25:48.277] iteration 29460 : model1 loss : 0.434556 model2 loss : 0.015755
[12:25:48.446] iteration 29461 : model1 loss : 0.437956 model2 loss : 0.017669
[12:25:48.618] iteration 29462 : model1 loss : 0.440900 model2 loss : 0.017579
[12:25:48.787] iteration 29463 : model1 loss : 0.439785 model2 loss : 0.018914
[12:25:48.955] iteration 29464 : model1 loss : 0.438107 model2 loss : 0.017846
[12:25:49.123] iteration 29465 : model1 loss : 0.441494 model2 loss : 0.019661
[12:25:49.291] iteration 29466 : model1 loss : 0.441882 model2 loss : 0.018316
[12:25:49.460] iteration 29467 : model1 loss : 0.443901 model2 loss : 0.020339
[12:25:49.627] iteration 29468 : model1 loss : 0.437441 model2 loss : 0.017705
[12:25:49.796] iteration 29469 : model1 loss : 0.438719 model2 loss : 0.020637
[12:25:51.747] iteration 29470 : model1 loss : 0.442978 model2 loss : 0.018689
[12:25:51.918] iteration 29471 : model1 loss : 0.437395 model2 loss : 0.017805
[12:25:52.090] iteration 29472 : model1 loss : 0.444819 model2 loss : 0.016428
[12:25:52.257] iteration 29473 : model1 loss : 0.443446 model2 loss : 0.017904
[12:25:52.424] iteration 29474 : model1 loss : 0.440493 model2 loss : 0.020214
[12:25:52.593] iteration 29475 : model1 loss : 0.439046 model2 loss : 0.017414
[12:25:52.762] iteration 29476 : model1 loss : 0.441311 model2 loss : 0.019444
[12:25:52.929] iteration 29477 : model1 loss : 0.436930 model2 loss : 0.018917
[12:25:53.100] iteration 29478 : model1 loss : 0.440933 model2 loss : 0.020155
[12:25:53.268] iteration 29479 : model1 loss : 0.441167 model2 loss : 0.020785
[12:25:53.438] iteration 29480 : model1 loss : 0.437872 model2 loss : 0.019558
[12:25:53.605] iteration 29481 : model1 loss : 0.445864 model2 loss : 0.023546
[12:25:53.773] iteration 29482 : model1 loss : 0.444603 model2 loss : 0.020184
[12:25:53.941] iteration 29483 : model1 loss : 0.444183 model2 loss : 0.019685
[12:25:54.109] iteration 29484 : model1 loss : 0.437402 model2 loss : 0.016377
[12:25:54.276] iteration 29485 : model1 loss : 0.443023 model2 loss : 0.020365
[12:25:54.446] iteration 29486 : model1 loss : 0.436304 model2 loss : 0.016725
[12:25:54.616] iteration 29487 : model1 loss : 0.440807 model2 loss : 0.020404
[12:25:54.786] iteration 29488 : model1 loss : 0.437951 model2 loss : 0.016848
[12:25:54.952] iteration 29489 : model1 loss : 0.439285 model2 loss : 0.020808
[12:25:55.139] iteration 29490 : model1 loss : 0.441256 model2 loss : 0.018360
[12:25:55.306] iteration 29491 : model1 loss : 0.445044 model2 loss : 0.017620
[12:25:55.475] iteration 29492 : model1 loss : 0.433844 model2 loss : 0.016304
[12:25:55.643] iteration 29493 : model1 loss : 0.442155 model2 loss : 0.018464
[12:25:55.813] iteration 29494 : model1 loss : 0.439305 model2 loss : 0.017302
[12:25:55.984] iteration 29495 : model1 loss : 0.439575 model2 loss : 0.018423
[12:25:56.152] iteration 29496 : model1 loss : 0.439792 model2 loss : 0.017603
[12:25:56.320] iteration 29497 : model1 loss : 0.440899 model2 loss : 0.018397
[12:25:56.490] iteration 29498 : model1 loss : 0.436951 model2 loss : 0.017907
[12:25:56.687] iteration 29499 : model1 loss : 0.438891 model2 loss : 0.016284
[12:25:56.857] iteration 29500 : model1 loss : 0.436337 model2 loss : 0.018937
[12:25:57.022] iteration 29501 : model1 loss : 0.435983 model2 loss : 0.016872
[12:25:57.191] iteration 29502 : model1 loss : 0.437649 model2 loss : 0.018354
[12:25:59.189] iteration 29503 : model1 loss : 0.440942 model2 loss : 0.017419
[12:25:59.361] iteration 29504 : model1 loss : 0.437712 model2 loss : 0.016107
[12:25:59.539] iteration 29505 : model1 loss : 0.444650 model2 loss : 0.020490
[12:25:59.707] iteration 29506 : model1 loss : 0.440584 model2 loss : 0.019299
[12:25:59.875] iteration 29507 : model1 loss : 0.437979 model2 loss : 0.016520
[12:26:00.042] iteration 29508 : model1 loss : 0.443664 model2 loss : 0.017967
[12:26:00.213] iteration 29509 : model1 loss : 0.439356 model2 loss : 0.018336
[12:26:00.382] iteration 29510 : model1 loss : 0.437213 model2 loss : 0.017691
[12:26:00.553] iteration 29511 : model1 loss : 0.444117 model2 loss : 0.018551
[12:26:00.722] iteration 29512 : model1 loss : 0.441151 model2 loss : 0.019079
[12:26:00.892] iteration 29513 : model1 loss : 0.438222 model2 loss : 0.018788
[12:26:01.058] iteration 29514 : model1 loss : 0.438665 model2 loss : 0.018430
[12:26:01.230] iteration 29515 : model1 loss : 0.438827 model2 loss : 0.017453
[12:26:01.396] iteration 29516 : model1 loss : 0.445125 model2 loss : 0.019133
[12:26:01.567] iteration 29517 : model1 loss : 0.439484 model2 loss : 0.019528
[12:26:01.734] iteration 29518 : model1 loss : 0.441321 model2 loss : 0.020761
[12:26:01.905] iteration 29519 : model1 loss : 0.440920 model2 loss : 0.018223
[12:26:02.074] iteration 29520 : model1 loss : 0.434300 model2 loss : 0.016743
[12:26:02.242] iteration 29521 : model1 loss : 0.439411 model2 loss : 0.018025
[12:26:02.412] iteration 29522 : model1 loss : 0.440847 model2 loss : 0.016313
[12:26:02.582] iteration 29523 : model1 loss : 0.439388 model2 loss : 0.017433
[12:26:02.751] iteration 29524 : model1 loss : 0.443317 model2 loss : 0.020075
[12:26:02.925] iteration 29525 : model1 loss : 0.437838 model2 loss : 0.019644
[12:26:03.092] iteration 29526 : model1 loss : 0.442466 model2 loss : 0.017413
[12:26:03.265] iteration 29527 : model1 loss : 0.439218 model2 loss : 0.019398
[12:26:03.433] iteration 29528 : model1 loss : 0.445085 model2 loss : 0.022122
[12:26:03.601] iteration 29529 : model1 loss : 0.443892 model2 loss : 0.019353
[12:26:03.772] iteration 29530 : model1 loss : 0.437218 model2 loss : 0.018484
[12:26:03.940] iteration 29531 : model1 loss : 0.436029 model2 loss : 0.018876
[12:26:04.107] iteration 29532 : model1 loss : 0.440078 model2 loss : 0.019910
[12:26:04.275] iteration 29533 : model1 loss : 0.438656 model2 loss : 0.019560
[12:26:04.444] iteration 29534 : model1 loss : 0.441005 model2 loss : 0.018247
[12:26:04.618] iteration 29535 : model1 loss : 0.435968 model2 loss : 0.017976
[12:26:06.580] iteration 29536 : model1 loss : 0.438100 model2 loss : 0.019890
[12:26:06.751] iteration 29537 : model1 loss : 0.438439 model2 loss : 0.017462
[12:26:06.922] iteration 29538 : model1 loss : 0.442709 model2 loss : 0.017572
[12:26:07.092] iteration 29539 : model1 loss : 0.440976 model2 loss : 0.019138
[12:26:07.262] iteration 29540 : model1 loss : 0.436579 model2 loss : 0.017331
[12:26:07.445] iteration 29541 : model1 loss : 0.436258 model2 loss : 0.017650
[12:26:07.620] iteration 29542 : model1 loss : 0.442749 model2 loss : 0.019381
[12:26:07.790] iteration 29543 : model1 loss : 0.443883 model2 loss : 0.017349
[12:26:07.961] iteration 29544 : model1 loss : 0.434188 model2 loss : 0.018022
[12:26:08.128] iteration 29545 : model1 loss : 0.444533 model2 loss : 0.019531
[12:26:08.298] iteration 29546 : model1 loss : 0.439058 model2 loss : 0.016867
[12:26:08.465] iteration 29547 : model1 loss : 0.440511 model2 loss : 0.018434
[12:26:08.637] iteration 29548 : model1 loss : 0.436186 model2 loss : 0.019170
[12:26:08.804] iteration 29549 : model1 loss : 0.440446 model2 loss : 0.019603
[12:26:08.974] iteration 29550 : model1 loss : 0.438703 model2 loss : 0.021530
[12:26:09.143] iteration 29551 : model1 loss : 0.437569 model2 loss : 0.019273
[12:26:09.311] iteration 29552 : model1 loss : 0.442632 model2 loss : 0.018740
[12:26:09.484] iteration 29553 : model1 loss : 0.435260 model2 loss : 0.017974
[12:26:09.654] iteration 29554 : model1 loss : 0.438440 model2 loss : 0.017660
[12:26:09.822] iteration 29555 : model1 loss : 0.436732 model2 loss : 0.017969
[12:26:09.992] iteration 29556 : model1 loss : 0.442504 model2 loss : 0.020277
[12:26:10.161] iteration 29557 : model1 loss : 0.440211 model2 loss : 0.017661
[12:26:10.331] iteration 29558 : model1 loss : 0.441592 model2 loss : 0.018907
[12:26:10.501] iteration 29559 : model1 loss : 0.443282 model2 loss : 0.017177
[12:26:10.672] iteration 29560 : model1 loss : 0.438951 model2 loss : 0.016819
[12:26:10.840] iteration 29561 : model1 loss : 0.439045 model2 loss : 0.018237
[12:26:11.010] iteration 29562 : model1 loss : 0.436241 model2 loss : 0.017180
[12:26:11.177] iteration 29563 : model1 loss : 0.446290 model2 loss : 0.018621
[12:26:11.346] iteration 29564 : model1 loss : 0.441493 model2 loss : 0.019080
[12:26:11.518] iteration 29565 : model1 loss : 0.441307 model2 loss : 0.018165
[12:26:11.688] iteration 29566 : model1 loss : 0.441662 model2 loss : 0.018032
[12:26:11.856] iteration 29567 : model1 loss : 0.445767 model2 loss : 0.019963
[12:26:12.025] iteration 29568 : model1 loss : 0.440522 model2 loss : 0.021048
[12:26:13.979] iteration 29569 : model1 loss : 0.435957 model2 loss : 0.016285
[12:26:14.147] iteration 29570 : model1 loss : 0.438263 model2 loss : 0.019469
[12:26:14.318] iteration 29571 : model1 loss : 0.437606 model2 loss : 0.017866
[12:26:14.483] iteration 29572 : model1 loss : 0.440289 model2 loss : 0.017530
[12:26:14.654] iteration 29573 : model1 loss : 0.438310 model2 loss : 0.016112
[12:26:14.822] iteration 29574 : model1 loss : 0.445503 model2 loss : 0.019729
[12:26:14.994] iteration 29575 : model1 loss : 0.443378 model2 loss : 0.017794
[12:26:15.162] iteration 29576 : model1 loss : 0.436895 model2 loss : 0.018857
[12:26:15.332] iteration 29577 : model1 loss : 0.439090 model2 loss : 0.016083
[12:26:15.501] iteration 29578 : model1 loss : 0.436919 model2 loss : 0.019961
[12:26:15.670] iteration 29579 : model1 loss : 0.438474 model2 loss : 0.018070
[12:26:15.838] iteration 29580 : model1 loss : 0.441748 model2 loss : 0.019511
[12:26:16.012] iteration 29581 : model1 loss : 0.444502 model2 loss : 0.018587
[12:26:16.181] iteration 29582 : model1 loss : 0.442422 model2 loss : 0.019629
[12:26:16.350] iteration 29583 : model1 loss : 0.435273 model2 loss : 0.018391
[12:26:16.524] iteration 29584 : model1 loss : 0.442073 model2 loss : 0.017890
[12:26:16.695] iteration 29585 : model1 loss : 0.443367 model2 loss : 0.017361
[12:26:16.863] iteration 29586 : model1 loss : 0.439888 model2 loss : 0.019118
[12:26:17.032] iteration 29587 : model1 loss : 0.441418 model2 loss : 0.018742
[12:26:17.200] iteration 29588 : model1 loss : 0.441142 model2 loss : 0.018889
[12:26:17.371] iteration 29589 : model1 loss : 0.441240 model2 loss : 0.019189
[12:26:17.553] iteration 29590 : model1 loss : 0.441625 model2 loss : 0.019123
[12:26:17.723] iteration 29591 : model1 loss : 0.440908 model2 loss : 0.018282
[12:26:17.891] iteration 29592 : model1 loss : 0.437149 model2 loss : 0.019731
[12:26:18.061] iteration 29593 : model1 loss : 0.438613 model2 loss : 0.016627
[12:26:18.229] iteration 29594 : model1 loss : 0.438551 model2 loss : 0.015405
[12:26:18.398] iteration 29595 : model1 loss : 0.438015 model2 loss : 0.019219
[12:26:18.568] iteration 29596 : model1 loss : 0.435250 model2 loss : 0.018055
[12:26:18.739] iteration 29597 : model1 loss : 0.442740 model2 loss : 0.019502
[12:26:18.909] iteration 29598 : model1 loss : 0.443892 model2 loss : 0.020439
[12:26:19.079] iteration 29599 : model1 loss : 0.441622 model2 loss : 0.020207
[12:26:19.246] iteration 29600 : model1 loss : 0.437638 model2 loss : 0.018239
[12:26:19.413] iteration 29601 : model1 loss : 0.442269 model2 loss : 0.021913
[12:26:21.393] iteration 29602 : model1 loss : 0.439816 model2 loss : 0.019613
[12:26:21.562] iteration 29603 : model1 loss : 0.436892 model2 loss : 0.017467
[12:26:21.735] iteration 29604 : model1 loss : 0.437408 model2 loss : 0.019599
[12:26:21.901] iteration 29605 : model1 loss : 0.440573 model2 loss : 0.018304
[12:26:22.074] iteration 29606 : model1 loss : 0.441761 model2 loss : 0.020570
[12:26:22.242] iteration 29607 : model1 loss : 0.441495 model2 loss : 0.018477
[12:26:22.413] iteration 29608 : model1 loss : 0.434180 model2 loss : 0.019858
[12:26:22.586] iteration 29609 : model1 loss : 0.441735 model2 loss : 0.018254
[12:26:22.758] iteration 29610 : model1 loss : 0.443406 model2 loss : 0.017343
[12:26:22.929] iteration 29611 : model1 loss : 0.441404 model2 loss : 0.020232
[12:26:23.103] iteration 29612 : model1 loss : 0.442688 model2 loss : 0.019349
[12:26:23.272] iteration 29613 : model1 loss : 0.439169 model2 loss : 0.017146
[12:26:23.444] iteration 29614 : model1 loss : 0.442086 model2 loss : 0.019335
[12:26:23.615] iteration 29615 : model1 loss : 0.441128 model2 loss : 0.019676
[12:26:23.788] iteration 29616 : model1 loss : 0.438549 model2 loss : 0.019436
[12:26:23.957] iteration 29617 : model1 loss : 0.438770 model2 loss : 0.016953
[12:26:24.129] iteration 29618 : model1 loss : 0.438857 model2 loss : 0.018745
[12:26:24.301] iteration 29619 : model1 loss : 0.442397 model2 loss : 0.019499
[12:26:24.472] iteration 29620 : model1 loss : 0.437638 model2 loss : 0.016745
[12:26:24.643] iteration 29621 : model1 loss : 0.444450 model2 loss : 0.019382
[12:26:24.817] iteration 29622 : model1 loss : 0.439782 model2 loss : 0.016854
[12:26:24.986] iteration 29623 : model1 loss : 0.439684 model2 loss : 0.015762
[12:26:25.158] iteration 29624 : model1 loss : 0.439834 model2 loss : 0.019199
[12:26:25.328] iteration 29625 : model1 loss : 0.440024 model2 loss : 0.017388
[12:26:25.504] iteration 29626 : model1 loss : 0.440518 model2 loss : 0.017400
[12:26:25.677] iteration 29627 : model1 loss : 0.440001 model2 loss : 0.017837
[12:26:25.847] iteration 29628 : model1 loss : 0.437615 model2 loss : 0.018443
[12:26:26.023] iteration 29629 : model1 loss : 0.436814 model2 loss : 0.017848
[12:26:26.194] iteration 29630 : model1 loss : 0.443528 model2 loss : 0.018278
[12:26:26.366] iteration 29631 : model1 loss : 0.443148 model2 loss : 0.019846
[12:26:26.544] iteration 29632 : model1 loss : 0.437468 model2 loss : 0.016864
[12:26:26.712] iteration 29633 : model1 loss : 0.442577 model2 loss : 0.017922
[12:26:26.882] iteration 29634 : model1 loss : 0.438734 model2 loss : 0.016517
[12:26:29.052] iteration 29635 : model1 loss : 0.437525 model2 loss : 0.018434
[12:26:29.232] iteration 29636 : model1 loss : 0.439216 model2 loss : 0.018618
[12:26:29.440] iteration 29637 : model1 loss : 0.437517 model2 loss : 0.018338
[12:26:29.641] iteration 29638 : model1 loss : 0.440478 model2 loss : 0.017683
[12:26:29.856] iteration 29639 : model1 loss : 0.439612 model2 loss : 0.019019
[12:26:30.074] iteration 29640 : model1 loss : 0.441439 model2 loss : 0.017344
[12:26:30.275] iteration 29641 : model1 loss : 0.440425 model2 loss : 0.018763
[12:26:30.481] iteration 29642 : model1 loss : 0.438342 model2 loss : 0.019380
[12:26:30.704] iteration 29643 : model1 loss : 0.439266 model2 loss : 0.017177
[12:26:30.906] iteration 29644 : model1 loss : 0.440293 model2 loss : 0.018200
[12:26:31.132] iteration 29645 : model1 loss : 0.440550 model2 loss : 0.019398
[12:26:31.341] iteration 29646 : model1 loss : 0.443815 model2 loss : 0.019721
[12:26:31.545] iteration 29647 : model1 loss : 0.444783 model2 loss : 0.018584
[12:26:31.753] iteration 29648 : model1 loss : 0.434591 model2 loss : 0.017745
[12:26:31.944] iteration 29649 : model1 loss : 0.442776 model2 loss : 0.020283
[12:26:32.124] iteration 29650 : model1 loss : 0.440781 model2 loss : 0.018501
[12:26:32.314] iteration 29651 : model1 loss : 0.437076 model2 loss : 0.017990
[12:26:32.500] iteration 29652 : model1 loss : 0.442744 model2 loss : 0.016129
[12:26:32.707] iteration 29653 : model1 loss : 0.443203 model2 loss : 0.019001
[12:26:32.907] iteration 29654 : model1 loss : 0.439847 model2 loss : 0.017729
[12:26:33.106] iteration 29655 : model1 loss : 0.443382 model2 loss : 0.018754
[12:26:33.306] iteration 29656 : model1 loss : 0.444065 model2 loss : 0.017732
[12:26:33.519] iteration 29657 : model1 loss : 0.438148 model2 loss : 0.016804
[12:26:33.723] iteration 29658 : model1 loss : 0.442177 model2 loss : 0.019164
[12:26:33.936] iteration 29659 : model1 loss : 0.439626 model2 loss : 0.018539
[12:26:34.132] iteration 29660 : model1 loss : 0.437862 model2 loss : 0.018487
[12:26:34.328] iteration 29661 : model1 loss : 0.438288 model2 loss : 0.017703
[12:26:34.532] iteration 29662 : model1 loss : 0.439235 model2 loss : 0.019260
[12:26:34.741] iteration 29663 : model1 loss : 0.440859 model2 loss : 0.020264
[12:26:34.940] iteration 29664 : model1 loss : 0.438479 model2 loss : 0.015779
[12:26:35.156] iteration 29665 : model1 loss : 0.442975 model2 loss : 0.020420
[12:26:35.333] iteration 29666 : model1 loss : 0.437447 model2 loss : 0.017877
[12:26:35.533] iteration 29667 : model1 loss : 0.436824 model2 loss : 0.017183
[12:26:37.475] iteration 29668 : model1 loss : 0.441076 model2 loss : 0.018074
[12:26:37.643] iteration 29669 : model1 loss : 0.439446 model2 loss : 0.018911
[12:26:37.814] iteration 29670 : model1 loss : 0.443274 model2 loss : 0.017925
[12:26:37.980] iteration 29671 : model1 loss : 0.440250 model2 loss : 0.019579
[12:26:38.149] iteration 29672 : model1 loss : 0.440871 model2 loss : 0.019083
[12:26:38.316] iteration 29673 : model1 loss : 0.438983 model2 loss : 0.016882
[12:26:38.485] iteration 29674 : model1 loss : 0.440016 model2 loss : 0.015713
[12:26:38.651] iteration 29675 : model1 loss : 0.434763 model2 loss : 0.016768
[12:26:38.819] iteration 29676 : model1 loss : 0.446852 model2 loss : 0.023153
[12:26:38.985] iteration 29677 : model1 loss : 0.439662 model2 loss : 0.019099
[12:26:39.155] iteration 29678 : model1 loss : 0.441761 model2 loss : 0.020235
[12:26:39.321] iteration 29679 : model1 loss : 0.441199 model2 loss : 0.017546
[12:26:39.492] iteration 29680 : model1 loss : 0.436690 model2 loss : 0.017902
[12:26:39.661] iteration 29681 : model1 loss : 0.440448 model2 loss : 0.019176
[12:26:39.831] iteration 29682 : model1 loss : 0.442461 model2 loss : 0.018414
[12:26:39.998] iteration 29683 : model1 loss : 0.442820 model2 loss : 0.018778
[12:26:40.165] iteration 29684 : model1 loss : 0.439137 model2 loss : 0.017762
[12:26:40.332] iteration 29685 : model1 loss : 0.441060 model2 loss : 0.021084
[12:26:40.504] iteration 29686 : model1 loss : 0.437706 model2 loss : 0.020370
[12:26:40.672] iteration 29687 : model1 loss : 0.440815 model2 loss : 0.019154
[12:26:40.841] iteration 29688 : model1 loss : 0.439690 model2 loss : 0.019283
[12:26:41.010] iteration 29689 : model1 loss : 0.441416 model2 loss : 0.018354
[12:26:41.179] iteration 29690 : model1 loss : 0.441437 model2 loss : 0.017623
[12:26:41.347] iteration 29691 : model1 loss : 0.440448 model2 loss : 0.018484
[12:26:41.518] iteration 29692 : model1 loss : 0.439788 model2 loss : 0.017876
[12:26:41.684] iteration 29693 : model1 loss : 0.441967 model2 loss : 0.018857
[12:26:41.853] iteration 29694 : model1 loss : 0.440428 model2 loss : 0.017933
[12:26:42.019] iteration 29695 : model1 loss : 0.437856 model2 loss : 0.018141
[12:26:42.187] iteration 29696 : model1 loss : 0.435562 model2 loss : 0.018020
[12:26:42.353] iteration 29697 : model1 loss : 0.439870 model2 loss : 0.016707
[12:26:42.526] iteration 29698 : model1 loss : 0.438708 model2 loss : 0.019454
[12:26:42.693] iteration 29699 : model1 loss : 0.437533 model2 loss : 0.018267
[12:26:42.862] iteration 29700 : model1 loss : 0.441444 model2 loss : 0.017748
[12:26:44.793] iteration 29701 : model1 loss : 0.442088 model2 loss : 0.017674
[12:26:44.960] iteration 29702 : model1 loss : 0.435419 model2 loss : 0.015724
[12:26:45.129] iteration 29703 : model1 loss : 0.438802 model2 loss : 0.020247
[12:26:45.295] iteration 29704 : model1 loss : 0.438862 model2 loss : 0.018999
[12:26:45.463] iteration 29705 : model1 loss : 0.441032 model2 loss : 0.019045
[12:26:45.630] iteration 29706 : model1 loss : 0.440458 model2 loss : 0.018480
[12:26:45.800] iteration 29707 : model1 loss : 0.440677 model2 loss : 0.018947
[12:26:45.970] iteration 29708 : model1 loss : 0.445144 model2 loss : 0.019747
[12:26:46.139] iteration 29709 : model1 loss : 0.441980 model2 loss : 0.016775
[12:26:46.307] iteration 29710 : model1 loss : 0.440733 model2 loss : 0.018184
[12:26:46.475] iteration 29711 : model1 loss : 0.437011 model2 loss : 0.018053
[12:26:46.643] iteration 29712 : model1 loss : 0.441839 model2 loss : 0.016569
[12:26:46.814] iteration 29713 : model1 loss : 0.439050 model2 loss : 0.019840
[12:26:46.982] iteration 29714 : model1 loss : 0.436984 model2 loss : 0.018440
[12:26:47.152] iteration 29715 : model1 loss : 0.438859 model2 loss : 0.016804
[12:26:47.320] iteration 29716 : model1 loss : 0.440038 model2 loss : 0.016046
[12:26:47.486] iteration 29717 : model1 loss : 0.441896 model2 loss : 0.018783
[12:26:47.653] iteration 29718 : model1 loss : 0.441254 model2 loss : 0.018784
[12:26:47.822] iteration 29719 : model1 loss : 0.437941 model2 loss : 0.017789
[12:26:47.988] iteration 29720 : model1 loss : 0.440441 model2 loss : 0.017222
[12:26:48.157] iteration 29721 : model1 loss : 0.438669 model2 loss : 0.017159
[12:26:48.326] iteration 29722 : model1 loss : 0.436928 model2 loss : 0.019386
[12:26:48.495] iteration 29723 : model1 loss : 0.438718 model2 loss : 0.017527
[12:26:48.663] iteration 29724 : model1 loss : 0.442548 model2 loss : 0.018413
[12:26:48.832] iteration 29725 : model1 loss : 0.443983 model2 loss : 0.020457
[12:26:49.000] iteration 29726 : model1 loss : 0.439978 model2 loss : 0.019136
[12:26:49.168] iteration 29727 : model1 loss : 0.439759 model2 loss : 0.018522
[12:26:49.335] iteration 29728 : model1 loss : 0.441764 model2 loss : 0.018230
[12:26:49.505] iteration 29729 : model1 loss : 0.439275 model2 loss : 0.015620
[12:26:49.672] iteration 29730 : model1 loss : 0.437526 model2 loss : 0.016471
[12:26:49.841] iteration 29731 : model1 loss : 0.437137 model2 loss : 0.017232
[12:26:50.009] iteration 29732 : model1 loss : 0.442170 model2 loss : 0.018393
[12:26:50.175] iteration 29733 : model1 loss : 0.439879 model2 loss : 0.018393
[12:26:52.099] iteration 29734 : model1 loss : 0.440600 model2 loss : 0.019891
[12:26:52.271] iteration 29735 : model1 loss : 0.443256 model2 loss : 0.021220
[12:26:52.443] iteration 29736 : model1 loss : 0.438302 model2 loss : 0.017297
[12:26:52.610] iteration 29737 : model1 loss : 0.444862 model2 loss : 0.019007
[12:26:52.779] iteration 29738 : model1 loss : 0.439601 model2 loss : 0.017753
[12:26:52.946] iteration 29739 : model1 loss : 0.439937 model2 loss : 0.019471
[12:26:53.114] iteration 29740 : model1 loss : 0.440975 model2 loss : 0.019452
[12:26:53.282] iteration 29741 : model1 loss : 0.444104 model2 loss : 0.018295
[12:26:53.451] iteration 29742 : model1 loss : 0.436278 model2 loss : 0.018632
[12:26:53.617] iteration 29743 : model1 loss : 0.438641 model2 loss : 0.017378
[12:26:53.786] iteration 29744 : model1 loss : 0.441558 model2 loss : 0.017822
[12:26:53.954] iteration 29745 : model1 loss : 0.437586 model2 loss : 0.019343
[12:26:54.124] iteration 29746 : model1 loss : 0.440134 model2 loss : 0.019790
[12:26:54.290] iteration 29747 : model1 loss : 0.442662 model2 loss : 0.018330
[12:26:54.458] iteration 29748 : model1 loss : 0.436911 model2 loss : 0.019293
[12:26:54.625] iteration 29749 : model1 loss : 0.440741 model2 loss : 0.018810
[12:26:54.793] iteration 29750 : model1 loss : 0.439642 model2 loss : 0.016250
[12:26:54.957] iteration 29751 : model1 loss : 0.437836 model2 loss : 0.018894
[12:26:55.128] iteration 29752 : model1 loss : 0.440674 model2 loss : 0.019210
[12:26:55.294] iteration 29753 : model1 loss : 0.441999 model2 loss : 0.020465
[12:26:55.465] iteration 29754 : model1 loss : 0.441063 model2 loss : 0.017545
[12:26:55.632] iteration 29755 : model1 loss : 0.439727 model2 loss : 0.017220
[12:26:55.801] iteration 29756 : model1 loss : 0.438903 model2 loss : 0.017446
[12:26:55.970] iteration 29757 : model1 loss : 0.442321 model2 loss : 0.020364
[12:26:56.138] iteration 29758 : model1 loss : 0.434175 model2 loss : 0.018162
[12:26:56.304] iteration 29759 : model1 loss : 0.445072 model2 loss : 0.018981
[12:26:56.473] iteration 29760 : model1 loss : 0.441641 model2 loss : 0.017613
[12:26:56.642] iteration 29761 : model1 loss : 0.439455 model2 loss : 0.020239
[12:26:56.811] iteration 29762 : model1 loss : 0.438932 model2 loss : 0.017478
[12:26:56.978] iteration 29763 : model1 loss : 0.442952 model2 loss : 0.018429
[12:26:57.148] iteration 29764 : model1 loss : 0.437402 model2 loss : 0.017963
[12:26:57.313] iteration 29765 : model1 loss : 0.440445 model2 loss : 0.018457
[12:26:57.482] iteration 29766 : model1 loss : 0.438289 model2 loss : 0.017826
[12:26:59.369] iteration 29767 : model1 loss : 0.437972 model2 loss : 0.015422
[12:26:59.538] iteration 29768 : model1 loss : 0.442746 model2 loss : 0.020143
[12:26:59.708] iteration 29769 : model1 loss : 0.439287 model2 loss : 0.019279
[12:26:59.873] iteration 29770 : model1 loss : 0.436850 model2 loss : 0.019292
[12:27:00.042] iteration 29771 : model1 loss : 0.438196 model2 loss : 0.018834
[12:27:00.208] iteration 29772 : model1 loss : 0.437535 model2 loss : 0.018173
[12:27:00.378] iteration 29773 : model1 loss : 0.434190 model2 loss : 0.017012
[12:27:00.546] iteration 29774 : model1 loss : 0.439974 model2 loss : 0.017276
[12:27:00.718] iteration 29775 : model1 loss : 0.440445 model2 loss : 0.016488
[12:27:00.885] iteration 29776 : model1 loss : 0.441422 model2 loss : 0.021158
[12:27:01.054] iteration 29777 : model1 loss : 0.442764 model2 loss : 0.020276
[12:27:01.222] iteration 29778 : model1 loss : 0.441070 model2 loss : 0.019326
[12:27:01.391] iteration 29779 : model1 loss : 0.442317 model2 loss : 0.018165
[12:27:01.557] iteration 29780 : model1 loss : 0.446281 model2 loss : 0.019344
[12:27:01.726] iteration 29781 : model1 loss : 0.441262 model2 loss : 0.017583
[12:27:01.893] iteration 29782 : model1 loss : 0.438421 model2 loss : 0.017807
[12:27:02.061] iteration 29783 : model1 loss : 0.444267 model2 loss : 0.021579
[12:27:02.228] iteration 29784 : model1 loss : 0.439492 model2 loss : 0.020971
[12:27:02.397] iteration 29785 : model1 loss : 0.442506 model2 loss : 0.018118
[12:27:02.564] iteration 29786 : model1 loss : 0.439434 model2 loss : 0.016508
[12:27:02.732] iteration 29787 : model1 loss : 0.438215 model2 loss : 0.016400
[12:27:02.898] iteration 29788 : model1 loss : 0.441641 model2 loss : 0.019513
[12:27:03.066] iteration 29789 : model1 loss : 0.438353 model2 loss : 0.019042
[12:27:03.232] iteration 29790 : model1 loss : 0.444247 model2 loss : 0.018576
[12:27:03.400] iteration 29791 : model1 loss : 0.437381 model2 loss : 0.017128
[12:27:03.567] iteration 29792 : model1 loss : 0.439529 model2 loss : 0.016032
[12:27:03.735] iteration 29793 : model1 loss : 0.437806 model2 loss : 0.018382
[12:27:03.901] iteration 29794 : model1 loss : 0.437740 model2 loss : 0.018418
[12:27:04.070] iteration 29795 : model1 loss : 0.443188 model2 loss : 0.018655
[12:27:04.237] iteration 29796 : model1 loss : 0.439187 model2 loss : 0.018331
[12:27:04.406] iteration 29797 : model1 loss : 0.441609 model2 loss : 0.018236
[12:27:04.570] iteration 29798 : model1 loss : 0.436597 model2 loss : 0.017236
[12:27:04.737] iteration 29799 : model1 loss : 0.440061 model2 loss : 0.018820
[12:27:06.693] iteration 29800 : model1 loss : 0.436036 model2 loss : 0.018035
[12:27:06.859] iteration 29801 : model1 loss : 0.441791 model2 loss : 0.017368
[12:27:07.029] iteration 29802 : model1 loss : 0.436886 model2 loss : 0.018146
[12:27:07.195] iteration 29803 : model1 loss : 0.439479 model2 loss : 0.016396
[12:27:07.363] iteration 29804 : model1 loss : 0.443257 model2 loss : 0.019540
[12:27:07.529] iteration 29805 : model1 loss : 0.438166 model2 loss : 0.017513
[12:27:07.700] iteration 29806 : model1 loss : 0.440775 model2 loss : 0.017910
[12:27:07.865] iteration 29807 : model1 loss : 0.441708 model2 loss : 0.017999
[12:27:08.034] iteration 29808 : model1 loss : 0.441705 model2 loss : 0.018690
[12:27:08.200] iteration 29809 : model1 loss : 0.438581 model2 loss : 0.019767
[12:27:08.369] iteration 29810 : model1 loss : 0.441787 model2 loss : 0.019695
[12:27:08.536] iteration 29811 : model1 loss : 0.437657 model2 loss : 0.017121
[12:27:08.704] iteration 29812 : model1 loss : 0.446203 model2 loss : 0.023423
[12:27:08.871] iteration 29813 : model1 loss : 0.439291 model2 loss : 0.019601
[12:27:09.040] iteration 29814 : model1 loss : 0.443362 model2 loss : 0.018953
[12:27:09.206] iteration 29815 : model1 loss : 0.441232 model2 loss : 0.018427
[12:27:09.377] iteration 29816 : model1 loss : 0.439513 model2 loss : 0.016372
[12:27:09.546] iteration 29817 : model1 loss : 0.438027 model2 loss : 0.018580
[12:27:09.716] iteration 29818 : model1 loss : 0.434354 model2 loss : 0.019079
[12:27:09.884] iteration 29819 : model1 loss : 0.442200 model2 loss : 0.019038
[12:27:10.052] iteration 29820 : model1 loss : 0.439908 model2 loss : 0.016828
[12:27:10.220] iteration 29821 : model1 loss : 0.446549 model2 loss : 0.020061
[12:27:10.389] iteration 29822 : model1 loss : 0.433806 model2 loss : 0.019017
[12:27:10.556] iteration 29823 : model1 loss : 0.436919 model2 loss : 0.018524
[12:27:10.726] iteration 29824 : model1 loss : 0.442429 model2 loss : 0.019505
[12:27:10.895] iteration 29825 : model1 loss : 0.439127 model2 loss : 0.018302
[12:27:11.063] iteration 29826 : model1 loss : 0.439164 model2 loss : 0.016531
[12:27:11.231] iteration 29827 : model1 loss : 0.438673 model2 loss : 0.019061
[12:27:11.400] iteration 29828 : model1 loss : 0.441275 model2 loss : 0.018616
[12:27:11.567] iteration 29829 : model1 loss : 0.442391 model2 loss : 0.019625
[12:27:11.736] iteration 29830 : model1 loss : 0.435997 model2 loss : 0.016650
[12:27:11.903] iteration 29831 : model1 loss : 0.440638 model2 loss : 0.020515
[12:27:12.070] iteration 29832 : model1 loss : 0.444848 model2 loss : 0.021869
[12:27:13.950] iteration 29833 : model1 loss : 0.441903 model2 loss : 0.018279
[12:27:14.117] iteration 29834 : model1 loss : 0.441490 model2 loss : 0.019190
[12:27:14.286] iteration 29835 : model1 loss : 0.438717 model2 loss : 0.017204
[12:27:14.453] iteration 29836 : model1 loss : 0.441640 model2 loss : 0.019137
[12:27:14.620] iteration 29837 : model1 loss : 0.438533 model2 loss : 0.015847
[12:27:14.790] iteration 29838 : model1 loss : 0.442375 model2 loss : 0.019606
[12:27:14.960] iteration 29839 : model1 loss : 0.439448 model2 loss : 0.016649
[12:27:15.126] iteration 29840 : model1 loss : 0.442359 model2 loss : 0.018689
[12:27:15.295] iteration 29841 : model1 loss : 0.437323 model2 loss : 0.017491
[12:27:15.462] iteration 29842 : model1 loss : 0.436802 model2 loss : 0.015944
[12:27:15.633] iteration 29843 : model1 loss : 0.438483 model2 loss : 0.019351
[12:27:15.802] iteration 29844 : model1 loss : 0.440181 model2 loss : 0.018422
[12:27:15.975] iteration 29845 : model1 loss : 0.438778 model2 loss : 0.018903
[12:27:16.140] iteration 29846 : model1 loss : 0.446325 model2 loss : 0.022068
[12:27:16.309] iteration 29847 : model1 loss : 0.437115 model2 loss : 0.018847
[12:27:16.477] iteration 29848 : model1 loss : 0.437923 model2 loss : 0.018069
[12:27:16.646] iteration 29849 : model1 loss : 0.437542 model2 loss : 0.019270
[12:27:16.812] iteration 29850 : model1 loss : 0.442628 model2 loss : 0.017867
[12:27:16.980] iteration 29851 : model1 loss : 0.439943 model2 loss : 0.016997
[12:27:17.147] iteration 29852 : model1 loss : 0.439813 model2 loss : 0.018991
[12:27:17.316] iteration 29853 : model1 loss : 0.440138 model2 loss : 0.019161
[12:27:17.483] iteration 29854 : model1 loss : 0.439689 model2 loss : 0.017576
[12:27:17.652] iteration 29855 : model1 loss : 0.436407 model2 loss : 0.017355
[12:27:17.818] iteration 29856 : model1 loss : 0.440629 model2 loss : 0.017438
[12:27:17.986] iteration 29857 : model1 loss : 0.441423 model2 loss : 0.018247
[12:27:18.155] iteration 29858 : model1 loss : 0.437739 model2 loss : 0.018604
[12:27:18.322] iteration 29859 : model1 loss : 0.439376 model2 loss : 0.017555
[12:27:18.490] iteration 29860 : model1 loss : 0.443609 model2 loss : 0.017817
[12:27:18.659] iteration 29861 : model1 loss : 0.439784 model2 loss : 0.018463
[12:27:18.826] iteration 29862 : model1 loss : 0.438074 model2 loss : 0.015896
[12:27:18.995] iteration 29863 : model1 loss : 0.439327 model2 loss : 0.018373
[12:27:19.161] iteration 29864 : model1 loss : 0.442715 model2 loss : 0.022105
[12:27:19.328] iteration 29865 : model1 loss : 0.441330 model2 loss : 0.018196
[12:27:21.244] iteration 29866 : model1 loss : 0.439685 model2 loss : 0.017403
[12:27:21.417] iteration 29867 : model1 loss : 0.439601 model2 loss : 0.016680
[12:27:21.588] iteration 29868 : model1 loss : 0.441049 model2 loss : 0.017764
[12:27:21.755] iteration 29869 : model1 loss : 0.435962 model2 loss : 0.019755
[12:27:21.922] iteration 29870 : model1 loss : 0.438906 model2 loss : 0.016442
[12:27:22.091] iteration 29871 : model1 loss : 0.442347 model2 loss : 0.019863
[12:27:22.259] iteration 29872 : model1 loss : 0.441955 model2 loss : 0.019144
[12:27:22.427] iteration 29873 : model1 loss : 0.440240 model2 loss : 0.016907
[12:27:22.596] iteration 29874 : model1 loss : 0.441492 model2 loss : 0.016674
[12:27:22.764] iteration 29875 : model1 loss : 0.437488 model2 loss : 0.018787
[12:27:22.932] iteration 29876 : model1 loss : 0.438492 model2 loss : 0.019489
[12:27:23.099] iteration 29877 : model1 loss : 0.439806 model2 loss : 0.019687
[12:27:23.268] iteration 29878 : model1 loss : 0.443878 model2 loss : 0.020005
[12:27:23.434] iteration 29879 : model1 loss : 0.438615 model2 loss : 0.018632
[12:27:23.605] iteration 29880 : model1 loss : 0.443166 model2 loss : 0.018734
[12:27:23.772] iteration 29881 : model1 loss : 0.442379 model2 loss : 0.016766
[12:27:23.941] iteration 29882 : model1 loss : 0.441319 model2 loss : 0.018533
[12:27:24.109] iteration 29883 : model1 loss : 0.438759 model2 loss : 0.017054
[12:27:24.279] iteration 29884 : model1 loss : 0.444403 model2 loss : 0.019118
[12:27:24.446] iteration 29885 : model1 loss : 0.436566 model2 loss : 0.017098
[12:27:24.615] iteration 29886 : model1 loss : 0.440696 model2 loss : 0.015672
[12:27:24.784] iteration 29887 : model1 loss : 0.437059 model2 loss : 0.018224
[12:27:24.953] iteration 29888 : model1 loss : 0.439430 model2 loss : 0.018481
[12:27:25.122] iteration 29889 : model1 loss : 0.440378 model2 loss : 0.017025
[12:27:25.291] iteration 29890 : model1 loss : 0.438738 model2 loss : 0.018917
[12:27:25.458] iteration 29891 : model1 loss : 0.442410 model2 loss : 0.020511
[12:27:25.626] iteration 29892 : model1 loss : 0.438479 model2 loss : 0.016766
[12:27:25.796] iteration 29893 : model1 loss : 0.439734 model2 loss : 0.019099
[12:27:25.966] iteration 29894 : model1 loss : 0.439666 model2 loss : 0.017902
[12:27:26.135] iteration 29895 : model1 loss : 0.443666 model2 loss : 0.020809
[12:27:26.303] iteration 29896 : model1 loss : 0.439614 model2 loss : 0.019777
[12:27:26.469] iteration 29897 : model1 loss : 0.439618 model2 loss : 0.017544
[12:27:26.635] iteration 29898 : model1 loss : 0.437275 model2 loss : 0.017849
[12:27:28.569] iteration 29899 : model1 loss : 0.439930 model2 loss : 0.017409
[12:27:28.737] iteration 29900 : model1 loss : 0.441668 model2 loss : 0.018713
[12:27:28.909] iteration 29901 : model1 loss : 0.440544 model2 loss : 0.017807
[12:27:29.075] iteration 29902 : model1 loss : 0.442665 model2 loss : 0.017397
[12:27:29.243] iteration 29903 : model1 loss : 0.437539 model2 loss : 0.016863
[12:27:29.410] iteration 29904 : model1 loss : 0.439999 model2 loss : 0.018503
[12:27:29.581] iteration 29905 : model1 loss : 0.440997 model2 loss : 0.017062
[12:27:29.748] iteration 29906 : model1 loss : 0.439708 model2 loss : 0.019996
[12:27:29.918] iteration 29907 : model1 loss : 0.437929 model2 loss : 0.016953
[12:27:30.085] iteration 29908 : model1 loss : 0.439727 model2 loss : 0.018283
[12:27:30.253] iteration 29909 : model1 loss : 0.435653 model2 loss : 0.017523
[12:27:30.420] iteration 29910 : model1 loss : 0.437308 model2 loss : 0.018601
[12:27:30.588] iteration 29911 : model1 loss : 0.437649 model2 loss : 0.017615
[12:27:30.756] iteration 29912 : model1 loss : 0.441244 model2 loss : 0.018324
[12:27:30.927] iteration 29913 : model1 loss : 0.438158 model2 loss : 0.018667
[12:27:31.095] iteration 29914 : model1 loss : 0.445198 model2 loss : 0.019871
[12:27:31.265] iteration 29915 : model1 loss : 0.436004 model2 loss : 0.018145
[12:27:31.432] iteration 29916 : model1 loss : 0.437899 model2 loss : 0.017851
[12:27:31.600] iteration 29917 : model1 loss : 0.439948 model2 loss : 0.016094
[12:27:31.766] iteration 29918 : model1 loss : 0.437185 model2 loss : 0.016978
[12:27:31.935] iteration 29919 : model1 loss : 0.440930 model2 loss : 0.018886
[12:27:32.101] iteration 29920 : model1 loss : 0.442397 model2 loss : 0.017404
[12:27:32.271] iteration 29921 : model1 loss : 0.438362 model2 loss : 0.019430
[12:27:32.439] iteration 29922 : model1 loss : 0.441600 model2 loss : 0.018842
[12:27:32.607] iteration 29923 : model1 loss : 0.444723 model2 loss : 0.024327
[12:27:32.774] iteration 29924 : model1 loss : 0.438644 model2 loss : 0.020693
[12:27:32.943] iteration 29925 : model1 loss : 0.440678 model2 loss : 0.019746
[12:27:33.108] iteration 29926 : model1 loss : 0.448823 model2 loss : 0.023851
[12:27:33.277] iteration 29927 : model1 loss : 0.438144 model2 loss : 0.018015
[12:27:33.443] iteration 29928 : model1 loss : 0.442840 model2 loss : 0.018144
[12:27:33.611] iteration 29929 : model1 loss : 0.439531 model2 loss : 0.018186
[12:27:33.778] iteration 29930 : model1 loss : 0.441529 model2 loss : 0.020330
[12:27:33.943] iteration 29931 : model1 loss : 0.437391 model2 loss : 0.017000
[12:27:35.897] iteration 29932 : model1 loss : 0.446221 model2 loss : 0.020443
[12:27:36.065] iteration 29933 : model1 loss : 0.436634 model2 loss : 0.018015
[12:27:36.233] iteration 29934 : model1 loss : 0.437895 model2 loss : 0.020510
[12:27:36.401] iteration 29935 : model1 loss : 0.438569 model2 loss : 0.018861
[12:27:36.571] iteration 29936 : model1 loss : 0.439776 model2 loss : 0.017877
[12:27:36.738] iteration 29937 : model1 loss : 0.440545 model2 loss : 0.018142
[12:27:36.907] iteration 29938 : model1 loss : 0.439169 model2 loss : 0.017528
[12:27:37.074] iteration 29939 : model1 loss : 0.442063 model2 loss : 0.019414
[12:27:37.244] iteration 29940 : model1 loss : 0.437729 model2 loss : 0.017623
[12:27:37.411] iteration 29941 : model1 loss : 0.439412 model2 loss : 0.019243
[12:27:37.581] iteration 29942 : model1 loss : 0.440456 model2 loss : 0.019473
[12:27:37.748] iteration 29943 : model1 loss : 0.435126 model2 loss : 0.017085
[12:27:37.916] iteration 29944 : model1 loss : 0.437539 model2 loss : 0.020108
[12:27:38.083] iteration 29945 : model1 loss : 0.440503 model2 loss : 0.019293
[12:27:38.251] iteration 29946 : model1 loss : 0.436489 model2 loss : 0.017899
[12:27:38.418] iteration 29947 : model1 loss : 0.438136 model2 loss : 0.017672
[12:27:38.588] iteration 29948 : model1 loss : 0.436377 model2 loss : 0.017138
[12:27:38.754] iteration 29949 : model1 loss : 0.442674 model2 loss : 0.020504
[12:27:38.921] iteration 29950 : model1 loss : 0.439935 model2 loss : 0.018282
[12:27:39.087] iteration 29951 : model1 loss : 0.440471 model2 loss : 0.019009
[12:27:39.255] iteration 29952 : model1 loss : 0.443610 model2 loss : 0.018528
[12:27:39.421] iteration 29953 : model1 loss : 0.437996 model2 loss : 0.017242
[12:27:39.591] iteration 29954 : model1 loss : 0.444055 model2 loss : 0.018229
[12:27:39.757] iteration 29955 : model1 loss : 0.438523 model2 loss : 0.016965
[12:27:39.925] iteration 29956 : model1 loss : 0.438781 model2 loss : 0.016977
[12:27:40.091] iteration 29957 : model1 loss : 0.438794 model2 loss : 0.019288
[12:27:40.260] iteration 29958 : model1 loss : 0.442976 model2 loss : 0.018203
[12:27:40.426] iteration 29959 : model1 loss : 0.439469 model2 loss : 0.015347
[12:27:40.597] iteration 29960 : model1 loss : 0.442925 model2 loss : 0.018725
[12:27:40.764] iteration 29961 : model1 loss : 0.445230 model2 loss : 0.020454
[12:27:40.935] iteration 29962 : model1 loss : 0.441769 model2 loss : 0.017394
[12:27:41.098] iteration 29963 : model1 loss : 0.439685 model2 loss : 0.018061
[12:27:41.268] iteration 29964 : model1 loss : 0.444180 model2 loss : 0.019273
[12:27:43.151] iteration 29965 : model1 loss : 0.440258 model2 loss : 0.019509
[12:27:43.320] iteration 29966 : model1 loss : 0.441946 model2 loss : 0.019228
[12:27:43.488] iteration 29967 : model1 loss : 0.437671 model2 loss : 0.019141
[12:27:43.654] iteration 29968 : model1 loss : 0.441409 model2 loss : 0.018230
[12:27:43.824] iteration 29969 : model1 loss : 0.443144 model2 loss : 0.020702
[12:27:43.991] iteration 29970 : model1 loss : 0.437015 model2 loss : 0.017919
[12:27:44.159] iteration 29971 : model1 loss : 0.442363 model2 loss : 0.018047
[12:27:44.326] iteration 29972 : model1 loss : 0.441668 model2 loss : 0.017196
[12:27:44.497] iteration 29973 : model1 loss : 0.440790 model2 loss : 0.018546
[12:27:44.664] iteration 29974 : model1 loss : 0.437970 model2 loss : 0.017518
[12:27:44.835] iteration 29975 : model1 loss : 0.444334 model2 loss : 0.018499
[12:27:45.000] iteration 29976 : model1 loss : 0.439741 model2 loss : 0.018073
[12:27:45.172] iteration 29977 : model1 loss : 0.437378 model2 loss : 0.019006
[12:27:45.339] iteration 29978 : model1 loss : 0.440077 model2 loss : 0.018381
[12:27:45.510] iteration 29979 : model1 loss : 0.438237 model2 loss : 0.017533
[12:27:45.677] iteration 29980 : model1 loss : 0.436388 model2 loss : 0.018812
[12:27:45.844] iteration 29981 : model1 loss : 0.442395 model2 loss : 0.019140
[12:27:46.013] iteration 29982 : model1 loss : 0.438972 model2 loss : 0.017696
[12:27:46.182] iteration 29983 : model1 loss : 0.440301 model2 loss : 0.017781
[12:27:46.349] iteration 29984 : model1 loss : 0.441369 model2 loss : 0.019932
[12:27:46.520] iteration 29985 : model1 loss : 0.441381 model2 loss : 0.018600
[12:27:46.687] iteration 29986 : model1 loss : 0.446124 model2 loss : 0.019545
[12:27:46.857] iteration 29987 : model1 loss : 0.442280 model2 loss : 0.018771
[12:27:47.024] iteration 29988 : model1 loss : 0.439112 model2 loss : 0.019755
[12:27:47.194] iteration 29989 : model1 loss : 0.438744 model2 loss : 0.018519
[12:27:47.359] iteration 29990 : model1 loss : 0.439476 model2 loss : 0.017638
[12:27:47.532] iteration 29991 : model1 loss : 0.441902 model2 loss : 0.018084
[12:27:47.700] iteration 29992 : model1 loss : 0.437036 model2 loss : 0.017938
[12:27:47.869] iteration 29993 : model1 loss : 0.438844 model2 loss : 0.018140
[12:27:48.040] iteration 29994 : model1 loss : 0.434347 model2 loss : 0.018448
[12:27:48.209] iteration 29995 : model1 loss : 0.440018 model2 loss : 0.017741
[12:27:48.375] iteration 29996 : model1 loss : 0.442411 model2 loss : 0.019453
[12:27:48.544] iteration 29997 : model1 loss : 0.437836 model2 loss : 0.018705
[12:27:50.430] iteration 29998 : model1 loss : 0.442269 model2 loss : 0.019333
[12:27:50.597] iteration 29999 : model1 loss : 0.443396 model2 loss : 0.017751
[12:27:50.765] iteration 30000 : model1 loss : 0.441767 model2 loss : 0.018204
[12:27:58.925] iteration 30000 : model1_mean_dice : 0.903022 model1_mean_hd95 : 3.253593
[12:28:07.100] iteration 30000 : model2_mean_dice : 0.899056 model2_mean_hd95 : 1.912682
[12:28:07.121] save model1 to ../model/ACDC/EVILv1_kl0.5_tau0.25_21_1337/unet\model1_iter_30000.pth
[12:28:07.139] save model2 to ../model/ACDC/EVILv1_kl0.5_tau0.25_21_1337/unet\model2_iter_30000.pth

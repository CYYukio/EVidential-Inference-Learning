[23:03:34.424] Namespace(base_lr=0.01, batch_size=24, consistency=0.1, consistency_rampup=200.0, consistency_type='mse', deterministic=1, ema_decay=0.99, exp='ACDC/EVILv1_kl0.5_tau0.25', labeled_bs=12, labeled_num=14, max_iterations=30000, model='unet', num_classes=4, patch_size=[256, 256], root_path='../data/ACDC', seed=1337)
[23:03:34.612] 21 iterations per epoch
[23:03:41.525] iteration 1 : model1 loss : 1.420299 model2 loss : 1.079641
[23:03:41.697] iteration 2 : model1 loss : 1.256367 model2 loss : 1.058142
[23:03:41.874] iteration 3 : model1 loss : 0.938886 model2 loss : 1.010964
[23:03:42.045] iteration 4 : model1 loss : 0.702061 model2 loss : 0.926272
[23:03:42.220] iteration 5 : model1 loss : 0.576539 model2 loss : 0.855055
[23:03:42.396] iteration 6 : model1 loss : 0.535793 model2 loss : 0.783629
[23:03:42.574] iteration 7 : model1 loss : 0.512494 model2 loss : 0.684206
[23:03:42.742] iteration 8 : model1 loss : 0.520366 model2 loss : 0.630125
[23:03:42.919] iteration 9 : model1 loss : 0.522511 model2 loss : 0.575562
[23:03:43.089] iteration 10 : model1 loss : 0.519713 model2 loss : 0.534446
[23:03:43.263] iteration 11 : model1 loss : 0.555984 model2 loss : 0.533621
[23:03:43.434] iteration 12 : model1 loss : 0.539885 model2 loss : 0.500583
[23:03:43.610] iteration 13 : model1 loss : 0.529399 model2 loss : 0.491941
[23:03:43.782] iteration 14 : model1 loss : 0.519549 model2 loss : 0.477589
[23:03:43.960] iteration 15 : model1 loss : 0.524589 model2 loss : 0.471457
[23:03:44.132] iteration 16 : model1 loss : 0.521285 model2 loss : 0.469639
[23:03:44.315] iteration 17 : model1 loss : 0.507477 model2 loss : 0.452593
[23:03:44.485] iteration 18 : model1 loss : 0.508949 model2 loss : 0.450823
[23:03:44.662] iteration 19 : model1 loss : 0.521209 model2 loss : 0.462521
[23:03:44.831] iteration 20 : model1 loss : 0.520914 model2 loss : 0.463885
[23:03:45.004] iteration 21 : model1 loss : 0.518868 model2 loss : 0.460435
[23:03:47.105] iteration 22 : model1 loss : 0.539723 model2 loss : 0.486950
[23:03:47.279] iteration 23 : model1 loss : 0.514601 model2 loss : 0.462858
[23:03:47.461] iteration 24 : model1 loss : 0.547025 model2 loss : 0.491556
[23:03:47.632] iteration 25 : model1 loss : 0.505229 model2 loss : 0.447282
[23:03:47.809] iteration 26 : model1 loss : 0.528002 model2 loss : 0.459160
[23:03:47.983] iteration 27 : model1 loss : 0.507064 model2 loss : 0.449547
[23:03:48.162] iteration 28 : model1 loss : 0.512331 model2 loss : 0.443660
[23:03:48.336] iteration 29 : model1 loss : 0.534553 model2 loss : 0.472213
[23:03:48.511] iteration 30 : model1 loss : 0.519228 model2 loss : 0.468512
[23:03:48.682] iteration 31 : model1 loss : 0.521154 model2 loss : 0.461192
[23:03:48.862] iteration 32 : model1 loss : 0.518630 model2 loss : 0.455332
[23:03:49.031] iteration 33 : model1 loss : 0.516014 model2 loss : 0.450611
[23:03:49.203] iteration 34 : model1 loss : 0.529040 model2 loss : 0.468530
[23:03:49.376] iteration 35 : model1 loss : 0.506863 model2 loss : 0.448902
[23:03:49.553] iteration 36 : model1 loss : 0.533630 model2 loss : 0.464519
[23:03:49.721] iteration 37 : model1 loss : 0.523645 model2 loss : 0.457617
[23:03:49.900] iteration 38 : model1 loss : 0.520847 model2 loss : 0.454200
[23:03:50.071] iteration 39 : model1 loss : 0.516673 model2 loss : 0.462954
[23:03:50.245] iteration 40 : model1 loss : 0.519306 model2 loss : 0.448165
[23:03:50.417] iteration 41 : model1 loss : 0.508143 model2 loss : 0.436632
[23:03:50.595] iteration 42 : model1 loss : 0.515916 model2 loss : 0.446713
[23:03:52.742] iteration 43 : model1 loss : 0.533573 model2 loss : 0.467570
[23:03:52.917] iteration 44 : model1 loss : 0.521332 model2 loss : 0.452280
[23:03:53.095] iteration 45 : model1 loss : 0.516696 model2 loss : 0.444273
[23:03:53.267] iteration 46 : model1 loss : 0.517050 model2 loss : 0.456319
[23:03:53.445] iteration 47 : model1 loss : 0.527959 model2 loss : 0.457675
[23:03:53.612] iteration 48 : model1 loss : 0.533263 model2 loss : 0.457057
[23:03:53.788] iteration 49 : model1 loss : 0.500124 model2 loss : 0.437146
[23:03:53.959] iteration 50 : model1 loss : 0.524982 model2 loss : 0.453916
[23:03:54.135] iteration 51 : model1 loss : 0.523483 model2 loss : 0.459253
[23:03:54.308] iteration 52 : model1 loss : 0.537884 model2 loss : 0.451138
[23:03:54.485] iteration 53 : model1 loss : 0.513051 model2 loss : 0.439839
[23:03:54.652] iteration 54 : model1 loss : 0.532076 model2 loss : 0.448872
[23:03:54.825] iteration 55 : model1 loss : 0.510470 model2 loss : 0.444166
[23:03:54.997] iteration 56 : model1 loss : 0.522968 model2 loss : 0.449227
[23:03:55.170] iteration 57 : model1 loss : 0.503650 model2 loss : 0.448248
[23:03:55.356] iteration 58 : model1 loss : 0.524969 model2 loss : 0.444542
[23:03:55.533] iteration 59 : model1 loss : 0.511760 model2 loss : 0.426057
[23:03:55.700] iteration 60 : model1 loss : 0.510027 model2 loss : 0.441138
[23:03:55.875] iteration 61 : model1 loss : 0.512975 model2 loss : 0.433605
[23:03:56.043] iteration 62 : model1 loss : 0.522916 model2 loss : 0.430087
[23:03:56.216] iteration 63 : model1 loss : 0.516970 model2 loss : 0.463070
[23:03:58.375] iteration 64 : model1 loss : 0.531720 model2 loss : 0.455110
[23:03:58.553] iteration 65 : model1 loss : 0.521054 model2 loss : 0.438906
[23:03:58.729] iteration 66 : model1 loss : 0.514263 model2 loss : 0.442282
[23:03:58.903] iteration 67 : model1 loss : 0.503210 model2 loss : 0.424853
[23:03:59.076] iteration 68 : model1 loss : 0.511491 model2 loss : 0.444473
[23:03:59.246] iteration 69 : model1 loss : 0.531050 model2 loss : 0.438174
[23:03:59.424] iteration 70 : model1 loss : 0.512783 model2 loss : 0.428289
[23:03:59.599] iteration 71 : model1 loss : 0.542264 model2 loss : 0.436936
[23:03:59.770] iteration 72 : model1 loss : 0.522987 model2 loss : 0.456938
[23:03:59.945] iteration 73 : model1 loss : 0.522257 model2 loss : 0.445898
[23:04:00.128] iteration 74 : model1 loss : 0.509855 model2 loss : 0.434421
[23:04:00.304] iteration 75 : model1 loss : 0.524470 model2 loss : 0.438875
[23:04:00.480] iteration 76 : model1 loss : 0.515349 model2 loss : 0.450922
[23:04:00.648] iteration 77 : model1 loss : 0.506138 model2 loss : 0.423614
[23:04:00.826] iteration 78 : model1 loss : 0.534662 model2 loss : 0.458804
[23:04:00.998] iteration 79 : model1 loss : 0.505789 model2 loss : 0.410865
[23:04:01.175] iteration 80 : model1 loss : 0.505447 model2 loss : 0.420961
[23:04:01.351] iteration 81 : model1 loss : 0.518975 model2 loss : 0.437738
[23:04:01.530] iteration 82 : model1 loss : 0.518105 model2 loss : 0.441213
[23:04:01.697] iteration 83 : model1 loss : 0.525091 model2 loss : 0.439335
[23:04:01.868] iteration 84 : model1 loss : 0.513754 model2 loss : 0.447243
[23:04:04.021] iteration 85 : model1 loss : 0.521371 model2 loss : 0.422238
[23:04:04.193] iteration 86 : model1 loss : 0.531111 model2 loss : 0.417404
[23:04:04.375] iteration 87 : model1 loss : 0.513546 model2 loss : 0.442724
[23:04:04.545] iteration 88 : model1 loss : 0.523066 model2 loss : 0.440009
[23:04:04.718] iteration 89 : model1 loss : 0.517114 model2 loss : 0.445128
[23:04:04.891] iteration 90 : model1 loss : 0.537188 model2 loss : 0.448761
[23:04:05.064] iteration 91 : model1 loss : 0.540176 model2 loss : 0.432012
[23:04:05.235] iteration 92 : model1 loss : 0.503368 model2 loss : 0.423091
[23:04:05.407] iteration 93 : model1 loss : 0.504909 model2 loss : 0.422531
[23:04:05.579] iteration 94 : model1 loss : 0.504733 model2 loss : 0.423911
[23:04:05.756] iteration 95 : model1 loss : 0.520848 model2 loss : 0.421787
[23:04:05.931] iteration 96 : model1 loss : 0.523539 model2 loss : 0.427073
[23:04:06.104] iteration 97 : model1 loss : 0.508077 model2 loss : 0.428798
[23:04:06.278] iteration 98 : model1 loss : 0.498867 model2 loss : 0.412650
[23:04:06.456] iteration 99 : model1 loss : 0.524182 model2 loss : 0.452635
[23:04:06.629] iteration 100 : model1 loss : 0.512590 model2 loss : 0.429113
[23:04:06.811] iteration 101 : model1 loss : 0.503245 model2 loss : 0.411544
[23:04:06.987] iteration 102 : model1 loss : 0.531773 model2 loss : 0.419302
[23:04:07.163] iteration 103 : model1 loss : 0.513200 model2 loss : 0.425692
[23:04:07.339] iteration 104 : model1 loss : 0.526954 model2 loss : 0.429244
[23:04:07.521] iteration 105 : model1 loss : 0.510322 model2 loss : 0.420650
[23:04:09.675] iteration 106 : model1 loss : 0.528266 model2 loss : 0.426291
[23:04:09.849] iteration 107 : model1 loss : 0.515778 model2 loss : 0.429785
[23:04:10.028] iteration 108 : model1 loss : 0.505875 model2 loss : 0.395272
[23:04:10.200] iteration 109 : model1 loss : 0.504840 model2 loss : 0.418625
[23:04:10.379] iteration 110 : model1 loss : 0.513421 model2 loss : 0.425981
[23:04:10.550] iteration 111 : model1 loss : 0.514536 model2 loss : 0.418798
[23:04:10.724] iteration 112 : model1 loss : 0.526975 model2 loss : 0.436888
[23:04:10.896] iteration 113 : model1 loss : 0.517662 model2 loss : 0.401875
[23:04:11.070] iteration 114 : model1 loss : 0.521685 model2 loss : 0.408729
[23:04:11.239] iteration 115 : model1 loss : 0.538182 model2 loss : 0.442838
[23:04:11.417] iteration 116 : model1 loss : 0.517770 model2 loss : 0.395090
[23:04:11.591] iteration 117 : model1 loss : 0.518193 model2 loss : 0.416052
[23:04:11.778] iteration 118 : model1 loss : 0.524330 model2 loss : 0.392535
[23:04:11.951] iteration 119 : model1 loss : 0.512789 model2 loss : 0.431335
[23:04:12.131] iteration 120 : model1 loss : 0.513781 model2 loss : 0.410444
[23:04:12.306] iteration 121 : model1 loss : 0.515828 model2 loss : 0.442443
[23:04:12.486] iteration 122 : model1 loss : 0.504424 model2 loss : 0.417728
[23:04:12.655] iteration 123 : model1 loss : 0.511139 model2 loss : 0.431709
[23:04:12.830] iteration 124 : model1 loss : 0.529560 model2 loss : 0.404151
[23:04:12.999] iteration 125 : model1 loss : 0.520620 model2 loss : 0.417289
[23:04:13.178] iteration 126 : model1 loss : 0.499192 model2 loss : 0.381105
[23:04:15.363] iteration 127 : model1 loss : 0.511741 model2 loss : 0.428164
[23:04:15.540] iteration 128 : model1 loss : 0.518798 model2 loss : 0.396483
[23:04:15.714] iteration 129 : model1 loss : 0.512105 model2 loss : 0.408638
[23:04:15.887] iteration 130 : model1 loss : 0.505922 model2 loss : 0.399458
[23:04:16.063] iteration 131 : model1 loss : 0.525202 model2 loss : 0.419625
[23:04:16.235] iteration 132 : model1 loss : 0.532457 model2 loss : 0.412732
[23:04:16.414] iteration 133 : model1 loss : 0.527612 model2 loss : 0.392496
[23:04:16.587] iteration 134 : model1 loss : 0.506837 model2 loss : 0.424394
[23:04:16.761] iteration 135 : model1 loss : 0.507228 model2 loss : 0.404236
[23:04:16.936] iteration 136 : model1 loss : 0.513316 model2 loss : 0.394389
[23:04:17.111] iteration 137 : model1 loss : 0.513974 model2 loss : 0.369380
[23:04:17.281] iteration 138 : model1 loss : 0.538031 model2 loss : 0.386564
[23:04:17.459] iteration 139 : model1 loss : 0.514546 model2 loss : 0.393731
[23:04:17.627] iteration 140 : model1 loss : 0.520671 model2 loss : 0.351639
[23:04:17.804] iteration 141 : model1 loss : 0.520925 model2 loss : 0.366169
[23:04:17.977] iteration 142 : model1 loss : 0.513099 model2 loss : 0.394950
[23:04:18.153] iteration 143 : model1 loss : 0.510284 model2 loss : 0.382104
[23:04:18.328] iteration 144 : model1 loss : 0.503974 model2 loss : 0.372338
[23:04:18.503] iteration 145 : model1 loss : 0.506906 model2 loss : 0.371546
[23:04:18.669] iteration 146 : model1 loss : 0.516830 model2 loss : 0.366310
[23:04:18.843] iteration 147 : model1 loss : 0.518121 model2 loss : 0.409590
[23:04:21.050] iteration 148 : model1 loss : 0.509801 model2 loss : 0.392279
[23:04:21.220] iteration 149 : model1 loss : 0.527022 model2 loss : 0.387675
[23:04:21.397] iteration 150 : model1 loss : 0.520072 model2 loss : 0.373446
[23:04:21.569] iteration 151 : model1 loss : 0.519672 model2 loss : 0.407835
[23:04:21.743] iteration 152 : model1 loss : 0.505171 model2 loss : 0.374942
[23:04:21.916] iteration 153 : model1 loss : 0.521108 model2 loss : 0.384287
[23:04:22.090] iteration 154 : model1 loss : 0.514227 model2 loss : 0.366144
[23:04:22.262] iteration 155 : model1 loss : 0.507921 model2 loss : 0.396423
[23:04:22.437] iteration 156 : model1 loss : 0.511098 model2 loss : 0.379555
[23:04:22.611] iteration 157 : model1 loss : 0.520435 model2 loss : 0.400965
[23:04:22.784] iteration 158 : model1 loss : 0.513836 model2 loss : 0.392159
[23:04:22.960] iteration 159 : model1 loss : 0.518502 model2 loss : 0.368052
[23:04:23.135] iteration 160 : model1 loss : 0.506291 model2 loss : 0.335263
[23:04:23.309] iteration 161 : model1 loss : 0.506976 model2 loss : 0.368703
[23:04:23.489] iteration 162 : model1 loss : 0.524986 model2 loss : 0.361778
[23:04:23.658] iteration 163 : model1 loss : 0.518741 model2 loss : 0.358178
[23:04:23.834] iteration 164 : model1 loss : 0.504798 model2 loss : 0.347402
[23:04:24.007] iteration 165 : model1 loss : 0.511375 model2 loss : 0.334256
[23:04:24.185] iteration 166 : model1 loss : 0.518672 model2 loss : 0.355700
[23:04:24.357] iteration 167 : model1 loss : 0.508840 model2 loss : 0.359935
[23:04:24.533] iteration 168 : model1 loss : 0.528805 model2 loss : 0.368360
[23:04:26.689] iteration 169 : model1 loss : 0.518541 model2 loss : 0.361370
[23:04:26.864] iteration 170 : model1 loss : 0.508256 model2 loss : 0.342678
[23:04:27.043] iteration 171 : model1 loss : 0.506681 model2 loss : 0.319509
[23:04:27.214] iteration 172 : model1 loss : 0.525686 model2 loss : 0.348930
[23:04:27.391] iteration 173 : model1 loss : 0.522811 model2 loss : 0.355820
[23:04:27.564] iteration 174 : model1 loss : 0.521677 model2 loss : 0.339137
[23:04:27.735] iteration 175 : model1 loss : 0.508250 model2 loss : 0.341320
[23:04:27.908] iteration 176 : model1 loss : 0.509374 model2 loss : 0.321002
[23:04:28.089] iteration 177 : model1 loss : 0.510788 model2 loss : 0.326603
[23:04:28.262] iteration 178 : model1 loss : 0.513484 model2 loss : 0.340996
[23:04:28.441] iteration 179 : model1 loss : 0.520096 model2 loss : 0.369636
[23:04:28.615] iteration 180 : model1 loss : 0.517591 model2 loss : 0.337869
[23:04:28.789] iteration 181 : model1 loss : 0.511434 model2 loss : 0.318007
[23:04:28.964] iteration 182 : model1 loss : 0.517376 model2 loss : 0.349037
[23:04:29.139] iteration 183 : model1 loss : 0.516164 model2 loss : 0.340144
[23:04:29.312] iteration 184 : model1 loss : 0.514001 model2 loss : 0.333885
[23:04:29.491] iteration 185 : model1 loss : 0.526537 model2 loss : 0.348364
[23:04:29.661] iteration 186 : model1 loss : 0.505672 model2 loss : 0.337751
[23:04:29.867] iteration 187 : model1 loss : 0.504836 model2 loss : 0.321140
[23:04:30.036] iteration 188 : model1 loss : 0.504654 model2 loss : 0.288933
[23:04:30.211] iteration 189 : model1 loss : 0.509182 model2 loss : 0.325448
[23:04:32.392] iteration 190 : model1 loss : 0.521241 model2 loss : 0.328789
[23:04:32.565] iteration 191 : model1 loss : 0.513317 model2 loss : 0.306527
[23:04:32.742] iteration 192 : model1 loss : 0.514560 model2 loss : 0.301780
[23:04:32.913] iteration 193 : model1 loss : 0.514351 model2 loss : 0.331655
[23:04:33.089] iteration 194 : model1 loss : 0.505843 model2 loss : 0.341952
[23:04:33.260] iteration 195 : model1 loss : 0.517281 model2 loss : 0.345732
[23:04:33.432] iteration 196 : model1 loss : 0.512848 model2 loss : 0.340086
[23:04:33.605] iteration 197 : model1 loss : 0.506986 model2 loss : 0.293742
[23:04:33.781] iteration 198 : model1 loss : 0.527461 model2 loss : 0.329613
[23:04:33.953] iteration 199 : model1 loss : 0.525946 model2 loss : 0.359657
[23:04:34.129] iteration 200 : model1 loss : 0.503622 model2 loss : 0.350312
[23:04:34.302] iteration 201 : model1 loss : 0.513871 model2 loss : 0.341257
[23:04:34.477] iteration 202 : model1 loss : 0.507150 model2 loss : 0.297853
[23:04:34.646] iteration 203 : model1 loss : 0.499223 model2 loss : 0.346509
[23:04:34.819] iteration 204 : model1 loss : 0.499325 model2 loss : 0.331647
[23:04:34.992] iteration 205 : model1 loss : 0.531783 model2 loss : 0.320822
[23:04:35.167] iteration 206 : model1 loss : 0.503668 model2 loss : 0.328192
[23:04:35.343] iteration 207 : model1 loss : 0.497362 model2 loss : 0.306610
[23:04:35.523] iteration 208 : model1 loss : 0.524207 model2 loss : 0.322490
[23:04:35.689] iteration 209 : model1 loss : 0.508917 model2 loss : 0.309097
[23:04:35.864] iteration 210 : model1 loss : 0.519775 model2 loss : 0.289905
[23:04:38.045] iteration 211 : model1 loss : 0.509469 model2 loss : 0.291852
[23:04:38.221] iteration 212 : model1 loss : 0.518274 model2 loss : 0.314422
[23:04:38.402] iteration 213 : model1 loss : 0.498296 model2 loss : 0.337777
[23:04:38.574] iteration 214 : model1 loss : 0.513248 model2 loss : 0.300130
[23:04:38.747] iteration 215 : model1 loss : 0.521360 model2 loss : 0.321976
[23:04:38.920] iteration 216 : model1 loss : 0.514157 model2 loss : 0.323637
[23:04:39.095] iteration 217 : model1 loss : 0.515631 model2 loss : 0.289058
[23:04:39.266] iteration 218 : model1 loss : 0.512455 model2 loss : 0.271749
[23:04:39.444] iteration 219 : model1 loss : 0.495829 model2 loss : 0.297309
[23:04:39.616] iteration 220 : model1 loss : 0.518078 model2 loss : 0.341088
[23:04:39.794] iteration 221 : model1 loss : 0.509803 model2 loss : 0.329122
[23:04:39.966] iteration 222 : model1 loss : 0.512201 model2 loss : 0.306311
[23:04:40.140] iteration 223 : model1 loss : 0.502489 model2 loss : 0.308143
[23:04:40.313] iteration 224 : model1 loss : 0.519185 model2 loss : 0.323495
[23:04:40.492] iteration 225 : model1 loss : 0.520787 model2 loss : 0.307282
[23:04:40.663] iteration 226 : model1 loss : 0.500653 model2 loss : 0.291657
[23:04:40.835] iteration 227 : model1 loss : 0.533790 model2 loss : 0.297657
[23:04:41.008] iteration 228 : model1 loss : 0.503503 model2 loss : 0.318311
[23:04:41.184] iteration 229 : model1 loss : 0.509926 model2 loss : 0.298320
[23:04:41.355] iteration 230 : model1 loss : 0.510899 model2 loss : 0.295494
[23:04:41.531] iteration 231 : model1 loss : 0.493262 model2 loss : 0.275348
[23:04:43.690] iteration 232 : model1 loss : 0.505953 model2 loss : 0.289230
[23:04:43.869] iteration 233 : model1 loss : 0.513537 model2 loss : 0.300795
[23:04:44.047] iteration 234 : model1 loss : 0.501553 model2 loss : 0.289406
[23:04:44.220] iteration 235 : model1 loss : 0.507698 model2 loss : 0.276232
[23:04:44.399] iteration 236 : model1 loss : 0.516486 model2 loss : 0.300317
[23:04:44.570] iteration 237 : model1 loss : 0.522512 model2 loss : 0.303705
[23:04:44.741] iteration 238 : model1 loss : 0.504960 model2 loss : 0.290976
[23:04:44.913] iteration 239 : model1 loss : 0.508921 model2 loss : 0.267782
[23:04:45.089] iteration 240 : model1 loss : 0.513478 model2 loss : 0.308679
[23:04:45.261] iteration 241 : model1 loss : 0.509534 model2 loss : 0.292942
[23:04:45.438] iteration 242 : model1 loss : 0.520319 model2 loss : 0.314055
[23:04:45.611] iteration 243 : model1 loss : 0.504014 model2 loss : 0.317350
[23:04:45.782] iteration 244 : model1 loss : 0.497815 model2 loss : 0.316655
[23:04:45.954] iteration 245 : model1 loss : 0.501365 model2 loss : 0.271975
[23:04:46.130] iteration 246 : model1 loss : 0.503982 model2 loss : 0.244985
[23:04:46.304] iteration 247 : model1 loss : 0.503764 model2 loss : 0.285048
[23:04:46.480] iteration 248 : model1 loss : 0.482659 model2 loss : 0.250800
[23:04:46.649] iteration 249 : model1 loss : 0.497203 model2 loss : 0.265068
[23:04:46.825] iteration 250 : model1 loss : 0.510011 model2 loss : 0.275055
[23:04:46.997] iteration 251 : model1 loss : 0.494466 model2 loss : 0.253445
[23:04:47.170] iteration 252 : model1 loss : 0.504637 model2 loss : 0.262762
[23:04:49.340] iteration 253 : model1 loss : 0.496778 model2 loss : 0.258370
[23:04:49.516] iteration 254 : model1 loss : 0.497389 model2 loss : 0.269160
[23:04:49.694] iteration 255 : model1 loss : 0.505057 model2 loss : 0.246885
[23:04:49.864] iteration 256 : model1 loss : 0.508380 model2 loss : 0.281118
[23:04:50.040] iteration 257 : model1 loss : 0.497613 model2 loss : 0.219218
[23:04:50.218] iteration 258 : model1 loss : 0.497816 model2 loss : 0.274536
[23:04:50.399] iteration 259 : model1 loss : 0.506624 model2 loss : 0.260023
[23:04:50.571] iteration 260 : model1 loss : 0.506753 model2 loss : 0.247568
[23:04:50.743] iteration 261 : model1 loss : 0.515051 model2 loss : 0.242391
[23:04:50.913] iteration 262 : model1 loss : 0.521902 model2 loss : 0.300982
[23:04:51.093] iteration 263 : model1 loss : 0.508099 model2 loss : 0.294801
[23:04:51.264] iteration 264 : model1 loss : 0.504454 model2 loss : 0.238555
[23:04:51.444] iteration 265 : model1 loss : 0.514399 model2 loss : 0.305880
[23:04:51.619] iteration 266 : model1 loss : 0.503959 model2 loss : 0.287285
[23:04:51.794] iteration 267 : model1 loss : 0.493929 model2 loss : 0.261897
[23:04:51.967] iteration 268 : model1 loss : 0.502659 model2 loss : 0.243009
[23:04:52.141] iteration 269 : model1 loss : 0.504839 model2 loss : 0.244602
[23:04:52.317] iteration 270 : model1 loss : 0.491877 model2 loss : 0.241473
[23:04:52.501] iteration 271 : model1 loss : 0.505293 model2 loss : 0.253852
[23:04:52.669] iteration 272 : model1 loss : 0.511322 model2 loss : 0.269442
[23:04:52.841] iteration 273 : model1 loss : 0.508042 model2 loss : 0.259700
[23:04:54.980] iteration 274 : model1 loss : 0.504617 model2 loss : 0.299252
[23:04:55.156] iteration 275 : model1 loss : 0.498365 model2 loss : 0.244677
[23:04:55.338] iteration 276 : model1 loss : 0.500536 model2 loss : 0.249352
[23:04:55.510] iteration 277 : model1 loss : 0.506159 model2 loss : 0.383298
[23:04:55.687] iteration 278 : model1 loss : 0.492648 model2 loss : 0.226671
[23:04:55.855] iteration 279 : model1 loss : 0.514647 model2 loss : 0.221518
[23:04:56.033] iteration 280 : model1 loss : 0.496166 model2 loss : 0.213578
[23:04:56.205] iteration 281 : model1 loss : 0.497340 model2 loss : 0.238054
[23:04:56.384] iteration 282 : model1 loss : 0.504368 model2 loss : 0.244315
[23:04:56.557] iteration 283 : model1 loss : 0.503356 model2 loss : 0.269532
[23:04:56.730] iteration 284 : model1 loss : 0.504744 model2 loss : 0.213956
[23:04:56.900] iteration 285 : model1 loss : 0.516020 model2 loss : 0.264940
[23:04:57.075] iteration 286 : model1 loss : 0.491817 model2 loss : 0.224484
[23:04:57.244] iteration 287 : model1 loss : 0.503698 model2 loss : 0.222363
[23:04:57.426] iteration 288 : model1 loss : 0.497653 model2 loss : 0.235931
[23:04:57.601] iteration 289 : model1 loss : 0.505412 model2 loss : 0.207366
[23:04:57.775] iteration 290 : model1 loss : 0.511222 model2 loss : 0.228286
[23:04:57.948] iteration 291 : model1 loss : 0.490665 model2 loss : 0.223814
[23:04:58.128] iteration 292 : model1 loss : 0.497346 model2 loss : 0.260724
[23:04:58.298] iteration 293 : model1 loss : 0.496216 model2 loss : 0.235954
[23:04:58.471] iteration 294 : model1 loss : 0.500507 model2 loss : 0.245460
[23:05:00.620] iteration 295 : model1 loss : 0.510395 model2 loss : 0.209235
[23:05:00.794] iteration 296 : model1 loss : 0.496945 model2 loss : 0.260055
[23:05:00.973] iteration 297 : model1 loss : 0.500973 model2 loss : 0.255562
[23:05:01.147] iteration 298 : model1 loss : 0.496839 model2 loss : 0.233100
[23:05:01.325] iteration 299 : model1 loss : 0.501251 model2 loss : 0.232597
[23:05:01.498] iteration 300 : model1 loss : 0.496220 model2 loss : 0.214981
[23:05:01.673] iteration 301 : model1 loss : 0.507774 model2 loss : 0.191284
[23:05:01.844] iteration 302 : model1 loss : 0.502939 model2 loss : 0.219081
[23:05:02.023] iteration 303 : model1 loss : 0.488321 model2 loss : 0.177796
[23:05:02.196] iteration 304 : model1 loss : 0.510453 model2 loss : 0.226863
[23:05:02.371] iteration 305 : model1 loss : 0.499660 model2 loss : 0.206840
[23:05:02.547] iteration 306 : model1 loss : 0.493450 model2 loss : 0.211430
[23:05:02.724] iteration 307 : model1 loss : 0.479753 model2 loss : 0.178507
[23:05:02.895] iteration 308 : model1 loss : 0.491442 model2 loss : 0.171104
[23:05:03.071] iteration 309 : model1 loss : 0.497767 model2 loss : 0.242551
[23:05:03.241] iteration 310 : model1 loss : 0.491309 model2 loss : 0.232913
[23:05:03.420] iteration 311 : model1 loss : 0.492287 model2 loss : 0.233625
[23:05:03.593] iteration 312 : model1 loss : 0.499587 model2 loss : 0.204154
[23:05:03.766] iteration 313 : model1 loss : 0.501493 model2 loss : 0.147798
[23:05:03.939] iteration 314 : model1 loss : 0.505116 model2 loss : 0.223698
[23:05:04.117] iteration 315 : model1 loss : 0.503146 model2 loss : 0.196765
[23:05:06.253] iteration 316 : model1 loss : 0.485526 model2 loss : 0.183847
[23:05:06.430] iteration 317 : model1 loss : 0.490891 model2 loss : 0.210397
[23:05:06.611] iteration 318 : model1 loss : 0.489868 model2 loss : 0.145521
[23:05:06.780] iteration 319 : model1 loss : 0.492235 model2 loss : 0.167148
[23:05:06.958] iteration 320 : model1 loss : 0.492178 model2 loss : 0.180773
[23:05:07.129] iteration 321 : model1 loss : 0.504863 model2 loss : 0.192016
[23:05:07.307] iteration 322 : model1 loss : 0.494188 model2 loss : 0.201328
[23:05:07.486] iteration 323 : model1 loss : 0.488600 model2 loss : 0.204096
[23:05:07.664] iteration 324 : model1 loss : 0.499652 model2 loss : 0.174000
[23:05:07.835] iteration 325 : model1 loss : 0.480754 model2 loss : 0.186053
[23:05:08.012] iteration 326 : model1 loss : 0.505742 model2 loss : 0.222743
[23:05:08.184] iteration 327 : model1 loss : 0.493831 model2 loss : 0.142075
[23:05:08.362] iteration 328 : model1 loss : 0.495364 model2 loss : 0.167104
[23:05:08.536] iteration 329 : model1 loss : 0.489814 model2 loss : 0.232394
[23:05:08.710] iteration 330 : model1 loss : 0.503646 model2 loss : 0.189676
[23:05:08.879] iteration 331 : model1 loss : 0.496432 model2 loss : 0.174285
[23:05:09.054] iteration 332 : model1 loss : 0.487368 model2 loss : 0.174468
[23:05:09.225] iteration 333 : model1 loss : 0.483718 model2 loss : 0.200970
[23:05:09.404] iteration 334 : model1 loss : 0.488793 model2 loss : 0.127123
[23:05:09.574] iteration 335 : model1 loss : 0.507412 model2 loss : 0.179275
[23:05:09.746] iteration 336 : model1 loss : 0.503865 model2 loss : 0.202455
[23:05:11.888] iteration 337 : model1 loss : 0.503468 model2 loss : 0.185564
[23:05:12.066] iteration 338 : model1 loss : 0.482327 model2 loss : 0.163553
[23:05:12.242] iteration 339 : model1 loss : 0.492233 model2 loss : 0.156595
[23:05:12.418] iteration 340 : model1 loss : 0.486295 model2 loss : 0.189962
[23:05:12.598] iteration 341 : model1 loss : 0.483027 model2 loss : 0.187137
[23:05:12.768] iteration 342 : model1 loss : 0.483942 model2 loss : 0.171902
[23:05:12.946] iteration 343 : model1 loss : 0.507187 model2 loss : 0.199806
[23:05:13.117] iteration 344 : model1 loss : 0.489964 model2 loss : 0.164362
[23:05:13.295] iteration 345 : model1 loss : 0.505723 model2 loss : 0.218448
[23:05:13.469] iteration 346 : model1 loss : 0.480035 model2 loss : 0.176260
[23:05:13.644] iteration 347 : model1 loss : 0.489690 model2 loss : 0.173051
[23:05:13.814] iteration 348 : model1 loss : 0.495578 model2 loss : 0.129718
[23:05:13.992] iteration 349 : model1 loss : 0.486857 model2 loss : 0.247244
[23:05:14.165] iteration 350 : model1 loss : 0.506541 model2 loss : 0.206796
[23:05:14.343] iteration 351 : model1 loss : 0.490824 model2 loss : 0.158080
[23:05:14.517] iteration 352 : model1 loss : 0.489629 model2 loss : 0.132438
[23:05:14.693] iteration 353 : model1 loss : 0.501305 model2 loss : 0.109778
[23:05:14.867] iteration 354 : model1 loss : 0.489512 model2 loss : 0.135464
[23:05:15.041] iteration 355 : model1 loss : 0.483432 model2 loss : 0.136838
[23:05:15.213] iteration 356 : model1 loss : 0.503218 model2 loss : 0.158003
[23:05:15.387] iteration 357 : model1 loss : 0.500776 model2 loss : 0.100609
[23:05:17.581] iteration 358 : model1 loss : 0.497395 model2 loss : 0.177974
[23:05:17.753] iteration 359 : model1 loss : 0.490254 model2 loss : 0.117674
[23:05:17.933] iteration 360 : model1 loss : 0.488088 model2 loss : 0.133474
[23:05:18.105] iteration 361 : model1 loss : 0.510560 model2 loss : 0.121460
[23:05:18.282] iteration 362 : model1 loss : 0.489091 model2 loss : 0.160148
[23:05:18.455] iteration 363 : model1 loss : 0.495891 model2 loss : 0.139035
[23:05:18.630] iteration 364 : model1 loss : 0.487135 model2 loss : 0.112707
[23:05:18.800] iteration 365 : model1 loss : 0.486749 model2 loss : 0.138314
[23:05:18.981] iteration 366 : model1 loss : 0.489854 model2 loss : 0.125761
[23:05:19.152] iteration 367 : model1 loss : 0.485238 model2 loss : 0.124786
[23:05:19.331] iteration 368 : model1 loss : 0.477215 model2 loss : 0.143311
[23:05:19.505] iteration 369 : model1 loss : 0.485171 model2 loss : 0.151419
[23:05:19.680] iteration 370 : model1 loss : 0.480006 model2 loss : 0.132507
[23:05:19.848] iteration 371 : model1 loss : 0.485325 model2 loss : 0.155263
[23:05:20.025] iteration 372 : model1 loss : 0.483290 model2 loss : 0.163500
[23:05:20.195] iteration 373 : model1 loss : 0.482531 model2 loss : 0.145508
[23:05:20.372] iteration 374 : model1 loss : 0.479001 model2 loss : 0.135585
[23:05:20.544] iteration 375 : model1 loss : 0.479874 model2 loss : 0.146651
[23:05:20.718] iteration 376 : model1 loss : 0.499294 model2 loss : 0.107935
[23:05:20.886] iteration 377 : model1 loss : 0.492257 model2 loss : 0.112822
[23:05:21.061] iteration 378 : model1 loss : 0.477739 model2 loss : 0.110116
[23:05:23.229] iteration 379 : model1 loss : 0.488245 model2 loss : 0.138372
[23:05:23.404] iteration 380 : model1 loss : 0.482140 model2 loss : 0.110855
[23:05:23.582] iteration 381 : model1 loss : 0.493066 model2 loss : 0.127039
[23:05:23.754] iteration 382 : model1 loss : 0.486755 model2 loss : 0.094118
[23:05:23.928] iteration 383 : model1 loss : 0.485204 model2 loss : 0.175193
[23:05:24.102] iteration 384 : model1 loss : 0.489196 model2 loss : 0.157110
[23:05:24.277] iteration 385 : model1 loss : 0.497330 model2 loss : 0.149333
[23:05:24.451] iteration 386 : model1 loss : 0.489087 model2 loss : 0.121668
[23:05:24.628] iteration 387 : model1 loss : 0.478066 model2 loss : 0.145402
[23:05:24.799] iteration 388 : model1 loss : 0.492286 model2 loss : 0.107023
[23:05:24.975] iteration 389 : model1 loss : 0.487523 model2 loss : 0.170957
[23:05:25.148] iteration 390 : model1 loss : 0.481413 model2 loss : 0.153591
[23:05:25.331] iteration 391 : model1 loss : 0.486162 model2 loss : 0.180380
[23:05:25.504] iteration 392 : model1 loss : 0.491705 model2 loss : 0.144883
[23:05:25.680] iteration 393 : model1 loss : 0.482606 model2 loss : 0.117112
[23:05:25.861] iteration 394 : model1 loss : 0.502446 model2 loss : 0.127964
[23:05:26.042] iteration 395 : model1 loss : 0.493219 model2 loss : 0.171174
[23:05:26.214] iteration 396 : model1 loss : 0.491038 model2 loss : 0.101440
[23:05:26.391] iteration 397 : model1 loss : 0.485799 model2 loss : 0.117915
[23:05:26.565] iteration 398 : model1 loss : 0.481850 model2 loss : 0.119316
[23:05:26.736] iteration 399 : model1 loss : 0.485401 model2 loss : 0.149921
[23:05:28.911] iteration 400 : model1 loss : 0.486951 model2 loss : 0.167750
[23:05:29.090] iteration 401 : model1 loss : 0.490337 model2 loss : 0.163063
[23:05:29.265] iteration 402 : model1 loss : 0.485675 model2 loss : 0.132126
[23:05:29.438] iteration 403 : model1 loss : 0.487450 model2 loss : 0.096958
[23:05:29.620] iteration 404 : model1 loss : 0.491744 model2 loss : 0.126725
[23:05:29.791] iteration 405 : model1 loss : 0.489472 model2 loss : 0.139824
[23:05:29.967] iteration 406 : model1 loss : 0.494381 model2 loss : 0.123547
[23:05:30.139] iteration 407 : model1 loss : 0.484815 model2 loss : 0.116591
[23:05:30.317] iteration 408 : model1 loss : 0.485511 model2 loss : 0.157834
[23:05:30.490] iteration 409 : model1 loss : 0.499291 model2 loss : 0.156936
[23:05:30.663] iteration 410 : model1 loss : 0.479362 model2 loss : 0.082866
[23:05:30.834] iteration 411 : model1 loss : 0.486987 model2 loss : 0.073074
[23:05:31.011] iteration 412 : model1 loss : 0.487047 model2 loss : 0.100980
[23:05:31.184] iteration 413 : model1 loss : 0.478285 model2 loss : 0.132729
[23:05:31.361] iteration 414 : model1 loss : 0.485561 model2 loss : 0.123211
[23:05:31.534] iteration 415 : model1 loss : 0.484377 model2 loss : 0.115469
[23:05:31.709] iteration 416 : model1 loss : 0.477003 model2 loss : 0.101507
[23:05:31.880] iteration 417 : model1 loss : 0.481110 model2 loss : 0.084833
[23:05:32.055] iteration 418 : model1 loss : 0.484361 model2 loss : 0.090059
[23:05:32.223] iteration 419 : model1 loss : 0.476210 model2 loss : 0.144802
[23:05:32.399] iteration 420 : model1 loss : 0.479331 model2 loss : 0.108365
[23:05:34.569] iteration 421 : model1 loss : 0.482846 model2 loss : 0.144836
[23:05:34.745] iteration 422 : model1 loss : 0.476707 model2 loss : 0.120836
[23:05:34.923] iteration 423 : model1 loss : 0.485507 model2 loss : 0.120016
[23:05:35.097] iteration 424 : model1 loss : 0.486326 model2 loss : 0.073958
[23:05:35.271] iteration 425 : model1 loss : 0.489683 model2 loss : 0.146153
[23:05:35.443] iteration 426 : model1 loss : 0.478121 model2 loss : 0.120694
[23:05:35.622] iteration 427 : model1 loss : 0.480730 model2 loss : 0.130950
[23:05:35.791] iteration 428 : model1 loss : 0.478162 model2 loss : 0.113200
[23:05:35.965] iteration 429 : model1 loss : 0.486603 model2 loss : 0.087347
[23:05:36.137] iteration 430 : model1 loss : 0.482132 model2 loss : 0.130409
[23:05:36.316] iteration 431 : model1 loss : 0.470133 model2 loss : 0.090022
[23:05:36.490] iteration 432 : model1 loss : 0.487366 model2 loss : 0.172976
[23:05:36.666] iteration 433 : model1 loss : 0.476647 model2 loss : 0.076289
[23:05:36.836] iteration 434 : model1 loss : 0.478039 model2 loss : 0.106537
[23:05:37.013] iteration 435 : model1 loss : 0.482472 model2 loss : 0.081923
[23:05:37.184] iteration 436 : model1 loss : 0.470126 model2 loss : 0.098821
[23:05:37.361] iteration 437 : model1 loss : 0.493973 model2 loss : 0.188508
[23:05:37.538] iteration 438 : model1 loss : 0.478217 model2 loss : 0.102964
[23:05:37.713] iteration 439 : model1 loss : 0.481000 model2 loss : 0.112082
[23:05:37.881] iteration 440 : model1 loss : 0.484457 model2 loss : 0.115028
[23:05:38.058] iteration 441 : model1 loss : 0.476179 model2 loss : 0.095875
[23:05:40.210] iteration 442 : model1 loss : 0.475255 model2 loss : 0.084067
[23:05:40.383] iteration 443 : model1 loss : 0.478419 model2 loss : 0.133757
[23:05:40.563] iteration 444 : model1 loss : 0.470845 model2 loss : 0.077881
[23:05:40.732] iteration 445 : model1 loss : 0.479436 model2 loss : 0.099507
[23:05:40.905] iteration 446 : model1 loss : 0.485105 model2 loss : 0.110911
[23:05:41.077] iteration 447 : model1 loss : 0.489770 model2 loss : 0.125047
[23:05:41.251] iteration 448 : model1 loss : 0.489245 model2 loss : 0.168644
[23:05:41.422] iteration 449 : model1 loss : 0.480893 model2 loss : 0.109913
[23:05:41.607] iteration 450 : model1 loss : 0.487587 model2 loss : 0.144848
[23:05:41.778] iteration 451 : model1 loss : 0.479240 model2 loss : 0.105588
[23:05:41.952] iteration 452 : model1 loss : 0.482237 model2 loss : 0.124685
[23:05:42.126] iteration 453 : model1 loss : 0.480081 model2 loss : 0.067433
[23:05:42.304] iteration 454 : model1 loss : 0.477848 model2 loss : 0.092383
[23:05:42.483] iteration 455 : model1 loss : 0.474779 model2 loss : 0.130681
[23:05:42.660] iteration 456 : model1 loss : 0.480364 model2 loss : 0.120739
[23:05:42.827] iteration 457 : model1 loss : 0.478442 model2 loss : 0.111063
[23:05:43.004] iteration 458 : model1 loss : 0.483323 model2 loss : 0.146261
[23:05:43.175] iteration 459 : model1 loss : 0.475544 model2 loss : 0.105560
[23:05:43.353] iteration 460 : model1 loss : 0.479523 model2 loss : 0.116928
[23:05:43.526] iteration 461 : model1 loss : 0.480100 model2 loss : 0.096934
[23:05:43.699] iteration 462 : model1 loss : 0.482431 model2 loss : 0.121270
[23:05:45.870] iteration 463 : model1 loss : 0.478776 model2 loss : 0.079868
[23:05:46.048] iteration 464 : model1 loss : 0.478275 model2 loss : 0.100396
[23:05:46.225] iteration 465 : model1 loss : 0.474613 model2 loss : 0.135621
[23:05:46.397] iteration 466 : model1 loss : 0.473974 model2 loss : 0.123360
[23:05:46.576] iteration 467 : model1 loss : 0.488758 model2 loss : 0.157626
[23:05:46.744] iteration 468 : model1 loss : 0.480730 model2 loss : 0.138440
[23:05:46.917] iteration 469 : model1 loss : 0.471290 model2 loss : 0.067537
[23:05:47.092] iteration 470 : model1 loss : 0.473362 model2 loss : 0.072042
[23:05:47.268] iteration 471 : model1 loss : 0.477340 model2 loss : 0.133161
[23:05:47.442] iteration 472 : model1 loss : 0.478003 model2 loss : 0.086389
[23:05:47.623] iteration 473 : model1 loss : 0.478583 model2 loss : 0.082701
[23:05:47.792] iteration 474 : model1 loss : 0.486546 model2 loss : 0.075550
[23:05:47.968] iteration 475 : model1 loss : 0.487972 model2 loss : 0.144170
[23:05:48.139] iteration 476 : model1 loss : 0.479835 model2 loss : 0.086023
[23:05:48.322] iteration 477 : model1 loss : 0.487259 model2 loss : 0.130529
[23:05:48.495] iteration 478 : model1 loss : 0.482775 model2 loss : 0.115386
[23:05:48.671] iteration 479 : model1 loss : 0.474954 model2 loss : 0.119690
[23:05:48.840] iteration 480 : model1 loss : 0.482052 model2 loss : 0.073844
[23:05:49.015] iteration 481 : model1 loss : 0.481559 model2 loss : 0.121567
[23:05:49.184] iteration 482 : model1 loss : 0.475309 model2 loss : 0.132568
[23:05:49.358] iteration 483 : model1 loss : 0.477551 model2 loss : 0.091371
[23:05:51.522] iteration 484 : model1 loss : 0.469262 model2 loss : 0.076144
[23:05:51.696] iteration 485 : model1 loss : 0.479496 model2 loss : 0.108392
[23:05:51.875] iteration 486 : model1 loss : 0.482730 model2 loss : 0.130178
[23:05:52.047] iteration 487 : model1 loss : 0.481677 model2 loss : 0.091304
[23:05:52.222] iteration 488 : model1 loss : 0.478223 model2 loss : 0.076957
[23:05:52.393] iteration 489 : model1 loss : 0.470632 model2 loss : 0.082459
[23:05:52.571] iteration 490 : model1 loss : 0.476026 model2 loss : 0.117214
[23:05:52.741] iteration 491 : model1 loss : 0.470642 model2 loss : 0.096647
[23:05:52.913] iteration 492 : model1 loss : 0.481487 model2 loss : 0.119845
[23:05:53.086] iteration 493 : model1 loss : 0.472124 model2 loss : 0.098958
[23:05:53.265] iteration 494 : model1 loss : 0.480463 model2 loss : 0.132392
[23:05:53.436] iteration 495 : model1 loss : 0.476924 model2 loss : 0.088431
[23:05:53.616] iteration 496 : model1 loss : 0.482109 model2 loss : 0.109750
[23:05:53.786] iteration 497 : model1 loss : 0.482773 model2 loss : 0.075537
[23:05:53.962] iteration 498 : model1 loss : 0.477009 model2 loss : 0.089100
[23:05:54.138] iteration 499 : model1 loss : 0.480204 model2 loss : 0.126239
[23:05:54.319] iteration 500 : model1 loss : 0.477150 model2 loss : 0.141521
[23:05:54.490] iteration 501 : model1 loss : 0.475407 model2 loss : 0.109596
[23:05:54.667] iteration 502 : model1 loss : 0.479185 model2 loss : 0.081028
[23:05:54.836] iteration 503 : model1 loss : 0.475898 model2 loss : 0.115488
[23:05:55.010] iteration 504 : model1 loss : 0.476221 model2 loss : 0.083268
[23:05:57.163] iteration 505 : model1 loss : 0.486736 model2 loss : 0.123140
[23:05:57.342] iteration 506 : model1 loss : 0.484546 model2 loss : 0.095859
[23:05:57.524] iteration 507 : model1 loss : 0.478275 model2 loss : 0.097980
[23:05:57.695] iteration 508 : model1 loss : 0.477236 model2 loss : 0.097509
[23:05:57.872] iteration 509 : model1 loss : 0.474013 model2 loss : 0.109835
[23:05:58.044] iteration 510 : model1 loss : 0.473588 model2 loss : 0.087529
[23:05:58.220] iteration 511 : model1 loss : 0.469925 model2 loss : 0.109095
[23:05:58.391] iteration 512 : model1 loss : 0.473820 model2 loss : 0.151278
[23:05:58.570] iteration 513 : model1 loss : 0.483930 model2 loss : 0.096920
[23:05:58.740] iteration 514 : model1 loss : 0.475772 model2 loss : 0.079549
[23:05:58.914] iteration 515 : model1 loss : 0.476745 model2 loss : 0.124092
[23:05:59.088] iteration 516 : model1 loss : 0.472733 model2 loss : 0.104332
[23:05:59.263] iteration 517 : model1 loss : 0.476237 model2 loss : 0.123492
[23:05:59.433] iteration 518 : model1 loss : 0.483684 model2 loss : 0.092984
[23:05:59.613] iteration 519 : model1 loss : 0.476236 model2 loss : 0.073388
[23:05:59.784] iteration 520 : model1 loss : 0.476729 model2 loss : 0.148476
[23:05:59.960] iteration 521 : model1 loss : 0.476573 model2 loss : 0.072011
[23:06:00.140] iteration 522 : model1 loss : 0.471618 model2 loss : 0.078512
[23:06:00.318] iteration 523 : model1 loss : 0.471391 model2 loss : 0.098432
[23:06:00.487] iteration 524 : model1 loss : 0.472693 model2 loss : 0.137789
[23:06:00.661] iteration 525 : model1 loss : 0.472711 model2 loss : 0.087294
[23:06:02.834] iteration 526 : model1 loss : 0.474182 model2 loss : 0.071089
[23:06:03.007] iteration 527 : model1 loss : 0.479792 model2 loss : 0.091827
[23:06:03.186] iteration 528 : model1 loss : 0.475960 model2 loss : 0.097957
[23:06:03.358] iteration 529 : model1 loss : 0.486232 model2 loss : 0.113831
[23:06:03.536] iteration 530 : model1 loss : 0.475353 model2 loss : 0.103272
[23:06:03.706] iteration 531 : model1 loss : 0.477687 model2 loss : 0.121053
[23:06:03.879] iteration 532 : model1 loss : 0.474498 model2 loss : 0.093162
[23:06:04.051] iteration 533 : model1 loss : 0.471047 model2 loss : 0.060464
[23:06:04.228] iteration 534 : model1 loss : 0.469071 model2 loss : 0.062574
[23:06:04.408] iteration 535 : model1 loss : 0.474599 model2 loss : 0.097716
[23:06:04.587] iteration 536 : model1 loss : 0.474532 model2 loss : 0.093301
[23:06:04.756] iteration 537 : model1 loss : 0.482064 model2 loss : 0.142037
[23:06:04.928] iteration 538 : model1 loss : 0.475345 model2 loss : 0.112783
[23:06:05.102] iteration 539 : model1 loss : 0.489593 model2 loss : 0.121895
[23:06:05.275] iteration 540 : model1 loss : 0.466810 model2 loss : 0.063596
[23:06:05.445] iteration 541 : model1 loss : 0.468729 model2 loss : 0.073028
[23:06:05.621] iteration 542 : model1 loss : 0.471778 model2 loss : 0.069315
[23:06:05.789] iteration 543 : model1 loss : 0.479031 model2 loss : 0.143558
[23:06:05.965] iteration 544 : model1 loss : 0.485576 model2 loss : 0.142490
[23:06:06.136] iteration 545 : model1 loss : 0.468150 model2 loss : 0.082381
[23:06:06.312] iteration 546 : model1 loss : 0.472720 model2 loss : 0.102489
[23:06:08.487] iteration 547 : model1 loss : 0.473091 model2 loss : 0.101725
[23:06:08.663] iteration 548 : model1 loss : 0.478879 model2 loss : 0.068240
[23:06:08.841] iteration 549 : model1 loss : 0.476272 model2 loss : 0.106161
[23:06:09.011] iteration 550 : model1 loss : 0.466329 model2 loss : 0.086928
[23:06:09.191] iteration 551 : model1 loss : 0.469015 model2 loss : 0.083637
[23:06:09.363] iteration 552 : model1 loss : 0.473317 model2 loss : 0.095331
[23:06:09.542] iteration 553 : model1 loss : 0.474235 model2 loss : 0.077651
[23:06:09.713] iteration 554 : model1 loss : 0.483317 model2 loss : 0.177330
[23:06:09.889] iteration 555 : model1 loss : 0.476931 model2 loss : 0.094673
[23:06:10.062] iteration 556 : model1 loss : 0.472700 model2 loss : 0.073745
[23:06:10.237] iteration 557 : model1 loss : 0.489119 model2 loss : 0.195157
[23:06:10.409] iteration 558 : model1 loss : 0.469942 model2 loss : 0.091450
[23:06:10.591] iteration 559 : model1 loss : 0.467208 model2 loss : 0.155841
[23:06:10.761] iteration 560 : model1 loss : 0.475168 model2 loss : 0.149910
[23:06:10.935] iteration 561 : model1 loss : 0.485440 model2 loss : 0.128865
[23:06:11.108] iteration 562 : model1 loss : 0.475984 model2 loss : 0.157219
[23:06:11.287] iteration 563 : model1 loss : 0.477589 model2 loss : 0.084641
[23:06:11.459] iteration 564 : model1 loss : 0.468958 model2 loss : 0.084472
[23:06:11.634] iteration 565 : model1 loss : 0.472441 model2 loss : 0.083202
[23:06:11.803] iteration 566 : model1 loss : 0.470642 model2 loss : 0.117503
[23:06:11.979] iteration 567 : model1 loss : 0.477100 model2 loss : 0.116703
[23:06:14.140] iteration 568 : model1 loss : 0.474229 model2 loss : 0.119607
[23:06:14.323] iteration 569 : model1 loss : 0.471462 model2 loss : 0.167897
[23:06:14.498] iteration 570 : model1 loss : 0.470582 model2 loss : 0.122309
[23:06:14.671] iteration 571 : model1 loss : 0.473347 model2 loss : 0.102423
[23:06:14.842] iteration 572 : model1 loss : 0.472285 model2 loss : 0.119574
[23:06:15.012] iteration 573 : model1 loss : 0.472769 model2 loss : 0.078772
[23:06:15.194] iteration 574 : model1 loss : 0.475940 model2 loss : 0.110128
[23:06:15.365] iteration 575 : model1 loss : 0.471782 model2 loss : 0.103075
[23:06:15.541] iteration 576 : model1 loss : 0.470497 model2 loss : 0.086051
[23:06:15.713] iteration 577 : model1 loss : 0.472661 model2 loss : 0.100757
[23:06:15.887] iteration 578 : model1 loss : 0.472432 model2 loss : 0.098646
[23:06:16.058] iteration 579 : model1 loss : 0.479151 model2 loss : 0.145654
[23:06:16.237] iteration 580 : model1 loss : 0.479743 model2 loss : 0.131348
[23:06:16.410] iteration 581 : model1 loss : 0.475061 model2 loss : 0.140408
[23:06:16.590] iteration 582 : model1 loss : 0.482621 model2 loss : 0.088054
[23:06:16.763] iteration 583 : model1 loss : 0.474810 model2 loss : 0.079449
[23:06:16.938] iteration 584 : model1 loss : 0.471853 model2 loss : 0.072468
[23:06:17.112] iteration 585 : model1 loss : 0.489333 model2 loss : 0.121263
[23:06:17.291] iteration 586 : model1 loss : 0.470463 model2 loss : 0.101218
[23:06:17.464] iteration 587 : model1 loss : 0.465427 model2 loss : 0.087499
[23:06:17.636] iteration 588 : model1 loss : 0.467778 model2 loss : 0.078830
[23:06:19.776] iteration 589 : model1 loss : 0.468643 model2 loss : 0.086839
[23:06:19.950] iteration 590 : model1 loss : 0.484894 model2 loss : 0.114699
[23:06:20.132] iteration 591 : model1 loss : 0.463041 model2 loss : 0.091929
[23:06:20.304] iteration 592 : model1 loss : 0.469709 model2 loss : 0.084610
[23:06:20.479] iteration 593 : model1 loss : 0.473064 model2 loss : 0.093361
[23:06:20.653] iteration 594 : model1 loss : 0.472728 model2 loss : 0.119113
[23:06:20.825] iteration 595 : model1 loss : 0.479190 model2 loss : 0.087444
[23:06:20.996] iteration 596 : model1 loss : 0.469982 model2 loss : 0.069522
[23:06:21.169] iteration 597 : model1 loss : 0.471946 model2 loss : 0.105903
[23:06:21.341] iteration 598 : model1 loss : 0.475611 model2 loss : 0.119629
[23:06:21.520] iteration 599 : model1 loss : 0.465601 model2 loss : 0.064768
[23:06:21.693] iteration 600 : model1 loss : 0.472744 model2 loss : 0.129081
[23:06:21.868] iteration 601 : model1 loss : 0.480106 model2 loss : 0.112368
[23:06:22.039] iteration 602 : model1 loss : 0.477612 model2 loss : 0.084117
[23:06:22.217] iteration 603 : model1 loss : 0.474808 model2 loss : 0.126598
[23:06:22.390] iteration 604 : model1 loss : 0.470550 model2 loss : 0.058890
[23:06:22.569] iteration 605 : model1 loss : 0.469672 model2 loss : 0.076859
[23:06:22.740] iteration 606 : model1 loss : 0.475800 model2 loss : 0.059385
[23:06:22.917] iteration 607 : model1 loss : 0.469904 model2 loss : 0.101540
[23:06:23.090] iteration 608 : model1 loss : 0.471676 model2 loss : 0.081911
[23:06:23.264] iteration 609 : model1 loss : 0.468022 model2 loss : 0.067402
[23:06:25.428] iteration 610 : model1 loss : 0.468325 model2 loss : 0.085741
[23:06:25.606] iteration 611 : model1 loss : 0.475168 model2 loss : 0.057972
[23:06:25.783] iteration 612 : model1 loss : 0.477798 model2 loss : 0.076369
[23:06:25.954] iteration 613 : model1 loss : 0.472072 model2 loss : 0.123958
[23:06:26.132] iteration 614 : model1 loss : 0.469407 model2 loss : 0.101636
[23:06:26.310] iteration 615 : model1 loss : 0.479080 model2 loss : 0.097515
[23:06:26.488] iteration 616 : model1 loss : 0.473527 model2 loss : 0.076114
[23:06:26.661] iteration 617 : model1 loss : 0.472748 model2 loss : 0.070966
[23:06:26.834] iteration 618 : model1 loss : 0.466686 model2 loss : 0.073207
[23:06:27.006] iteration 619 : model1 loss : 0.481923 model2 loss : 0.138813
[23:06:27.185] iteration 620 : model1 loss : 0.472325 model2 loss : 0.084626
[23:06:27.357] iteration 621 : model1 loss : 0.473238 model2 loss : 0.080849
[23:06:27.533] iteration 622 : model1 loss : 0.475533 model2 loss : 0.077847
[23:06:27.705] iteration 623 : model1 loss : 0.465240 model2 loss : 0.084196
[23:06:27.881] iteration 624 : model1 loss : 0.466669 model2 loss : 0.117463
[23:06:28.052] iteration 625 : model1 loss : 0.480342 model2 loss : 0.105467
[23:06:28.232] iteration 626 : model1 loss : 0.471645 model2 loss : 0.086637
[23:06:28.405] iteration 627 : model1 loss : 0.472556 model2 loss : 0.083619
[23:06:28.584] iteration 628 : model1 loss : 0.475775 model2 loss : 0.091692
[23:06:28.753] iteration 629 : model1 loss : 0.478831 model2 loss : 0.086484
[23:06:28.927] iteration 630 : model1 loss : 0.465606 model2 loss : 0.083358
[23:06:31.078] iteration 631 : model1 loss : 0.476194 model2 loss : 0.085727
[23:06:31.265] iteration 632 : model1 loss : 0.470152 model2 loss : 0.074894
[23:06:31.442] iteration 633 : model1 loss : 0.469967 model2 loss : 0.096117
[23:06:31.616] iteration 634 : model1 loss : 0.471210 model2 loss : 0.085100
[23:06:31.793] iteration 635 : model1 loss : 0.478862 model2 loss : 0.096163
[23:06:31.966] iteration 636 : model1 loss : 0.464973 model2 loss : 0.091952
[23:06:32.146] iteration 637 : model1 loss : 0.481678 model2 loss : 0.118702
[23:06:32.323] iteration 638 : model1 loss : 0.477375 model2 loss : 0.088662
[23:06:32.506] iteration 639 : model1 loss : 0.466932 model2 loss : 0.052859
[23:06:32.678] iteration 640 : model1 loss : 0.470146 model2 loss : 0.070817
[23:06:32.852] iteration 641 : model1 loss : 0.466755 model2 loss : 0.081721
[23:06:33.023] iteration 642 : model1 loss : 0.470413 model2 loss : 0.090713
[23:06:33.200] iteration 643 : model1 loss : 0.468279 model2 loss : 0.065883
[23:06:33.372] iteration 644 : model1 loss : 0.479647 model2 loss : 0.105668
[23:06:33.549] iteration 645 : model1 loss : 0.463302 model2 loss : 0.066252
[23:06:33.721] iteration 646 : model1 loss : 0.469828 model2 loss : 0.090034
[23:06:33.898] iteration 647 : model1 loss : 0.468158 model2 loss : 0.072261
[23:06:34.071] iteration 648 : model1 loss : 0.466431 model2 loss : 0.055106
[23:06:34.250] iteration 649 : model1 loss : 0.470971 model2 loss : 0.075580
[23:06:34.420] iteration 650 : model1 loss : 0.472028 model2 loss : 0.096050
[23:06:34.598] iteration 651 : model1 loss : 0.460884 model2 loss : 0.061670
[23:06:36.724] iteration 652 : model1 loss : 0.471256 model2 loss : 0.090707
[23:06:36.899] iteration 653 : model1 loss : 0.473933 model2 loss : 0.069836
[23:06:37.077] iteration 654 : model1 loss : 0.469006 model2 loss : 0.089012
[23:06:37.252] iteration 655 : model1 loss : 0.470644 model2 loss : 0.092851
[23:06:37.431] iteration 656 : model1 loss : 0.471030 model2 loss : 0.085339
[23:06:37.604] iteration 657 : model1 loss : 0.470962 model2 loss : 0.061440
[23:06:37.779] iteration 658 : model1 loss : 0.468485 model2 loss : 0.065709
[23:06:37.948] iteration 659 : model1 loss : 0.473499 model2 loss : 0.118042
[23:06:38.131] iteration 660 : model1 loss : 0.468499 model2 loss : 0.066868
[23:06:38.307] iteration 661 : model1 loss : 0.469594 model2 loss : 0.070900
[23:06:38.484] iteration 662 : model1 loss : 0.465080 model2 loss : 0.065845
[23:06:38.655] iteration 663 : model1 loss : 0.468117 model2 loss : 0.075425
[23:06:38.829] iteration 664 : model1 loss : 0.474395 model2 loss : 0.083449
[23:06:38.999] iteration 665 : model1 loss : 0.469137 model2 loss : 0.111310
[23:06:39.176] iteration 666 : model1 loss : 0.488777 model2 loss : 0.139989
[23:06:39.348] iteration 667 : model1 loss : 0.462763 model2 loss : 0.082433
[23:06:39.526] iteration 668 : model1 loss : 0.469797 model2 loss : 0.090202
[23:06:39.698] iteration 669 : model1 loss : 0.460687 model2 loss : 0.091585
[23:06:39.872] iteration 670 : model1 loss : 0.462861 model2 loss : 0.076219
[23:06:40.040] iteration 671 : model1 loss : 0.463665 model2 loss : 0.066938
[23:06:40.214] iteration 672 : model1 loss : 0.461432 model2 loss : 0.075388
[23:06:42.345] iteration 673 : model1 loss : 0.470158 model2 loss : 0.078483
[23:06:42.523] iteration 674 : model1 loss : 0.466093 model2 loss : 0.102616
[23:06:42.698] iteration 675 : model1 loss : 0.470091 model2 loss : 0.078610
[23:06:42.871] iteration 676 : model1 loss : 0.464684 model2 loss : 0.084465
[23:06:43.045] iteration 677 : model1 loss : 0.468165 model2 loss : 0.101327
[23:06:43.220] iteration 678 : model1 loss : 0.477098 model2 loss : 0.091392
[23:06:43.398] iteration 679 : model1 loss : 0.465299 model2 loss : 0.070324
[23:06:43.570] iteration 680 : model1 loss : 0.457660 model2 loss : 0.065862
[23:06:43.748] iteration 681 : model1 loss : 0.472290 model2 loss : 0.092945
[23:06:43.918] iteration 682 : model1 loss : 0.474630 model2 loss : 0.087692
[23:06:44.099] iteration 683 : model1 loss : 0.467302 model2 loss : 0.057569
[23:06:44.272] iteration 684 : model1 loss : 0.467306 model2 loss : 0.071863
[23:06:44.450] iteration 685 : model1 loss : 0.470133 model2 loss : 0.118104
[23:06:44.625] iteration 686 : model1 loss : 0.477043 model2 loss : 0.118808
[23:06:44.801] iteration 687 : model1 loss : 0.462499 model2 loss : 0.053258
[23:06:44.970] iteration 688 : model1 loss : 0.467335 model2 loss : 0.064067
[23:06:45.146] iteration 689 : model1 loss : 0.468866 model2 loss : 0.085523
[23:06:45.323] iteration 690 : model1 loss : 0.472035 model2 loss : 0.074129
[23:06:45.499] iteration 691 : model1 loss : 0.462895 model2 loss : 0.062408
[23:06:45.672] iteration 692 : model1 loss : 0.461342 model2 loss : 0.065846
[23:06:45.846] iteration 693 : model1 loss : 0.468874 model2 loss : 0.071178
[23:06:48.012] iteration 694 : model1 loss : 0.470891 model2 loss : 0.085452
[23:06:48.187] iteration 695 : model1 loss : 0.477754 model2 loss : 0.100362
[23:06:48.364] iteration 696 : model1 loss : 0.462426 model2 loss : 0.056930
[23:06:48.539] iteration 697 : model1 loss : 0.462379 model2 loss : 0.070895
[23:06:48.714] iteration 698 : model1 loss : 0.465450 model2 loss : 0.060869
[23:06:48.883] iteration 699 : model1 loss : 0.475270 model2 loss : 0.082945
[23:06:49.058] iteration 700 : model1 loss : 0.464513 model2 loss : 0.066844
[23:06:49.232] iteration 701 : model1 loss : 0.468791 model2 loss : 0.105219
[23:06:49.407] iteration 702 : model1 loss : 0.461778 model2 loss : 0.061288
[23:06:49.580] iteration 703 : model1 loss : 0.464063 model2 loss : 0.071100
[23:06:49.754] iteration 704 : model1 loss : 0.478058 model2 loss : 0.099161
[23:06:49.927] iteration 705 : model1 loss : 0.462276 model2 loss : 0.065753
[23:06:50.104] iteration 706 : model1 loss : 0.467322 model2 loss : 0.066306
[23:06:50.278] iteration 707 : model1 loss : 0.464444 model2 loss : 0.081362
[23:06:50.456] iteration 708 : model1 loss : 0.472939 model2 loss : 0.081458
[23:06:50.633] iteration 709 : model1 loss : 0.462384 model2 loss : 0.052534
[23:06:50.808] iteration 710 : model1 loss : 0.472016 model2 loss : 0.091484
[23:06:50.978] iteration 711 : model1 loss : 0.465201 model2 loss : 0.071622
[23:06:51.153] iteration 712 : model1 loss : 0.472092 model2 loss : 0.064681
[23:06:51.326] iteration 713 : model1 loss : 0.462247 model2 loss : 0.074840
[23:06:51.499] iteration 714 : model1 loss : 0.460505 model2 loss : 0.067579
[23:06:53.771] iteration 715 : model1 loss : 0.461641 model2 loss : 0.055475
[23:06:53.942] iteration 716 : model1 loss : 0.461094 model2 loss : 0.076314
[23:06:54.126] iteration 717 : model1 loss : 0.474509 model2 loss : 0.100191
[23:06:54.301] iteration 718 : model1 loss : 0.469179 model2 loss : 0.066790
[23:06:54.478] iteration 719 : model1 loss : 0.461097 model2 loss : 0.056888
[23:06:54.653] iteration 720 : model1 loss : 0.473578 model2 loss : 0.098306
[23:06:54.830] iteration 721 : model1 loss : 0.462408 model2 loss : 0.056977
[23:06:55.002] iteration 722 : model1 loss : 0.466439 model2 loss : 0.083461
[23:06:55.180] iteration 723 : model1 loss : 0.461972 model2 loss : 0.060210
[23:06:55.353] iteration 724 : model1 loss : 0.465049 model2 loss : 0.067604
[23:06:55.529] iteration 725 : model1 loss : 0.465710 model2 loss : 0.170690
[23:06:55.704] iteration 726 : model1 loss : 0.464886 model2 loss : 0.068711
[23:06:55.879] iteration 727 : model1 loss : 0.464347 model2 loss : 0.062188
[23:06:56.058] iteration 728 : model1 loss : 0.469973 model2 loss : 0.078254
[23:06:56.239] iteration 729 : model1 loss : 0.471023 model2 loss : 0.105043
[23:06:56.412] iteration 730 : model1 loss : 0.470212 model2 loss : 0.084238
[23:06:56.594] iteration 731 : model1 loss : 0.467723 model2 loss : 0.082589
[23:06:56.770] iteration 732 : model1 loss : 0.464455 model2 loss : 0.056222
[23:06:56.944] iteration 733 : model1 loss : 0.461749 model2 loss : 0.073078
[23:06:57.111] iteration 734 : model1 loss : 0.475014 model2 loss : 0.072576
[23:06:57.287] iteration 735 : model1 loss : 0.468479 model2 loss : 0.076896
[23:06:59.534] iteration 736 : model1 loss : 0.460067 model2 loss : 0.069245
[23:06:59.710] iteration 737 : model1 loss : 0.463262 model2 loss : 0.083137
[23:06:59.890] iteration 738 : model1 loss : 0.466454 model2 loss : 0.088033
[23:07:00.066] iteration 739 : model1 loss : 0.463715 model2 loss : 0.072719
[23:07:00.247] iteration 740 : model1 loss : 0.471929 model2 loss : 0.092316
[23:07:00.419] iteration 741 : model1 loss : 0.468950 model2 loss : 0.127909
[23:07:00.614] iteration 742 : model1 loss : 0.481088 model2 loss : 0.100244
[23:07:00.787] iteration 743 : model1 loss : 0.461183 model2 loss : 0.065881
[23:07:00.962] iteration 744 : model1 loss : 0.475145 model2 loss : 0.117967
[23:07:01.137] iteration 745 : model1 loss : 0.464709 model2 loss : 0.066001
[23:07:01.316] iteration 746 : model1 loss : 0.465976 model2 loss : 0.089266
[23:07:01.487] iteration 747 : model1 loss : 0.460597 model2 loss : 0.074870
[23:07:01.664] iteration 748 : model1 loss : 0.460975 model2 loss : 0.063673
[23:07:01.835] iteration 749 : model1 loss : 0.469967 model2 loss : 0.085788
[23:07:02.013] iteration 750 : model1 loss : 0.475982 model2 loss : 0.093581
[23:07:02.189] iteration 751 : model1 loss : 0.465543 model2 loss : 0.084723
[23:07:02.368] iteration 752 : model1 loss : 0.462412 model2 loss : 0.068880
[23:07:02.541] iteration 753 : model1 loss : 0.465355 model2 loss : 0.065479
[23:07:02.716] iteration 754 : model1 loss : 0.481781 model2 loss : 0.115454
[23:07:02.884] iteration 755 : model1 loss : 0.464185 model2 loss : 0.097328
[23:07:03.055] iteration 756 : model1 loss : 0.467650 model2 loss : 0.092234
[23:07:05.193] iteration 757 : model1 loss : 0.480380 model2 loss : 0.103257
[23:07:05.371] iteration 758 : model1 loss : 0.464912 model2 loss : 0.065951
[23:07:05.551] iteration 759 : model1 loss : 0.479725 model2 loss : 0.102896
[23:07:05.722] iteration 760 : model1 loss : 0.459774 model2 loss : 0.069954
[23:07:05.897] iteration 761 : model1 loss : 0.468885 model2 loss : 0.051013
[23:07:06.068] iteration 762 : model1 loss : 0.465344 model2 loss : 0.062724
[23:07:06.243] iteration 763 : model1 loss : 0.466125 model2 loss : 0.073361
[23:07:06.416] iteration 764 : model1 loss : 0.466910 model2 loss : 0.065451
[23:07:06.592] iteration 765 : model1 loss : 0.464273 model2 loss : 0.088148
[23:07:06.765] iteration 766 : model1 loss : 0.460949 model2 loss : 0.074015
[23:07:06.938] iteration 767 : model1 loss : 0.461948 model2 loss : 0.058910
[23:07:07.110] iteration 768 : model1 loss : 0.470555 model2 loss : 0.053603
[23:07:07.289] iteration 769 : model1 loss : 0.464731 model2 loss : 0.089484
[23:07:07.464] iteration 770 : model1 loss : 0.464022 model2 loss : 0.066891
[23:07:07.639] iteration 771 : model1 loss : 0.473575 model2 loss : 0.077249
[23:07:07.811] iteration 772 : model1 loss : 0.466994 model2 loss : 0.062515
[23:07:07.990] iteration 773 : model1 loss : 0.475108 model2 loss : 0.124720
[23:07:08.163] iteration 774 : model1 loss : 0.464551 model2 loss : 0.065952
[23:07:08.347] iteration 775 : model1 loss : 0.463938 model2 loss : 0.056245
[23:07:08.517] iteration 776 : model1 loss : 0.461905 model2 loss : 0.054729
[23:07:08.690] iteration 777 : model1 loss : 0.460536 model2 loss : 0.074344
[23:07:10.820] iteration 778 : model1 loss : 0.462949 model2 loss : 0.076958
[23:07:10.995] iteration 779 : model1 loss : 0.455714 model2 loss : 0.043317
[23:07:11.176] iteration 780 : model1 loss : 0.460371 model2 loss : 0.065282
[23:07:11.348] iteration 781 : model1 loss : 0.471215 model2 loss : 0.072409
[23:07:11.527] iteration 782 : model1 loss : 0.467622 model2 loss : 0.076706
[23:07:11.699] iteration 783 : model1 loss : 0.464478 model2 loss : 0.087430
[23:07:11.880] iteration 784 : model1 loss : 0.464316 model2 loss : 0.075191
[23:07:12.050] iteration 785 : model1 loss : 0.468294 model2 loss : 0.100972
[23:07:12.225] iteration 786 : model1 loss : 0.463025 model2 loss : 0.067716
[23:07:12.399] iteration 787 : model1 loss : 0.460125 model2 loss : 0.054198
[23:07:12.577] iteration 788 : model1 loss : 0.463459 model2 loss : 0.068603
[23:07:12.749] iteration 789 : model1 loss : 0.468113 model2 loss : 0.096672
[23:07:12.925] iteration 790 : model1 loss : 0.464169 model2 loss : 0.057321
[23:07:13.096] iteration 791 : model1 loss : 0.464819 model2 loss : 0.054722
[23:07:13.273] iteration 792 : model1 loss : 0.468458 model2 loss : 0.060554
[23:07:13.445] iteration 793 : model1 loss : 0.460757 model2 loss : 0.064996
[23:07:13.620] iteration 794 : model1 loss : 0.461549 model2 loss : 0.079732
[23:07:13.793] iteration 795 : model1 loss : 0.461872 model2 loss : 0.056835
[23:07:13.971] iteration 796 : model1 loss : 0.457095 model2 loss : 0.049496
[23:07:14.141] iteration 797 : model1 loss : 0.460405 model2 loss : 0.089648
[23:07:14.322] iteration 798 : model1 loss : 0.466624 model2 loss : 0.066995
[23:07:16.453] iteration 799 : model1 loss : 0.463889 model2 loss : 0.052374
[23:07:16.626] iteration 800 : model1 loss : 0.467976 model2 loss : 0.080588
[23:07:16.805] iteration 801 : model1 loss : 0.460452 model2 loss : 0.056441
[23:07:16.976] iteration 802 : model1 loss : 0.469299 model2 loss : 0.060284
[23:07:17.153] iteration 803 : model1 loss : 0.453414 model2 loss : 0.058592
[23:07:17.333] iteration 804 : model1 loss : 0.466083 model2 loss : 0.067660
[23:07:17.513] iteration 805 : model1 loss : 0.464276 model2 loss : 0.063974
[23:07:17.686] iteration 806 : model1 loss : 0.458431 model2 loss : 0.065431
[23:07:17.859] iteration 807 : model1 loss : 0.463744 model2 loss : 0.049609
[23:07:18.031] iteration 808 : model1 loss : 0.457128 model2 loss : 0.051960
[23:07:18.209] iteration 809 : model1 loss : 0.459726 model2 loss : 0.048909
[23:07:18.382] iteration 810 : model1 loss : 0.461185 model2 loss : 0.050967
[23:07:18.562] iteration 811 : model1 loss : 0.460874 model2 loss : 0.055296
[23:07:18.735] iteration 812 : model1 loss : 0.473725 model2 loss : 0.101326
[23:07:18.910] iteration 813 : model1 loss : 0.467288 model2 loss : 0.078554
[23:07:19.082] iteration 814 : model1 loss : 0.459988 model2 loss : 0.071215
[23:07:19.260] iteration 815 : model1 loss : 0.455867 model2 loss : 0.052078
[23:07:19.433] iteration 816 : model1 loss : 0.468528 model2 loss : 0.057813
[23:07:19.613] iteration 817 : model1 loss : 0.459350 model2 loss : 0.065510
[23:07:19.787] iteration 818 : model1 loss : 0.466886 model2 loss : 0.089424
[23:07:19.965] iteration 819 : model1 loss : 0.459522 model2 loss : 0.071170
[23:07:22.139] iteration 820 : model1 loss : 0.454620 model2 loss : 0.062629
[23:07:22.324] iteration 821 : model1 loss : 0.459589 model2 loss : 0.065297
[23:07:22.507] iteration 822 : model1 loss : 0.456691 model2 loss : 0.055198
[23:07:22.679] iteration 823 : model1 loss : 0.460482 model2 loss : 0.062288
[23:07:22.857] iteration 824 : model1 loss : 0.462100 model2 loss : 0.057798
[23:07:23.029] iteration 825 : model1 loss : 0.466232 model2 loss : 0.076947
[23:07:23.208] iteration 826 : model1 loss : 0.455517 model2 loss : 0.064349
[23:07:23.385] iteration 827 : model1 loss : 0.469009 model2 loss : 0.057749
[23:07:23.564] iteration 828 : model1 loss : 0.469169 model2 loss : 0.073894
[23:07:23.737] iteration 829 : model1 loss : 0.456266 model2 loss : 0.073858
[23:07:23.913] iteration 830 : model1 loss : 0.459695 model2 loss : 0.057461
[23:07:24.087] iteration 831 : model1 loss : 0.458229 model2 loss : 0.050086
[23:07:24.266] iteration 832 : model1 loss : 0.460800 model2 loss : 0.059413
[23:07:24.438] iteration 833 : model1 loss : 0.458744 model2 loss : 0.063657
[23:07:24.613] iteration 834 : model1 loss : 0.471707 model2 loss : 0.115611
[23:07:24.787] iteration 835 : model1 loss : 0.464044 model2 loss : 0.074847
[23:07:24.965] iteration 836 : model1 loss : 0.472561 model2 loss : 0.084750
[23:07:25.135] iteration 837 : model1 loss : 0.465460 model2 loss : 0.063068
[23:07:25.318] iteration 838 : model1 loss : 0.453725 model2 loss : 0.048936
[23:07:25.487] iteration 839 : model1 loss : 0.459224 model2 loss : 0.062008
[23:07:25.661] iteration 840 : model1 loss : 0.466064 model2 loss : 0.104451
[23:07:27.790] iteration 841 : model1 loss : 0.458872 model2 loss : 0.078556
[23:07:27.964] iteration 842 : model1 loss : 0.457511 model2 loss : 0.047450
[23:07:28.141] iteration 843 : model1 loss : 0.461441 model2 loss : 0.093322
[23:07:28.316] iteration 844 : model1 loss : 0.458451 model2 loss : 0.055471
[23:07:28.495] iteration 845 : model1 loss : 0.467618 model2 loss : 0.078381
[23:07:28.667] iteration 846 : model1 loss : 0.466874 model2 loss : 0.076185
[23:07:28.846] iteration 847 : model1 loss : 0.460231 model2 loss : 0.061224
[23:07:29.021] iteration 848 : model1 loss : 0.459140 model2 loss : 0.056760
[23:07:29.201] iteration 849 : model1 loss : 0.456786 model2 loss : 0.051457
[23:07:29.372] iteration 850 : model1 loss : 0.456946 model2 loss : 0.059337
[23:07:29.551] iteration 851 : model1 loss : 0.456003 model2 loss : 0.068431
[23:07:29.724] iteration 852 : model1 loss : 0.469551 model2 loss : 0.080730
[23:07:29.901] iteration 853 : model1 loss : 0.461287 model2 loss : 0.074091
[23:07:30.076] iteration 854 : model1 loss : 0.456823 model2 loss : 0.084362
[23:07:30.255] iteration 855 : model1 loss : 0.462890 model2 loss : 0.088704
[23:07:30.429] iteration 856 : model1 loss : 0.466582 model2 loss : 0.074953
[23:07:30.608] iteration 857 : model1 loss : 0.456112 model2 loss : 0.062988
[23:07:30.780] iteration 858 : model1 loss : 0.467547 model2 loss : 0.063153
[23:07:30.957] iteration 859 : model1 loss : 0.460902 model2 loss : 0.081859
[23:07:31.126] iteration 860 : model1 loss : 0.465834 model2 loss : 0.087016
[23:07:31.302] iteration 861 : model1 loss : 0.463266 model2 loss : 0.064307
[23:07:33.484] iteration 862 : model1 loss : 0.463320 model2 loss : 0.055704
[23:07:33.656] iteration 863 : model1 loss : 0.459733 model2 loss : 0.052099
[23:07:33.836] iteration 864 : model1 loss : 0.465154 model2 loss : 0.085976
[23:07:34.008] iteration 865 : model1 loss : 0.454594 model2 loss : 0.066271
[23:07:34.185] iteration 866 : model1 loss : 0.453751 model2 loss : 0.065736
[23:07:34.363] iteration 867 : model1 loss : 0.460359 model2 loss : 0.065351
[23:07:34.542] iteration 868 : model1 loss : 0.460116 model2 loss : 0.055832
[23:07:34.712] iteration 869 : model1 loss : 0.453533 model2 loss : 0.060704
[23:07:34.889] iteration 870 : model1 loss : 0.460523 model2 loss : 0.068535
[23:07:35.060] iteration 871 : model1 loss : 0.454161 model2 loss : 0.049637
[23:07:35.238] iteration 872 : model1 loss : 0.457265 model2 loss : 0.063496
[23:07:35.411] iteration 873 : model1 loss : 0.465434 model2 loss : 0.066041
[23:07:35.589] iteration 874 : model1 loss : 0.460527 model2 loss : 0.063864
[23:07:35.763] iteration 875 : model1 loss : 0.453893 model2 loss : 0.073070
[23:07:35.939] iteration 876 : model1 loss : 0.462721 model2 loss : 0.068550
[23:07:36.113] iteration 877 : model1 loss : 0.454609 model2 loss : 0.071340
[23:07:36.292] iteration 878 : model1 loss : 0.477166 model2 loss : 0.078508
[23:07:36.466] iteration 879 : model1 loss : 0.456978 model2 loss : 0.053723
[23:07:36.640] iteration 880 : model1 loss : 0.461740 model2 loss : 0.058727
[23:07:36.811] iteration 881 : model1 loss : 0.457058 model2 loss : 0.065027
[23:07:36.985] iteration 882 : model1 loss : 0.454377 model2 loss : 0.049939
[23:07:39.139] iteration 883 : model1 loss : 0.471689 model2 loss : 0.069303
[23:07:39.319] iteration 884 : model1 loss : 0.469237 model2 loss : 0.097346
[23:07:39.495] iteration 885 : model1 loss : 0.455106 model2 loss : 0.051807
[23:07:39.670] iteration 886 : model1 loss : 0.462790 model2 loss : 0.059651
[23:07:39.845] iteration 887 : model1 loss : 0.465016 model2 loss : 0.074485
[23:07:40.015] iteration 888 : model1 loss : 0.454398 model2 loss : 0.052098
[23:07:40.192] iteration 889 : model1 loss : 0.471852 model2 loss : 0.108955
[23:07:40.368] iteration 890 : model1 loss : 0.457142 model2 loss : 0.051128
[23:07:40.544] iteration 891 : model1 loss : 0.463461 model2 loss : 0.075210
[23:07:40.716] iteration 892 : model1 loss : 0.451522 model2 loss : 0.051001
[23:07:40.893] iteration 893 : model1 loss : 0.460947 model2 loss : 0.059447
[23:07:41.064] iteration 894 : model1 loss : 0.455273 model2 loss : 0.050524
[23:07:41.242] iteration 895 : model1 loss : 0.458991 model2 loss : 0.054880
[23:07:41.414] iteration 896 : model1 loss : 0.453850 model2 loss : 0.042863
[23:07:41.594] iteration 897 : model1 loss : 0.460682 model2 loss : 0.058011
[23:07:41.766] iteration 898 : model1 loss : 0.457692 model2 loss : 0.056885
[23:07:41.939] iteration 899 : model1 loss : 0.468889 model2 loss : 0.101595
[23:07:42.113] iteration 900 : model1 loss : 0.455278 model2 loss : 0.047828
[23:07:42.293] iteration 901 : model1 loss : 0.454938 model2 loss : 0.061041
[23:07:42.467] iteration 902 : model1 loss : 0.454036 model2 loss : 0.045066
[23:07:42.641] iteration 903 : model1 loss : 0.458623 model2 loss : 0.064611
[23:07:44.800] iteration 904 : model1 loss : 0.461968 model2 loss : 0.056480
[23:07:44.974] iteration 905 : model1 loss : 0.465535 model2 loss : 0.072793
[23:07:45.153] iteration 906 : model1 loss : 0.464255 model2 loss : 0.058526
[23:07:45.331] iteration 907 : model1 loss : 0.455030 model2 loss : 0.062084
[23:07:45.507] iteration 908 : model1 loss : 0.458377 model2 loss : 0.058696
[23:07:45.676] iteration 909 : model1 loss : 0.451911 model2 loss : 0.055750
[23:07:45.853] iteration 910 : model1 loss : 0.462849 model2 loss : 0.067265
[23:07:46.024] iteration 911 : model1 loss : 0.464857 model2 loss : 0.053441
[23:07:46.200] iteration 912 : model1 loss : 0.464023 model2 loss : 0.068644
[23:07:46.375] iteration 913 : model1 loss : 0.460616 model2 loss : 0.053447
[23:07:46.551] iteration 914 : model1 loss : 0.459543 model2 loss : 0.064914
[23:07:46.731] iteration 915 : model1 loss : 0.453180 model2 loss : 0.049776
[23:07:46.905] iteration 916 : model1 loss : 0.456372 model2 loss : 0.078318
[23:07:47.078] iteration 917 : model1 loss : 0.471024 model2 loss : 0.065996
[23:07:47.262] iteration 918 : model1 loss : 0.453931 model2 loss : 0.057015
[23:07:47.438] iteration 919 : model1 loss : 0.457595 model2 loss : 0.069137
[23:07:47.614] iteration 920 : model1 loss : 0.450424 model2 loss : 0.043633
[23:07:47.786] iteration 921 : model1 loss : 0.455012 model2 loss : 0.055203
[23:07:47.963] iteration 922 : model1 loss : 0.463666 model2 loss : 0.068234
[23:07:48.135] iteration 923 : model1 loss : 0.456738 model2 loss : 0.072462
[23:07:48.315] iteration 924 : model1 loss : 0.454133 model2 loss : 0.047878
[23:07:50.459] iteration 925 : model1 loss : 0.455066 model2 loss : 0.046886
[23:07:50.635] iteration 926 : model1 loss : 0.455838 model2 loss : 0.058392
[23:07:50.811] iteration 927 : model1 loss : 0.457607 model2 loss : 0.052305
[23:07:50.980] iteration 928 : model1 loss : 0.462839 model2 loss : 0.073670
[23:07:51.155] iteration 929 : model1 loss : 0.457833 model2 loss : 0.052142
[23:07:51.332] iteration 930 : model1 loss : 0.455250 model2 loss : 0.048280
[23:07:51.508] iteration 931 : model1 loss : 0.455188 model2 loss : 0.053250
[23:07:51.677] iteration 932 : model1 loss : 0.454000 model2 loss : 0.047850
[23:07:51.853] iteration 933 : model1 loss : 0.465629 model2 loss : 0.058469
[23:07:52.025] iteration 934 : model1 loss : 0.474207 model2 loss : 0.088724
[23:07:52.202] iteration 935 : model1 loss : 0.462092 model2 loss : 0.051566
[23:07:52.376] iteration 936 : model1 loss : 0.463203 model2 loss : 0.060371
[23:07:52.557] iteration 937 : model1 loss : 0.469876 model2 loss : 0.061057
[23:07:52.733] iteration 938 : model1 loss : 0.456418 model2 loss : 0.044870
[23:07:52.910] iteration 939 : model1 loss : 0.459069 model2 loss : 0.050840
[23:07:53.082] iteration 940 : model1 loss : 0.455941 model2 loss : 0.055911
[23:07:53.261] iteration 941 : model1 loss : 0.461118 model2 loss : 0.062465
[23:07:53.435] iteration 942 : model1 loss : 0.457105 model2 loss : 0.081002
[23:07:53.609] iteration 943 : model1 loss : 0.456679 model2 loss : 0.080098
[23:07:53.781] iteration 944 : model1 loss : 0.467667 model2 loss : 0.050621
[23:07:53.957] iteration 945 : model1 loss : 0.461231 model2 loss : 0.047297
[23:07:56.099] iteration 946 : model1 loss : 0.457696 model2 loss : 0.042921
[23:07:56.275] iteration 947 : model1 loss : 0.450926 model2 loss : 0.049340
[23:07:56.452] iteration 948 : model1 loss : 0.461566 model2 loss : 0.065825
[23:07:56.625] iteration 949 : model1 loss : 0.462512 model2 loss : 0.075232
[23:07:56.800] iteration 950 : model1 loss : 0.467807 model2 loss : 0.068142
[23:07:56.971] iteration 951 : model1 loss : 0.466282 model2 loss : 0.059672
[23:07:57.147] iteration 952 : model1 loss : 0.468356 model2 loss : 0.093739
[23:07:57.325] iteration 953 : model1 loss : 0.451418 model2 loss : 0.050043
[23:07:57.509] iteration 954 : model1 loss : 0.453327 model2 loss : 0.063133
[23:07:57.679] iteration 955 : model1 loss : 0.457760 model2 loss : 0.058028
[23:07:57.853] iteration 956 : model1 loss : 0.465042 model2 loss : 0.054937
[23:07:58.025] iteration 957 : model1 loss : 0.453271 model2 loss : 0.067301
[23:07:58.201] iteration 958 : model1 loss : 0.473511 model2 loss : 0.076921
[23:07:58.375] iteration 959 : model1 loss : 0.456425 model2 loss : 0.057412
[23:07:58.551] iteration 960 : model1 loss : 0.464496 model2 loss : 0.083517
[23:07:58.721] iteration 961 : model1 loss : 0.459940 model2 loss : 0.055498
[23:07:58.896] iteration 962 : model1 loss : 0.453701 model2 loss : 0.060528
[23:07:59.067] iteration 963 : model1 loss : 0.456306 model2 loss : 0.071585
[23:07:59.244] iteration 964 : model1 loss : 0.450515 model2 loss : 0.048214
[23:07:59.417] iteration 965 : model1 loss : 0.461715 model2 loss : 0.079227
[23:07:59.593] iteration 966 : model1 loss : 0.463065 model2 loss : 0.066848
[23:08:01.748] iteration 967 : model1 loss : 0.455047 model2 loss : 0.048942
[23:08:01.923] iteration 968 : model1 loss : 0.461116 model2 loss : 0.061122
[23:08:02.102] iteration 969 : model1 loss : 0.453621 model2 loss : 0.052547
[23:08:02.274] iteration 970 : model1 loss : 0.457380 model2 loss : 0.055092
[23:08:02.457] iteration 971 : model1 loss : 0.457580 model2 loss : 0.052663
[23:08:02.629] iteration 972 : model1 loss : 0.455130 model2 loss : 0.056626
[23:08:02.806] iteration 973 : model1 loss : 0.456010 model2 loss : 0.057318
[23:08:02.979] iteration 974 : model1 loss : 0.451485 model2 loss : 0.047694
[23:08:03.157] iteration 975 : model1 loss : 0.464406 model2 loss : 0.070123
[23:08:03.335] iteration 976 : model1 loss : 0.456440 model2 loss : 0.058999
[23:08:03.513] iteration 977 : model1 loss : 0.458215 model2 loss : 0.059425
[23:08:03.682] iteration 978 : model1 loss : 0.460954 model2 loss : 0.061427
[23:08:03.860] iteration 979 : model1 loss : 0.456570 model2 loss : 0.045077
[23:08:04.032] iteration 980 : model1 loss : 0.467177 model2 loss : 0.053038
[23:08:04.208] iteration 981 : model1 loss : 0.459968 model2 loss : 0.042425
[23:08:04.395] iteration 982 : model1 loss : 0.448002 model2 loss : 0.070174
[23:08:04.573] iteration 983 : model1 loss : 0.466553 model2 loss : 0.076658
[23:08:04.743] iteration 984 : model1 loss : 0.478060 model2 loss : 0.090515
[23:08:04.922] iteration 985 : model1 loss : 0.454973 model2 loss : 0.051308
[23:08:05.091] iteration 986 : model1 loss : 0.453080 model2 loss : 0.054372
[23:08:05.268] iteration 987 : model1 loss : 0.461868 model2 loss : 0.073211
[23:08:07.425] iteration 988 : model1 loss : 0.463732 model2 loss : 0.052470
[23:08:07.604] iteration 989 : model1 loss : 0.452679 model2 loss : 0.054582
[23:08:07.784] iteration 990 : model1 loss : 0.456289 model2 loss : 0.056292
[23:08:07.958] iteration 991 : model1 loss : 0.455783 model2 loss : 0.050471
[23:08:08.134] iteration 992 : model1 loss : 0.454335 model2 loss : 0.061487
[23:08:08.311] iteration 993 : model1 loss : 0.452876 model2 loss : 0.039339
[23:08:08.490] iteration 994 : model1 loss : 0.451799 model2 loss : 0.057505
[23:08:08.663] iteration 995 : model1 loss : 0.471385 model2 loss : 0.081374
[23:08:08.839] iteration 996 : model1 loss : 0.459971 model2 loss : 0.081914
[23:08:09.012] iteration 997 : model1 loss : 0.457994 model2 loss : 0.043341
[23:08:09.190] iteration 998 : model1 loss : 0.455333 model2 loss : 0.048698
[23:08:09.364] iteration 999 : model1 loss : 0.451666 model2 loss : 0.053468
[23:08:09.541] iteration 1000 : model1 loss : 0.456447 model2 loss : 0.086887
[23:08:18.563] iteration 1000 : model1_mean_dice : 0.507342 model1_mean_hd95 : 10.700410
[23:08:27.789] iteration 1000 : model2_mean_dice : 0.781278 model2_mean_hd95 : 3.553899
[23:08:27.975] iteration 1001 : model1 loss : 0.467584 model2 loss : 0.103461
[23:08:28.152] iteration 1002 : model1 loss : 0.460062 model2 loss : 0.045389
[23:08:28.328] iteration 1003 : model1 loss : 0.453334 model2 loss : 0.039933
[23:08:28.505] iteration 1004 : model1 loss : 0.455638 model2 loss : 0.054734
[23:08:28.675] iteration 1005 : model1 loss : 0.452411 model2 loss : 0.047326
[23:08:28.853] iteration 1006 : model1 loss : 0.455524 model2 loss : 0.069437
[23:08:29.021] iteration 1007 : model1 loss : 0.456116 model2 loss : 0.053448
[23:08:29.192] iteration 1008 : model1 loss : 0.456281 model2 loss : 0.065959
[23:08:31.318] iteration 1009 : model1 loss : 0.455051 model2 loss : 0.070242
[23:08:31.490] iteration 1010 : model1 loss : 0.451871 model2 loss : 0.062428
[23:08:31.667] iteration 1011 : model1 loss : 0.454183 model2 loss : 0.050333
[23:08:31.839] iteration 1012 : model1 loss : 0.450981 model2 loss : 0.056978
[23:08:32.012] iteration 1013 : model1 loss : 0.453347 model2 loss : 0.060067
[23:08:32.182] iteration 1014 : model1 loss : 0.458954 model2 loss : 0.050866
[23:08:32.360] iteration 1015 : model1 loss : 0.449723 model2 loss : 0.073118
[23:08:32.532] iteration 1016 : model1 loss : 0.464167 model2 loss : 0.071793
[23:08:32.710] iteration 1017 : model1 loss : 0.460442 model2 loss : 0.060806
[23:08:32.881] iteration 1018 : model1 loss : 0.457568 model2 loss : 0.055746
[23:08:33.058] iteration 1019 : model1 loss : 0.456217 model2 loss : 0.060665
[23:08:33.228] iteration 1020 : model1 loss : 0.465611 model2 loss : 0.066224
[23:08:33.402] iteration 1021 : model1 loss : 0.454518 model2 loss : 0.047723
[23:08:33.571] iteration 1022 : model1 loss : 0.456846 model2 loss : 0.081261
[23:08:33.744] iteration 1023 : model1 loss : 0.465853 model2 loss : 0.073900
[23:08:33.916] iteration 1024 : model1 loss : 0.449234 model2 loss : 0.063521
[23:08:34.092] iteration 1025 : model1 loss : 0.449461 model2 loss : 0.055582
[23:08:34.261] iteration 1026 : model1 loss : 0.453712 model2 loss : 0.048096
[23:08:34.437] iteration 1027 : model1 loss : 0.447317 model2 loss : 0.038967
[23:08:34.608] iteration 1028 : model1 loss : 0.451412 model2 loss : 0.050392
[23:08:34.781] iteration 1029 : model1 loss : 0.460391 model2 loss : 0.084098
[23:08:36.912] iteration 1030 : model1 loss : 0.464655 model2 loss : 0.067423
[23:08:37.083] iteration 1031 : model1 loss : 0.449813 model2 loss : 0.053852
[23:08:37.260] iteration 1032 : model1 loss : 0.457851 model2 loss : 0.053722
[23:08:37.436] iteration 1033 : model1 loss : 0.461631 model2 loss : 0.059115
[23:08:37.613] iteration 1034 : model1 loss : 0.458341 model2 loss : 0.065018
[23:08:37.782] iteration 1035 : model1 loss : 0.455268 model2 loss : 0.050425
[23:08:37.956] iteration 1036 : model1 loss : 0.454948 model2 loss : 0.062331
[23:08:38.129] iteration 1037 : model1 loss : 0.453602 model2 loss : 0.069595
[23:08:38.304] iteration 1038 : model1 loss : 0.460500 model2 loss : 0.056692
[23:08:38.478] iteration 1039 : model1 loss : 0.450087 model2 loss : 0.056912
[23:08:38.654] iteration 1040 : model1 loss : 0.450799 model2 loss : 0.046633
[23:08:38.823] iteration 1041 : model1 loss : 0.453919 model2 loss : 0.055692
[23:08:38.998] iteration 1042 : model1 loss : 0.445494 model2 loss : 0.050633
[23:08:39.167] iteration 1043 : model1 loss : 0.455989 model2 loss : 0.059067
[23:08:39.342] iteration 1044 : model1 loss : 0.458787 model2 loss : 0.065410
[23:08:39.515] iteration 1045 : model1 loss : 0.453789 model2 loss : 0.045153
[23:08:39.692] iteration 1046 : model1 loss : 0.450695 model2 loss : 0.048080
[23:08:39.863] iteration 1047 : model1 loss : 0.455771 model2 loss : 0.066330
[23:08:40.036] iteration 1048 : model1 loss : 0.452304 model2 loss : 0.055303
[23:08:40.203] iteration 1049 : model1 loss : 0.450127 model2 loss : 0.039930
[23:08:40.382] iteration 1050 : model1 loss : 0.453979 model2 loss : 0.085798
[23:08:42.530] iteration 1051 : model1 loss : 0.451667 model2 loss : 0.053801
[23:08:42.710] iteration 1052 : model1 loss : 0.460327 model2 loss : 0.069490
[23:08:42.884] iteration 1053 : model1 loss : 0.449519 model2 loss : 0.050461
[23:08:43.055] iteration 1054 : model1 loss : 0.449724 model2 loss : 0.048165
[23:08:43.229] iteration 1055 : model1 loss : 0.454320 model2 loss : 0.045595
[23:08:43.402] iteration 1056 : model1 loss : 0.454051 model2 loss : 0.048130
[23:08:43.578] iteration 1057 : model1 loss : 0.463359 model2 loss : 0.070073
[23:08:43.748] iteration 1058 : model1 loss : 0.451498 model2 loss : 0.044774
[23:08:43.923] iteration 1059 : model1 loss : 0.456823 model2 loss : 0.047707
[23:08:44.093] iteration 1060 : model1 loss : 0.456621 model2 loss : 0.055789
[23:08:44.266] iteration 1061 : model1 loss : 0.456157 model2 loss : 0.054219
[23:08:44.439] iteration 1062 : model1 loss : 0.457079 model2 loss : 0.048289
[23:08:44.621] iteration 1063 : model1 loss : 0.450537 model2 loss : 0.053376
[23:08:44.789] iteration 1064 : model1 loss : 0.446754 model2 loss : 0.047841
[23:08:44.963] iteration 1065 : model1 loss : 0.445093 model2 loss : 0.042042
[23:08:45.131] iteration 1066 : model1 loss : 0.464583 model2 loss : 0.055671
[23:08:45.306] iteration 1067 : model1 loss : 0.456599 model2 loss : 0.069435
[23:08:45.478] iteration 1068 : model1 loss : 0.458978 model2 loss : 0.071619
[23:08:45.652] iteration 1069 : model1 loss : 0.456433 model2 loss : 0.064974
[23:08:45.819] iteration 1070 : model1 loss : 0.451502 model2 loss : 0.046274
[23:08:45.994] iteration 1071 : model1 loss : 0.447825 model2 loss : 0.046296
[23:08:48.142] iteration 1072 : model1 loss : 0.458793 model2 loss : 0.058552
[23:08:48.317] iteration 1073 : model1 loss : 0.465636 model2 loss : 0.082369
[23:08:48.494] iteration 1074 : model1 loss : 0.464146 model2 loss : 0.056832
[23:08:48.664] iteration 1075 : model1 loss : 0.454630 model2 loss : 0.050480
[23:08:48.837] iteration 1076 : model1 loss : 0.454128 model2 loss : 0.049059
[23:08:49.010] iteration 1077 : model1 loss : 0.454568 model2 loss : 0.066400
[23:08:49.187] iteration 1078 : model1 loss : 0.451935 model2 loss : 0.036989
[23:08:49.358] iteration 1079 : model1 loss : 0.447801 model2 loss : 0.046038
[23:08:49.535] iteration 1080 : model1 loss : 0.462067 model2 loss : 0.082523
[23:08:49.712] iteration 1081 : model1 loss : 0.452524 model2 loss : 0.063181
[23:08:49.891] iteration 1082 : model1 loss : 0.454628 model2 loss : 0.054418
[23:08:50.060] iteration 1083 : model1 loss : 0.473200 model2 loss : 0.103758
[23:08:50.233] iteration 1084 : model1 loss : 0.455506 model2 loss : 0.059176
[23:08:50.408] iteration 1085 : model1 loss : 0.445803 model2 loss : 0.044052
[23:08:50.589] iteration 1086 : model1 loss : 0.452725 model2 loss : 0.050680
[23:08:50.758] iteration 1087 : model1 loss : 0.449654 model2 loss : 0.055267
[23:08:50.932] iteration 1088 : model1 loss : 0.451485 model2 loss : 0.040391
[23:08:51.101] iteration 1089 : model1 loss : 0.455905 model2 loss : 0.042565
[23:08:51.275] iteration 1090 : model1 loss : 0.454216 model2 loss : 0.047235
[23:08:51.446] iteration 1091 : model1 loss : 0.448707 model2 loss : 0.051101
[23:08:51.624] iteration 1092 : model1 loss : 0.457935 model2 loss : 0.064067
[23:08:53.769] iteration 1093 : model1 loss : 0.461223 model2 loss : 0.056781
[23:08:53.946] iteration 1094 : model1 loss : 0.453076 model2 loss : 0.046780
[23:08:54.127] iteration 1095 : model1 loss : 0.454809 model2 loss : 0.086257
[23:08:54.299] iteration 1096 : model1 loss : 0.450826 model2 loss : 0.058622
[23:08:54.473] iteration 1097 : model1 loss : 0.449867 model2 loss : 0.043391
[23:08:54.650] iteration 1098 : model1 loss : 0.448993 model2 loss : 0.046322
[23:08:54.825] iteration 1099 : model1 loss : 0.456234 model2 loss : 0.054201
[23:08:54.999] iteration 1100 : model1 loss : 0.448895 model2 loss : 0.053038
[23:08:55.174] iteration 1101 : model1 loss : 0.457614 model2 loss : 0.053313
[23:08:55.343] iteration 1102 : model1 loss : 0.446455 model2 loss : 0.043641
[23:08:55.521] iteration 1103 : model1 loss : 0.454835 model2 loss : 0.071654
[23:08:55.693] iteration 1104 : model1 loss : 0.457121 model2 loss : 0.050802
[23:08:55.865] iteration 1105 : model1 loss : 0.448894 model2 loss : 0.048844
[23:08:56.037] iteration 1106 : model1 loss : 0.459748 model2 loss : 0.042996
[23:08:56.213] iteration 1107 : model1 loss : 0.460681 model2 loss : 0.057528
[23:08:56.386] iteration 1108 : model1 loss : 0.447743 model2 loss : 0.048353
[23:08:56.565] iteration 1109 : model1 loss : 0.451802 model2 loss : 0.051024
[23:08:56.733] iteration 1110 : model1 loss : 0.460043 model2 loss : 0.049247
[23:08:56.909] iteration 1111 : model1 loss : 0.462484 model2 loss : 0.065978
[23:08:57.079] iteration 1112 : model1 loss : 0.458922 model2 loss : 0.056699
[23:08:57.252] iteration 1113 : model1 loss : 0.453001 model2 loss : 0.062528
[23:08:59.423] iteration 1114 : model1 loss : 0.462643 model2 loss : 0.060776
[23:08:59.596] iteration 1115 : model1 loss : 0.448270 model2 loss : 0.037388
[23:08:59.771] iteration 1116 : model1 loss : 0.457567 model2 loss : 0.057636
[23:08:59.943] iteration 1117 : model1 loss : 0.463976 model2 loss : 0.052630
[23:09:00.125] iteration 1118 : model1 loss : 0.448961 model2 loss : 0.035804
[23:09:00.293] iteration 1119 : model1 loss : 0.458218 model2 loss : 0.058621
[23:09:00.472] iteration 1120 : model1 loss : 0.457607 model2 loss : 0.058431
[23:09:00.646] iteration 1121 : model1 loss : 0.451486 model2 loss : 0.051358
[23:09:00.820] iteration 1122 : model1 loss : 0.450128 model2 loss : 0.046667
[23:09:00.991] iteration 1123 : model1 loss : 0.459089 model2 loss : 0.057577
[23:09:01.166] iteration 1124 : model1 loss : 0.453430 model2 loss : 0.050803
[23:09:01.338] iteration 1125 : model1 loss : 0.448171 model2 loss : 0.048400
[23:09:01.515] iteration 1126 : model1 loss : 0.458619 model2 loss : 0.064276
[23:09:01.687] iteration 1127 : model1 loss : 0.450462 model2 loss : 0.045379
[23:09:01.860] iteration 1128 : model1 loss : 0.464368 model2 loss : 0.064848
[23:09:02.034] iteration 1129 : model1 loss : 0.452469 model2 loss : 0.047258
[23:09:02.208] iteration 1130 : model1 loss : 0.460027 model2 loss : 0.069439
[23:09:02.381] iteration 1131 : model1 loss : 0.446496 model2 loss : 0.046222
[23:09:02.562] iteration 1132 : model1 loss : 0.455991 model2 loss : 0.062515
[23:09:02.730] iteration 1133 : model1 loss : 0.454322 model2 loss : 0.047485
[23:09:02.904] iteration 1134 : model1 loss : 0.454796 model2 loss : 0.054698
[23:09:05.035] iteration 1135 : model1 loss : 0.449573 model2 loss : 0.053815
[23:09:05.205] iteration 1136 : model1 loss : 0.452385 model2 loss : 0.060015
[23:09:05.383] iteration 1137 : model1 loss : 0.446244 model2 loss : 0.044316
[23:09:05.556] iteration 1138 : model1 loss : 0.451369 model2 loss : 0.047684
[23:09:05.728] iteration 1139 : model1 loss : 0.461219 model2 loss : 0.057242
[23:09:05.898] iteration 1140 : model1 loss : 0.454600 model2 loss : 0.055757
[23:09:06.073] iteration 1141 : model1 loss : 0.451523 model2 loss : 0.045036
[23:09:06.242] iteration 1142 : model1 loss : 0.450636 model2 loss : 0.041208
[23:09:06.419] iteration 1143 : model1 loss : 0.456827 model2 loss : 0.072303
[23:09:06.590] iteration 1144 : model1 loss : 0.460917 model2 loss : 0.049357
[23:09:06.764] iteration 1145 : model1 loss : 0.453791 model2 loss : 0.059227
[23:09:06.937] iteration 1146 : model1 loss : 0.457702 model2 loss : 0.045328
[23:09:07.112] iteration 1147 : model1 loss : 0.461219 model2 loss : 0.050173
[23:09:07.281] iteration 1148 : model1 loss : 0.448126 model2 loss : 0.049747
[23:09:07.464] iteration 1149 : model1 loss : 0.453002 model2 loss : 0.042814
[23:09:07.640] iteration 1150 : model1 loss : 0.453059 model2 loss : 0.045750
[23:09:07.815] iteration 1151 : model1 loss : 0.462063 model2 loss : 0.056259
[23:09:07.989] iteration 1152 : model1 loss : 0.453297 model2 loss : 0.048822
[23:09:08.166] iteration 1153 : model1 loss : 0.458525 model2 loss : 0.049032
[23:09:08.337] iteration 1154 : model1 loss : 0.456850 model2 loss : 0.049228
[23:09:08.509] iteration 1155 : model1 loss : 0.447546 model2 loss : 0.049229
[23:09:10.618] iteration 1156 : model1 loss : 0.448229 model2 loss : 0.044991
[23:09:10.790] iteration 1157 : model1 loss : 0.452305 model2 loss : 0.053389
[23:09:10.966] iteration 1158 : model1 loss : 0.447670 model2 loss : 0.042654
[23:09:11.136] iteration 1159 : model1 loss : 0.452077 model2 loss : 0.050452
[23:09:11.312] iteration 1160 : model1 loss : 0.459504 model2 loss : 0.072192
[23:09:11.485] iteration 1161 : model1 loss : 0.451961 model2 loss : 0.045110
[23:09:11.662] iteration 1162 : model1 loss : 0.453151 model2 loss : 0.043620
[23:09:11.830] iteration 1163 : model1 loss : 0.460670 model2 loss : 0.067543
[23:09:12.004] iteration 1164 : model1 loss : 0.450291 model2 loss : 0.043053
[23:09:12.174] iteration 1165 : model1 loss : 0.449895 model2 loss : 0.058724
[23:09:12.349] iteration 1166 : model1 loss : 0.451526 model2 loss : 0.055344
[23:09:12.528] iteration 1167 : model1 loss : 0.451010 model2 loss : 0.052564
[23:09:12.704] iteration 1168 : model1 loss : 0.449157 model2 loss : 0.048552
[23:09:12.874] iteration 1169 : model1 loss : 0.458301 model2 loss : 0.052702
[23:09:13.054] iteration 1170 : model1 loss : 0.444980 model2 loss : 0.046409
[23:09:13.226] iteration 1171 : model1 loss : 0.454014 model2 loss : 0.060239
[23:09:13.404] iteration 1172 : model1 loss : 0.458832 model2 loss : 0.059816
[23:09:13.577] iteration 1173 : model1 loss : 0.451620 model2 loss : 0.054704
[23:09:13.754] iteration 1174 : model1 loss : 0.460044 model2 loss : 0.062170
[23:09:13.924] iteration 1175 : model1 loss : 0.456396 model2 loss : 0.041243
[23:09:14.098] iteration 1176 : model1 loss : 0.455956 model2 loss : 0.046414
[23:09:16.265] iteration 1177 : model1 loss : 0.453156 model2 loss : 0.046412
[23:09:16.441] iteration 1178 : model1 loss : 0.455272 model2 loss : 0.050964
[23:09:16.619] iteration 1179 : model1 loss : 0.449442 model2 loss : 0.051357
[23:09:16.788] iteration 1180 : model1 loss : 0.452980 model2 loss : 0.051218
[23:09:16.963] iteration 1181 : model1 loss : 0.452511 model2 loss : 0.060688
[23:09:17.133] iteration 1182 : model1 loss : 0.451087 model2 loss : 0.053263
[23:09:17.308] iteration 1183 : model1 loss : 0.452003 model2 loss : 0.052887
[23:09:17.484] iteration 1184 : model1 loss : 0.455895 model2 loss : 0.063368
[23:09:17.660] iteration 1185 : model1 loss : 0.450777 model2 loss : 0.047811
[23:09:17.829] iteration 1186 : model1 loss : 0.449451 model2 loss : 0.048489
[23:09:18.006] iteration 1187 : model1 loss : 0.451432 model2 loss : 0.060613
[23:09:18.183] iteration 1188 : model1 loss : 0.460371 model2 loss : 0.065361
[23:09:18.360] iteration 1189 : model1 loss : 0.452647 model2 loss : 0.048249
[23:09:18.535] iteration 1190 : model1 loss : 0.448024 model2 loss : 0.050608
[23:09:18.710] iteration 1191 : model1 loss : 0.454859 model2 loss : 0.052783
[23:09:18.880] iteration 1192 : model1 loss : 0.450663 model2 loss : 0.041668
[23:09:19.056] iteration 1193 : model1 loss : 0.446697 model2 loss : 0.039642
[23:09:19.228] iteration 1194 : model1 loss : 0.446600 model2 loss : 0.044426
[23:09:19.404] iteration 1195 : model1 loss : 0.451230 model2 loss : 0.053816
[23:09:19.576] iteration 1196 : model1 loss : 0.449155 model2 loss : 0.044028
[23:09:19.751] iteration 1197 : model1 loss : 0.450672 model2 loss : 0.065698
[23:09:21.879] iteration 1198 : model1 loss : 0.462522 model2 loss : 0.079979
[23:09:22.055] iteration 1199 : model1 loss : 0.449152 model2 loss : 0.050352
[23:09:22.230] iteration 1200 : model1 loss : 0.456140 model2 loss : 0.056512
[23:09:22.405] iteration 1201 : model1 loss : 0.451385 model2 loss : 0.053772
[23:09:22.584] iteration 1202 : model1 loss : 0.452793 model2 loss : 0.047851
[23:09:22.755] iteration 1203 : model1 loss : 0.451820 model2 loss : 0.048297
[23:09:22.931] iteration 1204 : model1 loss : 0.448371 model2 loss : 0.059061
[23:09:23.109] iteration 1205 : model1 loss : 0.448780 model2 loss : 0.052934
[23:09:23.286] iteration 1206 : model1 loss : 0.457777 model2 loss : 0.050599
[23:09:23.459] iteration 1207 : model1 loss : 0.455462 model2 loss : 0.047752
[23:09:23.641] iteration 1208 : model1 loss : 0.451334 model2 loss : 0.061654
[23:09:23.810] iteration 1209 : model1 loss : 0.457791 model2 loss : 0.076637
[23:09:23.987] iteration 1210 : model1 loss : 0.447433 model2 loss : 0.040109
[23:09:24.158] iteration 1211 : model1 loss : 0.447298 model2 loss : 0.051881
[23:09:24.334] iteration 1212 : model1 loss : 0.445508 model2 loss : 0.036274
[23:09:24.519] iteration 1213 : model1 loss : 0.444882 model2 loss : 0.038265
[23:09:24.695] iteration 1214 : model1 loss : 0.443817 model2 loss : 0.040946
[23:09:24.865] iteration 1215 : model1 loss : 0.451414 model2 loss : 0.052668
[23:09:25.039] iteration 1216 : model1 loss : 0.451914 model2 loss : 0.056198
[23:09:25.207] iteration 1217 : model1 loss : 0.455122 model2 loss : 0.056073
[23:09:25.382] iteration 1218 : model1 loss : 0.457015 model2 loss : 0.057420
[23:09:27.579] iteration 1219 : model1 loss : 0.453346 model2 loss : 0.063130
[23:09:27.758] iteration 1220 : model1 loss : 0.446489 model2 loss : 0.054262
[23:09:27.936] iteration 1221 : model1 loss : 0.445867 model2 loss : 0.041868
[23:09:28.108] iteration 1222 : model1 loss : 0.455904 model2 loss : 0.065686
[23:09:28.281] iteration 1223 : model1 loss : 0.450874 model2 loss : 0.048406
[23:09:28.454] iteration 1224 : model1 loss : 0.448375 model2 loss : 0.041762
[23:09:28.636] iteration 1225 : model1 loss : 0.462125 model2 loss : 0.065051
[23:09:28.807] iteration 1226 : model1 loss : 0.446492 model2 loss : 0.040562
[23:09:28.982] iteration 1227 : model1 loss : 0.446981 model2 loss : 0.049466
[23:09:29.151] iteration 1228 : model1 loss : 0.461397 model2 loss : 0.060253
[23:09:29.329] iteration 1229 : model1 loss : 0.445881 model2 loss : 0.036848
[23:09:29.502] iteration 1230 : model1 loss : 0.461641 model2 loss : 0.074459
[23:09:29.676] iteration 1231 : model1 loss : 0.459486 model2 loss : 0.043074
[23:09:29.847] iteration 1232 : model1 loss : 0.448924 model2 loss : 0.057396
[23:09:30.024] iteration 1233 : model1 loss : 0.450248 model2 loss : 0.055829
[23:09:30.196] iteration 1234 : model1 loss : 0.453867 model2 loss : 0.051096
[23:09:30.371] iteration 1235 : model1 loss : 0.456046 model2 loss : 0.046276
[23:09:30.544] iteration 1236 : model1 loss : 0.450932 model2 loss : 0.039710
[23:09:30.721] iteration 1237 : model1 loss : 0.459463 model2 loss : 0.058287
[23:09:30.889] iteration 1238 : model1 loss : 0.449529 model2 loss : 0.053676
[23:09:31.064] iteration 1239 : model1 loss : 0.449021 model2 loss : 0.057118
[23:09:33.211] iteration 1240 : model1 loss : 0.455145 model2 loss : 0.062651
[23:09:33.383] iteration 1241 : model1 loss : 0.445115 model2 loss : 0.042900
[23:09:33.563] iteration 1242 : model1 loss : 0.458825 model2 loss : 0.051087
[23:09:33.732] iteration 1243 : model1 loss : 0.447984 model2 loss : 0.041028
[23:09:33.905] iteration 1244 : model1 loss : 0.454562 model2 loss : 0.058705
[23:09:34.079] iteration 1245 : model1 loss : 0.456660 model2 loss : 0.084491
[23:09:34.253] iteration 1246 : model1 loss : 0.455744 model2 loss : 0.050038
[23:09:34.424] iteration 1247 : model1 loss : 0.450599 model2 loss : 0.051066
[23:09:34.606] iteration 1248 : model1 loss : 0.443106 model2 loss : 0.038637
[23:09:34.776] iteration 1249 : model1 loss : 0.453363 model2 loss : 0.064240
[23:09:34.952] iteration 1250 : model1 loss : 0.460351 model2 loss : 0.061058
[23:09:35.125] iteration 1251 : model1 loss : 0.446601 model2 loss : 0.049394
[23:09:35.300] iteration 1252 : model1 loss : 0.452088 model2 loss : 0.048419
[23:09:35.473] iteration 1253 : model1 loss : 0.447698 model2 loss : 0.048465
[23:09:35.656] iteration 1254 : model1 loss : 0.446833 model2 loss : 0.036271
[23:09:35.826] iteration 1255 : model1 loss : 0.446505 model2 loss : 0.051908
[23:09:36.004] iteration 1256 : model1 loss : 0.458182 model2 loss : 0.065996
[23:09:36.174] iteration 1257 : model1 loss : 0.450313 model2 loss : 0.050572
[23:09:36.354] iteration 1258 : model1 loss : 0.459913 model2 loss : 0.047904
[23:09:36.526] iteration 1259 : model1 loss : 0.451194 model2 loss : 0.051541
[23:09:36.700] iteration 1260 : model1 loss : 0.458451 model2 loss : 0.064647
[23:09:38.817] iteration 1261 : model1 loss : 0.454746 model2 loss : 0.053757
[23:09:38.993] iteration 1262 : model1 loss : 0.455414 model2 loss : 0.060290
[23:09:39.172] iteration 1263 : model1 loss : 0.455261 model2 loss : 0.056710
[23:09:39.345] iteration 1264 : model1 loss : 0.455253 model2 loss : 0.052151
[23:09:39.525] iteration 1265 : model1 loss : 0.451537 model2 loss : 0.041144
[23:09:39.697] iteration 1266 : model1 loss : 0.449238 model2 loss : 0.046189
[23:09:39.874] iteration 1267 : model1 loss : 0.443429 model2 loss : 0.043229
[23:09:40.046] iteration 1268 : model1 loss : 0.453610 model2 loss : 0.044591
[23:09:40.222] iteration 1269 : model1 loss : 0.450109 model2 loss : 0.050514
[23:09:40.392] iteration 1270 : model1 loss : 0.448454 model2 loss : 0.052171
[23:09:40.568] iteration 1271 : model1 loss : 0.447876 model2 loss : 0.050381
[23:09:40.738] iteration 1272 : model1 loss : 0.450895 model2 loss : 0.072559
[23:09:40.910] iteration 1273 : model1 loss : 0.445910 model2 loss : 0.042103
[23:09:41.084] iteration 1274 : model1 loss : 0.452521 model2 loss : 0.072269
[23:09:41.261] iteration 1275 : model1 loss : 0.449476 model2 loss : 0.054206
[23:09:41.430] iteration 1276 : model1 loss : 0.447589 model2 loss : 0.041880
[23:09:41.609] iteration 1277 : model1 loss : 0.448982 model2 loss : 0.055632
[23:09:41.779] iteration 1278 : model1 loss : 0.442359 model2 loss : 0.053015
[23:09:41.954] iteration 1279 : model1 loss : 0.452806 model2 loss : 0.061161
[23:09:42.126] iteration 1280 : model1 loss : 0.450058 model2 loss : 0.054698
[23:09:42.300] iteration 1281 : model1 loss : 0.450324 model2 loss : 0.037346
[23:09:44.463] iteration 1282 : model1 loss : 0.443000 model2 loss : 0.043326
[23:09:44.640] iteration 1283 : model1 loss : 0.459374 model2 loss : 0.063350
[23:09:44.817] iteration 1284 : model1 loss : 0.450110 model2 loss : 0.046580
[23:09:44.989] iteration 1285 : model1 loss : 0.456647 model2 loss : 0.056767
[23:09:45.165] iteration 1286 : model1 loss : 0.450370 model2 loss : 0.054149
[23:09:45.336] iteration 1287 : model1 loss : 0.446851 model2 loss : 0.050171
[23:09:45.512] iteration 1288 : model1 loss : 0.442120 model2 loss : 0.048138
[23:09:45.683] iteration 1289 : model1 loss : 0.451789 model2 loss : 0.050918
[23:09:45.860] iteration 1290 : model1 loss : 0.447205 model2 loss : 0.043425
[23:09:46.031] iteration 1291 : model1 loss : 0.443141 model2 loss : 0.038992
[23:09:46.206] iteration 1292 : model1 loss : 0.444154 model2 loss : 0.039664
[23:09:46.376] iteration 1293 : model1 loss : 0.454405 model2 loss : 0.070899
[23:09:46.553] iteration 1294 : model1 loss : 0.452986 model2 loss : 0.058055
[23:09:46.723] iteration 1295 : model1 loss : 0.449439 model2 loss : 0.047317
[23:09:46.899] iteration 1296 : model1 loss : 0.448046 model2 loss : 0.044063
[23:09:47.071] iteration 1297 : model1 loss : 0.451910 model2 loss : 0.058190
[23:09:47.247] iteration 1298 : model1 loss : 0.444580 model2 loss : 0.042315
[23:09:47.421] iteration 1299 : model1 loss : 0.461066 model2 loss : 0.067727
[23:09:47.601] iteration 1300 : model1 loss : 0.444008 model2 loss : 0.042267
[23:09:47.770] iteration 1301 : model1 loss : 0.454535 model2 loss : 0.065046
[23:09:47.944] iteration 1302 : model1 loss : 0.449741 model2 loss : 0.047427
[23:09:50.084] iteration 1303 : model1 loss : 0.446073 model2 loss : 0.045685
[23:09:50.256] iteration 1304 : model1 loss : 0.452366 model2 loss : 0.046954
[23:09:50.433] iteration 1305 : model1 loss : 0.440906 model2 loss : 0.039473
[23:09:50.612] iteration 1306 : model1 loss : 0.451373 model2 loss : 0.048334
[23:09:50.787] iteration 1307 : model1 loss : 0.450029 model2 loss : 0.052666
[23:09:50.957] iteration 1308 : model1 loss : 0.445357 model2 loss : 0.038997
[23:09:51.136] iteration 1309 : model1 loss : 0.452986 model2 loss : 0.046855
[23:09:51.311] iteration 1310 : model1 loss : 0.450985 model2 loss : 0.049576
[23:09:51.486] iteration 1311 : model1 loss : 0.450215 model2 loss : 0.047740
[23:09:51.659] iteration 1312 : model1 loss : 0.445975 model2 loss : 0.044181
[23:09:51.833] iteration 1313 : model1 loss : 0.457714 model2 loss : 0.058510
[23:09:52.005] iteration 1314 : model1 loss : 0.445349 model2 loss : 0.046334
[23:09:52.183] iteration 1315 : model1 loss : 0.444705 model2 loss : 0.044474
[23:09:52.357] iteration 1316 : model1 loss : 0.445106 model2 loss : 0.038574
[23:09:52.537] iteration 1317 : model1 loss : 0.458589 model2 loss : 0.048397
[23:09:52.708] iteration 1318 : model1 loss : 0.464552 model2 loss : 0.068398
[23:09:52.882] iteration 1319 : model1 loss : 0.454182 model2 loss : 0.078006
[23:09:53.056] iteration 1320 : model1 loss : 0.445331 model2 loss : 0.048270
[23:09:53.233] iteration 1321 : model1 loss : 0.451570 model2 loss : 0.047892
[23:09:53.401] iteration 1322 : model1 loss : 0.463594 model2 loss : 0.090574
[23:09:53.576] iteration 1323 : model1 loss : 0.460971 model2 loss : 0.060788
[23:09:55.712] iteration 1324 : model1 loss : 0.447874 model2 loss : 0.053165
[23:09:55.889] iteration 1325 : model1 loss : 0.452152 model2 loss : 0.057361
[23:09:56.066] iteration 1326 : model1 loss : 0.451575 model2 loss : 0.060523
[23:09:56.236] iteration 1327 : model1 loss : 0.451422 model2 loss : 0.048224
[23:09:56.416] iteration 1328 : model1 loss : 0.465581 model2 loss : 0.087130
[23:09:56.594] iteration 1329 : model1 loss : 0.449713 model2 loss : 0.053624
[23:09:56.766] iteration 1330 : model1 loss : 0.454298 model2 loss : 0.046495
[23:09:56.935] iteration 1331 : model1 loss : 0.456844 model2 loss : 0.058239
[23:09:57.110] iteration 1332 : model1 loss : 0.449059 model2 loss : 0.044379
[23:09:57.281] iteration 1333 : model1 loss : 0.453231 model2 loss : 0.053322
[23:09:57.461] iteration 1334 : model1 loss : 0.450914 model2 loss : 0.065316
[23:09:57.638] iteration 1335 : model1 loss : 0.443692 model2 loss : 0.045591
[23:09:57.812] iteration 1336 : model1 loss : 0.447041 model2 loss : 0.046574
[23:09:57.983] iteration 1337 : model1 loss : 0.449663 model2 loss : 0.046397
[23:09:58.160] iteration 1338 : model1 loss : 0.445144 model2 loss : 0.051155
[23:09:58.331] iteration 1339 : model1 loss : 0.451587 model2 loss : 0.046850
[23:09:58.508] iteration 1340 : model1 loss : 0.443328 model2 loss : 0.051035
[23:09:58.681] iteration 1341 : model1 loss : 0.443594 model2 loss : 0.044702
[23:09:58.859] iteration 1342 : model1 loss : 0.449907 model2 loss : 0.040426
[23:09:59.029] iteration 1343 : model1 loss : 0.450176 model2 loss : 0.048921
[23:09:59.202] iteration 1344 : model1 loss : 0.448393 model2 loss : 0.049871
[23:10:01.345] iteration 1345 : model1 loss : 0.444301 model2 loss : 0.039044
[23:10:01.519] iteration 1346 : model1 loss : 0.441587 model2 loss : 0.042663
[23:10:01.698] iteration 1347 : model1 loss : 0.456032 model2 loss : 0.052939
[23:10:01.870] iteration 1348 : model1 loss : 0.450029 model2 loss : 0.042591
[23:10:02.048] iteration 1349 : model1 loss : 0.447362 model2 loss : 0.046471
[23:10:02.218] iteration 1350 : model1 loss : 0.452483 model2 loss : 0.050682
[23:10:02.394] iteration 1351 : model1 loss : 0.448326 model2 loss : 0.051660
[23:10:02.571] iteration 1352 : model1 loss : 0.453300 model2 loss : 0.055576
[23:10:02.746] iteration 1353 : model1 loss : 0.453684 model2 loss : 0.047006
[23:10:02.916] iteration 1354 : model1 loss : 0.448850 model2 loss : 0.045874
[23:10:03.091] iteration 1355 : model1 loss : 0.446252 model2 loss : 0.049328
[23:10:03.262] iteration 1356 : model1 loss : 0.444328 model2 loss : 0.039229
[23:10:03.437] iteration 1357 : model1 loss : 0.454760 model2 loss : 0.064322
[23:10:03.614] iteration 1358 : model1 loss : 0.455152 model2 loss : 0.041898
[23:10:03.790] iteration 1359 : model1 loss : 0.445168 model2 loss : 0.039482
[23:10:03.959] iteration 1360 : model1 loss : 0.453892 model2 loss : 0.042858
[23:10:04.135] iteration 1361 : model1 loss : 0.452165 model2 loss : 0.049390
[23:10:04.306] iteration 1362 : model1 loss : 0.450727 model2 loss : 0.054235
[23:10:04.483] iteration 1363 : model1 loss : 0.454781 model2 loss : 0.053055
[23:10:04.656] iteration 1364 : model1 loss : 0.444170 model2 loss : 0.045716
[23:10:04.829] iteration 1365 : model1 loss : 0.445306 model2 loss : 0.037803
[23:10:06.953] iteration 1366 : model1 loss : 0.447582 model2 loss : 0.039577
[23:10:07.128] iteration 1367 : model1 loss : 0.448634 model2 loss : 0.046763
[23:10:07.308] iteration 1368 : model1 loss : 0.447536 model2 loss : 0.046297
[23:10:07.484] iteration 1369 : model1 loss : 0.464310 model2 loss : 0.071899
[23:10:07.662] iteration 1370 : model1 loss : 0.446257 model2 loss : 0.033784
[23:10:07.832] iteration 1371 : model1 loss : 0.452644 model2 loss : 0.056765
[23:10:08.009] iteration 1372 : model1 loss : 0.455023 model2 loss : 0.060027
[23:10:08.180] iteration 1373 : model1 loss : 0.451208 model2 loss : 0.034249
[23:10:08.363] iteration 1374 : model1 loss : 0.445686 model2 loss : 0.038057
[23:10:08.538] iteration 1375 : model1 loss : 0.447462 model2 loss : 0.041616
[23:10:08.712] iteration 1376 : model1 loss : 0.449084 model2 loss : 0.045599
[23:10:08.882] iteration 1377 : model1 loss : 0.458856 model2 loss : 0.049193
[23:10:09.061] iteration 1378 : model1 loss : 0.453539 model2 loss : 0.045207
[23:10:09.234] iteration 1379 : model1 loss : 0.454134 model2 loss : 0.040049
[23:10:09.409] iteration 1380 : model1 loss : 0.447257 model2 loss : 0.039183
[23:10:09.582] iteration 1381 : model1 loss : 0.452107 model2 loss : 0.039573
[23:10:09.757] iteration 1382 : model1 loss : 0.447082 model2 loss : 0.036977
[23:10:09.928] iteration 1383 : model1 loss : 0.450239 model2 loss : 0.047239
[23:10:10.103] iteration 1384 : model1 loss : 0.446473 model2 loss : 0.044271
[23:10:10.272] iteration 1385 : model1 loss : 0.449417 model2 loss : 0.057709
[23:10:10.445] iteration 1386 : model1 loss : 0.456249 model2 loss : 0.044218
[23:10:12.611] iteration 1387 : model1 loss : 0.462038 model2 loss : 0.044886
[23:10:12.783] iteration 1388 : model1 loss : 0.447708 model2 loss : 0.048360
[23:10:12.961] iteration 1389 : model1 loss : 0.463951 model2 loss : 0.058429
[23:10:13.133] iteration 1390 : model1 loss : 0.445804 model2 loss : 0.038238
[23:10:13.311] iteration 1391 : model1 loss : 0.453790 model2 loss : 0.045159
[23:10:13.482] iteration 1392 : model1 loss : 0.447022 model2 loss : 0.065664
[23:10:13.660] iteration 1393 : model1 loss : 0.440501 model2 loss : 0.040034
[23:10:13.829] iteration 1394 : model1 loss : 0.448186 model2 loss : 0.043584
[23:10:14.006] iteration 1395 : model1 loss : 0.449230 model2 loss : 0.045261
[23:10:14.176] iteration 1396 : model1 loss : 0.444611 model2 loss : 0.041627
[23:10:14.358] iteration 1397 : model1 loss : 0.455116 model2 loss : 0.051716
[23:10:14.534] iteration 1398 : model1 loss : 0.450952 model2 loss : 0.038127
[23:10:14.709] iteration 1399 : model1 loss : 0.454583 model2 loss : 0.046104
[23:10:14.878] iteration 1400 : model1 loss : 0.446197 model2 loss : 0.053234
[23:10:15.054] iteration 1401 : model1 loss : 0.456786 model2 loss : 0.049227
[23:10:15.225] iteration 1402 : model1 loss : 0.449056 model2 loss : 0.037681
[23:10:15.401] iteration 1403 : model1 loss : 0.446306 model2 loss : 0.043965
[23:10:15.576] iteration 1404 : model1 loss : 0.451471 model2 loss : 0.045177
[23:10:15.756] iteration 1405 : model1 loss : 0.441425 model2 loss : 0.045819
[23:10:15.923] iteration 1406 : model1 loss : 0.443755 model2 loss : 0.042645
[23:10:16.098] iteration 1407 : model1 loss : 0.443862 model2 loss : 0.038393
[23:10:18.240] iteration 1408 : model1 loss : 0.443660 model2 loss : 0.049839
[23:10:18.414] iteration 1409 : model1 loss : 0.450219 model2 loss : 0.043380
[23:10:18.595] iteration 1410 : model1 loss : 0.441180 model2 loss : 0.037251
[23:10:18.765] iteration 1411 : model1 loss : 0.451030 model2 loss : 0.048995
[23:10:18.942] iteration 1412 : model1 loss : 0.445436 model2 loss : 0.043052
[23:10:19.116] iteration 1413 : model1 loss : 0.459608 model2 loss : 0.070035
[23:10:19.295] iteration 1414 : model1 loss : 0.455740 model2 loss : 0.053280
[23:10:19.467] iteration 1415 : model1 loss : 0.446864 model2 loss : 0.040531
[23:10:19.645] iteration 1416 : model1 loss : 0.438954 model2 loss : 0.049839
[23:10:19.816] iteration 1417 : model1 loss : 0.442441 model2 loss : 0.038254
[23:10:19.994] iteration 1418 : model1 loss : 0.456899 model2 loss : 0.048110
[23:10:20.167] iteration 1419 : model1 loss : 0.448051 model2 loss : 0.051963
[23:10:20.344] iteration 1420 : model1 loss : 0.450039 model2 loss : 0.046972
[23:10:20.517] iteration 1421 : model1 loss : 0.446681 model2 loss : 0.039167
[23:10:20.696] iteration 1422 : model1 loss : 0.458005 model2 loss : 0.064883
[23:10:20.873] iteration 1423 : model1 loss : 0.441267 model2 loss : 0.042952
[23:10:21.051] iteration 1424 : model1 loss : 0.451118 model2 loss : 0.053990
[23:10:21.223] iteration 1425 : model1 loss : 0.441148 model2 loss : 0.041364
[23:10:21.400] iteration 1426 : model1 loss : 0.447313 model2 loss : 0.041335
[23:10:21.572] iteration 1427 : model1 loss : 0.445129 model2 loss : 0.041004
[23:10:21.747] iteration 1428 : model1 loss : 0.441798 model2 loss : 0.038309
[23:10:23.899] iteration 1429 : model1 loss : 0.450235 model2 loss : 0.048040
[23:10:24.075] iteration 1430 : model1 loss : 0.444502 model2 loss : 0.038139
[23:10:24.253] iteration 1431 : model1 loss : 0.444276 model2 loss : 0.035830
[23:10:24.423] iteration 1432 : model1 loss : 0.447977 model2 loss : 0.040620
[23:10:24.604] iteration 1433 : model1 loss : 0.443626 model2 loss : 0.045491
[23:10:24.774] iteration 1434 : model1 loss : 0.445138 model2 loss : 0.044549
[23:10:24.948] iteration 1435 : model1 loss : 0.446685 model2 loss : 0.038383
[23:10:25.123] iteration 1436 : model1 loss : 0.441256 model2 loss : 0.041412
[23:10:25.297] iteration 1437 : model1 loss : 0.442752 model2 loss : 0.045626
[23:10:25.470] iteration 1438 : model1 loss : 0.450796 model2 loss : 0.055232
[23:10:25.647] iteration 1439 : model1 loss : 0.446045 model2 loss : 0.048044
[23:10:25.816] iteration 1440 : model1 loss : 0.452744 model2 loss : 0.055932
[23:10:25.990] iteration 1441 : model1 loss : 0.443734 model2 loss : 0.046937
[23:10:26.163] iteration 1442 : model1 loss : 0.448925 model2 loss : 0.057031
[23:10:26.341] iteration 1443 : model1 loss : 0.447651 model2 loss : 0.050415
[23:10:26.515] iteration 1444 : model1 loss : 0.445843 model2 loss : 0.048826
[23:10:26.693] iteration 1445 : model1 loss : 0.441472 model2 loss : 0.038388
[23:10:26.864] iteration 1446 : model1 loss : 0.449119 model2 loss : 0.039818
[23:10:27.041] iteration 1447 : model1 loss : 0.448856 model2 loss : 0.045691
[23:10:27.210] iteration 1448 : model1 loss : 0.455104 model2 loss : 0.042906
[23:10:27.385] iteration 1449 : model1 loss : 0.451437 model2 loss : 0.045073
[23:10:29.531] iteration 1450 : model1 loss : 0.454684 model2 loss : 0.055812
[23:10:29.703] iteration 1451 : model1 loss : 0.445221 model2 loss : 0.037046
[23:10:29.879] iteration 1452 : model1 loss : 0.452578 model2 loss : 0.048230
[23:10:30.051] iteration 1453 : model1 loss : 0.446551 model2 loss : 0.044251
[23:10:30.230] iteration 1454 : model1 loss : 0.449018 model2 loss : 0.044861
[23:10:30.403] iteration 1455 : model1 loss : 0.445563 model2 loss : 0.046567
[23:10:30.581] iteration 1456 : model1 loss : 0.453561 model2 loss : 0.046434
[23:10:30.750] iteration 1457 : model1 loss : 0.453565 model2 loss : 0.048833
[23:10:30.927] iteration 1458 : model1 loss : 0.447174 model2 loss : 0.036797
[23:10:31.100] iteration 1459 : model1 loss : 0.472787 model2 loss : 0.083918
[23:10:31.274] iteration 1460 : model1 loss : 0.448937 model2 loss : 0.049994
[23:10:31.445] iteration 1461 : model1 loss : 0.444675 model2 loss : 0.040426
[23:10:31.625] iteration 1462 : model1 loss : 0.442038 model2 loss : 0.035286
[23:10:31.796] iteration 1463 : model1 loss : 0.441897 model2 loss : 0.041156
[23:10:31.970] iteration 1464 : model1 loss : 0.442736 model2 loss : 0.047969
[23:10:32.142] iteration 1465 : model1 loss : 0.445650 model2 loss : 0.044685
[23:10:32.323] iteration 1466 : model1 loss : 0.448432 model2 loss : 0.045041
[23:10:32.500] iteration 1467 : model1 loss : 0.445687 model2 loss : 0.045836
[23:10:32.679] iteration 1468 : model1 loss : 0.451985 model2 loss : 0.048334
[23:10:32.848] iteration 1469 : model1 loss : 0.447108 model2 loss : 0.049474
[23:10:33.022] iteration 1470 : model1 loss : 0.440344 model2 loss : 0.040416
[23:10:35.170] iteration 1471 : model1 loss : 0.442644 model2 loss : 0.036144
[23:10:35.346] iteration 1472 : model1 loss : 0.446352 model2 loss : 0.043447
[23:10:35.523] iteration 1473 : model1 loss : 0.446470 model2 loss : 0.044195
[23:10:35.699] iteration 1474 : model1 loss : 0.444347 model2 loss : 0.041557
[23:10:35.875] iteration 1475 : model1 loss : 0.450237 model2 loss : 0.051283
[23:10:36.044] iteration 1476 : model1 loss : 0.455317 model2 loss : 0.044481
[23:10:36.221] iteration 1477 : model1 loss : 0.447597 model2 loss : 0.038827
[23:10:36.390] iteration 1478 : model1 loss : 0.452710 model2 loss : 0.032861
[23:10:36.570] iteration 1479 : model1 loss : 0.440157 model2 loss : 0.036647
[23:10:36.741] iteration 1480 : model1 loss : 0.445882 model2 loss : 0.052626
[23:10:36.916] iteration 1481 : model1 loss : 0.445538 model2 loss : 0.038383
[23:10:37.089] iteration 1482 : model1 loss : 0.448286 model2 loss : 0.051300
[23:10:37.263] iteration 1483 : model1 loss : 0.443933 model2 loss : 0.045592
[23:10:37.437] iteration 1484 : model1 loss : 0.443942 model2 loss : 0.036157
[23:10:37.617] iteration 1485 : model1 loss : 0.457290 model2 loss : 0.051553
[23:10:37.787] iteration 1486 : model1 loss : 0.454052 model2 loss : 0.043372
[23:10:37.963] iteration 1487 : model1 loss : 0.453054 model2 loss : 0.055508
[23:10:38.136] iteration 1488 : model1 loss : 0.452068 model2 loss : 0.037909
[23:10:38.316] iteration 1489 : model1 loss : 0.447319 model2 loss : 0.044135
[23:10:38.485] iteration 1490 : model1 loss : 0.445849 model2 loss : 0.036878
[23:10:38.658] iteration 1491 : model1 loss : 0.446150 model2 loss : 0.042388
[23:10:40.799] iteration 1492 : model1 loss : 0.438235 model2 loss : 0.033460
[23:10:40.972] iteration 1493 : model1 loss : 0.456779 model2 loss : 0.050774
[23:10:41.151] iteration 1494 : model1 loss : 0.448136 model2 loss : 0.051771
[23:10:41.325] iteration 1495 : model1 loss : 0.446571 model2 loss : 0.039058
[23:10:41.502] iteration 1496 : model1 loss : 0.447198 model2 loss : 0.044366
[23:10:41.674] iteration 1497 : model1 loss : 0.442903 model2 loss : 0.035164
[23:10:41.850] iteration 1498 : model1 loss : 0.446075 model2 loss : 0.037906
[23:10:42.020] iteration 1499 : model1 loss : 0.452018 model2 loss : 0.048024
[23:10:42.197] iteration 1500 : model1 loss : 0.449903 model2 loss : 0.040446
[23:10:42.371] iteration 1501 : model1 loss : 0.440895 model2 loss : 0.034005
[23:10:42.558] iteration 1502 : model1 loss : 0.444945 model2 loss : 0.043697
[23:10:42.730] iteration 1503 : model1 loss : 0.448005 model2 loss : 0.043985
[23:10:42.904] iteration 1504 : model1 loss : 0.449277 model2 loss : 0.043289
[23:10:43.076] iteration 1505 : model1 loss : 0.446937 model2 loss : 0.041902
[23:10:43.251] iteration 1506 : model1 loss : 0.445640 model2 loss : 0.046668
[23:10:43.423] iteration 1507 : model1 loss : 0.455080 model2 loss : 0.054263
[23:10:43.604] iteration 1508 : model1 loss : 0.446567 model2 loss : 0.042815
[23:10:43.774] iteration 1509 : model1 loss : 0.457823 model2 loss : 0.040787
[23:10:43.952] iteration 1510 : model1 loss : 0.450159 model2 loss : 0.044949
[23:10:44.124] iteration 1511 : model1 loss : 0.452210 model2 loss : 0.046956
[23:10:44.301] iteration 1512 : model1 loss : 0.447396 model2 loss : 0.049467
[23:10:46.441] iteration 1513 : model1 loss : 0.450057 model2 loss : 0.045434
[23:10:46.621] iteration 1514 : model1 loss : 0.452279 model2 loss : 0.051718
[23:10:46.798] iteration 1515 : model1 loss : 0.449900 model2 loss : 0.039395
[23:10:46.969] iteration 1516 : model1 loss : 0.442028 model2 loss : 0.031519
[23:10:47.145] iteration 1517 : model1 loss : 0.441128 model2 loss : 0.036449
[23:10:47.319] iteration 1518 : model1 loss : 0.445445 model2 loss : 0.048380
[23:10:47.499] iteration 1519 : model1 loss : 0.447593 model2 loss : 0.038146
[23:10:47.674] iteration 1520 : model1 loss : 0.443415 model2 loss : 0.044186
[23:10:47.847] iteration 1521 : model1 loss : 0.449146 model2 loss : 0.046571
[23:10:48.018] iteration 1522 : model1 loss : 0.457774 model2 loss : 0.050896
[23:10:48.196] iteration 1523 : model1 loss : 0.450094 model2 loss : 0.050231
[23:10:48.367] iteration 1524 : model1 loss : 0.453606 model2 loss : 0.045122
[23:10:48.543] iteration 1525 : model1 loss : 0.442657 model2 loss : 0.039487
[23:10:48.716] iteration 1526 : model1 loss : 0.449394 model2 loss : 0.049650
[23:10:48.893] iteration 1527 : model1 loss : 0.446680 model2 loss : 0.038648
[23:10:49.066] iteration 1528 : model1 loss : 0.445888 model2 loss : 0.040620
[23:10:49.241] iteration 1529 : model1 loss : 0.449393 model2 loss : 0.039543
[23:10:49.414] iteration 1530 : model1 loss : 0.441760 model2 loss : 0.043387
[23:10:49.598] iteration 1531 : model1 loss : 0.453740 model2 loss : 0.045168
[23:10:49.769] iteration 1532 : model1 loss : 0.449651 model2 loss : 0.048168
[23:10:49.943] iteration 1533 : model1 loss : 0.463359 model2 loss : 0.066789
[23:10:52.069] iteration 1534 : model1 loss : 0.448031 model2 loss : 0.046117
[23:10:52.240] iteration 1535 : model1 loss : 0.445407 model2 loss : 0.040632
[23:10:52.417] iteration 1536 : model1 loss : 0.449597 model2 loss : 0.042595
[23:10:52.593] iteration 1537 : model1 loss : 0.449348 model2 loss : 0.050281
[23:10:52.769] iteration 1538 : model1 loss : 0.442185 model2 loss : 0.035579
[23:10:52.940] iteration 1539 : model1 loss : 0.454413 model2 loss : 0.079608
[23:10:53.116] iteration 1540 : model1 loss : 0.454588 model2 loss : 0.078452
[23:10:53.286] iteration 1541 : model1 loss : 0.458766 model2 loss : 0.039663
[23:10:53.466] iteration 1542 : model1 loss : 0.449829 model2 loss : 0.044774
[23:10:53.642] iteration 1543 : model1 loss : 0.442138 model2 loss : 0.035512
[23:10:53.814] iteration 1544 : model1 loss : 0.444152 model2 loss : 0.034822
[23:10:53.984] iteration 1545 : model1 loss : 0.444113 model2 loss : 0.041341
[23:10:54.160] iteration 1546 : model1 loss : 0.447709 model2 loss : 0.047216
[23:10:54.336] iteration 1547 : model1 loss : 0.447037 model2 loss : 0.038540
[23:10:54.512] iteration 1548 : model1 loss : 0.443903 model2 loss : 0.037134
[23:10:54.687] iteration 1549 : model1 loss : 0.445109 model2 loss : 0.040553
[23:10:54.863] iteration 1550 : model1 loss : 0.448586 model2 loss : 0.046587
[23:10:55.033] iteration 1551 : model1 loss : 0.443261 model2 loss : 0.040262
[23:10:55.207] iteration 1552 : model1 loss : 0.443802 model2 loss : 0.041812
[23:10:55.377] iteration 1553 : model1 loss : 0.452272 model2 loss : 0.056742
[23:10:55.552] iteration 1554 : model1 loss : 0.442527 model2 loss : 0.037509
[23:10:57.707] iteration 1555 : model1 loss : 0.450307 model2 loss : 0.041667
[23:10:57.883] iteration 1556 : model1 loss : 0.444716 model2 loss : 0.037137
[23:10:58.060] iteration 1557 : model1 loss : 0.441551 model2 loss : 0.041728
[23:10:58.234] iteration 1558 : model1 loss : 0.439111 model2 loss : 0.035617
[23:10:58.410] iteration 1559 : model1 loss : 0.440618 model2 loss : 0.039623
[23:10:58.585] iteration 1560 : model1 loss : 0.450934 model2 loss : 0.045746
[23:10:58.763] iteration 1561 : model1 loss : 0.450057 model2 loss : 0.045590
[23:10:58.932] iteration 1562 : model1 loss : 0.443080 model2 loss : 0.040979
[23:10:59.110] iteration 1563 : model1 loss : 0.446092 model2 loss : 0.037329
[23:10:59.282] iteration 1564 : model1 loss : 0.440208 model2 loss : 0.036638
[23:10:59.458] iteration 1565 : model1 loss : 0.448271 model2 loss : 0.040903
[23:10:59.635] iteration 1566 : model1 loss : 0.444573 model2 loss : 0.034320
[23:10:59.809] iteration 1567 : model1 loss : 0.443131 model2 loss : 0.036685
[23:10:59.979] iteration 1568 : model1 loss : 0.441229 model2 loss : 0.045673
[23:11:00.159] iteration 1569 : model1 loss : 0.445059 model2 loss : 0.058517
[23:11:00.333] iteration 1570 : model1 loss : 0.441135 model2 loss : 0.034180
[23:11:00.508] iteration 1571 : model1 loss : 0.445873 model2 loss : 0.044143
[23:11:00.683] iteration 1572 : model1 loss : 0.443990 model2 loss : 0.048949
[23:11:00.858] iteration 1573 : model1 loss : 0.449132 model2 loss : 0.042551
[23:11:01.028] iteration 1574 : model1 loss : 0.442893 model2 loss : 0.032752
[23:11:01.200] iteration 1575 : model1 loss : 0.444614 model2 loss : 0.041708
[23:11:03.366] iteration 1576 : model1 loss : 0.450911 model2 loss : 0.041391
[23:11:03.536] iteration 1577 : model1 loss : 0.444447 model2 loss : 0.040533
[23:11:03.714] iteration 1578 : model1 loss : 0.446260 model2 loss : 0.044501
[23:11:03.883] iteration 1579 : model1 loss : 0.442583 model2 loss : 0.042542
[23:11:04.058] iteration 1580 : model1 loss : 0.449774 model2 loss : 0.042714
[23:11:04.232] iteration 1581 : model1 loss : 0.444340 model2 loss : 0.031700
[23:11:04.407] iteration 1582 : model1 loss : 0.444484 model2 loss : 0.037567
[23:11:04.582] iteration 1583 : model1 loss : 0.440421 model2 loss : 0.042652
[23:11:04.760] iteration 1584 : model1 loss : 0.451424 model2 loss : 0.044607
[23:11:04.929] iteration 1585 : model1 loss : 0.439949 model2 loss : 0.034362
[23:11:05.104] iteration 1586 : model1 loss : 0.452415 model2 loss : 0.052255
[23:11:05.275] iteration 1587 : model1 loss : 0.445134 model2 loss : 0.034364
[23:11:05.451] iteration 1588 : model1 loss : 0.441287 model2 loss : 0.038597
[23:11:05.629] iteration 1589 : model1 loss : 0.448200 model2 loss : 0.046405
[23:11:05.804] iteration 1590 : model1 loss : 0.448072 model2 loss : 0.032362
[23:11:05.975] iteration 1591 : model1 loss : 0.450087 model2 loss : 0.050394
[23:11:06.151] iteration 1592 : model1 loss : 0.440264 model2 loss : 0.041468
[23:11:06.323] iteration 1593 : model1 loss : 0.447346 model2 loss : 0.042535
[23:11:06.499] iteration 1594 : model1 loss : 0.443747 model2 loss : 0.042020
[23:11:06.676] iteration 1595 : model1 loss : 0.449410 model2 loss : 0.051360
[23:11:06.849] iteration 1596 : model1 loss : 0.442879 model2 loss : 0.037242
[23:11:08.987] iteration 1597 : model1 loss : 0.440169 model2 loss : 0.035782
[23:11:09.162] iteration 1598 : model1 loss : 0.444305 model2 loss : 0.040957
[23:11:09.343] iteration 1599 : model1 loss : 0.444645 model2 loss : 0.038294
[23:11:09.512] iteration 1600 : model1 loss : 0.439018 model2 loss : 0.033237
[23:11:09.690] iteration 1601 : model1 loss : 0.438672 model2 loss : 0.035637
[23:11:09.860] iteration 1602 : model1 loss : 0.440921 model2 loss : 0.039284
[23:11:10.032] iteration 1603 : model1 loss : 0.441854 model2 loss : 0.038584
[23:11:10.205] iteration 1604 : model1 loss : 0.444090 model2 loss : 0.038711
[23:11:10.380] iteration 1605 : model1 loss : 0.445936 model2 loss : 0.035799
[23:11:10.552] iteration 1606 : model1 loss : 0.449661 model2 loss : 0.044824
[23:11:10.729] iteration 1607 : model1 loss : 0.444597 model2 loss : 0.037422
[23:11:10.900] iteration 1608 : model1 loss : 0.453139 model2 loss : 0.040652
[23:11:11.074] iteration 1609 : model1 loss : 0.449722 model2 loss : 0.048642
[23:11:11.247] iteration 1610 : model1 loss : 0.451072 model2 loss : 0.049919
[23:11:11.425] iteration 1611 : model1 loss : 0.446802 model2 loss : 0.036068
[23:11:11.601] iteration 1612 : model1 loss : 0.446515 model2 loss : 0.050316
[23:11:11.778] iteration 1613 : model1 loss : 0.448236 model2 loss : 0.047870
[23:11:11.949] iteration 1614 : model1 loss : 0.441781 model2 loss : 0.040687
[23:11:12.125] iteration 1615 : model1 loss : 0.446196 model2 loss : 0.045125
[23:11:12.296] iteration 1616 : model1 loss : 0.446649 model2 loss : 0.035797
[23:11:12.474] iteration 1617 : model1 loss : 0.440433 model2 loss : 0.037846
[23:11:14.609] iteration 1618 : model1 loss : 0.443778 model2 loss : 0.041788
[23:11:14.785] iteration 1619 : model1 loss : 0.442189 model2 loss : 0.053145
[23:11:14.962] iteration 1620 : model1 loss : 0.446548 model2 loss : 0.047175
[23:11:15.133] iteration 1621 : model1 loss : 0.452417 model2 loss : 0.046997
[23:11:15.309] iteration 1622 : model1 loss : 0.444133 model2 loss : 0.041735
[23:11:15.480] iteration 1623 : model1 loss : 0.441029 model2 loss : 0.038365
[23:11:15.659] iteration 1624 : model1 loss : 0.438920 model2 loss : 0.032459
[23:11:15.829] iteration 1625 : model1 loss : 0.442425 model2 loss : 0.041323
[23:11:16.002] iteration 1626 : model1 loss : 0.447493 model2 loss : 0.040741
[23:11:16.175] iteration 1627 : model1 loss : 0.460092 model2 loss : 0.042016
[23:11:16.353] iteration 1628 : model1 loss : 0.449184 model2 loss : 0.049138
[23:11:16.524] iteration 1629 : model1 loss : 0.445821 model2 loss : 0.033096
[23:11:16.698] iteration 1630 : model1 loss : 0.451107 model2 loss : 0.040030
[23:11:16.869] iteration 1631 : model1 loss : 0.441167 model2 loss : 0.040960
[23:11:17.044] iteration 1632 : model1 loss : 0.454926 model2 loss : 0.060993
[23:11:17.216] iteration 1633 : model1 loss : 0.443893 model2 loss : 0.047583
[23:11:17.394] iteration 1634 : model1 loss : 0.445008 model2 loss : 0.040772
[23:11:17.566] iteration 1635 : model1 loss : 0.443068 model2 loss : 0.036749
[23:11:17.742] iteration 1636 : model1 loss : 0.448569 model2 loss : 0.043312
[23:11:17.911] iteration 1637 : model1 loss : 0.448642 model2 loss : 0.033997
[23:11:18.083] iteration 1638 : model1 loss : 0.447717 model2 loss : 0.042559
[23:11:20.215] iteration 1639 : model1 loss : 0.444198 model2 loss : 0.046047
[23:11:20.393] iteration 1640 : model1 loss : 0.442527 model2 loss : 0.037405
[23:11:20.572] iteration 1641 : model1 loss : 0.441696 model2 loss : 0.042776
[23:11:20.751] iteration 1642 : model1 loss : 0.448820 model2 loss : 0.039845
[23:11:20.928] iteration 1643 : model1 loss : 0.458896 model2 loss : 0.047549
[23:11:21.100] iteration 1644 : model1 loss : 0.442364 model2 loss : 0.041302
[23:11:21.275] iteration 1645 : model1 loss : 0.442782 model2 loss : 0.038520
[23:11:21.445] iteration 1646 : model1 loss : 0.445816 model2 loss : 0.041848
[23:11:21.626] iteration 1647 : model1 loss : 0.444990 model2 loss : 0.041858
[23:11:21.799] iteration 1648 : model1 loss : 0.443646 model2 loss : 0.040623
[23:11:21.974] iteration 1649 : model1 loss : 0.451166 model2 loss : 0.056661
[23:11:22.149] iteration 1650 : model1 loss : 0.445594 model2 loss : 0.040287
[23:11:22.330] iteration 1651 : model1 loss : 0.441902 model2 loss : 0.040968
[23:11:22.506] iteration 1652 : model1 loss : 0.443873 model2 loss : 0.043137
[23:11:22.683] iteration 1653 : model1 loss : 0.446182 model2 loss : 0.044417
[23:11:22.855] iteration 1654 : model1 loss : 0.447761 model2 loss : 0.035148
[23:11:23.029] iteration 1655 : model1 loss : 0.452318 model2 loss : 0.036062
[23:11:23.202] iteration 1656 : model1 loss : 0.440346 model2 loss : 0.038218
[23:11:23.379] iteration 1657 : model1 loss : 0.444154 model2 loss : 0.035489
[23:11:23.549] iteration 1658 : model1 loss : 0.449678 model2 loss : 0.050083
[23:11:23.726] iteration 1659 : model1 loss : 0.451649 model2 loss : 0.042131
[23:11:25.874] iteration 1660 : model1 loss : 0.448423 model2 loss : 0.034249
[23:11:26.047] iteration 1661 : model1 loss : 0.442413 model2 loss : 0.037874
[23:11:26.223] iteration 1662 : model1 loss : 0.451755 model2 loss : 0.048438
[23:11:26.396] iteration 1663 : model1 loss : 0.447945 model2 loss : 0.039983
[23:11:26.575] iteration 1664 : model1 loss : 0.441581 model2 loss : 0.048382
[23:11:26.747] iteration 1665 : model1 loss : 0.434748 model2 loss : 0.033313
[23:11:26.924] iteration 1666 : model1 loss : 0.446964 model2 loss : 0.046252
[23:11:27.095] iteration 1667 : model1 loss : 0.442726 model2 loss : 0.035081
[23:11:27.271] iteration 1668 : model1 loss : 0.452671 model2 loss : 0.044401
[23:11:27.444] iteration 1669 : model1 loss : 0.450932 model2 loss : 0.041074
[23:11:27.627] iteration 1670 : model1 loss : 0.453492 model2 loss : 0.038438
[23:11:27.800] iteration 1671 : model1 loss : 0.449256 model2 loss : 0.041144
[23:11:27.972] iteration 1672 : model1 loss : 0.450658 model2 loss : 0.037177
[23:11:28.145] iteration 1673 : model1 loss : 0.459717 model2 loss : 0.048123
[23:11:28.325] iteration 1674 : model1 loss : 0.445405 model2 loss : 0.045454
[23:11:28.496] iteration 1675 : model1 loss : 0.444521 model2 loss : 0.036836
[23:11:28.674] iteration 1676 : model1 loss : 0.455586 model2 loss : 0.041751
[23:11:28.844] iteration 1677 : model1 loss : 0.449980 model2 loss : 0.044069
[23:11:29.018] iteration 1678 : model1 loss : 0.448420 model2 loss : 0.044238
[23:11:29.189] iteration 1679 : model1 loss : 0.444048 model2 loss : 0.045669
[23:11:29.364] iteration 1680 : model1 loss : 0.445617 model2 loss : 0.050363
[23:11:31.535] iteration 1681 : model1 loss : 0.448041 model2 loss : 0.039237
[23:11:31.715] iteration 1682 : model1 loss : 0.443975 model2 loss : 0.041405
[23:11:31.892] iteration 1683 : model1 loss : 0.444416 model2 loss : 0.036158
[23:11:32.062] iteration 1684 : model1 loss : 0.450517 model2 loss : 0.051002
[23:11:32.239] iteration 1685 : model1 loss : 0.445778 model2 loss : 0.040681
[23:11:32.413] iteration 1686 : model1 loss : 0.440857 model2 loss : 0.038310
[23:11:32.593] iteration 1687 : model1 loss : 0.439324 model2 loss : 0.034079
[23:11:32.774] iteration 1688 : model1 loss : 0.440651 model2 loss : 0.039648
[23:11:32.951] iteration 1689 : model1 loss : 0.444106 model2 loss : 0.041357
[23:11:33.121] iteration 1690 : model1 loss : 0.443471 model2 loss : 0.036381
[23:11:33.303] iteration 1691 : model1 loss : 0.440671 model2 loss : 0.045073
[23:11:33.472] iteration 1692 : model1 loss : 0.443851 model2 loss : 0.042576
[23:11:33.649] iteration 1693 : model1 loss : 0.446529 model2 loss : 0.038726
[23:11:33.823] iteration 1694 : model1 loss : 0.441691 model2 loss : 0.042960
[23:11:33.999] iteration 1695 : model1 loss : 0.452669 model2 loss : 0.046628
[23:11:34.174] iteration 1696 : model1 loss : 0.446396 model2 loss : 0.039264
[23:11:34.352] iteration 1697 : model1 loss : 0.446693 model2 loss : 0.043047
[23:11:34.523] iteration 1698 : model1 loss : 0.446282 model2 loss : 0.055669
[23:11:34.698] iteration 1699 : model1 loss : 0.447104 model2 loss : 0.046510
[23:11:34.868] iteration 1700 : model1 loss : 0.441809 model2 loss : 0.042722
[23:11:35.041] iteration 1701 : model1 loss : 0.442048 model2 loss : 0.042693
[23:11:37.177] iteration 1702 : model1 loss : 0.444437 model2 loss : 0.034393
[23:11:37.358] iteration 1703 : model1 loss : 0.448658 model2 loss : 0.035428
[23:11:37.537] iteration 1704 : model1 loss : 0.443431 model2 loss : 0.041908
[23:11:37.709] iteration 1705 : model1 loss : 0.445643 model2 loss : 0.046988
[23:11:37.885] iteration 1706 : model1 loss : 0.445555 model2 loss : 0.038047
[23:11:38.054] iteration 1707 : model1 loss : 0.445694 model2 loss : 0.044198
[23:11:38.231] iteration 1708 : model1 loss : 0.451999 model2 loss : 0.051784
[23:11:38.404] iteration 1709 : model1 loss : 0.442514 model2 loss : 0.041561
[23:11:38.579] iteration 1710 : model1 loss : 0.443048 model2 loss : 0.046354
[23:11:38.752] iteration 1711 : model1 loss : 0.437188 model2 loss : 0.038346
[23:11:38.928] iteration 1712 : model1 loss : 0.439097 model2 loss : 0.043737
[23:11:39.098] iteration 1713 : model1 loss : 0.440183 model2 loss : 0.045295
[23:11:39.273] iteration 1714 : model1 loss : 0.442875 model2 loss : 0.039792
[23:11:39.444] iteration 1715 : model1 loss : 0.446415 model2 loss : 0.052368
[23:11:39.625] iteration 1716 : model1 loss : 0.441783 model2 loss : 0.037267
[23:11:39.797] iteration 1717 : model1 loss : 0.443720 model2 loss : 0.040716
[23:11:39.976] iteration 1718 : model1 loss : 0.439750 model2 loss : 0.041223
[23:11:40.146] iteration 1719 : model1 loss : 0.444601 model2 loss : 0.038572
[23:11:40.328] iteration 1720 : model1 loss : 0.447722 model2 loss : 0.044044
[23:11:40.497] iteration 1721 : model1 loss : 0.444708 model2 loss : 0.043906
[23:11:40.669] iteration 1722 : model1 loss : 0.441689 model2 loss : 0.042248
[23:11:42.783] iteration 1723 : model1 loss : 0.445920 model2 loss : 0.034607
[23:11:42.959] iteration 1724 : model1 loss : 0.444756 model2 loss : 0.040231
[23:11:43.137] iteration 1725 : model1 loss : 0.447347 model2 loss : 0.043522
[23:11:43.312] iteration 1726 : model1 loss : 0.444319 model2 loss : 0.050959
[23:11:43.491] iteration 1727 : model1 loss : 0.439404 model2 loss : 0.035489
[23:11:43.661] iteration 1728 : model1 loss : 0.441974 model2 loss : 0.036085
[23:11:43.838] iteration 1729 : model1 loss : 0.447040 model2 loss : 0.049854
[23:11:44.010] iteration 1730 : model1 loss : 0.444640 model2 loss : 0.039271
[23:11:44.187] iteration 1731 : model1 loss : 0.442391 model2 loss : 0.033952
[23:11:44.363] iteration 1732 : model1 loss : 0.446619 model2 loss : 0.047591
[23:11:44.542] iteration 1733 : model1 loss : 0.443565 model2 loss : 0.041375
[23:11:44.712] iteration 1734 : model1 loss : 0.442660 model2 loss : 0.039042
[23:11:44.887] iteration 1735 : model1 loss : 0.444704 model2 loss : 0.035666
[23:11:45.056] iteration 1736 : model1 loss : 0.443493 model2 loss : 0.040032
[23:11:45.233] iteration 1737 : model1 loss : 0.442532 model2 loss : 0.039402
[23:11:45.405] iteration 1738 : model1 loss : 0.443039 model2 loss : 0.041589
[23:11:45.582] iteration 1739 : model1 loss : 0.442650 model2 loss : 0.038515
[23:11:45.753] iteration 1740 : model1 loss : 0.441467 model2 loss : 0.038014
[23:11:45.931] iteration 1741 : model1 loss : 0.446955 model2 loss : 0.040280
[23:11:46.100] iteration 1742 : model1 loss : 0.440848 model2 loss : 0.033901
[23:11:46.275] iteration 1743 : model1 loss : 0.436644 model2 loss : 0.039274
[23:11:48.385] iteration 1744 : model1 loss : 0.437684 model2 loss : 0.032452
[23:11:48.560] iteration 1745 : model1 loss : 0.444541 model2 loss : 0.035256
[23:11:48.740] iteration 1746 : model1 loss : 0.447044 model2 loss : 0.039864
[23:11:48.909] iteration 1747 : model1 loss : 0.446865 model2 loss : 0.033309
[23:11:49.085] iteration 1748 : model1 loss : 0.439082 model2 loss : 0.040271
[23:11:49.258] iteration 1749 : model1 loss : 0.441064 model2 loss : 0.046231
[23:11:49.436] iteration 1750 : model1 loss : 0.446841 model2 loss : 0.038633
[23:11:49.610] iteration 1751 : model1 loss : 0.453539 model2 loss : 0.042506
[23:11:49.785] iteration 1752 : model1 loss : 0.443947 model2 loss : 0.043645
[23:11:49.967] iteration 1753 : model1 loss : 0.440835 model2 loss : 0.038225
[23:11:50.142] iteration 1754 : model1 loss : 0.444620 model2 loss : 0.045628
[23:11:50.315] iteration 1755 : model1 loss : 0.442495 model2 loss : 0.031747
[23:11:50.493] iteration 1756 : model1 loss : 0.447797 model2 loss : 0.048164
[23:11:50.666] iteration 1757 : model1 loss : 0.443051 model2 loss : 0.040864
[23:11:50.845] iteration 1758 : model1 loss : 0.447247 model2 loss : 0.043122
[23:11:51.015] iteration 1759 : model1 loss : 0.451268 model2 loss : 0.052963
[23:11:51.193] iteration 1760 : model1 loss : 0.443016 model2 loss : 0.038469
[23:11:51.366] iteration 1761 : model1 loss : 0.445061 model2 loss : 0.054532
[23:11:51.543] iteration 1762 : model1 loss : 0.442304 model2 loss : 0.042001
[23:11:51.714] iteration 1763 : model1 loss : 0.436723 model2 loss : 0.034647
[23:11:51.890] iteration 1764 : model1 loss : 0.444487 model2 loss : 0.041300
[23:11:54.013] iteration 1765 : model1 loss : 0.445081 model2 loss : 0.046354
[23:11:54.183] iteration 1766 : model1 loss : 0.439963 model2 loss : 0.034456
[23:11:54.364] iteration 1767 : model1 loss : 0.441541 model2 loss : 0.036580
[23:11:54.538] iteration 1768 : model1 loss : 0.444729 model2 loss : 0.043513
[23:11:54.713] iteration 1769 : model1 loss : 0.445427 model2 loss : 0.034611
[23:11:54.885] iteration 1770 : model1 loss : 0.447491 model2 loss : 0.042066
[23:11:55.061] iteration 1771 : model1 loss : 0.444771 model2 loss : 0.043585
[23:11:55.231] iteration 1772 : model1 loss : 0.442384 model2 loss : 0.034304
[23:11:55.409] iteration 1773 : model1 loss : 0.437954 model2 loss : 0.037467
[23:11:55.581] iteration 1774 : model1 loss : 0.447666 model2 loss : 0.051223
[23:11:55.760] iteration 1775 : model1 loss : 0.446791 model2 loss : 0.043497
[23:11:55.930] iteration 1776 : model1 loss : 0.441742 model2 loss : 0.040487
[23:11:56.107] iteration 1777 : model1 loss : 0.448339 model2 loss : 0.037144
[23:11:56.280] iteration 1778 : model1 loss : 0.441632 model2 loss : 0.035322
[23:11:56.460] iteration 1779 : model1 loss : 0.449427 model2 loss : 0.056562
[23:11:56.638] iteration 1780 : model1 loss : 0.450039 model2 loss : 0.043414
[23:11:56.813] iteration 1781 : model1 loss : 0.448155 model2 loss : 0.036987
[23:11:56.982] iteration 1782 : model1 loss : 0.443722 model2 loss : 0.038930
[23:11:57.160] iteration 1783 : model1 loss : 0.438873 model2 loss : 0.036767
[23:11:57.358] iteration 1784 : model1 loss : 0.440101 model2 loss : 0.047712
[23:11:57.534] iteration 1785 : model1 loss : 0.438126 model2 loss : 0.037987
[23:11:59.660] iteration 1786 : model1 loss : 0.443369 model2 loss : 0.034456
[23:11:59.835] iteration 1787 : model1 loss : 0.442709 model2 loss : 0.050091
[23:12:00.012] iteration 1788 : model1 loss : 0.439288 model2 loss : 0.037203
[23:12:00.186] iteration 1789 : model1 loss : 0.452538 model2 loss : 0.047034
[23:12:00.365] iteration 1790 : model1 loss : 0.444213 model2 loss : 0.035592
[23:12:00.536] iteration 1791 : model1 loss : 0.440889 model2 loss : 0.032562
[23:12:00.713] iteration 1792 : model1 loss : 0.443621 model2 loss : 0.037581
[23:12:00.885] iteration 1793 : model1 loss : 0.446487 model2 loss : 0.045629
[23:12:01.060] iteration 1794 : model1 loss : 0.442968 model2 loss : 0.043478
[23:12:01.232] iteration 1795 : model1 loss : 0.442743 model2 loss : 0.039601
[23:12:01.410] iteration 1796 : model1 loss : 0.449103 model2 loss : 0.052971
[23:12:01.584] iteration 1797 : model1 loss : 0.438070 model2 loss : 0.037468
[23:12:01.761] iteration 1798 : model1 loss : 0.449077 model2 loss : 0.036655
[23:12:01.930] iteration 1799 : model1 loss : 0.441700 model2 loss : 0.043604
[23:12:02.106] iteration 1800 : model1 loss : 0.447212 model2 loss : 0.047486
[23:12:02.279] iteration 1801 : model1 loss : 0.439986 model2 loss : 0.041081
[23:12:02.459] iteration 1802 : model1 loss : 0.445668 model2 loss : 0.044405
[23:12:02.633] iteration 1803 : model1 loss : 0.449611 model2 loss : 0.049320
[23:12:02.809] iteration 1804 : model1 loss : 0.445849 model2 loss : 0.038303
[23:12:02.977] iteration 1805 : model1 loss : 0.442075 model2 loss : 0.032302
[23:12:03.150] iteration 1806 : model1 loss : 0.439976 model2 loss : 0.035262
[23:12:05.286] iteration 1807 : model1 loss : 0.442046 model2 loss : 0.037429
[23:12:05.465] iteration 1808 : model1 loss : 0.448613 model2 loss : 0.038936
[23:12:05.641] iteration 1809 : model1 loss : 0.444333 model2 loss : 0.040955
[23:12:05.813] iteration 1810 : model1 loss : 0.452267 model2 loss : 0.052842
[23:12:05.992] iteration 1811 : model1 loss : 0.441539 model2 loss : 0.034568
[23:12:06.162] iteration 1812 : model1 loss : 0.441121 model2 loss : 0.041705
[23:12:06.339] iteration 1813 : model1 loss : 0.443878 model2 loss : 0.039859
[23:12:06.511] iteration 1814 : model1 loss : 0.443813 model2 loss : 0.040372
[23:12:06.688] iteration 1815 : model1 loss : 0.444159 model2 loss : 0.038322
[23:12:06.864] iteration 1816 : model1 loss : 0.446239 model2 loss : 0.049815
[23:12:07.041] iteration 1817 : model1 loss : 0.441575 model2 loss : 0.039557
[23:12:07.211] iteration 1818 : model1 loss : 0.447966 model2 loss : 0.052923
[23:12:07.393] iteration 1819 : model1 loss : 0.438430 model2 loss : 0.041154
[23:12:07.569] iteration 1820 : model1 loss : 0.450137 model2 loss : 0.040173
[23:12:07.746] iteration 1821 : model1 loss : 0.445212 model2 loss : 0.038967
[23:12:07.916] iteration 1822 : model1 loss : 0.450939 model2 loss : 0.043549
[23:12:08.091] iteration 1823 : model1 loss : 0.442480 model2 loss : 0.044078
[23:12:08.265] iteration 1824 : model1 loss : 0.446688 model2 loss : 0.057861
[23:12:08.443] iteration 1825 : model1 loss : 0.442126 model2 loss : 0.048420
[23:12:08.619] iteration 1826 : model1 loss : 0.444044 model2 loss : 0.036448
[23:12:08.794] iteration 1827 : model1 loss : 0.448638 model2 loss : 0.070800
[23:12:10.920] iteration 1828 : model1 loss : 0.444093 model2 loss : 0.046031
[23:12:11.093] iteration 1829 : model1 loss : 0.443203 model2 loss : 0.038474
[23:12:11.271] iteration 1830 : model1 loss : 0.446567 model2 loss : 0.044763
[23:12:11.442] iteration 1831 : model1 loss : 0.443152 model2 loss : 0.042153
[23:12:11.622] iteration 1832 : model1 loss : 0.448951 model2 loss : 0.052188
[23:12:11.797] iteration 1833 : model1 loss : 0.446667 model2 loss : 0.061641
[23:12:11.971] iteration 1834 : model1 loss : 0.446239 model2 loss : 0.041013
[23:12:12.140] iteration 1835 : model1 loss : 0.445490 model2 loss : 0.041874
[23:12:12.318] iteration 1836 : model1 loss : 0.447084 model2 loss : 0.044900
[23:12:12.495] iteration 1837 : model1 loss : 0.444203 model2 loss : 0.042340
[23:12:12.670] iteration 1838 : model1 loss : 0.448985 model2 loss : 0.057481
[23:12:12.841] iteration 1839 : model1 loss : 0.446220 model2 loss : 0.060206
[23:12:13.021] iteration 1840 : model1 loss : 0.445410 model2 loss : 0.050545
[23:12:13.195] iteration 1841 : model1 loss : 0.447852 model2 loss : 0.052582
[23:12:13.389] iteration 1842 : model1 loss : 0.445550 model2 loss : 0.041984
[23:12:13.561] iteration 1843 : model1 loss : 0.443459 model2 loss : 0.040397
[23:12:13.736] iteration 1844 : model1 loss : 0.438412 model2 loss : 0.041196
[23:12:13.907] iteration 1845 : model1 loss : 0.439961 model2 loss : 0.041474
[23:12:14.082] iteration 1846 : model1 loss : 0.445829 model2 loss : 0.057372
[23:12:14.252] iteration 1847 : model1 loss : 0.439282 model2 loss : 0.050296
[23:12:14.429] iteration 1848 : model1 loss : 0.444691 model2 loss : 0.045834
[23:12:16.605] iteration 1849 : model1 loss : 0.443518 model2 loss : 0.059145
[23:12:16.777] iteration 1850 : model1 loss : 0.439098 model2 loss : 0.044671
[23:12:16.954] iteration 1851 : model1 loss : 0.444412 model2 loss : 0.053953
[23:12:17.128] iteration 1852 : model1 loss : 0.445729 model2 loss : 0.038960
[23:12:17.304] iteration 1853 : model1 loss : 0.446656 model2 loss : 0.046423
[23:12:17.482] iteration 1854 : model1 loss : 0.438803 model2 loss : 0.037785
[23:12:17.661] iteration 1855 : model1 loss : 0.437911 model2 loss : 0.044157
[23:12:17.837] iteration 1856 : model1 loss : 0.442912 model2 loss : 0.046562
[23:12:18.010] iteration 1857 : model1 loss : 0.447905 model2 loss : 0.052473
[23:12:18.181] iteration 1858 : model1 loss : 0.460953 model2 loss : 0.056035
[23:12:18.357] iteration 1859 : model1 loss : 0.445220 model2 loss : 0.036514
[23:12:18.529] iteration 1860 : model1 loss : 0.438300 model2 loss : 0.036845
[23:12:18.703] iteration 1861 : model1 loss : 0.440455 model2 loss : 0.041867
[23:12:18.878] iteration 1862 : model1 loss : 0.440659 model2 loss : 0.038288
[23:12:19.052] iteration 1863 : model1 loss : 0.448130 model2 loss : 0.066810
[23:12:19.224] iteration 1864 : model1 loss : 0.441830 model2 loss : 0.050591
[23:12:19.402] iteration 1865 : model1 loss : 0.442235 model2 loss : 0.035363
[23:12:19.576] iteration 1866 : model1 loss : 0.445187 model2 loss : 0.041413
[23:12:19.754] iteration 1867 : model1 loss : 0.444500 model2 loss : 0.055832
[23:12:19.926] iteration 1868 : model1 loss : 0.441683 model2 loss : 0.040929
[23:12:20.097] iteration 1869 : model1 loss : 0.439528 model2 loss : 0.035621
[23:12:22.218] iteration 1870 : model1 loss : 0.448003 model2 loss : 0.045815
[23:12:22.399] iteration 1871 : model1 loss : 0.445996 model2 loss : 0.039703
[23:12:22.576] iteration 1872 : model1 loss : 0.443414 model2 loss : 0.044047
[23:12:22.747] iteration 1873 : model1 loss : 0.441779 model2 loss : 0.038460
[23:12:22.925] iteration 1874 : model1 loss : 0.444776 model2 loss : 0.040138
[23:12:23.095] iteration 1875 : model1 loss : 0.456850 model2 loss : 0.072401
[23:12:23.271] iteration 1876 : model1 loss : 0.443720 model2 loss : 0.038006
[23:12:23.444] iteration 1877 : model1 loss : 0.446052 model2 loss : 0.076910
[23:12:23.625] iteration 1878 : model1 loss : 0.446954 model2 loss : 0.056982
[23:12:23.795] iteration 1879 : model1 loss : 0.442804 model2 loss : 0.041218
[23:12:23.971] iteration 1880 : model1 loss : 0.438956 model2 loss : 0.037559
[23:12:24.141] iteration 1881 : model1 loss : 0.439451 model2 loss : 0.043969
[23:12:24.320] iteration 1882 : model1 loss : 0.441133 model2 loss : 0.051668
[23:12:24.493] iteration 1883 : model1 loss : 0.443506 model2 loss : 0.047510
[23:12:24.666] iteration 1884 : model1 loss : 0.449259 model2 loss : 0.047592
[23:12:24.842] iteration 1885 : model1 loss : 0.441378 model2 loss : 0.042826
[23:12:25.018] iteration 1886 : model1 loss : 0.448741 model2 loss : 0.054657
[23:12:25.189] iteration 1887 : model1 loss : 0.443898 model2 loss : 0.040909
[23:12:25.365] iteration 1888 : model1 loss : 0.445459 model2 loss : 0.049338
[23:12:25.533] iteration 1889 : model1 loss : 0.449941 model2 loss : 0.058596
[23:12:25.705] iteration 1890 : model1 loss : 0.447341 model2 loss : 0.044427
[23:12:27.864] iteration 1891 : model1 loss : 0.446270 model2 loss : 0.054372
[23:12:28.037] iteration 1892 : model1 loss : 0.448212 model2 loss : 0.046552
[23:12:28.215] iteration 1893 : model1 loss : 0.444775 model2 loss : 0.046057
[23:12:28.390] iteration 1894 : model1 loss : 0.444382 model2 loss : 0.048562
[23:12:28.567] iteration 1895 : model1 loss : 0.446718 model2 loss : 0.036384
[23:12:28.738] iteration 1896 : model1 loss : 0.440171 model2 loss : 0.036308
[23:12:28.913] iteration 1897 : model1 loss : 0.440845 model2 loss : 0.040900
[23:12:29.083] iteration 1898 : model1 loss : 0.443637 model2 loss : 0.037784
[23:12:29.259] iteration 1899 : model1 loss : 0.447264 model2 loss : 0.055258
[23:12:29.433] iteration 1900 : model1 loss : 0.444833 model2 loss : 0.042310
[23:12:29.613] iteration 1901 : model1 loss : 0.446059 model2 loss : 0.037186
[23:12:29.786] iteration 1902 : model1 loss : 0.451264 model2 loss : 0.041741
[23:12:29.964] iteration 1903 : model1 loss : 0.445402 model2 loss : 0.050039
[23:12:30.135] iteration 1904 : model1 loss : 0.450055 model2 loss : 0.047123
[23:12:30.313] iteration 1905 : model1 loss : 0.445099 model2 loss : 0.037551
[23:12:30.484] iteration 1906 : model1 loss : 0.445166 model2 loss : 0.041566
[23:12:30.663] iteration 1907 : model1 loss : 0.443894 model2 loss : 0.039016
[23:12:30.835] iteration 1908 : model1 loss : 0.440371 model2 loss : 0.035566
[23:12:31.010] iteration 1909 : model1 loss : 0.437776 model2 loss : 0.040675
[23:12:31.182] iteration 1910 : model1 loss : 0.441392 model2 loss : 0.043318
[23:12:31.362] iteration 1911 : model1 loss : 0.451130 model2 loss : 0.038789
[23:12:33.504] iteration 1912 : model1 loss : 0.452986 model2 loss : 0.065023
[23:12:33.675] iteration 1913 : model1 loss : 0.442057 model2 loss : 0.043229
[23:12:33.854] iteration 1914 : model1 loss : 0.438306 model2 loss : 0.037212
[23:12:34.024] iteration 1915 : model1 loss : 0.442272 model2 loss : 0.037327
[23:12:34.200] iteration 1916 : model1 loss : 0.451629 model2 loss : 0.040933
[23:12:34.373] iteration 1917 : model1 loss : 0.438919 model2 loss : 0.051668
[23:12:34.551] iteration 1918 : model1 loss : 0.447189 model2 loss : 0.041771
[23:12:34.721] iteration 1919 : model1 loss : 0.443415 model2 loss : 0.031991
[23:12:34.894] iteration 1920 : model1 loss : 0.443388 model2 loss : 0.037081
[23:12:35.065] iteration 1921 : model1 loss : 0.440325 model2 loss : 0.037092
[23:12:35.239] iteration 1922 : model1 loss : 0.453041 model2 loss : 0.051705
[23:12:35.411] iteration 1923 : model1 loss : 0.440363 model2 loss : 0.044822
[23:12:35.590] iteration 1924 : model1 loss : 0.448476 model2 loss : 0.048405
[23:12:35.760] iteration 1925 : model1 loss : 0.442458 model2 loss : 0.043839
[23:12:35.934] iteration 1926 : model1 loss : 0.446825 model2 loss : 0.059859
[23:12:36.105] iteration 1927 : model1 loss : 0.446255 model2 loss : 0.041766
[23:12:36.283] iteration 1928 : model1 loss : 0.444059 model2 loss : 0.054233
[23:12:36.458] iteration 1929 : model1 loss : 0.435716 model2 loss : 0.035901
[23:12:36.637] iteration 1930 : model1 loss : 0.443382 model2 loss : 0.058294
[23:12:36.807] iteration 1931 : model1 loss : 0.439363 model2 loss : 0.032112
[23:12:36.980] iteration 1932 : model1 loss : 0.440234 model2 loss : 0.038451
[23:12:39.146] iteration 1933 : model1 loss : 0.443889 model2 loss : 0.039213
[23:12:39.325] iteration 1934 : model1 loss : 0.441902 model2 loss : 0.038428
[23:12:39.502] iteration 1935 : model1 loss : 0.442426 model2 loss : 0.039323
[23:12:39.672] iteration 1936 : model1 loss : 0.449148 model2 loss : 0.075768
[23:12:39.848] iteration 1937 : model1 loss : 0.442784 model2 loss : 0.046282
[23:12:40.018] iteration 1938 : model1 loss : 0.443206 model2 loss : 0.039165
[23:12:40.194] iteration 1939 : model1 loss : 0.444810 model2 loss : 0.050222
[23:12:40.369] iteration 1940 : model1 loss : 0.438661 model2 loss : 0.042233
[23:12:40.546] iteration 1941 : model1 loss : 0.438503 model2 loss : 0.039763
[23:12:40.717] iteration 1942 : model1 loss : 0.442691 model2 loss : 0.043296
[23:12:40.892] iteration 1943 : model1 loss : 0.445452 model2 loss : 0.051998
[23:12:41.063] iteration 1944 : model1 loss : 0.438964 model2 loss : 0.036655
[23:12:41.237] iteration 1945 : model1 loss : 0.443138 model2 loss : 0.042384
[23:12:41.410] iteration 1946 : model1 loss : 0.443058 model2 loss : 0.050533
[23:12:41.590] iteration 1947 : model1 loss : 0.441490 model2 loss : 0.054654
[23:12:41.759] iteration 1948 : model1 loss : 0.447627 model2 loss : 0.048428
[23:12:41.937] iteration 1949 : model1 loss : 0.444486 model2 loss : 0.046318
[23:12:42.108] iteration 1950 : model1 loss : 0.442756 model2 loss : 0.040010
[23:12:42.283] iteration 1951 : model1 loss : 0.445156 model2 loss : 0.043041
[23:12:42.460] iteration 1952 : model1 loss : 0.444319 model2 loss : 0.058254
[23:12:42.636] iteration 1953 : model1 loss : 0.441015 model2 loss : 0.040220
[23:12:44.730] iteration 1954 : model1 loss : 0.442828 model2 loss : 0.037361
[23:12:44.901] iteration 1955 : model1 loss : 0.450376 model2 loss : 0.040726
[23:12:45.082] iteration 1956 : model1 loss : 0.442751 model2 loss : 0.052546
[23:12:45.251] iteration 1957 : model1 loss : 0.440210 model2 loss : 0.040190
[23:12:45.430] iteration 1958 : model1 loss : 0.439874 model2 loss : 0.041633
[23:12:45.604] iteration 1959 : model1 loss : 0.438775 model2 loss : 0.038229
[23:12:45.781] iteration 1960 : model1 loss : 0.447450 model2 loss : 0.057207
[23:12:45.956] iteration 1961 : model1 loss : 0.438640 model2 loss : 0.034057
[23:12:46.132] iteration 1962 : model1 loss : 0.437586 model2 loss : 0.035215
[23:12:46.304] iteration 1963 : model1 loss : 0.447277 model2 loss : 0.049005
[23:12:46.479] iteration 1964 : model1 loss : 0.447623 model2 loss : 0.063573
[23:12:46.652] iteration 1965 : model1 loss : 0.443157 model2 loss : 0.049844
[23:12:46.829] iteration 1966 : model1 loss : 0.446916 model2 loss : 0.038872
[23:12:47.002] iteration 1967 : model1 loss : 0.443580 model2 loss : 0.042068
[23:12:47.177] iteration 1968 : model1 loss : 0.446294 model2 loss : 0.034438
[23:12:47.350] iteration 1969 : model1 loss : 0.445699 model2 loss : 0.038795
[23:12:47.530] iteration 1970 : model1 loss : 0.447139 model2 loss : 0.055987
[23:12:47.702] iteration 1971 : model1 loss : 0.443795 model2 loss : 0.054328
[23:12:47.878] iteration 1972 : model1 loss : 0.446561 model2 loss : 0.033685
[23:12:48.046] iteration 1973 : model1 loss : 0.441559 model2 loss : 0.048175
[23:12:48.217] iteration 1974 : model1 loss : 0.439406 model2 loss : 0.037449
[23:12:50.368] iteration 1975 : model1 loss : 0.441799 model2 loss : 0.042194
[23:12:50.543] iteration 1976 : model1 loss : 0.446400 model2 loss : 0.038132
[23:12:50.720] iteration 1977 : model1 loss : 0.440577 model2 loss : 0.047160
[23:12:50.892] iteration 1978 : model1 loss : 0.441681 model2 loss : 0.039956
[23:12:51.069] iteration 1979 : model1 loss : 0.443890 model2 loss : 0.044854
[23:12:51.240] iteration 1980 : model1 loss : 0.450052 model2 loss : 0.046304
[23:12:51.416] iteration 1981 : model1 loss : 0.436576 model2 loss : 0.034987
[23:12:51.589] iteration 1982 : model1 loss : 0.445970 model2 loss : 0.044461
[23:12:51.761] iteration 1983 : model1 loss : 0.446010 model2 loss : 0.046567
[23:12:51.934] iteration 1984 : model1 loss : 0.441775 model2 loss : 0.040916
[23:12:52.109] iteration 1985 : model1 loss : 0.440004 model2 loss : 0.031188
[23:12:52.280] iteration 1986 : model1 loss : 0.442144 model2 loss : 0.041360
[23:12:52.457] iteration 1987 : model1 loss : 0.438954 model2 loss : 0.034321
[23:12:52.630] iteration 1988 : model1 loss : 0.453319 model2 loss : 0.053422
[23:12:52.806] iteration 1989 : model1 loss : 0.442913 model2 loss : 0.040782
[23:12:52.977] iteration 1990 : model1 loss : 0.439623 model2 loss : 0.048717
[23:12:53.156] iteration 1991 : model1 loss : 0.438932 model2 loss : 0.036732
[23:12:53.328] iteration 1992 : model1 loss : 0.445128 model2 loss : 0.038162
[23:12:53.505] iteration 1993 : model1 loss : 0.440293 model2 loss : 0.034377
[23:12:53.676] iteration 1994 : model1 loss : 0.444968 model2 loss : 0.042949
[23:12:53.851] iteration 1995 : model1 loss : 0.442683 model2 loss : 0.039037
[23:12:56.003] iteration 1996 : model1 loss : 0.438113 model2 loss : 0.036781
[23:12:56.176] iteration 1997 : model1 loss : 0.442901 model2 loss : 0.037495
[23:12:56.358] iteration 1998 : model1 loss : 0.445008 model2 loss : 0.041071
[23:12:56.529] iteration 1999 : model1 loss : 0.445934 model2 loss : 0.040079
[23:12:56.705] iteration 2000 : model1 loss : 0.442283 model2 loss : 0.036227
[23:13:05.752] iteration 2000 : model1_mean_dice : 0.663079 model1_mean_hd95 : 7.678226
[23:13:14.981] iteration 2000 : model2_mean_dice : 0.804854 model2_mean_hd95 : 12.261198
[23:13:15.162] iteration 2001 : model1 loss : 0.437115 model2 loss : 0.033003
[23:13:15.348] iteration 2002 : model1 loss : 0.444608 model2 loss : 0.037815
[23:13:15.521] iteration 2003 : model1 loss : 0.448129 model2 loss : 0.045134
[23:13:15.696] iteration 2004 : model1 loss : 0.438433 model2 loss : 0.035979
[23:13:15.869] iteration 2005 : model1 loss : 0.442151 model2 loss : 0.047961
[23:13:16.042] iteration 2006 : model1 loss : 0.441885 model2 loss : 0.031637
[23:13:16.212] iteration 2007 : model1 loss : 0.443085 model2 loss : 0.032019
[23:13:16.388] iteration 2008 : model1 loss : 0.441835 model2 loss : 0.040664
[23:13:16.560] iteration 2009 : model1 loss : 0.440959 model2 loss : 0.038323
[23:13:16.735] iteration 2010 : model1 loss : 0.446049 model2 loss : 0.055657
[23:13:16.907] iteration 2011 : model1 loss : 0.446017 model2 loss : 0.045695
[23:13:17.083] iteration 2012 : model1 loss : 0.445225 model2 loss : 0.040243
[23:13:17.253] iteration 2013 : model1 loss : 0.438471 model2 loss : 0.040751
[23:13:17.433] iteration 2014 : model1 loss : 0.443197 model2 loss : 0.046736
[23:13:17.603] iteration 2015 : model1 loss : 0.440647 model2 loss : 0.042960
[23:13:17.776] iteration 2016 : model1 loss : 0.438405 model2 loss : 0.033570
[23:13:19.908] iteration 2017 : model1 loss : 0.442590 model2 loss : 0.038278
[23:13:20.081] iteration 2018 : model1 loss : 0.440957 model2 loss : 0.032671
[23:13:20.257] iteration 2019 : model1 loss : 0.450319 model2 loss : 0.049733
[23:13:20.431] iteration 2020 : model1 loss : 0.446652 model2 loss : 0.054844
[23:13:20.608] iteration 2021 : model1 loss : 0.443873 model2 loss : 0.039070
[23:13:20.778] iteration 2022 : model1 loss : 0.440301 model2 loss : 0.041087
[23:13:20.951] iteration 2023 : model1 loss : 0.440821 model2 loss : 0.041024
[23:13:21.121] iteration 2024 : model1 loss : 0.441554 model2 loss : 0.042200
[23:13:21.297] iteration 2025 : model1 loss : 0.438167 model2 loss : 0.034742
[23:13:21.469] iteration 2026 : model1 loss : 0.445226 model2 loss : 0.054559
[23:13:21.646] iteration 2027 : model1 loss : 0.442131 model2 loss : 0.033621
[23:13:21.816] iteration 2028 : model1 loss : 0.440545 model2 loss : 0.038882
[23:13:21.992] iteration 2029 : model1 loss : 0.445407 model2 loss : 0.047745
[23:13:22.160] iteration 2030 : model1 loss : 0.443225 model2 loss : 0.035159
[23:13:22.334] iteration 2031 : model1 loss : 0.444147 model2 loss : 0.035471
[23:13:22.511] iteration 2032 : model1 loss : 0.444503 model2 loss : 0.045906
[23:13:22.689] iteration 2033 : model1 loss : 0.438918 model2 loss : 0.036629
[23:13:22.859] iteration 2034 : model1 loss : 0.446820 model2 loss : 0.038117
[23:13:23.033] iteration 2035 : model1 loss : 0.437801 model2 loss : 0.038223
[23:13:23.201] iteration 2036 : model1 loss : 0.435605 model2 loss : 0.033481
[23:13:23.378] iteration 2037 : model1 loss : 0.445174 model2 loss : 0.041841
[23:13:25.526] iteration 2038 : model1 loss : 0.442592 model2 loss : 0.036363
[23:13:25.700] iteration 2039 : model1 loss : 0.444956 model2 loss : 0.037105
[23:13:25.877] iteration 2040 : model1 loss : 0.443996 model2 loss : 0.038432
[23:13:26.046] iteration 2041 : model1 loss : 0.440840 model2 loss : 0.043854
[23:13:26.221] iteration 2042 : model1 loss : 0.445630 model2 loss : 0.056784
[23:13:26.393] iteration 2043 : model1 loss : 0.436831 model2 loss : 0.029936
[23:13:26.571] iteration 2044 : model1 loss : 0.437549 model2 loss : 0.040493
[23:13:26.740] iteration 2045 : model1 loss : 0.438753 model2 loss : 0.033090
[23:13:26.915] iteration 2046 : model1 loss : 0.447095 model2 loss : 0.039367
[23:13:27.085] iteration 2047 : model1 loss : 0.444106 model2 loss : 0.043813
[23:13:27.260] iteration 2048 : model1 loss : 0.448888 model2 loss : 0.038617
[23:13:27.436] iteration 2049 : model1 loss : 0.442237 model2 loss : 0.040167
[23:13:27.615] iteration 2050 : model1 loss : 0.442358 model2 loss : 0.039532
[23:13:27.785] iteration 2051 : model1 loss : 0.439014 model2 loss : 0.033560
[23:13:27.962] iteration 2052 : model1 loss : 0.446132 model2 loss : 0.036736
[23:13:28.131] iteration 2053 : model1 loss : 0.442785 model2 loss : 0.037681
[23:13:28.307] iteration 2054 : model1 loss : 0.443466 model2 loss : 0.040103
[23:13:28.480] iteration 2055 : model1 loss : 0.441584 model2 loss : 0.036662
[23:13:28.659] iteration 2056 : model1 loss : 0.441606 model2 loss : 0.038062
[23:13:28.828] iteration 2057 : model1 loss : 0.442368 model2 loss : 0.037665
[23:13:29.000] iteration 2058 : model1 loss : 0.438030 model2 loss : 0.040296
[23:13:31.291] iteration 2059 : model1 loss : 0.446810 model2 loss : 0.041438
[23:13:31.466] iteration 2060 : model1 loss : 0.440769 model2 loss : 0.032686
[23:13:31.643] iteration 2061 : model1 loss : 0.443649 model2 loss : 0.043109
[23:13:31.814] iteration 2062 : model1 loss : 0.440899 model2 loss : 0.035918
[23:13:31.991] iteration 2063 : model1 loss : 0.436702 model2 loss : 0.031061
[23:13:32.162] iteration 2064 : model1 loss : 0.442905 model2 loss : 0.035920
[23:13:32.342] iteration 2065 : model1 loss : 0.440350 model2 loss : 0.043882
[23:13:32.519] iteration 2066 : model1 loss : 0.444189 model2 loss : 0.035094
[23:13:32.695] iteration 2067 : model1 loss : 0.436638 model2 loss : 0.036849
[23:13:32.865] iteration 2068 : model1 loss : 0.450881 model2 loss : 0.044794
[23:13:33.042] iteration 2069 : model1 loss : 0.443512 model2 loss : 0.050464
[23:13:33.214] iteration 2070 : model1 loss : 0.441375 model2 loss : 0.032066
[23:13:33.390] iteration 2071 : model1 loss : 0.452047 model2 loss : 0.056897
[23:13:33.566] iteration 2072 : model1 loss : 0.439631 model2 loss : 0.034383
[23:13:33.741] iteration 2073 : model1 loss : 0.446380 model2 loss : 0.045286
[23:13:33.912] iteration 2074 : model1 loss : 0.442337 model2 loss : 0.052590
[23:13:34.089] iteration 2075 : model1 loss : 0.444085 model2 loss : 0.038921
[23:13:34.257] iteration 2076 : model1 loss : 0.441574 model2 loss : 0.044165
[23:13:34.435] iteration 2077 : model1 loss : 0.440084 model2 loss : 0.032374
[23:13:34.607] iteration 2078 : model1 loss : 0.446797 model2 loss : 0.048538
[23:13:34.779] iteration 2079 : model1 loss : 0.442764 model2 loss : 0.035744
[23:13:36.923] iteration 2080 : model1 loss : 0.440159 model2 loss : 0.030497
[23:13:37.093] iteration 2081 : model1 loss : 0.449604 model2 loss : 0.042096
[23:13:37.272] iteration 2082 : model1 loss : 0.449103 model2 loss : 0.051229
[23:13:37.447] iteration 2083 : model1 loss : 0.441041 model2 loss : 0.032561
[23:13:37.626] iteration 2084 : model1 loss : 0.440428 model2 loss : 0.034039
[23:13:37.795] iteration 2085 : model1 loss : 0.438967 model2 loss : 0.035499
[23:13:37.972] iteration 2086 : model1 loss : 0.449181 model2 loss : 0.033872
[23:13:38.143] iteration 2087 : model1 loss : 0.445178 model2 loss : 0.045440
[23:13:38.324] iteration 2088 : model1 loss : 0.444109 model2 loss : 0.043217
[23:13:38.498] iteration 2089 : model1 loss : 0.442111 model2 loss : 0.042013
[23:13:38.672] iteration 2090 : model1 loss : 0.446759 model2 loss : 0.040200
[23:13:38.843] iteration 2091 : model1 loss : 0.446966 model2 loss : 0.038277
[23:13:39.019] iteration 2092 : model1 loss : 0.435747 model2 loss : 0.032720
[23:13:39.189] iteration 2093 : model1 loss : 0.443292 model2 loss : 0.047464
[23:13:39.366] iteration 2094 : model1 loss : 0.447631 model2 loss : 0.041877
[23:13:39.541] iteration 2095 : model1 loss : 0.438637 model2 loss : 0.032077
[23:13:39.716] iteration 2096 : model1 loss : 0.449523 model2 loss : 0.054512
[23:13:39.887] iteration 2097 : model1 loss : 0.440577 model2 loss : 0.039996
[23:13:40.064] iteration 2098 : model1 loss : 0.442585 model2 loss : 0.045523
[23:13:40.233] iteration 2099 : model1 loss : 0.444293 model2 loss : 0.038497
[23:13:40.408] iteration 2100 : model1 loss : 0.442055 model2 loss : 0.032933
[23:13:42.548] iteration 2101 : model1 loss : 0.439495 model2 loss : 0.032420
[23:13:42.716] iteration 2102 : model1 loss : 0.440818 model2 loss : 0.035032
[23:13:42.896] iteration 2103 : model1 loss : 0.438570 model2 loss : 0.036217
[23:13:43.067] iteration 2104 : model1 loss : 0.440225 model2 loss : 0.036906
[23:13:43.244] iteration 2105 : model1 loss : 0.446875 model2 loss : 0.042617
[23:13:43.417] iteration 2106 : model1 loss : 0.442413 model2 loss : 0.033432
[23:13:43.599] iteration 2107 : model1 loss : 0.447908 model2 loss : 0.038909
[23:13:43.769] iteration 2108 : model1 loss : 0.448293 model2 loss : 0.040806
[23:13:43.945] iteration 2109 : model1 loss : 0.444184 model2 loss : 0.046987
[23:13:44.117] iteration 2110 : model1 loss : 0.444198 model2 loss : 0.043060
[23:13:44.297] iteration 2111 : model1 loss : 0.442454 model2 loss : 0.042096
[23:13:44.473] iteration 2112 : model1 loss : 0.450400 model2 loss : 0.048360
[23:13:44.653] iteration 2113 : model1 loss : 0.441343 model2 loss : 0.042350
[23:13:44.821] iteration 2114 : model1 loss : 0.450525 model2 loss : 0.041572
[23:13:44.998] iteration 2115 : model1 loss : 0.440046 model2 loss : 0.033204
[23:13:45.168] iteration 2116 : model1 loss : 0.437705 model2 loss : 0.032459
[23:13:45.343] iteration 2117 : model1 loss : 0.438862 model2 loss : 0.033539
[23:13:45.517] iteration 2118 : model1 loss : 0.443177 model2 loss : 0.034320
[23:13:45.696] iteration 2119 : model1 loss : 0.449499 model2 loss : 0.034881
[23:13:45.864] iteration 2120 : model1 loss : 0.440787 model2 loss : 0.034106
[23:13:46.041] iteration 2121 : model1 loss : 0.459051 model2 loss : 0.038900
[23:13:48.172] iteration 2122 : model1 loss : 0.442560 model2 loss : 0.033622
[23:13:48.351] iteration 2123 : model1 loss : 0.455155 model2 loss : 0.043259
[23:13:48.530] iteration 2124 : model1 loss : 0.443079 model2 loss : 0.035539
[23:13:48.700] iteration 2125 : model1 loss : 0.440272 model2 loss : 0.027054
[23:13:48.876] iteration 2126 : model1 loss : 0.445785 model2 loss : 0.036093
[23:13:49.047] iteration 2127 : model1 loss : 0.445877 model2 loss : 0.038617
[23:13:49.228] iteration 2128 : model1 loss : 0.450244 model2 loss : 0.035321
[23:13:49.403] iteration 2129 : model1 loss : 0.446067 model2 loss : 0.044147
[23:13:49.581] iteration 2130 : model1 loss : 0.440317 model2 loss : 0.040041
[23:13:49.750] iteration 2131 : model1 loss : 0.450502 model2 loss : 0.059059
[23:13:49.924] iteration 2132 : model1 loss : 0.443331 model2 loss : 0.038456
[23:13:50.096] iteration 2133 : model1 loss : 0.440740 model2 loss : 0.028375
[23:13:50.272] iteration 2134 : model1 loss : 0.440134 model2 loss : 0.039696
[23:13:50.445] iteration 2135 : model1 loss : 0.446457 model2 loss : 0.054131
[23:13:50.625] iteration 2136 : model1 loss : 0.443175 model2 loss : 0.035309
[23:13:50.794] iteration 2137 : model1 loss : 0.446879 model2 loss : 0.039536
[23:13:50.972] iteration 2138 : model1 loss : 0.440236 model2 loss : 0.030858
[23:13:51.141] iteration 2139 : model1 loss : 0.437523 model2 loss : 0.034065
[23:13:51.320] iteration 2140 : model1 loss : 0.445846 model2 loss : 0.042169
[23:13:51.493] iteration 2141 : model1 loss : 0.438851 model2 loss : 0.032974
[23:13:51.667] iteration 2142 : model1 loss : 0.446418 model2 loss : 0.040873
[23:13:53.793] iteration 2143 : model1 loss : 0.452643 model2 loss : 0.036425
[23:13:53.975] iteration 2144 : model1 loss : 0.441610 model2 loss : 0.040714
[23:13:54.150] iteration 2145 : model1 loss : 0.442769 model2 loss : 0.047824
[23:13:54.326] iteration 2146 : model1 loss : 0.440372 model2 loss : 0.035804
[23:13:54.505] iteration 2147 : model1 loss : 0.447068 model2 loss : 0.041019
[23:13:54.678] iteration 2148 : model1 loss : 0.446533 model2 loss : 0.056742
[23:13:54.853] iteration 2149 : model1 loss : 0.439540 model2 loss : 0.045916
[23:13:55.026] iteration 2150 : model1 loss : 0.441966 model2 loss : 0.034434
[23:13:55.201] iteration 2151 : model1 loss : 0.442720 model2 loss : 0.042182
[23:13:55.376] iteration 2152 : model1 loss : 0.445372 model2 loss : 0.038207
[23:13:55.554] iteration 2153 : model1 loss : 0.444908 model2 loss : 0.051487
[23:13:55.724] iteration 2154 : model1 loss : 0.441333 model2 loss : 0.035370
[23:13:55.899] iteration 2155 : model1 loss : 0.445279 model2 loss : 0.033382
[23:13:56.073] iteration 2156 : model1 loss : 0.453976 model2 loss : 0.041759
[23:13:56.250] iteration 2157 : model1 loss : 0.442046 model2 loss : 0.038219
[23:13:56.434] iteration 2158 : model1 loss : 0.438969 model2 loss : 0.033600
[23:13:56.612] iteration 2159 : model1 loss : 0.439408 model2 loss : 0.033408
[23:13:56.783] iteration 2160 : model1 loss : 0.441685 model2 loss : 0.036750
[23:13:56.961] iteration 2161 : model1 loss : 0.441330 model2 loss : 0.037306
[23:13:57.132] iteration 2162 : model1 loss : 0.441388 model2 loss : 0.046761
[23:13:57.307] iteration 2163 : model1 loss : 0.443783 model2 loss : 0.043662
[23:13:59.534] iteration 2164 : model1 loss : 0.445817 model2 loss : 0.034131
[23:13:59.712] iteration 2165 : model1 loss : 0.447227 model2 loss : 0.042073
[23:13:59.887] iteration 2166 : model1 loss : 0.440210 model2 loss : 0.040579
[23:14:00.063] iteration 2167 : model1 loss : 0.436476 model2 loss : 0.035782
[23:14:00.239] iteration 2168 : model1 loss : 0.441976 model2 loss : 0.041828
[23:14:00.413] iteration 2169 : model1 loss : 0.445375 model2 loss : 0.035234
[23:14:00.592] iteration 2170 : model1 loss : 0.447722 model2 loss : 0.043277
[23:14:00.765] iteration 2171 : model1 loss : 0.442371 model2 loss : 0.037300
[23:14:00.942] iteration 2172 : model1 loss : 0.442994 model2 loss : 0.040720
[23:14:01.115] iteration 2173 : model1 loss : 0.439771 model2 loss : 0.034559
[23:14:01.293] iteration 2174 : model1 loss : 0.437395 model2 loss : 0.037384
[23:14:01.470] iteration 2175 : model1 loss : 0.438555 model2 loss : 0.036565
[23:14:01.646] iteration 2176 : model1 loss : 0.445717 model2 loss : 0.032145
[23:14:01.816] iteration 2177 : model1 loss : 0.441300 model2 loss : 0.034774
[23:14:01.993] iteration 2178 : model1 loss : 0.442672 model2 loss : 0.033455
[23:14:02.163] iteration 2179 : model1 loss : 0.438875 model2 loss : 0.035813
[23:14:02.340] iteration 2180 : model1 loss : 0.435728 model2 loss : 0.034255
[23:14:02.521] iteration 2181 : model1 loss : 0.443603 model2 loss : 0.036715
[23:14:02.698] iteration 2182 : model1 loss : 0.451718 model2 loss : 0.040704
[23:14:02.865] iteration 2183 : model1 loss : 0.443815 model2 loss : 0.039852
[23:14:03.038] iteration 2184 : model1 loss : 0.441275 model2 loss : 0.036965
[23:14:05.179] iteration 2185 : model1 loss : 0.445870 model2 loss : 0.034457
[23:14:05.354] iteration 2186 : model1 loss : 0.439539 model2 loss : 0.035339
[23:14:05.533] iteration 2187 : model1 loss : 0.440297 model2 loss : 0.033253
[23:14:05.704] iteration 2188 : model1 loss : 0.441720 model2 loss : 0.030937
[23:14:05.879] iteration 2189 : model1 loss : 0.440870 model2 loss : 0.032865
[23:14:06.053] iteration 2190 : model1 loss : 0.439401 model2 loss : 0.033170
[23:14:06.230] iteration 2191 : model1 loss : 0.440751 model2 loss : 0.036769
[23:14:06.403] iteration 2192 : model1 loss : 0.439547 model2 loss : 0.033962
[23:14:06.584] iteration 2193 : model1 loss : 0.441545 model2 loss : 0.035086
[23:14:06.756] iteration 2194 : model1 loss : 0.442743 model2 loss : 0.035746
[23:14:06.932] iteration 2195 : model1 loss : 0.442075 model2 loss : 0.035149
[23:14:07.104] iteration 2196 : model1 loss : 0.454798 model2 loss : 0.048294
[23:14:07.280] iteration 2197 : model1 loss : 0.436740 model2 loss : 0.034368
[23:14:07.458] iteration 2198 : model1 loss : 0.445051 model2 loss : 0.054583
[23:14:07.634] iteration 2199 : model1 loss : 0.438714 model2 loss : 0.041686
[23:14:07.803] iteration 2200 : model1 loss : 0.442220 model2 loss : 0.035215
[23:14:07.981] iteration 2201 : model1 loss : 0.444347 model2 loss : 0.038391
[23:14:08.152] iteration 2202 : model1 loss : 0.438781 model2 loss : 0.033274
[23:14:08.331] iteration 2203 : model1 loss : 0.438771 model2 loss : 0.033364
[23:14:08.504] iteration 2204 : model1 loss : 0.443167 model2 loss : 0.036070
[23:14:08.677] iteration 2205 : model1 loss : 0.450499 model2 loss : 0.047969
[23:14:10.812] iteration 2206 : model1 loss : 0.445929 model2 loss : 0.037891
[23:14:10.987] iteration 2207 : model1 loss : 0.440241 model2 loss : 0.035766
[23:14:11.165] iteration 2208 : model1 loss : 0.447883 model2 loss : 0.037128
[23:14:11.338] iteration 2209 : model1 loss : 0.441990 model2 loss : 0.035446
[23:14:11.517] iteration 2210 : model1 loss : 0.440456 model2 loss : 0.037285
[23:14:11.687] iteration 2211 : model1 loss : 0.441048 model2 loss : 0.036229
[23:14:11.861] iteration 2212 : model1 loss : 0.437671 model2 loss : 0.029071
[23:14:12.035] iteration 2213 : model1 loss : 0.447805 model2 loss : 0.037418
[23:14:12.211] iteration 2214 : model1 loss : 0.442068 model2 loss : 0.034038
[23:14:12.382] iteration 2215 : model1 loss : 0.437039 model2 loss : 0.032458
[23:14:12.562] iteration 2216 : model1 loss : 0.438125 model2 loss : 0.034789
[23:14:12.730] iteration 2217 : model1 loss : 0.442673 model2 loss : 0.037048
[23:14:12.905] iteration 2218 : model1 loss : 0.443766 model2 loss : 0.033622
[23:14:13.079] iteration 2219 : model1 loss : 0.441112 model2 loss : 0.034021
[23:14:13.258] iteration 2220 : model1 loss : 0.442739 model2 loss : 0.034777
[23:14:13.432] iteration 2221 : model1 loss : 0.442017 model2 loss : 0.043625
[23:14:13.614] iteration 2222 : model1 loss : 0.439817 model2 loss : 0.046320
[23:14:13.788] iteration 2223 : model1 loss : 0.445086 model2 loss : 0.041649
[23:14:13.963] iteration 2224 : model1 loss : 0.444833 model2 loss : 0.039182
[23:14:14.132] iteration 2225 : model1 loss : 0.439996 model2 loss : 0.030275
[23:14:14.309] iteration 2226 : model1 loss : 0.443283 model2 loss : 0.035151
[23:14:16.505] iteration 2227 : model1 loss : 0.441923 model2 loss : 0.035280
[23:14:16.680] iteration 2228 : model1 loss : 0.438076 model2 loss : 0.035263
[23:14:16.858] iteration 2229 : model1 loss : 0.444542 model2 loss : 0.039998
[23:14:17.032] iteration 2230 : model1 loss : 0.438754 model2 loss : 0.036861
[23:14:17.209] iteration 2231 : model1 loss : 0.440535 model2 loss : 0.032243
[23:14:17.382] iteration 2232 : model1 loss : 0.444596 model2 loss : 0.034339
[23:14:17.559] iteration 2233 : model1 loss : 0.440261 model2 loss : 0.035096
[23:14:17.730] iteration 2234 : model1 loss : 0.440742 model2 loss : 0.036231
[23:14:17.904] iteration 2235 : model1 loss : 0.444373 model2 loss : 0.036906
[23:14:18.076] iteration 2236 : model1 loss : 0.439894 model2 loss : 0.032741
[23:14:18.253] iteration 2237 : model1 loss : 0.435914 model2 loss : 0.032956
[23:14:18.425] iteration 2238 : model1 loss : 0.447338 model2 loss : 0.050288
[23:14:18.605] iteration 2239 : model1 loss : 0.445652 model2 loss : 0.038296
[23:14:18.776] iteration 2240 : model1 loss : 0.445035 model2 loss : 0.041301
[23:14:18.951] iteration 2241 : model1 loss : 0.441090 model2 loss : 0.039025
[23:14:19.126] iteration 2242 : model1 loss : 0.446607 model2 loss : 0.048459
[23:14:19.303] iteration 2243 : model1 loss : 0.442533 model2 loss : 0.034723
[23:14:19.477] iteration 2244 : model1 loss : 0.445879 model2 loss : 0.039034
[23:14:19.657] iteration 2245 : model1 loss : 0.440872 model2 loss : 0.027743
[23:14:19.827] iteration 2246 : model1 loss : 0.439934 model2 loss : 0.036175
[23:14:20.002] iteration 2247 : model1 loss : 0.440401 model2 loss : 0.039336
[23:14:22.200] iteration 2248 : model1 loss : 0.439207 model2 loss : 0.030826
[23:14:22.373] iteration 2249 : model1 loss : 0.446351 model2 loss : 0.035571
[23:14:22.551] iteration 2250 : model1 loss : 0.441102 model2 loss : 0.036414
[23:14:22.724] iteration 2251 : model1 loss : 0.445725 model2 loss : 0.038703
[23:14:22.899] iteration 2252 : model1 loss : 0.437152 model2 loss : 0.035223
[23:14:23.073] iteration 2253 : model1 loss : 0.440800 model2 loss : 0.034933
[23:14:23.250] iteration 2254 : model1 loss : 0.443360 model2 loss : 0.037000
[23:14:23.426] iteration 2255 : model1 loss : 0.442740 model2 loss : 0.039432
[23:14:23.606] iteration 2256 : model1 loss : 0.445306 model2 loss : 0.051513
[23:14:23.776] iteration 2257 : model1 loss : 0.441009 model2 loss : 0.035928
[23:14:23.953] iteration 2258 : model1 loss : 0.445392 model2 loss : 0.035742
[23:14:24.129] iteration 2259 : model1 loss : 0.440834 model2 loss : 0.034402
[23:14:24.305] iteration 2260 : model1 loss : 0.438797 model2 loss : 0.033663
[23:14:24.481] iteration 2261 : model1 loss : 0.445694 model2 loss : 0.039029
[23:14:24.661] iteration 2262 : model1 loss : 0.437103 model2 loss : 0.039443
[23:14:24.831] iteration 2263 : model1 loss : 0.440832 model2 loss : 0.044655
[23:14:25.005] iteration 2264 : model1 loss : 0.441156 model2 loss : 0.035786
[23:14:25.180] iteration 2265 : model1 loss : 0.443395 model2 loss : 0.038529
[23:14:25.357] iteration 2266 : model1 loss : 0.439982 model2 loss : 0.035968
[23:14:25.541] iteration 2267 : model1 loss : 0.444442 model2 loss : 0.041319
[23:14:25.715] iteration 2268 : model1 loss : 0.441552 model2 loss : 0.037443
[23:14:27.887] iteration 2269 : model1 loss : 0.448600 model2 loss : 0.045715
[23:14:28.063] iteration 2270 : model1 loss : 0.446455 model2 loss : 0.051652
[23:14:28.239] iteration 2271 : model1 loss : 0.439288 model2 loss : 0.032143
[23:14:28.411] iteration 2272 : model1 loss : 0.441649 model2 loss : 0.039095
[23:14:28.589] iteration 2273 : model1 loss : 0.436947 model2 loss : 0.034351
[23:14:28.759] iteration 2274 : model1 loss : 0.437025 model2 loss : 0.037909
[23:14:28.934] iteration 2275 : model1 loss : 0.437612 model2 loss : 0.031289
[23:14:29.107] iteration 2276 : model1 loss : 0.439832 model2 loss : 0.034388
[23:14:29.283] iteration 2277 : model1 loss : 0.444367 model2 loss : 0.036990
[23:14:29.456] iteration 2278 : model1 loss : 0.438917 model2 loss : 0.042214
[23:14:29.632] iteration 2279 : model1 loss : 0.440007 model2 loss : 0.037360
[23:14:29.802] iteration 2280 : model1 loss : 0.437143 model2 loss : 0.025104
[23:14:29.979] iteration 2281 : model1 loss : 0.436424 model2 loss : 0.033591
[23:14:30.152] iteration 2282 : model1 loss : 0.436392 model2 loss : 0.030747
[23:14:30.337] iteration 2283 : model1 loss : 0.447011 model2 loss : 0.042648
[23:14:30.511] iteration 2284 : model1 loss : 0.444514 model2 loss : 0.029833
[23:14:30.687] iteration 2285 : model1 loss : 0.440439 model2 loss : 0.029371
[23:14:30.856] iteration 2286 : model1 loss : 0.441150 model2 loss : 0.036136
[23:14:31.032] iteration 2287 : model1 loss : 0.442349 model2 loss : 0.034496
[23:14:31.202] iteration 2288 : model1 loss : 0.445104 model2 loss : 0.040950
[23:14:31.378] iteration 2289 : model1 loss : 0.451119 model2 loss : 0.045297
[23:14:33.532] iteration 2290 : model1 loss : 0.441743 model2 loss : 0.032293
[23:14:33.704] iteration 2291 : model1 loss : 0.447445 model2 loss : 0.041437
[23:14:33.880] iteration 2292 : model1 loss : 0.440344 model2 loss : 0.031836
[23:14:34.053] iteration 2293 : model1 loss : 0.442151 model2 loss : 0.034912
[23:14:34.230] iteration 2294 : model1 loss : 0.441108 model2 loss : 0.028442
[23:14:34.404] iteration 2295 : model1 loss : 0.444177 model2 loss : 0.040720
[23:14:34.581] iteration 2296 : model1 loss : 0.440078 model2 loss : 0.034748
[23:14:34.752] iteration 2297 : model1 loss : 0.445669 model2 loss : 0.043338
[23:14:34.927] iteration 2298 : model1 loss : 0.443303 model2 loss : 0.031892
[23:14:35.099] iteration 2299 : model1 loss : 0.449901 model2 loss : 0.036391
[23:14:35.274] iteration 2300 : model1 loss : 0.442408 model2 loss : 0.034793
[23:14:35.446] iteration 2301 : model1 loss : 0.444809 model2 loss : 0.033434
[23:14:35.628] iteration 2302 : model1 loss : 0.438572 model2 loss : 0.039247
[23:14:35.800] iteration 2303 : model1 loss : 0.446754 model2 loss : 0.038750
[23:14:35.974] iteration 2304 : model1 loss : 0.438117 model2 loss : 0.033062
[23:14:36.146] iteration 2305 : model1 loss : 0.443480 model2 loss : 0.033959
[23:14:36.329] iteration 2306 : model1 loss : 0.445545 model2 loss : 0.038043
[23:14:36.503] iteration 2307 : model1 loss : 0.434504 model2 loss : 0.029582
[23:14:36.677] iteration 2308 : model1 loss : 0.440544 model2 loss : 0.035120
[23:14:36.846] iteration 2309 : model1 loss : 0.440563 model2 loss : 0.030963
[23:14:37.023] iteration 2310 : model1 loss : 0.445104 model2 loss : 0.035706
[23:14:39.154] iteration 2311 : model1 loss : 0.438934 model2 loss : 0.033522
[23:14:39.326] iteration 2312 : model1 loss : 0.441510 model2 loss : 0.032312
[23:14:39.508] iteration 2313 : model1 loss : 0.442246 model2 loss : 0.036108
[23:14:39.679] iteration 2314 : model1 loss : 0.439431 model2 loss : 0.036001
[23:14:39.852] iteration 2315 : model1 loss : 0.441975 model2 loss : 0.038476
[23:14:40.025] iteration 2316 : model1 loss : 0.443262 model2 loss : 0.040170
[23:14:40.201] iteration 2317 : model1 loss : 0.437102 model2 loss : 0.031863
[23:14:40.373] iteration 2318 : model1 loss : 0.441534 model2 loss : 0.035999
[23:14:40.553] iteration 2319 : model1 loss : 0.442113 model2 loss : 0.035599
[23:14:40.725] iteration 2320 : model1 loss : 0.442876 model2 loss : 0.039284
[23:14:40.901] iteration 2321 : model1 loss : 0.439661 model2 loss : 0.032183
[23:14:41.075] iteration 2322 : model1 loss : 0.443445 model2 loss : 0.039006
[23:14:41.250] iteration 2323 : model1 loss : 0.441447 model2 loss : 0.037932
[23:14:41.425] iteration 2324 : model1 loss : 0.442690 model2 loss : 0.035186
[23:14:41.603] iteration 2325 : model1 loss : 0.442224 model2 loss : 0.037004
[23:14:41.773] iteration 2326 : model1 loss : 0.442054 model2 loss : 0.031855
[23:14:41.950] iteration 2327 : model1 loss : 0.442936 model2 loss : 0.036070
[23:14:42.125] iteration 2328 : model1 loss : 0.440366 model2 loss : 0.037683
[23:14:42.302] iteration 2329 : model1 loss : 0.444209 model2 loss : 0.036967
[23:14:42.478] iteration 2330 : model1 loss : 0.438795 model2 loss : 0.037274
[23:14:42.658] iteration 2331 : model1 loss : 0.441203 model2 loss : 0.034661
[23:14:44.802] iteration 2332 : model1 loss : 0.434951 model2 loss : 0.028823
[23:14:44.979] iteration 2333 : model1 loss : 0.442929 model2 loss : 0.034507
[23:14:45.158] iteration 2334 : model1 loss : 0.434851 model2 loss : 0.028344
[23:14:45.334] iteration 2335 : model1 loss : 0.438178 model2 loss : 0.036056
[23:14:45.512] iteration 2336 : model1 loss : 0.437821 model2 loss : 0.029850
[23:14:45.684] iteration 2337 : model1 loss : 0.438620 model2 loss : 0.032957
[23:14:45.859] iteration 2338 : model1 loss : 0.435117 model2 loss : 0.029678
[23:14:46.031] iteration 2339 : model1 loss : 0.441039 model2 loss : 0.039679
[23:14:46.207] iteration 2340 : model1 loss : 0.439636 model2 loss : 0.036978
[23:14:46.380] iteration 2341 : model1 loss : 0.441474 model2 loss : 0.037157
[23:14:46.560] iteration 2342 : model1 loss : 0.441903 model2 loss : 0.031507
[23:14:46.731] iteration 2343 : model1 loss : 0.441604 model2 loss : 0.040021
[23:14:46.905] iteration 2344 : model1 loss : 0.444296 model2 loss : 0.036650
[23:14:47.077] iteration 2345 : model1 loss : 0.443520 model2 loss : 0.036235
[23:14:47.255] iteration 2346 : model1 loss : 0.446527 model2 loss : 0.058773
[23:14:47.430] iteration 2347 : model1 loss : 0.439463 model2 loss : 0.034302
[23:14:47.611] iteration 2348 : model1 loss : 0.450699 model2 loss : 0.057719
[23:14:47.783] iteration 2349 : model1 loss : 0.439457 model2 loss : 0.033826
[23:14:47.957] iteration 2350 : model1 loss : 0.441030 model2 loss : 0.034540
[23:14:48.130] iteration 2351 : model1 loss : 0.441663 model2 loss : 0.038645
[23:14:48.305] iteration 2352 : model1 loss : 0.443128 model2 loss : 0.040304
[23:14:50.440] iteration 2353 : model1 loss : 0.436909 model2 loss : 0.030533
[23:14:50.618] iteration 2354 : model1 loss : 0.439410 model2 loss : 0.034081
[23:14:50.795] iteration 2355 : model1 loss : 0.446790 model2 loss : 0.039606
[23:14:50.966] iteration 2356 : model1 loss : 0.440870 model2 loss : 0.033476
[23:14:51.140] iteration 2357 : model1 loss : 0.448562 model2 loss : 0.068794
[23:14:51.314] iteration 2358 : model1 loss : 0.445527 model2 loss : 0.042870
[23:14:51.492] iteration 2359 : model1 loss : 0.443252 model2 loss : 0.040400
[23:14:51.668] iteration 2360 : model1 loss : 0.447888 model2 loss : 0.040137
[23:14:51.844] iteration 2361 : model1 loss : 0.437926 model2 loss : 0.034602
[23:14:52.015] iteration 2362 : model1 loss : 0.441570 model2 loss : 0.034943
[23:14:52.193] iteration 2363 : model1 loss : 0.433361 model2 loss : 0.030705
[23:14:52.365] iteration 2364 : model1 loss : 0.443945 model2 loss : 0.034125
[23:14:52.545] iteration 2365 : model1 loss : 0.439807 model2 loss : 0.034445
[23:14:52.716] iteration 2366 : model1 loss : 0.442388 model2 loss : 0.044773
[23:14:52.889] iteration 2367 : model1 loss : 0.436660 model2 loss : 0.030158
[23:14:53.060] iteration 2368 : model1 loss : 0.443359 model2 loss : 0.042969
[23:14:53.237] iteration 2369 : model1 loss : 0.441617 model2 loss : 0.046869
[23:14:53.411] iteration 2370 : model1 loss : 0.437747 model2 loss : 0.031217
[23:14:53.591] iteration 2371 : model1 loss : 0.439119 model2 loss : 0.035736
[23:14:53.761] iteration 2372 : model1 loss : 0.439709 model2 loss : 0.037873
[23:14:53.934] iteration 2373 : model1 loss : 0.441500 model2 loss : 0.044340
[23:14:56.073] iteration 2374 : model1 loss : 0.443572 model2 loss : 0.042823
[23:14:56.246] iteration 2375 : model1 loss : 0.440175 model2 loss : 0.039130
[23:14:56.426] iteration 2376 : model1 loss : 0.439407 model2 loss : 0.031761
[23:14:56.606] iteration 2377 : model1 loss : 0.436953 model2 loss : 0.029134
[23:14:56.781] iteration 2378 : model1 loss : 0.449778 model2 loss : 0.034432
[23:14:56.949] iteration 2379 : model1 loss : 0.436354 model2 loss : 0.033978
[23:14:57.129] iteration 2380 : model1 loss : 0.437253 model2 loss : 0.032981
[23:14:57.302] iteration 2381 : model1 loss : 0.437936 model2 loss : 0.033347
[23:14:57.484] iteration 2382 : model1 loss : 0.440683 model2 loss : 0.034266
[23:14:57.660] iteration 2383 : model1 loss : 0.449075 model2 loss : 0.036100
[23:14:57.836] iteration 2384 : model1 loss : 0.442379 model2 loss : 0.037067
[23:14:58.006] iteration 2385 : model1 loss : 0.440535 model2 loss : 0.037501
[23:14:58.183] iteration 2386 : model1 loss : 0.437252 model2 loss : 0.033510
[23:14:58.356] iteration 2387 : model1 loss : 0.439738 model2 loss : 0.036750
[23:14:58.534] iteration 2388 : model1 loss : 0.444670 model2 loss : 0.043098
[23:14:58.704] iteration 2389 : model1 loss : 0.437737 model2 loss : 0.031295
[23:14:58.878] iteration 2390 : model1 loss : 0.440117 model2 loss : 0.039021
[23:14:59.051] iteration 2391 : model1 loss : 0.440767 model2 loss : 0.033677
[23:14:59.229] iteration 2392 : model1 loss : 0.441679 model2 loss : 0.040140
[23:14:59.400] iteration 2393 : model1 loss : 0.440300 model2 loss : 0.035438
[23:14:59.581] iteration 2394 : model1 loss : 0.446520 model2 loss : 0.039315
[23:15:01.728] iteration 2395 : model1 loss : 0.446691 model2 loss : 0.038507
[23:15:01.899] iteration 2396 : model1 loss : 0.444061 model2 loss : 0.035286
[23:15:02.079] iteration 2397 : model1 loss : 0.445358 model2 loss : 0.042298
[23:15:02.251] iteration 2398 : model1 loss : 0.445398 model2 loss : 0.030874
[23:15:02.432] iteration 2399 : model1 loss : 0.443973 model2 loss : 0.036653
[23:15:02.613] iteration 2400 : model1 loss : 0.437397 model2 loss : 0.033875
[23:15:02.787] iteration 2401 : model1 loss : 0.443977 model2 loss : 0.032560
[23:15:02.960] iteration 2402 : model1 loss : 0.438158 model2 loss : 0.032465
[23:15:03.137] iteration 2403 : model1 loss : 0.437648 model2 loss : 0.031068
[23:15:03.311] iteration 2404 : model1 loss : 0.438465 model2 loss : 0.033017
[23:15:03.489] iteration 2405 : model1 loss : 0.437114 model2 loss : 0.037648
[23:15:03.663] iteration 2406 : model1 loss : 0.441379 model2 loss : 0.030070
[23:15:03.838] iteration 2407 : model1 loss : 0.439788 model2 loss : 0.036462
[23:15:04.009] iteration 2408 : model1 loss : 0.443933 model2 loss : 0.033666
[23:15:04.186] iteration 2409 : model1 loss : 0.439791 model2 loss : 0.030244
[23:15:04.357] iteration 2410 : model1 loss : 0.441559 model2 loss : 0.036339
[23:15:04.533] iteration 2411 : model1 loss : 0.449954 model2 loss : 0.047248
[23:15:04.705] iteration 2412 : model1 loss : 0.437773 model2 loss : 0.032683
[23:15:04.879] iteration 2413 : model1 loss : 0.441003 model2 loss : 0.040030
[23:15:05.052] iteration 2414 : model1 loss : 0.437467 model2 loss : 0.030054
[23:15:05.229] iteration 2415 : model1 loss : 0.442014 model2 loss : 0.036633
[23:15:07.361] iteration 2416 : model1 loss : 0.440155 model2 loss : 0.033326
[23:15:07.539] iteration 2417 : model1 loss : 0.443497 model2 loss : 0.037469
[23:15:07.717] iteration 2418 : model1 loss : 0.437630 model2 loss : 0.033538
[23:15:07.887] iteration 2419 : model1 loss : 0.445805 model2 loss : 0.034926
[23:15:08.065] iteration 2420 : model1 loss : 0.437750 model2 loss : 0.036901
[23:15:08.238] iteration 2421 : model1 loss : 0.441667 model2 loss : 0.032153
[23:15:08.420] iteration 2422 : model1 loss : 0.451139 model2 loss : 0.032930
[23:15:08.596] iteration 2423 : model1 loss : 0.438677 model2 loss : 0.033195
[23:15:08.770] iteration 2424 : model1 loss : 0.433856 model2 loss : 0.031668
[23:15:08.939] iteration 2425 : model1 loss : 0.441578 model2 loss : 0.030541
[23:15:09.114] iteration 2426 : model1 loss : 0.446212 model2 loss : 0.046527
[23:15:09.285] iteration 2427 : model1 loss : 0.440889 model2 loss : 0.033158
[23:15:09.464] iteration 2428 : model1 loss : 0.437543 model2 loss : 0.032045
[23:15:09.641] iteration 2429 : model1 loss : 0.440620 model2 loss : 0.029088
[23:15:09.818] iteration 2430 : model1 loss : 0.447198 model2 loss : 0.048593
[23:15:09.990] iteration 2431 : model1 loss : 0.443163 model2 loss : 0.034045
[23:15:10.165] iteration 2432 : model1 loss : 0.447198 model2 loss : 0.044830
[23:15:10.341] iteration 2433 : model1 loss : 0.439131 model2 loss : 0.035673
[23:15:10.517] iteration 2434 : model1 loss : 0.444782 model2 loss : 0.036421
[23:15:10.690] iteration 2435 : model1 loss : 0.440433 model2 loss : 0.034269
[23:15:10.864] iteration 2436 : model1 loss : 0.441899 model2 loss : 0.035303
[23:15:13.057] iteration 2437 : model1 loss : 0.440333 model2 loss : 0.039161
[23:15:13.235] iteration 2438 : model1 loss : 0.439871 model2 loss : 0.030456
[23:15:13.415] iteration 2439 : model1 loss : 0.442921 model2 loss : 0.038769
[23:15:13.590] iteration 2440 : model1 loss : 0.439524 model2 loss : 0.038924
[23:15:13.766] iteration 2441 : model1 loss : 0.442238 model2 loss : 0.042252
[23:15:13.937] iteration 2442 : model1 loss : 0.443151 model2 loss : 0.034021
[23:15:14.116] iteration 2443 : model1 loss : 0.439942 model2 loss : 0.032395
[23:15:14.289] iteration 2444 : model1 loss : 0.441190 model2 loss : 0.032112
[23:15:14.468] iteration 2445 : model1 loss : 0.441236 model2 loss : 0.027392
[23:15:14.640] iteration 2446 : model1 loss : 0.438429 model2 loss : 0.033919
[23:15:14.816] iteration 2447 : model1 loss : 0.438538 model2 loss : 0.032456
[23:15:14.988] iteration 2448 : model1 loss : 0.438593 model2 loss : 0.036441
[23:15:15.163] iteration 2449 : model1 loss : 0.442884 model2 loss : 0.036835
[23:15:15.339] iteration 2450 : model1 loss : 0.442054 model2 loss : 0.040611
[23:15:15.519] iteration 2451 : model1 loss : 0.442474 model2 loss : 0.033263
[23:15:15.692] iteration 2452 : model1 loss : 0.445489 model2 loss : 0.039538
[23:15:15.870] iteration 2453 : model1 loss : 0.438606 model2 loss : 0.035378
[23:15:16.040] iteration 2454 : model1 loss : 0.442093 model2 loss : 0.038887
[23:15:16.215] iteration 2455 : model1 loss : 0.450209 model2 loss : 0.035034
[23:15:16.385] iteration 2456 : model1 loss : 0.444700 model2 loss : 0.036521
[23:15:16.564] iteration 2457 : model1 loss : 0.447508 model2 loss : 0.037560
[23:15:18.751] iteration 2458 : model1 loss : 0.442931 model2 loss : 0.031543
[23:15:18.925] iteration 2459 : model1 loss : 0.439565 model2 loss : 0.033369
[23:15:19.104] iteration 2460 : model1 loss : 0.438564 model2 loss : 0.027881
[23:15:19.277] iteration 2461 : model1 loss : 0.441054 model2 loss : 0.032164
[23:15:19.457] iteration 2462 : model1 loss : 0.434809 model2 loss : 0.030530
[23:15:19.629] iteration 2463 : model1 loss : 0.441487 model2 loss : 0.036930
[23:15:19.806] iteration 2464 : model1 loss : 0.438390 model2 loss : 0.028674
[23:15:19.979] iteration 2465 : model1 loss : 0.447282 model2 loss : 0.038587
[23:15:20.159] iteration 2466 : model1 loss : 0.437919 model2 loss : 0.029947
[23:15:20.333] iteration 2467 : model1 loss : 0.442964 model2 loss : 0.035230
[23:15:20.508] iteration 2468 : model1 loss : 0.445882 model2 loss : 0.046380
[23:15:20.681] iteration 2469 : model1 loss : 0.437897 model2 loss : 0.032471
[23:15:20.859] iteration 2470 : model1 loss : 0.439275 model2 loss : 0.029702
[23:15:21.029] iteration 2471 : model1 loss : 0.436455 model2 loss : 0.031607
[23:15:21.204] iteration 2472 : model1 loss : 0.445272 model2 loss : 0.037647
[23:15:21.376] iteration 2473 : model1 loss : 0.446233 model2 loss : 0.035289
[23:15:21.553] iteration 2474 : model1 loss : 0.440478 model2 loss : 0.037350
[23:15:21.728] iteration 2475 : model1 loss : 0.440122 model2 loss : 0.035203
[23:15:21.903] iteration 2476 : model1 loss : 0.435502 model2 loss : 0.029232
[23:15:22.072] iteration 2477 : model1 loss : 0.443255 model2 loss : 0.032594
[23:15:22.247] iteration 2478 : model1 loss : 0.445338 model2 loss : 0.037830
[23:15:24.387] iteration 2479 : model1 loss : 0.439517 model2 loss : 0.037243
[23:15:24.562] iteration 2480 : model1 loss : 0.437768 model2 loss : 0.029644
[23:15:24.738] iteration 2481 : model1 loss : 0.439530 model2 loss : 0.033775
[23:15:24.909] iteration 2482 : model1 loss : 0.437627 model2 loss : 0.031281
[23:15:25.085] iteration 2483 : model1 loss : 0.442290 model2 loss : 0.030462
[23:15:25.258] iteration 2484 : model1 loss : 0.441873 model2 loss : 0.043603
[23:15:25.437] iteration 2485 : model1 loss : 0.440939 model2 loss : 0.034247
[23:15:25.613] iteration 2486 : model1 loss : 0.441196 model2 loss : 0.034655
[23:15:25.791] iteration 2487 : model1 loss : 0.442851 model2 loss : 0.035870
[23:15:25.962] iteration 2488 : model1 loss : 0.437163 model2 loss : 0.031828
[23:15:26.142] iteration 2489 : model1 loss : 0.438467 model2 loss : 0.034300
[23:15:26.327] iteration 2490 : model1 loss : 0.443087 model2 loss : 0.030464
[23:15:26.507] iteration 2491 : model1 loss : 0.443362 model2 loss : 0.028744
[23:15:26.680] iteration 2492 : model1 loss : 0.437712 model2 loss : 0.033150
[23:15:26.860] iteration 2493 : model1 loss : 0.449307 model2 loss : 0.059569
[23:15:27.029] iteration 2494 : model1 loss : 0.436727 model2 loss : 0.030756
[23:15:27.204] iteration 2495 : model1 loss : 0.446052 model2 loss : 0.036014
[23:15:27.378] iteration 2496 : model1 loss : 0.437138 model2 loss : 0.032030
[23:15:27.556] iteration 2497 : model1 loss : 0.438007 model2 loss : 0.029062
[23:15:27.731] iteration 2498 : model1 loss : 0.442170 model2 loss : 0.031771
[23:15:27.903] iteration 2499 : model1 loss : 0.441443 model2 loss : 0.041445
[23:15:30.041] iteration 2500 : model1 loss : 0.438377 model2 loss : 0.030182
[23:15:30.213] iteration 2501 : model1 loss : 0.441643 model2 loss : 0.036212
[23:15:30.391] iteration 2502 : model1 loss : 0.438519 model2 loss : 0.038188
[23:15:30.567] iteration 2503 : model1 loss : 0.445247 model2 loss : 0.046240
[23:15:30.744] iteration 2504 : model1 loss : 0.445273 model2 loss : 0.040188
[23:15:30.914] iteration 2505 : model1 loss : 0.442927 model2 loss : 0.031138
[23:15:31.093] iteration 2506 : model1 loss : 0.438760 model2 loss : 0.036208
[23:15:31.267] iteration 2507 : model1 loss : 0.442263 model2 loss : 0.037256
[23:15:31.442] iteration 2508 : model1 loss : 0.447628 model2 loss : 0.047282
[23:15:31.618] iteration 2509 : model1 loss : 0.433704 model2 loss : 0.029013
[23:15:31.794] iteration 2510 : model1 loss : 0.448972 model2 loss : 0.063107
[23:15:31.964] iteration 2511 : model1 loss : 0.435948 model2 loss : 0.034018
[23:15:32.141] iteration 2512 : model1 loss : 0.441785 model2 loss : 0.032421
[23:15:32.315] iteration 2513 : model1 loss : 0.441018 model2 loss : 0.035092
[23:15:32.496] iteration 2514 : model1 loss : 0.440125 model2 loss : 0.037097
[23:15:32.676] iteration 2515 : model1 loss : 0.442474 model2 loss : 0.047271
[23:15:32.850] iteration 2516 : model1 loss : 0.440172 model2 loss : 0.039783
[23:15:33.021] iteration 2517 : model1 loss : 0.443398 model2 loss : 0.038491
[23:15:33.200] iteration 2518 : model1 loss : 0.436471 model2 loss : 0.032005
[23:15:33.371] iteration 2519 : model1 loss : 0.439944 model2 loss : 0.029176
[23:15:33.545] iteration 2520 : model1 loss : 0.442495 model2 loss : 0.038021
[23:15:35.711] iteration 2521 : model1 loss : 0.445302 model2 loss : 0.037763
[23:15:35.888] iteration 2522 : model1 loss : 0.442673 model2 loss : 0.034078
[23:15:36.065] iteration 2523 : model1 loss : 0.443569 model2 loss : 0.039297
[23:15:36.241] iteration 2524 : model1 loss : 0.444706 model2 loss : 0.035781
[23:15:36.418] iteration 2525 : model1 loss : 0.443282 model2 loss : 0.033838
[23:15:36.593] iteration 2526 : model1 loss : 0.439334 model2 loss : 0.035162
[23:15:36.771] iteration 2527 : model1 loss : 0.444636 model2 loss : 0.046040
[23:15:36.941] iteration 2528 : model1 loss : 0.440021 model2 loss : 0.040355
[23:15:37.119] iteration 2529 : model1 loss : 0.442359 model2 loss : 0.032660
[23:15:37.295] iteration 2530 : model1 loss : 0.436926 model2 loss : 0.031736
[23:15:37.474] iteration 2531 : model1 loss : 0.442260 model2 loss : 0.041313
[23:15:37.645] iteration 2532 : model1 loss : 0.440296 model2 loss : 0.038636
[23:15:37.822] iteration 2533 : model1 loss : 0.442550 model2 loss : 0.045499
[23:15:37.994] iteration 2534 : model1 loss : 0.443638 model2 loss : 0.041591
[23:15:38.173] iteration 2535 : model1 loss : 0.441506 model2 loss : 0.035532
[23:15:38.347] iteration 2536 : model1 loss : 0.443996 model2 loss : 0.041582
[23:15:38.525] iteration 2537 : model1 loss : 0.439067 model2 loss : 0.032809
[23:15:38.699] iteration 2538 : model1 loss : 0.441405 model2 loss : 0.037310
[23:15:38.872] iteration 2539 : model1 loss : 0.443901 model2 loss : 0.037710
[23:15:39.041] iteration 2540 : model1 loss : 0.440702 model2 loss : 0.040108
[23:15:39.216] iteration 2541 : model1 loss : 0.436231 model2 loss : 0.035800
[23:15:41.439] iteration 2542 : model1 loss : 0.442149 model2 loss : 0.035480
[23:15:41.619] iteration 2543 : model1 loss : 0.442366 model2 loss : 0.033398
[23:15:41.797] iteration 2544 : model1 loss : 0.437263 model2 loss : 0.034230
[23:15:41.968] iteration 2545 : model1 loss : 0.443625 model2 loss : 0.038007
[23:15:42.148] iteration 2546 : model1 loss : 0.441735 model2 loss : 0.034034
[23:15:42.324] iteration 2547 : model1 loss : 0.438065 model2 loss : 0.033401
[23:15:42.503] iteration 2548 : model1 loss : 0.438127 model2 loss : 0.041941
[23:15:42.676] iteration 2549 : model1 loss : 0.440786 model2 loss : 0.029838
[23:15:42.852] iteration 2550 : model1 loss : 0.447947 model2 loss : 0.039613
[23:15:43.024] iteration 2551 : model1 loss : 0.443763 model2 loss : 0.044960
[23:15:43.201] iteration 2552 : model1 loss : 0.436439 model2 loss : 0.028779
[23:15:43.373] iteration 2553 : model1 loss : 0.439078 model2 loss : 0.034218
[23:15:43.553] iteration 2554 : model1 loss : 0.450691 model2 loss : 0.053262
[23:15:43.728] iteration 2555 : model1 loss : 0.440271 model2 loss : 0.036793
[23:15:43.901] iteration 2556 : model1 loss : 0.438751 model2 loss : 0.036044
[23:15:44.073] iteration 2557 : model1 loss : 0.440447 model2 loss : 0.030122
[23:15:44.251] iteration 2558 : model1 loss : 0.442571 model2 loss : 0.037744
[23:15:44.423] iteration 2559 : model1 loss : 0.435721 model2 loss : 0.030909
[23:15:44.601] iteration 2560 : model1 loss : 0.441471 model2 loss : 0.039396
[23:15:44.771] iteration 2561 : model1 loss : 0.441960 model2 loss : 0.033147
[23:15:44.945] iteration 2562 : model1 loss : 0.438013 model2 loss : 0.032941
[23:15:47.090] iteration 2563 : model1 loss : 0.439870 model2 loss : 0.033574
[23:15:47.273] iteration 2564 : model1 loss : 0.438561 model2 loss : 0.038081
[23:15:47.456] iteration 2565 : model1 loss : 0.442064 model2 loss : 0.041256
[23:15:47.628] iteration 2566 : model1 loss : 0.438292 model2 loss : 0.033281
[23:15:47.807] iteration 2567 : model1 loss : 0.448748 model2 loss : 0.056286
[23:15:47.977] iteration 2568 : model1 loss : 0.434937 model2 loss : 0.030309
[23:15:48.155] iteration 2569 : model1 loss : 0.442397 model2 loss : 0.031387
[23:15:48.339] iteration 2570 : model1 loss : 0.444166 model2 loss : 0.039678
[23:15:48.517] iteration 2571 : model1 loss : 0.437467 model2 loss : 0.032787
[23:15:48.690] iteration 2572 : model1 loss : 0.438516 model2 loss : 0.038356
[23:15:48.867] iteration 2573 : model1 loss : 0.446363 model2 loss : 0.041585
[23:15:49.038] iteration 2574 : model1 loss : 0.440749 model2 loss : 0.036384
[23:15:49.216] iteration 2575 : model1 loss : 0.441251 model2 loss : 0.036979
[23:15:49.389] iteration 2576 : model1 loss : 0.437073 model2 loss : 0.031076
[23:15:49.570] iteration 2577 : model1 loss : 0.440951 model2 loss : 0.028996
[23:15:49.744] iteration 2578 : model1 loss : 0.442273 model2 loss : 0.035992
[23:15:49.924] iteration 2579 : model1 loss : 0.443525 model2 loss : 0.037319
[23:15:50.097] iteration 2580 : model1 loss : 0.435422 model2 loss : 0.032188
[23:15:50.276] iteration 2581 : model1 loss : 0.427824 model2 loss : 0.028972
[23:15:50.446] iteration 2582 : model1 loss : 0.442645 model2 loss : 0.034953
[23:15:50.622] iteration 2583 : model1 loss : 0.444300 model2 loss : 0.035998
[23:15:52.777] iteration 2584 : model1 loss : 0.441148 model2 loss : 0.030463
[23:15:52.948] iteration 2585 : model1 loss : 0.440108 model2 loss : 0.034744
[23:15:53.126] iteration 2586 : model1 loss : 0.443437 model2 loss : 0.036399
[23:15:53.305] iteration 2587 : model1 loss : 0.441381 model2 loss : 0.037403
[23:15:53.482] iteration 2588 : model1 loss : 0.438285 model2 loss : 0.034876
[23:15:53.655] iteration 2589 : model1 loss : 0.442497 model2 loss : 0.033143
[23:15:53.830] iteration 2590 : model1 loss : 0.447010 model2 loss : 0.046451
[23:15:54.002] iteration 2591 : model1 loss : 0.439685 model2 loss : 0.036409
[23:15:54.181] iteration 2592 : model1 loss : 0.438774 model2 loss : 0.033746
[23:15:54.357] iteration 2593 : model1 loss : 0.443889 model2 loss : 0.031775
[23:15:54.533] iteration 2594 : model1 loss : 0.442722 model2 loss : 0.046805
[23:15:54.707] iteration 2595 : model1 loss : 0.437033 model2 loss : 0.033153
[23:15:54.882] iteration 2596 : model1 loss : 0.439489 model2 loss : 0.031419
[23:15:55.052] iteration 2597 : model1 loss : 0.446411 model2 loss : 0.044172
[23:15:55.231] iteration 2598 : model1 loss : 0.436706 model2 loss : 0.031445
[23:15:55.405] iteration 2599 : model1 loss : 0.442130 model2 loss : 0.035754
[23:15:55.582] iteration 2600 : model1 loss : 0.441398 model2 loss : 0.034581
[23:15:55.756] iteration 2601 : model1 loss : 0.437309 model2 loss : 0.035896
[23:15:55.931] iteration 2602 : model1 loss : 0.441905 model2 loss : 0.029852
[23:15:56.101] iteration 2603 : model1 loss : 0.442444 model2 loss : 0.039448
[23:15:56.277] iteration 2604 : model1 loss : 0.438402 model2 loss : 0.039780
[23:15:58.476] iteration 2605 : model1 loss : 0.443438 model2 loss : 0.046374
[23:15:58.649] iteration 2606 : model1 loss : 0.445510 model2 loss : 0.033685
[23:15:58.830] iteration 2607 : model1 loss : 0.440578 model2 loss : 0.042025
[23:15:59.002] iteration 2608 : model1 loss : 0.444154 model2 loss : 0.032735
[23:15:59.183] iteration 2609 : model1 loss : 0.436995 model2 loss : 0.034300
[23:15:59.358] iteration 2610 : model1 loss : 0.437533 model2 loss : 0.032256
[23:15:59.536] iteration 2611 : model1 loss : 0.441315 model2 loss : 0.039609
[23:15:59.710] iteration 2612 : model1 loss : 0.439064 model2 loss : 0.032462
[23:15:59.887] iteration 2613 : model1 loss : 0.444573 model2 loss : 0.035209
[23:16:00.060] iteration 2614 : model1 loss : 0.442769 model2 loss : 0.032107
[23:16:00.239] iteration 2615 : model1 loss : 0.438005 model2 loss : 0.036544
[23:16:00.413] iteration 2616 : model1 loss : 0.438753 model2 loss : 0.033991
[23:16:00.594] iteration 2617 : model1 loss : 0.437077 model2 loss : 0.028990
[23:16:00.766] iteration 2618 : model1 loss : 0.450094 model2 loss : 0.059230
[23:16:00.941] iteration 2619 : model1 loss : 0.432978 model2 loss : 0.027599
[23:16:01.113] iteration 2620 : model1 loss : 0.434274 model2 loss : 0.037243
[23:16:01.291] iteration 2621 : model1 loss : 0.438286 model2 loss : 0.033322
[23:16:01.462] iteration 2622 : model1 loss : 0.439397 model2 loss : 0.031846
[23:16:01.636] iteration 2623 : model1 loss : 0.441021 model2 loss : 0.040245
[23:16:01.808] iteration 2624 : model1 loss : 0.440666 model2 loss : 0.038999
[23:16:01.982] iteration 2625 : model1 loss : 0.441338 model2 loss : 0.037365
[23:16:04.164] iteration 2626 : model1 loss : 0.438076 model2 loss : 0.033792
[23:16:04.348] iteration 2627 : model1 loss : 0.446318 model2 loss : 0.044459
[23:16:04.526] iteration 2628 : model1 loss : 0.439384 model2 loss : 0.035285
[23:16:04.699] iteration 2629 : model1 loss : 0.441285 model2 loss : 0.042012
[23:16:04.871] iteration 2630 : model1 loss : 0.441358 model2 loss : 0.032891
[23:16:05.040] iteration 2631 : model1 loss : 0.437070 model2 loss : 0.036494
[23:16:05.218] iteration 2632 : model1 loss : 0.437523 model2 loss : 0.031236
[23:16:05.392] iteration 2633 : model1 loss : 0.440165 model2 loss : 0.030329
[23:16:05.575] iteration 2634 : model1 loss : 0.438045 model2 loss : 0.030810
[23:16:05.746] iteration 2635 : model1 loss : 0.440404 model2 loss : 0.031159
[23:16:05.924] iteration 2636 : model1 loss : 0.436150 model2 loss : 0.027198
[23:16:06.096] iteration 2637 : model1 loss : 0.437836 model2 loss : 0.034434
[23:16:06.275] iteration 2638 : model1 loss : 0.440422 model2 loss : 0.034306
[23:16:06.446] iteration 2639 : model1 loss : 0.446090 model2 loss : 0.031908
[23:16:06.626] iteration 2640 : model1 loss : 0.443293 model2 loss : 0.038436
[23:16:06.802] iteration 2641 : model1 loss : 0.439349 model2 loss : 0.031132
[23:16:06.978] iteration 2642 : model1 loss : 0.440959 model2 loss : 0.038071
[23:16:07.150] iteration 2643 : model1 loss : 0.434942 model2 loss : 0.030148
[23:16:07.335] iteration 2644 : model1 loss : 0.441947 model2 loss : 0.031315
[23:16:07.509] iteration 2645 : model1 loss : 0.440686 model2 loss : 0.034976
[23:16:07.684] iteration 2646 : model1 loss : 0.439055 model2 loss : 0.032961
[23:16:09.842] iteration 2647 : model1 loss : 0.437485 model2 loss : 0.035498
[23:16:10.014] iteration 2648 : model1 loss : 0.439941 model2 loss : 0.028525
[23:16:10.196] iteration 2649 : model1 loss : 0.442773 model2 loss : 0.030675
[23:16:10.370] iteration 2650 : model1 loss : 0.440800 model2 loss : 0.033141
[23:16:10.546] iteration 2651 : model1 loss : 0.444499 model2 loss : 0.037580
[23:16:10.722] iteration 2652 : model1 loss : 0.442925 model2 loss : 0.032801
[23:16:10.899] iteration 2653 : model1 loss : 0.437205 model2 loss : 0.034242
[23:16:11.070] iteration 2654 : model1 loss : 0.437214 model2 loss : 0.030602
[23:16:11.248] iteration 2655 : model1 loss : 0.439923 model2 loss : 0.029265
[23:16:11.421] iteration 2656 : model1 loss : 0.444113 model2 loss : 0.034773
[23:16:11.601] iteration 2657 : model1 loss : 0.442691 model2 loss : 0.031924
[23:16:11.782] iteration 2658 : model1 loss : 0.439534 model2 loss : 0.032636
[23:16:11.958] iteration 2659 : model1 loss : 0.445563 model2 loss : 0.033494
[23:16:12.132] iteration 2660 : model1 loss : 0.440216 model2 loss : 0.033185
[23:16:12.314] iteration 2661 : model1 loss : 0.442676 model2 loss : 0.043294
[23:16:12.491] iteration 2662 : model1 loss : 0.438372 model2 loss : 0.032186
[23:16:12.668] iteration 2663 : model1 loss : 0.441969 model2 loss : 0.032942
[23:16:12.841] iteration 2664 : model1 loss : 0.438401 model2 loss : 0.030836
[23:16:13.017] iteration 2665 : model1 loss : 0.443761 model2 loss : 0.039602
[23:16:13.187] iteration 2666 : model1 loss : 0.440185 model2 loss : 0.035098
[23:16:13.365] iteration 2667 : model1 loss : 0.439232 model2 loss : 0.039948
[23:16:15.524] iteration 2668 : model1 loss : 0.440889 model2 loss : 0.031547
[23:16:15.698] iteration 2669 : model1 loss : 0.444101 model2 loss : 0.035437
[23:16:15.876] iteration 2670 : model1 loss : 0.439233 model2 loss : 0.035333
[23:16:16.046] iteration 2671 : model1 loss : 0.442374 model2 loss : 0.033289
[23:16:16.226] iteration 2672 : model1 loss : 0.439916 model2 loss : 0.029225
[23:16:16.400] iteration 2673 : model1 loss : 0.441581 model2 loss : 0.032922
[23:16:16.577] iteration 2674 : model1 loss : 0.445510 model2 loss : 0.038566
[23:16:16.750] iteration 2675 : model1 loss : 0.441163 model2 loss : 0.033122
[23:16:16.927] iteration 2676 : model1 loss : 0.445985 model2 loss : 0.045741
[23:16:17.099] iteration 2677 : model1 loss : 0.444829 model2 loss : 0.033172
[23:16:17.281] iteration 2678 : model1 loss : 0.436931 model2 loss : 0.028501
[23:16:17.457] iteration 2679 : model1 loss : 0.437006 model2 loss : 0.031315
[23:16:17.635] iteration 2680 : model1 loss : 0.440324 model2 loss : 0.028199
[23:16:17.808] iteration 2681 : model1 loss : 0.442183 model2 loss : 0.034618
[23:16:17.984] iteration 2682 : model1 loss : 0.437320 model2 loss : 0.031788
[23:16:18.156] iteration 2683 : model1 loss : 0.443358 model2 loss : 0.040205
[23:16:18.338] iteration 2684 : model1 loss : 0.439632 model2 loss : 0.033735
[23:16:18.509] iteration 2685 : model1 loss : 0.443615 model2 loss : 0.032775
[23:16:18.684] iteration 2686 : model1 loss : 0.441143 model2 loss : 0.032155
[23:16:18.856] iteration 2687 : model1 loss : 0.454215 model2 loss : 0.035247
[23:16:19.030] iteration 2688 : model1 loss : 0.434621 model2 loss : 0.029139
[23:16:21.200] iteration 2689 : model1 loss : 0.439998 model2 loss : 0.034492
[23:16:21.375] iteration 2690 : model1 loss : 0.443875 model2 loss : 0.035401
[23:16:21.554] iteration 2691 : model1 loss : 0.440977 model2 loss : 0.033440
[23:16:21.728] iteration 2692 : model1 loss : 0.435517 model2 loss : 0.026139
[23:16:21.905] iteration 2693 : model1 loss : 0.438118 model2 loss : 0.028363
[23:16:22.077] iteration 2694 : model1 loss : 0.438225 model2 loss : 0.033716
[23:16:22.255] iteration 2695 : model1 loss : 0.444441 model2 loss : 0.038204
[23:16:22.430] iteration 2696 : model1 loss : 0.444302 model2 loss : 0.032639
[23:16:22.610] iteration 2697 : model1 loss : 0.442650 model2 loss : 0.033507
[23:16:22.784] iteration 2698 : model1 loss : 0.436279 model2 loss : 0.030522
[23:16:22.962] iteration 2699 : model1 loss : 0.439707 model2 loss : 0.035014
[23:16:23.134] iteration 2700 : model1 loss : 0.441339 model2 loss : 0.033353
[23:16:23.315] iteration 2701 : model1 loss : 0.439914 model2 loss : 0.032826
[23:16:23.487] iteration 2702 : model1 loss : 0.435802 model2 loss : 0.033242
[23:16:23.667] iteration 2703 : model1 loss : 0.446851 model2 loss : 0.036555
[23:16:23.841] iteration 2704 : model1 loss : 0.442263 model2 loss : 0.034664
[23:16:24.017] iteration 2705 : model1 loss : 0.446340 model2 loss : 0.036910
[23:16:24.191] iteration 2706 : model1 loss : 0.439472 model2 loss : 0.031027
[23:16:24.373] iteration 2707 : model1 loss : 0.439927 model2 loss : 0.032174
[23:16:24.543] iteration 2708 : model1 loss : 0.439149 model2 loss : 0.034189
[23:16:24.716] iteration 2709 : model1 loss : 0.443427 model2 loss : 0.035232
[23:16:26.840] iteration 2710 : model1 loss : 0.442024 model2 loss : 0.032867
[23:16:27.009] iteration 2711 : model1 loss : 0.439524 model2 loss : 0.034002
[23:16:27.188] iteration 2712 : model1 loss : 0.436750 model2 loss : 0.026035
[23:16:27.362] iteration 2713 : model1 loss : 0.442550 model2 loss : 0.043976
[23:16:27.540] iteration 2714 : model1 loss : 0.450897 model2 loss : 0.043423
[23:16:27.710] iteration 2715 : model1 loss : 0.441691 model2 loss : 0.033661
[23:16:27.886] iteration 2716 : model1 loss : 0.441150 model2 loss : 0.035440
[23:16:28.058] iteration 2717 : model1 loss : 0.440062 model2 loss : 0.028810
[23:16:28.236] iteration 2718 : model1 loss : 0.435292 model2 loss : 0.030779
[23:16:28.411] iteration 2719 : model1 loss : 0.445753 model2 loss : 0.038380
[23:16:28.589] iteration 2720 : model1 loss : 0.440090 model2 loss : 0.029071
[23:16:28.761] iteration 2721 : model1 loss : 0.440995 model2 loss : 0.037680
[23:16:28.935] iteration 2722 : model1 loss : 0.446649 model2 loss : 0.043447
[23:16:29.106] iteration 2723 : model1 loss : 0.437870 model2 loss : 0.031075
[23:16:29.286] iteration 2724 : model1 loss : 0.443435 model2 loss : 0.035370
[23:16:29.459] iteration 2725 : model1 loss : 0.444762 model2 loss : 0.035648
[23:16:29.635] iteration 2726 : model1 loss : 0.438353 model2 loss : 0.030648
[23:16:29.808] iteration 2727 : model1 loss : 0.443457 model2 loss : 0.033943
[23:16:29.984] iteration 2728 : model1 loss : 0.442677 model2 loss : 0.047821
[23:16:30.155] iteration 2729 : model1 loss : 0.443278 model2 loss : 0.034701
[23:16:30.336] iteration 2730 : model1 loss : 0.438944 model2 loss : 0.033475
[23:16:32.468] iteration 2731 : model1 loss : 0.440575 model2 loss : 0.033285
[23:16:32.640] iteration 2732 : model1 loss : 0.442840 model2 loss : 0.039822
[23:16:32.818] iteration 2733 : model1 loss : 0.437998 model2 loss : 0.033504
[23:16:32.989] iteration 2734 : model1 loss : 0.440874 model2 loss : 0.031416
[23:16:33.165] iteration 2735 : model1 loss : 0.443931 model2 loss : 0.039962
[23:16:33.341] iteration 2736 : model1 loss : 0.443081 model2 loss : 0.033341
[23:16:33.520] iteration 2737 : model1 loss : 0.444227 model2 loss : 0.035518
[23:16:33.690] iteration 2738 : model1 loss : 0.439736 model2 loss : 0.027733
[23:16:33.865] iteration 2739 : model1 loss : 0.438343 model2 loss : 0.038434
[23:16:34.033] iteration 2740 : model1 loss : 0.439949 model2 loss : 0.037066
[23:16:34.210] iteration 2741 : model1 loss : 0.444177 model2 loss : 0.035904
[23:16:34.383] iteration 2742 : model1 loss : 0.439323 model2 loss : 0.033804
[23:16:34.564] iteration 2743 : model1 loss : 0.438265 model2 loss : 0.031126
[23:16:34.734] iteration 2744 : model1 loss : 0.446723 model2 loss : 0.040273
[23:16:34.917] iteration 2745 : model1 loss : 0.435098 model2 loss : 0.027873
[23:16:35.087] iteration 2746 : model1 loss : 0.442777 model2 loss : 0.031924
[23:16:35.264] iteration 2747 : model1 loss : 0.449575 model2 loss : 0.047007
[23:16:35.438] iteration 2748 : model1 loss : 0.440102 model2 loss : 0.033324
[23:16:35.617] iteration 2749 : model1 loss : 0.440334 model2 loss : 0.035298
[23:16:35.787] iteration 2750 : model1 loss : 0.442317 model2 loss : 0.027961
[23:16:35.961] iteration 2751 : model1 loss : 0.442559 model2 loss : 0.034166
[23:16:38.139] iteration 2752 : model1 loss : 0.444871 model2 loss : 0.046020
[23:16:38.323] iteration 2753 : model1 loss : 0.440547 model2 loss : 0.034553
[23:16:38.498] iteration 2754 : model1 loss : 0.443517 model2 loss : 0.031137
[23:16:38.670] iteration 2755 : model1 loss : 0.438554 model2 loss : 0.032377
[23:16:38.848] iteration 2756 : model1 loss : 0.439440 model2 loss : 0.035218
[23:16:39.018] iteration 2757 : model1 loss : 0.443098 model2 loss : 0.040449
[23:16:39.196] iteration 2758 : model1 loss : 0.438749 model2 loss : 0.030415
[23:16:39.369] iteration 2759 : model1 loss : 0.443614 model2 loss : 0.030665
[23:16:39.546] iteration 2760 : model1 loss : 0.443366 model2 loss : 0.038525
[23:16:39.716] iteration 2761 : model1 loss : 0.439690 model2 loss : 0.028511
[23:16:39.894] iteration 2762 : model1 loss : 0.435637 model2 loss : 0.031769
[23:16:40.066] iteration 2763 : model1 loss : 0.439205 model2 loss : 0.031035
[23:16:40.244] iteration 2764 : model1 loss : 0.435258 model2 loss : 0.030647
[23:16:40.418] iteration 2765 : model1 loss : 0.444588 model2 loss : 0.040809
[23:16:40.599] iteration 2766 : model1 loss : 0.432720 model2 loss : 0.028779
[23:16:40.772] iteration 2767 : model1 loss : 0.442323 model2 loss : 0.042705
[23:16:40.947] iteration 2768 : model1 loss : 0.438541 model2 loss : 0.034967
[23:16:41.120] iteration 2769 : model1 loss : 0.446900 model2 loss : 0.044565
[23:16:41.300] iteration 2770 : model1 loss : 0.441419 model2 loss : 0.035153
[23:16:41.474] iteration 2771 : model1 loss : 0.440571 model2 loss : 0.034652
[23:16:41.648] iteration 2772 : model1 loss : 0.437974 model2 loss : 0.037286
[23:16:43.823] iteration 2773 : model1 loss : 0.437274 model2 loss : 0.029954
[23:16:43.996] iteration 2774 : model1 loss : 0.443230 model2 loss : 0.042464
[23:16:44.175] iteration 2775 : model1 loss : 0.439597 model2 loss : 0.029915
[23:16:44.354] iteration 2776 : model1 loss : 0.438054 model2 loss : 0.039991
[23:16:44.533] iteration 2777 : model1 loss : 0.443488 model2 loss : 0.041990
[23:16:44.704] iteration 2778 : model1 loss : 0.443272 model2 loss : 0.038481
[23:16:44.878] iteration 2779 : model1 loss : 0.437572 model2 loss : 0.037174
[23:16:45.048] iteration 2780 : model1 loss : 0.439489 model2 loss : 0.034228
[23:16:45.224] iteration 2781 : model1 loss : 0.441237 model2 loss : 0.030978
[23:16:45.401] iteration 2782 : model1 loss : 0.436539 model2 loss : 0.026965
[23:16:45.582] iteration 2783 : model1 loss : 0.435016 model2 loss : 0.032121
[23:16:45.752] iteration 2784 : model1 loss : 0.440512 model2 loss : 0.041169
[23:16:45.929] iteration 2785 : model1 loss : 0.440283 model2 loss : 0.042833
[23:16:46.101] iteration 2786 : model1 loss : 0.434653 model2 loss : 0.032375
[23:16:46.278] iteration 2787 : model1 loss : 0.440946 model2 loss : 0.037590
[23:16:46.451] iteration 2788 : model1 loss : 0.441391 model2 loss : 0.034655
[23:16:46.631] iteration 2789 : model1 loss : 0.447699 model2 loss : 0.034650
[23:16:46.805] iteration 2790 : model1 loss : 0.441672 model2 loss : 0.032158
[23:16:46.981] iteration 2791 : model1 loss : 0.443270 model2 loss : 0.035126
[23:16:47.151] iteration 2792 : model1 loss : 0.440076 model2 loss : 0.038594
[23:16:47.332] iteration 2793 : model1 loss : 0.444560 model2 loss : 0.044857
[23:16:49.512] iteration 2794 : model1 loss : 0.441945 model2 loss : 0.043978
[23:16:49.688] iteration 2795 : model1 loss : 0.440584 model2 loss : 0.033994
[23:16:49.867] iteration 2796 : model1 loss : 0.438516 model2 loss : 0.034975
[23:16:50.040] iteration 2797 : model1 loss : 0.439460 model2 loss : 0.030119
[23:16:50.216] iteration 2798 : model1 loss : 0.447802 model2 loss : 0.040500
[23:16:50.392] iteration 2799 : model1 loss : 0.444318 model2 loss : 0.036338
[23:16:50.570] iteration 2800 : model1 loss : 0.441655 model2 loss : 0.032360
[23:16:50.742] iteration 2801 : model1 loss : 0.441656 model2 loss : 0.035025
[23:16:50.919] iteration 2802 : model1 loss : 0.443392 model2 loss : 0.030262
[23:16:51.091] iteration 2803 : model1 loss : 0.441096 model2 loss : 0.033986
[23:16:51.267] iteration 2804 : model1 loss : 0.440314 model2 loss : 0.030979
[23:16:51.442] iteration 2805 : model1 loss : 0.438202 model2 loss : 0.028274
[23:16:51.618] iteration 2806 : model1 loss : 0.438554 model2 loss : 0.034634
[23:16:51.791] iteration 2807 : model1 loss : 0.438076 model2 loss : 0.031662
[23:16:51.968] iteration 2808 : model1 loss : 0.441197 model2 loss : 0.034104
[23:16:52.137] iteration 2809 : model1 loss : 0.442615 model2 loss : 0.031661
[23:16:52.318] iteration 2810 : model1 loss : 0.441276 model2 loss : 0.033403
[23:16:52.496] iteration 2811 : model1 loss : 0.438949 model2 loss : 0.034320
[23:16:52.673] iteration 2812 : model1 loss : 0.432542 model2 loss : 0.026842
[23:16:52.844] iteration 2813 : model1 loss : 0.443568 model2 loss : 0.037971
[23:16:53.019] iteration 2814 : model1 loss : 0.440016 model2 loss : 0.036763
[23:16:55.183] iteration 2815 : model1 loss : 0.435415 model2 loss : 0.033251
[23:16:55.358] iteration 2816 : model1 loss : 0.440876 model2 loss : 0.033851
[23:16:55.539] iteration 2817 : model1 loss : 0.437211 model2 loss : 0.029175
[23:16:55.710] iteration 2818 : model1 loss : 0.437904 model2 loss : 0.028954
[23:16:55.887] iteration 2819 : model1 loss : 0.437116 model2 loss : 0.033844
[23:16:56.061] iteration 2820 : model1 loss : 0.436006 model2 loss : 0.030435
[23:16:56.238] iteration 2821 : model1 loss : 0.445073 model2 loss : 0.042242
[23:16:56.415] iteration 2822 : model1 loss : 0.441507 model2 loss : 0.029181
[23:16:56.595] iteration 2823 : model1 loss : 0.442307 model2 loss : 0.033880
[23:16:56.765] iteration 2824 : model1 loss : 0.439721 model2 loss : 0.032540
[23:16:56.941] iteration 2825 : model1 loss : 0.444677 model2 loss : 0.031526
[23:16:57.111] iteration 2826 : model1 loss : 0.438049 model2 loss : 0.026654
[23:16:57.292] iteration 2827 : model1 loss : 0.444318 model2 loss : 0.042194
[23:16:57.471] iteration 2828 : model1 loss : 0.444443 model2 loss : 0.037357
[23:16:57.647] iteration 2829 : model1 loss : 0.438037 model2 loss : 0.031427
[23:16:57.819] iteration 2830 : model1 loss : 0.438120 model2 loss : 0.031900
[23:16:57.996] iteration 2831 : model1 loss : 0.435544 model2 loss : 0.027898
[23:16:58.170] iteration 2832 : model1 loss : 0.441574 model2 loss : 0.034370
[23:16:58.351] iteration 2833 : model1 loss : 0.440359 model2 loss : 0.031467
[23:16:58.522] iteration 2834 : model1 loss : 0.443933 model2 loss : 0.038745
[23:16:58.696] iteration 2835 : model1 loss : 0.442032 model2 loss : 0.040602
[23:17:00.850] iteration 2836 : model1 loss : 0.444337 model2 loss : 0.033600
[23:17:01.024] iteration 2837 : model1 loss : 0.437897 model2 loss : 0.037759
[23:17:01.205] iteration 2838 : model1 loss : 0.436371 model2 loss : 0.029694
[23:17:01.380] iteration 2839 : model1 loss : 0.438777 model2 loss : 0.031420
[23:17:01.560] iteration 2840 : model1 loss : 0.443130 model2 loss : 0.037846
[23:17:01.730] iteration 2841 : model1 loss : 0.440858 model2 loss : 0.030583
[23:17:01.906] iteration 2842 : model1 loss : 0.436909 model2 loss : 0.038353
[23:17:02.078] iteration 2843 : model1 loss : 0.442500 model2 loss : 0.038986
[23:17:02.258] iteration 2844 : model1 loss : 0.439507 model2 loss : 0.036700
[23:17:02.437] iteration 2845 : model1 loss : 0.444761 model2 loss : 0.037271
[23:17:02.616] iteration 2846 : model1 loss : 0.434679 model2 loss : 0.030131
[23:17:02.785] iteration 2847 : model1 loss : 0.438820 model2 loss : 0.032244
[23:17:02.963] iteration 2848 : model1 loss : 0.445555 model2 loss : 0.032863
[23:17:03.134] iteration 2849 : model1 loss : 0.443982 model2 loss : 0.037727
[23:17:03.313] iteration 2850 : model1 loss : 0.440528 model2 loss : 0.030607
[23:17:03.486] iteration 2851 : model1 loss : 0.433751 model2 loss : 0.030803
[23:17:03.669] iteration 2852 : model1 loss : 0.443090 model2 loss : 0.031465
[23:17:03.842] iteration 2853 : model1 loss : 0.440972 model2 loss : 0.042443
[23:17:04.019] iteration 2854 : model1 loss : 0.443264 model2 loss : 0.029736
[23:17:04.191] iteration 2855 : model1 loss : 0.445180 model2 loss : 0.036924
[23:17:04.369] iteration 2856 : model1 loss : 0.444059 model2 loss : 0.044688
[23:17:06.537] iteration 2857 : model1 loss : 0.438157 model2 loss : 0.030218
[23:17:06.716] iteration 2858 : model1 loss : 0.442043 model2 loss : 0.030815
[23:17:06.894] iteration 2859 : model1 loss : 0.440920 model2 loss : 0.030937
[23:17:07.066] iteration 2860 : model1 loss : 0.443531 model2 loss : 0.041407
[23:17:07.243] iteration 2861 : model1 loss : 0.442576 model2 loss : 0.034477
[23:17:07.420] iteration 2862 : model1 loss : 0.438644 model2 loss : 0.033210
[23:17:07.601] iteration 2863 : model1 loss : 0.438010 model2 loss : 0.032258
[23:17:07.769] iteration 2864 : model1 loss : 0.445961 model2 loss : 0.034529
[23:17:07.948] iteration 2865 : model1 loss : 0.436059 model2 loss : 0.027183
[23:17:08.123] iteration 2866 : model1 loss : 0.436889 model2 loss : 0.032904
[23:17:08.304] iteration 2867 : model1 loss : 0.444163 model2 loss : 0.033125
[23:17:08.477] iteration 2868 : model1 loss : 0.443248 model2 loss : 0.034308
[23:17:08.654] iteration 2869 : model1 loss : 0.434674 model2 loss : 0.029675
[23:17:08.826] iteration 2870 : model1 loss : 0.441556 model2 loss : 0.035013
[23:17:09.004] iteration 2871 : model1 loss : 0.442136 model2 loss : 0.040786
[23:17:09.177] iteration 2872 : model1 loss : 0.443625 model2 loss : 0.038968
[23:17:09.355] iteration 2873 : model1 loss : 0.438310 model2 loss : 0.029640
[23:17:09.529] iteration 2874 : model1 loss : 0.444204 model2 loss : 0.033123
[23:17:09.704] iteration 2875 : model1 loss : 0.441821 model2 loss : 0.032543
[23:17:09.875] iteration 2876 : model1 loss : 0.441837 model2 loss : 0.039633
[23:17:10.049] iteration 2877 : model1 loss : 0.443282 model2 loss : 0.040899
[23:17:12.185] iteration 2878 : model1 loss : 0.438993 model2 loss : 0.034582
[23:17:12.366] iteration 2879 : model1 loss : 0.437006 model2 loss : 0.033297
[23:17:12.546] iteration 2880 : model1 loss : 0.435864 model2 loss : 0.032626
[23:17:12.715] iteration 2881 : model1 loss : 0.436475 model2 loss : 0.035518
[23:17:12.895] iteration 2882 : model1 loss : 0.438493 model2 loss : 0.030690
[23:17:13.067] iteration 2883 : model1 loss : 0.443201 model2 loss : 0.037464
[23:17:13.245] iteration 2884 : model1 loss : 0.442397 model2 loss : 0.031971
[23:17:13.420] iteration 2885 : model1 loss : 0.438926 model2 loss : 0.030715
[23:17:13.600] iteration 2886 : model1 loss : 0.435468 model2 loss : 0.030747
[23:17:13.769] iteration 2887 : model1 loss : 0.441672 model2 loss : 0.034405
[23:17:13.948] iteration 2888 : model1 loss : 0.433013 model2 loss : 0.029513
[23:17:14.122] iteration 2889 : model1 loss : 0.443256 model2 loss : 0.038303
[23:17:14.302] iteration 2890 : model1 loss : 0.440339 model2 loss : 0.036169
[23:17:14.478] iteration 2891 : model1 loss : 0.441260 model2 loss : 0.032427
[23:17:14.657] iteration 2892 : model1 loss : 0.443488 model2 loss : 0.032222
[23:17:14.829] iteration 2893 : model1 loss : 0.452433 model2 loss : 0.040684
[23:17:15.004] iteration 2894 : model1 loss : 0.438175 model2 loss : 0.030739
[23:17:15.174] iteration 2895 : model1 loss : 0.443671 model2 loss : 0.041651
[23:17:15.356] iteration 2896 : model1 loss : 0.441095 model2 loss : 0.032056
[23:17:15.528] iteration 2897 : model1 loss : 0.435391 model2 loss : 0.028262
[23:17:15.702] iteration 2898 : model1 loss : 0.441172 model2 loss : 0.031793
[23:17:17.862] iteration 2899 : model1 loss : 0.437811 model2 loss : 0.029858
[23:17:18.034] iteration 2900 : model1 loss : 0.439741 model2 loss : 0.031557
[23:17:18.213] iteration 2901 : model1 loss : 0.439778 model2 loss : 0.033762
[23:17:18.387] iteration 2902 : model1 loss : 0.445365 model2 loss : 0.029810
[23:17:18.567] iteration 2903 : model1 loss : 0.437134 model2 loss : 0.030523
[23:17:18.736] iteration 2904 : model1 loss : 0.438882 model2 loss : 0.034233
[23:17:18.912] iteration 2905 : model1 loss : 0.434615 model2 loss : 0.027852
[23:17:19.084] iteration 2906 : model1 loss : 0.439375 model2 loss : 0.034429
[23:17:19.263] iteration 2907 : model1 loss : 0.436302 model2 loss : 0.031810
[23:17:19.440] iteration 2908 : model1 loss : 0.440949 model2 loss : 0.038719
[23:17:19.615] iteration 2909 : model1 loss : 0.443931 model2 loss : 0.035306
[23:17:19.786] iteration 2910 : model1 loss : 0.437738 model2 loss : 0.027421
[23:17:19.965] iteration 2911 : model1 loss : 0.444651 model2 loss : 0.037580
[23:17:20.137] iteration 2912 : model1 loss : 0.439531 model2 loss : 0.035829
[23:17:20.315] iteration 2913 : model1 loss : 0.443395 model2 loss : 0.031459
[23:17:20.491] iteration 2914 : model1 loss : 0.446183 model2 loss : 0.032215
[23:17:20.671] iteration 2915 : model1 loss : 0.434941 model2 loss : 0.032094
[23:17:20.844] iteration 2916 : model1 loss : 0.442615 model2 loss : 0.037537
[23:17:21.020] iteration 2917 : model1 loss : 0.439821 model2 loss : 0.029426
[23:17:21.191] iteration 2918 : model1 loss : 0.436084 model2 loss : 0.032452
[23:17:21.367] iteration 2919 : model1 loss : 0.442595 model2 loss : 0.043805
[23:17:23.545] iteration 2920 : model1 loss : 0.438130 model2 loss : 0.031366
[23:17:23.722] iteration 2921 : model1 loss : 0.438996 model2 loss : 0.032515
[23:17:23.904] iteration 2922 : model1 loss : 0.438263 model2 loss : 0.032476
[23:17:24.074] iteration 2923 : model1 loss : 0.438097 model2 loss : 0.031113
[23:17:24.252] iteration 2924 : model1 loss : 0.441918 model2 loss : 0.032711
[23:17:24.429] iteration 2925 : model1 loss : 0.442954 model2 loss : 0.040845
[23:17:24.608] iteration 2926 : model1 loss : 0.437341 model2 loss : 0.028101
[23:17:24.777] iteration 2927 : model1 loss : 0.441168 model2 loss : 0.034936
[23:17:24.953] iteration 2928 : model1 loss : 0.441625 model2 loss : 0.035833
[23:17:25.126] iteration 2929 : model1 loss : 0.435689 model2 loss : 0.029538
[23:17:25.307] iteration 2930 : model1 loss : 0.437397 model2 loss : 0.033593
[23:17:25.483] iteration 2931 : model1 loss : 0.439436 model2 loss : 0.028235
[23:17:25.664] iteration 2932 : model1 loss : 0.440713 model2 loss : 0.035189
[23:17:25.834] iteration 2933 : model1 loss : 0.448648 model2 loss : 0.039662
[23:17:26.012] iteration 2934 : model1 loss : 0.434732 model2 loss : 0.025277
[23:17:26.186] iteration 2935 : model1 loss : 0.441160 model2 loss : 0.030859
[23:17:26.367] iteration 2936 : model1 loss : 0.440597 model2 loss : 0.040510
[23:17:26.539] iteration 2937 : model1 loss : 0.438420 model2 loss : 0.032168
[23:17:26.715] iteration 2938 : model1 loss : 0.439728 model2 loss : 0.036394
[23:17:26.886] iteration 2939 : model1 loss : 0.442359 model2 loss : 0.036219
[23:17:27.060] iteration 2940 : model1 loss : 0.437779 model2 loss : 0.034157
[23:17:29.287] iteration 2941 : model1 loss : 0.442419 model2 loss : 0.033143
[23:17:29.463] iteration 2942 : model1 loss : 0.436685 model2 loss : 0.030038
[23:17:29.645] iteration 2943 : model1 loss : 0.436856 model2 loss : 0.031991
[23:17:29.815] iteration 2944 : model1 loss : 0.440771 model2 loss : 0.031838
[23:17:29.993] iteration 2945 : model1 loss : 0.440620 model2 loss : 0.031947
[23:17:30.166] iteration 2946 : model1 loss : 0.441290 model2 loss : 0.037255
[23:17:30.347] iteration 2947 : model1 loss : 0.439866 model2 loss : 0.029267
[23:17:30.520] iteration 2948 : model1 loss : 0.435222 model2 loss : 0.031561
[23:17:30.696] iteration 2949 : model1 loss : 0.450638 model2 loss : 0.042678
[23:17:30.870] iteration 2950 : model1 loss : 0.437778 model2 loss : 0.028484
[23:17:31.048] iteration 2951 : model1 loss : 0.435001 model2 loss : 0.027999
[23:17:31.223] iteration 2952 : model1 loss : 0.438431 model2 loss : 0.031847
[23:17:31.403] iteration 2953 : model1 loss : 0.437226 model2 loss : 0.029752
[23:17:31.575] iteration 2954 : model1 loss : 0.442827 model2 loss : 0.033353
[23:17:31.754] iteration 2955 : model1 loss : 0.442827 model2 loss : 0.038910
[23:17:31.929] iteration 2956 : model1 loss : 0.436103 model2 loss : 0.032129
[23:17:32.108] iteration 2957 : model1 loss : 0.438303 model2 loss : 0.029950
[23:17:32.279] iteration 2958 : model1 loss : 0.442415 model2 loss : 0.033304
[23:17:32.459] iteration 2959 : model1 loss : 0.439566 model2 loss : 0.028305
[23:17:32.628] iteration 2960 : model1 loss : 0.438939 model2 loss : 0.024752
[23:17:32.802] iteration 2961 : model1 loss : 0.441815 model2 loss : 0.029945
[23:17:34.947] iteration 2962 : model1 loss : 0.440757 model2 loss : 0.032583
[23:17:35.121] iteration 2963 : model1 loss : 0.441227 model2 loss : 0.033847
[23:17:35.302] iteration 2964 : model1 loss : 0.442906 model2 loss : 0.033891
[23:17:35.477] iteration 2965 : model1 loss : 0.441012 model2 loss : 0.035378
[23:17:35.652] iteration 2966 : model1 loss : 0.440736 model2 loss : 0.031317
[23:17:35.824] iteration 2967 : model1 loss : 0.442298 model2 loss : 0.032838
[23:17:36.003] iteration 2968 : model1 loss : 0.437814 model2 loss : 0.030587
[23:17:36.175] iteration 2969 : model1 loss : 0.439564 model2 loss : 0.033624
[23:17:36.358] iteration 2970 : model1 loss : 0.438669 model2 loss : 0.030644
[23:17:36.533] iteration 2971 : model1 loss : 0.440329 model2 loss : 0.035128
[23:17:36.708] iteration 2972 : model1 loss : 0.438249 model2 loss : 0.033256
[23:17:36.882] iteration 2973 : model1 loss : 0.436208 model2 loss : 0.030724
[23:17:37.062] iteration 2974 : model1 loss : 0.436136 model2 loss : 0.030193
[23:17:37.234] iteration 2975 : model1 loss : 0.439512 model2 loss : 0.032299
[23:17:37.414] iteration 2976 : model1 loss : 0.439323 model2 loss : 0.033297
[23:17:37.587] iteration 2977 : model1 loss : 0.437655 model2 loss : 0.028300
[23:17:37.764] iteration 2978 : model1 loss : 0.435986 model2 loss : 0.036340
[23:17:37.937] iteration 2979 : model1 loss : 0.440810 model2 loss : 0.029393
[23:17:38.115] iteration 2980 : model1 loss : 0.436993 model2 loss : 0.026630
[23:17:38.286] iteration 2981 : model1 loss : 0.443686 model2 loss : 0.036524
[23:17:38.463] iteration 2982 : model1 loss : 0.437069 model2 loss : 0.029179
[23:17:40.627] iteration 2983 : model1 loss : 0.438848 model2 loss : 0.035713
[23:17:40.797] iteration 2984 : model1 loss : 0.446116 model2 loss : 0.038453
[23:17:40.976] iteration 2985 : model1 loss : 0.435956 model2 loss : 0.034966
[23:17:41.148] iteration 2986 : model1 loss : 0.440797 model2 loss : 0.035998
[23:17:41.327] iteration 2987 : model1 loss : 0.440095 model2 loss : 0.029907
[23:17:41.501] iteration 2988 : model1 loss : 0.435820 model2 loss : 0.031660
[23:17:41.678] iteration 2989 : model1 loss : 0.439489 model2 loss : 0.028766
[23:17:41.849] iteration 2990 : model1 loss : 0.444035 model2 loss : 0.033280
[23:17:42.028] iteration 2991 : model1 loss : 0.438333 model2 loss : 0.035105
[23:17:42.201] iteration 2992 : model1 loss : 0.441949 model2 loss : 0.035014
[23:17:42.381] iteration 2993 : model1 loss : 0.439249 model2 loss : 0.031422
[23:17:42.556] iteration 2994 : model1 loss : 0.433432 model2 loss : 0.027681
[23:17:42.733] iteration 2995 : model1 loss : 0.438264 model2 loss : 0.031799
[23:17:42.906] iteration 2996 : model1 loss : 0.437455 model2 loss : 0.031816
[23:17:43.084] iteration 2997 : model1 loss : 0.439257 model2 loss : 0.031262
[23:17:43.258] iteration 2998 : model1 loss : 0.444588 model2 loss : 0.039721
[23:17:43.437] iteration 2999 : model1 loss : 0.436858 model2 loss : 0.026827
[23:17:43.609] iteration 3000 : model1 loss : 0.437165 model2 loss : 0.031061
[23:17:52.872] iteration 3000 : model1_mean_dice : 0.743308 model1_mean_hd95 : 12.255470
[23:18:02.109] iteration 3000 : model2_mean_dice : 0.818643 model2_mean_hd95 : 8.523263
[23:18:02.138] save model1 to ../model/ACDC/EVILv1_kl0.5_tau0.25_14_1337/unet\model1_iter_3000.pth
[23:18:02.166] save model2 to ../model/ACDC/EVILv1_kl0.5_tau0.25_14_1337/unet\model2_iter_3000.pth
[23:18:02.355] iteration 3001 : model1 loss : 0.443157 model2 loss : 0.044996
[23:18:02.534] iteration 3002 : model1 loss : 0.440778 model2 loss : 0.033957
[23:18:02.708] iteration 3003 : model1 loss : 0.434071 model2 loss : 0.027334
[23:18:04.863] iteration 3004 : model1 loss : 0.439918 model2 loss : 0.034786
[23:18:05.039] iteration 3005 : model1 loss : 0.440438 model2 loss : 0.027046
[23:18:05.217] iteration 3006 : model1 loss : 0.436806 model2 loss : 0.032169
[23:18:05.386] iteration 3007 : model1 loss : 0.440926 model2 loss : 0.030083
[23:18:05.564] iteration 3008 : model1 loss : 0.435396 model2 loss : 0.030956
[23:18:05.737] iteration 3009 : model1 loss : 0.437997 model2 loss : 0.028113
[23:18:05.915] iteration 3010 : model1 loss : 0.438698 model2 loss : 0.029398
[23:18:06.086] iteration 3011 : model1 loss : 0.441104 model2 loss : 0.031721
[23:18:06.259] iteration 3012 : model1 loss : 0.440329 model2 loss : 0.032467
[23:18:06.431] iteration 3013 : model1 loss : 0.441060 model2 loss : 0.035789
[23:18:06.610] iteration 3014 : model1 loss : 0.437837 model2 loss : 0.033589
[23:18:06.781] iteration 3015 : model1 loss : 0.438172 model2 loss : 0.026373
[23:18:06.958] iteration 3016 : model1 loss : 0.441231 model2 loss : 0.030594
[23:18:07.129] iteration 3017 : model1 loss : 0.434747 model2 loss : 0.028003
[23:18:07.302] iteration 3018 : model1 loss : 0.439587 model2 loss : 0.036811
[23:18:07.479] iteration 3019 : model1 loss : 0.442164 model2 loss : 0.039214
[23:18:07.656] iteration 3020 : model1 loss : 0.440841 model2 loss : 0.037928
[23:18:07.827] iteration 3021 : model1 loss : 0.434852 model2 loss : 0.026725
[23:18:08.005] iteration 3022 : model1 loss : 0.441322 model2 loss : 0.036267
[23:18:08.173] iteration 3023 : model1 loss : 0.442688 model2 loss : 0.034551
[23:18:08.354] iteration 3024 : model1 loss : 0.442640 model2 loss : 0.032183
[23:18:10.499] iteration 3025 : model1 loss : 0.438545 model2 loss : 0.029391
[23:18:10.672] iteration 3026 : model1 loss : 0.437800 model2 loss : 0.031450
[23:18:10.850] iteration 3027 : model1 loss : 0.435561 model2 loss : 0.027470
[23:18:11.023] iteration 3028 : model1 loss : 0.438299 model2 loss : 0.030731
[23:18:11.198] iteration 3029 : model1 loss : 0.441222 model2 loss : 0.029491
[23:18:11.368] iteration 3030 : model1 loss : 0.441484 model2 loss : 0.034186
[23:18:11.544] iteration 3031 : model1 loss : 0.438700 model2 loss : 0.030510
[23:18:11.726] iteration 3032 : model1 loss : 0.444126 model2 loss : 0.039213
[23:18:11.900] iteration 3033 : model1 loss : 0.438360 model2 loss : 0.027602
[23:18:12.076] iteration 3034 : model1 loss : 0.441472 model2 loss : 0.032427
[23:18:12.252] iteration 3035 : model1 loss : 0.438250 model2 loss : 0.033617
[23:18:12.427] iteration 3036 : model1 loss : 0.441661 model2 loss : 0.034218
[23:18:12.607] iteration 3037 : model1 loss : 0.437637 model2 loss : 0.032188
[23:18:12.777] iteration 3038 : model1 loss : 0.435830 model2 loss : 0.028370
[23:18:12.953] iteration 3039 : model1 loss : 0.440793 model2 loss : 0.034692
[23:18:13.123] iteration 3040 : model1 loss : 0.443479 model2 loss : 0.036809
[23:18:13.296] iteration 3041 : model1 loss : 0.436461 model2 loss : 0.031882
[23:18:13.470] iteration 3042 : model1 loss : 0.437892 model2 loss : 0.030741
[23:18:13.646] iteration 3043 : model1 loss : 0.445208 model2 loss : 0.033249
[23:18:13.815] iteration 3044 : model1 loss : 0.440661 model2 loss : 0.037871
[23:18:13.991] iteration 3045 : model1 loss : 0.437294 model2 loss : 0.032185
[23:18:16.135] iteration 3046 : model1 loss : 0.442062 model2 loss : 0.037332
[23:18:16.311] iteration 3047 : model1 loss : 0.436450 model2 loss : 0.027041
[23:18:16.490] iteration 3048 : model1 loss : 0.442786 model2 loss : 0.031118
[23:18:16.663] iteration 3049 : model1 loss : 0.441495 model2 loss : 0.031221
[23:18:16.837] iteration 3050 : model1 loss : 0.444089 model2 loss : 0.037064
[23:18:17.012] iteration 3051 : model1 loss : 0.433635 model2 loss : 0.030096
[23:18:17.190] iteration 3052 : model1 loss : 0.438898 model2 loss : 0.033226
[23:18:17.361] iteration 3053 : model1 loss : 0.442421 model2 loss : 0.036603
[23:18:17.538] iteration 3054 : model1 loss : 0.441299 model2 loss : 0.030349
[23:18:17.712] iteration 3055 : model1 loss : 0.441143 model2 loss : 0.033319
[23:18:17.886] iteration 3056 : model1 loss : 0.431332 model2 loss : 0.026734
[23:18:18.059] iteration 3057 : model1 loss : 0.443860 model2 loss : 0.036306
[23:18:18.236] iteration 3058 : model1 loss : 0.440553 model2 loss : 0.035362
[23:18:18.408] iteration 3059 : model1 loss : 0.436315 model2 loss : 0.031130
[23:18:18.587] iteration 3060 : model1 loss : 0.444069 model2 loss : 0.036407
[23:18:18.759] iteration 3061 : model1 loss : 0.441956 model2 loss : 0.038603
[23:18:18.935] iteration 3062 : model1 loss : 0.442594 model2 loss : 0.034370
[23:18:19.109] iteration 3063 : model1 loss : 0.442680 model2 loss : 0.027702
[23:18:19.284] iteration 3064 : model1 loss : 0.441793 model2 loss : 0.034962
[23:18:19.456] iteration 3065 : model1 loss : 0.440838 model2 loss : 0.035207
[23:18:19.634] iteration 3066 : model1 loss : 0.441272 model2 loss : 0.031035
[23:18:21.766] iteration 3067 : model1 loss : 0.446935 model2 loss : 0.033074
[23:18:21.940] iteration 3068 : model1 loss : 0.442284 model2 loss : 0.042067
[23:18:22.122] iteration 3069 : model1 loss : 0.439936 model2 loss : 0.029389
[23:18:22.292] iteration 3070 : model1 loss : 0.439591 model2 loss : 0.032997
[23:18:22.474] iteration 3071 : model1 loss : 0.439179 model2 loss : 0.030852
[23:18:22.647] iteration 3072 : model1 loss : 0.439321 model2 loss : 0.033144
[23:18:22.822] iteration 3073 : model1 loss : 0.442466 model2 loss : 0.038328
[23:18:22.996] iteration 3074 : model1 loss : 0.434366 model2 loss : 0.030000
[23:18:23.174] iteration 3075 : model1 loss : 0.440129 model2 loss : 0.032447
[23:18:23.344] iteration 3076 : model1 loss : 0.437188 model2 loss : 0.030424
[23:18:23.521] iteration 3077 : model1 loss : 0.438814 model2 loss : 0.033598
[23:18:23.692] iteration 3078 : model1 loss : 0.436948 model2 loss : 0.036796
[23:18:23.869] iteration 3079 : model1 loss : 0.442170 model2 loss : 0.033511
[23:18:24.043] iteration 3080 : model1 loss : 0.437874 model2 loss : 0.028334
[23:18:24.220] iteration 3081 : model1 loss : 0.442989 model2 loss : 0.037928
[23:18:24.392] iteration 3082 : model1 loss : 0.437594 model2 loss : 0.035578
[23:18:24.570] iteration 3083 : model1 loss : 0.439459 model2 loss : 0.036257
[23:18:24.739] iteration 3084 : model1 loss : 0.438599 model2 loss : 0.032553
[23:18:24.914] iteration 3085 : model1 loss : 0.443488 model2 loss : 0.037165
[23:18:25.085] iteration 3086 : model1 loss : 0.438364 model2 loss : 0.029732
[23:18:25.262] iteration 3087 : model1 loss : 0.442315 model2 loss : 0.035415
[23:18:27.357] iteration 3088 : model1 loss : 0.439921 model2 loss : 0.030920
[23:18:27.540] iteration 3089 : model1 loss : 0.441770 model2 loss : 0.037772
[23:18:27.717] iteration 3090 : model1 loss : 0.442049 model2 loss : 0.033881
[23:18:27.888] iteration 3091 : model1 loss : 0.436631 model2 loss : 0.032002
[23:18:28.064] iteration 3092 : model1 loss : 0.439751 model2 loss : 0.028174
[23:18:28.234] iteration 3093 : model1 loss : 0.440314 model2 loss : 0.030766
[23:18:28.412] iteration 3094 : model1 loss : 0.441577 model2 loss : 0.034027
[23:18:28.587] iteration 3095 : model1 loss : 0.441508 model2 loss : 0.033510
[23:18:28.764] iteration 3096 : model1 loss : 0.440055 model2 loss : 0.031497
[23:18:28.935] iteration 3097 : model1 loss : 0.442547 model2 loss : 0.039090
[23:18:29.113] iteration 3098 : model1 loss : 0.442444 model2 loss : 0.030282
[23:18:29.283] iteration 3099 : model1 loss : 0.437954 model2 loss : 0.030696
[23:18:29.460] iteration 3100 : model1 loss : 0.438979 model2 loss : 0.030361
[23:18:29.634] iteration 3101 : model1 loss : 0.442432 model2 loss : 0.028679
[23:18:29.812] iteration 3102 : model1 loss : 0.441622 model2 loss : 0.031826
[23:18:29.984] iteration 3103 : model1 loss : 0.443887 model2 loss : 0.034643
[23:18:30.161] iteration 3104 : model1 loss : 0.438421 model2 loss : 0.029198
[23:18:30.335] iteration 3105 : model1 loss : 0.434870 model2 loss : 0.024598
[23:18:30.512] iteration 3106 : model1 loss : 0.439865 model2 loss : 0.030360
[23:18:30.682] iteration 3107 : model1 loss : 0.438830 model2 loss : 0.034976
[23:18:30.856] iteration 3108 : model1 loss : 0.438845 model2 loss : 0.029407
[23:18:32.996] iteration 3109 : model1 loss : 0.442119 model2 loss : 0.030610
[23:18:33.169] iteration 3110 : model1 loss : 0.440529 model2 loss : 0.035800
[23:18:33.349] iteration 3111 : model1 loss : 0.441054 model2 loss : 0.031692
[23:18:33.521] iteration 3112 : model1 loss : 0.438531 model2 loss : 0.028435
[23:18:33.697] iteration 3113 : model1 loss : 0.443372 model2 loss : 0.039671
[23:18:33.866] iteration 3114 : model1 loss : 0.441115 model2 loss : 0.032906
[23:18:34.042] iteration 3115 : model1 loss : 0.436822 model2 loss : 0.029850
[23:18:34.213] iteration 3116 : model1 loss : 0.439865 model2 loss : 0.029942
[23:18:34.389] iteration 3117 : model1 loss : 0.440156 model2 loss : 0.030197
[23:18:34.562] iteration 3118 : model1 loss : 0.439037 model2 loss : 0.031863
[23:18:34.736] iteration 3119 : model1 loss : 0.445108 model2 loss : 0.034202
[23:18:34.904] iteration 3120 : model1 loss : 0.441856 model2 loss : 0.029963
[23:18:35.081] iteration 3121 : model1 loss : 0.437888 model2 loss : 0.031562
[23:18:35.250] iteration 3122 : model1 loss : 0.442563 model2 loss : 0.030825
[23:18:35.425] iteration 3123 : model1 loss : 0.438293 model2 loss : 0.032784
[23:18:35.601] iteration 3124 : model1 loss : 0.445113 model2 loss : 0.031420
[23:18:35.779] iteration 3125 : model1 loss : 0.436794 model2 loss : 0.031352
[23:18:35.950] iteration 3126 : model1 loss : 0.441869 model2 loss : 0.031513
[23:18:36.130] iteration 3127 : model1 loss : 0.441541 model2 loss : 0.029743
[23:18:36.299] iteration 3128 : model1 loss : 0.437014 model2 loss : 0.031253
[23:18:36.474] iteration 3129 : model1 loss : 0.440852 model2 loss : 0.041035
[23:18:38.604] iteration 3130 : model1 loss : 0.438570 model2 loss : 0.027896
[23:18:38.776] iteration 3131 : model1 loss : 0.435814 model2 loss : 0.031182
[23:18:38.954] iteration 3132 : model1 loss : 0.440478 model2 loss : 0.031207
[23:18:39.129] iteration 3133 : model1 loss : 0.437900 model2 loss : 0.032908
[23:18:39.304] iteration 3134 : model1 loss : 0.438213 model2 loss : 0.033438
[23:18:39.477] iteration 3135 : model1 loss : 0.439817 model2 loss : 0.033273
[23:18:39.655] iteration 3136 : model1 loss : 0.441631 model2 loss : 0.032255
[23:18:39.826] iteration 3137 : model1 loss : 0.438605 model2 loss : 0.031466
[23:18:40.002] iteration 3138 : model1 loss : 0.439587 model2 loss : 0.032897
[23:18:40.172] iteration 3139 : model1 loss : 0.439347 model2 loss : 0.034052
[23:18:40.348] iteration 3140 : model1 loss : 0.441821 model2 loss : 0.033994
[23:18:40.523] iteration 3141 : model1 loss : 0.444442 model2 loss : 0.034882
[23:18:40.699] iteration 3142 : model1 loss : 0.441867 model2 loss : 0.029625
[23:18:40.870] iteration 3143 : model1 loss : 0.442138 model2 loss : 0.030628
[23:18:41.046] iteration 3144 : model1 loss : 0.438069 model2 loss : 0.027099
[23:18:41.216] iteration 3145 : model1 loss : 0.436582 model2 loss : 0.028563
[23:18:41.393] iteration 3146 : model1 loss : 0.438990 model2 loss : 0.028398
[23:18:41.569] iteration 3147 : model1 loss : 0.433431 model2 loss : 0.027654
[23:18:41.743] iteration 3148 : model1 loss : 0.443291 model2 loss : 0.035960
[23:18:41.911] iteration 3149 : model1 loss : 0.441890 model2 loss : 0.029698
[23:18:42.087] iteration 3150 : model1 loss : 0.435997 model2 loss : 0.029633
[23:18:44.233] iteration 3151 : model1 loss : 0.443745 model2 loss : 0.029597
[23:18:44.407] iteration 3152 : model1 loss : 0.440837 model2 loss : 0.044937
[23:18:44.586] iteration 3153 : model1 loss : 0.438478 model2 loss : 0.031114
[23:18:44.757] iteration 3154 : model1 loss : 0.441799 model2 loss : 0.032143
[23:18:44.932] iteration 3155 : model1 loss : 0.437919 model2 loss : 0.028340
[23:18:45.106] iteration 3156 : model1 loss : 0.439601 model2 loss : 0.033184
[23:18:45.281] iteration 3157 : model1 loss : 0.442820 model2 loss : 0.030574
[23:18:45.450] iteration 3158 : model1 loss : 0.439780 model2 loss : 0.028525
[23:18:45.631] iteration 3159 : model1 loss : 0.434074 model2 loss : 0.026789
[23:18:45.803] iteration 3160 : model1 loss : 0.446492 model2 loss : 0.036549
[23:18:45.977] iteration 3161 : model1 loss : 0.440539 model2 loss : 0.036072
[23:18:46.150] iteration 3162 : model1 loss : 0.438321 model2 loss : 0.030484
[23:18:46.331] iteration 3163 : model1 loss : 0.439436 model2 loss : 0.031200
[23:18:46.504] iteration 3164 : model1 loss : 0.439952 model2 loss : 0.030475
[23:18:46.680] iteration 3165 : model1 loss : 0.441262 model2 loss : 0.033934
[23:18:46.849] iteration 3166 : model1 loss : 0.436164 model2 loss : 0.028457
[23:18:47.024] iteration 3167 : model1 loss : 0.442310 model2 loss : 0.034763
[23:18:47.196] iteration 3168 : model1 loss : 0.437860 model2 loss : 0.030289
[23:18:47.371] iteration 3169 : model1 loss : 0.438658 model2 loss : 0.032667
[23:18:47.543] iteration 3170 : model1 loss : 0.437939 model2 loss : 0.035853
[23:18:47.719] iteration 3171 : model1 loss : 0.436626 model2 loss : 0.027839
[23:18:49.875] iteration 3172 : model1 loss : 0.434787 model2 loss : 0.032055
[23:18:50.052] iteration 3173 : model1 loss : 0.434620 model2 loss : 0.029261
[23:18:50.231] iteration 3174 : model1 loss : 0.443202 model2 loss : 0.029437
[23:18:50.406] iteration 3175 : model1 loss : 0.438248 model2 loss : 0.030352
[23:18:50.585] iteration 3176 : model1 loss : 0.438583 model2 loss : 0.030823
[23:18:50.755] iteration 3177 : model1 loss : 0.442675 model2 loss : 0.038798
[23:18:50.929] iteration 3178 : model1 loss : 0.438015 model2 loss : 0.028993
[23:18:51.100] iteration 3179 : model1 loss : 0.435789 model2 loss : 0.029456
[23:18:51.275] iteration 3180 : model1 loss : 0.445798 model2 loss : 0.034854
[23:18:51.444] iteration 3181 : model1 loss : 0.439941 model2 loss : 0.035315
[23:18:51.621] iteration 3182 : model1 loss : 0.438452 model2 loss : 0.033169
[23:18:51.792] iteration 3183 : model1 loss : 0.437644 model2 loss : 0.031252
[23:18:51.968] iteration 3184 : model1 loss : 0.443925 model2 loss : 0.039772
[23:18:52.141] iteration 3185 : model1 loss : 0.439022 model2 loss : 0.030375
[23:18:52.317] iteration 3186 : model1 loss : 0.440871 model2 loss : 0.029132
[23:18:52.493] iteration 3187 : model1 loss : 0.440483 model2 loss : 0.033048
[23:18:52.671] iteration 3188 : model1 loss : 0.440196 model2 loss : 0.032274
[23:18:52.841] iteration 3189 : model1 loss : 0.443919 model2 loss : 0.034886
[23:18:53.016] iteration 3190 : model1 loss : 0.435050 model2 loss : 0.033111
[23:18:53.186] iteration 3191 : model1 loss : 0.441014 model2 loss : 0.034484
[23:18:53.360] iteration 3192 : model1 loss : 0.443104 model2 loss : 0.037036
[23:18:55.517] iteration 3193 : model1 loss : 0.435025 model2 loss : 0.031791
[23:18:55.693] iteration 3194 : model1 loss : 0.439653 model2 loss : 0.034515
[23:18:55.869] iteration 3195 : model1 loss : 0.436605 model2 loss : 0.028784
[23:18:56.042] iteration 3196 : model1 loss : 0.442035 model2 loss : 0.032886
[23:18:56.218] iteration 3197 : model1 loss : 0.440773 model2 loss : 0.040167
[23:18:56.390] iteration 3198 : model1 loss : 0.441368 model2 loss : 0.030868
[23:18:56.569] iteration 3199 : model1 loss : 0.446462 model2 loss : 0.035701
[23:18:56.740] iteration 3200 : model1 loss : 0.438606 model2 loss : 0.035706
[23:18:56.915] iteration 3201 : model1 loss : 0.442888 model2 loss : 0.039570
[23:18:57.089] iteration 3202 : model1 loss : 0.442490 model2 loss : 0.038211
[23:18:57.262] iteration 3203 : model1 loss : 0.439581 model2 loss : 0.035023
[23:18:57.435] iteration 3204 : model1 loss : 0.439349 model2 loss : 0.030278
[23:18:57.614] iteration 3205 : model1 loss : 0.434733 model2 loss : 0.030359
[23:18:57.786] iteration 3206 : model1 loss : 0.438690 model2 loss : 0.032940
[23:18:57.962] iteration 3207 : model1 loss : 0.441999 model2 loss : 0.036591
[23:18:58.136] iteration 3208 : model1 loss : 0.441626 model2 loss : 0.034049
[23:18:58.313] iteration 3209 : model1 loss : 0.438705 model2 loss : 0.031423
[23:18:58.485] iteration 3210 : model1 loss : 0.441942 model2 loss : 0.033784
[23:18:58.663] iteration 3211 : model1 loss : 0.435886 model2 loss : 0.028952
[23:18:58.832] iteration 3212 : model1 loss : 0.437112 model2 loss : 0.029239
[23:18:59.003] iteration 3213 : model1 loss : 0.442199 model2 loss : 0.034319
[23:19:01.153] iteration 3214 : model1 loss : 0.439246 model2 loss : 0.032271
[23:19:01.327] iteration 3215 : model1 loss : 0.442543 model2 loss : 0.034226
[23:19:01.504] iteration 3216 : model1 loss : 0.440063 model2 loss : 0.028590
[23:19:01.679] iteration 3217 : model1 loss : 0.439991 model2 loss : 0.031947
[23:19:01.855] iteration 3218 : model1 loss : 0.444472 model2 loss : 0.031220
[23:19:02.026] iteration 3219 : model1 loss : 0.437857 model2 loss : 0.027775
[23:19:02.201] iteration 3220 : model1 loss : 0.438730 model2 loss : 0.032497
[23:19:02.374] iteration 3221 : model1 loss : 0.436182 model2 loss : 0.030275
[23:19:02.553] iteration 3222 : model1 loss : 0.437576 model2 loss : 0.027605
[23:19:02.727] iteration 3223 : model1 loss : 0.436682 model2 loss : 0.029540
[23:19:02.902] iteration 3224 : model1 loss : 0.439646 model2 loss : 0.029358
[23:19:03.073] iteration 3225 : model1 loss : 0.435316 model2 loss : 0.027013
[23:19:03.250] iteration 3226 : model1 loss : 0.437430 model2 loss : 0.026351
[23:19:03.420] iteration 3227 : model1 loss : 0.441268 model2 loss : 0.036788
[23:19:03.600] iteration 3228 : model1 loss : 0.437468 model2 loss : 0.034412
[23:19:03.770] iteration 3229 : model1 loss : 0.441179 model2 loss : 0.027711
[23:19:03.945] iteration 3230 : model1 loss : 0.438237 model2 loss : 0.027807
[23:19:04.120] iteration 3231 : model1 loss : 0.435680 model2 loss : 0.031518
[23:19:04.302] iteration 3232 : model1 loss : 0.439997 model2 loss : 0.034706
[23:19:04.470] iteration 3233 : model1 loss : 0.439530 model2 loss : 0.027707
[23:19:04.647] iteration 3234 : model1 loss : 0.438253 model2 loss : 0.029522
[23:19:06.760] iteration 3235 : model1 loss : 0.435607 model2 loss : 0.028704
[23:19:06.931] iteration 3236 : model1 loss : 0.440739 model2 loss : 0.034280
[23:19:07.109] iteration 3237 : model1 loss : 0.435893 model2 loss : 0.028957
[23:19:07.280] iteration 3238 : model1 loss : 0.439118 model2 loss : 0.030515
[23:19:07.459] iteration 3239 : model1 loss : 0.437012 model2 loss : 0.030653
[23:19:07.633] iteration 3240 : model1 loss : 0.438785 model2 loss : 0.033586
[23:19:07.806] iteration 3241 : model1 loss : 0.439881 model2 loss : 0.028240
[23:19:07.976] iteration 3242 : model1 loss : 0.438681 model2 loss : 0.029033
[23:19:08.153] iteration 3243 : model1 loss : 0.440901 model2 loss : 0.034609
[23:19:08.326] iteration 3244 : model1 loss : 0.437589 model2 loss : 0.033175
[23:19:08.505] iteration 3245 : model1 loss : 0.435783 model2 loss : 0.025577
[23:19:08.678] iteration 3246 : model1 loss : 0.441262 model2 loss : 0.029090
[23:19:08.853] iteration 3247 : model1 loss : 0.440377 model2 loss : 0.030571
[23:19:09.026] iteration 3248 : model1 loss : 0.442447 model2 loss : 0.037424
[23:19:09.202] iteration 3249 : model1 loss : 0.440377 model2 loss : 0.033297
[23:19:09.372] iteration 3250 : model1 loss : 0.438977 model2 loss : 0.038080
[23:19:09.550] iteration 3251 : model1 loss : 0.442179 model2 loss : 0.032894
[23:19:09.721] iteration 3252 : model1 loss : 0.443757 model2 loss : 0.028570
[23:19:09.896] iteration 3253 : model1 loss : 0.435439 model2 loss : 0.029877
[23:19:10.066] iteration 3254 : model1 loss : 0.438920 model2 loss : 0.031269
[23:19:10.242] iteration 3255 : model1 loss : 0.441745 model2 loss : 0.037592
[23:19:12.387] iteration 3256 : model1 loss : 0.439196 model2 loss : 0.033947
[23:19:12.558] iteration 3257 : model1 loss : 0.436019 model2 loss : 0.029209
[23:19:12.739] iteration 3258 : model1 loss : 0.440825 model2 loss : 0.035557
[23:19:12.909] iteration 3259 : model1 loss : 0.438479 model2 loss : 0.028322
[23:19:13.086] iteration 3260 : model1 loss : 0.436941 model2 loss : 0.025791
[23:19:13.257] iteration 3261 : model1 loss : 0.446994 model2 loss : 0.035388
[23:19:13.431] iteration 3262 : model1 loss : 0.443169 model2 loss : 0.039561
[23:19:13.609] iteration 3263 : model1 loss : 0.439609 model2 loss : 0.028108
[23:19:13.784] iteration 3264 : model1 loss : 0.437533 model2 loss : 0.030908
[23:19:13.954] iteration 3265 : model1 loss : 0.443417 model2 loss : 0.036223
[23:19:14.138] iteration 3266 : model1 loss : 0.445203 model2 loss : 0.035241
[23:19:14.313] iteration 3267 : model1 loss : 0.442497 model2 loss : 0.030367
[23:19:14.492] iteration 3268 : model1 loss : 0.436188 model2 loss : 0.029095
[23:19:14.666] iteration 3269 : model1 loss : 0.437974 model2 loss : 0.033857
[23:19:14.841] iteration 3270 : model1 loss : 0.443288 model2 loss : 0.028502
[23:19:15.011] iteration 3271 : model1 loss : 0.436943 model2 loss : 0.031189
[23:19:15.190] iteration 3272 : model1 loss : 0.437449 model2 loss : 0.027270
[23:19:15.361] iteration 3273 : model1 loss : 0.442025 model2 loss : 0.036106
[23:19:15.539] iteration 3274 : model1 loss : 0.437667 model2 loss : 0.034396
[23:19:15.709] iteration 3275 : model1 loss : 0.439874 model2 loss : 0.031787
[23:19:15.883] iteration 3276 : model1 loss : 0.437086 model2 loss : 0.030951
[23:19:18.033] iteration 3277 : model1 loss : 0.441062 model2 loss : 0.029674
[23:19:18.209] iteration 3278 : model1 loss : 0.442440 model2 loss : 0.036275
[23:19:18.386] iteration 3279 : model1 loss : 0.439392 model2 loss : 0.032544
[23:19:18.557] iteration 3280 : model1 loss : 0.440301 model2 loss : 0.028206
[23:19:18.735] iteration 3281 : model1 loss : 0.446322 model2 loss : 0.038876
[23:19:18.904] iteration 3282 : model1 loss : 0.438077 model2 loss : 0.035471
[23:19:19.083] iteration 3283 : model1 loss : 0.437378 model2 loss : 0.029880
[23:19:19.255] iteration 3284 : model1 loss : 0.439314 model2 loss : 0.031103
[23:19:19.434] iteration 3285 : model1 loss : 0.443448 model2 loss : 0.032493
[23:19:19.608] iteration 3286 : model1 loss : 0.437061 model2 loss : 0.028119
[23:19:19.783] iteration 3287 : model1 loss : 0.434556 model2 loss : 0.032075
[23:19:19.954] iteration 3288 : model1 loss : 0.436603 model2 loss : 0.025590
[23:19:20.136] iteration 3289 : model1 loss : 0.443031 model2 loss : 0.038066
[23:19:20.310] iteration 3290 : model1 loss : 0.445066 model2 loss : 0.033085
[23:19:20.488] iteration 3291 : model1 loss : 0.438998 model2 loss : 0.032161
[23:19:20.662] iteration 3292 : model1 loss : 0.440686 model2 loss : 0.025800
[23:19:20.838] iteration 3293 : model1 loss : 0.443098 model2 loss : 0.038299
[23:19:21.006] iteration 3294 : model1 loss : 0.432497 model2 loss : 0.034226
[23:19:21.183] iteration 3295 : model1 loss : 0.442735 model2 loss : 0.039313
[23:19:21.352] iteration 3296 : model1 loss : 0.439626 model2 loss : 0.034661
[23:19:21.526] iteration 3297 : model1 loss : 0.437359 model2 loss : 0.033067
[23:19:23.641] iteration 3298 : model1 loss : 0.439960 model2 loss : 0.031662
[23:19:23.815] iteration 3299 : model1 loss : 0.435769 model2 loss : 0.029827
[23:19:23.993] iteration 3300 : model1 loss : 0.438064 model2 loss : 0.027436
[23:19:24.166] iteration 3301 : model1 loss : 0.434635 model2 loss : 0.027859
[23:19:24.343] iteration 3302 : model1 loss : 0.435688 model2 loss : 0.027551
[23:19:24.516] iteration 3303 : model1 loss : 0.444427 model2 loss : 0.035492
[23:19:24.695] iteration 3304 : model1 loss : 0.439582 model2 loss : 0.028983
[23:19:24.866] iteration 3305 : model1 loss : 0.439712 model2 loss : 0.038179
[23:19:25.041] iteration 3306 : model1 loss : 0.438255 model2 loss : 0.035455
[23:19:25.213] iteration 3307 : model1 loss : 0.437629 model2 loss : 0.031606
[23:19:25.393] iteration 3308 : model1 loss : 0.441300 model2 loss : 0.052473
[23:19:25.565] iteration 3309 : model1 loss : 0.438170 model2 loss : 0.032097
[23:19:25.741] iteration 3310 : model1 loss : 0.436567 model2 loss : 0.032209
[23:19:25.911] iteration 3311 : model1 loss : 0.443645 model2 loss : 0.031862
[23:19:26.087] iteration 3312 : model1 loss : 0.438347 model2 loss : 0.027705
[23:19:26.261] iteration 3313 : model1 loss : 0.439512 model2 loss : 0.032227
[23:19:26.440] iteration 3314 : model1 loss : 0.440913 model2 loss : 0.030160
[23:19:26.616] iteration 3315 : model1 loss : 0.442007 model2 loss : 0.028629
[23:19:26.793] iteration 3316 : model1 loss : 0.436886 model2 loss : 0.031211
[23:19:26.961] iteration 3317 : model1 loss : 0.439414 model2 loss : 0.031652
[23:19:27.137] iteration 3318 : model1 loss : 0.441795 model2 loss : 0.037505
[23:19:29.281] iteration 3319 : model1 loss : 0.440396 model2 loss : 0.031796
[23:19:29.455] iteration 3320 : model1 loss : 0.439080 model2 loss : 0.027677
[23:19:29.636] iteration 3321 : model1 loss : 0.433309 model2 loss : 0.031658
[23:19:29.809] iteration 3322 : model1 loss : 0.436560 model2 loss : 0.030761
[23:19:29.983] iteration 3323 : model1 loss : 0.444112 model2 loss : 0.038423
[23:19:30.158] iteration 3324 : model1 loss : 0.438328 model2 loss : 0.029733
[23:19:30.334] iteration 3325 : model1 loss : 0.440552 model2 loss : 0.029938
[23:19:30.506] iteration 3326 : model1 loss : 0.440069 model2 loss : 0.032885
[23:19:30.681] iteration 3327 : model1 loss : 0.437531 model2 loss : 0.034423
[23:19:30.852] iteration 3328 : model1 loss : 0.442346 model2 loss : 0.030699
[23:19:31.025] iteration 3329 : model1 loss : 0.438220 model2 loss : 0.031042
[23:19:31.198] iteration 3330 : model1 loss : 0.439100 model2 loss : 0.030091
[23:19:31.373] iteration 3331 : model1 loss : 0.438623 model2 loss : 0.031093
[23:19:31.547] iteration 3332 : model1 loss : 0.439008 model2 loss : 0.031478
[23:19:31.725] iteration 3333 : model1 loss : 0.439503 model2 loss : 0.027226
[23:19:31.894] iteration 3334 : model1 loss : 0.438659 model2 loss : 0.035031
[23:19:32.070] iteration 3335 : model1 loss : 0.441290 model2 loss : 0.036033
[23:19:32.242] iteration 3336 : model1 loss : 0.438911 model2 loss : 0.030361
[23:19:32.429] iteration 3337 : model1 loss : 0.439008 model2 loss : 0.035849
[23:19:32.603] iteration 3338 : model1 loss : 0.441007 model2 loss : 0.030825
[23:19:32.776] iteration 3339 : model1 loss : 0.434011 model2 loss : 0.028352
[23:19:34.879] iteration 3340 : model1 loss : 0.441893 model2 loss : 0.031478
[23:19:35.050] iteration 3341 : model1 loss : 0.438729 model2 loss : 0.028231
[23:19:35.229] iteration 3342 : model1 loss : 0.438027 model2 loss : 0.030549
[23:19:35.402] iteration 3343 : model1 loss : 0.433395 model2 loss : 0.028713
[23:19:35.578] iteration 3344 : model1 loss : 0.434865 model2 loss : 0.029554
[23:19:35.753] iteration 3345 : model1 loss : 0.440640 model2 loss : 0.036121
[23:19:35.929] iteration 3346 : model1 loss : 0.435830 model2 loss : 0.029490
[23:19:36.100] iteration 3347 : model1 loss : 0.438738 model2 loss : 0.033055
[23:19:36.275] iteration 3348 : model1 loss : 0.436985 model2 loss : 0.028336
[23:19:36.446] iteration 3349 : model1 loss : 0.442022 model2 loss : 0.032970
[23:19:36.627] iteration 3350 : model1 loss : 0.446211 model2 loss : 0.034377
[23:19:36.796] iteration 3351 : model1 loss : 0.438250 model2 loss : 0.032745
[23:19:36.974] iteration 3352 : model1 loss : 0.437459 model2 loss : 0.030721
[23:19:37.147] iteration 3353 : model1 loss : 0.438978 model2 loss : 0.034462
[23:19:37.325] iteration 3354 : model1 loss : 0.440235 model2 loss : 0.031161
[23:19:37.503] iteration 3355 : model1 loss : 0.434120 model2 loss : 0.031731
[23:19:37.680] iteration 3356 : model1 loss : 0.441340 model2 loss : 0.035887
[23:19:37.850] iteration 3357 : model1 loss : 0.437650 model2 loss : 0.031965
[23:19:38.024] iteration 3358 : model1 loss : 0.441017 model2 loss : 0.032315
[23:19:38.196] iteration 3359 : model1 loss : 0.442254 model2 loss : 0.034245
[23:19:38.373] iteration 3360 : model1 loss : 0.436686 model2 loss : 0.028205
[23:19:40.514] iteration 3361 : model1 loss : 0.438498 model2 loss : 0.031082
[23:19:40.690] iteration 3362 : model1 loss : 0.439638 model2 loss : 0.032415
[23:19:40.866] iteration 3363 : model1 loss : 0.441970 model2 loss : 0.037401
[23:19:41.036] iteration 3364 : model1 loss : 0.438153 model2 loss : 0.040588
[23:19:41.212] iteration 3365 : model1 loss : 0.437329 model2 loss : 0.031416
[23:19:41.383] iteration 3366 : model1 loss : 0.437218 model2 loss : 0.039161
[23:19:41.561] iteration 3367 : model1 loss : 0.440475 model2 loss : 0.028462
[23:19:41.734] iteration 3368 : model1 loss : 0.436572 model2 loss : 0.032541
[23:19:41.908] iteration 3369 : model1 loss : 0.436981 model2 loss : 0.033440
[23:19:42.078] iteration 3370 : model1 loss : 0.440843 model2 loss : 0.033182
[23:19:42.254] iteration 3371 : model1 loss : 0.441134 model2 loss : 0.030979
[23:19:42.428] iteration 3372 : model1 loss : 0.435306 model2 loss : 0.027204
[23:19:42.609] iteration 3373 : model1 loss : 0.443979 model2 loss : 0.036995
[23:19:42.781] iteration 3374 : model1 loss : 0.439240 model2 loss : 0.037637
[23:19:42.959] iteration 3375 : model1 loss : 0.437869 model2 loss : 0.030662
[23:19:43.134] iteration 3376 : model1 loss : 0.436785 model2 loss : 0.029381
[23:19:43.311] iteration 3377 : model1 loss : 0.441792 model2 loss : 0.037776
[23:19:43.482] iteration 3378 : model1 loss : 0.439184 model2 loss : 0.035341
[23:19:43.667] iteration 3379 : model1 loss : 0.438619 model2 loss : 0.032654
[23:19:43.838] iteration 3380 : model1 loss : 0.436161 model2 loss : 0.030023
[23:19:44.012] iteration 3381 : model1 loss : 0.439435 model2 loss : 0.030886
[23:19:46.148] iteration 3382 : model1 loss : 0.435363 model2 loss : 0.025587
[23:19:46.327] iteration 3383 : model1 loss : 0.443247 model2 loss : 0.031274
[23:19:46.505] iteration 3384 : model1 loss : 0.444785 model2 loss : 0.041392
[23:19:46.679] iteration 3385 : model1 loss : 0.442464 model2 loss : 0.034335
[23:19:46.858] iteration 3386 : model1 loss : 0.442584 model2 loss : 0.058195
[23:19:47.027] iteration 3387 : model1 loss : 0.434576 model2 loss : 0.030525
[23:19:47.206] iteration 3388 : model1 loss : 0.436292 model2 loss : 0.030123
[23:19:47.377] iteration 3389 : model1 loss : 0.436780 model2 loss : 0.030773
[23:19:47.556] iteration 3390 : model1 loss : 0.445324 model2 loss : 0.040501
[23:19:47.730] iteration 3391 : model1 loss : 0.437125 model2 loss : 0.027211
[23:19:47.905] iteration 3392 : model1 loss : 0.438388 model2 loss : 0.029781
[23:19:48.075] iteration 3393 : model1 loss : 0.437997 model2 loss : 0.031542
[23:19:48.253] iteration 3394 : model1 loss : 0.436287 model2 loss : 0.028933
[23:19:48.425] iteration 3395 : model1 loss : 0.443220 model2 loss : 0.036585
[23:19:48.602] iteration 3396 : model1 loss : 0.440814 model2 loss : 0.038816
[23:19:48.776] iteration 3397 : model1 loss : 0.438565 model2 loss : 0.030462
[23:19:48.952] iteration 3398 : model1 loss : 0.441445 model2 loss : 0.033666
[23:19:49.124] iteration 3399 : model1 loss : 0.435975 model2 loss : 0.030783
[23:19:49.304] iteration 3400 : model1 loss : 0.437675 model2 loss : 0.036525
[23:19:49.474] iteration 3401 : model1 loss : 0.440584 model2 loss : 0.034382
[23:19:49.650] iteration 3402 : model1 loss : 0.438875 model2 loss : 0.028948
[23:19:51.755] iteration 3403 : model1 loss : 0.440199 model2 loss : 0.041588
[23:19:51.928] iteration 3404 : model1 loss : 0.442152 model2 loss : 0.047512
[23:19:52.105] iteration 3405 : model1 loss : 0.439172 model2 loss : 0.030014
[23:19:52.281] iteration 3406 : model1 loss : 0.438334 model2 loss : 0.028473
[23:19:52.464] iteration 3407 : model1 loss : 0.433841 model2 loss : 0.026861
[23:19:52.639] iteration 3408 : model1 loss : 0.443391 model2 loss : 0.038449
[23:19:52.814] iteration 3409 : model1 loss : 0.439368 model2 loss : 0.033881
[23:19:52.982] iteration 3410 : model1 loss : 0.441236 model2 loss : 0.036879
[23:19:53.161] iteration 3411 : model1 loss : 0.435719 model2 loss : 0.032079
[23:19:53.335] iteration 3412 : model1 loss : 0.440778 model2 loss : 0.030228
[23:19:53.510] iteration 3413 : model1 loss : 0.435754 model2 loss : 0.028551
[23:19:53.683] iteration 3414 : model1 loss : 0.439157 model2 loss : 0.034267
[23:19:53.863] iteration 3415 : model1 loss : 0.441639 model2 loss : 0.039304
[23:19:54.034] iteration 3416 : model1 loss : 0.438027 model2 loss : 0.030989
[23:19:54.211] iteration 3417 : model1 loss : 0.438257 model2 loss : 0.033129
[23:19:54.386] iteration 3418 : model1 loss : 0.443743 model2 loss : 0.032907
[23:19:54.563] iteration 3419 : model1 loss : 0.445201 model2 loss : 0.046780
[23:19:54.735] iteration 3420 : model1 loss : 0.441697 model2 loss : 0.031911
[23:19:54.910] iteration 3421 : model1 loss : 0.438868 model2 loss : 0.031075
[23:19:55.079] iteration 3422 : model1 loss : 0.439293 model2 loss : 0.028428
[23:19:55.251] iteration 3423 : model1 loss : 0.438149 model2 loss : 0.033468
[23:19:57.398] iteration 3424 : model1 loss : 0.445463 model2 loss : 0.034985
[23:19:57.569] iteration 3425 : model1 loss : 0.442452 model2 loss : 0.034071
[23:19:57.747] iteration 3426 : model1 loss : 0.438104 model2 loss : 0.035682
[23:19:57.917] iteration 3427 : model1 loss : 0.443819 model2 loss : 0.030816
[23:19:58.093] iteration 3428 : model1 loss : 0.434468 model2 loss : 0.025835
[23:19:58.266] iteration 3429 : model1 loss : 0.436686 model2 loss : 0.030805
[23:19:58.441] iteration 3430 : model1 loss : 0.440589 model2 loss : 0.029667
[23:19:58.614] iteration 3431 : model1 loss : 0.438756 model2 loss : 0.028485
[23:19:58.794] iteration 3432 : model1 loss : 0.442533 model2 loss : 0.035606
[23:19:58.963] iteration 3433 : model1 loss : 0.440480 model2 loss : 0.040420
[23:19:59.139] iteration 3434 : model1 loss : 0.436976 model2 loss : 0.029686
[23:19:59.311] iteration 3435 : model1 loss : 0.436313 model2 loss : 0.030563
[23:19:59.488] iteration 3436 : model1 loss : 0.436314 model2 loss : 0.027525
[23:19:59.664] iteration 3437 : model1 loss : 0.443491 model2 loss : 0.034157
[23:19:59.838] iteration 3438 : model1 loss : 0.438290 model2 loss : 0.039535
[23:20:00.009] iteration 3439 : model1 loss : 0.438281 model2 loss : 0.027453
[23:20:00.194] iteration 3440 : model1 loss : 0.438608 model2 loss : 0.033081
[23:20:00.368] iteration 3441 : model1 loss : 0.437919 model2 loss : 0.027823
[23:20:00.545] iteration 3442 : model1 loss : 0.444617 model2 loss : 0.032967
[23:20:00.716] iteration 3443 : model1 loss : 0.435685 model2 loss : 0.030443
[23:20:00.895] iteration 3444 : model1 loss : 0.443526 model2 loss : 0.032215
[23:20:03.035] iteration 3445 : model1 loss : 0.436175 model2 loss : 0.026476
[23:20:03.207] iteration 3446 : model1 loss : 0.442616 model2 loss : 0.032026
[23:20:03.385] iteration 3447 : model1 loss : 0.438009 model2 loss : 0.026523
[23:20:03.556] iteration 3448 : model1 loss : 0.438596 model2 loss : 0.028873
[23:20:03.733] iteration 3449 : model1 loss : 0.432846 model2 loss : 0.028804
[23:20:03.902] iteration 3450 : model1 loss : 0.441067 model2 loss : 0.032262
[23:20:04.080] iteration 3451 : model1 loss : 0.440752 model2 loss : 0.035341
[23:20:04.254] iteration 3452 : model1 loss : 0.436726 model2 loss : 0.028727
[23:20:04.432] iteration 3453 : model1 loss : 0.442252 model2 loss : 0.029888
[23:20:04.607] iteration 3454 : model1 loss : 0.441698 model2 loss : 0.034423
[23:20:04.784] iteration 3455 : model1 loss : 0.439149 model2 loss : 0.030958
[23:20:04.954] iteration 3456 : model1 loss : 0.440862 model2 loss : 0.029560
[23:20:05.128] iteration 3457 : model1 loss : 0.436822 model2 loss : 0.030158
[23:20:05.303] iteration 3458 : model1 loss : 0.442452 model2 loss : 0.031733
[23:20:05.479] iteration 3459 : model1 loss : 0.435510 model2 loss : 0.029685
[23:20:05.651] iteration 3460 : model1 loss : 0.441516 model2 loss : 0.029558
[23:20:05.828] iteration 3461 : model1 loss : 0.436724 model2 loss : 0.034460
[23:20:05.997] iteration 3462 : model1 loss : 0.436931 model2 loss : 0.030161
[23:20:06.175] iteration 3463 : model1 loss : 0.440556 model2 loss : 0.029889
[23:20:06.345] iteration 3464 : model1 loss : 0.442518 model2 loss : 0.035101
[23:20:06.520] iteration 3465 : model1 loss : 0.441329 model2 loss : 0.040567
[23:20:08.675] iteration 3466 : model1 loss : 0.440214 model2 loss : 0.030113
[23:20:08.851] iteration 3467 : model1 loss : 0.438141 model2 loss : 0.033612
[23:20:09.027] iteration 3468 : model1 loss : 0.442527 model2 loss : 0.029622
[23:20:09.198] iteration 3469 : model1 loss : 0.435075 model2 loss : 0.036596
[23:20:09.373] iteration 3470 : model1 loss : 0.440737 model2 loss : 0.030850
[23:20:09.545] iteration 3471 : model1 loss : 0.439757 model2 loss : 0.036412
[23:20:09.724] iteration 3472 : model1 loss : 0.440611 model2 loss : 0.034117
[23:20:09.894] iteration 3473 : model1 loss : 0.438780 model2 loss : 0.033728
[23:20:10.069] iteration 3474 : model1 loss : 0.438253 model2 loss : 0.030219
[23:20:10.242] iteration 3475 : model1 loss : 0.437036 model2 loss : 0.034175
[23:20:10.420] iteration 3476 : model1 loss : 0.441359 model2 loss : 0.032464
[23:20:10.592] iteration 3477 : model1 loss : 0.442588 model2 loss : 0.037674
[23:20:10.776] iteration 3478 : model1 loss : 0.441332 model2 loss : 0.031464
[23:20:10.944] iteration 3479 : model1 loss : 0.437520 model2 loss : 0.034843
[23:20:11.117] iteration 3480 : model1 loss : 0.445655 model2 loss : 0.042990
[23:20:11.291] iteration 3481 : model1 loss : 0.440572 model2 loss : 0.036951
[23:20:11.466] iteration 3482 : model1 loss : 0.439752 model2 loss : 0.034239
[23:20:11.638] iteration 3483 : model1 loss : 0.439061 model2 loss : 0.030215
[23:20:11.820] iteration 3484 : model1 loss : 0.439377 model2 loss : 0.030868
[23:20:11.989] iteration 3485 : model1 loss : 0.438084 model2 loss : 0.034189
[23:20:12.162] iteration 3486 : model1 loss : 0.440680 model2 loss : 0.032678
[23:20:14.322] iteration 3487 : model1 loss : 0.440259 model2 loss : 0.031967
[23:20:14.494] iteration 3488 : model1 loss : 0.438716 model2 loss : 0.026954
[23:20:14.673] iteration 3489 : model1 loss : 0.441061 model2 loss : 0.035934
[23:20:14.843] iteration 3490 : model1 loss : 0.438540 model2 loss : 0.031611
[23:20:15.018] iteration 3491 : model1 loss : 0.444569 model2 loss : 0.033802
[23:20:15.189] iteration 3492 : model1 loss : 0.437692 model2 loss : 0.040286
[23:20:15.365] iteration 3493 : model1 loss : 0.435895 model2 loss : 0.026349
[23:20:15.536] iteration 3494 : model1 loss : 0.440798 model2 loss : 0.034807
[23:20:15.714] iteration 3495 : model1 loss : 0.437637 model2 loss : 0.030897
[23:20:15.885] iteration 3496 : model1 loss : 0.438176 model2 loss : 0.030046
[23:20:16.061] iteration 3497 : model1 loss : 0.439231 model2 loss : 0.032498
[23:20:16.233] iteration 3498 : model1 loss : 0.436266 model2 loss : 0.027507
[23:20:16.413] iteration 3499 : model1 loss : 0.438577 model2 loss : 0.025858
[23:20:16.585] iteration 3500 : model1 loss : 0.439364 model2 loss : 0.036650
[23:20:16.763] iteration 3501 : model1 loss : 0.441858 model2 loss : 0.032473
[23:20:16.932] iteration 3502 : model1 loss : 0.436073 model2 loss : 0.028815
[23:20:17.107] iteration 3503 : model1 loss : 0.441430 model2 loss : 0.036205
[23:20:17.280] iteration 3504 : model1 loss : 0.441150 model2 loss : 0.036201
[23:20:17.457] iteration 3505 : model1 loss : 0.445118 model2 loss : 0.038415
[23:20:17.626] iteration 3506 : model1 loss : 0.440577 model2 loss : 0.028202
[23:20:17.800] iteration 3507 : model1 loss : 0.437403 model2 loss : 0.024971
[23:20:19.936] iteration 3508 : model1 loss : 0.435836 model2 loss : 0.028144
[23:20:20.109] iteration 3509 : model1 loss : 0.443423 model2 loss : 0.033832
[23:20:20.287] iteration 3510 : model1 loss : 0.442448 model2 loss : 0.035697
[23:20:20.458] iteration 3511 : model1 loss : 0.439791 model2 loss : 0.034839
[23:20:20.636] iteration 3512 : model1 loss : 0.434501 model2 loss : 0.028692
[23:20:20.809] iteration 3513 : model1 loss : 0.436471 model2 loss : 0.025752
[23:20:20.984] iteration 3514 : model1 loss : 0.440787 model2 loss : 0.034526
[23:20:21.155] iteration 3515 : model1 loss : 0.437803 model2 loss : 0.029670
[23:20:21.334] iteration 3516 : model1 loss : 0.441971 model2 loss : 0.033469
[23:20:21.503] iteration 3517 : model1 loss : 0.441374 model2 loss : 0.030599
[23:20:21.681] iteration 3518 : model1 loss : 0.443910 model2 loss : 0.040503
[23:20:21.852] iteration 3519 : model1 loss : 0.438940 model2 loss : 0.027062
[23:20:22.029] iteration 3520 : model1 loss : 0.438142 model2 loss : 0.031358
[23:20:22.204] iteration 3521 : model1 loss : 0.439264 model2 loss : 0.033205
[23:20:22.380] iteration 3522 : model1 loss : 0.439981 model2 loss : 0.032275
[23:20:22.553] iteration 3523 : model1 loss : 0.436884 model2 loss : 0.028776
[23:20:22.732] iteration 3524 : model1 loss : 0.433674 model2 loss : 0.029741
[23:20:22.903] iteration 3525 : model1 loss : 0.435897 model2 loss : 0.030290
[23:20:23.079] iteration 3526 : model1 loss : 0.437499 model2 loss : 0.030794
[23:20:23.251] iteration 3527 : model1 loss : 0.442870 model2 loss : 0.034673
[23:20:23.427] iteration 3528 : model1 loss : 0.438658 model2 loss : 0.027850
[23:20:25.539] iteration 3529 : model1 loss : 0.438842 model2 loss : 0.030231
[23:20:25.712] iteration 3530 : model1 loss : 0.441009 model2 loss : 0.031008
[23:20:25.889] iteration 3531 : model1 loss : 0.445157 model2 loss : 0.044474
[23:20:26.059] iteration 3532 : model1 loss : 0.441016 model2 loss : 0.029101
[23:20:26.237] iteration 3533 : model1 loss : 0.441730 model2 loss : 0.032388
[23:20:26.411] iteration 3534 : model1 loss : 0.436466 model2 loss : 0.026434
[23:20:26.591] iteration 3535 : model1 loss : 0.443224 model2 loss : 0.038526
[23:20:26.765] iteration 3536 : model1 loss : 0.440364 model2 loss : 0.037204
[23:20:26.938] iteration 3537 : model1 loss : 0.440294 model2 loss : 0.031963
[23:20:27.110] iteration 3538 : model1 loss : 0.437670 model2 loss : 0.031487
[23:20:27.286] iteration 3539 : model1 loss : 0.434783 model2 loss : 0.027351
[23:20:27.461] iteration 3540 : model1 loss : 0.440256 model2 loss : 0.031159
[23:20:27.641] iteration 3541 : model1 loss : 0.441180 model2 loss : 0.034161
[23:20:27.813] iteration 3542 : model1 loss : 0.436416 model2 loss : 0.034238
[23:20:27.988] iteration 3543 : model1 loss : 0.440120 model2 loss : 0.028094
[23:20:28.158] iteration 3544 : model1 loss : 0.448667 model2 loss : 0.031181
[23:20:28.337] iteration 3545 : model1 loss : 0.436861 model2 loss : 0.027318
[23:20:28.508] iteration 3546 : model1 loss : 0.437682 model2 loss : 0.024885
[23:20:28.688] iteration 3547 : model1 loss : 0.439800 model2 loss : 0.032667
[23:20:28.858] iteration 3548 : model1 loss : 0.439584 model2 loss : 0.028769
[23:20:29.035] iteration 3549 : model1 loss : 0.442295 model2 loss : 0.032228
[23:20:31.164] iteration 3550 : model1 loss : 0.440847 model2 loss : 0.030079
[23:20:31.344] iteration 3551 : model1 loss : 0.435627 model2 loss : 0.028614
[23:20:31.519] iteration 3552 : model1 loss : 0.442710 model2 loss : 0.030845
[23:20:31.692] iteration 3553 : model1 loss : 0.435335 model2 loss : 0.025023
[23:20:31.871] iteration 3554 : model1 loss : 0.440405 model2 loss : 0.028544
[23:20:32.041] iteration 3555 : model1 loss : 0.436110 model2 loss : 0.027143
[23:20:32.218] iteration 3556 : model1 loss : 0.444014 model2 loss : 0.031421
[23:20:32.393] iteration 3557 : model1 loss : 0.441817 model2 loss : 0.032683
[23:20:32.570] iteration 3558 : model1 loss : 0.435824 model2 loss : 0.029972
[23:20:32.745] iteration 3559 : model1 loss : 0.439517 model2 loss : 0.027268
[23:20:32.923] iteration 3560 : model1 loss : 0.441236 model2 loss : 0.035157
[23:20:33.092] iteration 3561 : model1 loss : 0.441997 model2 loss : 0.032057
[23:20:33.271] iteration 3562 : model1 loss : 0.436254 model2 loss : 0.027691
[23:20:33.443] iteration 3563 : model1 loss : 0.440939 model2 loss : 0.031729
[23:20:33.623] iteration 3564 : model1 loss : 0.437590 model2 loss : 0.026904
[23:20:33.796] iteration 3565 : model1 loss : 0.439271 model2 loss : 0.027163
[23:20:33.972] iteration 3566 : model1 loss : 0.441771 model2 loss : 0.031056
[23:20:34.141] iteration 3567 : model1 loss : 0.441221 model2 loss : 0.033963
[23:20:34.322] iteration 3568 : model1 loss : 0.439468 model2 loss : 0.028082
[23:20:34.494] iteration 3569 : model1 loss : 0.436818 model2 loss : 0.028455
[23:20:34.667] iteration 3570 : model1 loss : 0.445674 model2 loss : 0.033967
[23:20:36.780] iteration 3571 : model1 loss : 0.438477 model2 loss : 0.030021
[23:20:36.954] iteration 3572 : model1 loss : 0.438425 model2 loss : 0.025401
[23:20:37.132] iteration 3573 : model1 loss : 0.442247 model2 loss : 0.026743
[23:20:37.309] iteration 3574 : model1 loss : 0.438221 model2 loss : 0.027633
[23:20:37.492] iteration 3575 : model1 loss : 0.437549 model2 loss : 0.029533
[23:20:37.661] iteration 3576 : model1 loss : 0.441729 model2 loss : 0.032884
[23:20:37.838] iteration 3577 : model1 loss : 0.442562 model2 loss : 0.029271
[23:20:38.008] iteration 3578 : model1 loss : 0.440255 model2 loss : 0.031637
[23:20:38.185] iteration 3579 : model1 loss : 0.439156 model2 loss : 0.028836
[23:20:38.365] iteration 3580 : model1 loss : 0.440935 model2 loss : 0.031842
[23:20:38.543] iteration 3581 : model1 loss : 0.438108 model2 loss : 0.028913
[23:20:38.717] iteration 3582 : model1 loss : 0.444634 model2 loss : 0.038890
[23:20:38.894] iteration 3583 : model1 loss : 0.434302 model2 loss : 0.028934
[23:20:39.064] iteration 3584 : model1 loss : 0.438142 model2 loss : 0.029790
[23:20:39.240] iteration 3585 : model1 loss : 0.432946 model2 loss : 0.025511
[23:20:39.412] iteration 3586 : model1 loss : 0.441060 model2 loss : 0.028686
[23:20:39.594] iteration 3587 : model1 loss : 0.440716 model2 loss : 0.035223
[23:20:39.767] iteration 3588 : model1 loss : 0.433806 model2 loss : 0.027611
[23:20:39.943] iteration 3589 : model1 loss : 0.432074 model2 loss : 0.028689
[23:20:40.137] iteration 3590 : model1 loss : 0.444947 model2 loss : 0.037897
[23:20:40.315] iteration 3591 : model1 loss : 0.439771 model2 loss : 0.029878
[23:20:42.458] iteration 3592 : model1 loss : 0.445639 model2 loss : 0.031725
[23:20:42.630] iteration 3593 : model1 loss : 0.440026 model2 loss : 0.034813
[23:20:42.808] iteration 3594 : model1 loss : 0.440000 model2 loss : 0.029593
[23:20:42.978] iteration 3595 : model1 loss : 0.442021 model2 loss : 0.036897
[23:20:43.153] iteration 3596 : model1 loss : 0.445756 model2 loss : 0.039335
[23:20:43.334] iteration 3597 : model1 loss : 0.440241 model2 loss : 0.027482
[23:20:43.510] iteration 3598 : model1 loss : 0.438152 model2 loss : 0.029413
[23:20:43.682] iteration 3599 : model1 loss : 0.434371 model2 loss : 0.026016
[23:20:43.859] iteration 3600 : model1 loss : 0.435506 model2 loss : 0.028258
[23:20:44.029] iteration 3601 : model1 loss : 0.443565 model2 loss : 0.030095
[23:20:44.204] iteration 3602 : model1 loss : 0.435878 model2 loss : 0.029413
[23:20:44.379] iteration 3603 : model1 loss : 0.441050 model2 loss : 0.037994
[23:20:44.556] iteration 3604 : model1 loss : 0.439772 model2 loss : 0.032672
[23:20:44.730] iteration 3605 : model1 loss : 0.439548 model2 loss : 0.027575
[23:20:44.906] iteration 3606 : model1 loss : 0.439168 model2 loss : 0.030941
[23:20:45.075] iteration 3607 : model1 loss : 0.438771 model2 loss : 0.029154
[23:20:45.251] iteration 3608 : model1 loss : 0.440489 model2 loss : 0.028972
[23:20:45.422] iteration 3609 : model1 loss : 0.441379 model2 loss : 0.032378
[23:20:45.601] iteration 3610 : model1 loss : 0.443824 model2 loss : 0.034436
[23:20:45.774] iteration 3611 : model1 loss : 0.440488 model2 loss : 0.033201
[23:20:45.947] iteration 3612 : model1 loss : 0.436946 model2 loss : 0.030777
[23:20:48.100] iteration 3613 : model1 loss : 0.439709 model2 loss : 0.027429
[23:20:48.272] iteration 3614 : model1 loss : 0.436580 model2 loss : 0.032025
[23:20:48.450] iteration 3615 : model1 loss : 0.439461 model2 loss : 0.035252
[23:20:48.621] iteration 3616 : model1 loss : 0.437272 model2 loss : 0.027771
[23:20:48.799] iteration 3617 : model1 loss : 0.441219 model2 loss : 0.032998
[23:20:48.972] iteration 3618 : model1 loss : 0.440268 model2 loss : 0.030670
[23:20:49.147] iteration 3619 : model1 loss : 0.440863 model2 loss : 0.030452
[23:20:49.321] iteration 3620 : model1 loss : 0.442872 model2 loss : 0.035457
[23:20:49.496] iteration 3621 : model1 loss : 0.440952 model2 loss : 0.027955
[23:20:49.668] iteration 3622 : model1 loss : 0.438179 model2 loss : 0.027570
[23:20:49.847] iteration 3623 : model1 loss : 0.436717 model2 loss : 0.027228
[23:20:50.019] iteration 3624 : model1 loss : 0.441928 model2 loss : 0.029187
[23:20:50.191] iteration 3625 : model1 loss : 0.438705 model2 loss : 0.029474
[23:20:50.367] iteration 3626 : model1 loss : 0.443302 model2 loss : 0.033860
[23:20:50.542] iteration 3627 : model1 loss : 0.434590 model2 loss : 0.025396
[23:20:50.714] iteration 3628 : model1 loss : 0.441614 model2 loss : 0.035420
[23:20:50.890] iteration 3629 : model1 loss : 0.438639 model2 loss : 0.026539
[23:20:51.063] iteration 3630 : model1 loss : 0.437140 model2 loss : 0.028762
[23:20:51.240] iteration 3631 : model1 loss : 0.438990 model2 loss : 0.034353
[23:20:51.411] iteration 3632 : model1 loss : 0.436547 model2 loss : 0.028155
[23:20:51.587] iteration 3633 : model1 loss : 0.443266 model2 loss : 0.033809
[23:20:53.740] iteration 3634 : model1 loss : 0.441548 model2 loss : 0.031385
[23:20:53.915] iteration 3635 : model1 loss : 0.436937 model2 loss : 0.029298
[23:20:54.090] iteration 3636 : model1 loss : 0.435860 model2 loss : 0.031070
[23:20:54.264] iteration 3637 : model1 loss : 0.439067 model2 loss : 0.030185
[23:20:54.442] iteration 3638 : model1 loss : 0.441078 model2 loss : 0.033912
[23:20:54.615] iteration 3639 : model1 loss : 0.433833 model2 loss : 0.029067
[23:20:54.795] iteration 3640 : model1 loss : 0.438234 model2 loss : 0.031044
[23:20:54.968] iteration 3641 : model1 loss : 0.438138 model2 loss : 0.026198
[23:20:55.143] iteration 3642 : model1 loss : 0.438021 model2 loss : 0.029023
[23:20:55.322] iteration 3643 : model1 loss : 0.439164 model2 loss : 0.033078
[23:20:55.500] iteration 3644 : model1 loss : 0.434466 model2 loss : 0.024705
[23:20:55.671] iteration 3645 : model1 loss : 0.443388 model2 loss : 0.033039
[23:20:55.847] iteration 3646 : model1 loss : 0.441397 model2 loss : 0.029417
[23:20:56.018] iteration 3647 : model1 loss : 0.436217 model2 loss : 0.023146
[23:20:56.193] iteration 3648 : model1 loss : 0.440047 model2 loss : 0.031728
[23:20:56.370] iteration 3649 : model1 loss : 0.440269 model2 loss : 0.032306
[23:20:56.544] iteration 3650 : model1 loss : 0.434433 model2 loss : 0.029179
[23:20:56.719] iteration 3651 : model1 loss : 0.443036 model2 loss : 0.039166
[23:20:56.903] iteration 3652 : model1 loss : 0.440996 model2 loss : 0.027686
[23:20:57.072] iteration 3653 : model1 loss : 0.442150 model2 loss : 0.032259
[23:20:57.249] iteration 3654 : model1 loss : 0.435931 model2 loss : 0.027148
[23:20:59.427] iteration 3655 : model1 loss : 0.439398 model2 loss : 0.029138
[23:20:59.602] iteration 3656 : model1 loss : 0.438357 model2 loss : 0.028261
[23:20:59.784] iteration 3657 : model1 loss : 0.436324 model2 loss : 0.028126
[23:20:59.953] iteration 3658 : model1 loss : 0.440264 model2 loss : 0.029486
[23:21:00.139] iteration 3659 : model1 loss : 0.440525 model2 loss : 0.034265
[23:21:00.316] iteration 3660 : model1 loss : 0.439528 model2 loss : 0.029939
[23:21:00.494] iteration 3661 : model1 loss : 0.441788 model2 loss : 0.029869
[23:21:00.666] iteration 3662 : model1 loss : 0.442930 model2 loss : 0.029079
[23:21:00.843] iteration 3663 : model1 loss : 0.436621 model2 loss : 0.024982
[23:21:01.014] iteration 3664 : model1 loss : 0.437521 model2 loss : 0.031135
[23:21:01.190] iteration 3665 : model1 loss : 0.435482 model2 loss : 0.030072
[23:21:01.365] iteration 3666 : model1 loss : 0.435066 model2 loss : 0.029772
[23:21:01.542] iteration 3667 : model1 loss : 0.440704 model2 loss : 0.032771
[23:21:01.712] iteration 3668 : model1 loss : 0.437564 model2 loss : 0.031861
[23:21:01.890] iteration 3669 : model1 loss : 0.437719 model2 loss : 0.026790
[23:21:02.060] iteration 3670 : model1 loss : 0.442615 model2 loss : 0.027866
[23:21:02.235] iteration 3671 : model1 loss : 0.445366 model2 loss : 0.029692
[23:21:02.412] iteration 3672 : model1 loss : 0.434513 model2 loss : 0.026124
[23:21:02.592] iteration 3673 : model1 loss : 0.438292 model2 loss : 0.030274
[23:21:02.763] iteration 3674 : model1 loss : 0.437141 model2 loss : 0.029392
[23:21:02.935] iteration 3675 : model1 loss : 0.435896 model2 loss : 0.026231
[23:21:05.063] iteration 3676 : model1 loss : 0.434083 model2 loss : 0.026646
[23:21:05.240] iteration 3677 : model1 loss : 0.443093 model2 loss : 0.030378
[23:21:05.420] iteration 3678 : model1 loss : 0.439817 model2 loss : 0.029108
[23:21:05.592] iteration 3679 : model1 loss : 0.447382 model2 loss : 0.036278
[23:21:05.769] iteration 3680 : model1 loss : 0.438497 model2 loss : 0.029742
[23:21:05.941] iteration 3681 : model1 loss : 0.439402 model2 loss : 0.029343
[23:21:06.116] iteration 3682 : model1 loss : 0.436980 model2 loss : 0.026638
[23:21:06.291] iteration 3683 : model1 loss : 0.448389 model2 loss : 0.039982
[23:21:06.467] iteration 3684 : model1 loss : 0.436412 model2 loss : 0.029751
[23:21:06.638] iteration 3685 : model1 loss : 0.442305 model2 loss : 0.030661
[23:21:06.816] iteration 3686 : model1 loss : 0.441308 model2 loss : 0.032631
[23:21:06.990] iteration 3687 : model1 loss : 0.439472 model2 loss : 0.033301
[23:21:07.166] iteration 3688 : model1 loss : 0.438424 model2 loss : 0.027775
[23:21:07.346] iteration 3689 : model1 loss : 0.435912 model2 loss : 0.029198
[23:21:07.528] iteration 3690 : model1 loss : 0.437688 model2 loss : 0.032000
[23:21:07.698] iteration 3691 : model1 loss : 0.436322 model2 loss : 0.029877
[23:21:07.871] iteration 3692 : model1 loss : 0.437742 model2 loss : 0.028662
[23:21:08.043] iteration 3693 : model1 loss : 0.438352 model2 loss : 0.034356
[23:21:08.219] iteration 3694 : model1 loss : 0.437923 model2 loss : 0.029824
[23:21:08.394] iteration 3695 : model1 loss : 0.441304 model2 loss : 0.033078
[23:21:08.568] iteration 3696 : model1 loss : 0.435380 model2 loss : 0.027226
[23:21:10.684] iteration 3697 : model1 loss : 0.437986 model2 loss : 0.027739
[23:21:10.862] iteration 3698 : model1 loss : 0.437664 model2 loss : 0.026441
[23:21:11.036] iteration 3699 : model1 loss : 0.444008 model2 loss : 0.039087
[23:21:11.209] iteration 3700 : model1 loss : 0.436702 model2 loss : 0.028465
[23:21:11.387] iteration 3701 : model1 loss : 0.435899 model2 loss : 0.028374
[23:21:11.560] iteration 3702 : model1 loss : 0.446445 model2 loss : 0.031653
[23:21:11.737] iteration 3703 : model1 loss : 0.441901 model2 loss : 0.033215
[23:21:11.912] iteration 3704 : model1 loss : 0.440300 model2 loss : 0.032672
[23:21:12.087] iteration 3705 : model1 loss : 0.440664 model2 loss : 0.038433
[23:21:12.263] iteration 3706 : model1 loss : 0.441095 model2 loss : 0.030190
[23:21:12.444] iteration 3707 : model1 loss : 0.439528 model2 loss : 0.029116
[23:21:12.617] iteration 3708 : model1 loss : 0.440406 model2 loss : 0.029499
[23:21:12.798] iteration 3709 : model1 loss : 0.437497 model2 loss : 0.028535
[23:21:12.967] iteration 3710 : model1 loss : 0.437088 model2 loss : 0.028951
[23:21:13.143] iteration 3711 : model1 loss : 0.442914 model2 loss : 0.027524
[23:21:13.319] iteration 3712 : model1 loss : 0.437318 model2 loss : 0.028739
[23:21:13.498] iteration 3713 : model1 loss : 0.437115 model2 loss : 0.025040
[23:21:13.668] iteration 3714 : model1 loss : 0.439161 model2 loss : 0.034285
[23:21:13.844] iteration 3715 : model1 loss : 0.444325 model2 loss : 0.056785
[23:21:14.014] iteration 3716 : model1 loss : 0.442816 model2 loss : 0.032473
[23:21:14.189] iteration 3717 : model1 loss : 0.438840 model2 loss : 0.034882
[23:21:16.377] iteration 3718 : model1 loss : 0.446776 model2 loss : 0.034498
[23:21:16.547] iteration 3719 : model1 loss : 0.434322 model2 loss : 0.027911
[23:21:16.728] iteration 3720 : model1 loss : 0.444317 model2 loss : 0.031078
[23:21:16.903] iteration 3721 : model1 loss : 0.437477 model2 loss : 0.025552
[23:21:17.078] iteration 3722 : model1 loss : 0.438912 model2 loss : 0.033662
[23:21:17.246] iteration 3723 : model1 loss : 0.439133 model2 loss : 0.036118
[23:21:17.430] iteration 3724 : model1 loss : 0.438114 model2 loss : 0.028824
[23:21:17.608] iteration 3725 : model1 loss : 0.438727 model2 loss : 0.040814
[23:21:17.784] iteration 3726 : model1 loss : 0.441732 model2 loss : 0.029591
[23:21:17.956] iteration 3727 : model1 loss : 0.440897 model2 loss : 0.029068
[23:21:18.132] iteration 3728 : model1 loss : 0.436512 model2 loss : 0.027520
[23:21:18.308] iteration 3729 : model1 loss : 0.440231 model2 loss : 0.032783
[23:21:18.485] iteration 3730 : model1 loss : 0.436669 model2 loss : 0.029024
[23:21:18.658] iteration 3731 : model1 loss : 0.440793 model2 loss : 0.031276
[23:21:18.835] iteration 3732 : model1 loss : 0.439473 model2 loss : 0.031880
[23:21:19.004] iteration 3733 : model1 loss : 0.438291 model2 loss : 0.031621
[23:21:19.181] iteration 3734 : model1 loss : 0.435665 model2 loss : 0.029879
[23:21:19.357] iteration 3735 : model1 loss : 0.437713 model2 loss : 0.028476
[23:21:19.538] iteration 3736 : model1 loss : 0.435272 model2 loss : 0.029549
[23:21:19.708] iteration 3737 : model1 loss : 0.440365 model2 loss : 0.039235
[23:21:19.884] iteration 3738 : model1 loss : 0.441262 model2 loss : 0.031181
[23:21:22.002] iteration 3739 : model1 loss : 0.440831 model2 loss : 0.030603
[23:21:22.171] iteration 3740 : model1 loss : 0.437891 model2 loss : 0.027455
[23:21:22.351] iteration 3741 : model1 loss : 0.436798 model2 loss : 0.027727
[23:21:22.528] iteration 3742 : model1 loss : 0.440167 model2 loss : 0.028803
[23:21:22.704] iteration 3743 : model1 loss : 0.437957 model2 loss : 0.029498
[23:21:22.874] iteration 3744 : model1 loss : 0.441729 model2 loss : 0.032538
[23:21:23.051] iteration 3745 : model1 loss : 0.436771 model2 loss : 0.029308
[23:21:23.222] iteration 3746 : model1 loss : 0.435681 model2 loss : 0.029994
[23:21:23.398] iteration 3747 : model1 loss : 0.440309 model2 loss : 0.032017
[23:21:23.570] iteration 3748 : model1 loss : 0.439980 model2 loss : 0.038162
[23:21:23.746] iteration 3749 : model1 loss : 0.437801 model2 loss : 0.032739
[23:21:23.922] iteration 3750 : model1 loss : 0.437734 model2 loss : 0.030659
[23:21:24.098] iteration 3751 : model1 loss : 0.436289 model2 loss : 0.030622
[23:21:24.269] iteration 3752 : model1 loss : 0.436332 model2 loss : 0.029770
[23:21:24.449] iteration 3753 : model1 loss : 0.436896 model2 loss : 0.033290
[23:21:24.622] iteration 3754 : model1 loss : 0.439269 model2 loss : 0.030940
[23:21:24.799] iteration 3755 : model1 loss : 0.439999 model2 loss : 0.029563
[23:21:24.971] iteration 3756 : model1 loss : 0.443954 model2 loss : 0.040849
[23:21:25.147] iteration 3757 : model1 loss : 0.444658 model2 loss : 0.029246
[23:21:25.321] iteration 3758 : model1 loss : 0.437122 model2 loss : 0.030747
[23:21:25.498] iteration 3759 : model1 loss : 0.440446 model2 loss : 0.034427
[23:21:27.637] iteration 3760 : model1 loss : 0.436420 model2 loss : 0.028173
[23:21:27.812] iteration 3761 : model1 loss : 0.443044 model2 loss : 0.026510
[23:21:27.990] iteration 3762 : model1 loss : 0.442159 model2 loss : 0.029020
[23:21:28.161] iteration 3763 : model1 loss : 0.438086 model2 loss : 0.032643
[23:21:28.343] iteration 3764 : model1 loss : 0.439971 model2 loss : 0.030717
[23:21:28.518] iteration 3765 : model1 loss : 0.437021 model2 loss : 0.027686
[23:21:28.696] iteration 3766 : model1 loss : 0.437199 model2 loss : 0.026358
[23:21:28.870] iteration 3767 : model1 loss : 0.435409 model2 loss : 0.028147
[23:21:29.042] iteration 3768 : model1 loss : 0.440648 model2 loss : 0.030939
[23:21:29.212] iteration 3769 : model1 loss : 0.435481 model2 loss : 0.027567
[23:21:29.389] iteration 3770 : model1 loss : 0.435470 model2 loss : 0.027646
[23:21:29.561] iteration 3771 : model1 loss : 0.436008 model2 loss : 0.025356
[23:21:29.738] iteration 3772 : model1 loss : 0.443110 model2 loss : 0.028585
[23:21:29.912] iteration 3773 : model1 loss : 0.440520 model2 loss : 0.028699
[23:21:30.089] iteration 3774 : model1 loss : 0.439915 model2 loss : 0.030020
[23:21:30.261] iteration 3775 : model1 loss : 0.443519 model2 loss : 0.030229
[23:21:30.441] iteration 3776 : model1 loss : 0.436015 model2 loss : 0.028825
[23:21:30.614] iteration 3777 : model1 loss : 0.439426 model2 loss : 0.029407
[23:21:30.792] iteration 3778 : model1 loss : 0.437255 model2 loss : 0.035424
[23:21:30.963] iteration 3779 : model1 loss : 0.437030 model2 loss : 0.030932
[23:21:31.138] iteration 3780 : model1 loss : 0.446494 model2 loss : 0.042677
[23:21:33.274] iteration 3781 : model1 loss : 0.439178 model2 loss : 0.033876
[23:21:33.449] iteration 3782 : model1 loss : 0.439547 model2 loss : 0.030115
[23:21:33.630] iteration 3783 : model1 loss : 0.433726 model2 loss : 0.029518
[23:21:33.804] iteration 3784 : model1 loss : 0.442157 model2 loss : 0.038766
[23:21:33.979] iteration 3785 : model1 loss : 0.437445 model2 loss : 0.028885
[23:21:34.149] iteration 3786 : model1 loss : 0.437881 model2 loss : 0.030084
[23:21:34.334] iteration 3787 : model1 loss : 0.437600 model2 loss : 0.031356
[23:21:34.506] iteration 3788 : model1 loss : 0.444351 model2 loss : 0.035312
[23:21:34.683] iteration 3789 : model1 loss : 0.436449 model2 loss : 0.025554
[23:21:34.856] iteration 3790 : model1 loss : 0.438248 model2 loss : 0.027552
[23:21:35.030] iteration 3791 : model1 loss : 0.434475 model2 loss : 0.029574
[23:21:35.202] iteration 3792 : model1 loss : 0.438430 model2 loss : 0.027744
[23:21:35.379] iteration 3793 : model1 loss : 0.439148 model2 loss : 0.029599
[23:21:35.552] iteration 3794 : model1 loss : 0.440801 model2 loss : 0.029424
[23:21:35.728] iteration 3795 : model1 loss : 0.442377 model2 loss : 0.027938
[23:21:35.901] iteration 3796 : model1 loss : 0.437012 model2 loss : 0.028132
[23:21:36.075] iteration 3797 : model1 loss : 0.435023 model2 loss : 0.026584
[23:21:36.247] iteration 3798 : model1 loss : 0.441843 model2 loss : 0.037769
[23:21:36.426] iteration 3799 : model1 loss : 0.438939 model2 loss : 0.031882
[23:21:36.599] iteration 3800 : model1 loss : 0.444320 model2 loss : 0.039067
[23:21:36.774] iteration 3801 : model1 loss : 0.437193 model2 loss : 0.028885
[23:21:38.898] iteration 3802 : model1 loss : 0.436043 model2 loss : 0.028029
[23:21:39.074] iteration 3803 : model1 loss : 0.440546 model2 loss : 0.028155
[23:21:39.249] iteration 3804 : model1 loss : 0.437114 model2 loss : 0.029335
[23:21:39.426] iteration 3805 : model1 loss : 0.434701 model2 loss : 0.026169
[23:21:39.606] iteration 3806 : model1 loss : 0.433408 model2 loss : 0.026801
[23:21:39.778] iteration 3807 : model1 loss : 0.439913 model2 loss : 0.034388
[23:21:39.959] iteration 3808 : model1 loss : 0.438715 model2 loss : 0.031764
[23:21:40.129] iteration 3809 : model1 loss : 0.436906 model2 loss : 0.034399
[23:21:40.305] iteration 3810 : model1 loss : 0.443705 model2 loss : 0.035193
[23:21:40.480] iteration 3811 : model1 loss : 0.439250 model2 loss : 0.030360
[23:21:40.656] iteration 3812 : model1 loss : 0.441020 model2 loss : 0.029416
[23:21:40.828] iteration 3813 : model1 loss : 0.434604 model2 loss : 0.030765
[23:21:41.006] iteration 3814 : model1 loss : 0.436956 model2 loss : 0.030384
[23:21:41.179] iteration 3815 : model1 loss : 0.441647 model2 loss : 0.033600
[23:21:41.359] iteration 3816 : model1 loss : 0.442905 model2 loss : 0.041756
[23:21:41.531] iteration 3817 : model1 loss : 0.438785 model2 loss : 0.037332
[23:21:41.705] iteration 3818 : model1 loss : 0.440964 model2 loss : 0.033744
[23:21:41.878] iteration 3819 : model1 loss : 0.441539 model2 loss : 0.033735
[23:21:42.053] iteration 3820 : model1 loss : 0.435555 model2 loss : 0.029579
[23:21:42.221] iteration 3821 : model1 loss : 0.437830 model2 loss : 0.031458
[23:21:42.398] iteration 3822 : model1 loss : 0.439672 model2 loss : 0.041228
[23:21:44.555] iteration 3823 : model1 loss : 0.435470 model2 loss : 0.030465
[23:21:44.733] iteration 3824 : model1 loss : 0.437943 model2 loss : 0.029446
[23:21:44.910] iteration 3825 : model1 loss : 0.438615 model2 loss : 0.031845
[23:21:45.079] iteration 3826 : model1 loss : 0.440464 model2 loss : 0.032835
[23:21:45.256] iteration 3827 : model1 loss : 0.438483 model2 loss : 0.032190
[23:21:45.430] iteration 3828 : model1 loss : 0.436079 model2 loss : 0.037512
[23:21:45.608] iteration 3829 : model1 loss : 0.449870 model2 loss : 0.056463
[23:21:45.778] iteration 3830 : model1 loss : 0.436594 model2 loss : 0.027081
[23:21:45.954] iteration 3831 : model1 loss : 0.439308 model2 loss : 0.032486
[23:21:46.126] iteration 3832 : model1 loss : 0.438183 model2 loss : 0.029390
[23:21:46.302] iteration 3833 : model1 loss : 0.437396 model2 loss : 0.037329
[23:21:46.477] iteration 3834 : model1 loss : 0.432742 model2 loss : 0.030794
[23:21:46.659] iteration 3835 : model1 loss : 0.439181 model2 loss : 0.034695
[23:21:46.832] iteration 3836 : model1 loss : 0.442216 model2 loss : 0.048320
[23:21:47.007] iteration 3837 : model1 loss : 0.438601 model2 loss : 0.040143
[23:21:47.177] iteration 3838 : model1 loss : 0.439448 model2 loss : 0.028533
[23:21:47.359] iteration 3839 : model1 loss : 0.442077 model2 loss : 0.037531
[23:21:47.533] iteration 3840 : model1 loss : 0.441741 model2 loss : 0.057640
[23:21:47.709] iteration 3841 : model1 loss : 0.435921 model2 loss : 0.037545
[23:21:47.879] iteration 3842 : model1 loss : 0.435064 model2 loss : 0.029810
[23:21:48.054] iteration 3843 : model1 loss : 0.442640 model2 loss : 0.038211
[23:21:50.185] iteration 3844 : model1 loss : 0.433440 model2 loss : 0.030028
[23:21:50.361] iteration 3845 : model1 loss : 0.439769 model2 loss : 0.043375
[23:21:50.537] iteration 3846 : model1 loss : 0.436637 model2 loss : 0.029201
[23:21:50.707] iteration 3847 : model1 loss : 0.436656 model2 loss : 0.035110
[23:21:50.884] iteration 3848 : model1 loss : 0.437779 model2 loss : 0.031711
[23:21:51.056] iteration 3849 : model1 loss : 0.438849 model2 loss : 0.037007
[23:21:51.233] iteration 3850 : model1 loss : 0.439315 model2 loss : 0.029489
[23:21:51.407] iteration 3851 : model1 loss : 0.443044 model2 loss : 0.061157
[23:21:51.583] iteration 3852 : model1 loss : 0.434066 model2 loss : 0.027544
[23:21:51.752] iteration 3853 : model1 loss : 0.438154 model2 loss : 0.032500
[23:21:51.926] iteration 3854 : model1 loss : 0.439087 model2 loss : 0.029423
[23:21:52.096] iteration 3855 : model1 loss : 0.438513 model2 loss : 0.029489
[23:21:52.272] iteration 3856 : model1 loss : 0.435338 model2 loss : 0.032968
[23:21:52.448] iteration 3857 : model1 loss : 0.441170 model2 loss : 0.032351
[23:21:52.628] iteration 3858 : model1 loss : 0.436111 model2 loss : 0.031192
[23:21:52.799] iteration 3859 : model1 loss : 0.444031 model2 loss : 0.044003
[23:21:52.975] iteration 3860 : model1 loss : 0.437284 model2 loss : 0.028707
[23:21:53.146] iteration 3861 : model1 loss : 0.437741 model2 loss : 0.031166
[23:21:53.327] iteration 3862 : model1 loss : 0.437944 model2 loss : 0.035097
[23:21:53.499] iteration 3863 : model1 loss : 0.440255 model2 loss : 0.032842
[23:21:53.673] iteration 3864 : model1 loss : 0.439208 model2 loss : 0.037593
[23:21:55.831] iteration 3865 : model1 loss : 0.435394 model2 loss : 0.027764
[23:21:56.006] iteration 3866 : model1 loss : 0.437541 model2 loss : 0.025207
[23:21:56.184] iteration 3867 : model1 loss : 0.435277 model2 loss : 0.031098
[23:21:56.360] iteration 3868 : model1 loss : 0.443777 model2 loss : 0.033331
[23:21:56.538] iteration 3869 : model1 loss : 0.437987 model2 loss : 0.035330
[23:21:56.707] iteration 3870 : model1 loss : 0.436895 model2 loss : 0.034157
[23:21:56.884] iteration 3871 : model1 loss : 0.436189 model2 loss : 0.028766
[23:21:57.055] iteration 3872 : model1 loss : 0.433100 model2 loss : 0.031986
[23:21:57.229] iteration 3873 : model1 loss : 0.440003 model2 loss : 0.033613
[23:21:57.406] iteration 3874 : model1 loss : 0.439723 model2 loss : 0.038012
[23:21:57.584] iteration 3875 : model1 loss : 0.438681 model2 loss : 0.033034
[23:21:57.754] iteration 3876 : model1 loss : 0.436532 model2 loss : 0.029211
[23:21:57.931] iteration 3877 : model1 loss : 0.445722 model2 loss : 0.047677
[23:21:58.102] iteration 3878 : model1 loss : 0.437795 model2 loss : 0.030759
[23:21:58.276] iteration 3879 : model1 loss : 0.441144 model2 loss : 0.031936
[23:21:58.452] iteration 3880 : model1 loss : 0.442317 model2 loss : 0.035261
[23:21:58.628] iteration 3881 : model1 loss : 0.441916 model2 loss : 0.037050
[23:21:58.798] iteration 3882 : model1 loss : 0.441535 model2 loss : 0.034386
[23:21:58.976] iteration 3883 : model1 loss : 0.443315 model2 loss : 0.032494
[23:21:59.148] iteration 3884 : model1 loss : 0.440627 model2 loss : 0.033080
[23:21:59.328] iteration 3885 : model1 loss : 0.435328 model2 loss : 0.029309
[23:22:01.482] iteration 3886 : model1 loss : 0.444565 model2 loss : 0.043831
[23:22:01.655] iteration 3887 : model1 loss : 0.440183 model2 loss : 0.030991
[23:22:01.833] iteration 3888 : model1 loss : 0.433473 model2 loss : 0.029818
[23:22:02.007] iteration 3889 : model1 loss : 0.437704 model2 loss : 0.029922
[23:22:02.183] iteration 3890 : model1 loss : 0.443381 model2 loss : 0.037560
[23:22:02.358] iteration 3891 : model1 loss : 0.440357 model2 loss : 0.032677
[23:22:02.539] iteration 3892 : model1 loss : 0.433336 model2 loss : 0.027465
[23:22:02.710] iteration 3893 : model1 loss : 0.446785 model2 loss : 0.039415
[23:22:02.886] iteration 3894 : model1 loss : 0.434622 model2 loss : 0.026094
[23:22:03.057] iteration 3895 : model1 loss : 0.436383 model2 loss : 0.028876
[23:22:03.233] iteration 3896 : model1 loss : 0.435473 model2 loss : 0.028655
[23:22:03.409] iteration 3897 : model1 loss : 0.435749 model2 loss : 0.025923
[23:22:03.587] iteration 3898 : model1 loss : 0.440413 model2 loss : 0.031729
[23:22:03.760] iteration 3899 : model1 loss : 0.437190 model2 loss : 0.031043
[23:22:03.936] iteration 3900 : model1 loss : 0.440809 model2 loss : 0.035779
[23:22:04.107] iteration 3901 : model1 loss : 0.445185 model2 loss : 0.037490
[23:22:04.283] iteration 3902 : model1 loss : 0.438181 model2 loss : 0.032990
[23:22:04.459] iteration 3903 : model1 loss : 0.438925 model2 loss : 0.029013
[23:22:04.640] iteration 3904 : model1 loss : 0.437775 model2 loss : 0.027974
[23:22:04.811] iteration 3905 : model1 loss : 0.439156 model2 loss : 0.030909
[23:22:04.987] iteration 3906 : model1 loss : 0.435473 model2 loss : 0.031575
[23:22:07.107] iteration 3907 : model1 loss : 0.439641 model2 loss : 0.031863
[23:22:07.283] iteration 3908 : model1 loss : 0.438584 model2 loss : 0.028631
[23:22:07.463] iteration 3909 : model1 loss : 0.437353 model2 loss : 0.028049
[23:22:07.635] iteration 3910 : model1 loss : 0.440761 model2 loss : 0.026013
[23:22:07.813] iteration 3911 : model1 loss : 0.435590 model2 loss : 0.026766
[23:22:07.988] iteration 3912 : model1 loss : 0.438657 model2 loss : 0.035089
[23:22:08.165] iteration 3913 : model1 loss : 0.435805 model2 loss : 0.027279
[23:22:08.340] iteration 3914 : model1 loss : 0.438753 model2 loss : 0.029909
[23:22:08.517] iteration 3915 : model1 loss : 0.432335 model2 loss : 0.025910
[23:22:08.688] iteration 3916 : model1 loss : 0.435523 model2 loss : 0.026548
[23:22:08.864] iteration 3917 : model1 loss : 0.437835 model2 loss : 0.033648
[23:22:09.036] iteration 3918 : model1 loss : 0.442671 model2 loss : 0.041484
[23:22:09.210] iteration 3919 : model1 loss : 0.438363 model2 loss : 0.030352
[23:22:09.385] iteration 3920 : model1 loss : 0.437505 model2 loss : 0.027229
[23:22:09.564] iteration 3921 : model1 loss : 0.439149 model2 loss : 0.029556
[23:22:09.736] iteration 3922 : model1 loss : 0.434761 model2 loss : 0.028822
[23:22:09.911] iteration 3923 : model1 loss : 0.444768 model2 loss : 0.034421
[23:22:10.083] iteration 3924 : model1 loss : 0.439293 model2 loss : 0.028420
[23:22:10.261] iteration 3925 : model1 loss : 0.443837 model2 loss : 0.031617
[23:22:10.433] iteration 3926 : model1 loss : 0.439786 model2 loss : 0.030545
[23:22:10.609] iteration 3927 : model1 loss : 0.440118 model2 loss : 0.032316
[23:22:12.731] iteration 3928 : model1 loss : 0.434121 model2 loss : 0.032486
[23:22:12.910] iteration 3929 : model1 loss : 0.437388 model2 loss : 0.029939
[23:22:13.087] iteration 3930 : model1 loss : 0.436591 model2 loss : 0.026729
[23:22:13.260] iteration 3931 : model1 loss : 0.440349 model2 loss : 0.039695
[23:22:13.439] iteration 3932 : model1 loss : 0.441798 model2 loss : 0.032697
[23:22:13.613] iteration 3933 : model1 loss : 0.433767 model2 loss : 0.026722
[23:22:13.793] iteration 3934 : model1 loss : 0.439613 model2 loss : 0.030496
[23:22:13.965] iteration 3935 : model1 loss : 0.439283 model2 loss : 0.027560
[23:22:14.141] iteration 3936 : model1 loss : 0.443156 model2 loss : 0.033205
[23:22:14.315] iteration 3937 : model1 loss : 0.440060 model2 loss : 0.031392
[23:22:14.494] iteration 3938 : model1 loss : 0.437871 model2 loss : 0.027920
[23:22:14.665] iteration 3939 : model1 loss : 0.440622 model2 loss : 0.029222
[23:22:14.838] iteration 3940 : model1 loss : 0.437059 model2 loss : 0.031743
[23:22:15.012] iteration 3941 : model1 loss : 0.450435 model2 loss : 0.030564
[23:22:15.189] iteration 3942 : model1 loss : 0.437728 model2 loss : 0.029167
[23:22:15.361] iteration 3943 : model1 loss : 0.438765 model2 loss : 0.033143
[23:22:15.538] iteration 3944 : model1 loss : 0.440059 model2 loss : 0.028269
[23:22:15.708] iteration 3945 : model1 loss : 0.438177 model2 loss : 0.031082
[23:22:15.888] iteration 3946 : model1 loss : 0.434134 model2 loss : 0.024301
[23:22:16.058] iteration 3947 : model1 loss : 0.439108 model2 loss : 0.028710
[23:22:16.231] iteration 3948 : model1 loss : 0.437645 model2 loss : 0.030941
[23:22:18.374] iteration 3949 : model1 loss : 0.439958 model2 loss : 0.032092
[23:22:18.549] iteration 3950 : model1 loss : 0.437285 model2 loss : 0.027445
[23:22:18.724] iteration 3951 : model1 loss : 0.441127 model2 loss : 0.025235
[23:22:18.897] iteration 3952 : model1 loss : 0.439159 model2 loss : 0.033996
[23:22:19.073] iteration 3953 : model1 loss : 0.436537 model2 loss : 0.024520
[23:22:19.244] iteration 3954 : model1 loss : 0.437839 model2 loss : 0.027658
[23:22:19.423] iteration 3955 : model1 loss : 0.439798 model2 loss : 0.030122
[23:22:19.598] iteration 3956 : model1 loss : 0.435576 model2 loss : 0.027964
[23:22:19.774] iteration 3957 : model1 loss : 0.435980 model2 loss : 0.027487
[23:22:19.947] iteration 3958 : model1 loss : 0.440830 model2 loss : 0.031004
[23:22:20.127] iteration 3959 : model1 loss : 0.439175 model2 loss : 0.030666
[23:22:20.298] iteration 3960 : model1 loss : 0.440844 model2 loss : 0.032261
[23:22:20.476] iteration 3961 : model1 loss : 0.438143 model2 loss : 0.033738
[23:22:20.647] iteration 3962 : model1 loss : 0.438852 model2 loss : 0.029613
[23:22:20.824] iteration 3963 : model1 loss : 0.434297 model2 loss : 0.029086
[23:22:20.995] iteration 3964 : model1 loss : 0.443415 model2 loss : 0.035421
[23:22:21.170] iteration 3965 : model1 loss : 0.438225 model2 loss : 0.027159
[23:22:21.345] iteration 3966 : model1 loss : 0.435675 model2 loss : 0.030391
[23:22:21.524] iteration 3967 : model1 loss : 0.440591 model2 loss : 0.027731
[23:22:21.694] iteration 3968 : model1 loss : 0.442785 model2 loss : 0.029166
[23:22:21.870] iteration 3969 : model1 loss : 0.440242 model2 loss : 0.027129
[23:22:24.011] iteration 3970 : model1 loss : 0.442797 model2 loss : 0.032801
[23:22:24.184] iteration 3971 : model1 loss : 0.437251 model2 loss : 0.028454
[23:22:24.360] iteration 3972 : model1 loss : 0.445972 model2 loss : 0.041051
[23:22:24.537] iteration 3973 : model1 loss : 0.439292 model2 loss : 0.031740
[23:22:24.712] iteration 3974 : model1 loss : 0.440740 model2 loss : 0.032984
[23:22:24.882] iteration 3975 : model1 loss : 0.439920 model2 loss : 0.028258
[23:22:25.062] iteration 3976 : model1 loss : 0.436659 model2 loss : 0.032300
[23:22:25.234] iteration 3977 : model1 loss : 0.436778 model2 loss : 0.032294
[23:22:25.413] iteration 3978 : model1 loss : 0.436130 model2 loss : 0.030961
[23:22:25.586] iteration 3979 : model1 loss : 0.434234 model2 loss : 0.027517
[23:22:25.761] iteration 3980 : model1 loss : 0.440966 model2 loss : 0.028604
[23:22:25.933] iteration 3981 : model1 loss : 0.437505 model2 loss : 0.032126
[23:22:26.109] iteration 3982 : model1 loss : 0.433343 model2 loss : 0.027521
[23:22:26.280] iteration 3983 : model1 loss : 0.437997 model2 loss : 0.029555
[23:22:26.461] iteration 3984 : model1 loss : 0.442845 model2 loss : 0.032757
[23:22:26.632] iteration 3985 : model1 loss : 0.438201 model2 loss : 0.028841
[23:22:26.807] iteration 3986 : model1 loss : 0.440729 model2 loss : 0.032075
[23:22:26.982] iteration 3987 : model1 loss : 0.439993 model2 loss : 0.031343
[23:22:27.163] iteration 3988 : model1 loss : 0.435882 model2 loss : 0.038366
[23:22:27.336] iteration 3989 : model1 loss : 0.436694 model2 loss : 0.027943
[23:22:27.513] iteration 3990 : model1 loss : 0.437917 model2 loss : 0.027186
[23:22:29.633] iteration 3991 : model1 loss : 0.439602 model2 loss : 0.028665
[23:22:29.810] iteration 3992 : model1 loss : 0.438236 model2 loss : 0.031090
[23:22:29.988] iteration 3993 : model1 loss : 0.435666 model2 loss : 0.026505
[23:22:30.162] iteration 3994 : model1 loss : 0.437647 model2 loss : 0.033863
[23:22:30.341] iteration 3995 : model1 loss : 0.438979 model2 loss : 0.032855
[23:22:30.515] iteration 3996 : model1 loss : 0.444230 model2 loss : 0.034235
[23:22:30.691] iteration 3997 : model1 loss : 0.441206 model2 loss : 0.035841
[23:22:30.863] iteration 3998 : model1 loss : 0.445301 model2 loss : 0.034680
[23:22:31.039] iteration 3999 : model1 loss : 0.435450 model2 loss : 0.027809
[23:22:31.210] iteration 4000 : model1 loss : 0.436850 model2 loss : 0.026006
[23:22:40.391] iteration 4000 : model1_mean_dice : 0.775002 model1_mean_hd95 : 8.319023
[23:22:49.576] iteration 4000 : model2_mean_dice : 0.844335 model2_mean_hd95 : 13.928192
[23:22:49.764] iteration 4001 : model1 loss : 0.439648 model2 loss : 0.029926
[23:22:49.942] iteration 4002 : model1 loss : 0.437876 model2 loss : 0.030911
[23:22:50.116] iteration 4003 : model1 loss : 0.439907 model2 loss : 0.031120
[23:22:50.293] iteration 4004 : model1 loss : 0.435342 model2 loss : 0.029728
[23:22:50.463] iteration 4005 : model1 loss : 0.443233 model2 loss : 0.036254
[23:22:50.640] iteration 4006 : model1 loss : 0.435875 model2 loss : 0.027633
[23:22:50.812] iteration 4007 : model1 loss : 0.440565 model2 loss : 0.028039
[23:22:50.990] iteration 4008 : model1 loss : 0.436343 model2 loss : 0.026493
[23:22:51.161] iteration 4009 : model1 loss : 0.432617 model2 loss : 0.025261
[23:22:51.335] iteration 4010 : model1 loss : 0.431987 model2 loss : 0.027250
[23:22:51.505] iteration 4011 : model1 loss : 0.437798 model2 loss : 0.030113
[23:22:53.654] iteration 4012 : model1 loss : 0.441679 model2 loss : 0.031274
[23:22:53.827] iteration 4013 : model1 loss : 0.435735 model2 loss : 0.027649
[23:22:54.008] iteration 4014 : model1 loss : 0.437761 model2 loss : 0.029546
[23:22:54.178] iteration 4015 : model1 loss : 0.435704 model2 loss : 0.023787
[23:22:54.355] iteration 4016 : model1 loss : 0.441008 model2 loss : 0.028622
[23:22:54.527] iteration 4017 : model1 loss : 0.437141 model2 loss : 0.029302
[23:22:54.702] iteration 4018 : model1 loss : 0.445492 model2 loss : 0.031265
[23:22:54.872] iteration 4019 : model1 loss : 0.440719 model2 loss : 0.031091
[23:22:55.048] iteration 4020 : model1 loss : 0.436058 model2 loss : 0.026838
[23:22:55.217] iteration 4021 : model1 loss : 0.445789 model2 loss : 0.037125
[23:22:55.392] iteration 4022 : model1 loss : 0.438378 model2 loss : 0.029185
[23:22:55.568] iteration 4023 : model1 loss : 0.432547 model2 loss : 0.027769
[23:22:55.742] iteration 4024 : model1 loss : 0.441255 model2 loss : 0.031854
[23:22:55.912] iteration 4025 : model1 loss : 0.439085 model2 loss : 0.034878
[23:22:56.089] iteration 4026 : model1 loss : 0.442053 model2 loss : 0.031549
[23:22:56.259] iteration 4027 : model1 loss : 0.436435 model2 loss : 0.040677
[23:22:56.435] iteration 4028 : model1 loss : 0.441018 model2 loss : 0.033812
[23:22:56.612] iteration 4029 : model1 loss : 0.440105 model2 loss : 0.035215
[23:22:56.790] iteration 4030 : model1 loss : 0.438051 model2 loss : 0.038975
[23:22:56.961] iteration 4031 : model1 loss : 0.441105 model2 loss : 0.036991
[23:22:57.136] iteration 4032 : model1 loss : 0.435499 model2 loss : 0.027128
[23:22:59.274] iteration 4033 : model1 loss : 0.437866 model2 loss : 0.035859
[23:22:59.446] iteration 4034 : model1 loss : 0.447434 model2 loss : 0.035841
[23:22:59.628] iteration 4035 : model1 loss : 0.436936 model2 loss : 0.028680
[23:22:59.801] iteration 4036 : model1 loss : 0.438944 model2 loss : 0.030684
[23:22:59.981] iteration 4037 : model1 loss : 0.434680 model2 loss : 0.028673
[23:23:00.155] iteration 4038 : model1 loss : 0.445126 model2 loss : 0.034759
[23:23:00.332] iteration 4039 : model1 loss : 0.438801 model2 loss : 0.037368
[23:23:00.506] iteration 4040 : model1 loss : 0.438990 model2 loss : 0.026669
[23:23:00.682] iteration 4041 : model1 loss : 0.434277 model2 loss : 0.032051
[23:23:00.853] iteration 4042 : model1 loss : 0.437030 model2 loss : 0.029974
[23:23:01.031] iteration 4043 : model1 loss : 0.439540 model2 loss : 0.036773
[23:23:01.202] iteration 4044 : model1 loss : 0.439630 model2 loss : 0.033413
[23:23:01.376] iteration 4045 : model1 loss : 0.439936 model2 loss : 0.039674
[23:23:01.553] iteration 4046 : model1 loss : 0.435069 model2 loss : 0.027332
[23:23:01.732] iteration 4047 : model1 loss : 0.442253 model2 loss : 0.038907
[23:23:01.903] iteration 4048 : model1 loss : 0.434041 model2 loss : 0.026127
[23:23:02.076] iteration 4049 : model1 loss : 0.441116 model2 loss : 0.035059
[23:23:02.255] iteration 4050 : model1 loss : 0.444508 model2 loss : 0.035734
[23:23:02.433] iteration 4051 : model1 loss : 0.438696 model2 loss : 0.036041
[23:23:02.610] iteration 4052 : model1 loss : 0.437683 model2 loss : 0.045912
[23:23:02.786] iteration 4053 : model1 loss : 0.440204 model2 loss : 0.033469
[23:23:04.925] iteration 4054 : model1 loss : 0.434750 model2 loss : 0.026601
[23:23:05.107] iteration 4055 : model1 loss : 0.436646 model2 loss : 0.032330
[23:23:05.282] iteration 4056 : model1 loss : 0.435435 model2 loss : 0.027584
[23:23:05.450] iteration 4057 : model1 loss : 0.443210 model2 loss : 0.040861
[23:23:05.630] iteration 4058 : model1 loss : 0.437301 model2 loss : 0.033523
[23:23:05.804] iteration 4059 : model1 loss : 0.440678 model2 loss : 0.029325
[23:23:05.981] iteration 4060 : model1 loss : 0.436115 model2 loss : 0.025915
[23:23:06.152] iteration 4061 : model1 loss : 0.440275 model2 loss : 0.030657
[23:23:06.330] iteration 4062 : model1 loss : 0.442640 model2 loss : 0.031275
[23:23:06.503] iteration 4063 : model1 loss : 0.440047 model2 loss : 0.027190
[23:23:06.679] iteration 4064 : model1 loss : 0.435312 model2 loss : 0.029881
[23:23:06.850] iteration 4065 : model1 loss : 0.441635 model2 loss : 0.036082
[23:23:07.030] iteration 4066 : model1 loss : 0.437543 model2 loss : 0.028548
[23:23:07.201] iteration 4067 : model1 loss : 0.439239 model2 loss : 0.035108
[23:23:07.375] iteration 4068 : model1 loss : 0.437357 model2 loss : 0.028291
[23:23:07.551] iteration 4069 : model1 loss : 0.441131 model2 loss : 0.032886
[23:23:07.728] iteration 4070 : model1 loss : 0.438168 model2 loss : 0.029909
[23:23:07.901] iteration 4071 : model1 loss : 0.437275 model2 loss : 0.030297
[23:23:08.078] iteration 4072 : model1 loss : 0.437195 model2 loss : 0.029916
[23:23:08.246] iteration 4073 : model1 loss : 0.435967 model2 loss : 0.032163
[23:23:08.421] iteration 4074 : model1 loss : 0.442887 model2 loss : 0.034786
[23:23:10.615] iteration 4075 : model1 loss : 0.438430 model2 loss : 0.028143
[23:23:10.787] iteration 4076 : model1 loss : 0.439417 model2 loss : 0.037691
[23:23:10.965] iteration 4077 : model1 loss : 0.434617 model2 loss : 0.028280
[23:23:11.139] iteration 4078 : model1 loss : 0.436526 model2 loss : 0.025412
[23:23:11.318] iteration 4079 : model1 loss : 0.442395 model2 loss : 0.029658
[23:23:11.488] iteration 4080 : model1 loss : 0.438560 model2 loss : 0.025304
[23:23:11.663] iteration 4081 : model1 loss : 0.435635 model2 loss : 0.028295
[23:23:11.834] iteration 4082 : model1 loss : 0.439407 model2 loss : 0.032663
[23:23:12.011] iteration 4083 : model1 loss : 0.441067 model2 loss : 0.031129
[23:23:12.182] iteration 4084 : model1 loss : 0.436628 model2 loss : 0.029262
[23:23:12.360] iteration 4085 : model1 loss : 0.438499 model2 loss : 0.027399
[23:23:12.533] iteration 4086 : model1 loss : 0.435026 model2 loss : 0.024864
[23:23:12.708] iteration 4087 : model1 loss : 0.433317 model2 loss : 0.026886
[23:23:12.878] iteration 4088 : model1 loss : 0.437678 model2 loss : 0.030905
[23:23:13.055] iteration 4089 : model1 loss : 0.441734 model2 loss : 0.031258
[23:23:13.227] iteration 4090 : model1 loss : 0.436307 model2 loss : 0.027149
[23:23:13.403] iteration 4091 : model1 loss : 0.442743 model2 loss : 0.035415
[23:23:13.577] iteration 4092 : model1 loss : 0.441100 model2 loss : 0.035384
[23:23:13.753] iteration 4093 : model1 loss : 0.438644 model2 loss : 0.030221
[23:23:13.922] iteration 4094 : model1 loss : 0.433857 model2 loss : 0.027280
[23:23:14.097] iteration 4095 : model1 loss : 0.442407 model2 loss : 0.031782
[23:23:16.246] iteration 4096 : model1 loss : 0.437363 model2 loss : 0.036260
[23:23:16.416] iteration 4097 : model1 loss : 0.440921 model2 loss : 0.033453
[23:23:16.596] iteration 4098 : model1 loss : 0.436802 model2 loss : 0.027122
[23:23:16.766] iteration 4099 : model1 loss : 0.440419 model2 loss : 0.030908
[23:23:16.939] iteration 4100 : model1 loss : 0.434412 model2 loss : 0.027395
[23:23:17.112] iteration 4101 : model1 loss : 0.439094 model2 loss : 0.031124
[23:23:17.288] iteration 4102 : model1 loss : 0.441901 model2 loss : 0.034157
[23:23:17.460] iteration 4103 : model1 loss : 0.438529 model2 loss : 0.029917
[23:23:17.640] iteration 4104 : model1 loss : 0.442410 model2 loss : 0.032856
[23:23:17.810] iteration 4105 : model1 loss : 0.438672 model2 loss : 0.029081
[23:23:17.987] iteration 4106 : model1 loss : 0.442301 model2 loss : 0.037355
[23:23:18.159] iteration 4107 : model1 loss : 0.433049 model2 loss : 0.029341
[23:23:18.335] iteration 4108 : model1 loss : 0.444401 model2 loss : 0.027716
[23:23:18.507] iteration 4109 : model1 loss : 0.443167 model2 loss : 0.037053
[23:23:18.685] iteration 4110 : model1 loss : 0.439500 model2 loss : 0.030547
[23:23:18.856] iteration 4111 : model1 loss : 0.440388 model2 loss : 0.031388
[23:23:19.031] iteration 4112 : model1 loss : 0.441890 model2 loss : 0.029490
[23:23:19.202] iteration 4113 : model1 loss : 0.435478 model2 loss : 0.025262
[23:23:19.375] iteration 4114 : model1 loss : 0.438126 model2 loss : 0.027195
[23:23:19.548] iteration 4115 : model1 loss : 0.434545 model2 loss : 0.027410
[23:23:19.723] iteration 4116 : model1 loss : 0.438810 model2 loss : 0.029700
[23:23:21.824] iteration 4117 : model1 loss : 0.439709 model2 loss : 0.031989
[23:23:21.996] iteration 4118 : model1 loss : 0.433916 model2 loss : 0.027429
[23:23:22.176] iteration 4119 : model1 loss : 0.443632 model2 loss : 0.042139
[23:23:22.352] iteration 4120 : model1 loss : 0.437884 model2 loss : 0.029679
[23:23:22.532] iteration 4121 : model1 loss : 0.438975 model2 loss : 0.029465
[23:23:22.702] iteration 4122 : model1 loss : 0.438119 model2 loss : 0.027487
[23:23:22.878] iteration 4123 : model1 loss : 0.437588 model2 loss : 0.028534
[23:23:23.050] iteration 4124 : model1 loss : 0.434947 model2 loss : 0.033667
[23:23:23.228] iteration 4125 : model1 loss : 0.435725 model2 loss : 0.027683
[23:23:23.398] iteration 4126 : model1 loss : 0.439069 model2 loss : 0.027851
[23:23:23.576] iteration 4127 : model1 loss : 0.440768 model2 loss : 0.031042
[23:23:23.749] iteration 4128 : model1 loss : 0.441863 model2 loss : 0.029029
[23:23:23.925] iteration 4129 : model1 loss : 0.440167 model2 loss : 0.030911
[23:23:24.104] iteration 4130 : model1 loss : 0.439070 model2 loss : 0.032072
[23:23:24.280] iteration 4131 : model1 loss : 0.439637 model2 loss : 0.033319
[23:23:24.450] iteration 4132 : model1 loss : 0.444005 model2 loss : 0.036218
[23:23:24.629] iteration 4133 : model1 loss : 0.446235 model2 loss : 0.040580
[23:23:24.800] iteration 4134 : model1 loss : 0.445184 model2 loss : 0.032547
[23:23:24.975] iteration 4135 : model1 loss : 0.439818 model2 loss : 0.035049
[23:23:25.145] iteration 4136 : model1 loss : 0.434930 model2 loss : 0.029027
[23:23:25.321] iteration 4137 : model1 loss : 0.436596 model2 loss : 0.030607
[23:23:27.444] iteration 4138 : model1 loss : 0.442050 model2 loss : 0.026766
[23:23:27.624] iteration 4139 : model1 loss : 0.442367 model2 loss : 0.032076
[23:23:27.803] iteration 4140 : model1 loss : 0.441166 model2 loss : 0.032945
[23:23:27.974] iteration 4141 : model1 loss : 0.441814 model2 loss : 0.029258
[23:23:28.151] iteration 4142 : model1 loss : 0.438314 model2 loss : 0.030158
[23:23:28.329] iteration 4143 : model1 loss : 0.439115 model2 loss : 0.027902
[23:23:28.505] iteration 4144 : model1 loss : 0.439194 model2 loss : 0.029180
[23:23:28.680] iteration 4145 : model1 loss : 0.439451 model2 loss : 0.025620
[23:23:28.858] iteration 4146 : model1 loss : 0.438203 model2 loss : 0.027696
[23:23:29.029] iteration 4147 : model1 loss : 0.439820 model2 loss : 0.028408
[23:23:29.204] iteration 4148 : model1 loss : 0.447138 model2 loss : 0.036997
[23:23:29.374] iteration 4149 : model1 loss : 0.439640 model2 loss : 0.029071
[23:23:29.551] iteration 4150 : model1 loss : 0.439427 model2 loss : 0.029520
[23:23:29.722] iteration 4151 : model1 loss : 0.439409 model2 loss : 0.030108
[23:23:29.900] iteration 4152 : model1 loss : 0.436179 model2 loss : 0.027607
[23:23:30.073] iteration 4153 : model1 loss : 0.442501 model2 loss : 0.030226
[23:23:30.246] iteration 4154 : model1 loss : 0.432617 model2 loss : 0.024364
[23:23:30.416] iteration 4155 : model1 loss : 0.438101 model2 loss : 0.032164
[23:23:30.596] iteration 4156 : model1 loss : 0.440653 model2 loss : 0.030859
[23:23:30.766] iteration 4157 : model1 loss : 0.436511 model2 loss : 0.027831
[23:23:30.938] iteration 4158 : model1 loss : 0.436644 model2 loss : 0.029883
[23:23:33.115] iteration 4159 : model1 loss : 0.435142 model2 loss : 0.028378
[23:23:33.291] iteration 4160 : model1 loss : 0.435916 model2 loss : 0.024325
[23:23:33.467] iteration 4161 : model1 loss : 0.438096 model2 loss : 0.032761
[23:23:33.639] iteration 4162 : model1 loss : 0.440236 model2 loss : 0.028991
[23:23:33.817] iteration 4163 : model1 loss : 0.440085 model2 loss : 0.029078
[23:23:33.988] iteration 4164 : model1 loss : 0.441600 model2 loss : 0.029284
[23:23:34.164] iteration 4165 : model1 loss : 0.437822 model2 loss : 0.028636
[23:23:34.338] iteration 4166 : model1 loss : 0.436437 model2 loss : 0.028868
[23:23:34.512] iteration 4167 : model1 loss : 0.438939 model2 loss : 0.026726
[23:23:34.685] iteration 4168 : model1 loss : 0.442625 model2 loss : 0.025289
[23:23:34.861] iteration 4169 : model1 loss : 0.439122 model2 loss : 0.030402
[23:23:35.032] iteration 4170 : model1 loss : 0.436651 model2 loss : 0.027978
[23:23:35.208] iteration 4171 : model1 loss : 0.441964 model2 loss : 0.035757
[23:23:35.379] iteration 4172 : model1 loss : 0.438576 model2 loss : 0.031731
[23:23:35.555] iteration 4173 : model1 loss : 0.444742 model2 loss : 0.032373
[23:23:35.728] iteration 4174 : model1 loss : 0.440152 model2 loss : 0.024872
[23:23:35.901] iteration 4175 : model1 loss : 0.431150 model2 loss : 0.026177
[23:23:36.074] iteration 4176 : model1 loss : 0.438709 model2 loss : 0.030122
[23:23:36.250] iteration 4177 : model1 loss : 0.436806 model2 loss : 0.025758
[23:23:36.419] iteration 4178 : model1 loss : 0.437577 model2 loss : 0.031533
[23:23:36.596] iteration 4179 : model1 loss : 0.436432 model2 loss : 0.027802
[23:23:38.733] iteration 4180 : model1 loss : 0.438754 model2 loss : 0.029755
[23:23:38.904] iteration 4181 : model1 loss : 0.443778 model2 loss : 0.031619
[23:23:39.081] iteration 4182 : model1 loss : 0.442972 model2 loss : 0.034103
[23:23:39.252] iteration 4183 : model1 loss : 0.436490 model2 loss : 0.031405
[23:23:39.429] iteration 4184 : model1 loss : 0.438393 model2 loss : 0.024542
[23:23:39.607] iteration 4185 : model1 loss : 0.439750 model2 loss : 0.027398
[23:23:39.781] iteration 4186 : model1 loss : 0.433160 model2 loss : 0.025602
[23:23:39.952] iteration 4187 : model1 loss : 0.446513 model2 loss : 0.034296
[23:23:40.130] iteration 4188 : model1 loss : 0.439459 model2 loss : 0.026658
[23:23:40.303] iteration 4189 : model1 loss : 0.437335 model2 loss : 0.025523
[23:23:40.476] iteration 4190 : model1 loss : 0.438079 model2 loss : 0.028988
[23:23:40.650] iteration 4191 : model1 loss : 0.438968 model2 loss : 0.029127
[23:23:40.827] iteration 4192 : model1 loss : 0.441756 model2 loss : 0.033426
[23:23:40.998] iteration 4193 : model1 loss : 0.435340 model2 loss : 0.024348
[23:23:41.175] iteration 4194 : model1 loss : 0.437860 model2 loss : 0.035054
[23:23:41.348] iteration 4195 : model1 loss : 0.434741 model2 loss : 0.028124
[23:23:41.524] iteration 4196 : model1 loss : 0.440022 model2 loss : 0.032876
[23:23:41.699] iteration 4197 : model1 loss : 0.445687 model2 loss : 0.033108
[23:23:41.875] iteration 4198 : model1 loss : 0.443109 model2 loss : 0.035310
[23:23:42.046] iteration 4199 : model1 loss : 0.433548 model2 loss : 0.031641
[23:23:42.221] iteration 4200 : model1 loss : 0.432125 model2 loss : 0.024578
[23:23:44.361] iteration 4201 : model1 loss : 0.435217 model2 loss : 0.026380
[23:23:44.532] iteration 4202 : model1 loss : 0.443329 model2 loss : 0.032934
[23:23:44.715] iteration 4203 : model1 loss : 0.437932 model2 loss : 0.031013
[23:23:44.885] iteration 4204 : model1 loss : 0.444598 model2 loss : 0.030266
[23:23:45.063] iteration 4205 : model1 loss : 0.440140 model2 loss : 0.030925
[23:23:45.235] iteration 4206 : model1 loss : 0.442810 model2 loss : 0.032419
[23:23:45.410] iteration 4207 : model1 loss : 0.432797 model2 loss : 0.024670
[23:23:45.582] iteration 4208 : model1 loss : 0.438141 model2 loss : 0.027825
[23:23:45.760] iteration 4209 : model1 loss : 0.439984 model2 loss : 0.028794
[23:23:45.927] iteration 4210 : model1 loss : 0.438677 model2 loss : 0.024644
[23:23:46.105] iteration 4211 : model1 loss : 0.439397 model2 loss : 0.032142
[23:23:46.276] iteration 4212 : model1 loss : 0.437409 model2 loss : 0.026694
[23:23:46.449] iteration 4213 : model1 loss : 0.441567 model2 loss : 0.033464
[23:23:46.634] iteration 4214 : model1 loss : 0.438643 model2 loss : 0.028110
[23:23:46.810] iteration 4215 : model1 loss : 0.435334 model2 loss : 0.028014
[23:23:46.979] iteration 4216 : model1 loss : 0.439466 model2 loss : 0.025115
[23:23:47.155] iteration 4217 : model1 loss : 0.443140 model2 loss : 0.031068
[23:23:47.330] iteration 4218 : model1 loss : 0.438950 model2 loss : 0.028411
[23:23:47.511] iteration 4219 : model1 loss : 0.438280 model2 loss : 0.031024
[23:23:47.684] iteration 4220 : model1 loss : 0.440382 model2 loss : 0.028612
[23:23:47.859] iteration 4221 : model1 loss : 0.436513 model2 loss : 0.024803
[23:23:50.029] iteration 4222 : model1 loss : 0.438654 model2 loss : 0.027854
[23:23:50.208] iteration 4223 : model1 loss : 0.440779 model2 loss : 0.031807
[23:23:50.383] iteration 4224 : model1 loss : 0.438229 model2 loss : 0.026369
[23:23:50.554] iteration 4225 : model1 loss : 0.438441 model2 loss : 0.028872
[23:23:50.731] iteration 4226 : model1 loss : 0.438533 model2 loss : 0.029201
[23:23:50.903] iteration 4227 : model1 loss : 0.432332 model2 loss : 0.024859
[23:23:51.080] iteration 4228 : model1 loss : 0.440960 model2 loss : 0.029341
[23:23:51.252] iteration 4229 : model1 loss : 0.436103 model2 loss : 0.025393
[23:23:51.425] iteration 4230 : model1 loss : 0.438464 model2 loss : 0.024949
[23:23:51.602] iteration 4231 : model1 loss : 0.436814 model2 loss : 0.027328
[23:23:51.778] iteration 4232 : model1 loss : 0.438297 model2 loss : 0.030191
[23:23:51.948] iteration 4233 : model1 loss : 0.435169 model2 loss : 0.025793
[23:23:52.128] iteration 4234 : model1 loss : 0.440183 model2 loss : 0.030121
[23:23:52.299] iteration 4235 : model1 loss : 0.437223 model2 loss : 0.028335
[23:23:52.475] iteration 4236 : model1 loss : 0.441790 model2 loss : 0.029889
[23:23:52.648] iteration 4237 : model1 loss : 0.440035 model2 loss : 0.030643
[23:23:52.827] iteration 4238 : model1 loss : 0.442833 model2 loss : 0.027711
[23:23:52.997] iteration 4239 : model1 loss : 0.436642 model2 loss : 0.029799
[23:23:53.174] iteration 4240 : model1 loss : 0.440554 model2 loss : 0.029446
[23:23:53.344] iteration 4241 : model1 loss : 0.439144 model2 loss : 0.029709
[23:23:53.518] iteration 4242 : model1 loss : 0.442145 model2 loss : 0.028689
[23:23:55.673] iteration 4243 : model1 loss : 0.444968 model2 loss : 0.033481
[23:23:55.844] iteration 4244 : model1 loss : 0.436872 model2 loss : 0.024504
[23:23:56.021] iteration 4245 : model1 loss : 0.437709 model2 loss : 0.030629
[23:23:56.194] iteration 4246 : model1 loss : 0.437517 model2 loss : 0.030002
[23:23:56.375] iteration 4247 : model1 loss : 0.437270 model2 loss : 0.029571
[23:23:56.546] iteration 4248 : model1 loss : 0.437690 model2 loss : 0.028961
[23:23:56.723] iteration 4249 : model1 loss : 0.435268 model2 loss : 0.022572
[23:23:56.894] iteration 4250 : model1 loss : 0.437700 model2 loss : 0.023758
[23:23:57.068] iteration 4251 : model1 loss : 0.441361 model2 loss : 0.030654
[23:23:57.239] iteration 4252 : model1 loss : 0.435917 model2 loss : 0.027012
[23:23:57.419] iteration 4253 : model1 loss : 0.436932 model2 loss : 0.028049
[23:23:57.592] iteration 4254 : model1 loss : 0.443422 model2 loss : 0.027075
[23:23:57.768] iteration 4255 : model1 loss : 0.439041 model2 loss : 0.027645
[23:23:57.937] iteration 4256 : model1 loss : 0.435720 model2 loss : 0.030591
[23:23:58.118] iteration 4257 : model1 loss : 0.432385 model2 loss : 0.034321
[23:23:58.288] iteration 4258 : model1 loss : 0.441354 model2 loss : 0.033473
[23:23:58.464] iteration 4259 : model1 loss : 0.443356 model2 loss : 0.028484
[23:23:58.640] iteration 4260 : model1 loss : 0.440492 model2 loss : 0.029837
[23:23:58.816] iteration 4261 : model1 loss : 0.443111 model2 loss : 0.031362
[23:23:58.984] iteration 4262 : model1 loss : 0.436851 model2 loss : 0.028464
[23:23:59.159] iteration 4263 : model1 loss : 0.435734 model2 loss : 0.027607
[23:24:01.354] iteration 4264 : model1 loss : 0.438431 model2 loss : 0.028488
[23:24:01.533] iteration 4265 : model1 loss : 0.440166 model2 loss : 0.026908
[23:24:01.711] iteration 4266 : model1 loss : 0.438511 model2 loss : 0.029106
[23:24:01.880] iteration 4267 : model1 loss : 0.436190 model2 loss : 0.025112
[23:24:02.054] iteration 4268 : model1 loss : 0.437509 model2 loss : 0.027198
[23:24:02.227] iteration 4269 : model1 loss : 0.447274 model2 loss : 0.031657
[23:24:02.405] iteration 4270 : model1 loss : 0.437164 model2 loss : 0.026500
[23:24:02.580] iteration 4271 : model1 loss : 0.437019 model2 loss : 0.029096
[23:24:02.760] iteration 4272 : model1 loss : 0.439088 model2 loss : 0.023797
[23:24:02.931] iteration 4273 : model1 loss : 0.439803 model2 loss : 0.028555
[23:24:03.107] iteration 4274 : model1 loss : 0.435041 model2 loss : 0.027741
[23:24:03.279] iteration 4275 : model1 loss : 0.437135 model2 loss : 0.028461
[23:24:03.456] iteration 4276 : model1 loss : 0.437990 model2 loss : 0.026971
[23:24:03.631] iteration 4277 : model1 loss : 0.439465 model2 loss : 0.027527
[23:24:03.807] iteration 4278 : model1 loss : 0.431613 model2 loss : 0.026950
[23:24:03.979] iteration 4279 : model1 loss : 0.435998 model2 loss : 0.025422
[23:24:04.156] iteration 4280 : model1 loss : 0.435705 model2 loss : 0.030034
[23:24:04.330] iteration 4281 : model1 loss : 0.440556 model2 loss : 0.028934
[23:24:04.505] iteration 4282 : model1 loss : 0.447063 model2 loss : 0.028908
[23:24:04.677] iteration 4283 : model1 loss : 0.439301 model2 loss : 0.027890
[23:24:04.850] iteration 4284 : model1 loss : 0.437337 model2 loss : 0.029084
[23:24:07.000] iteration 4285 : model1 loss : 0.437035 model2 loss : 0.026971
[23:24:07.176] iteration 4286 : model1 loss : 0.437567 model2 loss : 0.028095
[23:24:07.355] iteration 4287 : model1 loss : 0.435824 model2 loss : 0.029408
[23:24:07.528] iteration 4288 : model1 loss : 0.437537 model2 loss : 0.031071
[23:24:07.704] iteration 4289 : model1 loss : 0.440346 model2 loss : 0.027140
[23:24:07.874] iteration 4290 : model1 loss : 0.440110 model2 loss : 0.027288
[23:24:08.051] iteration 4291 : model1 loss : 0.440435 model2 loss : 0.030071
[23:24:08.225] iteration 4292 : model1 loss : 0.438693 model2 loss : 0.031725
[23:24:08.401] iteration 4293 : model1 loss : 0.438002 model2 loss : 0.028792
[23:24:08.573] iteration 4294 : model1 loss : 0.440610 model2 loss : 0.029003
[23:24:08.751] iteration 4295 : model1 loss : 0.444786 model2 loss : 0.030189
[23:24:08.933] iteration 4296 : model1 loss : 0.436084 model2 loss : 0.028032
[23:24:09.112] iteration 4297 : model1 loss : 0.438701 model2 loss : 0.026204
[23:24:09.282] iteration 4298 : model1 loss : 0.439919 model2 loss : 0.030074
[23:24:09.457] iteration 4299 : model1 loss : 0.435931 model2 loss : 0.024092
[23:24:09.633] iteration 4300 : model1 loss : 0.438937 model2 loss : 0.031112
[23:24:09.809] iteration 4301 : model1 loss : 0.442583 model2 loss : 0.036166
[23:24:09.981] iteration 4302 : model1 loss : 0.439098 model2 loss : 0.028407
[23:24:10.162] iteration 4303 : model1 loss : 0.435109 model2 loss : 0.025034
[23:24:10.334] iteration 4304 : model1 loss : 0.438410 model2 loss : 0.029098
[23:24:10.507] iteration 4305 : model1 loss : 0.437317 model2 loss : 0.027109
[23:24:12.701] iteration 4306 : model1 loss : 0.439557 model2 loss : 0.029822
[23:24:12.876] iteration 4307 : model1 loss : 0.442447 model2 loss : 0.032339
[23:24:13.052] iteration 4308 : model1 loss : 0.435997 model2 loss : 0.028548
[23:24:13.226] iteration 4309 : model1 loss : 0.437835 model2 loss : 0.031346
[23:24:13.403] iteration 4310 : model1 loss : 0.440663 model2 loss : 0.028242
[23:24:13.575] iteration 4311 : model1 loss : 0.442836 model2 loss : 0.025189
[23:24:13.750] iteration 4312 : model1 loss : 0.440683 model2 loss : 0.029527
[23:24:13.920] iteration 4313 : model1 loss : 0.438875 model2 loss : 0.030243
[23:24:14.095] iteration 4314 : model1 loss : 0.443455 model2 loss : 0.029719
[23:24:14.269] iteration 4315 : model1 loss : 0.440137 model2 loss : 0.026034
[23:24:14.445] iteration 4316 : model1 loss : 0.439011 model2 loss : 0.027617
[23:24:14.621] iteration 4317 : model1 loss : 0.438336 model2 loss : 0.031066
[23:24:14.802] iteration 4318 : model1 loss : 0.431851 model2 loss : 0.026547
[23:24:14.970] iteration 4319 : model1 loss : 0.443172 model2 loss : 0.033301
[23:24:15.145] iteration 4320 : model1 loss : 0.437004 model2 loss : 0.026467
[23:24:15.319] iteration 4321 : model1 loss : 0.441288 model2 loss : 0.029092
[23:24:15.496] iteration 4322 : model1 loss : 0.441035 model2 loss : 0.029215
[23:24:15.670] iteration 4323 : model1 loss : 0.435087 model2 loss : 0.028846
[23:24:15.846] iteration 4324 : model1 loss : 0.438824 model2 loss : 0.028439
[23:24:16.016] iteration 4325 : model1 loss : 0.434789 model2 loss : 0.026242
[23:24:16.193] iteration 4326 : model1 loss : 0.437175 model2 loss : 0.024675
[23:24:18.335] iteration 4327 : model1 loss : 0.439585 model2 loss : 0.033539
[23:24:18.508] iteration 4328 : model1 loss : 0.435887 model2 loss : 0.027919
[23:24:18.687] iteration 4329 : model1 loss : 0.435613 model2 loss : 0.028205
[23:24:18.857] iteration 4330 : model1 loss : 0.439308 model2 loss : 0.027188
[23:24:19.035] iteration 4331 : model1 loss : 0.441158 model2 loss : 0.026944
[23:24:19.209] iteration 4332 : model1 loss : 0.436271 model2 loss : 0.026291
[23:24:19.384] iteration 4333 : model1 loss : 0.437140 model2 loss : 0.024711
[23:24:19.554] iteration 4334 : model1 loss : 0.436022 model2 loss : 0.024605
[23:24:19.730] iteration 4335 : model1 loss : 0.436712 model2 loss : 0.026683
[23:24:19.901] iteration 4336 : model1 loss : 0.436942 model2 loss : 0.028532
[23:24:20.075] iteration 4337 : model1 loss : 0.442696 model2 loss : 0.029416
[23:24:20.247] iteration 4338 : model1 loss : 0.439068 model2 loss : 0.023991
[23:24:20.425] iteration 4339 : model1 loss : 0.437173 model2 loss : 0.026498
[23:24:20.600] iteration 4340 : model1 loss : 0.437908 model2 loss : 0.026922
[23:24:20.777] iteration 4341 : model1 loss : 0.440855 model2 loss : 0.033050
[23:24:20.951] iteration 4342 : model1 loss : 0.440631 model2 loss : 0.028588
[23:24:21.129] iteration 4343 : model1 loss : 0.437564 model2 loss : 0.030782
[23:24:21.304] iteration 4344 : model1 loss : 0.442652 model2 loss : 0.031958
[23:24:21.477] iteration 4345 : model1 loss : 0.439658 model2 loss : 0.030711
[23:24:21.646] iteration 4346 : model1 loss : 0.439295 model2 loss : 0.023524
[23:24:21.823] iteration 4347 : model1 loss : 0.436866 model2 loss : 0.029477
[23:24:24.017] iteration 4348 : model1 loss : 0.440220 model2 loss : 0.031358
[23:24:24.193] iteration 4349 : model1 loss : 0.437055 model2 loss : 0.029996
[23:24:24.371] iteration 4350 : model1 loss : 0.436106 model2 loss : 0.029423
[23:24:24.541] iteration 4351 : model1 loss : 0.446211 model2 loss : 0.036870
[23:24:24.719] iteration 4352 : model1 loss : 0.434471 model2 loss : 0.027201
[23:24:24.889] iteration 4353 : model1 loss : 0.435232 model2 loss : 0.025960
[23:24:25.076] iteration 4354 : model1 loss : 0.441414 model2 loss : 0.030870
[23:24:25.249] iteration 4355 : model1 loss : 0.436338 model2 loss : 0.025375
[23:24:25.426] iteration 4356 : model1 loss : 0.443164 model2 loss : 0.032297
[23:24:25.600] iteration 4357 : model1 loss : 0.441277 model2 loss : 0.028428
[23:24:25.779] iteration 4358 : model1 loss : 0.438454 model2 loss : 0.028022
[23:24:25.950] iteration 4359 : model1 loss : 0.435426 model2 loss : 0.025354
[23:24:26.139] iteration 4360 : model1 loss : 0.440483 model2 loss : 0.027630
[23:24:26.313] iteration 4361 : model1 loss : 0.436374 model2 loss : 0.026886
[23:24:26.492] iteration 4362 : model1 loss : 0.436157 model2 loss : 0.030745
[23:24:26.663] iteration 4363 : model1 loss : 0.439610 model2 loss : 0.030263
[23:24:26.838] iteration 4364 : model1 loss : 0.440530 model2 loss : 0.027642
[23:24:27.008] iteration 4365 : model1 loss : 0.440742 model2 loss : 0.025473
[23:24:27.184] iteration 4366 : model1 loss : 0.435538 model2 loss : 0.025364
[23:24:27.356] iteration 4367 : model1 loss : 0.440306 model2 loss : 0.029275
[23:24:27.530] iteration 4368 : model1 loss : 0.437189 model2 loss : 0.028927
[23:24:29.636] iteration 4369 : model1 loss : 0.438459 model2 loss : 0.027180
[23:24:29.814] iteration 4370 : model1 loss : 0.434145 model2 loss : 0.025097
[23:24:29.991] iteration 4371 : model1 loss : 0.437679 model2 loss : 0.027045
[23:24:30.161] iteration 4372 : model1 loss : 0.440903 model2 loss : 0.030211
[23:24:30.342] iteration 4373 : model1 loss : 0.442723 model2 loss : 0.032711
[23:24:30.513] iteration 4374 : model1 loss : 0.440677 model2 loss : 0.030846
[23:24:30.692] iteration 4375 : model1 loss : 0.440463 model2 loss : 0.031163
[23:24:30.862] iteration 4376 : model1 loss : 0.441722 model2 loss : 0.034955
[23:24:31.037] iteration 4377 : model1 loss : 0.437667 model2 loss : 0.025586
[23:24:31.211] iteration 4378 : model1 loss : 0.439842 model2 loss : 0.030478
[23:24:31.390] iteration 4379 : model1 loss : 0.436916 model2 loss : 0.024580
[23:24:31.560] iteration 4380 : model1 loss : 0.438649 model2 loss : 0.028196
[23:24:31.737] iteration 4381 : model1 loss : 0.438790 model2 loss : 0.029476
[23:24:31.907] iteration 4382 : model1 loss : 0.435272 model2 loss : 0.027972
[23:24:32.083] iteration 4383 : model1 loss : 0.433456 model2 loss : 0.025131
[23:24:32.256] iteration 4384 : model1 loss : 0.433525 model2 loss : 0.027043
[23:24:32.432] iteration 4385 : model1 loss : 0.438735 model2 loss : 0.028237
[23:24:32.607] iteration 4386 : model1 loss : 0.436125 model2 loss : 0.027997
[23:24:32.782] iteration 4387 : model1 loss : 0.441335 model2 loss : 0.029164
[23:24:32.951] iteration 4388 : model1 loss : 0.437450 model2 loss : 0.030311
[23:24:33.127] iteration 4389 : model1 loss : 0.440821 model2 loss : 0.031969
[23:24:35.309] iteration 4390 : model1 loss : 0.441633 model2 loss : 0.028823
[23:24:35.484] iteration 4391 : model1 loss : 0.436310 model2 loss : 0.026651
[23:24:35.669] iteration 4392 : model1 loss : 0.440365 model2 loss : 0.029952
[23:24:35.839] iteration 4393 : model1 loss : 0.437394 model2 loss : 0.025067
[23:24:36.017] iteration 4394 : model1 loss : 0.439780 model2 loss : 0.028116
[23:24:36.190] iteration 4395 : model1 loss : 0.439573 model2 loss : 0.025435
[23:24:36.365] iteration 4396 : model1 loss : 0.439329 model2 loss : 0.027035
[23:24:36.536] iteration 4397 : model1 loss : 0.435498 model2 loss : 0.031067
[23:24:36.712] iteration 4398 : model1 loss : 0.439013 model2 loss : 0.034651
[23:24:36.882] iteration 4399 : model1 loss : 0.438794 model2 loss : 0.028013
[23:24:37.060] iteration 4400 : model1 loss : 0.434234 model2 loss : 0.030910
[23:24:37.232] iteration 4401 : model1 loss : 0.441297 model2 loss : 0.032325
[23:24:37.409] iteration 4402 : model1 loss : 0.439993 model2 loss : 0.030241
[23:24:37.581] iteration 4403 : model1 loss : 0.432867 model2 loss : 0.022963
[23:24:37.758] iteration 4404 : model1 loss : 0.440020 model2 loss : 0.025751
[23:24:37.927] iteration 4405 : model1 loss : 0.440708 model2 loss : 0.030472
[23:24:38.102] iteration 4406 : model1 loss : 0.438471 model2 loss : 0.028124
[23:24:38.275] iteration 4407 : model1 loss : 0.439873 model2 loss : 0.028716
[23:24:38.451] iteration 4408 : model1 loss : 0.440092 model2 loss : 0.025515
[23:24:38.622] iteration 4409 : model1 loss : 0.435966 model2 loss : 0.029435
[23:24:38.807] iteration 4410 : model1 loss : 0.432221 model2 loss : 0.025636
[23:24:40.928] iteration 4411 : model1 loss : 0.438892 model2 loss : 0.026117
[23:24:41.101] iteration 4412 : model1 loss : 0.441513 model2 loss : 0.029096
[23:24:41.280] iteration 4413 : model1 loss : 0.439825 model2 loss : 0.032068
[23:24:41.451] iteration 4414 : model1 loss : 0.436613 model2 loss : 0.027489
[23:24:41.627] iteration 4415 : model1 loss : 0.437564 model2 loss : 0.029224
[23:24:41.802] iteration 4416 : model1 loss : 0.435623 model2 loss : 0.026596
[23:24:41.975] iteration 4417 : model1 loss : 0.438778 model2 loss : 0.031183
[23:24:42.144] iteration 4418 : model1 loss : 0.438285 model2 loss : 0.031064
[23:24:42.324] iteration 4419 : model1 loss : 0.437266 model2 loss : 0.025612
[23:24:42.502] iteration 4420 : model1 loss : 0.438655 model2 loss : 0.024709
[23:24:42.677] iteration 4421 : model1 loss : 0.436701 model2 loss : 0.026844
[23:24:42.847] iteration 4422 : model1 loss : 0.438309 model2 loss : 0.025285
[23:24:43.026] iteration 4423 : model1 loss : 0.434156 model2 loss : 0.032241
[23:24:43.199] iteration 4424 : model1 loss : 0.439550 model2 loss : 0.027623
[23:24:43.375] iteration 4425 : model1 loss : 0.437438 model2 loss : 0.026149
[23:24:43.548] iteration 4426 : model1 loss : 0.435009 model2 loss : 0.025936
[23:24:43.728] iteration 4427 : model1 loss : 0.444307 model2 loss : 0.034382
[23:24:43.899] iteration 4428 : model1 loss : 0.437354 model2 loss : 0.029504
[23:24:44.072] iteration 4429 : model1 loss : 0.440559 model2 loss : 0.030924
[23:24:44.246] iteration 4430 : model1 loss : 0.443350 model2 loss : 0.029914
[23:24:44.421] iteration 4431 : model1 loss : 0.435690 model2 loss : 0.031017
[23:24:46.566] iteration 4432 : model1 loss : 0.434815 model2 loss : 0.026536
[23:24:46.740] iteration 4433 : model1 loss : 0.434450 model2 loss : 0.028175
[23:24:46.917] iteration 4434 : model1 loss : 0.437820 model2 loss : 0.027805
[23:24:47.089] iteration 4435 : model1 loss : 0.436809 model2 loss : 0.029408
[23:24:47.269] iteration 4436 : model1 loss : 0.439594 model2 loss : 0.032730
[23:24:47.443] iteration 4437 : model1 loss : 0.436143 model2 loss : 0.027285
[23:24:47.624] iteration 4438 : model1 loss : 0.439223 model2 loss : 0.028783
[23:24:47.800] iteration 4439 : model1 loss : 0.438685 model2 loss : 0.035121
[23:24:47.974] iteration 4440 : model1 loss : 0.438991 model2 loss : 0.029750
[23:24:48.146] iteration 4441 : model1 loss : 0.438725 model2 loss : 0.026571
[23:24:48.328] iteration 4442 : model1 loss : 0.434731 model2 loss : 0.026407
[23:24:48.500] iteration 4443 : model1 loss : 0.443247 model2 loss : 0.033114
[23:24:48.678] iteration 4444 : model1 loss : 0.442907 model2 loss : 0.031121
[23:24:48.851] iteration 4445 : model1 loss : 0.440836 model2 loss : 0.030649
[23:24:49.031] iteration 4446 : model1 loss : 0.442241 model2 loss : 0.032963
[23:24:49.205] iteration 4447 : model1 loss : 0.440681 model2 loss : 0.031730
[23:24:49.381] iteration 4448 : model1 loss : 0.436822 model2 loss : 0.024076
[23:24:49.554] iteration 4449 : model1 loss : 0.439289 model2 loss : 0.033609
[23:24:49.731] iteration 4450 : model1 loss : 0.440481 model2 loss : 0.030419
[23:24:49.900] iteration 4451 : model1 loss : 0.437627 model2 loss : 0.032838
[23:24:50.073] iteration 4452 : model1 loss : 0.438858 model2 loss : 0.027777
[23:24:52.251] iteration 4453 : model1 loss : 0.437802 model2 loss : 0.027029
[23:24:52.426] iteration 4454 : model1 loss : 0.440655 model2 loss : 0.033867
[23:24:52.605] iteration 4455 : model1 loss : 0.439303 model2 loss : 0.026519
[23:24:52.783] iteration 4456 : model1 loss : 0.435546 model2 loss : 0.031303
[23:24:52.962] iteration 4457 : model1 loss : 0.440745 model2 loss : 0.030404
[23:24:53.132] iteration 4458 : model1 loss : 0.437406 model2 loss : 0.029371
[23:24:53.310] iteration 4459 : model1 loss : 0.436644 model2 loss : 0.029780
[23:24:53.481] iteration 4460 : model1 loss : 0.439920 model2 loss : 0.026571
[23:24:53.655] iteration 4461 : model1 loss : 0.438052 model2 loss : 0.027009
[23:24:53.829] iteration 4462 : model1 loss : 0.439407 model2 loss : 0.029502
[23:24:54.003] iteration 4463 : model1 loss : 0.440320 model2 loss : 0.028288
[23:24:54.174] iteration 4464 : model1 loss : 0.441078 model2 loss : 0.030160
[23:24:54.354] iteration 4465 : model1 loss : 0.434222 model2 loss : 0.026565
[23:24:54.525] iteration 4466 : model1 loss : 0.435371 model2 loss : 0.029285
[23:24:54.702] iteration 4467 : model1 loss : 0.434553 model2 loss : 0.025780
[23:24:54.875] iteration 4468 : model1 loss : 0.439197 model2 loss : 0.031038
[23:24:55.053] iteration 4469 : model1 loss : 0.434419 model2 loss : 0.024728
[23:24:55.225] iteration 4470 : model1 loss : 0.439100 model2 loss : 0.028258
[23:24:55.400] iteration 4471 : model1 loss : 0.438481 model2 loss : 0.028356
[23:24:55.569] iteration 4472 : model1 loss : 0.438139 model2 loss : 0.028212
[23:24:55.744] iteration 4473 : model1 loss : 0.445218 model2 loss : 0.030806
[23:24:57.907] iteration 4474 : model1 loss : 0.438110 model2 loss : 0.029780
[23:24:58.081] iteration 4475 : model1 loss : 0.439338 model2 loss : 0.028454
[23:24:58.259] iteration 4476 : model1 loss : 0.434858 model2 loss : 0.026206
[23:24:58.433] iteration 4477 : model1 loss : 0.438414 model2 loss : 0.033149
[23:24:58.611] iteration 4478 : model1 loss : 0.438698 model2 loss : 0.027632
[23:24:58.784] iteration 4479 : model1 loss : 0.439559 model2 loss : 0.029807
[23:24:58.960] iteration 4480 : model1 loss : 0.436912 model2 loss : 0.027741
[23:24:59.131] iteration 4481 : model1 loss : 0.437085 model2 loss : 0.026182
[23:24:59.308] iteration 4482 : model1 loss : 0.438347 model2 loss : 0.028140
[23:24:59.480] iteration 4483 : model1 loss : 0.443360 model2 loss : 0.030497
[23:24:59.658] iteration 4484 : model1 loss : 0.436666 model2 loss : 0.028154
[23:24:59.832] iteration 4485 : model1 loss : 0.437929 model2 loss : 0.028870
[23:25:00.008] iteration 4486 : model1 loss : 0.443087 model2 loss : 0.033178
[23:25:00.185] iteration 4487 : model1 loss : 0.439006 model2 loss : 0.031793
[23:25:00.364] iteration 4488 : model1 loss : 0.438243 model2 loss : 0.027724
[23:25:00.536] iteration 4489 : model1 loss : 0.436234 model2 loss : 0.030137
[23:25:00.713] iteration 4490 : model1 loss : 0.437278 model2 loss : 0.026041
[23:25:00.884] iteration 4491 : model1 loss : 0.436259 model2 loss : 0.027737
[23:25:01.060] iteration 4492 : model1 loss : 0.438274 model2 loss : 0.030462
[23:25:01.231] iteration 4493 : model1 loss : 0.438371 model2 loss : 0.027408
[23:25:01.407] iteration 4494 : model1 loss : 0.439277 model2 loss : 0.030603
[23:25:03.582] iteration 4495 : model1 loss : 0.439520 model2 loss : 0.028519
[23:25:03.761] iteration 4496 : model1 loss : 0.438416 model2 loss : 0.029081
[23:25:03.939] iteration 4497 : model1 loss : 0.441731 model2 loss : 0.031097
[23:25:04.109] iteration 4498 : model1 loss : 0.433388 model2 loss : 0.024470
[23:25:04.284] iteration 4499 : model1 loss : 0.439806 model2 loss : 0.028780
[23:25:04.458] iteration 4500 : model1 loss : 0.435283 model2 loss : 0.025206
[23:25:04.636] iteration 4501 : model1 loss : 0.438159 model2 loss : 0.030880
[23:25:04.813] iteration 4502 : model1 loss : 0.438671 model2 loss : 0.029674
[23:25:04.989] iteration 4503 : model1 loss : 0.436257 model2 loss : 0.026080
[23:25:05.161] iteration 4504 : model1 loss : 0.439531 model2 loss : 0.027823
[23:25:05.337] iteration 4505 : model1 loss : 0.437649 model2 loss : 0.025160
[23:25:05.510] iteration 4506 : model1 loss : 0.437966 model2 loss : 0.027764
[23:25:05.688] iteration 4507 : model1 loss : 0.445404 model2 loss : 0.034273
[23:25:05.861] iteration 4508 : model1 loss : 0.437282 model2 loss : 0.028151
[23:25:06.035] iteration 4509 : model1 loss : 0.437880 model2 loss : 0.029408
[23:25:06.205] iteration 4510 : model1 loss : 0.436678 model2 loss : 0.030261
[23:25:06.384] iteration 4511 : model1 loss : 0.435717 model2 loss : 0.026128
[23:25:06.557] iteration 4512 : model1 loss : 0.437304 model2 loss : 0.031050
[23:25:06.736] iteration 4513 : model1 loss : 0.440058 model2 loss : 0.027506
[23:25:06.906] iteration 4514 : model1 loss : 0.438730 model2 loss : 0.029173
[23:25:07.080] iteration 4515 : model1 loss : 0.436559 model2 loss : 0.025688
[23:25:09.246] iteration 4516 : model1 loss : 0.441973 model2 loss : 0.033109
[23:25:09.422] iteration 4517 : model1 loss : 0.432809 model2 loss : 0.023700
[23:25:09.600] iteration 4518 : model1 loss : 0.436764 model2 loss : 0.024563
[23:25:09.774] iteration 4519 : model1 loss : 0.438312 model2 loss : 0.031182
[23:25:09.949] iteration 4520 : model1 loss : 0.443481 model2 loss : 0.033720
[23:25:10.123] iteration 4521 : model1 loss : 0.435494 model2 loss : 0.022344
[23:25:10.302] iteration 4522 : model1 loss : 0.435065 model2 loss : 0.022722
[23:25:10.474] iteration 4523 : model1 loss : 0.435749 model2 loss : 0.028253
[23:25:10.652] iteration 4524 : model1 loss : 0.438315 model2 loss : 0.028920
[23:25:10.825] iteration 4525 : model1 loss : 0.438179 model2 loss : 0.027619
[23:25:10.999] iteration 4526 : model1 loss : 0.439094 model2 loss : 0.029811
[23:25:11.171] iteration 4527 : model1 loss : 0.436378 model2 loss : 0.028952
[23:25:11.347] iteration 4528 : model1 loss : 0.436022 model2 loss : 0.026918
[23:25:11.517] iteration 4529 : model1 loss : 0.442301 model2 loss : 0.030157
[23:25:11.694] iteration 4530 : model1 loss : 0.438952 model2 loss : 0.031426
[23:25:11.869] iteration 4531 : model1 loss : 0.439768 model2 loss : 0.029026
[23:25:12.043] iteration 4532 : model1 loss : 0.435567 model2 loss : 0.025069
[23:25:12.213] iteration 4533 : model1 loss : 0.439040 model2 loss : 0.031442
[23:25:12.392] iteration 4534 : model1 loss : 0.435510 model2 loss : 0.026413
[23:25:12.562] iteration 4535 : model1 loss : 0.436227 model2 loss : 0.029376
[23:25:12.737] iteration 4536 : model1 loss : 0.443220 model2 loss : 0.031857
[23:25:14.948] iteration 4537 : model1 loss : 0.438014 model2 loss : 0.027038
[23:25:15.124] iteration 4538 : model1 loss : 0.437953 model2 loss : 0.026538
[23:25:15.307] iteration 4539 : model1 loss : 0.436077 model2 loss : 0.022520
[23:25:15.476] iteration 4540 : model1 loss : 0.437280 model2 loss : 0.025522
[23:25:15.653] iteration 4541 : model1 loss : 0.434475 model2 loss : 0.025788
[23:25:15.827] iteration 4542 : model1 loss : 0.442626 model2 loss : 0.030951
[23:25:16.004] iteration 4543 : model1 loss : 0.441614 model2 loss : 0.030502
[23:25:16.175] iteration 4544 : model1 loss : 0.438487 model2 loss : 0.029046
[23:25:16.354] iteration 4545 : model1 loss : 0.441770 model2 loss : 0.029198
[23:25:16.525] iteration 4546 : model1 loss : 0.434465 model2 loss : 0.024956
[23:25:16.700] iteration 4547 : model1 loss : 0.437998 model2 loss : 0.028985
[23:25:16.874] iteration 4548 : model1 loss : 0.438145 model2 loss : 0.027789
[23:25:17.047] iteration 4549 : model1 loss : 0.434256 model2 loss : 0.027829
[23:25:17.218] iteration 4550 : model1 loss : 0.435396 model2 loss : 0.024142
[23:25:17.400] iteration 4551 : model1 loss : 0.437659 model2 loss : 0.027621
[23:25:17.572] iteration 4552 : model1 loss : 0.437296 model2 loss : 0.031407
[23:25:17.752] iteration 4553 : model1 loss : 0.438746 model2 loss : 0.035296
[23:25:17.924] iteration 4554 : model1 loss : 0.437805 model2 loss : 0.028964
[23:25:18.100] iteration 4555 : model1 loss : 0.437468 model2 loss : 0.029117
[23:25:18.270] iteration 4556 : model1 loss : 0.440812 model2 loss : 0.037235
[23:25:18.444] iteration 4557 : model1 loss : 0.441037 model2 loss : 0.027460
[23:25:20.551] iteration 4558 : model1 loss : 0.438317 model2 loss : 0.025291
[23:25:20.726] iteration 4559 : model1 loss : 0.435522 model2 loss : 0.024922
[23:25:20.905] iteration 4560 : model1 loss : 0.438599 model2 loss : 0.031337
[23:25:21.075] iteration 4561 : model1 loss : 0.438712 model2 loss : 0.027144
[23:25:21.251] iteration 4562 : model1 loss : 0.433009 model2 loss : 0.025674
[23:25:21.423] iteration 4563 : model1 loss : 0.434580 model2 loss : 0.026309
[23:25:21.600] iteration 4564 : model1 loss : 0.439041 model2 loss : 0.031984
[23:25:21.774] iteration 4565 : model1 loss : 0.438830 model2 loss : 0.023883
[23:25:21.950] iteration 4566 : model1 loss : 0.436588 model2 loss : 0.027368
[23:25:22.124] iteration 4567 : model1 loss : 0.440039 model2 loss : 0.025905
[23:25:22.304] iteration 4568 : model1 loss : 0.439930 model2 loss : 0.029433
[23:25:22.480] iteration 4569 : model1 loss : 0.441402 model2 loss : 0.033001
[23:25:22.659] iteration 4570 : model1 loss : 0.438548 model2 loss : 0.029019
[23:25:22.833] iteration 4571 : model1 loss : 0.438424 model2 loss : 0.028410
[23:25:23.009] iteration 4572 : model1 loss : 0.439292 model2 loss : 0.031164
[23:25:23.179] iteration 4573 : model1 loss : 0.441016 model2 loss : 0.030099
[23:25:23.356] iteration 4574 : model1 loss : 0.439948 model2 loss : 0.031350
[23:25:23.529] iteration 4575 : model1 loss : 0.435691 model2 loss : 0.026941
[23:25:23.703] iteration 4576 : model1 loss : 0.433856 model2 loss : 0.021713
[23:25:23.875] iteration 4577 : model1 loss : 0.437996 model2 loss : 0.026357
[23:25:24.050] iteration 4578 : model1 loss : 0.439709 model2 loss : 0.032486
[23:25:26.203] iteration 4579 : model1 loss : 0.437004 model2 loss : 0.030731
[23:25:26.376] iteration 4580 : model1 loss : 0.433896 model2 loss : 0.026959
[23:25:26.553] iteration 4581 : model1 loss : 0.438817 model2 loss : 0.026815
[23:25:26.724] iteration 4582 : model1 loss : 0.441744 model2 loss : 0.029027
[23:25:26.904] iteration 4583 : model1 loss : 0.438098 model2 loss : 0.028846
[23:25:27.075] iteration 4584 : model1 loss : 0.435433 model2 loss : 0.025900
[23:25:27.252] iteration 4585 : model1 loss : 0.438591 model2 loss : 0.031107
[23:25:27.429] iteration 4586 : model1 loss : 0.440343 model2 loss : 0.025834
[23:25:27.606] iteration 4587 : model1 loss : 0.438848 model2 loss : 0.029531
[23:25:27.779] iteration 4588 : model1 loss : 0.437474 model2 loss : 0.026133
[23:25:27.956] iteration 4589 : model1 loss : 0.437744 model2 loss : 0.027842
[23:25:28.126] iteration 4590 : model1 loss : 0.438046 model2 loss : 0.024880
[23:25:28.305] iteration 4591 : model1 loss : 0.437245 model2 loss : 0.027821
[23:25:28.477] iteration 4592 : model1 loss : 0.436676 model2 loss : 0.027821
[23:25:28.653] iteration 4593 : model1 loss : 0.432611 model2 loss : 0.027555
[23:25:28.828] iteration 4594 : model1 loss : 0.437312 model2 loss : 0.028012
[23:25:29.006] iteration 4595 : model1 loss : 0.437559 model2 loss : 0.028831
[23:25:29.179] iteration 4596 : model1 loss : 0.442512 model2 loss : 0.034840
[23:25:29.355] iteration 4597 : model1 loss : 0.440136 model2 loss : 0.030599
[23:25:29.526] iteration 4598 : model1 loss : 0.440045 model2 loss : 0.029385
[23:25:29.701] iteration 4599 : model1 loss : 0.437966 model2 loss : 0.029050
[23:25:31.841] iteration 4600 : model1 loss : 0.441930 model2 loss : 0.028399
[23:25:32.012] iteration 4601 : model1 loss : 0.438415 model2 loss : 0.030362
[23:25:32.189] iteration 4602 : model1 loss : 0.442447 model2 loss : 0.031058
[23:25:32.365] iteration 4603 : model1 loss : 0.436976 model2 loss : 0.027499
[23:25:32.546] iteration 4604 : model1 loss : 0.435968 model2 loss : 0.025596
[23:25:32.716] iteration 4605 : model1 loss : 0.443501 model2 loss : 0.026519
[23:25:32.892] iteration 4606 : model1 loss : 0.440189 model2 loss : 0.027518
[23:25:33.063] iteration 4607 : model1 loss : 0.435343 model2 loss : 0.030368
[23:25:33.237] iteration 4608 : model1 loss : 0.436213 model2 loss : 0.026909
[23:25:33.410] iteration 4609 : model1 loss : 0.435704 model2 loss : 0.028561
[23:25:33.589] iteration 4610 : model1 loss : 0.436062 model2 loss : 0.025356
[23:25:33.761] iteration 4611 : model1 loss : 0.435888 model2 loss : 0.028819
[23:25:33.938] iteration 4612 : model1 loss : 0.436839 model2 loss : 0.023994
[23:25:34.108] iteration 4613 : model1 loss : 0.437050 model2 loss : 0.028149
[23:25:34.285] iteration 4614 : model1 loss : 0.441430 model2 loss : 0.031782
[23:25:34.458] iteration 4615 : model1 loss : 0.439955 model2 loss : 0.030858
[23:25:34.636] iteration 4616 : model1 loss : 0.432894 model2 loss : 0.024803
[23:25:34.811] iteration 4617 : model1 loss : 0.438487 model2 loss : 0.028342
[23:25:34.987] iteration 4618 : model1 loss : 0.443374 model2 loss : 0.027065
[23:25:35.157] iteration 4619 : model1 loss : 0.435055 model2 loss : 0.027010
[23:25:35.334] iteration 4620 : model1 loss : 0.435777 model2 loss : 0.025783
[23:25:37.541] iteration 4621 : model1 loss : 0.438326 model2 loss : 0.028996
[23:25:37.717] iteration 4622 : model1 loss : 0.438640 model2 loss : 0.029782
[23:25:37.898] iteration 4623 : model1 loss : 0.435539 model2 loss : 0.026636
[23:25:38.068] iteration 4624 : model1 loss : 0.436897 model2 loss : 0.030260
[23:25:38.246] iteration 4625 : model1 loss : 0.436877 model2 loss : 0.024951
[23:25:38.422] iteration 4626 : model1 loss : 0.435342 model2 loss : 0.028213
[23:25:38.601] iteration 4627 : model1 loss : 0.438541 model2 loss : 0.024267
[23:25:38.771] iteration 4628 : model1 loss : 0.440313 model2 loss : 0.028139
[23:25:38.948] iteration 4629 : model1 loss : 0.440664 model2 loss : 0.027995
[23:25:39.119] iteration 4630 : model1 loss : 0.436537 model2 loss : 0.028975
[23:25:39.297] iteration 4631 : model1 loss : 0.442512 model2 loss : 0.036217
[23:25:39.470] iteration 4632 : model1 loss : 0.439932 model2 loss : 0.026403
[23:25:39.647] iteration 4633 : model1 loss : 0.434036 model2 loss : 0.028196
[23:25:39.821] iteration 4634 : model1 loss : 0.436631 model2 loss : 0.028339
[23:25:40.000] iteration 4635 : model1 loss : 0.440367 model2 loss : 0.030862
[23:25:40.173] iteration 4636 : model1 loss : 0.436838 model2 loss : 0.024503
[23:25:40.352] iteration 4637 : model1 loss : 0.440047 model2 loss : 0.024944
[23:25:40.523] iteration 4638 : model1 loss : 0.438096 model2 loss : 0.027151
[23:25:40.698] iteration 4639 : model1 loss : 0.441886 model2 loss : 0.028980
[23:25:40.869] iteration 4640 : model1 loss : 0.439251 model2 loss : 0.028881
[23:25:41.043] iteration 4641 : model1 loss : 0.437548 model2 loss : 0.027922
[23:25:43.188] iteration 4642 : model1 loss : 0.438627 model2 loss : 0.025915
[23:25:43.363] iteration 4643 : model1 loss : 0.435532 model2 loss : 0.030947
[23:25:43.542] iteration 4644 : model1 loss : 0.436953 model2 loss : 0.028892
[23:25:43.712] iteration 4645 : model1 loss : 0.441131 model2 loss : 0.029304
[23:25:43.899] iteration 4646 : model1 loss : 0.440185 model2 loss : 0.027812
[23:25:44.069] iteration 4647 : model1 loss : 0.440344 model2 loss : 0.027808
[23:25:44.245] iteration 4648 : model1 loss : 0.436181 model2 loss : 0.027706
[23:25:44.419] iteration 4649 : model1 loss : 0.441423 model2 loss : 0.025000
[23:25:44.600] iteration 4650 : model1 loss : 0.434544 model2 loss : 0.024414
[23:25:44.771] iteration 4651 : model1 loss : 0.436636 model2 loss : 0.028861
[23:25:44.949] iteration 4652 : model1 loss : 0.434817 model2 loss : 0.025534
[23:25:45.118] iteration 4653 : model1 loss : 0.437630 model2 loss : 0.023993
[23:25:45.302] iteration 4654 : model1 loss : 0.438979 model2 loss : 0.027582
[23:25:45.471] iteration 4655 : model1 loss : 0.434384 model2 loss : 0.026563
[23:25:45.650] iteration 4656 : model1 loss : 0.436745 model2 loss : 0.024592
[23:25:45.824] iteration 4657 : model1 loss : 0.437389 model2 loss : 0.026565
[23:25:46.000] iteration 4658 : model1 loss : 0.446311 model2 loss : 0.030048
[23:25:46.171] iteration 4659 : model1 loss : 0.443227 model2 loss : 0.038008
[23:25:46.349] iteration 4660 : model1 loss : 0.436911 model2 loss : 0.033551
[23:25:46.518] iteration 4661 : model1 loss : 0.436873 model2 loss : 0.027437
[23:25:46.690] iteration 4662 : model1 loss : 0.435878 model2 loss : 0.024408
[23:25:48.841] iteration 4663 : model1 loss : 0.435952 model2 loss : 0.026535
[23:25:49.017] iteration 4664 : model1 loss : 0.441892 model2 loss : 0.031100
[23:25:49.197] iteration 4665 : model1 loss : 0.436344 model2 loss : 0.025860
[23:25:49.370] iteration 4666 : model1 loss : 0.438066 model2 loss : 0.027786
[23:25:49.547] iteration 4667 : model1 loss : 0.438465 model2 loss : 0.027896
[23:25:49.719] iteration 4668 : model1 loss : 0.437380 model2 loss : 0.027333
[23:25:49.896] iteration 4669 : model1 loss : 0.440257 model2 loss : 0.027513
[23:25:50.068] iteration 4670 : model1 loss : 0.436737 model2 loss : 0.025335
[23:25:50.245] iteration 4671 : model1 loss : 0.440271 model2 loss : 0.030647
[23:25:50.418] iteration 4672 : model1 loss : 0.440029 model2 loss : 0.033896
[23:25:50.597] iteration 4673 : model1 loss : 0.438049 model2 loss : 0.025860
[23:25:50.769] iteration 4674 : model1 loss : 0.434955 model2 loss : 0.027433
[23:25:50.946] iteration 4675 : model1 loss : 0.439245 model2 loss : 0.028975
[23:25:51.119] iteration 4676 : model1 loss : 0.436661 model2 loss : 0.029393
[23:25:51.298] iteration 4677 : model1 loss : 0.435244 model2 loss : 0.023476
[23:25:51.473] iteration 4678 : model1 loss : 0.439724 model2 loss : 0.030061
[23:25:51.651] iteration 4679 : model1 loss : 0.437629 model2 loss : 0.027105
[23:25:51.824] iteration 4680 : model1 loss : 0.434889 model2 loss : 0.024531
[23:25:52.001] iteration 4681 : model1 loss : 0.443441 model2 loss : 0.031060
[23:25:52.170] iteration 4682 : model1 loss : 0.435915 model2 loss : 0.025672
[23:25:52.346] iteration 4683 : model1 loss : 0.438489 model2 loss : 0.025214
[23:25:54.539] iteration 4684 : model1 loss : 0.438046 model2 loss : 0.024296
[23:25:54.712] iteration 4685 : model1 loss : 0.433959 model2 loss : 0.026933
[23:25:54.891] iteration 4686 : model1 loss : 0.438185 model2 loss : 0.025476
[23:25:55.061] iteration 4687 : model1 loss : 0.435137 model2 loss : 0.029269
[23:25:55.235] iteration 4688 : model1 loss : 0.438276 model2 loss : 0.026006
[23:25:55.409] iteration 4689 : model1 loss : 0.440540 model2 loss : 0.024469
[23:25:55.589] iteration 4690 : model1 loss : 0.438479 model2 loss : 0.025383
[23:25:55.761] iteration 4691 : model1 loss : 0.438980 model2 loss : 0.027713
[23:25:55.935] iteration 4692 : model1 loss : 0.440020 model2 loss : 0.027715
[23:25:56.107] iteration 4693 : model1 loss : 0.442679 model2 loss : 0.027664
[23:25:56.280] iteration 4694 : model1 loss : 0.439408 model2 loss : 0.030933
[23:25:56.456] iteration 4695 : model1 loss : 0.440475 model2 loss : 0.028024
[23:25:56.634] iteration 4696 : model1 loss : 0.436735 model2 loss : 0.029651
[23:25:56.808] iteration 4697 : model1 loss : 0.436837 model2 loss : 0.025826
[23:25:56.986] iteration 4698 : model1 loss : 0.436530 model2 loss : 0.027199
[23:25:57.159] iteration 4699 : model1 loss : 0.439391 model2 loss : 0.029744
[23:25:57.339] iteration 4700 : model1 loss : 0.445457 model2 loss : 0.036287
[23:25:57.516] iteration 4701 : model1 loss : 0.437835 model2 loss : 0.026485
[23:25:57.695] iteration 4702 : model1 loss : 0.436256 model2 loss : 0.026737
[23:25:57.868] iteration 4703 : model1 loss : 0.435244 model2 loss : 0.024740
[23:25:58.041] iteration 4704 : model1 loss : 0.441489 model2 loss : 0.026801
[23:26:00.169] iteration 4705 : model1 loss : 0.440385 model2 loss : 0.024255
[23:26:00.342] iteration 4706 : model1 loss : 0.444023 model2 loss : 0.028694
[23:26:00.521] iteration 4707 : model1 loss : 0.440620 model2 loss : 0.029343
[23:26:00.690] iteration 4708 : model1 loss : 0.441207 model2 loss : 0.029174
[23:26:00.867] iteration 4709 : model1 loss : 0.435035 model2 loss : 0.025604
[23:26:01.038] iteration 4710 : model1 loss : 0.443259 model2 loss : 0.031925
[23:26:01.213] iteration 4711 : model1 loss : 0.432580 model2 loss : 0.026089
[23:26:01.387] iteration 4712 : model1 loss : 0.439234 model2 loss : 0.029384
[23:26:01.566] iteration 4713 : model1 loss : 0.441908 model2 loss : 0.028868
[23:26:01.738] iteration 4714 : model1 loss : 0.441037 model2 loss : 0.029041
[23:26:01.913] iteration 4715 : model1 loss : 0.436291 model2 loss : 0.025676
[23:26:02.084] iteration 4716 : model1 loss : 0.441490 model2 loss : 0.028383
[23:26:02.262] iteration 4717 : model1 loss : 0.437480 model2 loss : 0.026362
[23:26:02.440] iteration 4718 : model1 loss : 0.436185 model2 loss : 0.026967
[23:26:02.618] iteration 4719 : model1 loss : 0.437209 model2 loss : 0.025580
[23:26:02.789] iteration 4720 : model1 loss : 0.437720 model2 loss : 0.026919
[23:26:02.966] iteration 4721 : model1 loss : 0.431478 model2 loss : 0.021777
[23:26:03.137] iteration 4722 : model1 loss : 0.437086 model2 loss : 0.030402
[23:26:03.314] iteration 4723 : model1 loss : 0.446491 model2 loss : 0.031739
[23:26:03.485] iteration 4724 : model1 loss : 0.435581 model2 loss : 0.026700
[23:26:03.661] iteration 4725 : model1 loss : 0.438343 model2 loss : 0.027711
[23:26:05.805] iteration 4726 : model1 loss : 0.438919 model2 loss : 0.027718
[23:26:05.983] iteration 4727 : model1 loss : 0.443478 model2 loss : 0.034109
[23:26:06.159] iteration 4728 : model1 loss : 0.442953 model2 loss : 0.026495
[23:26:06.336] iteration 4729 : model1 loss : 0.440224 model2 loss : 0.033217
[23:26:06.513] iteration 4730 : model1 loss : 0.443241 model2 loss : 0.032112
[23:26:06.683] iteration 4731 : model1 loss : 0.435468 model2 loss : 0.024681
[23:26:06.858] iteration 4732 : model1 loss : 0.439412 model2 loss : 0.032322
[23:26:07.030] iteration 4733 : model1 loss : 0.438980 model2 loss : 0.024784
[23:26:07.206] iteration 4734 : model1 loss : 0.436959 model2 loss : 0.026854
[23:26:07.378] iteration 4735 : model1 loss : 0.435039 model2 loss : 0.026485
[23:26:07.555] iteration 4736 : model1 loss : 0.437779 model2 loss : 0.028167
[23:26:07.728] iteration 4737 : model1 loss : 0.433910 model2 loss : 0.022601
[23:26:07.903] iteration 4738 : model1 loss : 0.434659 model2 loss : 0.026786
[23:26:08.072] iteration 4739 : model1 loss : 0.437332 model2 loss : 0.028478
[23:26:08.249] iteration 4740 : model1 loss : 0.435666 model2 loss : 0.025436
[23:26:08.424] iteration 4741 : model1 loss : 0.440751 model2 loss : 0.026957
[23:26:08.601] iteration 4742 : model1 loss : 0.439734 model2 loss : 0.026329
[23:26:08.774] iteration 4743 : model1 loss : 0.438840 model2 loss : 0.027866
[23:26:08.950] iteration 4744 : model1 loss : 0.440245 model2 loss : 0.030005
[23:26:09.120] iteration 4745 : model1 loss : 0.436830 model2 loss : 0.025151
[23:26:09.296] iteration 4746 : model1 loss : 0.437229 model2 loss : 0.027523
[23:26:11.453] iteration 4747 : model1 loss : 0.437955 model2 loss : 0.028302
[23:26:11.624] iteration 4748 : model1 loss : 0.435991 model2 loss : 0.026292
[23:26:11.805] iteration 4749 : model1 loss : 0.438024 model2 loss : 0.029048
[23:26:11.978] iteration 4750 : model1 loss : 0.439702 model2 loss : 0.028075
[23:26:12.154] iteration 4751 : model1 loss : 0.437001 model2 loss : 0.027155
[23:26:12.327] iteration 4752 : model1 loss : 0.439642 model2 loss : 0.028360
[23:26:12.512] iteration 4753 : model1 loss : 0.441433 model2 loss : 0.025391
[23:26:12.682] iteration 4754 : model1 loss : 0.437155 model2 loss : 0.024697
[23:26:12.859] iteration 4755 : model1 loss : 0.445001 model2 loss : 0.028208
[23:26:13.032] iteration 4756 : model1 loss : 0.438648 model2 loss : 0.024148
[23:26:13.207] iteration 4757 : model1 loss : 0.436532 model2 loss : 0.027185
[23:26:13.380] iteration 4758 : model1 loss : 0.441174 model2 loss : 0.030157
[23:26:13.558] iteration 4759 : model1 loss : 0.439664 model2 loss : 0.031719
[23:26:13.728] iteration 4760 : model1 loss : 0.433898 model2 loss : 0.028063
[23:26:13.907] iteration 4761 : model1 loss : 0.437817 model2 loss : 0.022122
[23:26:14.077] iteration 4762 : model1 loss : 0.437577 model2 loss : 0.031975
[23:26:14.252] iteration 4763 : model1 loss : 0.436562 model2 loss : 0.026527
[23:26:14.425] iteration 4764 : model1 loss : 0.434843 model2 loss : 0.025206
[23:26:14.607] iteration 4765 : model1 loss : 0.437813 model2 loss : 0.023979
[23:26:14.792] iteration 4766 : model1 loss : 0.439343 model2 loss : 0.028700
[23:26:14.966] iteration 4767 : model1 loss : 0.439354 model2 loss : 0.025175
[23:26:17.097] iteration 4768 : model1 loss : 0.433688 model2 loss : 0.026092
[23:26:17.268] iteration 4769 : model1 loss : 0.436647 model2 loss : 0.025629
[23:26:17.449] iteration 4770 : model1 loss : 0.436157 model2 loss : 0.024186
[23:26:17.622] iteration 4771 : model1 loss : 0.438060 model2 loss : 0.025158
[23:26:17.799] iteration 4772 : model1 loss : 0.438509 model2 loss : 0.026000
[23:26:17.970] iteration 4773 : model1 loss : 0.441933 model2 loss : 0.034339
[23:26:18.146] iteration 4774 : model1 loss : 0.432287 model2 loss : 0.025432
[23:26:18.324] iteration 4775 : model1 loss : 0.436654 model2 loss : 0.027186
[23:26:18.500] iteration 4776 : model1 loss : 0.433781 model2 loss : 0.024836
[23:26:18.672] iteration 4777 : model1 loss : 0.439508 model2 loss : 0.026296
[23:26:18.847] iteration 4778 : model1 loss : 0.440218 model2 loss : 0.028007
[23:26:19.020] iteration 4779 : model1 loss : 0.436560 model2 loss : 0.027194
[23:26:19.198] iteration 4780 : model1 loss : 0.446249 model2 loss : 0.027196
[23:26:19.375] iteration 4781 : model1 loss : 0.435238 model2 loss : 0.025781
[23:26:19.551] iteration 4782 : model1 loss : 0.438235 model2 loss : 0.032583
[23:26:19.722] iteration 4783 : model1 loss : 0.440845 model2 loss : 0.029135
[23:26:19.900] iteration 4784 : model1 loss : 0.440472 model2 loss : 0.025099
[23:26:20.070] iteration 4785 : model1 loss : 0.438420 model2 loss : 0.029374
[23:26:20.246] iteration 4786 : model1 loss : 0.437012 model2 loss : 0.027249
[23:26:20.418] iteration 4787 : model1 loss : 0.441536 model2 loss : 0.026628
[23:26:20.596] iteration 4788 : model1 loss : 0.442348 model2 loss : 0.032005
[23:26:22.749] iteration 4789 : model1 loss : 0.437751 model2 loss : 0.029545
[23:26:22.928] iteration 4790 : model1 loss : 0.438757 model2 loss : 0.028851
[23:26:23.105] iteration 4791 : model1 loss : 0.438714 model2 loss : 0.026671
[23:26:23.275] iteration 4792 : model1 loss : 0.436859 model2 loss : 0.023925
[23:26:23.450] iteration 4793 : model1 loss : 0.434067 model2 loss : 0.023882
[23:26:23.624] iteration 4794 : model1 loss : 0.437915 model2 loss : 0.022885
[23:26:23.805] iteration 4795 : model1 loss : 0.437997 model2 loss : 0.027474
[23:26:23.977] iteration 4796 : model1 loss : 0.435075 model2 loss : 0.025510
[23:26:24.153] iteration 4797 : model1 loss : 0.447863 model2 loss : 0.031016
[23:26:24.327] iteration 4798 : model1 loss : 0.442499 model2 loss : 0.027164
[23:26:24.507] iteration 4799 : model1 loss : 0.438166 model2 loss : 0.028245
[23:26:24.678] iteration 4800 : model1 loss : 0.440303 model2 loss : 0.025758
[23:26:24.870] iteration 4801 : model1 loss : 0.439292 model2 loss : 0.028089
[23:26:25.041] iteration 4802 : model1 loss : 0.439306 model2 loss : 0.029220
[23:26:25.215] iteration 4803 : model1 loss : 0.440776 model2 loss : 0.028887
[23:26:25.387] iteration 4804 : model1 loss : 0.440645 model2 loss : 0.030489
[23:26:25.563] iteration 4805 : model1 loss : 0.439098 model2 loss : 0.028217
[23:26:25.734] iteration 4806 : model1 loss : 0.443902 model2 loss : 0.032219
[23:26:25.909] iteration 4807 : model1 loss : 0.438812 model2 loss : 0.026261
[23:26:26.084] iteration 4808 : model1 loss : 0.440999 model2 loss : 0.029063
[23:26:26.260] iteration 4809 : model1 loss : 0.440815 model2 loss : 0.028448
[23:26:28.430] iteration 4810 : model1 loss : 0.434696 model2 loss : 0.023987
[23:26:28.603] iteration 4811 : model1 loss : 0.429979 model2 loss : 0.021090
[23:26:28.780] iteration 4812 : model1 loss : 0.439247 model2 loss : 0.026474
[23:26:28.954] iteration 4813 : model1 loss : 0.436986 model2 loss : 0.027007
[23:26:29.130] iteration 4814 : model1 loss : 0.437308 model2 loss : 0.027187
[23:26:29.303] iteration 4815 : model1 loss : 0.440276 model2 loss : 0.031534
[23:26:29.479] iteration 4816 : model1 loss : 0.438303 model2 loss : 0.026848
[23:26:29.651] iteration 4817 : model1 loss : 0.439056 model2 loss : 0.028614
[23:26:29.828] iteration 4818 : model1 loss : 0.441510 model2 loss : 0.029838
[23:26:30.001] iteration 4819 : model1 loss : 0.442018 model2 loss : 0.028846
[23:26:30.177] iteration 4820 : model1 loss : 0.440987 model2 loss : 0.026734
[23:26:30.349] iteration 4821 : model1 loss : 0.442152 model2 loss : 0.025216
[23:26:30.528] iteration 4822 : model1 loss : 0.436233 model2 loss : 0.033238
[23:26:30.702] iteration 4823 : model1 loss : 0.438449 model2 loss : 0.026474
[23:26:30.880] iteration 4824 : model1 loss : 0.439135 model2 loss : 0.027492
[23:26:31.052] iteration 4825 : model1 loss : 0.436082 model2 loss : 0.027801
[23:26:31.228] iteration 4826 : model1 loss : 0.440394 model2 loss : 0.031498
[23:26:31.404] iteration 4827 : model1 loss : 0.437622 model2 loss : 0.025183
[23:26:31.580] iteration 4828 : model1 loss : 0.438866 model2 loss : 0.028207
[23:26:31.749] iteration 4829 : model1 loss : 0.443049 model2 loss : 0.034693
[23:26:31.927] iteration 4830 : model1 loss : 0.441839 model2 loss : 0.028474
[23:26:34.115] iteration 4831 : model1 loss : 0.435554 model2 loss : 0.023909
[23:26:34.292] iteration 4832 : model1 loss : 0.436485 model2 loss : 0.028842
[23:26:34.470] iteration 4833 : model1 loss : 0.442483 model2 loss : 0.029714
[23:26:34.642] iteration 4834 : model1 loss : 0.436783 model2 loss : 0.027730
[23:26:34.818] iteration 4835 : model1 loss : 0.440725 model2 loss : 0.029901
[23:26:34.990] iteration 4836 : model1 loss : 0.437621 model2 loss : 0.030377
[23:26:35.167] iteration 4837 : model1 loss : 0.439356 model2 loss : 0.028596
[23:26:35.341] iteration 4838 : model1 loss : 0.438687 model2 loss : 0.026671
[23:26:35.518] iteration 4839 : model1 loss : 0.438531 model2 loss : 0.029572
[23:26:35.690] iteration 4840 : model1 loss : 0.441088 model2 loss : 0.030945
[23:26:35.865] iteration 4841 : model1 loss : 0.440373 model2 loss : 0.028874
[23:26:36.040] iteration 4842 : model1 loss : 0.432229 model2 loss : 0.022705
[23:26:36.213] iteration 4843 : model1 loss : 0.442456 model2 loss : 0.040112
[23:26:36.388] iteration 4844 : model1 loss : 0.437853 model2 loss : 0.026555
[23:26:36.566] iteration 4845 : model1 loss : 0.441972 model2 loss : 0.029432
[23:26:36.738] iteration 4846 : model1 loss : 0.439789 model2 loss : 0.024854
[23:26:36.914] iteration 4847 : model1 loss : 0.440443 model2 loss : 0.036935
[23:26:37.085] iteration 4848 : model1 loss : 0.436705 model2 loss : 0.030841
[23:26:37.263] iteration 4849 : model1 loss : 0.435446 model2 loss : 0.027238
[23:26:37.438] iteration 4850 : model1 loss : 0.436946 model2 loss : 0.027360
[23:26:37.611] iteration 4851 : model1 loss : 0.435025 model2 loss : 0.024531
[23:26:39.754] iteration 4852 : model1 loss : 0.436291 model2 loss : 0.033997
[23:26:39.927] iteration 4853 : model1 loss : 0.439384 model2 loss : 0.025382
[23:26:40.109] iteration 4854 : model1 loss : 0.438708 model2 loss : 0.025200
[23:26:40.286] iteration 4855 : model1 loss : 0.437288 model2 loss : 0.027889
[23:26:40.464] iteration 4856 : model1 loss : 0.439301 model2 loss : 0.025849
[23:26:40.637] iteration 4857 : model1 loss : 0.438686 model2 loss : 0.025903
[23:26:40.812] iteration 4858 : model1 loss : 0.439883 model2 loss : 0.031769
[23:26:40.985] iteration 4859 : model1 loss : 0.438574 model2 loss : 0.031172
[23:26:41.159] iteration 4860 : model1 loss : 0.438610 model2 loss : 0.032925
[23:26:41.332] iteration 4861 : model1 loss : 0.440794 model2 loss : 0.032469
[23:26:41.507] iteration 4862 : model1 loss : 0.440172 model2 loss : 0.029694
[23:26:41.678] iteration 4863 : model1 loss : 0.442057 model2 loss : 0.026210
[23:26:41.854] iteration 4864 : model1 loss : 0.433895 model2 loss : 0.025388
[23:26:42.030] iteration 4865 : model1 loss : 0.434119 model2 loss : 0.024230
[23:26:42.203] iteration 4866 : model1 loss : 0.436458 model2 loss : 0.026908
[23:26:42.375] iteration 4867 : model1 loss : 0.438220 model2 loss : 0.027155
[23:26:42.554] iteration 4868 : model1 loss : 0.439398 model2 loss : 0.031815
[23:26:42.724] iteration 4869 : model1 loss : 0.440700 model2 loss : 0.030720
[23:26:42.903] iteration 4870 : model1 loss : 0.436784 model2 loss : 0.030138
[23:26:43.073] iteration 4871 : model1 loss : 0.436912 model2 loss : 0.026916
[23:26:43.248] iteration 4872 : model1 loss : 0.440946 model2 loss : 0.029685
[23:26:45.373] iteration 4873 : model1 loss : 0.436225 model2 loss : 0.025842
[23:26:45.551] iteration 4874 : model1 loss : 0.438109 model2 loss : 0.031131
[23:26:45.726] iteration 4875 : model1 loss : 0.438879 model2 loss : 0.027493
[23:26:45.900] iteration 4876 : model1 loss : 0.436522 model2 loss : 0.028021
[23:26:46.080] iteration 4877 : model1 loss : 0.433042 model2 loss : 0.024836
[23:26:46.249] iteration 4878 : model1 loss : 0.440420 model2 loss : 0.027144
[23:26:46.429] iteration 4879 : model1 loss : 0.438743 model2 loss : 0.030375
[23:26:46.603] iteration 4880 : model1 loss : 0.434386 model2 loss : 0.026665
[23:26:46.776] iteration 4881 : model1 loss : 0.442570 model2 loss : 0.031905
[23:26:46.949] iteration 4882 : model1 loss : 0.439433 model2 loss : 0.029029
[23:26:47.125] iteration 4883 : model1 loss : 0.439293 model2 loss : 0.026231
[23:26:47.299] iteration 4884 : model1 loss : 0.438544 model2 loss : 0.028384
[23:26:47.481] iteration 4885 : model1 loss : 0.437766 model2 loss : 0.025532
[23:26:47.652] iteration 4886 : model1 loss : 0.440349 model2 loss : 0.035142
[23:26:47.829] iteration 4887 : model1 loss : 0.433567 model2 loss : 0.025301
[23:26:48.001] iteration 4888 : model1 loss : 0.437312 model2 loss : 0.029491
[23:26:48.176] iteration 4889 : model1 loss : 0.435224 model2 loss : 0.027516
[23:26:48.351] iteration 4890 : model1 loss : 0.447469 model2 loss : 0.028770
[23:26:48.528] iteration 4891 : model1 loss : 0.438964 model2 loss : 0.025707
[23:26:48.697] iteration 4892 : model1 loss : 0.440333 model2 loss : 0.027437
[23:26:48.871] iteration 4893 : model1 loss : 0.438718 model2 loss : 0.029127
[23:26:51.089] iteration 4894 : model1 loss : 0.440443 model2 loss : 0.027451
[23:26:51.265] iteration 4895 : model1 loss : 0.436334 model2 loss : 0.027309
[23:26:51.443] iteration 4896 : model1 loss : 0.439903 model2 loss : 0.029430
[23:26:51.617] iteration 4897 : model1 loss : 0.440107 model2 loss : 0.028027
[23:26:51.793] iteration 4898 : model1 loss : 0.433487 model2 loss : 0.024638
[23:26:51.966] iteration 4899 : model1 loss : 0.438747 model2 loss : 0.023810
[23:26:52.142] iteration 4900 : model1 loss : 0.436991 model2 loss : 0.026458
[23:26:52.314] iteration 4901 : model1 loss : 0.435106 model2 loss : 0.024207
[23:26:52.498] iteration 4902 : model1 loss : 0.442963 model2 loss : 0.026975
[23:26:52.669] iteration 4903 : model1 loss : 0.437482 model2 loss : 0.023349
[23:26:52.845] iteration 4904 : model1 loss : 0.439612 model2 loss : 0.030107
[23:26:53.019] iteration 4905 : model1 loss : 0.441412 model2 loss : 0.027513
[23:26:53.200] iteration 4906 : model1 loss : 0.437598 model2 loss : 0.028523
[23:26:53.370] iteration 4907 : model1 loss : 0.436899 model2 loss : 0.025750
[23:26:53.548] iteration 4908 : model1 loss : 0.437297 model2 loss : 0.029890
[23:26:53.719] iteration 4909 : model1 loss : 0.441057 model2 loss : 0.026910
[23:26:53.894] iteration 4910 : model1 loss : 0.434866 model2 loss : 0.025269
[23:26:54.064] iteration 4911 : model1 loss : 0.440058 model2 loss : 0.026608
[23:26:54.239] iteration 4912 : model1 loss : 0.439482 model2 loss : 0.029496
[23:26:54.410] iteration 4913 : model1 loss : 0.439412 model2 loss : 0.028886
[23:26:54.587] iteration 4914 : model1 loss : 0.440435 model2 loss : 0.029447
[23:26:56.748] iteration 4915 : model1 loss : 0.436352 model2 loss : 0.027811
[23:26:56.920] iteration 4916 : model1 loss : 0.438705 model2 loss : 0.028348
[23:26:57.099] iteration 4917 : model1 loss : 0.444215 model2 loss : 0.028947
[23:26:57.270] iteration 4918 : model1 loss : 0.443083 model2 loss : 0.034151
[23:26:57.450] iteration 4919 : model1 loss : 0.436875 model2 loss : 0.028806
[23:26:57.625] iteration 4920 : model1 loss : 0.437663 model2 loss : 0.027645
[23:26:57.802] iteration 4921 : model1 loss : 0.439705 model2 loss : 0.025865
[23:26:57.974] iteration 4922 : model1 loss : 0.436983 model2 loss : 0.027910
[23:26:58.152] iteration 4923 : model1 loss : 0.446649 model2 loss : 0.037697
[23:26:58.324] iteration 4924 : model1 loss : 0.436985 model2 loss : 0.024818
[23:26:58.503] iteration 4925 : model1 loss : 0.438404 model2 loss : 0.023402
[23:26:58.673] iteration 4926 : model1 loss : 0.436570 model2 loss : 0.028934
[23:26:58.847] iteration 4927 : model1 loss : 0.437591 model2 loss : 0.029641
[23:26:59.022] iteration 4928 : model1 loss : 0.438790 model2 loss : 0.025695
[23:26:59.197] iteration 4929 : model1 loss : 0.436666 model2 loss : 0.024769
[23:26:59.368] iteration 4930 : model1 loss : 0.436903 model2 loss : 0.024636
[23:26:59.548] iteration 4931 : model1 loss : 0.441730 model2 loss : 0.028601
[23:26:59.719] iteration 4932 : model1 loss : 0.437614 model2 loss : 0.024957
[23:26:59.894] iteration 4933 : model1 loss : 0.436417 model2 loss : 0.023937
[23:27:00.068] iteration 4934 : model1 loss : 0.439882 model2 loss : 0.025673
[23:27:00.244] iteration 4935 : model1 loss : 0.434822 model2 loss : 0.024788
[23:27:02.368] iteration 4936 : model1 loss : 0.438383 model2 loss : 0.029564
[23:27:02.542] iteration 4937 : model1 loss : 0.435803 model2 loss : 0.022721
[23:27:02.719] iteration 4938 : model1 loss : 0.434553 model2 loss : 0.025802
[23:27:02.890] iteration 4939 : model1 loss : 0.432224 model2 loss : 0.025025
[23:27:03.066] iteration 4940 : model1 loss : 0.443047 model2 loss : 0.029594
[23:27:03.237] iteration 4941 : model1 loss : 0.436660 model2 loss : 0.021821
[23:27:03.416] iteration 4942 : model1 loss : 0.437971 model2 loss : 0.028269
[23:27:03.591] iteration 4943 : model1 loss : 0.441428 model2 loss : 0.029047
[23:27:03.765] iteration 4944 : model1 loss : 0.439048 model2 loss : 0.028533
[23:27:03.937] iteration 4945 : model1 loss : 0.440053 model2 loss : 0.026374
[23:27:04.117] iteration 4946 : model1 loss : 0.439999 model2 loss : 0.029666
[23:27:04.288] iteration 4947 : model1 loss : 0.438304 model2 loss : 0.025783
[23:27:04.465] iteration 4948 : model1 loss : 0.439281 model2 loss : 0.025432
[23:27:04.639] iteration 4949 : model1 loss : 0.438101 model2 loss : 0.028144
[23:27:04.816] iteration 4950 : model1 loss : 0.441285 model2 loss : 0.032709
[23:27:04.988] iteration 4951 : model1 loss : 0.441277 model2 loss : 0.027640
[23:27:05.163] iteration 4952 : model1 loss : 0.435611 model2 loss : 0.026137
[23:27:05.334] iteration 4953 : model1 loss : 0.441437 model2 loss : 0.028149
[23:27:05.512] iteration 4954 : model1 loss : 0.435549 model2 loss : 0.026630
[23:27:05.681] iteration 4955 : model1 loss : 0.441082 model2 loss : 0.024567
[23:27:05.856] iteration 4956 : model1 loss : 0.441366 model2 loss : 0.027062
[23:27:08.064] iteration 4957 : model1 loss : 0.437697 model2 loss : 0.026294
[23:27:08.237] iteration 4958 : model1 loss : 0.438061 model2 loss : 0.025007
[23:27:08.416] iteration 4959 : model1 loss : 0.433769 model2 loss : 0.023560
[23:27:08.590] iteration 4960 : model1 loss : 0.447018 model2 loss : 0.031225
[23:27:08.765] iteration 4961 : model1 loss : 0.438143 model2 loss : 0.030912
[23:27:08.939] iteration 4962 : model1 loss : 0.444242 model2 loss : 0.026641
[23:27:09.116] iteration 4963 : model1 loss : 0.437276 model2 loss : 0.022814
[23:27:09.286] iteration 4964 : model1 loss : 0.436492 model2 loss : 0.026719
[23:27:09.464] iteration 4965 : model1 loss : 0.439687 model2 loss : 0.029912
[23:27:09.637] iteration 4966 : model1 loss : 0.434720 model2 loss : 0.027080
[23:27:09.814] iteration 4967 : model1 loss : 0.434823 model2 loss : 0.024389
[23:27:09.987] iteration 4968 : model1 loss : 0.441065 model2 loss : 0.028524
[23:27:10.167] iteration 4969 : model1 loss : 0.440233 model2 loss : 0.023950
[23:27:10.340] iteration 4970 : model1 loss : 0.447618 model2 loss : 0.025237
[23:27:10.516] iteration 4971 : model1 loss : 0.436025 model2 loss : 0.028064
[23:27:10.686] iteration 4972 : model1 loss : 0.442996 model2 loss : 0.028104
[23:27:10.864] iteration 4973 : model1 loss : 0.437422 model2 loss : 0.028634
[23:27:11.036] iteration 4974 : model1 loss : 0.442959 model2 loss : 0.027593
[23:27:11.210] iteration 4975 : model1 loss : 0.436745 model2 loss : 0.025861
[23:27:11.378] iteration 4976 : model1 loss : 0.437807 model2 loss : 0.030007
[23:27:11.554] iteration 4977 : model1 loss : 0.441102 model2 loss : 0.030561
[23:27:13.715] iteration 4978 : model1 loss : 0.438063 model2 loss : 0.026434
[23:27:13.892] iteration 4979 : model1 loss : 0.441074 model2 loss : 0.035060
[23:27:14.070] iteration 4980 : model1 loss : 0.435600 model2 loss : 0.025322
[23:27:14.240] iteration 4981 : model1 loss : 0.441729 model2 loss : 0.028413
[23:27:14.418] iteration 4982 : model1 loss : 0.441371 model2 loss : 0.031569
[23:27:14.595] iteration 4983 : model1 loss : 0.438504 model2 loss : 0.028510
[23:27:14.772] iteration 4984 : model1 loss : 0.439793 model2 loss : 0.028360
[23:27:14.943] iteration 4985 : model1 loss : 0.442440 model2 loss : 0.029083
[23:27:15.120] iteration 4986 : model1 loss : 0.445975 model2 loss : 0.028353
[23:27:15.292] iteration 4987 : model1 loss : 0.438205 model2 loss : 0.030241
[23:27:15.470] iteration 4988 : model1 loss : 0.439048 model2 loss : 0.025365
[23:27:15.642] iteration 4989 : model1 loss : 0.439364 model2 loss : 0.024868
[23:27:15.822] iteration 4990 : model1 loss : 0.437581 model2 loss : 0.030684
[23:27:15.995] iteration 4991 : model1 loss : 0.439010 model2 loss : 0.029037
[23:27:16.172] iteration 4992 : model1 loss : 0.435670 model2 loss : 0.023561
[23:27:16.346] iteration 4993 : model1 loss : 0.438400 model2 loss : 0.023396
[23:27:16.526] iteration 4994 : model1 loss : 0.436168 model2 loss : 0.033753
[23:27:16.697] iteration 4995 : model1 loss : 0.441805 model2 loss : 0.027887
[23:27:16.873] iteration 4996 : model1 loss : 0.440574 model2 loss : 0.034331
[23:27:17.044] iteration 4997 : model1 loss : 0.439483 model2 loss : 0.031428
[23:27:17.220] iteration 4998 : model1 loss : 0.437519 model2 loss : 0.025919
[23:27:19.355] iteration 4999 : model1 loss : 0.441121 model2 loss : 0.027579
[23:27:19.536] iteration 5000 : model1 loss : 0.442479 model2 loss : 0.029949
[23:27:28.769] iteration 5000 : model1_mean_dice : 0.752147 model1_mean_hd95 : 10.822809
[23:27:38.077] iteration 5000 : model2_mean_dice : 0.788706 model2_mean_hd95 : 26.108436
[23:27:38.259] iteration 5001 : model1 loss : 0.441338 model2 loss : 0.031906
[23:27:38.436] iteration 5002 : model1 loss : 0.437797 model2 loss : 0.028083
[23:27:38.610] iteration 5003 : model1 loss : 0.440808 model2 loss : 0.032420
[23:27:38.784] iteration 5004 : model1 loss : 0.436574 model2 loss : 0.026144
[23:27:38.953] iteration 5005 : model1 loss : 0.441599 model2 loss : 0.027927
[23:27:39.129] iteration 5006 : model1 loss : 0.437926 model2 loss : 0.028213
[23:27:39.301] iteration 5007 : model1 loss : 0.439963 model2 loss : 0.029410
[23:27:39.476] iteration 5008 : model1 loss : 0.437016 model2 loss : 0.027853
[23:27:39.651] iteration 5009 : model1 loss : 0.440713 model2 loss : 0.028494
[23:27:39.830] iteration 5010 : model1 loss : 0.436828 model2 loss : 0.027115
[23:27:40.002] iteration 5011 : model1 loss : 0.434903 model2 loss : 0.022589
[23:27:40.180] iteration 5012 : model1 loss : 0.435736 model2 loss : 0.025447
[23:27:40.352] iteration 5013 : model1 loss : 0.436275 model2 loss : 0.024348
[23:27:40.531] iteration 5014 : model1 loss : 0.437511 model2 loss : 0.029904
[23:27:40.702] iteration 5015 : model1 loss : 0.441381 model2 loss : 0.028475
[23:27:40.877] iteration 5016 : model1 loss : 0.442689 model2 loss : 0.033655
[23:27:41.049] iteration 5017 : model1 loss : 0.435549 model2 loss : 0.024818
[23:27:41.225] iteration 5018 : model1 loss : 0.441022 model2 loss : 0.027487
[23:27:41.394] iteration 5019 : model1 loss : 0.436654 model2 loss : 0.030764
[23:27:43.612] iteration 5020 : model1 loss : 0.435124 model2 loss : 0.027046
[23:27:43.783] iteration 5021 : model1 loss : 0.438527 model2 loss : 0.027345
[23:27:43.960] iteration 5022 : model1 loss : 0.440080 model2 loss : 0.028502
[23:27:44.134] iteration 5023 : model1 loss : 0.437903 model2 loss : 0.025526
[23:27:44.310] iteration 5024 : model1 loss : 0.441733 model2 loss : 0.028815
[23:27:44.481] iteration 5025 : model1 loss : 0.436804 model2 loss : 0.026810
[23:27:44.661] iteration 5026 : model1 loss : 0.440674 model2 loss : 0.027460
[23:27:44.832] iteration 5027 : model1 loss : 0.438368 model2 loss : 0.027701
[23:27:45.007] iteration 5028 : model1 loss : 0.434899 model2 loss : 0.025723
[23:27:45.178] iteration 5029 : model1 loss : 0.440755 model2 loss : 0.030368
[23:27:45.354] iteration 5030 : model1 loss : 0.437533 model2 loss : 0.027703
[23:27:45.528] iteration 5031 : model1 loss : 0.435348 model2 loss : 0.024901
[23:27:45.705] iteration 5032 : model1 loss : 0.441996 model2 loss : 0.027779
[23:27:45.879] iteration 5033 : model1 loss : 0.439908 model2 loss : 0.028847
[23:27:46.060] iteration 5034 : model1 loss : 0.439460 model2 loss : 0.030805
[23:27:46.232] iteration 5035 : model1 loss : 0.433034 model2 loss : 0.029826
[23:27:46.408] iteration 5036 : model1 loss : 0.440577 model2 loss : 0.040525
[23:27:46.581] iteration 5037 : model1 loss : 0.436778 model2 loss : 0.023250
[23:27:46.757] iteration 5038 : model1 loss : 0.433568 model2 loss : 0.023654
[23:27:46.925] iteration 5039 : model1 loss : 0.439210 model2 loss : 0.023654
[23:27:47.098] iteration 5040 : model1 loss : 0.442278 model2 loss : 0.032977
[23:27:49.236] iteration 5041 : model1 loss : 0.436029 model2 loss : 0.027024
[23:27:49.408] iteration 5042 : model1 loss : 0.436376 model2 loss : 0.025269
[23:27:49.587] iteration 5043 : model1 loss : 0.439708 model2 loss : 0.027742
[23:27:49.759] iteration 5044 : model1 loss : 0.438301 model2 loss : 0.025684
[23:27:49.935] iteration 5045 : model1 loss : 0.437545 model2 loss : 0.025055
[23:27:50.107] iteration 5046 : model1 loss : 0.433864 model2 loss : 0.023310
[23:27:50.284] iteration 5047 : model1 loss : 0.445199 model2 loss : 0.036348
[23:27:50.452] iteration 5048 : model1 loss : 0.437200 model2 loss : 0.024801
[23:27:50.630] iteration 5049 : model1 loss : 0.438134 model2 loss : 0.028203
[23:27:50.802] iteration 5050 : model1 loss : 0.438261 model2 loss : 0.024896
[23:27:50.977] iteration 5051 : model1 loss : 0.435207 model2 loss : 0.027755
[23:27:51.150] iteration 5052 : model1 loss : 0.443956 model2 loss : 0.031659
[23:27:51.328] iteration 5053 : model1 loss : 0.436515 model2 loss : 0.024572
[23:27:51.500] iteration 5054 : model1 loss : 0.436643 model2 loss : 0.025110
[23:27:51.677] iteration 5055 : model1 loss : 0.436889 model2 loss : 0.026608
[23:27:51.848] iteration 5056 : model1 loss : 0.442277 model2 loss : 0.029449
[23:27:52.027] iteration 5057 : model1 loss : 0.441246 model2 loss : 0.027112
[23:27:52.201] iteration 5058 : model1 loss : 0.436860 model2 loss : 0.029936
[23:27:52.379] iteration 5059 : model1 loss : 0.441551 model2 loss : 0.030388
[23:27:52.549] iteration 5060 : model1 loss : 0.445882 model2 loss : 0.033303
[23:27:52.723] iteration 5061 : model1 loss : 0.439837 model2 loss : 0.025704
[23:27:54.857] iteration 5062 : model1 loss : 0.433759 model2 loss : 0.025614
[23:27:55.038] iteration 5063 : model1 loss : 0.435571 model2 loss : 0.025168
[23:27:55.212] iteration 5064 : model1 loss : 0.441600 model2 loss : 0.025612
[23:27:55.382] iteration 5065 : model1 loss : 0.440149 model2 loss : 0.032554
[23:27:55.563] iteration 5066 : model1 loss : 0.441072 model2 loss : 0.026698
[23:27:55.735] iteration 5067 : model1 loss : 0.434460 model2 loss : 0.026905
[23:27:55.908] iteration 5068 : model1 loss : 0.434368 model2 loss : 0.025504
[23:27:56.081] iteration 5069 : model1 loss : 0.441396 model2 loss : 0.036572
[23:27:56.262] iteration 5070 : model1 loss : 0.440634 model2 loss : 0.028029
[23:27:56.432] iteration 5071 : model1 loss : 0.436564 model2 loss : 0.029572
[23:27:56.610] iteration 5072 : model1 loss : 0.434930 model2 loss : 0.028711
[23:27:56.779] iteration 5073 : model1 loss : 0.435204 model2 loss : 0.039267
[23:27:56.956] iteration 5074 : model1 loss : 0.442605 model2 loss : 0.041373
[23:27:57.130] iteration 5075 : model1 loss : 0.443137 model2 loss : 0.047216
[23:27:57.306] iteration 5076 : model1 loss : 0.438132 model2 loss : 0.029349
[23:27:57.480] iteration 5077 : model1 loss : 0.439238 model2 loss : 0.033267
[23:27:57.664] iteration 5078 : model1 loss : 0.437544 model2 loss : 0.035310
[23:27:57.834] iteration 5079 : model1 loss : 0.436536 model2 loss : 0.034504
[23:27:58.009] iteration 5080 : model1 loss : 0.444339 model2 loss : 0.049397
[23:27:58.177] iteration 5081 : model1 loss : 0.441324 model2 loss : 0.038766
[23:27:58.354] iteration 5082 : model1 loss : 0.438550 model2 loss : 0.028889
[23:28:00.536] iteration 5083 : model1 loss : 0.436200 model2 loss : 0.034075
[23:28:00.710] iteration 5084 : model1 loss : 0.435577 model2 loss : 0.029954
[23:28:00.887] iteration 5085 : model1 loss : 0.438691 model2 loss : 0.032272
[23:28:01.065] iteration 5086 : model1 loss : 0.437040 model2 loss : 0.033219
[23:28:01.242] iteration 5087 : model1 loss : 0.438121 model2 loss : 0.037631
[23:28:01.413] iteration 5088 : model1 loss : 0.437649 model2 loss : 0.034350
[23:28:01.592] iteration 5089 : model1 loss : 0.441386 model2 loss : 0.052538
[23:28:01.763] iteration 5090 : model1 loss : 0.436220 model2 loss : 0.028362
[23:28:01.937] iteration 5091 : model1 loss : 0.436285 model2 loss : 0.033561
[23:28:02.113] iteration 5092 : model1 loss : 0.438896 model2 loss : 0.043710
[23:28:02.289] iteration 5093 : model1 loss : 0.439826 model2 loss : 0.043962
[23:28:02.466] iteration 5094 : model1 loss : 0.437647 model2 loss : 0.030562
[23:28:02.642] iteration 5095 : model1 loss : 0.438316 model2 loss : 0.030534
[23:28:02.814] iteration 5096 : model1 loss : 0.440358 model2 loss : 0.033101
[23:28:02.991] iteration 5097 : model1 loss : 0.439422 model2 loss : 0.036301
[23:28:03.165] iteration 5098 : model1 loss : 0.433424 model2 loss : 0.036672
[23:28:03.346] iteration 5099 : model1 loss : 0.445710 model2 loss : 0.044051
[23:28:03.517] iteration 5100 : model1 loss : 0.437097 model2 loss : 0.039684
[23:28:03.695] iteration 5101 : model1 loss : 0.436760 model2 loss : 0.028746
[23:28:03.865] iteration 5102 : model1 loss : 0.441129 model2 loss : 0.039658
[23:28:04.038] iteration 5103 : model1 loss : 0.442696 model2 loss : 0.033181
[23:28:06.168] iteration 5104 : model1 loss : 0.437775 model2 loss : 0.032049
[23:28:06.342] iteration 5105 : model1 loss : 0.438201 model2 loss : 0.037277
[23:28:06.519] iteration 5106 : model1 loss : 0.437480 model2 loss : 0.028363
[23:28:06.692] iteration 5107 : model1 loss : 0.435484 model2 loss : 0.033327
[23:28:06.869] iteration 5108 : model1 loss : 0.437179 model2 loss : 0.027974
[23:28:07.039] iteration 5109 : model1 loss : 0.433748 model2 loss : 0.028314
[23:28:07.215] iteration 5110 : model1 loss : 0.437465 model2 loss : 0.030628
[23:28:07.388] iteration 5111 : model1 loss : 0.435806 model2 loss : 0.029332
[23:28:07.567] iteration 5112 : model1 loss : 0.441599 model2 loss : 0.032212
[23:28:07.738] iteration 5113 : model1 loss : 0.444132 model2 loss : 0.043586
[23:28:07.914] iteration 5114 : model1 loss : 0.439521 model2 loss : 0.035688
[23:28:08.087] iteration 5115 : model1 loss : 0.440458 model2 loss : 0.032485
[23:28:08.267] iteration 5116 : model1 loss : 0.438526 model2 loss : 0.031221
[23:28:08.468] iteration 5117 : model1 loss : 0.438832 model2 loss : 0.029063
[23:28:08.652] iteration 5118 : model1 loss : 0.438396 model2 loss : 0.030513
[23:28:08.825] iteration 5119 : model1 loss : 0.440716 model2 loss : 0.037435
[23:28:09.000] iteration 5120 : model1 loss : 0.437378 model2 loss : 0.029901
[23:28:09.174] iteration 5121 : model1 loss : 0.439051 model2 loss : 0.028002
[23:28:09.355] iteration 5122 : model1 loss : 0.437956 model2 loss : 0.030228
[23:28:09.522] iteration 5123 : model1 loss : 0.438215 model2 loss : 0.033480
[23:28:09.698] iteration 5124 : model1 loss : 0.437182 model2 loss : 0.039024
[23:28:11.823] iteration 5125 : model1 loss : 0.434927 model2 loss : 0.030290
[23:28:11.998] iteration 5126 : model1 loss : 0.442169 model2 loss : 0.033641
[23:28:12.177] iteration 5127 : model1 loss : 0.439175 model2 loss : 0.028834
[23:28:12.347] iteration 5128 : model1 loss : 0.435975 model2 loss : 0.027825
[23:28:12.526] iteration 5129 : model1 loss : 0.435409 model2 loss : 0.030015
[23:28:12.700] iteration 5130 : model1 loss : 0.436586 model2 loss : 0.025858
[23:28:12.877] iteration 5131 : model1 loss : 0.434140 model2 loss : 0.023920
[23:28:13.047] iteration 5132 : model1 loss : 0.438929 model2 loss : 0.026889
[23:28:13.223] iteration 5133 : model1 loss : 0.440228 model2 loss : 0.032031
[23:28:13.394] iteration 5134 : model1 loss : 0.436658 model2 loss : 0.028611
[23:28:13.573] iteration 5135 : model1 loss : 0.439405 model2 loss : 0.025836
[23:28:13.744] iteration 5136 : model1 loss : 0.435811 model2 loss : 0.032379
[23:28:13.918] iteration 5137 : model1 loss : 0.435880 model2 loss : 0.023684
[23:28:14.090] iteration 5138 : model1 loss : 0.438727 model2 loss : 0.032453
[23:28:14.268] iteration 5139 : model1 loss : 0.441568 model2 loss : 0.034900
[23:28:14.437] iteration 5140 : model1 loss : 0.440434 model2 loss : 0.028662
[23:28:14.617] iteration 5141 : model1 loss : 0.437070 model2 loss : 0.030898
[23:28:14.789] iteration 5142 : model1 loss : 0.438972 model2 loss : 0.028348
[23:28:14.965] iteration 5143 : model1 loss : 0.442657 model2 loss : 0.030898
[23:28:15.136] iteration 5144 : model1 loss : 0.440485 model2 loss : 0.027496
[23:28:15.310] iteration 5145 : model1 loss : 0.437183 model2 loss : 0.030897
[23:28:17.453] iteration 5146 : model1 loss : 0.443769 model2 loss : 0.028833
[23:28:17.627] iteration 5147 : model1 loss : 0.439249 model2 loss : 0.028226
[23:28:17.806] iteration 5148 : model1 loss : 0.438735 model2 loss : 0.032639
[23:28:17.977] iteration 5149 : model1 loss : 0.436482 model2 loss : 0.030252
[23:28:18.155] iteration 5150 : model1 loss : 0.442361 model2 loss : 0.029198
[23:28:18.329] iteration 5151 : model1 loss : 0.437748 model2 loss : 0.025525
[23:28:18.505] iteration 5152 : model1 loss : 0.439117 model2 loss : 0.039371
[23:28:18.677] iteration 5153 : model1 loss : 0.433984 model2 loss : 0.026790
[23:28:18.853] iteration 5154 : model1 loss : 0.436923 model2 loss : 0.026748
[23:28:19.024] iteration 5155 : model1 loss : 0.441084 model2 loss : 0.027086
[23:28:19.198] iteration 5156 : model1 loss : 0.437104 model2 loss : 0.024228
[23:28:19.370] iteration 5157 : model1 loss : 0.436841 model2 loss : 0.030618
[23:28:19.545] iteration 5158 : model1 loss : 0.436265 model2 loss : 0.032824
[23:28:19.719] iteration 5159 : model1 loss : 0.436152 model2 loss : 0.029617
[23:28:19.896] iteration 5160 : model1 loss : 0.436661 model2 loss : 0.029381
[23:28:20.065] iteration 5161 : model1 loss : 0.439289 model2 loss : 0.026799
[23:28:20.243] iteration 5162 : model1 loss : 0.439592 model2 loss : 0.027811
[23:28:20.413] iteration 5163 : model1 loss : 0.434498 model2 loss : 0.026558
[23:28:20.593] iteration 5164 : model1 loss : 0.436220 model2 loss : 0.026401
[23:28:20.766] iteration 5165 : model1 loss : 0.441946 model2 loss : 0.031949
[23:28:20.940] iteration 5166 : model1 loss : 0.439042 model2 loss : 0.027830
[23:28:23.088] iteration 5167 : model1 loss : 0.437147 model2 loss : 0.027688
[23:28:23.260] iteration 5168 : model1 loss : 0.437984 model2 loss : 0.025738
[23:28:23.438] iteration 5169 : model1 loss : 0.437197 model2 loss : 0.025530
[23:28:23.614] iteration 5170 : model1 loss : 0.435323 model2 loss : 0.024997
[23:28:23.793] iteration 5171 : model1 loss : 0.436831 model2 loss : 0.029737
[23:28:23.966] iteration 5172 : model1 loss : 0.432140 model2 loss : 0.022530
[23:28:24.145] iteration 5173 : model1 loss : 0.437133 model2 loss : 0.036625
[23:28:24.320] iteration 5174 : model1 loss : 0.437462 model2 loss : 0.029561
[23:28:24.497] iteration 5175 : model1 loss : 0.437501 model2 loss : 0.030662
[23:28:24.670] iteration 5176 : model1 loss : 0.440797 model2 loss : 0.031640
[23:28:24.846] iteration 5177 : model1 loss : 0.439207 model2 loss : 0.030178
[23:28:25.017] iteration 5178 : model1 loss : 0.440157 model2 loss : 0.027850
[23:28:25.195] iteration 5179 : model1 loss : 0.439614 model2 loss : 0.029764
[23:28:25.368] iteration 5180 : model1 loss : 0.440298 model2 loss : 0.027509
[23:28:25.544] iteration 5181 : model1 loss : 0.436186 model2 loss : 0.032960
[23:28:25.718] iteration 5182 : model1 loss : 0.435719 model2 loss : 0.030718
[23:28:25.895] iteration 5183 : model1 loss : 0.438695 model2 loss : 0.031523
[23:28:26.067] iteration 5184 : model1 loss : 0.437854 model2 loss : 0.028521
[23:28:26.244] iteration 5185 : model1 loss : 0.442947 model2 loss : 0.032355
[23:28:26.412] iteration 5186 : model1 loss : 0.436621 model2 loss : 0.027471
[23:28:26.588] iteration 5187 : model1 loss : 0.435213 model2 loss : 0.029266
[23:28:28.755] iteration 5188 : model1 loss : 0.436508 model2 loss : 0.030567
[23:28:28.935] iteration 5189 : model1 loss : 0.439172 model2 loss : 0.027858
[23:28:29.110] iteration 5190 : model1 loss : 0.437244 model2 loss : 0.028276
[23:28:29.279] iteration 5191 : model1 loss : 0.436469 model2 loss : 0.028773
[23:28:29.455] iteration 5192 : model1 loss : 0.437715 model2 loss : 0.026958
[23:28:29.631] iteration 5193 : model1 loss : 0.443687 model2 loss : 0.027153
[23:28:29.807] iteration 5194 : model1 loss : 0.438090 model2 loss : 0.024467
[23:28:29.977] iteration 5195 : model1 loss : 0.443387 model2 loss : 0.030853
[23:28:30.156] iteration 5196 : model1 loss : 0.434778 model2 loss : 0.024073
[23:28:30.330] iteration 5197 : model1 loss : 0.433209 model2 loss : 0.028491
[23:28:30.506] iteration 5198 : model1 loss : 0.438607 model2 loss : 0.031863
[23:28:30.680] iteration 5199 : model1 loss : 0.439964 model2 loss : 0.027124
[23:28:30.856] iteration 5200 : model1 loss : 0.437229 model2 loss : 0.024440
[23:28:31.025] iteration 5201 : model1 loss : 0.437916 model2 loss : 0.027763
[23:28:31.201] iteration 5202 : model1 loss : 0.440783 model2 loss : 0.035326
[23:28:31.372] iteration 5203 : model1 loss : 0.441790 model2 loss : 0.030625
[23:28:31.548] iteration 5204 : model1 loss : 0.436231 model2 loss : 0.028581
[23:28:31.722] iteration 5205 : model1 loss : 0.438237 model2 loss : 0.026435
[23:28:31.898] iteration 5206 : model1 loss : 0.436037 model2 loss : 0.030809
[23:28:32.071] iteration 5207 : model1 loss : 0.436981 model2 loss : 0.026878
[23:28:32.249] iteration 5208 : model1 loss : 0.440515 model2 loss : 0.026641
[23:28:34.403] iteration 5209 : model1 loss : 0.439136 model2 loss : 0.026235
[23:28:34.577] iteration 5210 : model1 loss : 0.440770 model2 loss : 0.028821
[23:28:34.755] iteration 5211 : model1 loss : 0.445645 model2 loss : 0.038081
[23:28:34.926] iteration 5212 : model1 loss : 0.438302 model2 loss : 0.027909
[23:28:35.102] iteration 5213 : model1 loss : 0.441535 model2 loss : 0.029796
[23:28:35.275] iteration 5214 : model1 loss : 0.438316 model2 loss : 0.025740
[23:28:35.448] iteration 5215 : model1 loss : 0.438759 model2 loss : 0.032241
[23:28:35.622] iteration 5216 : model1 loss : 0.436180 model2 loss : 0.026444
[23:28:35.799] iteration 5217 : model1 loss : 0.434529 model2 loss : 0.025336
[23:28:35.971] iteration 5218 : model1 loss : 0.434561 model2 loss : 0.024686
[23:28:36.148] iteration 5219 : model1 loss : 0.437416 model2 loss : 0.029891
[23:28:36.323] iteration 5220 : model1 loss : 0.435270 model2 loss : 0.024662
[23:28:36.497] iteration 5221 : model1 loss : 0.441017 model2 loss : 0.032113
[23:28:36.670] iteration 5222 : model1 loss : 0.437654 model2 loss : 0.027785
[23:28:36.845] iteration 5223 : model1 loss : 0.434189 model2 loss : 0.025194
[23:28:37.014] iteration 5224 : model1 loss : 0.435088 model2 loss : 0.026760
[23:28:37.190] iteration 5225 : model1 loss : 0.437167 model2 loss : 0.031344
[23:28:37.364] iteration 5226 : model1 loss : 0.432981 model2 loss : 0.024917
[23:28:37.543] iteration 5227 : model1 loss : 0.437824 model2 loss : 0.026821
[23:28:37.713] iteration 5228 : model1 loss : 0.439449 model2 loss : 0.026352
[23:28:37.887] iteration 5229 : model1 loss : 0.443662 model2 loss : 0.030921
[23:28:40.034] iteration 5230 : model1 loss : 0.439032 model2 loss : 0.025618
[23:28:40.209] iteration 5231 : model1 loss : 0.436385 model2 loss : 0.025088
[23:28:40.386] iteration 5232 : model1 loss : 0.438828 model2 loss : 0.030404
[23:28:40.557] iteration 5233 : model1 loss : 0.443786 model2 loss : 0.040723
[23:28:40.731] iteration 5234 : model1 loss : 0.436437 model2 loss : 0.025116
[23:28:40.901] iteration 5235 : model1 loss : 0.436931 model2 loss : 0.027300
[23:28:41.077] iteration 5236 : model1 loss : 0.439402 model2 loss : 0.029049
[23:28:41.251] iteration 5237 : model1 loss : 0.438257 model2 loss : 0.031440
[23:28:41.425] iteration 5238 : model1 loss : 0.435636 model2 loss : 0.026533
[23:28:41.597] iteration 5239 : model1 loss : 0.434928 model2 loss : 0.030252
[23:28:41.776] iteration 5240 : model1 loss : 0.437003 model2 loss : 0.027470
[23:28:41.946] iteration 5241 : model1 loss : 0.440622 model2 loss : 0.030006
[23:28:42.128] iteration 5242 : model1 loss : 0.435009 model2 loss : 0.025212
[23:28:42.301] iteration 5243 : model1 loss : 0.436236 model2 loss : 0.023786
[23:28:42.481] iteration 5244 : model1 loss : 0.435944 model2 loss : 0.025732
[23:28:42.656] iteration 5245 : model1 loss : 0.440284 model2 loss : 0.031664
[23:28:42.832] iteration 5246 : model1 loss : 0.436818 model2 loss : 0.027895
[23:28:43.003] iteration 5247 : model1 loss : 0.440184 model2 loss : 0.031970
[23:28:43.181] iteration 5248 : model1 loss : 0.434403 model2 loss : 0.026524
[23:28:43.351] iteration 5249 : model1 loss : 0.436031 model2 loss : 0.024348
[23:28:43.527] iteration 5250 : model1 loss : 0.444465 model2 loss : 0.045427
[23:28:45.626] iteration 5251 : model1 loss : 0.438449 model2 loss : 0.026879
[23:28:45.802] iteration 5252 : model1 loss : 0.437739 model2 loss : 0.029222
[23:28:45.981] iteration 5253 : model1 loss : 0.434863 model2 loss : 0.025762
[23:28:46.153] iteration 5254 : model1 loss : 0.438006 model2 loss : 0.026565
[23:28:46.334] iteration 5255 : model1 loss : 0.439010 model2 loss : 0.028706
[23:28:46.505] iteration 5256 : model1 loss : 0.432786 model2 loss : 0.025621
[23:28:46.682] iteration 5257 : model1 loss : 0.434753 model2 loss : 0.023395
[23:28:46.852] iteration 5258 : model1 loss : 0.439570 model2 loss : 0.026451
[23:28:47.028] iteration 5259 : model1 loss : 0.438516 model2 loss : 0.027742
[23:28:47.200] iteration 5260 : model1 loss : 0.445519 model2 loss : 0.027976
[23:28:47.374] iteration 5261 : model1 loss : 0.442377 model2 loss : 0.031623
[23:28:47.544] iteration 5262 : model1 loss : 0.434777 model2 loss : 0.026372
[23:28:47.722] iteration 5263 : model1 loss : 0.440804 model2 loss : 0.027949
[23:28:47.892] iteration 5264 : model1 loss : 0.437606 model2 loss : 0.027915
[23:28:48.070] iteration 5265 : model1 loss : 0.436925 model2 loss : 0.025525
[23:28:48.242] iteration 5266 : model1 loss : 0.437856 model2 loss : 0.029211
[23:28:48.416] iteration 5267 : model1 loss : 0.438754 model2 loss : 0.031367
[23:28:48.589] iteration 5268 : model1 loss : 0.436233 model2 loss : 0.025378
[23:28:48.767] iteration 5269 : model1 loss : 0.431863 model2 loss : 0.025609
[23:28:48.934] iteration 5270 : model1 loss : 0.439728 model2 loss : 0.026016
[23:28:49.108] iteration 5271 : model1 loss : 0.441218 model2 loss : 0.026970
[23:28:51.225] iteration 5272 : model1 loss : 0.438923 model2 loss : 0.026711
[23:28:51.398] iteration 5273 : model1 loss : 0.436894 model2 loss : 0.028220
[23:28:51.577] iteration 5274 : model1 loss : 0.438891 model2 loss : 0.025892
[23:28:51.750] iteration 5275 : model1 loss : 0.440997 model2 loss : 0.031024
[23:28:51.926] iteration 5276 : model1 loss : 0.437788 model2 loss : 0.024793
[23:28:52.095] iteration 5277 : model1 loss : 0.436426 model2 loss : 0.024962
[23:28:52.273] iteration 5278 : model1 loss : 0.440550 model2 loss : 0.029699
[23:28:52.445] iteration 5279 : model1 loss : 0.439147 model2 loss : 0.025887
[23:28:52.627] iteration 5280 : model1 loss : 0.437839 model2 loss : 0.026144
[23:28:52.800] iteration 5281 : model1 loss : 0.436626 model2 loss : 0.027974
[23:28:52.973] iteration 5282 : model1 loss : 0.435039 model2 loss : 0.024770
[23:28:53.144] iteration 5283 : model1 loss : 0.436219 model2 loss : 0.025871
[23:28:53.327] iteration 5284 : model1 loss : 0.439636 model2 loss : 0.026969
[23:28:53.497] iteration 5285 : model1 loss : 0.436969 model2 loss : 0.025648
[23:28:53.675] iteration 5286 : model1 loss : 0.439042 model2 loss : 0.029991
[23:28:53.846] iteration 5287 : model1 loss : 0.433158 model2 loss : 0.025281
[23:28:54.022] iteration 5288 : model1 loss : 0.442509 model2 loss : 0.030823
[23:28:54.195] iteration 5289 : model1 loss : 0.438589 model2 loss : 0.029527
[23:28:54.368] iteration 5290 : model1 loss : 0.440367 model2 loss : 0.032398
[23:28:54.537] iteration 5291 : model1 loss : 0.435980 model2 loss : 0.025753
[23:28:54.713] iteration 5292 : model1 loss : 0.439515 model2 loss : 0.030359
[23:28:56.845] iteration 5293 : model1 loss : 0.439492 model2 loss : 0.030184
[23:28:57.019] iteration 5294 : model1 loss : 0.439650 model2 loss : 0.028977
[23:28:57.198] iteration 5295 : model1 loss : 0.438204 model2 loss : 0.026788
[23:28:57.370] iteration 5296 : model1 loss : 0.438955 model2 loss : 0.025255
[23:28:57.544] iteration 5297 : model1 loss : 0.433632 model2 loss : 0.027241
[23:28:57.717] iteration 5298 : model1 loss : 0.438845 model2 loss : 0.027580
[23:28:57.895] iteration 5299 : model1 loss : 0.440059 model2 loss : 0.026356
[23:28:58.064] iteration 5300 : model1 loss : 0.436083 model2 loss : 0.023329
[23:28:58.240] iteration 5301 : model1 loss : 0.436281 model2 loss : 0.026295
[23:28:58.412] iteration 5302 : model1 loss : 0.436318 model2 loss : 0.026004
[23:28:58.590] iteration 5303 : model1 loss : 0.434852 model2 loss : 0.024922
[23:28:58.762] iteration 5304 : model1 loss : 0.439426 model2 loss : 0.025568
[23:28:58.938] iteration 5305 : model1 loss : 0.441389 model2 loss : 0.032278
[23:28:59.109] iteration 5306 : model1 loss : 0.436357 model2 loss : 0.028264
[23:28:59.284] iteration 5307 : model1 loss : 0.432600 model2 loss : 0.021433
[23:28:59.454] iteration 5308 : model1 loss : 0.439714 model2 loss : 0.028265
[23:28:59.634] iteration 5309 : model1 loss : 0.439273 model2 loss : 0.030130
[23:28:59.834] iteration 5310 : model1 loss : 0.448417 model2 loss : 0.029755
[23:29:00.009] iteration 5311 : model1 loss : 0.439750 model2 loss : 0.025816
[23:29:00.185] iteration 5312 : model1 loss : 0.436366 model2 loss : 0.026650
[23:29:00.371] iteration 5313 : model1 loss : 0.440968 model2 loss : 0.025037
[23:29:02.523] iteration 5314 : model1 loss : 0.436678 model2 loss : 0.023689
[23:29:02.698] iteration 5315 : model1 loss : 0.438142 model2 loss : 0.029773
[23:29:02.875] iteration 5316 : model1 loss : 0.443500 model2 loss : 0.030988
[23:29:03.044] iteration 5317 : model1 loss : 0.440160 model2 loss : 0.034388
[23:29:03.219] iteration 5318 : model1 loss : 0.437972 model2 loss : 0.025891
[23:29:03.390] iteration 5319 : model1 loss : 0.439829 model2 loss : 0.025275
[23:29:03.564] iteration 5320 : model1 loss : 0.439548 model2 loss : 0.030384
[23:29:03.737] iteration 5321 : model1 loss : 0.443078 model2 loss : 0.029423
[23:29:03.912] iteration 5322 : model1 loss : 0.437955 model2 loss : 0.027802
[23:29:04.083] iteration 5323 : model1 loss : 0.439117 model2 loss : 0.024285
[23:29:04.259] iteration 5324 : model1 loss : 0.436963 model2 loss : 0.032757
[23:29:04.430] iteration 5325 : model1 loss : 0.438549 model2 loss : 0.027598
[23:29:04.607] iteration 5326 : model1 loss : 0.439899 model2 loss : 0.028504
[23:29:04.780] iteration 5327 : model1 loss : 0.434513 model2 loss : 0.023840
[23:29:04.956] iteration 5328 : model1 loss : 0.439093 model2 loss : 0.027600
[23:29:05.127] iteration 5329 : model1 loss : 0.440470 model2 loss : 0.028338
[23:29:05.305] iteration 5330 : model1 loss : 0.438702 model2 loss : 0.028737
[23:29:05.474] iteration 5331 : model1 loss : 0.444205 model2 loss : 0.039638
[23:29:05.651] iteration 5332 : model1 loss : 0.436522 model2 loss : 0.029246
[23:29:05.824] iteration 5333 : model1 loss : 0.446908 model2 loss : 0.047842
[23:29:05.999] iteration 5334 : model1 loss : 0.435472 model2 loss : 0.027647
[23:29:08.159] iteration 5335 : model1 loss : 0.440767 model2 loss : 0.025609
[23:29:08.334] iteration 5336 : model1 loss : 0.437560 model2 loss : 0.027667
[23:29:08.511] iteration 5337 : model1 loss : 0.437868 model2 loss : 0.029563
[23:29:08.684] iteration 5338 : model1 loss : 0.441267 model2 loss : 0.028723
[23:29:08.861] iteration 5339 : model1 loss : 0.437608 model2 loss : 0.028785
[23:29:09.031] iteration 5340 : model1 loss : 0.438423 model2 loss : 0.031323
[23:29:09.206] iteration 5341 : model1 loss : 0.439534 model2 loss : 0.032106
[23:29:09.376] iteration 5342 : model1 loss : 0.435897 model2 loss : 0.028389
[23:29:09.550] iteration 5343 : model1 loss : 0.439348 model2 loss : 0.026266
[23:29:09.724] iteration 5344 : model1 loss : 0.436458 model2 loss : 0.026890
[23:29:09.900] iteration 5345 : model1 loss : 0.438722 model2 loss : 0.028462
[23:29:10.071] iteration 5346 : model1 loss : 0.437985 model2 loss : 0.029053
[23:29:10.250] iteration 5347 : model1 loss : 0.441055 model2 loss : 0.031266
[23:29:10.420] iteration 5348 : model1 loss : 0.436478 model2 loss : 0.031441
[23:29:10.596] iteration 5349 : model1 loss : 0.441750 model2 loss : 0.037247
[23:29:10.770] iteration 5350 : model1 loss : 0.438051 model2 loss : 0.028909
[23:29:10.944] iteration 5351 : model1 loss : 0.440931 model2 loss : 0.028410
[23:29:11.114] iteration 5352 : model1 loss : 0.441334 model2 loss : 0.027469
[23:29:11.292] iteration 5353 : model1 loss : 0.434839 model2 loss : 0.028306
[23:29:11.460] iteration 5354 : model1 loss : 0.438820 model2 loss : 0.033736
[23:29:11.634] iteration 5355 : model1 loss : 0.439574 model2 loss : 0.030148
[23:29:13.800] iteration 5356 : model1 loss : 0.434959 model2 loss : 0.024886
[23:29:13.976] iteration 5357 : model1 loss : 0.437978 model2 loss : 0.030794
[23:29:14.151] iteration 5358 : model1 loss : 0.436544 model2 loss : 0.026490
[23:29:14.330] iteration 5359 : model1 loss : 0.436102 model2 loss : 0.027325
[23:29:14.506] iteration 5360 : model1 loss : 0.438661 model2 loss : 0.036495
[23:29:14.681] iteration 5361 : model1 loss : 0.442596 model2 loss : 0.034690
[23:29:14.858] iteration 5362 : model1 loss : 0.437269 model2 loss : 0.027686
[23:29:15.028] iteration 5363 : model1 loss : 0.437265 model2 loss : 0.029126
[23:29:15.203] iteration 5364 : model1 loss : 0.437561 model2 loss : 0.029792
[23:29:15.375] iteration 5365 : model1 loss : 0.439307 model2 loss : 0.027744
[23:29:15.550] iteration 5366 : model1 loss : 0.437397 model2 loss : 0.027791
[23:29:15.722] iteration 5367 : model1 loss : 0.441922 model2 loss : 0.028093
[23:29:15.899] iteration 5368 : model1 loss : 0.438468 model2 loss : 0.027650
[23:29:16.070] iteration 5369 : model1 loss : 0.435500 model2 loss : 0.027715
[23:29:16.246] iteration 5370 : model1 loss : 0.439217 model2 loss : 0.032430
[23:29:16.419] iteration 5371 : model1 loss : 0.438342 model2 loss : 0.033884
[23:29:16.599] iteration 5372 : model1 loss : 0.440033 model2 loss : 0.028622
[23:29:16.771] iteration 5373 : model1 loss : 0.440340 model2 loss : 0.031903
[23:29:16.945] iteration 5374 : model1 loss : 0.440807 model2 loss : 0.028091
[23:29:17.115] iteration 5375 : model1 loss : 0.435527 model2 loss : 0.027277
[23:29:17.290] iteration 5376 : model1 loss : 0.436019 model2 loss : 0.026851
[23:29:19.488] iteration 5377 : model1 loss : 0.442055 model2 loss : 0.033979
[23:29:19.661] iteration 5378 : model1 loss : 0.438921 model2 loss : 0.028140
[23:29:19.842] iteration 5379 : model1 loss : 0.436894 model2 loss : 0.026477
[23:29:20.013] iteration 5380 : model1 loss : 0.438421 model2 loss : 0.027161
[23:29:20.189] iteration 5381 : model1 loss : 0.437548 model2 loss : 0.028289
[23:29:20.362] iteration 5382 : model1 loss : 0.438432 model2 loss : 0.026232
[23:29:20.536] iteration 5383 : model1 loss : 0.438121 model2 loss : 0.031703
[23:29:20.708] iteration 5384 : model1 loss : 0.435275 model2 loss : 0.025024
[23:29:20.883] iteration 5385 : model1 loss : 0.436229 model2 loss : 0.030060
[23:29:21.054] iteration 5386 : model1 loss : 0.438421 model2 loss : 0.028828
[23:29:21.231] iteration 5387 : model1 loss : 0.441227 model2 loss : 0.028661
[23:29:21.401] iteration 5388 : model1 loss : 0.442082 model2 loss : 0.030929
[23:29:21.575] iteration 5389 : model1 loss : 0.436918 model2 loss : 0.029846
[23:29:21.749] iteration 5390 : model1 loss : 0.440090 model2 loss : 0.029943
[23:29:21.926] iteration 5391 : model1 loss : 0.431940 model2 loss : 0.026036
[23:29:22.095] iteration 5392 : model1 loss : 0.433652 model2 loss : 0.023548
[23:29:22.274] iteration 5393 : model1 loss : 0.437319 model2 loss : 0.026313
[23:29:22.450] iteration 5394 : model1 loss : 0.441204 model2 loss : 0.030776
[23:29:22.630] iteration 5395 : model1 loss : 0.437486 model2 loss : 0.034349
[23:29:22.801] iteration 5396 : model1 loss : 0.436314 model2 loss : 0.025195
[23:29:22.975] iteration 5397 : model1 loss : 0.439003 model2 loss : 0.026244
[23:29:25.123] iteration 5398 : model1 loss : 0.435447 model2 loss : 0.023372
[23:29:25.294] iteration 5399 : model1 loss : 0.439400 model2 loss : 0.025394
[23:29:25.471] iteration 5400 : model1 loss : 0.438714 model2 loss : 0.028563
[23:29:25.646] iteration 5401 : model1 loss : 0.438490 model2 loss : 0.028066
[23:29:25.823] iteration 5402 : model1 loss : 0.436345 model2 loss : 0.025588
[23:29:25.993] iteration 5403 : model1 loss : 0.438896 model2 loss : 0.029792
[23:29:26.169] iteration 5404 : model1 loss : 0.441833 model2 loss : 0.031521
[23:29:26.344] iteration 5405 : model1 loss : 0.438014 model2 loss : 0.028380
[23:29:26.523] iteration 5406 : model1 loss : 0.434606 model2 loss : 0.028783
[23:29:26.695] iteration 5407 : model1 loss : 0.439459 model2 loss : 0.026494
[23:29:26.871] iteration 5408 : model1 loss : 0.441233 model2 loss : 0.030690
[23:29:27.041] iteration 5409 : model1 loss : 0.437138 model2 loss : 0.027906
[23:29:27.220] iteration 5410 : model1 loss : 0.436753 model2 loss : 0.027284
[23:29:27.391] iteration 5411 : model1 loss : 0.438293 model2 loss : 0.029692
[23:29:27.568] iteration 5412 : model1 loss : 0.437689 model2 loss : 0.029147
[23:29:27.742] iteration 5413 : model1 loss : 0.441220 model2 loss : 0.031584
[23:29:27.917] iteration 5414 : model1 loss : 0.436577 model2 loss : 0.026222
[23:29:28.087] iteration 5415 : model1 loss : 0.434571 model2 loss : 0.024895
[23:29:28.265] iteration 5416 : model1 loss : 0.436465 model2 loss : 0.024754
[23:29:28.433] iteration 5417 : model1 loss : 0.438811 model2 loss : 0.024286
[23:29:28.609] iteration 5418 : model1 loss : 0.438380 model2 loss : 0.028210
[23:29:30.748] iteration 5419 : model1 loss : 0.439657 model2 loss : 0.031372
[23:29:30.925] iteration 5420 : model1 loss : 0.440157 model2 loss : 0.025857
[23:29:31.104] iteration 5421 : model1 loss : 0.435174 model2 loss : 0.023171
[23:29:31.276] iteration 5422 : model1 loss : 0.436691 model2 loss : 0.027391
[23:29:31.453] iteration 5423 : model1 loss : 0.435674 model2 loss : 0.026950
[23:29:31.625] iteration 5424 : model1 loss : 0.437751 model2 loss : 0.026835
[23:29:31.802] iteration 5425 : model1 loss : 0.437917 model2 loss : 0.026555
[23:29:31.971] iteration 5426 : model1 loss : 0.437808 model2 loss : 0.026930
[23:29:32.148] iteration 5427 : model1 loss : 0.443481 model2 loss : 0.029400
[23:29:32.324] iteration 5428 : model1 loss : 0.435821 model2 loss : 0.028564
[23:29:32.503] iteration 5429 : model1 loss : 0.437251 model2 loss : 0.027896
[23:29:32.673] iteration 5430 : model1 loss : 0.436087 model2 loss : 0.023858
[23:29:32.849] iteration 5431 : model1 loss : 0.439395 model2 loss : 0.026420
[23:29:33.019] iteration 5432 : model1 loss : 0.439536 model2 loss : 0.024365
[23:29:33.193] iteration 5433 : model1 loss : 0.437443 model2 loss : 0.026314
[23:29:33.364] iteration 5434 : model1 loss : 0.436449 model2 loss : 0.024819
[23:29:33.541] iteration 5435 : model1 loss : 0.433736 model2 loss : 0.026708
[23:29:33.714] iteration 5436 : model1 loss : 0.434311 model2 loss : 0.024613
[23:29:33.891] iteration 5437 : model1 loss : 0.439667 model2 loss : 0.028121
[23:29:34.059] iteration 5438 : model1 loss : 0.433674 model2 loss : 0.023911
[23:29:34.234] iteration 5439 : model1 loss : 0.443315 model2 loss : 0.035429
[23:29:36.315] iteration 5440 : model1 loss : 0.434592 model2 loss : 0.024850
[23:29:36.485] iteration 5441 : model1 loss : 0.437913 model2 loss : 0.026542
[23:29:36.663] iteration 5442 : model1 loss : 0.437361 model2 loss : 0.026421
[23:29:36.838] iteration 5443 : model1 loss : 0.435655 model2 loss : 0.026145
[23:29:37.012] iteration 5444 : model1 loss : 0.441999 model2 loss : 0.027599
[23:29:37.182] iteration 5445 : model1 loss : 0.434781 model2 loss : 0.027682
[23:29:37.361] iteration 5446 : model1 loss : 0.441601 model2 loss : 0.033884
[23:29:37.534] iteration 5447 : model1 loss : 0.438028 model2 loss : 0.024570
[23:29:37.711] iteration 5448 : model1 loss : 0.437002 model2 loss : 0.023267
[23:29:37.884] iteration 5449 : model1 loss : 0.438725 model2 loss : 0.023873
[23:29:38.060] iteration 5450 : model1 loss : 0.436975 model2 loss : 0.026677
[23:29:38.232] iteration 5451 : model1 loss : 0.440222 model2 loss : 0.029282
[23:29:38.409] iteration 5452 : model1 loss : 0.438991 model2 loss : 0.029591
[23:29:38.583] iteration 5453 : model1 loss : 0.436612 model2 loss : 0.028240
[23:29:38.761] iteration 5454 : model1 loss : 0.439684 model2 loss : 0.025772
[23:29:38.933] iteration 5455 : model1 loss : 0.436834 model2 loss : 0.026816
[23:29:39.104] iteration 5456 : model1 loss : 0.435326 model2 loss : 0.025300
[23:29:39.276] iteration 5457 : model1 loss : 0.439317 model2 loss : 0.024418
[23:29:39.453] iteration 5458 : model1 loss : 0.435298 model2 loss : 0.025614
[23:29:39.623] iteration 5459 : model1 loss : 0.438405 model2 loss : 0.026815
[23:29:39.798] iteration 5460 : model1 loss : 0.437385 model2 loss : 0.030186
[23:29:41.927] iteration 5461 : model1 loss : 0.438620 model2 loss : 0.027447
[23:29:42.103] iteration 5462 : model1 loss : 0.435785 model2 loss : 0.022466
[23:29:42.281] iteration 5463 : model1 loss : 0.434771 model2 loss : 0.026940
[23:29:42.455] iteration 5464 : model1 loss : 0.436691 model2 loss : 0.024636
[23:29:42.631] iteration 5465 : model1 loss : 0.437957 model2 loss : 0.027437
[23:29:42.805] iteration 5466 : model1 loss : 0.434312 model2 loss : 0.023408
[23:29:42.980] iteration 5467 : model1 loss : 0.437310 model2 loss : 0.028467
[23:29:43.150] iteration 5468 : model1 loss : 0.433669 model2 loss : 0.022478
[23:29:43.328] iteration 5469 : model1 loss : 0.438658 model2 loss : 0.027160
[23:29:43.499] iteration 5470 : model1 loss : 0.438147 model2 loss : 0.031167
[23:29:43.671] iteration 5471 : model1 loss : 0.438912 model2 loss : 0.027201
[23:29:43.845] iteration 5472 : model1 loss : 0.441371 model2 loss : 0.029363
[23:29:44.018] iteration 5473 : model1 loss : 0.437303 model2 loss : 0.024919
[23:29:44.191] iteration 5474 : model1 loss : 0.442806 model2 loss : 0.033914
[23:29:44.368] iteration 5475 : model1 loss : 0.434273 model2 loss : 0.024854
[23:29:44.538] iteration 5476 : model1 loss : 0.437511 model2 loss : 0.028896
[23:29:44.712] iteration 5477 : model1 loss : 0.441313 model2 loss : 0.026261
[23:29:44.886] iteration 5478 : model1 loss : 0.437525 model2 loss : 0.024379
[23:29:45.062] iteration 5479 : model1 loss : 0.439666 model2 loss : 0.030919
[23:29:45.233] iteration 5480 : model1 loss : 0.436748 model2 loss : 0.024575
[23:29:45.407] iteration 5481 : model1 loss : 0.440621 model2 loss : 0.030191
[23:29:47.558] iteration 5482 : model1 loss : 0.436256 model2 loss : 0.031064
[23:29:47.736] iteration 5483 : model1 loss : 0.436537 model2 loss : 0.024582
[23:29:47.914] iteration 5484 : model1 loss : 0.438508 model2 loss : 0.026001
[23:29:48.084] iteration 5485 : model1 loss : 0.435424 model2 loss : 0.026703
[23:29:48.262] iteration 5486 : model1 loss : 0.443748 model2 loss : 0.032425
[23:29:48.434] iteration 5487 : model1 loss : 0.433820 model2 loss : 0.023676
[23:29:48.612] iteration 5488 : model1 loss : 0.436622 model2 loss : 0.024281
[23:29:48.786] iteration 5489 : model1 loss : 0.439616 model2 loss : 0.027588
[23:29:48.961] iteration 5490 : model1 loss : 0.437741 model2 loss : 0.025642
[23:29:49.130] iteration 5491 : model1 loss : 0.440162 model2 loss : 0.026239
[23:29:49.307] iteration 5492 : model1 loss : 0.439378 model2 loss : 0.028204
[23:29:49.478] iteration 5493 : model1 loss : 0.440138 model2 loss : 0.027253
[23:29:49.654] iteration 5494 : model1 loss : 0.437871 model2 loss : 0.027725
[23:29:49.830] iteration 5495 : model1 loss : 0.435559 model2 loss : 0.026461
[23:29:50.006] iteration 5496 : model1 loss : 0.440587 model2 loss : 0.024255
[23:29:50.176] iteration 5497 : model1 loss : 0.441531 model2 loss : 0.025693
[23:29:50.352] iteration 5498 : model1 loss : 0.437622 model2 loss : 0.023009
[23:29:50.523] iteration 5499 : model1 loss : 0.433297 model2 loss : 0.023803
[23:29:50.697] iteration 5500 : model1 loss : 0.437058 model2 loss : 0.027488
[23:29:50.869] iteration 5501 : model1 loss : 0.438589 model2 loss : 0.029173
[23:29:51.041] iteration 5502 : model1 loss : 0.439826 model2 loss : 0.031479
[23:29:53.209] iteration 5503 : model1 loss : 0.435594 model2 loss : 0.027137
[23:29:53.383] iteration 5504 : model1 loss : 0.439974 model2 loss : 0.030299
[23:29:53.560] iteration 5505 : model1 loss : 0.440488 model2 loss : 0.027297
[23:29:53.731] iteration 5506 : model1 loss : 0.433767 model2 loss : 0.026248
[23:29:53.907] iteration 5507 : model1 loss : 0.436489 model2 loss : 0.026086
[23:29:54.078] iteration 5508 : model1 loss : 0.436083 model2 loss : 0.028381
[23:29:54.254] iteration 5509 : model1 loss : 0.439075 model2 loss : 0.029922
[23:29:54.428] iteration 5510 : model1 loss : 0.439490 model2 loss : 0.034815
[23:29:54.605] iteration 5511 : model1 loss : 0.440382 model2 loss : 0.025912
[23:29:54.777] iteration 5512 : model1 loss : 0.436674 model2 loss : 0.022618
[23:29:54.953] iteration 5513 : model1 loss : 0.432567 model2 loss : 0.024061
[23:29:55.123] iteration 5514 : model1 loss : 0.437729 model2 loss : 0.026976
[23:29:55.301] iteration 5515 : model1 loss : 0.440944 model2 loss : 0.027136
[23:29:55.471] iteration 5516 : model1 loss : 0.440653 model2 loss : 0.026145
[23:29:55.647] iteration 5517 : model1 loss : 0.435377 model2 loss : 0.026720
[23:29:55.820] iteration 5518 : model1 loss : 0.436363 model2 loss : 0.027542
[23:29:55.995] iteration 5519 : model1 loss : 0.436619 model2 loss : 0.026578
[23:29:56.169] iteration 5520 : model1 loss : 0.438647 model2 loss : 0.029230
[23:29:56.346] iteration 5521 : model1 loss : 0.439841 model2 loss : 0.031115
[23:29:56.517] iteration 5522 : model1 loss : 0.438693 model2 loss : 0.029080
[23:29:56.693] iteration 5523 : model1 loss : 0.438081 model2 loss : 0.024082
[23:29:58.849] iteration 5524 : model1 loss : 0.438943 model2 loss : 0.025931
[23:29:59.022] iteration 5525 : model1 loss : 0.435246 model2 loss : 0.027692
[23:29:59.199] iteration 5526 : model1 loss : 0.441079 model2 loss : 0.033557
[23:29:59.372] iteration 5527 : model1 loss : 0.435718 model2 loss : 0.026474
[23:29:59.548] iteration 5528 : model1 loss : 0.439735 model2 loss : 0.025845
[23:29:59.719] iteration 5529 : model1 loss : 0.437410 model2 loss : 0.037791
[23:29:59.896] iteration 5530 : model1 loss : 0.434495 model2 loss : 0.022463
[23:30:00.069] iteration 5531 : model1 loss : 0.440189 model2 loss : 0.030631
[23:30:00.247] iteration 5532 : model1 loss : 0.435947 model2 loss : 0.027786
[23:30:00.419] iteration 5533 : model1 loss : 0.435112 model2 loss : 0.025277
[23:30:00.599] iteration 5534 : model1 loss : 0.442922 model2 loss : 0.032064
[23:30:00.772] iteration 5535 : model1 loss : 0.439809 model2 loss : 0.027503
[23:30:00.948] iteration 5536 : model1 loss : 0.438628 model2 loss : 0.027946
[23:30:01.118] iteration 5537 : model1 loss : 0.436718 model2 loss : 0.024915
[23:30:01.292] iteration 5538 : model1 loss : 0.442370 model2 loss : 0.029219
[23:30:01.463] iteration 5539 : model1 loss : 0.430348 model2 loss : 0.021317
[23:30:01.642] iteration 5540 : model1 loss : 0.446612 model2 loss : 0.033176
[23:30:01.817] iteration 5541 : model1 loss : 0.439301 model2 loss : 0.025394
[23:30:01.994] iteration 5542 : model1 loss : 0.438492 model2 loss : 0.029306
[23:30:02.166] iteration 5543 : model1 loss : 0.439340 model2 loss : 0.025758
[23:30:02.343] iteration 5544 : model1 loss : 0.434152 model2 loss : 0.028057
[23:30:04.499] iteration 5545 : model1 loss : 0.439660 model2 loss : 0.031489
[23:30:04.672] iteration 5546 : model1 loss : 0.437250 model2 loss : 0.026828
[23:30:04.850] iteration 5547 : model1 loss : 0.437898 model2 loss : 0.029007
[23:30:05.020] iteration 5548 : model1 loss : 0.439372 model2 loss : 0.030087
[23:30:05.195] iteration 5549 : model1 loss : 0.436404 model2 loss : 0.026030
[23:30:05.370] iteration 5550 : model1 loss : 0.440467 model2 loss : 0.025444
[23:30:05.546] iteration 5551 : model1 loss : 0.437770 model2 loss : 0.028095
[23:30:05.715] iteration 5552 : model1 loss : 0.435893 model2 loss : 0.025602
[23:30:05.896] iteration 5553 : model1 loss : 0.441639 model2 loss : 0.030004
[23:30:06.068] iteration 5554 : model1 loss : 0.438826 model2 loss : 0.023780
[23:30:06.244] iteration 5555 : model1 loss : 0.437073 model2 loss : 0.025798
[23:30:06.416] iteration 5556 : model1 loss : 0.445448 model2 loss : 0.029807
[23:30:06.596] iteration 5557 : model1 loss : 0.437294 model2 loss : 0.027344
[23:30:06.769] iteration 5558 : model1 loss : 0.440786 model2 loss : 0.028467
[23:30:06.943] iteration 5559 : model1 loss : 0.438040 model2 loss : 0.023871
[23:30:07.112] iteration 5560 : model1 loss : 0.437441 model2 loss : 0.027894
[23:30:07.288] iteration 5561 : model1 loss : 0.438597 model2 loss : 0.023092
[23:30:07.464] iteration 5562 : model1 loss : 0.437305 model2 loss : 0.024831
[23:30:07.640] iteration 5563 : model1 loss : 0.439304 model2 loss : 0.026172
[23:30:07.813] iteration 5564 : model1 loss : 0.439428 model2 loss : 0.024776
[23:30:07.990] iteration 5565 : model1 loss : 0.432384 model2 loss : 0.027315
[23:30:10.152] iteration 5566 : model1 loss : 0.437591 model2 loss : 0.027257
[23:30:10.329] iteration 5567 : model1 loss : 0.436817 model2 loss : 0.025356
[23:30:10.507] iteration 5568 : model1 loss : 0.434465 model2 loss : 0.024342
[23:30:10.678] iteration 5569 : model1 loss : 0.443523 model2 loss : 0.032897
[23:30:10.856] iteration 5570 : model1 loss : 0.440883 model2 loss : 0.028327
[23:30:11.025] iteration 5571 : model1 loss : 0.438761 model2 loss : 0.025680
[23:30:11.199] iteration 5572 : model1 loss : 0.433786 model2 loss : 0.025128
[23:30:11.371] iteration 5573 : model1 loss : 0.441236 model2 loss : 0.026079
[23:30:11.546] iteration 5574 : model1 loss : 0.437381 model2 loss : 0.024661
[23:30:11.717] iteration 5575 : model1 loss : 0.436813 model2 loss : 0.024895
[23:30:11.897] iteration 5576 : model1 loss : 0.436915 model2 loss : 0.024397
[23:30:12.069] iteration 5577 : model1 loss : 0.437346 model2 loss : 0.028843
[23:30:12.241] iteration 5578 : model1 loss : 0.440386 model2 loss : 0.030572
[23:30:12.418] iteration 5579 : model1 loss : 0.438132 model2 loss : 0.024270
[23:30:12.597] iteration 5580 : model1 loss : 0.439713 model2 loss : 0.030136
[23:30:12.769] iteration 5581 : model1 loss : 0.438091 model2 loss : 0.028992
[23:30:12.943] iteration 5582 : model1 loss : 0.439076 model2 loss : 0.026462
[23:30:13.113] iteration 5583 : model1 loss : 0.433833 model2 loss : 0.025001
[23:30:13.290] iteration 5584 : model1 loss : 0.436581 model2 loss : 0.025286
[23:30:13.463] iteration 5585 : model1 loss : 0.438625 model2 loss : 0.025879
[23:30:13.634] iteration 5586 : model1 loss : 0.434337 model2 loss : 0.031935
[23:30:15.739] iteration 5587 : model1 loss : 0.441462 model2 loss : 0.039172
[23:30:15.914] iteration 5588 : model1 loss : 0.436847 model2 loss : 0.023851
[23:30:16.095] iteration 5589 : model1 loss : 0.439356 model2 loss : 0.024776
[23:30:16.266] iteration 5590 : model1 loss : 0.437507 model2 loss : 0.021640
[23:30:16.445] iteration 5591 : model1 loss : 0.437640 model2 loss : 0.027422
[23:30:16.618] iteration 5592 : model1 loss : 0.439214 model2 loss : 0.025812
[23:30:16.795] iteration 5593 : model1 loss : 0.437182 model2 loss : 0.030355
[23:30:16.967] iteration 5594 : model1 loss : 0.433599 model2 loss : 0.027707
[23:30:17.142] iteration 5595 : model1 loss : 0.438104 model2 loss : 0.025583
[23:30:17.317] iteration 5596 : model1 loss : 0.437246 model2 loss : 0.024572
[23:30:17.500] iteration 5597 : model1 loss : 0.444123 model2 loss : 0.031444
[23:30:17.670] iteration 5598 : model1 loss : 0.436589 model2 loss : 0.024090
[23:30:17.849] iteration 5599 : model1 loss : 0.437265 model2 loss : 0.024411
[23:30:18.019] iteration 5600 : model1 loss : 0.437309 model2 loss : 0.027007
[23:30:18.196] iteration 5601 : model1 loss : 0.440754 model2 loss : 0.028660
[23:30:18.371] iteration 5602 : model1 loss : 0.440146 model2 loss : 0.028047
[23:30:18.546] iteration 5603 : model1 loss : 0.436037 model2 loss : 0.027908
[23:30:18.716] iteration 5604 : model1 loss : 0.438075 model2 loss : 0.030584
[23:30:18.892] iteration 5605 : model1 loss : 0.437802 model2 loss : 0.025919
[23:30:19.062] iteration 5606 : model1 loss : 0.437133 model2 loss : 0.027721
[23:30:19.235] iteration 5607 : model1 loss : 0.437813 model2 loss : 0.027860
[23:30:21.329] iteration 5608 : model1 loss : 0.440104 model2 loss : 0.026950
[23:30:21.500] iteration 5609 : model1 loss : 0.436812 model2 loss : 0.024639
[23:30:21.677] iteration 5610 : model1 loss : 0.439175 model2 loss : 0.028382
[23:30:21.852] iteration 5611 : model1 loss : 0.438132 model2 loss : 0.029978
[23:30:22.030] iteration 5612 : model1 loss : 0.439613 model2 loss : 0.027618
[23:30:22.201] iteration 5613 : model1 loss : 0.438081 model2 loss : 0.026039
[23:30:22.377] iteration 5614 : model1 loss : 0.438666 model2 loss : 0.027482
[23:30:22.547] iteration 5615 : model1 loss : 0.437632 model2 loss : 0.030294
[23:30:22.722] iteration 5616 : model1 loss : 0.438301 model2 loss : 0.024122
[23:30:22.896] iteration 5617 : model1 loss : 0.436762 model2 loss : 0.028400
[23:30:23.073] iteration 5618 : model1 loss : 0.436066 model2 loss : 0.024425
[23:30:23.242] iteration 5619 : model1 loss : 0.434374 model2 loss : 0.025056
[23:30:23.418] iteration 5620 : model1 loss : 0.434605 model2 loss : 0.023321
[23:30:23.591] iteration 5621 : model1 loss : 0.437413 model2 loss : 0.027040
[23:30:23.767] iteration 5622 : model1 loss : 0.441795 model2 loss : 0.031774
[23:30:23.939] iteration 5623 : model1 loss : 0.439654 model2 loss : 0.027322
[23:30:24.118] iteration 5624 : model1 loss : 0.435622 model2 loss : 0.028658
[23:30:24.289] iteration 5625 : model1 loss : 0.432217 model2 loss : 0.024680
[23:30:24.468] iteration 5626 : model1 loss : 0.439771 model2 loss : 0.025802
[23:30:24.637] iteration 5627 : model1 loss : 0.440849 model2 loss : 0.025833
[23:30:24.810] iteration 5628 : model1 loss : 0.440549 model2 loss : 0.031123
[23:30:26.908] iteration 5629 : model1 loss : 0.438673 model2 loss : 0.024685
[23:30:27.079] iteration 5630 : model1 loss : 0.434594 model2 loss : 0.023534
[23:30:27.255] iteration 5631 : model1 loss : 0.437274 model2 loss : 0.023415
[23:30:27.429] iteration 5632 : model1 loss : 0.439367 model2 loss : 0.029015
[23:30:27.606] iteration 5633 : model1 loss : 0.433681 model2 loss : 0.024087
[23:30:27.776] iteration 5634 : model1 loss : 0.433441 model2 loss : 0.027801
[23:30:27.951] iteration 5635 : model1 loss : 0.440049 model2 loss : 0.028738
[23:30:28.125] iteration 5636 : model1 loss : 0.436214 model2 loss : 0.024249
[23:30:28.302] iteration 5637 : model1 loss : 0.436180 model2 loss : 0.025829
[23:30:28.475] iteration 5638 : model1 loss : 0.434627 model2 loss : 0.024106
[23:30:28.652] iteration 5639 : model1 loss : 0.438994 model2 loss : 0.031042
[23:30:28.823] iteration 5640 : model1 loss : 0.435627 model2 loss : 0.028050
[23:30:28.999] iteration 5641 : model1 loss : 0.437250 model2 loss : 0.027395
[23:30:29.171] iteration 5642 : model1 loss : 0.443705 model2 loss : 0.032059
[23:30:29.348] iteration 5643 : model1 loss : 0.436433 model2 loss : 0.024245
[23:30:29.519] iteration 5644 : model1 loss : 0.435421 model2 loss : 0.025021
[23:30:29.696] iteration 5645 : model1 loss : 0.436605 model2 loss : 0.026323
[23:30:29.869] iteration 5646 : model1 loss : 0.443107 model2 loss : 0.032275
[23:30:30.043] iteration 5647 : model1 loss : 0.439958 model2 loss : 0.025916
[23:30:30.216] iteration 5648 : model1 loss : 0.441918 model2 loss : 0.025389
[23:30:30.395] iteration 5649 : model1 loss : 0.436575 model2 loss : 0.026628
[23:30:32.534] iteration 5650 : model1 loss : 0.434913 model2 loss : 0.025131
[23:30:32.705] iteration 5651 : model1 loss : 0.434434 model2 loss : 0.023288
[23:30:32.885] iteration 5652 : model1 loss : 0.439437 model2 loss : 0.024840
[23:30:33.056] iteration 5653 : model1 loss : 0.438893 model2 loss : 0.024337
[23:30:33.231] iteration 5654 : model1 loss : 0.446044 model2 loss : 0.032103
[23:30:33.406] iteration 5655 : model1 loss : 0.433191 model2 loss : 0.024871
[23:30:33.580] iteration 5656 : model1 loss : 0.439901 model2 loss : 0.031580
[23:30:33.750] iteration 5657 : model1 loss : 0.439806 model2 loss : 0.031736
[23:30:33.928] iteration 5658 : model1 loss : 0.442933 model2 loss : 0.027438
[23:30:34.101] iteration 5659 : model1 loss : 0.439355 model2 loss : 0.026849
[23:30:34.276] iteration 5660 : model1 loss : 0.437954 model2 loss : 0.027459
[23:30:34.448] iteration 5661 : model1 loss : 0.442202 model2 loss : 0.031521
[23:30:34.628] iteration 5662 : model1 loss : 0.436122 model2 loss : 0.025103
[23:30:34.805] iteration 5663 : model1 loss : 0.436953 model2 loss : 0.024098
[23:30:34.980] iteration 5664 : model1 loss : 0.431133 model2 loss : 0.024351
[23:30:35.151] iteration 5665 : model1 loss : 0.435422 model2 loss : 0.026046
[23:30:35.335] iteration 5666 : model1 loss : 0.437463 model2 loss : 0.028293
[23:30:35.509] iteration 5667 : model1 loss : 0.438252 model2 loss : 0.025164
[23:30:35.685] iteration 5668 : model1 loss : 0.437350 model2 loss : 0.026990
[23:30:35.858] iteration 5669 : model1 loss : 0.438874 model2 loss : 0.027457
[23:30:36.033] iteration 5670 : model1 loss : 0.436664 model2 loss : 0.027485
[23:30:38.217] iteration 5671 : model1 loss : 0.438340 model2 loss : 0.022718
[23:30:38.393] iteration 5672 : model1 loss : 0.432699 model2 loss : 0.025102
[23:30:38.572] iteration 5673 : model1 loss : 0.434595 model2 loss : 0.021985
[23:30:38.743] iteration 5674 : model1 loss : 0.436756 model2 loss : 0.024491
[23:30:38.919] iteration 5675 : model1 loss : 0.442971 model2 loss : 0.028491
[23:30:39.089] iteration 5676 : model1 loss : 0.441181 model2 loss : 0.031394
[23:30:39.264] iteration 5677 : model1 loss : 0.436256 model2 loss : 0.024800
[23:30:39.439] iteration 5678 : model1 loss : 0.437210 model2 loss : 0.023233
[23:30:39.617] iteration 5679 : model1 loss : 0.435014 model2 loss : 0.023917
[23:30:39.789] iteration 5680 : model1 loss : 0.440590 model2 loss : 0.028669
[23:30:39.966] iteration 5681 : model1 loss : 0.432669 model2 loss : 0.022993
[23:30:40.138] iteration 5682 : model1 loss : 0.437418 model2 loss : 0.030619
[23:30:40.316] iteration 5683 : model1 loss : 0.435596 model2 loss : 0.024610
[23:30:40.490] iteration 5684 : model1 loss : 0.442236 model2 loss : 0.026061
[23:30:40.665] iteration 5685 : model1 loss : 0.441360 model2 loss : 0.032862
[23:30:40.839] iteration 5686 : model1 loss : 0.436956 model2 loss : 0.026902
[23:30:41.015] iteration 5687 : model1 loss : 0.437510 model2 loss : 0.026839
[23:30:41.184] iteration 5688 : model1 loss : 0.436785 model2 loss : 0.028683
[23:30:41.370] iteration 5689 : model1 loss : 0.433175 model2 loss : 0.028339
[23:30:41.544] iteration 5690 : model1 loss : 0.441136 model2 loss : 0.032904
[23:30:41.720] iteration 5691 : model1 loss : 0.437736 model2 loss : 0.028635
[23:30:43.869] iteration 5692 : model1 loss : 0.437635 model2 loss : 0.028263
[23:30:44.041] iteration 5693 : model1 loss : 0.435827 model2 loss : 0.027175
[23:30:44.217] iteration 5694 : model1 loss : 0.433452 model2 loss : 0.031323
[23:30:44.393] iteration 5695 : model1 loss : 0.434789 model2 loss : 0.024915
[23:30:44.570] iteration 5696 : model1 loss : 0.438469 model2 loss : 0.024935
[23:30:44.742] iteration 5697 : model1 loss : 0.437848 model2 loss : 0.028224
[23:30:44.920] iteration 5698 : model1 loss : 0.437198 model2 loss : 0.024118
[23:30:45.093] iteration 5699 : model1 loss : 0.437336 model2 loss : 0.024864
[23:30:45.268] iteration 5700 : model1 loss : 0.437464 model2 loss : 0.025535
[23:30:45.440] iteration 5701 : model1 loss : 0.439126 model2 loss : 0.027199
[23:30:45.617] iteration 5702 : model1 loss : 0.436301 model2 loss : 0.027409
[23:30:45.790] iteration 5703 : model1 loss : 0.434512 model2 loss : 0.026680
[23:30:45.966] iteration 5704 : model1 loss : 0.436472 model2 loss : 0.034013
[23:30:46.138] iteration 5705 : model1 loss : 0.440429 model2 loss : 0.033152
[23:30:46.316] iteration 5706 : model1 loss : 0.443540 model2 loss : 0.034722
[23:30:46.491] iteration 5707 : model1 loss : 0.437080 model2 loss : 0.027381
[23:30:46.665] iteration 5708 : model1 loss : 0.440957 model2 loss : 0.032915
[23:30:46.839] iteration 5709 : model1 loss : 0.437474 model2 loss : 0.029438
[23:30:47.014] iteration 5710 : model1 loss : 0.433550 model2 loss : 0.024162
[23:30:47.183] iteration 5711 : model1 loss : 0.438639 model2 loss : 0.027545
[23:30:47.360] iteration 5712 : model1 loss : 0.437811 model2 loss : 0.025652
[23:30:49.542] iteration 5713 : model1 loss : 0.430144 model2 loss : 0.024056
[23:30:49.717] iteration 5714 : model1 loss : 0.441189 model2 loss : 0.030545
[23:30:49.896] iteration 5715 : model1 loss : 0.436218 model2 loss : 0.024622
[23:30:50.066] iteration 5716 : model1 loss : 0.437025 model2 loss : 0.027045
[23:30:50.238] iteration 5717 : model1 loss : 0.437319 model2 loss : 0.028972
[23:30:50.415] iteration 5718 : model1 loss : 0.440388 model2 loss : 0.030648
[23:30:50.597] iteration 5719 : model1 loss : 0.438918 model2 loss : 0.027288
[23:30:50.769] iteration 5720 : model1 loss : 0.437347 model2 loss : 0.029230
[23:30:50.945] iteration 5721 : model1 loss : 0.441913 model2 loss : 0.030688
[23:30:51.116] iteration 5722 : model1 loss : 0.433098 model2 loss : 0.026191
[23:30:51.292] iteration 5723 : model1 loss : 0.436619 model2 loss : 0.026847
[23:30:51.465] iteration 5724 : model1 loss : 0.436159 model2 loss : 0.025313
[23:30:51.644] iteration 5725 : model1 loss : 0.440101 model2 loss : 0.031361
[23:30:51.815] iteration 5726 : model1 loss : 0.440841 model2 loss : 0.024379
[23:30:51.992] iteration 5727 : model1 loss : 0.444420 model2 loss : 0.025981
[23:30:52.164] iteration 5728 : model1 loss : 0.438826 model2 loss : 0.028915
[23:30:52.343] iteration 5729 : model1 loss : 0.437977 model2 loss : 0.023771
[23:30:52.520] iteration 5730 : model1 loss : 0.440335 model2 loss : 0.029702
[23:30:52.697] iteration 5731 : model1 loss : 0.437354 model2 loss : 0.026213
[23:30:52.870] iteration 5732 : model1 loss : 0.438096 model2 loss : 0.026573
[23:30:53.042] iteration 5733 : model1 loss : 0.443955 model2 loss : 0.029750
[23:30:55.167] iteration 5734 : model1 loss : 0.432990 model2 loss : 0.023210
[23:30:55.339] iteration 5735 : model1 loss : 0.435826 model2 loss : 0.025496
[23:30:55.519] iteration 5736 : model1 loss : 0.442406 model2 loss : 0.029778
[23:30:55.691] iteration 5737 : model1 loss : 0.435092 model2 loss : 0.025175
[23:30:55.867] iteration 5738 : model1 loss : 0.437346 model2 loss : 0.028716
[23:30:56.041] iteration 5739 : model1 loss : 0.440233 model2 loss : 0.031782
[23:30:56.220] iteration 5740 : model1 loss : 0.436204 model2 loss : 0.027604
[23:30:56.395] iteration 5741 : model1 loss : 0.438623 model2 loss : 0.026752
[23:30:56.574] iteration 5742 : model1 loss : 0.440158 model2 loss : 0.026746
[23:30:56.745] iteration 5743 : model1 loss : 0.435213 model2 loss : 0.026534
[23:30:56.923] iteration 5744 : model1 loss : 0.437334 model2 loss : 0.028511
[23:30:57.092] iteration 5745 : model1 loss : 0.440741 model2 loss : 0.028051
[23:30:57.267] iteration 5746 : model1 loss : 0.438676 model2 loss : 0.029093
[23:30:57.443] iteration 5747 : model1 loss : 0.439711 model2 loss : 0.023884
[23:30:57.624] iteration 5748 : model1 loss : 0.440739 model2 loss : 0.024739
[23:30:57.795] iteration 5749 : model1 loss : 0.440173 model2 loss : 0.024899
[23:30:57.970] iteration 5750 : model1 loss : 0.438826 model2 loss : 0.026115
[23:30:58.141] iteration 5751 : model1 loss : 0.435047 model2 loss : 0.023261
[23:30:58.323] iteration 5752 : model1 loss : 0.438911 model2 loss : 0.029808
[23:30:58.495] iteration 5753 : model1 loss : 0.437622 model2 loss : 0.026600
[23:30:58.669] iteration 5754 : model1 loss : 0.435562 model2 loss : 0.025557
[23:31:00.802] iteration 5755 : model1 loss : 0.432298 model2 loss : 0.023718
[23:31:00.975] iteration 5756 : model1 loss : 0.434552 model2 loss : 0.028146
[23:31:01.152] iteration 5757 : model1 loss : 0.438645 model2 loss : 0.026913
[23:31:01.327] iteration 5758 : model1 loss : 0.437411 model2 loss : 0.030502
[23:31:01.507] iteration 5759 : model1 loss : 0.437605 model2 loss : 0.026186
[23:31:01.677] iteration 5760 : model1 loss : 0.434432 model2 loss : 0.023615
[23:31:01.852] iteration 5761 : model1 loss : 0.441204 model2 loss : 0.031561
[23:31:02.026] iteration 5762 : model1 loss : 0.437314 model2 loss : 0.025752
[23:31:02.203] iteration 5763 : model1 loss : 0.437765 model2 loss : 0.025201
[23:31:02.379] iteration 5764 : model1 loss : 0.440204 model2 loss : 0.023405
[23:31:02.559] iteration 5765 : model1 loss : 0.435745 model2 loss : 0.023347
[23:31:02.730] iteration 5766 : model1 loss : 0.436367 model2 loss : 0.028844
[23:31:02.906] iteration 5767 : model1 loss : 0.438053 model2 loss : 0.033244
[23:31:03.077] iteration 5768 : model1 loss : 0.445462 model2 loss : 0.033198
[23:31:03.253] iteration 5769 : model1 loss : 0.435361 model2 loss : 0.026451
[23:31:03.425] iteration 5770 : model1 loss : 0.441834 model2 loss : 0.029604
[23:31:03.613] iteration 5771 : model1 loss : 0.437197 model2 loss : 0.028021
[23:31:03.784] iteration 5772 : model1 loss : 0.437000 model2 loss : 0.028724
[23:31:03.961] iteration 5773 : model1 loss : 0.434094 model2 loss : 0.022181
[23:31:04.130] iteration 5774 : model1 loss : 0.439274 model2 loss : 0.029042
[23:31:04.301] iteration 5775 : model1 loss : 0.439030 model2 loss : 0.026726
[23:31:06.421] iteration 5776 : model1 loss : 0.435800 model2 loss : 0.027951
[23:31:06.594] iteration 5777 : model1 loss : 0.437719 model2 loss : 0.028999
[23:31:06.770] iteration 5778 : model1 loss : 0.434105 model2 loss : 0.024513
[23:31:06.943] iteration 5779 : model1 loss : 0.442198 model2 loss : 0.029164
[23:31:07.120] iteration 5780 : model1 loss : 0.440646 model2 loss : 0.029065
[23:31:07.291] iteration 5781 : model1 loss : 0.436802 model2 loss : 0.024443
[23:31:07.474] iteration 5782 : model1 loss : 0.442647 model2 loss : 0.028372
[23:31:07.644] iteration 5783 : model1 loss : 0.442276 model2 loss : 0.032876
[23:31:07.820] iteration 5784 : model1 loss : 0.439245 model2 loss : 0.025718
[23:31:07.994] iteration 5785 : model1 loss : 0.436343 model2 loss : 0.028231
[23:31:08.168] iteration 5786 : model1 loss : 0.435284 model2 loss : 0.024865
[23:31:08.345] iteration 5787 : model1 loss : 0.437810 model2 loss : 0.026945
[23:31:08.526] iteration 5788 : model1 loss : 0.437868 model2 loss : 0.029840
[23:31:08.699] iteration 5789 : model1 loss : 0.434414 model2 loss : 0.026418
[23:31:08.875] iteration 5790 : model1 loss : 0.436987 model2 loss : 0.027634
[23:31:09.047] iteration 5791 : model1 loss : 0.441637 model2 loss : 0.028135
[23:31:09.223] iteration 5792 : model1 loss : 0.432750 model2 loss : 0.023836
[23:31:09.393] iteration 5793 : model1 loss : 0.438098 model2 loss : 0.026331
[23:31:09.571] iteration 5794 : model1 loss : 0.438771 model2 loss : 0.023983
[23:31:09.741] iteration 5795 : model1 loss : 0.439963 model2 loss : 0.028605
[23:31:09.917] iteration 5796 : model1 loss : 0.439474 model2 loss : 0.025226
[23:31:12.046] iteration 5797 : model1 loss : 0.440116 model2 loss : 0.029387
[23:31:12.223] iteration 5798 : model1 loss : 0.441216 model2 loss : 0.028234
[23:31:12.401] iteration 5799 : model1 loss : 0.439130 model2 loss : 0.026472
[23:31:12.573] iteration 5800 : model1 loss : 0.442513 model2 loss : 0.033336
[23:31:12.748] iteration 5801 : model1 loss : 0.437217 model2 loss : 0.027275
[23:31:12.921] iteration 5802 : model1 loss : 0.439760 model2 loss : 0.025397
[23:31:13.096] iteration 5803 : model1 loss : 0.433167 model2 loss : 0.027127
[23:31:13.266] iteration 5804 : model1 loss : 0.440425 model2 loss : 0.027225
[23:31:13.443] iteration 5805 : model1 loss : 0.436663 model2 loss : 0.026323
[23:31:13.617] iteration 5806 : model1 loss : 0.436181 model2 loss : 0.025309
[23:31:13.793] iteration 5807 : model1 loss : 0.436656 model2 loss : 0.025233
[23:31:13.966] iteration 5808 : model1 loss : 0.436732 model2 loss : 0.028974
[23:31:14.142] iteration 5809 : model1 loss : 0.439267 model2 loss : 0.027861
[23:31:14.317] iteration 5810 : model1 loss : 0.434764 model2 loss : 0.020557
[23:31:14.498] iteration 5811 : model1 loss : 0.437787 model2 loss : 0.028181
[23:31:14.668] iteration 5812 : model1 loss : 0.447257 model2 loss : 0.025021
[23:31:14.845] iteration 5813 : model1 loss : 0.438231 model2 loss : 0.025654
[23:31:15.017] iteration 5814 : model1 loss : 0.437102 model2 loss : 0.026652
[23:31:15.195] iteration 5815 : model1 loss : 0.439361 model2 loss : 0.028457
[23:31:15.363] iteration 5816 : model1 loss : 0.441140 model2 loss : 0.026484
[23:31:15.538] iteration 5817 : model1 loss : 0.440946 model2 loss : 0.031823
[23:31:17.679] iteration 5818 : model1 loss : 0.435836 model2 loss : 0.029077
[23:31:17.853] iteration 5819 : model1 loss : 0.438832 model2 loss : 0.027799
[23:31:18.033] iteration 5820 : model1 loss : 0.431443 model2 loss : 0.023765
[23:31:18.205] iteration 5821 : model1 loss : 0.441500 model2 loss : 0.034205
[23:31:18.382] iteration 5822 : model1 loss : 0.440571 model2 loss : 0.030106
[23:31:18.557] iteration 5823 : model1 loss : 0.436588 model2 loss : 0.025998
[23:31:18.732] iteration 5824 : model1 loss : 0.443209 model2 loss : 0.025669
[23:31:18.903] iteration 5825 : model1 loss : 0.436930 model2 loss : 0.025404
[23:31:19.081] iteration 5826 : model1 loss : 0.443111 model2 loss : 0.031806
[23:31:19.252] iteration 5827 : model1 loss : 0.435809 model2 loss : 0.026842
[23:31:19.429] iteration 5828 : model1 loss : 0.437523 model2 loss : 0.025972
[23:31:19.604] iteration 5829 : model1 loss : 0.442701 model2 loss : 0.030671
[23:31:19.781] iteration 5830 : model1 loss : 0.442084 model2 loss : 0.028693
[23:31:19.953] iteration 5831 : model1 loss : 0.436864 model2 loss : 0.025770
[23:31:20.129] iteration 5832 : model1 loss : 0.438506 model2 loss : 0.027286
[23:31:20.300] iteration 5833 : model1 loss : 0.441999 model2 loss : 0.026218
[23:31:20.477] iteration 5834 : model1 loss : 0.438138 model2 loss : 0.024764
[23:31:20.649] iteration 5835 : model1 loss : 0.442587 model2 loss : 0.026769
[23:31:20.825] iteration 5836 : model1 loss : 0.434347 model2 loss : 0.024691
[23:31:20.995] iteration 5837 : model1 loss : 0.440625 model2 loss : 0.026817
[23:31:21.169] iteration 5838 : model1 loss : 0.436591 model2 loss : 0.027836
[23:31:23.296] iteration 5839 : model1 loss : 0.441796 model2 loss : 0.029663
[23:31:23.470] iteration 5840 : model1 loss : 0.434523 model2 loss : 0.028113
[23:31:23.647] iteration 5841 : model1 loss : 0.441346 model2 loss : 0.028891
[23:31:23.817] iteration 5842 : model1 loss : 0.438802 model2 loss : 0.027851
[23:31:23.997] iteration 5843 : model1 loss : 0.435926 model2 loss : 0.023574
[23:31:24.168] iteration 5844 : model1 loss : 0.443519 model2 loss : 0.024151
[23:31:24.345] iteration 5845 : model1 loss : 0.434633 model2 loss : 0.025902
[23:31:24.522] iteration 5846 : model1 loss : 0.439436 model2 loss : 0.027293
[23:31:24.697] iteration 5847 : model1 loss : 0.441627 model2 loss : 0.025146
[23:31:24.866] iteration 5848 : model1 loss : 0.441230 model2 loss : 0.028606
[23:31:25.042] iteration 5849 : model1 loss : 0.435188 model2 loss : 0.026288
[23:31:25.214] iteration 5850 : model1 loss : 0.441202 model2 loss : 0.031480
[23:31:25.389] iteration 5851 : model1 loss : 0.434894 model2 loss : 0.023956
[23:31:25.564] iteration 5852 : model1 loss : 0.432869 model2 loss : 0.028400
[23:31:25.738] iteration 5853 : model1 loss : 0.442719 model2 loss : 0.026782
[23:31:25.908] iteration 5854 : model1 loss : 0.433958 model2 loss : 0.024900
[23:31:26.086] iteration 5855 : model1 loss : 0.440735 model2 loss : 0.026398
[23:31:26.257] iteration 5856 : model1 loss : 0.436334 model2 loss : 0.025135
[23:31:26.434] iteration 5857 : model1 loss : 0.446665 model2 loss : 0.032932
[23:31:26.606] iteration 5858 : model1 loss : 0.434560 model2 loss : 0.023693
[23:31:26.783] iteration 5859 : model1 loss : 0.442965 model2 loss : 0.028260
[23:31:28.914] iteration 5860 : model1 loss : 0.438355 model2 loss : 0.025002
[23:31:29.087] iteration 5861 : model1 loss : 0.436765 model2 loss : 0.027841
[23:31:29.265] iteration 5862 : model1 loss : 0.435261 model2 loss : 0.024924
[23:31:29.438] iteration 5863 : model1 loss : 0.434105 model2 loss : 0.025431
[23:31:29.617] iteration 5864 : model1 loss : 0.437963 model2 loss : 0.026861
[23:31:29.788] iteration 5865 : model1 loss : 0.439479 model2 loss : 0.025774
[23:31:29.963] iteration 5866 : model1 loss : 0.436937 model2 loss : 0.027459
[23:31:30.136] iteration 5867 : model1 loss : 0.439333 model2 loss : 0.027760
[23:31:30.313] iteration 5868 : model1 loss : 0.438409 model2 loss : 0.025445
[23:31:30.488] iteration 5869 : model1 loss : 0.438395 model2 loss : 0.026859
[23:31:30.665] iteration 5870 : model1 loss : 0.434717 model2 loss : 0.024392
[23:31:30.837] iteration 5871 : model1 loss : 0.437971 model2 loss : 0.024228
[23:31:31.012] iteration 5872 : model1 loss : 0.437808 model2 loss : 0.026912
[23:31:31.184] iteration 5873 : model1 loss : 0.440511 model2 loss : 0.030941
[23:31:31.361] iteration 5874 : model1 loss : 0.440344 model2 loss : 0.026024
[23:31:31.535] iteration 5875 : model1 loss : 0.443931 model2 loss : 0.029580
[23:31:31.711] iteration 5876 : model1 loss : 0.440474 model2 loss : 0.027415
[23:31:31.882] iteration 5877 : model1 loss : 0.434292 model2 loss : 0.024474
[23:31:32.061] iteration 5878 : model1 loss : 0.438088 model2 loss : 0.026485
[23:31:32.231] iteration 5879 : model1 loss : 0.438533 model2 loss : 0.028848
[23:31:32.402] iteration 5880 : model1 loss : 0.438436 model2 loss : 0.023096
[23:31:34.576] iteration 5881 : model1 loss : 0.437569 model2 loss : 0.024453
[23:31:34.752] iteration 5882 : model1 loss : 0.438821 model2 loss : 0.029787
[23:31:34.929] iteration 5883 : model1 loss : 0.437067 model2 loss : 0.026240
[23:31:35.103] iteration 5884 : model1 loss : 0.435370 model2 loss : 0.023811
[23:31:35.278] iteration 5885 : model1 loss : 0.442356 model2 loss : 0.028497
[23:31:35.450] iteration 5886 : model1 loss : 0.436717 model2 loss : 0.022373
[23:31:35.632] iteration 5887 : model1 loss : 0.435943 model2 loss : 0.022069
[23:31:35.806] iteration 5888 : model1 loss : 0.435938 model2 loss : 0.026232
[23:31:35.984] iteration 5889 : model1 loss : 0.440249 model2 loss : 0.027396
[23:31:36.158] iteration 5890 : model1 loss : 0.439929 model2 loss : 0.030195
[23:31:36.336] iteration 5891 : model1 loss : 0.438498 model2 loss : 0.023498
[23:31:36.511] iteration 5892 : model1 loss : 0.444641 model2 loss : 0.025557
[23:31:36.691] iteration 5893 : model1 loss : 0.436766 model2 loss : 0.024498
[23:31:36.865] iteration 5894 : model1 loss : 0.433704 model2 loss : 0.022690
[23:31:37.041] iteration 5895 : model1 loss : 0.434749 model2 loss : 0.021416
[23:31:37.211] iteration 5896 : model1 loss : 0.435818 model2 loss : 0.029789
[23:31:37.390] iteration 5897 : model1 loss : 0.439167 model2 loss : 0.029014
[23:31:37.566] iteration 5898 : model1 loss : 0.438124 model2 loss : 0.027189
[23:31:37.741] iteration 5899 : model1 loss : 0.445344 model2 loss : 0.035965
[23:31:37.910] iteration 5900 : model1 loss : 0.435529 model2 loss : 0.027445
[23:31:38.086] iteration 5901 : model1 loss : 0.432453 model2 loss : 0.021586
[23:31:40.205] iteration 5902 : model1 loss : 0.440729 model2 loss : 0.024379
[23:31:40.381] iteration 5903 : model1 loss : 0.436243 model2 loss : 0.022692
[23:31:40.561] iteration 5904 : model1 loss : 0.437385 model2 loss : 0.026803
[23:31:40.732] iteration 5905 : model1 loss : 0.436828 model2 loss : 0.023023
[23:31:40.907] iteration 5906 : model1 loss : 0.433746 model2 loss : 0.024150
[23:31:41.078] iteration 5907 : model1 loss : 0.434850 model2 loss : 0.025518
[23:31:41.254] iteration 5908 : model1 loss : 0.435065 model2 loss : 0.027582
[23:31:41.428] iteration 5909 : model1 loss : 0.438296 model2 loss : 0.024861
[23:31:41.609] iteration 5910 : model1 loss : 0.437713 model2 loss : 0.029384
[23:31:41.779] iteration 5911 : model1 loss : 0.442899 model2 loss : 0.030552
[23:31:41.955] iteration 5912 : model1 loss : 0.436725 model2 loss : 0.025944
[23:31:42.130] iteration 5913 : model1 loss : 0.437750 model2 loss : 0.030489
[23:31:42.308] iteration 5914 : model1 loss : 0.436052 model2 loss : 0.024182
[23:31:42.487] iteration 5915 : model1 loss : 0.435788 model2 loss : 0.023866
[23:31:42.665] iteration 5916 : model1 loss : 0.438682 model2 loss : 0.027179
[23:31:42.837] iteration 5917 : model1 loss : 0.439448 model2 loss : 0.030402
[23:31:43.015] iteration 5918 : model1 loss : 0.434542 model2 loss : 0.025657
[23:31:43.185] iteration 5919 : model1 loss : 0.436688 model2 loss : 0.024882
[23:31:43.367] iteration 5920 : model1 loss : 0.438336 model2 loss : 0.027705
[23:31:43.541] iteration 5921 : model1 loss : 0.436922 model2 loss : 0.021248
[23:31:43.714] iteration 5922 : model1 loss : 0.435983 model2 loss : 0.022047
[23:31:45.825] iteration 5923 : model1 loss : 0.438392 model2 loss : 0.028846
[23:31:45.999] iteration 5924 : model1 loss : 0.434590 model2 loss : 0.028532
[23:31:46.179] iteration 5925 : model1 loss : 0.441762 model2 loss : 0.030626
[23:31:46.352] iteration 5926 : model1 loss : 0.437711 model2 loss : 0.027075
[23:31:46.531] iteration 5927 : model1 loss : 0.437361 model2 loss : 0.023605
[23:31:46.700] iteration 5928 : model1 loss : 0.433273 model2 loss : 0.022660
[23:31:46.876] iteration 5929 : model1 loss : 0.434870 model2 loss : 0.024994
[23:31:47.049] iteration 5930 : model1 loss : 0.431276 model2 loss : 0.020088
[23:31:47.227] iteration 5931 : model1 loss : 0.441937 model2 loss : 0.024539
[23:31:47.398] iteration 5932 : model1 loss : 0.434820 model2 loss : 0.024844
[23:31:47.577] iteration 5933 : model1 loss : 0.438665 model2 loss : 0.024513
[23:31:47.747] iteration 5934 : model1 loss : 0.439893 model2 loss : 0.024204
[23:31:47.924] iteration 5935 : model1 loss : 0.436495 model2 loss : 0.024365
[23:31:48.098] iteration 5936 : model1 loss : 0.438524 model2 loss : 0.026143
[23:31:48.275] iteration 5937 : model1 loss : 0.439760 model2 loss : 0.027351
[23:31:48.446] iteration 5938 : model1 loss : 0.439092 model2 loss : 0.028672
[23:31:48.628] iteration 5939 : model1 loss : 0.438816 model2 loss : 0.027694
[23:31:48.799] iteration 5940 : model1 loss : 0.433930 model2 loss : 0.023619
[23:31:48.975] iteration 5941 : model1 loss : 0.437098 model2 loss : 0.024158
[23:31:49.145] iteration 5942 : model1 loss : 0.441762 model2 loss : 0.031453
[23:31:49.325] iteration 5943 : model1 loss : 0.440207 model2 loss : 0.026768
[23:31:51.454] iteration 5944 : model1 loss : 0.435562 model2 loss : 0.025716
[23:31:51.628] iteration 5945 : model1 loss : 0.439599 model2 loss : 0.025350
[23:31:51.810] iteration 5946 : model1 loss : 0.437608 model2 loss : 0.027442
[23:31:52.009] iteration 5947 : model1 loss : 0.437772 model2 loss : 0.023164
[23:31:52.185] iteration 5948 : model1 loss : 0.439235 model2 loss : 0.030097
[23:31:52.357] iteration 5949 : model1 loss : 0.435125 model2 loss : 0.026273
[23:31:52.540] iteration 5950 : model1 loss : 0.434498 model2 loss : 0.023179
[23:31:52.712] iteration 5951 : model1 loss : 0.439009 model2 loss : 0.026912
[23:31:52.888] iteration 5952 : model1 loss : 0.437838 model2 loss : 0.027144
[23:31:53.062] iteration 5953 : model1 loss : 0.436289 model2 loss : 0.024026
[23:31:53.238] iteration 5954 : model1 loss : 0.437099 model2 loss : 0.026730
[23:31:53.410] iteration 5955 : model1 loss : 0.435640 model2 loss : 0.021707
[23:31:53.593] iteration 5956 : model1 loss : 0.439305 model2 loss : 0.024679
[23:31:53.764] iteration 5957 : model1 loss : 0.439063 model2 loss : 0.025337
[23:31:53.937] iteration 5958 : model1 loss : 0.438815 model2 loss : 0.024882
[23:31:54.111] iteration 5959 : model1 loss : 0.436444 model2 loss : 0.026189
[23:31:54.289] iteration 5960 : model1 loss : 0.439333 model2 loss : 0.025533
[23:31:54.460] iteration 5961 : model1 loss : 0.438686 model2 loss : 0.024037
[23:31:54.637] iteration 5962 : model1 loss : 0.434874 model2 loss : 0.022511
[23:31:54.806] iteration 5963 : model1 loss : 0.436403 model2 loss : 0.024624
[23:31:54.981] iteration 5964 : model1 loss : 0.439458 model2 loss : 0.030879
[23:31:57.103] iteration 5965 : model1 loss : 0.439460 model2 loss : 0.026634
[23:31:57.280] iteration 5966 : model1 loss : 0.430990 model2 loss : 0.021667
[23:31:57.460] iteration 5967 : model1 loss : 0.436732 model2 loss : 0.023926
[23:31:57.633] iteration 5968 : model1 loss : 0.434296 model2 loss : 0.025139
[23:31:57.809] iteration 5969 : model1 loss : 0.439704 model2 loss : 0.026752
[23:31:57.979] iteration 5970 : model1 loss : 0.440768 model2 loss : 0.027134
[23:31:58.157] iteration 5971 : model1 loss : 0.441342 model2 loss : 0.027170
[23:31:58.336] iteration 5972 : model1 loss : 0.439028 model2 loss : 0.025556
[23:31:58.515] iteration 5973 : model1 loss : 0.437117 model2 loss : 0.022121
[23:31:58.684] iteration 5974 : model1 loss : 0.435629 model2 loss : 0.023550
[23:31:58.864] iteration 5975 : model1 loss : 0.443619 model2 loss : 0.029864
[23:31:59.038] iteration 5976 : model1 loss : 0.435931 model2 loss : 0.022929
[23:31:59.214] iteration 5977 : model1 loss : 0.433793 model2 loss : 0.024418
[23:31:59.388] iteration 5978 : model1 loss : 0.443246 model2 loss : 0.034723
[23:31:59.567] iteration 5979 : model1 loss : 0.438440 model2 loss : 0.030114
[23:31:59.737] iteration 5980 : model1 loss : 0.434168 model2 loss : 0.024806
[23:31:59.912] iteration 5981 : model1 loss : 0.438034 model2 loss : 0.027393
[23:32:00.087] iteration 5982 : model1 loss : 0.440710 model2 loss : 0.027654
[23:32:00.266] iteration 5983 : model1 loss : 0.436731 model2 loss : 0.023140
[23:32:00.437] iteration 5984 : model1 loss : 0.439815 model2 loss : 0.032691
[23:32:00.613] iteration 5985 : model1 loss : 0.439585 model2 loss : 0.027904
[23:32:02.743] iteration 5986 : model1 loss : 0.437849 model2 loss : 0.026606
[23:32:02.917] iteration 5987 : model1 loss : 0.440153 model2 loss : 0.024488
[23:32:03.095] iteration 5988 : model1 loss : 0.440376 model2 loss : 0.029045
[23:32:03.265] iteration 5989 : model1 loss : 0.436855 model2 loss : 0.027125
[23:32:03.441] iteration 5990 : model1 loss : 0.435530 model2 loss : 0.025276
[23:32:03.617] iteration 5991 : model1 loss : 0.441464 model2 loss : 0.030020
[23:32:03.791] iteration 5992 : model1 loss : 0.437984 model2 loss : 0.025395
[23:32:03.961] iteration 5993 : model1 loss : 0.433602 model2 loss : 0.024108
[23:32:04.138] iteration 5994 : model1 loss : 0.439428 model2 loss : 0.026745
[23:32:04.312] iteration 5995 : model1 loss : 0.437304 model2 loss : 0.027918
[23:32:04.490] iteration 5996 : model1 loss : 0.434361 model2 loss : 0.022511
[23:32:04.665] iteration 5997 : model1 loss : 0.438330 model2 loss : 0.026716
[23:32:04.841] iteration 5998 : model1 loss : 0.438064 model2 loss : 0.022923
[23:32:05.014] iteration 5999 : model1 loss : 0.435653 model2 loss : 0.025357
[23:32:05.192] iteration 6000 : model1 loss : 0.440083 model2 loss : 0.027077
[23:32:14.414] iteration 6000 : model1_mean_dice : 0.811766 model1_mean_hd95 : 10.373289
[23:32:23.549] iteration 6000 : model2_mean_dice : 0.842512 model2_mean_hd95 : 9.099845
[23:32:23.578] save model1 to ../model/ACDC/EVILv1_kl0.5_tau0.25_14_1337/unet\model1_iter_6000.pth
[23:32:23.605] save model2 to ../model/ACDC/EVILv1_kl0.5_tau0.25_14_1337/unet\model2_iter_6000.pth
[23:32:23.790] iteration 6001 : model1 loss : 0.441770 model2 loss : 0.030659
[23:32:23.966] iteration 6002 : model1 loss : 0.439127 model2 loss : 0.027910
[23:32:24.143] iteration 6003 : model1 loss : 0.435206 model2 loss : 0.024165
[23:32:24.319] iteration 6004 : model1 loss : 0.437172 model2 loss : 0.024357
[23:32:24.495] iteration 6005 : model1 loss : 0.433376 model2 loss : 0.028852
[23:32:24.667] iteration 6006 : model1 loss : 0.436988 model2 loss : 0.021816
[23:32:26.803] iteration 6007 : model1 loss : 0.436853 model2 loss : 0.024583
[23:32:26.974] iteration 6008 : model1 loss : 0.439109 model2 loss : 0.025495
[23:32:27.151] iteration 6009 : model1 loss : 0.436318 model2 loss : 0.023809
[23:32:27.325] iteration 6010 : model1 loss : 0.439512 model2 loss : 0.025406
[23:32:27.506] iteration 6011 : model1 loss : 0.434065 model2 loss : 0.023466
[23:32:27.679] iteration 6012 : model1 loss : 0.436536 model2 loss : 0.022491
[23:32:27.855] iteration 6013 : model1 loss : 0.435585 model2 loss : 0.024670
[23:32:28.023] iteration 6014 : model1 loss : 0.441089 model2 loss : 0.028786
[23:32:28.201] iteration 6015 : model1 loss : 0.438124 model2 loss : 0.029670
[23:32:28.371] iteration 6016 : model1 loss : 0.436934 model2 loss : 0.025028
[23:32:28.546] iteration 6017 : model1 loss : 0.438631 model2 loss : 0.027145
[23:32:28.718] iteration 6018 : model1 loss : 0.438199 model2 loss : 0.023208
[23:32:28.895] iteration 6019 : model1 loss : 0.431544 model2 loss : 0.023291
[23:32:29.068] iteration 6020 : model1 loss : 0.440775 model2 loss : 0.026083
[23:32:29.244] iteration 6021 : model1 loss : 0.440729 model2 loss : 0.028280
[23:32:29.415] iteration 6022 : model1 loss : 0.437418 model2 loss : 0.027266
[23:32:29.591] iteration 6023 : model1 loss : 0.438889 model2 loss : 0.025323
[23:32:29.761] iteration 6024 : model1 loss : 0.435864 model2 loss : 0.025325
[23:32:29.937] iteration 6025 : model1 loss : 0.438622 model2 loss : 0.027996
[23:32:30.108] iteration 6026 : model1 loss : 0.440503 model2 loss : 0.027785
[23:32:30.281] iteration 6027 : model1 loss : 0.437850 model2 loss : 0.027177
[23:32:32.383] iteration 6028 : model1 loss : 0.434076 model2 loss : 0.024458
[23:32:32.554] iteration 6029 : model1 loss : 0.437060 model2 loss : 0.025325
[23:32:32.733] iteration 6030 : model1 loss : 0.437842 model2 loss : 0.028354
[23:32:32.903] iteration 6031 : model1 loss : 0.441327 model2 loss : 0.031416
[23:32:33.085] iteration 6032 : model1 loss : 0.436496 model2 loss : 0.025965
[23:32:33.259] iteration 6033 : model1 loss : 0.437047 model2 loss : 0.029525
[23:32:33.431] iteration 6034 : model1 loss : 0.438638 model2 loss : 0.025875
[23:32:33.608] iteration 6035 : model1 loss : 0.440582 model2 loss : 0.032985
[23:32:33.784] iteration 6036 : model1 loss : 0.438081 model2 loss : 0.029288
[23:32:33.954] iteration 6037 : model1 loss : 0.443554 model2 loss : 0.025048
[23:32:34.133] iteration 6038 : model1 loss : 0.437023 model2 loss : 0.023613
[23:32:34.306] iteration 6039 : model1 loss : 0.440492 model2 loss : 0.023129
[23:32:34.481] iteration 6040 : model1 loss : 0.437991 model2 loss : 0.025209
[23:32:34.655] iteration 6041 : model1 loss : 0.438860 model2 loss : 0.029638
[23:32:34.831] iteration 6042 : model1 loss : 0.435191 model2 loss : 0.023689
[23:32:35.001] iteration 6043 : model1 loss : 0.436059 model2 loss : 0.028947
[23:32:35.179] iteration 6044 : model1 loss : 0.431086 model2 loss : 0.021266
[23:32:35.350] iteration 6045 : model1 loss : 0.434032 model2 loss : 0.023670
[23:32:35.527] iteration 6046 : model1 loss : 0.436141 model2 loss : 0.025496
[23:32:35.699] iteration 6047 : model1 loss : 0.437609 model2 loss : 0.026217
[23:32:35.872] iteration 6048 : model1 loss : 0.437227 model2 loss : 0.029732
[23:32:38.053] iteration 6049 : model1 loss : 0.434839 model2 loss : 0.028197
[23:32:38.231] iteration 6050 : model1 loss : 0.441899 model2 loss : 0.032866
[23:32:38.409] iteration 6051 : model1 loss : 0.442543 model2 loss : 0.027135
[23:32:38.581] iteration 6052 : model1 loss : 0.435775 model2 loss : 0.024372
[23:32:38.756] iteration 6053 : model1 loss : 0.438694 model2 loss : 0.021969
[23:32:38.926] iteration 6054 : model1 loss : 0.435174 model2 loss : 0.023073
[23:32:39.103] iteration 6055 : model1 loss : 0.433463 model2 loss : 0.024991
[23:32:39.273] iteration 6056 : model1 loss : 0.433555 model2 loss : 0.029731
[23:32:39.447] iteration 6057 : model1 loss : 0.441507 model2 loss : 0.031190
[23:32:39.621] iteration 6058 : model1 loss : 0.438640 model2 loss : 0.024962
[23:32:39.799] iteration 6059 : model1 loss : 0.437823 model2 loss : 0.025199
[23:32:39.969] iteration 6060 : model1 loss : 0.435746 model2 loss : 0.026701
[23:32:40.144] iteration 6061 : model1 loss : 0.435916 model2 loss : 0.026400
[23:32:40.315] iteration 6062 : model1 loss : 0.442842 model2 loss : 0.027304
[23:32:40.491] iteration 6063 : model1 loss : 0.438699 model2 loss : 0.025496
[23:32:40.665] iteration 6064 : model1 loss : 0.442312 model2 loss : 0.030291
[23:32:40.840] iteration 6065 : model1 loss : 0.437599 model2 loss : 0.030943
[23:32:41.010] iteration 6066 : model1 loss : 0.441826 model2 loss : 0.027017
[23:32:41.187] iteration 6067 : model1 loss : 0.437908 model2 loss : 0.025424
[23:32:41.356] iteration 6068 : model1 loss : 0.437289 model2 loss : 0.024992
[23:32:41.530] iteration 6069 : model1 loss : 0.437404 model2 loss : 0.024743
[23:32:43.694] iteration 6070 : model1 loss : 0.437601 model2 loss : 0.026409
[23:32:43.867] iteration 6071 : model1 loss : 0.434005 model2 loss : 0.026145
[23:32:44.047] iteration 6072 : model1 loss : 0.440295 model2 loss : 0.034518
[23:32:44.220] iteration 6073 : model1 loss : 0.439959 model2 loss : 0.028261
[23:32:44.398] iteration 6074 : model1 loss : 0.441853 model2 loss : 0.025831
[23:32:44.574] iteration 6075 : model1 loss : 0.437279 model2 loss : 0.023872
[23:32:44.746] iteration 6076 : model1 loss : 0.436262 model2 loss : 0.027036
[23:32:44.918] iteration 6077 : model1 loss : 0.435848 model2 loss : 0.027619
[23:32:45.095] iteration 6078 : model1 loss : 0.434669 model2 loss : 0.026520
[23:32:45.266] iteration 6079 : model1 loss : 0.438716 model2 loss : 0.025383
[23:32:45.439] iteration 6080 : model1 loss : 0.433326 model2 loss : 0.024067
[23:32:45.616] iteration 6081 : model1 loss : 0.438669 model2 loss : 0.027402
[23:32:45.797] iteration 6082 : model1 loss : 0.440024 model2 loss : 0.033024
[23:32:45.968] iteration 6083 : model1 loss : 0.436278 model2 loss : 0.026728
[23:32:46.143] iteration 6084 : model1 loss : 0.436763 model2 loss : 0.026979
[23:32:46.316] iteration 6085 : model1 loss : 0.438280 model2 loss : 0.030289
[23:32:46.489] iteration 6086 : model1 loss : 0.444192 model2 loss : 0.030109
[23:32:46.665] iteration 6087 : model1 loss : 0.436845 model2 loss : 0.030456
[23:32:46.841] iteration 6088 : model1 loss : 0.437450 model2 loss : 0.025727
[23:32:47.008] iteration 6089 : model1 loss : 0.441256 model2 loss : 0.025722
[23:32:47.184] iteration 6090 : model1 loss : 0.442686 model2 loss : 0.046051
[23:32:49.334] iteration 6091 : model1 loss : 0.437160 model2 loss : 0.036512
[23:32:49.515] iteration 6092 : model1 loss : 0.441271 model2 loss : 0.026756
[23:32:49.691] iteration 6093 : model1 loss : 0.441560 model2 loss : 0.031195
[23:32:49.863] iteration 6094 : model1 loss : 0.436056 model2 loss : 0.025189
[23:32:50.036] iteration 6095 : model1 loss : 0.437674 model2 loss : 0.026701
[23:32:50.209] iteration 6096 : model1 loss : 0.439331 model2 loss : 0.030981
[23:32:50.388] iteration 6097 : model1 loss : 0.439485 model2 loss : 0.027805
[23:32:50.559] iteration 6098 : model1 loss : 0.430028 model2 loss : 0.021510
[23:32:50.737] iteration 6099 : model1 loss : 0.438386 model2 loss : 0.027904
[23:32:50.908] iteration 6100 : model1 loss : 0.440377 model2 loss : 0.037475
[23:32:51.085] iteration 6101 : model1 loss : 0.438038 model2 loss : 0.030501
[23:32:51.255] iteration 6102 : model1 loss : 0.442780 model2 loss : 0.025684
[23:32:51.431] iteration 6103 : model1 loss : 0.437332 model2 loss : 0.024255
[23:32:51.606] iteration 6104 : model1 loss : 0.440323 model2 loss : 0.028587
[23:32:51.785] iteration 6105 : model1 loss : 0.437106 model2 loss : 0.027678
[23:32:51.955] iteration 6106 : model1 loss : 0.434652 model2 loss : 0.027433
[23:32:52.133] iteration 6107 : model1 loss : 0.436581 model2 loss : 0.025945
[23:32:52.307] iteration 6108 : model1 loss : 0.442089 model2 loss : 0.024533
[23:32:52.489] iteration 6109 : model1 loss : 0.439392 model2 loss : 0.033073
[23:32:52.660] iteration 6110 : model1 loss : 0.438623 model2 loss : 0.027400
[23:32:52.837] iteration 6111 : model1 loss : 0.436580 model2 loss : 0.032054
[23:32:54.935] iteration 6112 : model1 loss : 0.436990 model2 loss : 0.027951
[23:32:55.114] iteration 6113 : model1 loss : 0.441476 model2 loss : 0.029778
[23:32:55.292] iteration 6114 : model1 loss : 0.440754 model2 loss : 0.030367
[23:32:55.462] iteration 6115 : model1 loss : 0.437282 model2 loss : 0.026490
[23:32:55.640] iteration 6116 : model1 loss : 0.437248 model2 loss : 0.029006
[23:32:55.812] iteration 6117 : model1 loss : 0.438069 model2 loss : 0.029146
[23:32:55.989] iteration 6118 : model1 loss : 0.435711 model2 loss : 0.023703
[23:32:56.161] iteration 6119 : model1 loss : 0.445381 model2 loss : 0.042305
[23:32:56.343] iteration 6120 : model1 loss : 0.438482 model2 loss : 0.023163
[23:32:56.513] iteration 6121 : model1 loss : 0.442289 model2 loss : 0.033149
[23:32:56.690] iteration 6122 : model1 loss : 0.435919 model2 loss : 0.023727
[23:32:56.861] iteration 6123 : model1 loss : 0.438511 model2 loss : 0.031112
[23:32:57.035] iteration 6124 : model1 loss : 0.432710 model2 loss : 0.022126
[23:32:57.209] iteration 6125 : model1 loss : 0.441375 model2 loss : 0.031702
[23:32:57.387] iteration 6126 : model1 loss : 0.436154 model2 loss : 0.025117
[23:32:57.557] iteration 6127 : model1 loss : 0.441802 model2 loss : 0.028324
[23:32:57.732] iteration 6128 : model1 loss : 0.440129 model2 loss : 0.032356
[23:32:57.903] iteration 6129 : model1 loss : 0.441440 model2 loss : 0.030391
[23:32:58.077] iteration 6130 : model1 loss : 0.436561 model2 loss : 0.026811
[23:32:58.248] iteration 6131 : model1 loss : 0.433391 model2 loss : 0.026350
[23:32:58.425] iteration 6132 : model1 loss : 0.440481 model2 loss : 0.028327
[23:33:00.548] iteration 6133 : model1 loss : 0.442506 model2 loss : 0.037270
[23:33:00.729] iteration 6134 : model1 loss : 0.442216 model2 loss : 0.026956
[23:33:00.904] iteration 6135 : model1 loss : 0.436911 model2 loss : 0.023852
[23:33:01.074] iteration 6136 : model1 loss : 0.435493 model2 loss : 0.025404
[23:33:01.253] iteration 6137 : model1 loss : 0.440755 model2 loss : 0.027519
[23:33:01.424] iteration 6138 : model1 loss : 0.440458 model2 loss : 0.028400
[23:33:01.603] iteration 6139 : model1 loss : 0.435700 model2 loss : 0.027411
[23:33:01.776] iteration 6140 : model1 loss : 0.437613 model2 loss : 0.025594
[23:33:01.951] iteration 6141 : model1 loss : 0.439099 model2 loss : 0.026256
[23:33:02.126] iteration 6142 : model1 loss : 0.439440 model2 loss : 0.027093
[23:33:02.301] iteration 6143 : model1 loss : 0.441424 model2 loss : 0.034303
[23:33:02.476] iteration 6144 : model1 loss : 0.436099 model2 loss : 0.026961
[23:33:02.655] iteration 6145 : model1 loss : 0.436884 model2 loss : 0.027121
[23:33:02.828] iteration 6146 : model1 loss : 0.433837 model2 loss : 0.024937
[23:33:03.002] iteration 6147 : model1 loss : 0.439132 model2 loss : 0.026697
[23:33:03.180] iteration 6148 : model1 loss : 0.435156 model2 loss : 0.024876
[23:33:03.362] iteration 6149 : model1 loss : 0.437415 model2 loss : 0.025707
[23:33:03.532] iteration 6150 : model1 loss : 0.438540 model2 loss : 0.027411
[23:33:03.707] iteration 6151 : model1 loss : 0.434821 model2 loss : 0.026822
[23:33:03.877] iteration 6152 : model1 loss : 0.440217 model2 loss : 0.023308
[23:33:04.051] iteration 6153 : model1 loss : 0.440363 model2 loss : 0.027934
[23:33:06.181] iteration 6154 : model1 loss : 0.438720 model2 loss : 0.027108
[23:33:06.358] iteration 6155 : model1 loss : 0.438025 model2 loss : 0.025457
[23:33:06.535] iteration 6156 : model1 loss : 0.434192 model2 loss : 0.026413
[23:33:06.708] iteration 6157 : model1 loss : 0.433191 model2 loss : 0.025566
[23:33:06.883] iteration 6158 : model1 loss : 0.434768 model2 loss : 0.025100
[23:33:07.051] iteration 6159 : model1 loss : 0.438422 model2 loss : 0.024481
[23:33:07.237] iteration 6160 : model1 loss : 0.441401 model2 loss : 0.023326
[23:33:07.425] iteration 6161 : model1 loss : 0.436584 model2 loss : 0.026375
[23:33:07.605] iteration 6162 : model1 loss : 0.434863 model2 loss : 0.026502
[23:33:07.778] iteration 6163 : model1 loss : 0.436500 model2 loss : 0.025319
[23:33:07.953] iteration 6164 : model1 loss : 0.438221 model2 loss : 0.024651
[23:33:08.131] iteration 6165 : model1 loss : 0.438622 model2 loss : 0.031764
[23:33:08.306] iteration 6166 : model1 loss : 0.443797 model2 loss : 0.037686
[23:33:08.479] iteration 6167 : model1 loss : 0.441428 model2 loss : 0.024093
[23:33:08.658] iteration 6168 : model1 loss : 0.439589 model2 loss : 0.023727
[23:33:08.828] iteration 6169 : model1 loss : 0.437502 model2 loss : 0.028424
[23:33:09.002] iteration 6170 : model1 loss : 0.434635 model2 loss : 0.023290
[23:33:09.176] iteration 6171 : model1 loss : 0.441092 model2 loss : 0.033706
[23:33:09.350] iteration 6172 : model1 loss : 0.437499 model2 loss : 0.027008
[23:33:09.519] iteration 6173 : model1 loss : 0.439633 model2 loss : 0.026933
[23:33:09.694] iteration 6174 : model1 loss : 0.436493 model2 loss : 0.029329
[23:33:11.851] iteration 6175 : model1 loss : 0.434795 model2 loss : 0.027473
[23:33:12.021] iteration 6176 : model1 loss : 0.438346 model2 loss : 0.027361
[23:33:12.200] iteration 6177 : model1 loss : 0.436080 model2 loss : 0.026847
[23:33:12.371] iteration 6178 : model1 loss : 0.438546 model2 loss : 0.027194
[23:33:12.551] iteration 6179 : model1 loss : 0.435283 model2 loss : 0.023118
[23:33:12.722] iteration 6180 : model1 loss : 0.435858 model2 loss : 0.023572
[23:33:12.897] iteration 6181 : model1 loss : 0.441185 model2 loss : 0.032042
[23:33:13.065] iteration 6182 : model1 loss : 0.436341 model2 loss : 0.023123
[23:33:13.240] iteration 6183 : model1 loss : 0.435894 model2 loss : 0.028595
[23:33:13.412] iteration 6184 : model1 loss : 0.439784 model2 loss : 0.026474
[23:33:13.589] iteration 6185 : model1 loss : 0.436368 model2 loss : 0.024932
[23:33:13.761] iteration 6186 : model1 loss : 0.437259 model2 loss : 0.026606
[23:33:13.934] iteration 6187 : model1 loss : 0.440168 model2 loss : 0.024669
[23:33:14.107] iteration 6188 : model1 loss : 0.440920 model2 loss : 0.028922
[23:33:14.283] iteration 6189 : model1 loss : 0.437414 model2 loss : 0.027991
[23:33:14.454] iteration 6190 : model1 loss : 0.434070 model2 loss : 0.024110
[23:33:14.633] iteration 6191 : model1 loss : 0.439690 model2 loss : 0.025378
[23:33:14.804] iteration 6192 : model1 loss : 0.436935 model2 loss : 0.030557
[23:33:14.979] iteration 6193 : model1 loss : 0.438267 model2 loss : 0.024765
[23:33:15.149] iteration 6194 : model1 loss : 0.433999 model2 loss : 0.026550
[23:33:15.325] iteration 6195 : model1 loss : 0.441042 model2 loss : 0.027388
[23:33:17.451] iteration 6196 : model1 loss : 0.436748 model2 loss : 0.026555
[23:33:17.622] iteration 6197 : model1 loss : 0.437859 model2 loss : 0.025024
[23:33:17.802] iteration 6198 : model1 loss : 0.441216 model2 loss : 0.027490
[23:33:17.972] iteration 6199 : model1 loss : 0.441221 model2 loss : 0.032058
[23:33:18.149] iteration 6200 : model1 loss : 0.437625 model2 loss : 0.026594
[23:33:18.323] iteration 6201 : model1 loss : 0.435931 model2 loss : 0.026230
[23:33:18.500] iteration 6202 : model1 loss : 0.440800 model2 loss : 0.023640
[23:33:18.673] iteration 6203 : model1 loss : 0.438254 model2 loss : 0.025017
[23:33:18.850] iteration 6204 : model1 loss : 0.434822 model2 loss : 0.026665
[23:33:19.018] iteration 6205 : model1 loss : 0.434769 model2 loss : 0.027411
[23:33:19.195] iteration 6206 : model1 loss : 0.437648 model2 loss : 0.025355
[23:33:19.369] iteration 6207 : model1 loss : 0.438032 model2 loss : 0.028675
[23:33:19.543] iteration 6208 : model1 loss : 0.434845 model2 loss : 0.023836
[23:33:19.716] iteration 6209 : model1 loss : 0.436691 model2 loss : 0.030519
[23:33:19.893] iteration 6210 : model1 loss : 0.437090 model2 loss : 0.027550
[23:33:20.064] iteration 6211 : model1 loss : 0.436069 model2 loss : 0.026617
[23:33:20.239] iteration 6212 : model1 loss : 0.440124 model2 loss : 0.025536
[23:33:20.410] iteration 6213 : model1 loss : 0.436358 model2 loss : 0.022926
[23:33:20.587] iteration 6214 : model1 loss : 0.437993 model2 loss : 0.023283
[23:33:20.759] iteration 6215 : model1 loss : 0.437755 model2 loss : 0.024559
[23:33:20.935] iteration 6216 : model1 loss : 0.440296 model2 loss : 0.028651
[23:33:23.088] iteration 6217 : model1 loss : 0.433801 model2 loss : 0.026112
[23:33:23.266] iteration 6218 : model1 loss : 0.439787 model2 loss : 0.028811
[23:33:23.443] iteration 6219 : model1 loss : 0.442609 model2 loss : 0.029862
[23:33:23.619] iteration 6220 : model1 loss : 0.437877 model2 loss : 0.028397
[23:33:23.800] iteration 6221 : model1 loss : 0.437991 model2 loss : 0.024677
[23:33:23.968] iteration 6222 : model1 loss : 0.438528 model2 loss : 0.028575
[23:33:24.145] iteration 6223 : model1 loss : 0.434560 model2 loss : 0.023112
[23:33:24.319] iteration 6224 : model1 loss : 0.432561 model2 loss : 0.024229
[23:33:24.495] iteration 6225 : model1 loss : 0.438200 model2 loss : 0.027838
[23:33:24.666] iteration 6226 : model1 loss : 0.438399 model2 loss : 0.027528
[23:33:24.843] iteration 6227 : model1 loss : 0.434688 model2 loss : 0.025274
[23:33:25.012] iteration 6228 : model1 loss : 0.434149 model2 loss : 0.024205
[23:33:25.191] iteration 6229 : model1 loss : 0.439449 model2 loss : 0.026305
[23:33:25.366] iteration 6230 : model1 loss : 0.442685 model2 loss : 0.027886
[23:33:25.542] iteration 6231 : model1 loss : 0.435183 model2 loss : 0.027007
[23:33:25.715] iteration 6232 : model1 loss : 0.439305 model2 loss : 0.026214
[23:33:25.894] iteration 6233 : model1 loss : 0.437225 model2 loss : 0.023918
[23:33:26.064] iteration 6234 : model1 loss : 0.437223 model2 loss : 0.026859
[23:33:26.238] iteration 6235 : model1 loss : 0.440007 model2 loss : 0.029969
[23:33:26.406] iteration 6236 : model1 loss : 0.440483 model2 loss : 0.026886
[23:33:26.581] iteration 6237 : model1 loss : 0.437724 model2 loss : 0.026032
[23:33:28.770] iteration 6238 : model1 loss : 0.435995 model2 loss : 0.023437
[23:33:28.940] iteration 6239 : model1 loss : 0.440752 model2 loss : 0.023149
[23:33:29.118] iteration 6240 : model1 loss : 0.432372 model2 loss : 0.024829
[23:33:29.291] iteration 6241 : model1 loss : 0.435636 model2 loss : 0.029493
[23:33:29.466] iteration 6242 : model1 loss : 0.436950 model2 loss : 0.026119
[23:33:29.640] iteration 6243 : model1 loss : 0.437842 model2 loss : 0.024482
[23:33:29.817] iteration 6244 : model1 loss : 0.438465 model2 loss : 0.027932
[23:33:29.990] iteration 6245 : model1 loss : 0.438467 model2 loss : 0.028878
[23:33:30.169] iteration 6246 : model1 loss : 0.440528 model2 loss : 0.028976
[23:33:30.342] iteration 6247 : model1 loss : 0.437520 model2 loss : 0.026052
[23:33:30.518] iteration 6248 : model1 loss : 0.438330 model2 loss : 0.023181
[23:33:30.691] iteration 6249 : model1 loss : 0.439142 model2 loss : 0.029107
[23:33:30.871] iteration 6250 : model1 loss : 0.440802 model2 loss : 0.033387
[23:33:31.041] iteration 6251 : model1 loss : 0.437983 model2 loss : 0.029472
[23:33:31.217] iteration 6252 : model1 loss : 0.438738 model2 loss : 0.027154
[23:33:31.389] iteration 6253 : model1 loss : 0.434460 model2 loss : 0.025103
[23:33:31.565] iteration 6254 : model1 loss : 0.436863 model2 loss : 0.025709
[23:33:31.738] iteration 6255 : model1 loss : 0.437856 model2 loss : 0.024234
[23:33:31.913] iteration 6256 : model1 loss : 0.441698 model2 loss : 0.025570
[23:33:32.082] iteration 6257 : model1 loss : 0.434385 model2 loss : 0.025763
[23:33:32.257] iteration 6258 : model1 loss : 0.436251 model2 loss : 0.025537
[23:33:34.396] iteration 6259 : model1 loss : 0.432577 model2 loss : 0.025630
[23:33:34.569] iteration 6260 : model1 loss : 0.434936 model2 loss : 0.022808
[23:33:34.746] iteration 6261 : model1 loss : 0.437577 model2 loss : 0.023958
[23:33:34.916] iteration 6262 : model1 loss : 0.438518 model2 loss : 0.026356
[23:33:35.093] iteration 6263 : model1 loss : 0.441319 model2 loss : 0.023572
[23:33:35.268] iteration 6264 : model1 loss : 0.437857 model2 loss : 0.026626
[23:33:35.442] iteration 6265 : model1 loss : 0.437094 model2 loss : 0.026591
[23:33:35.615] iteration 6266 : model1 loss : 0.443025 model2 loss : 0.026215
[23:33:35.791] iteration 6267 : model1 loss : 0.437395 model2 loss : 0.028250
[23:33:35.962] iteration 6268 : model1 loss : 0.438013 model2 loss : 0.023570
[23:33:36.136] iteration 6269 : model1 loss : 0.437909 model2 loss : 0.025383
[23:33:36.312] iteration 6270 : model1 loss : 0.435061 model2 loss : 0.022309
[23:33:36.488] iteration 6271 : model1 loss : 0.440976 model2 loss : 0.026208
[23:33:36.659] iteration 6272 : model1 loss : 0.437690 model2 loss : 0.025811
[23:33:36.835] iteration 6273 : model1 loss : 0.438000 model2 loss : 0.030376
[23:33:37.006] iteration 6274 : model1 loss : 0.433215 model2 loss : 0.025729
[23:33:37.184] iteration 6275 : model1 loss : 0.436982 model2 loss : 0.024561
[23:33:37.356] iteration 6276 : model1 loss : 0.441005 model2 loss : 0.028201
[23:33:37.533] iteration 6277 : model1 loss : 0.439961 model2 loss : 0.027136
[23:33:37.705] iteration 6278 : model1 loss : 0.446607 model2 loss : 0.025711
[23:33:37.879] iteration 6279 : model1 loss : 0.438990 model2 loss : 0.030452
[23:33:40.007] iteration 6280 : model1 loss : 0.437746 model2 loss : 0.026022
[23:33:40.184] iteration 6281 : model1 loss : 0.439175 model2 loss : 0.025248
[23:33:40.361] iteration 6282 : model1 loss : 0.433766 model2 loss : 0.021356
[23:33:40.533] iteration 6283 : model1 loss : 0.434371 model2 loss : 0.026124
[23:33:40.709] iteration 6284 : model1 loss : 0.437248 model2 loss : 0.026239
[23:33:40.882] iteration 6285 : model1 loss : 0.438066 model2 loss : 0.022316
[23:33:41.057] iteration 6286 : model1 loss : 0.437216 model2 loss : 0.024898
[23:33:41.231] iteration 6287 : model1 loss : 0.438883 model2 loss : 0.027806
[23:33:41.408] iteration 6288 : model1 loss : 0.437180 model2 loss : 0.024923
[23:33:41.578] iteration 6289 : model1 loss : 0.437196 model2 loss : 0.025838
[23:33:41.760] iteration 6290 : model1 loss : 0.439308 model2 loss : 0.028361
[23:33:41.934] iteration 6291 : model1 loss : 0.436749 model2 loss : 0.026444
[23:33:42.110] iteration 6292 : model1 loss : 0.437186 model2 loss : 0.024164
[23:33:42.282] iteration 6293 : model1 loss : 0.440231 model2 loss : 0.025124
[23:33:42.460] iteration 6294 : model1 loss : 0.441124 model2 loss : 0.027952
[23:33:42.633] iteration 6295 : model1 loss : 0.437676 model2 loss : 0.027118
[23:33:42.810] iteration 6296 : model1 loss : 0.435855 model2 loss : 0.022803
[23:33:42.980] iteration 6297 : model1 loss : 0.431747 model2 loss : 0.024911
[23:33:43.155] iteration 6298 : model1 loss : 0.436709 model2 loss : 0.026050
[23:33:43.329] iteration 6299 : model1 loss : 0.438239 model2 loss : 0.024279
[23:33:43.501] iteration 6300 : model1 loss : 0.441667 model2 loss : 0.027927
[23:33:45.591] iteration 6301 : model1 loss : 0.440805 model2 loss : 0.026240
[23:33:45.774] iteration 6302 : model1 loss : 0.437386 model2 loss : 0.027001
[23:33:45.948] iteration 6303 : model1 loss : 0.437223 model2 loss : 0.024128
[23:33:46.120] iteration 6304 : model1 loss : 0.441125 model2 loss : 0.026710
[23:33:46.297] iteration 6305 : model1 loss : 0.436205 model2 loss : 0.021546
[23:33:46.466] iteration 6306 : model1 loss : 0.447498 model2 loss : 0.038059
[23:33:46.645] iteration 6307 : model1 loss : 0.437284 model2 loss : 0.026100
[23:33:46.820] iteration 6308 : model1 loss : 0.436371 model2 loss : 0.023346
[23:33:46.997] iteration 6309 : model1 loss : 0.438224 model2 loss : 0.027693
[23:33:47.172] iteration 6310 : model1 loss : 0.436410 model2 loss : 0.023419
[23:33:47.348] iteration 6311 : model1 loss : 0.437839 model2 loss : 0.027250
[23:33:47.519] iteration 6312 : model1 loss : 0.436012 model2 loss : 0.022558
[23:33:47.696] iteration 6313 : model1 loss : 0.439428 model2 loss : 0.022145
[23:33:47.871] iteration 6314 : model1 loss : 0.434054 model2 loss : 0.023931
[23:33:48.046] iteration 6315 : model1 loss : 0.437262 model2 loss : 0.027281
[23:33:48.219] iteration 6316 : model1 loss : 0.434081 model2 loss : 0.022828
[23:33:48.397] iteration 6317 : model1 loss : 0.439301 model2 loss : 0.025493
[23:33:48.571] iteration 6318 : model1 loss : 0.434205 model2 loss : 0.023706
[23:33:48.748] iteration 6319 : model1 loss : 0.434093 model2 loss : 0.022927
[23:33:48.918] iteration 6320 : model1 loss : 0.439569 model2 loss : 0.022660
[23:33:49.094] iteration 6321 : model1 loss : 0.438779 model2 loss : 0.026043
[23:33:51.241] iteration 6322 : model1 loss : 0.434870 model2 loss : 0.024618
[23:33:51.416] iteration 6323 : model1 loss : 0.436966 model2 loss : 0.023305
[23:33:51.598] iteration 6324 : model1 loss : 0.439563 model2 loss : 0.024870
[23:33:51.774] iteration 6325 : model1 loss : 0.440686 model2 loss : 0.031850
[23:33:51.949] iteration 6326 : model1 loss : 0.437434 model2 loss : 0.024396
[23:33:52.122] iteration 6327 : model1 loss : 0.436398 model2 loss : 0.023017
[23:33:52.298] iteration 6328 : model1 loss : 0.440420 model2 loss : 0.023185
[23:33:52.471] iteration 6329 : model1 loss : 0.441876 model2 loss : 0.026276
[23:33:52.648] iteration 6330 : model1 loss : 0.435346 model2 loss : 0.021646
[23:33:52.824] iteration 6331 : model1 loss : 0.437820 model2 loss : 0.026330
[23:33:52.998] iteration 6332 : model1 loss : 0.429711 model2 loss : 0.021027
[23:33:53.168] iteration 6333 : model1 loss : 0.435016 model2 loss : 0.022184
[23:33:53.345] iteration 6334 : model1 loss : 0.440177 model2 loss : 0.029802
[23:33:53.514] iteration 6335 : model1 loss : 0.436611 model2 loss : 0.028510
[23:33:53.691] iteration 6336 : model1 loss : 0.443083 model2 loss : 0.027462
[23:33:53.865] iteration 6337 : model1 loss : 0.437774 model2 loss : 0.025713
[23:33:54.040] iteration 6338 : model1 loss : 0.436795 model2 loss : 0.024213
[23:33:54.214] iteration 6339 : model1 loss : 0.437799 model2 loss : 0.027254
[23:33:54.390] iteration 6340 : model1 loss : 0.435256 model2 loss : 0.026300
[23:33:54.562] iteration 6341 : model1 loss : 0.434700 model2 loss : 0.023245
[23:33:54.736] iteration 6342 : model1 loss : 0.439524 model2 loss : 0.025697
[23:33:56.820] iteration 6343 : model1 loss : 0.437948 model2 loss : 0.023322
[23:33:56.992] iteration 6344 : model1 loss : 0.440561 model2 loss : 0.026984
[23:33:57.172] iteration 6345 : model1 loss : 0.438734 model2 loss : 0.024610
[23:33:57.344] iteration 6346 : model1 loss : 0.437181 model2 loss : 0.025888
[23:33:57.521] iteration 6347 : model1 loss : 0.438405 model2 loss : 0.023794
[23:33:57.692] iteration 6348 : model1 loss : 0.436402 model2 loss : 0.025276
[23:33:57.872] iteration 6349 : model1 loss : 0.441806 model2 loss : 0.024790
[23:33:58.044] iteration 6350 : model1 loss : 0.440041 model2 loss : 0.027422
[23:33:58.221] iteration 6351 : model1 loss : 0.438106 model2 loss : 0.024223
[23:33:58.395] iteration 6352 : model1 loss : 0.437948 model2 loss : 0.027387
[23:33:58.569] iteration 6353 : model1 loss : 0.433188 model2 loss : 0.025025
[23:33:58.743] iteration 6354 : model1 loss : 0.433876 model2 loss : 0.025725
[23:33:58.920] iteration 6355 : model1 loss : 0.438439 model2 loss : 0.024066
[23:33:59.090] iteration 6356 : model1 loss : 0.434564 model2 loss : 0.023260
[23:33:59.267] iteration 6357 : model1 loss : 0.441134 model2 loss : 0.025494
[23:33:59.441] iteration 6358 : model1 loss : 0.438650 model2 loss : 0.026578
[23:33:59.618] iteration 6359 : model1 loss : 0.439146 model2 loss : 0.024204
[23:33:59.792] iteration 6360 : model1 loss : 0.438231 model2 loss : 0.029189
[23:33:59.965] iteration 6361 : model1 loss : 0.435317 model2 loss : 0.025275
[23:34:00.139] iteration 6362 : model1 loss : 0.441601 model2 loss : 0.025890
[23:34:00.314] iteration 6363 : model1 loss : 0.436536 model2 loss : 0.023626
[23:34:02.444] iteration 6364 : model1 loss : 0.438134 model2 loss : 0.025219
[23:34:02.618] iteration 6365 : model1 loss : 0.442485 model2 loss : 0.027641
[23:34:02.795] iteration 6366 : model1 loss : 0.441476 model2 loss : 0.026974
[23:34:02.966] iteration 6367 : model1 loss : 0.437896 model2 loss : 0.026074
[23:34:03.141] iteration 6368 : model1 loss : 0.436358 model2 loss : 0.026462
[23:34:03.314] iteration 6369 : model1 loss : 0.434774 model2 loss : 0.026567
[23:34:03.494] iteration 6370 : model1 loss : 0.432139 model2 loss : 0.022007
[23:34:03.663] iteration 6371 : model1 loss : 0.438100 model2 loss : 0.026880
[23:34:03.839] iteration 6372 : model1 loss : 0.439387 model2 loss : 0.026210
[23:34:04.009] iteration 6373 : model1 loss : 0.440115 model2 loss : 0.026620
[23:34:04.189] iteration 6374 : model1 loss : 0.437442 model2 loss : 0.026716
[23:34:04.367] iteration 6375 : model1 loss : 0.435430 model2 loss : 0.020558
[23:34:04.543] iteration 6376 : model1 loss : 0.440429 model2 loss : 0.027257
[23:34:04.714] iteration 6377 : model1 loss : 0.438943 model2 loss : 0.022022
[23:34:04.893] iteration 6378 : model1 loss : 0.438879 model2 loss : 0.023966
[23:34:05.063] iteration 6379 : model1 loss : 0.431524 model2 loss : 0.023097
[23:34:05.239] iteration 6380 : model1 loss : 0.435593 model2 loss : 0.026882
[23:34:05.412] iteration 6381 : model1 loss : 0.440398 model2 loss : 0.031343
[23:34:05.589] iteration 6382 : model1 loss : 0.437174 model2 loss : 0.027019
[23:34:05.761] iteration 6383 : model1 loss : 0.442378 model2 loss : 0.029476
[23:34:05.935] iteration 6384 : model1 loss : 0.435244 model2 loss : 0.025416
[23:34:08.084] iteration 6385 : model1 loss : 0.435269 model2 loss : 0.025111
[23:34:08.258] iteration 6386 : model1 loss : 0.435093 model2 loss : 0.024110
[23:34:08.433] iteration 6387 : model1 loss : 0.435962 model2 loss : 0.026703
[23:34:08.609] iteration 6388 : model1 loss : 0.439904 model2 loss : 0.028667
[23:34:08.790] iteration 6389 : model1 loss : 0.437486 model2 loss : 0.026312
[23:34:08.960] iteration 6390 : model1 loss : 0.436948 model2 loss : 0.022646
[23:34:09.135] iteration 6391 : model1 loss : 0.443065 model2 loss : 0.029536
[23:34:09.310] iteration 6392 : model1 loss : 0.437423 model2 loss : 0.026692
[23:34:09.484] iteration 6393 : model1 loss : 0.439699 model2 loss : 0.025000
[23:34:09.656] iteration 6394 : model1 loss : 0.437353 model2 loss : 0.024158
[23:34:09.834] iteration 6395 : model1 loss : 0.438371 model2 loss : 0.027238
[23:34:10.007] iteration 6396 : model1 loss : 0.439329 model2 loss : 0.026359
[23:34:10.183] iteration 6397 : model1 loss : 0.438559 model2 loss : 0.029529
[23:34:10.358] iteration 6398 : model1 loss : 0.436871 model2 loss : 0.029139
[23:34:10.535] iteration 6399 : model1 loss : 0.434138 model2 loss : 0.025411
[23:34:10.706] iteration 6400 : model1 loss : 0.438536 model2 loss : 0.031339
[23:34:10.884] iteration 6401 : model1 loss : 0.441025 model2 loss : 0.024731
[23:34:11.054] iteration 6402 : model1 loss : 0.439906 model2 loss : 0.026887
[23:34:11.233] iteration 6403 : model1 loss : 0.433419 model2 loss : 0.024914
[23:34:11.403] iteration 6404 : model1 loss : 0.434215 model2 loss : 0.027404
[23:34:11.578] iteration 6405 : model1 loss : 0.438845 model2 loss : 0.025649
[23:34:13.745] iteration 6406 : model1 loss : 0.439096 model2 loss : 0.025637
[23:34:13.919] iteration 6407 : model1 loss : 0.436469 model2 loss : 0.026497
[23:34:14.097] iteration 6408 : model1 loss : 0.439688 model2 loss : 0.025538
[23:34:14.271] iteration 6409 : model1 loss : 0.439643 model2 loss : 0.030847
[23:34:14.448] iteration 6410 : model1 loss : 0.436274 model2 loss : 0.020754
[23:34:14.623] iteration 6411 : model1 loss : 0.436188 model2 loss : 0.029324
[23:34:14.803] iteration 6412 : model1 loss : 0.436712 model2 loss : 0.028209
[23:34:14.975] iteration 6413 : model1 loss : 0.438142 model2 loss : 0.024063
[23:34:15.152] iteration 6414 : model1 loss : 0.438103 model2 loss : 0.024151
[23:34:15.330] iteration 6415 : model1 loss : 0.437031 model2 loss : 0.027029
[23:34:15.504] iteration 6416 : model1 loss : 0.437845 model2 loss : 0.025823
[23:34:15.674] iteration 6417 : model1 loss : 0.436999 model2 loss : 0.025290
[23:34:15.850] iteration 6418 : model1 loss : 0.437304 model2 loss : 0.023685
[23:34:16.023] iteration 6419 : model1 loss : 0.436079 model2 loss : 0.025063
[23:34:16.199] iteration 6420 : model1 loss : 0.436323 model2 loss : 0.024471
[23:34:16.372] iteration 6421 : model1 loss : 0.441868 model2 loss : 0.028068
[23:34:16.548] iteration 6422 : model1 loss : 0.435040 model2 loss : 0.023484
[23:34:16.721] iteration 6423 : model1 loss : 0.436138 model2 loss : 0.023928
[23:34:16.897] iteration 6424 : model1 loss : 0.437452 model2 loss : 0.028394
[23:34:17.067] iteration 6425 : model1 loss : 0.436727 model2 loss : 0.025889
[23:34:17.239] iteration 6426 : model1 loss : 0.440720 model2 loss : 0.030877
[23:34:19.475] iteration 6427 : model1 loss : 0.435757 model2 loss : 0.024394
[23:34:19.653] iteration 6428 : model1 loss : 0.434094 model2 loss : 0.023644
[23:34:19.829] iteration 6429 : model1 loss : 0.441060 model2 loss : 0.028060
[23:34:19.999] iteration 6430 : model1 loss : 0.434730 model2 loss : 0.024126
[23:34:20.174] iteration 6431 : model1 loss : 0.436795 model2 loss : 0.025099
[23:34:20.349] iteration 6432 : model1 loss : 0.432803 model2 loss : 0.026958
[23:34:20.526] iteration 6433 : model1 loss : 0.443238 model2 loss : 0.026442
[23:34:20.698] iteration 6434 : model1 loss : 0.443753 model2 loss : 0.032493
[23:34:20.876] iteration 6435 : model1 loss : 0.438124 model2 loss : 0.027283
[23:34:21.046] iteration 6436 : model1 loss : 0.435080 model2 loss : 0.025077
[23:34:21.223] iteration 6437 : model1 loss : 0.435891 model2 loss : 0.025484
[23:34:21.396] iteration 6438 : model1 loss : 0.438726 model2 loss : 0.025561
[23:34:21.571] iteration 6439 : model1 loss : 0.437750 model2 loss : 0.024784
[23:34:21.744] iteration 6440 : model1 loss : 0.437932 model2 loss : 0.026353
[23:34:21.923] iteration 6441 : model1 loss : 0.436519 model2 loss : 0.024402
[23:34:22.095] iteration 6442 : model1 loss : 0.440141 model2 loss : 0.025715
[23:34:22.272] iteration 6443 : model1 loss : 0.440749 model2 loss : 0.027688
[23:34:22.447] iteration 6444 : model1 loss : 0.434718 model2 loss : 0.023014
[23:34:22.624] iteration 6445 : model1 loss : 0.436618 model2 loss : 0.025326
[23:34:22.795] iteration 6446 : model1 loss : 0.437319 model2 loss : 0.024320
[23:34:22.969] iteration 6447 : model1 loss : 0.439175 model2 loss : 0.025832
[23:34:25.085] iteration 6448 : model1 loss : 0.434992 model2 loss : 0.023701
[23:34:25.262] iteration 6449 : model1 loss : 0.440922 model2 loss : 0.026100
[23:34:25.441] iteration 6450 : model1 loss : 0.438721 model2 loss : 0.023491
[23:34:25.615] iteration 6451 : model1 loss : 0.435605 model2 loss : 0.027615
[23:34:25.796] iteration 6452 : model1 loss : 0.432920 model2 loss : 0.026085
[23:34:25.968] iteration 6453 : model1 loss : 0.435982 model2 loss : 0.023513
[23:34:26.146] iteration 6454 : model1 loss : 0.438139 model2 loss : 0.025630
[23:34:26.322] iteration 6455 : model1 loss : 0.436916 model2 loss : 0.025835
[23:34:26.503] iteration 6456 : model1 loss : 0.435711 model2 loss : 0.024679
[23:34:26.673] iteration 6457 : model1 loss : 0.433781 model2 loss : 0.023560
[23:34:26.850] iteration 6458 : model1 loss : 0.438817 model2 loss : 0.022663
[23:34:27.020] iteration 6459 : model1 loss : 0.441507 model2 loss : 0.028987
[23:34:27.198] iteration 6460 : model1 loss : 0.437440 model2 loss : 0.024438
[23:34:27.372] iteration 6461 : model1 loss : 0.439347 model2 loss : 0.028691
[23:34:27.548] iteration 6462 : model1 loss : 0.438243 model2 loss : 0.030567
[23:34:27.719] iteration 6463 : model1 loss : 0.437904 model2 loss : 0.025183
[23:34:27.898] iteration 6464 : model1 loss : 0.437827 model2 loss : 0.023396
[23:34:28.068] iteration 6465 : model1 loss : 0.438289 model2 loss : 0.028963
[23:34:28.246] iteration 6466 : model1 loss : 0.438709 model2 loss : 0.028147
[23:34:28.416] iteration 6467 : model1 loss : 0.441025 model2 loss : 0.026827
[23:34:28.594] iteration 6468 : model1 loss : 0.435406 model2 loss : 0.021962
[23:34:30.724] iteration 6469 : model1 loss : 0.435779 model2 loss : 0.024027
[23:34:30.901] iteration 6470 : model1 loss : 0.437581 model2 loss : 0.028048
[23:34:31.083] iteration 6471 : model1 loss : 0.439306 model2 loss : 0.028478
[23:34:31.254] iteration 6472 : model1 loss : 0.437139 model2 loss : 0.024030
[23:34:31.433] iteration 6473 : model1 loss : 0.438692 model2 loss : 0.028947
[23:34:31.607] iteration 6474 : model1 loss : 0.440721 model2 loss : 0.027682
[23:34:31.784] iteration 6475 : model1 loss : 0.434810 model2 loss : 0.021792
[23:34:31.955] iteration 6476 : model1 loss : 0.437121 model2 loss : 0.022927
[23:34:32.132] iteration 6477 : model1 loss : 0.438902 model2 loss : 0.027240
[23:34:32.307] iteration 6478 : model1 loss : 0.429219 model2 loss : 0.024078
[23:34:32.489] iteration 6479 : model1 loss : 0.440017 model2 loss : 0.028922
[23:34:32.658] iteration 6480 : model1 loss : 0.437143 model2 loss : 0.025960
[23:34:32.837] iteration 6481 : model1 loss : 0.431753 model2 loss : 0.023676
[23:34:33.007] iteration 6482 : model1 loss : 0.442853 model2 loss : 0.028705
[23:34:33.184] iteration 6483 : model1 loss : 0.437889 model2 loss : 0.029147
[23:34:33.356] iteration 6484 : model1 loss : 0.440413 model2 loss : 0.028356
[23:34:33.534] iteration 6485 : model1 loss : 0.438192 model2 loss : 0.028039
[23:34:33.705] iteration 6486 : model1 loss : 0.438012 model2 loss : 0.024825
[23:34:33.880] iteration 6487 : model1 loss : 0.437444 model2 loss : 0.025338
[23:34:34.049] iteration 6488 : model1 loss : 0.434364 model2 loss : 0.023977
[23:34:34.221] iteration 6489 : model1 loss : 0.439119 model2 loss : 0.029247
[23:34:36.378] iteration 6490 : model1 loss : 0.437404 model2 loss : 0.027309
[23:34:36.548] iteration 6491 : model1 loss : 0.440212 model2 loss : 0.032955
[23:34:36.742] iteration 6492 : model1 loss : 0.438197 model2 loss : 0.023577
[23:34:36.914] iteration 6493 : model1 loss : 0.434964 model2 loss : 0.025545
[23:34:37.092] iteration 6494 : model1 loss : 0.436046 model2 loss : 0.027276
[23:34:37.264] iteration 6495 : model1 loss : 0.434514 model2 loss : 0.022467
[23:34:37.442] iteration 6496 : model1 loss : 0.434075 model2 loss : 0.025765
[23:34:37.616] iteration 6497 : model1 loss : 0.440018 model2 loss : 0.031856
[23:34:37.792] iteration 6498 : model1 loss : 0.437634 model2 loss : 0.027170
[23:34:37.965] iteration 6499 : model1 loss : 0.435307 model2 loss : 0.023906
[23:34:38.140] iteration 6500 : model1 loss : 0.435242 model2 loss : 0.022210
[23:34:38.318] iteration 6501 : model1 loss : 0.440052 model2 loss : 0.029715
[23:34:38.496] iteration 6502 : model1 loss : 0.441089 model2 loss : 0.030135
[23:34:38.667] iteration 6503 : model1 loss : 0.438992 model2 loss : 0.026115
[23:34:38.843] iteration 6504 : model1 loss : 0.437987 model2 loss : 0.025602
[23:34:39.013] iteration 6505 : model1 loss : 0.443516 model2 loss : 0.031111
[23:34:39.189] iteration 6506 : model1 loss : 0.436605 model2 loss : 0.025094
[23:34:39.363] iteration 6507 : model1 loss : 0.435949 model2 loss : 0.025219
[23:34:39.539] iteration 6508 : model1 loss : 0.433883 model2 loss : 0.025562
[23:34:39.707] iteration 6509 : model1 loss : 0.437494 model2 loss : 0.026547
[23:34:39.881] iteration 6510 : model1 loss : 0.438335 model2 loss : 0.025598
[23:34:42.026] iteration 6511 : model1 loss : 0.438690 model2 loss : 0.027335
[23:34:42.201] iteration 6512 : model1 loss : 0.435393 model2 loss : 0.024274
[23:34:42.378] iteration 6513 : model1 loss : 0.440357 model2 loss : 0.028675
[23:34:42.549] iteration 6514 : model1 loss : 0.437895 model2 loss : 0.028672
[23:34:42.722] iteration 6515 : model1 loss : 0.439157 model2 loss : 0.025858
[23:34:42.899] iteration 6516 : model1 loss : 0.435963 model2 loss : 0.023785
[23:34:43.073] iteration 6517 : model1 loss : 0.440780 model2 loss : 0.027240
[23:34:43.246] iteration 6518 : model1 loss : 0.440597 model2 loss : 0.022322
[23:34:43.426] iteration 6519 : model1 loss : 0.436428 model2 loss : 0.022339
[23:34:43.602] iteration 6520 : model1 loss : 0.440016 model2 loss : 0.029773
[23:34:43.778] iteration 6521 : model1 loss : 0.434292 model2 loss : 0.026205
[23:34:43.951] iteration 6522 : model1 loss : 0.435165 model2 loss : 0.022079
[23:34:44.130] iteration 6523 : model1 loss : 0.434178 model2 loss : 0.022920
[23:34:44.303] iteration 6524 : model1 loss : 0.440934 model2 loss : 0.027480
[23:34:44.478] iteration 6525 : model1 loss : 0.442804 model2 loss : 0.025958
[23:34:44.648] iteration 6526 : model1 loss : 0.436488 model2 loss : 0.027116
[23:34:44.824] iteration 6527 : model1 loss : 0.432866 model2 loss : 0.023624
[23:34:44.997] iteration 6528 : model1 loss : 0.439402 model2 loss : 0.028947
[23:34:45.169] iteration 6529 : model1 loss : 0.436268 model2 loss : 0.024715
[23:34:45.345] iteration 6530 : model1 loss : 0.434985 model2 loss : 0.023779
[23:34:45.520] iteration 6531 : model1 loss : 0.435345 model2 loss : 0.026518
[23:34:47.677] iteration 6532 : model1 loss : 0.439696 model2 loss : 0.026535
[23:34:47.854] iteration 6533 : model1 loss : 0.443619 model2 loss : 0.033568
[23:34:48.029] iteration 6534 : model1 loss : 0.436305 model2 loss : 0.024053
[23:34:48.201] iteration 6535 : model1 loss : 0.436485 model2 loss : 0.026126
[23:34:48.377] iteration 6536 : model1 loss : 0.436824 model2 loss : 0.025713
[23:34:48.548] iteration 6537 : model1 loss : 0.437240 model2 loss : 0.026249
[23:34:48.727] iteration 6538 : model1 loss : 0.438259 model2 loss : 0.025132
[23:34:48.901] iteration 6539 : model1 loss : 0.435772 model2 loss : 0.022914
[23:34:49.078] iteration 6540 : model1 loss : 0.434094 model2 loss : 0.024067
[23:34:49.250] iteration 6541 : model1 loss : 0.433928 model2 loss : 0.022007
[23:34:49.429] iteration 6542 : model1 loss : 0.437975 model2 loss : 0.025245
[23:34:49.607] iteration 6543 : model1 loss : 0.445103 model2 loss : 0.041995
[23:34:49.783] iteration 6544 : model1 loss : 0.438116 model2 loss : 0.026326
[23:34:49.958] iteration 6545 : model1 loss : 0.442517 model2 loss : 0.028180
[23:34:50.135] iteration 6546 : model1 loss : 0.433971 model2 loss : 0.024848
[23:34:50.310] iteration 6547 : model1 loss : 0.439015 model2 loss : 0.024996
[23:34:50.490] iteration 6548 : model1 loss : 0.438133 model2 loss : 0.026245
[23:34:50.662] iteration 6549 : model1 loss : 0.440236 model2 loss : 0.025383
[23:34:50.841] iteration 6550 : model1 loss : 0.430991 model2 loss : 0.022210
[23:34:51.010] iteration 6551 : model1 loss : 0.435530 model2 loss : 0.024947
[23:34:51.183] iteration 6552 : model1 loss : 0.439255 model2 loss : 0.025342
[23:34:53.334] iteration 6553 : model1 loss : 0.436413 model2 loss : 0.025771
[23:34:53.506] iteration 6554 : model1 loss : 0.437084 model2 loss : 0.024574
[23:34:53.687] iteration 6555 : model1 loss : 0.439451 model2 loss : 0.032114
[23:34:53.861] iteration 6556 : model1 loss : 0.436334 model2 loss : 0.025360
[23:34:54.036] iteration 6557 : model1 loss : 0.435675 model2 loss : 0.025034
[23:34:54.206] iteration 6558 : model1 loss : 0.431594 model2 loss : 0.021865
[23:34:54.386] iteration 6559 : model1 loss : 0.436401 model2 loss : 0.023678
[23:34:54.559] iteration 6560 : model1 loss : 0.436679 model2 loss : 0.026075
[23:34:54.736] iteration 6561 : model1 loss : 0.437193 model2 loss : 0.026625
[23:34:54.910] iteration 6562 : model1 loss : 0.438319 model2 loss : 0.021830
[23:34:55.086] iteration 6563 : model1 loss : 0.440776 model2 loss : 0.024539
[23:34:55.256] iteration 6564 : model1 loss : 0.437082 model2 loss : 0.026049
[23:34:55.434] iteration 6565 : model1 loss : 0.438549 model2 loss : 0.027722
[23:34:55.610] iteration 6566 : model1 loss : 0.440116 model2 loss : 0.022862
[23:34:55.785] iteration 6567 : model1 loss : 0.440286 model2 loss : 0.025752
[23:34:55.959] iteration 6568 : model1 loss : 0.437081 model2 loss : 0.022098
[23:34:56.133] iteration 6569 : model1 loss : 0.440725 model2 loss : 0.027794
[23:34:56.306] iteration 6570 : model1 loss : 0.439705 model2 loss : 0.029465
[23:34:56.483] iteration 6571 : model1 loss : 0.439691 model2 loss : 0.028080
[23:34:56.652] iteration 6572 : model1 loss : 0.434887 model2 loss : 0.027511
[23:34:56.829] iteration 6573 : model1 loss : 0.439451 model2 loss : 0.025324
[23:34:58.994] iteration 6574 : model1 loss : 0.440825 model2 loss : 0.027480
[23:34:59.171] iteration 6575 : model1 loss : 0.437280 model2 loss : 0.024495
[23:34:59.353] iteration 6576 : model1 loss : 0.435354 model2 loss : 0.024781
[23:34:59.524] iteration 6577 : model1 loss : 0.440466 model2 loss : 0.031543
[23:34:59.698] iteration 6578 : model1 loss : 0.432731 model2 loss : 0.021785
[23:34:59.878] iteration 6579 : model1 loss : 0.435012 model2 loss : 0.023241
[23:35:00.055] iteration 6580 : model1 loss : 0.434018 model2 loss : 0.021981
[23:35:00.228] iteration 6581 : model1 loss : 0.435097 model2 loss : 0.025546
[23:35:00.405] iteration 6582 : model1 loss : 0.436440 model2 loss : 0.023205
[23:35:00.576] iteration 6583 : model1 loss : 0.435341 model2 loss : 0.026519
[23:35:00.754] iteration 6584 : model1 loss : 0.435022 model2 loss : 0.026697
[23:35:00.928] iteration 6585 : model1 loss : 0.440344 model2 loss : 0.025718
[23:35:01.103] iteration 6586 : model1 loss : 0.437414 model2 loss : 0.022562
[23:35:01.273] iteration 6587 : model1 loss : 0.440567 model2 loss : 0.031113
[23:35:01.451] iteration 6588 : model1 loss : 0.434425 model2 loss : 0.024547
[23:35:01.623] iteration 6589 : model1 loss : 0.440893 model2 loss : 0.031934
[23:35:01.803] iteration 6590 : model1 loss : 0.439322 model2 loss : 0.025299
[23:35:01.975] iteration 6591 : model1 loss : 0.439703 model2 loss : 0.025638
[23:35:02.152] iteration 6592 : model1 loss : 0.439133 model2 loss : 0.028092
[23:35:02.324] iteration 6593 : model1 loss : 0.440711 model2 loss : 0.031172
[23:35:02.504] iteration 6594 : model1 loss : 0.435425 model2 loss : 0.024189
[23:35:04.636] iteration 6595 : model1 loss : 0.437103 model2 loss : 0.020571
[23:35:04.810] iteration 6596 : model1 loss : 0.438977 model2 loss : 0.025170
[23:35:04.990] iteration 6597 : model1 loss : 0.438912 model2 loss : 0.025643
[23:35:05.161] iteration 6598 : model1 loss : 0.434998 model2 loss : 0.023016
[23:35:05.341] iteration 6599 : model1 loss : 0.439171 model2 loss : 0.023970
[23:35:05.514] iteration 6600 : model1 loss : 0.436286 model2 loss : 0.031080
[23:35:05.691] iteration 6601 : model1 loss : 0.438793 model2 loss : 0.031648
[23:35:05.865] iteration 6602 : model1 loss : 0.431735 model2 loss : 0.023323
[23:35:06.041] iteration 6603 : model1 loss : 0.433728 model2 loss : 0.023029
[23:35:06.212] iteration 6604 : model1 loss : 0.435894 model2 loss : 0.027056
[23:35:06.388] iteration 6605 : model1 loss : 0.437107 model2 loss : 0.026773
[23:35:06.559] iteration 6606 : model1 loss : 0.435721 model2 loss : 0.025794
[23:35:06.734] iteration 6607 : model1 loss : 0.439445 model2 loss : 0.031627
[23:35:06.913] iteration 6608 : model1 loss : 0.436467 model2 loss : 0.025129
[23:35:07.090] iteration 6609 : model1 loss : 0.442637 model2 loss : 0.035043
[23:35:07.262] iteration 6610 : model1 loss : 0.439893 model2 loss : 0.025967
[23:35:07.439] iteration 6611 : model1 loss : 0.437399 model2 loss : 0.024088
[23:35:07.613] iteration 6612 : model1 loss : 0.444183 model2 loss : 0.029658
[23:35:07.790] iteration 6613 : model1 loss : 0.439591 model2 loss : 0.029048
[23:35:07.961] iteration 6614 : model1 loss : 0.432807 model2 loss : 0.023901
[23:35:08.135] iteration 6615 : model1 loss : 0.436515 model2 loss : 0.025764
[23:35:10.312] iteration 6616 : model1 loss : 0.436949 model2 loss : 0.022497
[23:35:10.493] iteration 6617 : model1 loss : 0.439086 model2 loss : 0.030728
[23:35:10.670] iteration 6618 : model1 loss : 0.440247 model2 loss : 0.025170
[23:35:10.843] iteration 6619 : model1 loss : 0.436713 model2 loss : 0.021731
[23:35:11.021] iteration 6620 : model1 loss : 0.435128 model2 loss : 0.019789
[23:35:11.190] iteration 6621 : model1 loss : 0.438837 model2 loss : 0.027340
[23:35:11.367] iteration 6622 : model1 loss : 0.436903 model2 loss : 0.023618
[23:35:11.540] iteration 6623 : model1 loss : 0.436073 model2 loss : 0.026913
[23:35:11.729] iteration 6624 : model1 loss : 0.435730 model2 loss : 0.029163
[23:35:11.905] iteration 6625 : model1 loss : 0.432666 model2 loss : 0.024035
[23:35:12.082] iteration 6626 : model1 loss : 0.432996 model2 loss : 0.023474
[23:35:12.251] iteration 6627 : model1 loss : 0.441150 model2 loss : 0.028512
[23:35:12.430] iteration 6628 : model1 loss : 0.444424 model2 loss : 0.039498
[23:35:12.607] iteration 6629 : model1 loss : 0.440896 model2 loss : 0.025909
[23:35:12.781] iteration 6630 : model1 loss : 0.436372 model2 loss : 0.026462
[23:35:12.954] iteration 6631 : model1 loss : 0.436198 model2 loss : 0.026160
[23:35:13.129] iteration 6632 : model1 loss : 0.434191 model2 loss : 0.025969
[23:35:13.301] iteration 6633 : model1 loss : 0.435428 model2 loss : 0.023798
[23:35:13.479] iteration 6634 : model1 loss : 0.438798 model2 loss : 0.034167
[23:35:13.652] iteration 6635 : model1 loss : 0.444110 model2 loss : 0.029647
[23:35:13.830] iteration 6636 : model1 loss : 0.436104 model2 loss : 0.029632
[23:35:15.992] iteration 6637 : model1 loss : 0.434693 model2 loss : 0.024745
[23:35:16.167] iteration 6638 : model1 loss : 0.434139 model2 loss : 0.024898
[23:35:16.348] iteration 6639 : model1 loss : 0.437018 model2 loss : 0.026326
[23:35:16.517] iteration 6640 : model1 loss : 0.439619 model2 loss : 0.033077
[23:35:16.693] iteration 6641 : model1 loss : 0.435189 model2 loss : 0.024364
[23:35:16.866] iteration 6642 : model1 loss : 0.436367 model2 loss : 0.028410
[23:35:17.041] iteration 6643 : model1 loss : 0.444791 model2 loss : 0.042240
[23:35:17.213] iteration 6644 : model1 loss : 0.434268 model2 loss : 0.026969
[23:35:17.390] iteration 6645 : model1 loss : 0.438840 model2 loss : 0.025434
[23:35:17.562] iteration 6646 : model1 loss : 0.436096 model2 loss : 0.030241
[23:35:17.735] iteration 6647 : model1 loss : 0.433341 model2 loss : 0.030487
[23:35:17.910] iteration 6648 : model1 loss : 0.436855 model2 loss : 0.040011
[23:35:18.085] iteration 6649 : model1 loss : 0.439171 model2 loss : 0.038910
[23:35:18.256] iteration 6650 : model1 loss : 0.439861 model2 loss : 0.028513
[23:35:18.433] iteration 6651 : model1 loss : 0.437860 model2 loss : 0.028486
[23:35:18.605] iteration 6652 : model1 loss : 0.440190 model2 loss : 0.023715
[23:35:18.784] iteration 6653 : model1 loss : 0.437450 model2 loss : 0.024010
[23:35:18.961] iteration 6654 : model1 loss : 0.443777 model2 loss : 0.037283
[23:35:19.139] iteration 6655 : model1 loss : 0.436410 model2 loss : 0.026009
[23:35:19.309] iteration 6656 : model1 loss : 0.440072 model2 loss : 0.031666
[23:35:19.490] iteration 6657 : model1 loss : 0.437557 model2 loss : 0.026523
[23:35:21.638] iteration 6658 : model1 loss : 0.438294 model2 loss : 0.023664
[23:35:21.810] iteration 6659 : model1 loss : 0.433065 model2 loss : 0.023196
[23:35:21.990] iteration 6660 : model1 loss : 0.438166 model2 loss : 0.027600
[23:35:22.163] iteration 6661 : model1 loss : 0.434810 model2 loss : 0.025246
[23:35:22.343] iteration 6662 : model1 loss : 0.442360 model2 loss : 0.035813
[23:35:22.519] iteration 6663 : model1 loss : 0.433647 model2 loss : 0.025092
[23:35:22.697] iteration 6664 : model1 loss : 0.431292 model2 loss : 0.023452
[23:35:22.872] iteration 6665 : model1 loss : 0.436548 model2 loss : 0.027080
[23:35:23.049] iteration 6666 : model1 loss : 0.438614 model2 loss : 0.031293
[23:35:23.222] iteration 6667 : model1 loss : 0.440476 model2 loss : 0.026708
[23:35:23.398] iteration 6668 : model1 loss : 0.440184 model2 loss : 0.029548
[23:35:23.570] iteration 6669 : model1 loss : 0.438921 model2 loss : 0.031579
[23:35:23.746] iteration 6670 : model1 loss : 0.436451 model2 loss : 0.027269
[23:35:23.920] iteration 6671 : model1 loss : 0.439447 model2 loss : 0.028808
[23:35:24.101] iteration 6672 : model1 loss : 0.439496 model2 loss : 0.023899
[23:35:24.275] iteration 6673 : model1 loss : 0.436482 model2 loss : 0.026246
[23:35:24.451] iteration 6674 : model1 loss : 0.437185 model2 loss : 0.026972
[23:35:24.624] iteration 6675 : model1 loss : 0.436828 model2 loss : 0.023591
[23:35:24.799] iteration 6676 : model1 loss : 0.436309 model2 loss : 0.026447
[23:35:24.970] iteration 6677 : model1 loss : 0.434240 model2 loss : 0.026073
[23:35:25.144] iteration 6678 : model1 loss : 0.437885 model2 loss : 0.025058
[23:35:27.284] iteration 6679 : model1 loss : 0.437854 model2 loss : 0.029375
[23:35:27.464] iteration 6680 : model1 loss : 0.437744 model2 loss : 0.029576
[23:35:27.648] iteration 6681 : model1 loss : 0.435028 model2 loss : 0.026499
[23:35:27.818] iteration 6682 : model1 loss : 0.432481 model2 loss : 0.023527
[23:35:27.995] iteration 6683 : model1 loss : 0.434174 model2 loss : 0.023968
[23:35:28.164] iteration 6684 : model1 loss : 0.438948 model2 loss : 0.023843
[23:35:28.343] iteration 6685 : model1 loss : 0.437205 model2 loss : 0.026713
[23:35:28.515] iteration 6686 : model1 loss : 0.439564 model2 loss : 0.025166
[23:35:28.696] iteration 6687 : model1 loss : 0.437102 model2 loss : 0.029378
[23:35:28.871] iteration 6688 : model1 loss : 0.441461 model2 loss : 0.024098
[23:35:29.048] iteration 6689 : model1 loss : 0.436197 model2 loss : 0.021871
[23:35:29.220] iteration 6690 : model1 loss : 0.438591 model2 loss : 0.022734
[23:35:29.397] iteration 6691 : model1 loss : 0.435683 model2 loss : 0.026420
[23:35:29.575] iteration 6692 : model1 loss : 0.439754 model2 loss : 0.035493
[23:35:29.751] iteration 6693 : model1 loss : 0.438588 model2 loss : 0.027577
[23:35:29.923] iteration 6694 : model1 loss : 0.434163 model2 loss : 0.025353
[23:35:30.101] iteration 6695 : model1 loss : 0.438584 model2 loss : 0.042370
[23:35:30.274] iteration 6696 : model1 loss : 0.438157 model2 loss : 0.027786
[23:35:30.449] iteration 6697 : model1 loss : 0.437087 model2 loss : 0.027414
[23:35:30.621] iteration 6698 : model1 loss : 0.438314 model2 loss : 0.026975
[23:35:30.795] iteration 6699 : model1 loss : 0.435858 model2 loss : 0.026097
[23:35:32.970] iteration 6700 : model1 loss : 0.434530 model2 loss : 0.025765
[23:35:33.140] iteration 6701 : model1 loss : 0.438657 model2 loss : 0.026838
[23:35:33.320] iteration 6702 : model1 loss : 0.437644 model2 loss : 0.026190
[23:35:33.494] iteration 6703 : model1 loss : 0.435039 model2 loss : 0.021589
[23:35:33.670] iteration 6704 : model1 loss : 0.437820 model2 loss : 0.028700
[23:35:33.840] iteration 6705 : model1 loss : 0.432466 model2 loss : 0.025997
[23:35:34.020] iteration 6706 : model1 loss : 0.439132 model2 loss : 0.032624
[23:35:34.190] iteration 6707 : model1 loss : 0.438982 model2 loss : 0.026824
[23:35:34.365] iteration 6708 : model1 loss : 0.439738 model2 loss : 0.026348
[23:35:34.538] iteration 6709 : model1 loss : 0.438834 model2 loss : 0.026906
[23:35:34.714] iteration 6710 : model1 loss : 0.439152 model2 loss : 0.027608
[23:35:34.890] iteration 6711 : model1 loss : 0.434911 model2 loss : 0.027559
[23:35:35.068] iteration 6712 : model1 loss : 0.435724 model2 loss : 0.024561
[23:35:35.238] iteration 6713 : model1 loss : 0.436062 model2 loss : 0.025522
[23:35:35.416] iteration 6714 : model1 loss : 0.436485 model2 loss : 0.026016
[23:35:35.589] iteration 6715 : model1 loss : 0.440549 model2 loss : 0.027246
[23:35:35.762] iteration 6716 : model1 loss : 0.436337 model2 loss : 0.027321
[23:35:35.937] iteration 6717 : model1 loss : 0.438698 model2 loss : 0.025934
[23:35:36.114] iteration 6718 : model1 loss : 0.439411 model2 loss : 0.025985
[23:35:36.283] iteration 6719 : model1 loss : 0.437865 model2 loss : 0.028002
[23:35:36.458] iteration 6720 : model1 loss : 0.436324 model2 loss : 0.026342
[23:35:38.623] iteration 6721 : model1 loss : 0.437756 model2 loss : 0.025266
[23:35:38.798] iteration 6722 : model1 loss : 0.439825 model2 loss : 0.025978
[23:35:38.977] iteration 6723 : model1 loss : 0.436463 model2 loss : 0.026737
[23:35:39.149] iteration 6724 : model1 loss : 0.438018 model2 loss : 0.025715
[23:35:39.326] iteration 6725 : model1 loss : 0.437110 model2 loss : 0.031804
[23:35:39.501] iteration 6726 : model1 loss : 0.435284 model2 loss : 0.024611
[23:35:39.676] iteration 6727 : model1 loss : 0.438887 model2 loss : 0.024855
[23:35:39.846] iteration 6728 : model1 loss : 0.438845 model2 loss : 0.025819
[23:35:40.024] iteration 6729 : model1 loss : 0.438842 model2 loss : 0.023272
[23:35:40.193] iteration 6730 : model1 loss : 0.434692 model2 loss : 0.025654
[23:35:40.368] iteration 6731 : model1 loss : 0.435443 model2 loss : 0.026670
[23:35:40.541] iteration 6732 : model1 loss : 0.440295 model2 loss : 0.027870
[23:35:40.715] iteration 6733 : model1 loss : 0.440828 model2 loss : 0.028842
[23:35:40.888] iteration 6734 : model1 loss : 0.437230 model2 loss : 0.026767
[23:35:41.066] iteration 6735 : model1 loss : 0.439533 model2 loss : 0.026860
[23:35:41.238] iteration 6736 : model1 loss : 0.436906 model2 loss : 0.024254
[23:35:41.415] iteration 6737 : model1 loss : 0.433420 model2 loss : 0.025178
[23:35:41.589] iteration 6738 : model1 loss : 0.438890 model2 loss : 0.024799
[23:35:41.763] iteration 6739 : model1 loss : 0.434809 model2 loss : 0.025624
[23:35:41.936] iteration 6740 : model1 loss : 0.439430 model2 loss : 0.034703
[23:35:42.109] iteration 6741 : model1 loss : 0.436265 model2 loss : 0.027685
[23:35:44.277] iteration 6742 : model1 loss : 0.436889 model2 loss : 0.026473
[23:35:44.454] iteration 6743 : model1 loss : 0.439181 model2 loss : 0.025928
[23:35:44.630] iteration 6744 : model1 loss : 0.437803 model2 loss : 0.024156
[23:35:44.802] iteration 6745 : model1 loss : 0.440456 model2 loss : 0.025510
[23:35:44.976] iteration 6746 : model1 loss : 0.437766 model2 loss : 0.027001
[23:35:45.147] iteration 6747 : model1 loss : 0.440457 model2 loss : 0.028249
[23:35:45.332] iteration 6748 : model1 loss : 0.438159 model2 loss : 0.023625
[23:35:45.505] iteration 6749 : model1 loss : 0.431200 model2 loss : 0.026621
[23:35:45.681] iteration 6750 : model1 loss : 0.440546 model2 loss : 0.024818
[23:35:45.851] iteration 6751 : model1 loss : 0.443519 model2 loss : 0.026834
[23:35:46.027] iteration 6752 : model1 loss : 0.437975 model2 loss : 0.024944
[23:35:46.198] iteration 6753 : model1 loss : 0.433775 model2 loss : 0.023135
[23:35:46.371] iteration 6754 : model1 loss : 0.434892 model2 loss : 0.024425
[23:35:46.544] iteration 6755 : model1 loss : 0.437090 model2 loss : 0.026430
[23:35:46.720] iteration 6756 : model1 loss : 0.439621 model2 loss : 0.028947
[23:35:46.893] iteration 6757 : model1 loss : 0.434215 model2 loss : 0.023677
[23:35:47.067] iteration 6758 : model1 loss : 0.437109 model2 loss : 0.023721
[23:35:47.236] iteration 6759 : model1 loss : 0.439377 model2 loss : 0.030432
[23:35:47.418] iteration 6760 : model1 loss : 0.432154 model2 loss : 0.021518
[23:35:47.589] iteration 6761 : model1 loss : 0.441080 model2 loss : 0.029818
[23:35:47.764] iteration 6762 : model1 loss : 0.436996 model2 loss : 0.025754
[23:35:49.892] iteration 6763 : model1 loss : 0.433982 model2 loss : 0.025131
[23:35:50.068] iteration 6764 : model1 loss : 0.440142 model2 loss : 0.029456
[23:35:50.244] iteration 6765 : model1 loss : 0.436371 model2 loss : 0.024080
[23:35:50.418] iteration 6766 : model1 loss : 0.438477 model2 loss : 0.027035
[23:35:50.600] iteration 6767 : model1 loss : 0.438478 model2 loss : 0.027550
[23:35:50.771] iteration 6768 : model1 loss : 0.437844 model2 loss : 0.025247
[23:35:50.950] iteration 6769 : model1 loss : 0.439411 model2 loss : 0.026458
[23:35:51.121] iteration 6770 : model1 loss : 0.438624 model2 loss : 0.027191
[23:35:51.296] iteration 6771 : model1 loss : 0.439472 model2 loss : 0.025722
[23:35:51.470] iteration 6772 : model1 loss : 0.436109 model2 loss : 0.024483
[23:35:51.647] iteration 6773 : model1 loss : 0.440108 model2 loss : 0.027095
[23:35:51.818] iteration 6774 : model1 loss : 0.438268 model2 loss : 0.022142
[23:35:51.994] iteration 6775 : model1 loss : 0.433753 model2 loss : 0.022933
[23:35:52.168] iteration 6776 : model1 loss : 0.438341 model2 loss : 0.030495
[23:35:52.343] iteration 6777 : model1 loss : 0.436177 model2 loss : 0.023902
[23:35:52.519] iteration 6778 : model1 loss : 0.434199 model2 loss : 0.023637
[23:35:52.695] iteration 6779 : model1 loss : 0.439861 model2 loss : 0.023145
[23:35:52.868] iteration 6780 : model1 loss : 0.434779 model2 loss : 0.026608
[23:35:53.046] iteration 6781 : model1 loss : 0.435344 model2 loss : 0.027375
[23:35:53.216] iteration 6782 : model1 loss : 0.437552 model2 loss : 0.024758
[23:35:53.390] iteration 6783 : model1 loss : 0.438420 model2 loss : 0.025625
[23:35:55.567] iteration 6784 : model1 loss : 0.437864 model2 loss : 0.026577
[23:35:55.740] iteration 6785 : model1 loss : 0.439232 model2 loss : 0.028046
[23:35:55.919] iteration 6786 : model1 loss : 0.438502 model2 loss : 0.023880
[23:35:56.090] iteration 6787 : model1 loss : 0.443361 model2 loss : 0.028790
[23:35:56.265] iteration 6788 : model1 loss : 0.443742 model2 loss : 0.025786
[23:35:56.438] iteration 6789 : model1 loss : 0.437982 model2 loss : 0.029232
[23:35:56.616] iteration 6790 : model1 loss : 0.438151 model2 loss : 0.026085
[23:35:56.788] iteration 6791 : model1 loss : 0.438139 model2 loss : 0.024932
[23:35:56.969] iteration 6792 : model1 loss : 0.436367 model2 loss : 0.026953
[23:35:57.139] iteration 6793 : model1 loss : 0.438098 model2 loss : 0.025438
[23:35:57.320] iteration 6794 : model1 loss : 0.436996 model2 loss : 0.025871
[23:35:57.498] iteration 6795 : model1 loss : 0.437935 model2 loss : 0.025366
[23:35:57.678] iteration 6796 : model1 loss : 0.436767 model2 loss : 0.024472
[23:35:57.848] iteration 6797 : model1 loss : 0.434436 model2 loss : 0.025327
[23:35:58.024] iteration 6798 : model1 loss : 0.437085 model2 loss : 0.026092
[23:35:58.193] iteration 6799 : model1 loss : 0.436565 model2 loss : 0.026731
[23:35:58.369] iteration 6800 : model1 loss : 0.437396 model2 loss : 0.026645
[23:35:58.543] iteration 6801 : model1 loss : 0.430565 model2 loss : 0.023460
[23:35:58.720] iteration 6802 : model1 loss : 0.438257 model2 loss : 0.029320
[23:35:58.891] iteration 6803 : model1 loss : 0.440337 model2 loss : 0.027249
[23:35:59.067] iteration 6804 : model1 loss : 0.434771 model2 loss : 0.023697
[23:36:01.259] iteration 6805 : model1 loss : 0.439995 model2 loss : 0.026737
[23:36:01.435] iteration 6806 : model1 loss : 0.435115 model2 loss : 0.023858
[23:36:01.615] iteration 6807 : model1 loss : 0.437704 model2 loss : 0.027010
[23:36:01.786] iteration 6808 : model1 loss : 0.437537 model2 loss : 0.026837
[23:36:01.963] iteration 6809 : model1 loss : 0.437301 model2 loss : 0.024652
[23:36:02.135] iteration 6810 : model1 loss : 0.437915 model2 loss : 0.022729
[23:36:02.317] iteration 6811 : model1 loss : 0.440708 model2 loss : 0.027574
[23:36:02.496] iteration 6812 : model1 loss : 0.436784 model2 loss : 0.025872
[23:36:02.673] iteration 6813 : model1 loss : 0.435253 model2 loss : 0.026707
[23:36:02.844] iteration 6814 : model1 loss : 0.438435 model2 loss : 0.026786
[23:36:03.021] iteration 6815 : model1 loss : 0.440426 model2 loss : 0.033506
[23:36:03.192] iteration 6816 : model1 loss : 0.438983 model2 loss : 0.025315
[23:36:03.367] iteration 6817 : model1 loss : 0.432164 model2 loss : 0.022428
[23:36:03.541] iteration 6818 : model1 loss : 0.442741 model2 loss : 0.038522
[23:36:03.718] iteration 6819 : model1 loss : 0.436205 model2 loss : 0.024157
[23:36:03.893] iteration 6820 : model1 loss : 0.439963 model2 loss : 0.029091
[23:36:04.071] iteration 6821 : model1 loss : 0.439041 model2 loss : 0.025833
[23:36:04.242] iteration 6822 : model1 loss : 0.440783 model2 loss : 0.028635
[23:36:04.418] iteration 6823 : model1 loss : 0.434704 model2 loss : 0.024304
[23:36:04.591] iteration 6824 : model1 loss : 0.438176 model2 loss : 0.027896
[23:36:04.765] iteration 6825 : model1 loss : 0.436122 model2 loss : 0.027503
[23:36:06.896] iteration 6826 : model1 loss : 0.439071 model2 loss : 0.027221
[23:36:07.072] iteration 6827 : model1 loss : 0.437156 model2 loss : 0.021471
[23:36:07.249] iteration 6828 : model1 loss : 0.433335 model2 loss : 0.023883
[23:36:07.425] iteration 6829 : model1 loss : 0.438833 model2 loss : 0.029998
[23:36:07.608] iteration 6830 : model1 loss : 0.437080 model2 loss : 0.027376
[23:36:07.779] iteration 6831 : model1 loss : 0.437434 model2 loss : 0.029928
[23:36:07.957] iteration 6832 : model1 loss : 0.440366 model2 loss : 0.037180
[23:36:08.133] iteration 6833 : model1 loss : 0.435421 model2 loss : 0.023867
[23:36:08.309] iteration 6834 : model1 loss : 0.437292 model2 loss : 0.021668
[23:36:08.485] iteration 6835 : model1 loss : 0.439902 model2 loss : 0.026990
[23:36:08.661] iteration 6836 : model1 loss : 0.438043 model2 loss : 0.032209
[23:36:08.834] iteration 6837 : model1 loss : 0.441675 model2 loss : 0.025436
[23:36:09.010] iteration 6838 : model1 loss : 0.434504 model2 loss : 0.024541
[23:36:09.184] iteration 6839 : model1 loss : 0.435713 model2 loss : 0.026497
[23:36:09.360] iteration 6840 : model1 loss : 0.439735 model2 loss : 0.027159
[23:36:09.533] iteration 6841 : model1 loss : 0.441279 model2 loss : 0.025792
[23:36:09.710] iteration 6842 : model1 loss : 0.437559 model2 loss : 0.027278
[23:36:09.883] iteration 6843 : model1 loss : 0.441825 model2 loss : 0.032966
[23:36:10.060] iteration 6844 : model1 loss : 0.439185 model2 loss : 0.032130
[23:36:10.229] iteration 6845 : model1 loss : 0.438639 model2 loss : 0.026075
[23:36:10.401] iteration 6846 : model1 loss : 0.437459 model2 loss : 0.026557
[23:36:12.564] iteration 6847 : model1 loss : 0.440642 model2 loss : 0.029548
[23:36:12.740] iteration 6848 : model1 loss : 0.438304 model2 loss : 0.029039
[23:36:12.918] iteration 6849 : model1 loss : 0.439146 model2 loss : 0.028646
[23:36:13.092] iteration 6850 : model1 loss : 0.443833 model2 loss : 0.037455
[23:36:13.268] iteration 6851 : model1 loss : 0.436963 model2 loss : 0.028581
[23:36:13.442] iteration 6852 : model1 loss : 0.436838 model2 loss : 0.025321
[23:36:13.620] iteration 6853 : model1 loss : 0.438087 model2 loss : 0.028461
[23:36:13.790] iteration 6854 : model1 loss : 0.436847 model2 loss : 0.040849
[23:36:13.966] iteration 6855 : model1 loss : 0.438486 model2 loss : 0.029297
[23:36:14.136] iteration 6856 : model1 loss : 0.440719 model2 loss : 0.033037
[23:36:14.313] iteration 6857 : model1 loss : 0.436455 model2 loss : 0.025870
[23:36:14.489] iteration 6858 : model1 loss : 0.434341 model2 loss : 0.027077
[23:36:14.665] iteration 6859 : model1 loss : 0.439363 model2 loss : 0.027052
[23:36:14.839] iteration 6860 : model1 loss : 0.439040 model2 loss : 0.031531
[23:36:15.017] iteration 6861 : model1 loss : 0.438050 model2 loss : 0.028928
[23:36:15.187] iteration 6862 : model1 loss : 0.438532 model2 loss : 0.028488
[23:36:15.365] iteration 6863 : model1 loss : 0.440311 model2 loss : 0.040038
[23:36:15.537] iteration 6864 : model1 loss : 0.434455 model2 loss : 0.027398
[23:36:15.712] iteration 6865 : model1 loss : 0.437297 model2 loss : 0.025275
[23:36:15.884] iteration 6866 : model1 loss : 0.437591 model2 loss : 0.027080
[23:36:16.061] iteration 6867 : model1 loss : 0.434735 model2 loss : 0.026746
[23:36:18.220] iteration 6868 : model1 loss : 0.438506 model2 loss : 0.026289
[23:36:18.392] iteration 6869 : model1 loss : 0.438739 model2 loss : 0.031149
[23:36:18.572] iteration 6870 : model1 loss : 0.438626 model2 loss : 0.032241
[23:36:18.744] iteration 6871 : model1 loss : 0.437951 model2 loss : 0.031073
[23:36:18.919] iteration 6872 : model1 loss : 0.435924 model2 loss : 0.029289
[23:36:19.093] iteration 6873 : model1 loss : 0.438015 model2 loss : 0.039102
[23:36:19.267] iteration 6874 : model1 loss : 0.437710 model2 loss : 0.031497
[23:36:19.440] iteration 6875 : model1 loss : 0.439812 model2 loss : 0.025991
[23:36:19.621] iteration 6876 : model1 loss : 0.438941 model2 loss : 0.030360
[23:36:19.791] iteration 6877 : model1 loss : 0.434805 model2 loss : 0.025770
[23:36:19.967] iteration 6878 : model1 loss : 0.437016 model2 loss : 0.025651
[23:36:20.137] iteration 6879 : model1 loss : 0.440699 model2 loss : 0.029150
[23:36:20.318] iteration 6880 : model1 loss : 0.433471 model2 loss : 0.028964
[23:36:20.492] iteration 6881 : model1 loss : 0.439135 model2 loss : 0.029464
[23:36:20.669] iteration 6882 : model1 loss : 0.439809 model2 loss : 0.028612
[23:36:20.840] iteration 6883 : model1 loss : 0.433046 model2 loss : 0.026114
[23:36:21.021] iteration 6884 : model1 loss : 0.441294 model2 loss : 0.034417
[23:36:21.191] iteration 6885 : model1 loss : 0.439624 model2 loss : 0.031036
[23:36:21.368] iteration 6886 : model1 loss : 0.439904 model2 loss : 0.032220
[23:36:21.538] iteration 6887 : model1 loss : 0.438496 model2 loss : 0.031487
[23:36:21.712] iteration 6888 : model1 loss : 0.439140 model2 loss : 0.031016
[23:36:23.847] iteration 6889 : model1 loss : 0.434081 model2 loss : 0.030315
[23:36:24.023] iteration 6890 : model1 loss : 0.438165 model2 loss : 0.030731
[23:36:24.199] iteration 6891 : model1 loss : 0.440259 model2 loss : 0.028513
[23:36:24.372] iteration 6892 : model1 loss : 0.440756 model2 loss : 0.025761
[23:36:24.551] iteration 6893 : model1 loss : 0.434706 model2 loss : 0.026285
[23:36:24.721] iteration 6894 : model1 loss : 0.436843 model2 loss : 0.025148
[23:36:24.896] iteration 6895 : model1 loss : 0.438015 model2 loss : 0.025533
[23:36:25.071] iteration 6896 : model1 loss : 0.439322 model2 loss : 0.028358
[23:36:25.248] iteration 6897 : model1 loss : 0.438994 model2 loss : 0.026181
[23:36:25.418] iteration 6898 : model1 loss : 0.435273 model2 loss : 0.023150
[23:36:25.599] iteration 6899 : model1 loss : 0.438899 model2 loss : 0.030946
[23:36:25.768] iteration 6900 : model1 loss : 0.441282 model2 loss : 0.025719
[23:36:25.946] iteration 6901 : model1 loss : 0.437365 model2 loss : 0.026694
[23:36:26.123] iteration 6902 : model1 loss : 0.437958 model2 loss : 0.027821
[23:36:26.300] iteration 6903 : model1 loss : 0.437575 model2 loss : 0.027313
[23:36:26.474] iteration 6904 : model1 loss : 0.436116 model2 loss : 0.027043
[23:36:26.651] iteration 6905 : model1 loss : 0.441680 model2 loss : 0.028305
[23:36:26.822] iteration 6906 : model1 loss : 0.436336 model2 loss : 0.025598
[23:36:26.998] iteration 6907 : model1 loss : 0.433238 model2 loss : 0.025102
[23:36:27.172] iteration 6908 : model1 loss : 0.440464 model2 loss : 0.032543
[23:36:27.349] iteration 6909 : model1 loss : 0.438407 model2 loss : 0.024278
[23:36:29.550] iteration 6910 : model1 loss : 0.435727 model2 loss : 0.022635
[23:36:29.723] iteration 6911 : model1 loss : 0.439139 model2 loss : 0.026864
[23:36:29.902] iteration 6912 : model1 loss : 0.440270 model2 loss : 0.028180
[23:36:30.076] iteration 6913 : model1 loss : 0.437236 model2 loss : 0.026922
[23:36:30.249] iteration 6914 : model1 loss : 0.436686 model2 loss : 0.026028
[23:36:30.419] iteration 6915 : model1 loss : 0.432426 model2 loss : 0.024069
[23:36:30.605] iteration 6916 : model1 loss : 0.438085 model2 loss : 0.027204
[23:36:30.775] iteration 6917 : model1 loss : 0.432814 model2 loss : 0.025744
[23:36:30.953] iteration 6918 : model1 loss : 0.438369 model2 loss : 0.028381
[23:36:31.126] iteration 6919 : model1 loss : 0.438069 model2 loss : 0.022795
[23:36:31.301] iteration 6920 : model1 loss : 0.435277 model2 loss : 0.025435
[23:36:31.475] iteration 6921 : model1 loss : 0.444998 model2 loss : 0.031009
[23:36:31.652] iteration 6922 : model1 loss : 0.436316 model2 loss : 0.026233
[23:36:31.823] iteration 6923 : model1 loss : 0.439746 model2 loss : 0.025151
[23:36:31.999] iteration 6924 : model1 loss : 0.435029 model2 loss : 0.022114
[23:36:32.172] iteration 6925 : model1 loss : 0.434003 model2 loss : 0.024080
[23:36:32.352] iteration 6926 : model1 loss : 0.435998 model2 loss : 0.024387
[23:36:32.527] iteration 6927 : model1 loss : 0.441715 model2 loss : 0.028929
[23:36:32.700] iteration 6928 : model1 loss : 0.434864 model2 loss : 0.024092
[23:36:32.870] iteration 6929 : model1 loss : 0.440968 model2 loss : 0.027527
[23:36:33.047] iteration 6930 : model1 loss : 0.440340 model2 loss : 0.030129
[23:36:35.204] iteration 6931 : model1 loss : 0.437107 model2 loss : 0.022878
[23:36:35.374] iteration 6932 : model1 loss : 0.440172 model2 loss : 0.027777
[23:36:35.553] iteration 6933 : model1 loss : 0.435550 model2 loss : 0.026273
[23:36:35.726] iteration 6934 : model1 loss : 0.439789 model2 loss : 0.032317
[23:36:35.900] iteration 6935 : model1 loss : 0.442540 model2 loss : 0.025895
[23:36:36.072] iteration 6936 : model1 loss : 0.434459 model2 loss : 0.028914
[23:36:36.248] iteration 6937 : model1 loss : 0.436948 model2 loss : 0.023710
[23:36:36.420] iteration 6938 : model1 loss : 0.443997 model2 loss : 0.027714
[23:36:36.599] iteration 6939 : model1 loss : 0.438291 model2 loss : 0.025283
[23:36:36.768] iteration 6940 : model1 loss : 0.432603 model2 loss : 0.022351
[23:36:36.945] iteration 6941 : model1 loss : 0.436323 model2 loss : 0.024098
[23:36:37.117] iteration 6942 : model1 loss : 0.436440 model2 loss : 0.025340
[23:36:37.295] iteration 6943 : model1 loss : 0.434832 model2 loss : 0.024167
[23:36:37.471] iteration 6944 : model1 loss : 0.437779 model2 loss : 0.024590
[23:36:37.647] iteration 6945 : model1 loss : 0.438096 model2 loss : 0.024274
[23:36:37.819] iteration 6946 : model1 loss : 0.436180 model2 loss : 0.022745
[23:36:37.994] iteration 6947 : model1 loss : 0.439872 model2 loss : 0.030791
[23:36:38.166] iteration 6948 : model1 loss : 0.440807 model2 loss : 0.026989
[23:36:38.347] iteration 6949 : model1 loss : 0.438776 model2 loss : 0.024768
[23:36:38.521] iteration 6950 : model1 loss : 0.431315 model2 loss : 0.022701
[23:36:38.698] iteration 6951 : model1 loss : 0.438126 model2 loss : 0.027558
[23:36:40.865] iteration 6952 : model1 loss : 0.435910 model2 loss : 0.024865
[23:36:41.045] iteration 6953 : model1 loss : 0.440219 model2 loss : 0.029649
[23:36:41.220] iteration 6954 : model1 loss : 0.438060 model2 loss : 0.023426
[23:36:41.392] iteration 6955 : model1 loss : 0.435315 model2 loss : 0.025165
[23:36:41.570] iteration 6956 : model1 loss : 0.438288 model2 loss : 0.024794
[23:36:41.739] iteration 6957 : model1 loss : 0.436264 model2 loss : 0.024222
[23:36:41.913] iteration 6958 : model1 loss : 0.434849 model2 loss : 0.027391
[23:36:42.086] iteration 6959 : model1 loss : 0.438877 model2 loss : 0.027578
[23:36:42.265] iteration 6960 : model1 loss : 0.439557 model2 loss : 0.031702
[23:36:42.439] iteration 6961 : model1 loss : 0.435363 model2 loss : 0.024767
[23:36:42.618] iteration 6962 : model1 loss : 0.436872 model2 loss : 0.024954
[23:36:42.790] iteration 6963 : model1 loss : 0.435244 model2 loss : 0.023526
[23:36:42.963] iteration 6964 : model1 loss : 0.444733 model2 loss : 0.029739
[23:36:43.137] iteration 6965 : model1 loss : 0.436188 model2 loss : 0.023011
[23:36:43.316] iteration 6966 : model1 loss : 0.441540 model2 loss : 0.027844
[23:36:43.490] iteration 6967 : model1 loss : 0.436869 model2 loss : 0.022365
[23:36:43.666] iteration 6968 : model1 loss : 0.432926 model2 loss : 0.023950
[23:36:43.838] iteration 6969 : model1 loss : 0.437145 model2 loss : 0.026332
[23:36:44.014] iteration 6970 : model1 loss : 0.437745 model2 loss : 0.024356
[23:36:44.183] iteration 6971 : model1 loss : 0.433604 model2 loss : 0.024081
[23:36:44.357] iteration 6972 : model1 loss : 0.438692 model2 loss : 0.024540
[23:36:46.528] iteration 6973 : model1 loss : 0.436694 model2 loss : 0.025943
[23:36:46.702] iteration 6974 : model1 loss : 0.438698 model2 loss : 0.027877
[23:36:46.879] iteration 6975 : model1 loss : 0.435636 model2 loss : 0.024707
[23:36:47.054] iteration 6976 : model1 loss : 0.436774 model2 loss : 0.023563
[23:36:47.236] iteration 6977 : model1 loss : 0.437644 model2 loss : 0.024778
[23:36:47.409] iteration 6978 : model1 loss : 0.441039 model2 loss : 0.024275
[23:36:47.590] iteration 6979 : model1 loss : 0.437635 model2 loss : 0.025092
[23:36:47.760] iteration 6980 : model1 loss : 0.441536 model2 loss : 0.028327
[23:36:47.935] iteration 6981 : model1 loss : 0.438716 model2 loss : 0.027919
[23:36:48.108] iteration 6982 : model1 loss : 0.435190 model2 loss : 0.026835
[23:36:48.285] iteration 6983 : model1 loss : 0.435856 model2 loss : 0.026059
[23:36:48.456] iteration 6984 : model1 loss : 0.435604 model2 loss : 0.025526
[23:36:48.634] iteration 6985 : model1 loss : 0.436845 model2 loss : 0.027380
[23:36:48.804] iteration 6986 : model1 loss : 0.436891 model2 loss : 0.023858
[23:36:48.979] iteration 6987 : model1 loss : 0.431867 model2 loss : 0.022621
[23:36:49.154] iteration 6988 : model1 loss : 0.438429 model2 loss : 0.028287
[23:36:49.333] iteration 6989 : model1 loss : 0.435257 model2 loss : 0.024071
[23:36:49.507] iteration 6990 : model1 loss : 0.440083 model2 loss : 0.026399
[23:36:49.684] iteration 6991 : model1 loss : 0.438717 model2 loss : 0.023986
[23:36:49.855] iteration 6992 : model1 loss : 0.435956 model2 loss : 0.025561
[23:36:50.030] iteration 6993 : model1 loss : 0.438875 model2 loss : 0.024320
[23:36:52.184] iteration 6994 : model1 loss : 0.436376 model2 loss : 0.024098
[23:36:52.360] iteration 6995 : model1 loss : 0.441479 model2 loss : 0.025877
[23:36:52.539] iteration 6996 : model1 loss : 0.438417 model2 loss : 0.028538
[23:36:52.709] iteration 6997 : model1 loss : 0.440441 model2 loss : 0.028027
[23:36:52.888] iteration 6998 : model1 loss : 0.440585 model2 loss : 0.028017
[23:36:53.063] iteration 6999 : model1 loss : 0.439335 model2 loss : 0.025120
[23:36:53.238] iteration 7000 : model1 loss : 0.438474 model2 loss : 0.025237
[23:37:02.469] iteration 7000 : model1_mean_dice : 0.805815 model1_mean_hd95 : 5.143435
[23:37:11.695] iteration 7000 : model2_mean_dice : 0.862817 model2_mean_hd95 : 7.279679
[23:37:11.877] iteration 7001 : model1 loss : 0.440356 model2 loss : 0.027844
[23:37:12.061] iteration 7002 : model1 loss : 0.434835 model2 loss : 0.027503
[23:37:12.234] iteration 7003 : model1 loss : 0.439462 model2 loss : 0.025723
[23:37:12.413] iteration 7004 : model1 loss : 0.434874 model2 loss : 0.027159
[23:37:12.589] iteration 7005 : model1 loss : 0.433983 model2 loss : 0.024549
[23:37:12.765] iteration 7006 : model1 loss : 0.436029 model2 loss : 0.024215
[23:37:12.936] iteration 7007 : model1 loss : 0.432943 model2 loss : 0.022979
[23:37:13.112] iteration 7008 : model1 loss : 0.432633 model2 loss : 0.023748
[23:37:13.283] iteration 7009 : model1 loss : 0.435758 model2 loss : 0.026539
[23:37:13.459] iteration 7010 : model1 loss : 0.435786 model2 loss : 0.026473
[23:37:13.633] iteration 7011 : model1 loss : 0.438106 model2 loss : 0.026695
[23:37:13.807] iteration 7012 : model1 loss : 0.436629 model2 loss : 0.023929
[23:37:13.975] iteration 7013 : model1 loss : 0.439149 model2 loss : 0.028355
[23:37:14.149] iteration 7014 : model1 loss : 0.437150 model2 loss : 0.025054
[23:37:16.310] iteration 7015 : model1 loss : 0.441100 model2 loss : 0.026709
[23:37:16.481] iteration 7016 : model1 loss : 0.434679 model2 loss : 0.026402
[23:37:16.656] iteration 7017 : model1 loss : 0.439307 model2 loss : 0.022001
[23:37:16.826] iteration 7018 : model1 loss : 0.435370 model2 loss : 0.027329
[23:37:16.999] iteration 7019 : model1 loss : 0.437592 model2 loss : 0.027150
[23:37:17.171] iteration 7020 : model1 loss : 0.439539 model2 loss : 0.029826
[23:37:17.350] iteration 7021 : model1 loss : 0.439444 model2 loss : 0.026233
[23:37:17.523] iteration 7022 : model1 loss : 0.436760 model2 loss : 0.027332
[23:37:17.700] iteration 7023 : model1 loss : 0.435613 model2 loss : 0.022839
[23:37:17.873] iteration 7024 : model1 loss : 0.438880 model2 loss : 0.022602
[23:37:18.050] iteration 7025 : model1 loss : 0.436054 model2 loss : 0.024612
[23:37:18.224] iteration 7026 : model1 loss : 0.436635 model2 loss : 0.024292
[23:37:18.399] iteration 7027 : model1 loss : 0.431587 model2 loss : 0.023451
[23:37:18.573] iteration 7028 : model1 loss : 0.442825 model2 loss : 0.029809
[23:37:18.751] iteration 7029 : model1 loss : 0.437708 model2 loss : 0.023739
[23:37:18.921] iteration 7030 : model1 loss : 0.437252 model2 loss : 0.019449
[23:37:19.099] iteration 7031 : model1 loss : 0.438143 model2 loss : 0.028875
[23:37:19.270] iteration 7032 : model1 loss : 0.434605 model2 loss : 0.026304
[23:37:19.447] iteration 7033 : model1 loss : 0.440227 model2 loss : 0.028261
[23:37:19.620] iteration 7034 : model1 loss : 0.438696 model2 loss : 0.027099
[23:37:19.797] iteration 7035 : model1 loss : 0.433601 model2 loss : 0.027344
[23:37:21.922] iteration 7036 : model1 loss : 0.436268 model2 loss : 0.024844
[23:37:22.099] iteration 7037 : model1 loss : 0.436893 model2 loss : 0.029470
[23:37:22.275] iteration 7038 : model1 loss : 0.437465 model2 loss : 0.025089
[23:37:22.448] iteration 7039 : model1 loss : 0.435074 model2 loss : 0.023709
[23:37:22.629] iteration 7040 : model1 loss : 0.438290 model2 loss : 0.025594
[23:37:22.802] iteration 7041 : model1 loss : 0.435527 model2 loss : 0.024088
[23:37:22.978] iteration 7042 : model1 loss : 0.439528 model2 loss : 0.024982
[23:37:23.159] iteration 7043 : model1 loss : 0.440153 model2 loss : 0.031124
[23:37:23.336] iteration 7044 : model1 loss : 0.436846 model2 loss : 0.022258
[23:37:23.505] iteration 7045 : model1 loss : 0.436050 model2 loss : 0.026392
[23:37:23.682] iteration 7046 : model1 loss : 0.441764 model2 loss : 0.027421
[23:37:23.853] iteration 7047 : model1 loss : 0.437084 model2 loss : 0.022831
[23:37:24.027] iteration 7048 : model1 loss : 0.437827 model2 loss : 0.024387
[23:37:24.200] iteration 7049 : model1 loss : 0.438040 model2 loss : 0.027823
[23:37:24.376] iteration 7050 : model1 loss : 0.438248 model2 loss : 0.027687
[23:37:24.549] iteration 7051 : model1 loss : 0.437697 model2 loss : 0.026762
[23:37:24.727] iteration 7052 : model1 loss : 0.433368 model2 loss : 0.024430
[23:37:24.900] iteration 7053 : model1 loss : 0.436105 model2 loss : 0.027535
[23:37:25.077] iteration 7054 : model1 loss : 0.435981 model2 loss : 0.023586
[23:37:25.246] iteration 7055 : model1 loss : 0.437305 model2 loss : 0.030923
[23:37:25.422] iteration 7056 : model1 loss : 0.434719 model2 loss : 0.028083
[23:37:27.629] iteration 7057 : model1 loss : 0.437480 model2 loss : 0.028202
[23:37:27.801] iteration 7058 : model1 loss : 0.437319 model2 loss : 0.025106
[23:37:27.981] iteration 7059 : model1 loss : 0.435853 model2 loss : 0.025179
[23:37:28.153] iteration 7060 : model1 loss : 0.434983 model2 loss : 0.024629
[23:37:28.330] iteration 7061 : model1 loss : 0.433285 model2 loss : 0.023420
[23:37:28.499] iteration 7062 : model1 loss : 0.442706 model2 loss : 0.030549
[23:37:28.675] iteration 7063 : model1 loss : 0.437328 model2 loss : 0.027689
[23:37:28.846] iteration 7064 : model1 loss : 0.440810 model2 loss : 0.029980
[23:37:29.024] iteration 7065 : model1 loss : 0.435132 model2 loss : 0.023166
[23:37:29.197] iteration 7066 : model1 loss : 0.437026 model2 loss : 0.030018
[23:37:29.375] iteration 7067 : model1 loss : 0.432764 model2 loss : 0.024794
[23:37:29.546] iteration 7068 : model1 loss : 0.436667 model2 loss : 0.025220
[23:37:29.725] iteration 7069 : model1 loss : 0.438088 model2 loss : 0.029114
[23:37:29.896] iteration 7070 : model1 loss : 0.436958 model2 loss : 0.024981
[23:37:30.073] iteration 7071 : model1 loss : 0.435687 model2 loss : 0.023405
[23:37:30.244] iteration 7072 : model1 loss : 0.443334 model2 loss : 0.024170
[23:37:30.418] iteration 7073 : model1 loss : 0.436234 model2 loss : 0.029100
[23:37:30.596] iteration 7074 : model1 loss : 0.433892 model2 loss : 0.024951
[23:37:30.773] iteration 7075 : model1 loss : 0.439424 model2 loss : 0.026369
[23:37:30.943] iteration 7076 : model1 loss : 0.439121 model2 loss : 0.030321
[23:37:31.123] iteration 7077 : model1 loss : 0.438823 model2 loss : 0.028801
[23:37:33.311] iteration 7078 : model1 loss : 0.438337 model2 loss : 0.025084
[23:37:33.486] iteration 7079 : model1 loss : 0.436796 model2 loss : 0.025854
[23:37:33.665] iteration 7080 : model1 loss : 0.439367 model2 loss : 0.024899
[23:37:33.838] iteration 7081 : model1 loss : 0.432970 model2 loss : 0.027133
[23:37:34.015] iteration 7082 : model1 loss : 0.439074 model2 loss : 0.023904
[23:37:34.187] iteration 7083 : model1 loss : 0.442443 model2 loss : 0.024738
[23:37:34.365] iteration 7084 : model1 loss : 0.433814 model2 loss : 0.031284
[23:37:34.535] iteration 7085 : model1 loss : 0.436391 model2 loss : 0.023179
[23:37:34.710] iteration 7086 : model1 loss : 0.434141 model2 loss : 0.023095
[23:37:34.881] iteration 7087 : model1 loss : 0.440569 model2 loss : 0.027470
[23:37:35.057] iteration 7088 : model1 loss : 0.433689 model2 loss : 0.022496
[23:37:35.236] iteration 7089 : model1 loss : 0.432813 model2 loss : 0.023477
[23:37:35.414] iteration 7090 : model1 loss : 0.443093 model2 loss : 0.027536
[23:37:35.588] iteration 7091 : model1 loss : 0.439961 model2 loss : 0.030006
[23:37:35.768] iteration 7092 : model1 loss : 0.443471 model2 loss : 0.031484
[23:37:35.940] iteration 7093 : model1 loss : 0.437727 model2 loss : 0.024606
[23:37:36.119] iteration 7094 : model1 loss : 0.434428 model2 loss : 0.023952
[23:37:36.289] iteration 7095 : model1 loss : 0.435740 model2 loss : 0.028742
[23:37:36.465] iteration 7096 : model1 loss : 0.439573 model2 loss : 0.028370
[23:37:36.636] iteration 7097 : model1 loss : 0.436938 model2 loss : 0.023410
[23:37:36.810] iteration 7098 : model1 loss : 0.439581 model2 loss : 0.030312
[23:37:38.975] iteration 7099 : model1 loss : 0.439038 model2 loss : 0.023229
[23:37:39.149] iteration 7100 : model1 loss : 0.438336 model2 loss : 0.023724
[23:37:39.332] iteration 7101 : model1 loss : 0.437686 model2 loss : 0.023308
[23:37:39.503] iteration 7102 : model1 loss : 0.439644 model2 loss : 0.026271
[23:37:39.679] iteration 7103 : model1 loss : 0.438763 model2 loss : 0.028365
[23:37:39.849] iteration 7104 : model1 loss : 0.436748 model2 loss : 0.025007
[23:37:40.024] iteration 7105 : model1 loss : 0.436944 model2 loss : 0.023807
[23:37:40.200] iteration 7106 : model1 loss : 0.432455 model2 loss : 0.022018
[23:37:40.376] iteration 7107 : model1 loss : 0.434293 model2 loss : 0.021772
[23:37:40.549] iteration 7108 : model1 loss : 0.440921 model2 loss : 0.027196
[23:37:40.727] iteration 7109 : model1 loss : 0.440188 model2 loss : 0.028958
[23:37:40.901] iteration 7110 : model1 loss : 0.439456 model2 loss : 0.026756
[23:37:41.077] iteration 7111 : model1 loss : 0.436423 model2 loss : 0.028216
[23:37:41.251] iteration 7112 : model1 loss : 0.436411 model2 loss : 0.023872
[23:37:41.426] iteration 7113 : model1 loss : 0.437120 model2 loss : 0.024761
[23:37:41.603] iteration 7114 : model1 loss : 0.439547 model2 loss : 0.029926
[23:37:41.777] iteration 7115 : model1 loss : 0.437578 model2 loss : 0.024952
[23:37:41.948] iteration 7116 : model1 loss : 0.439347 model2 loss : 0.024574
[23:37:42.126] iteration 7117 : model1 loss : 0.436704 model2 loss : 0.023971
[23:37:42.297] iteration 7118 : model1 loss : 0.440498 model2 loss : 0.028305
[23:37:42.471] iteration 7119 : model1 loss : 0.437226 model2 loss : 0.024411
[23:37:44.625] iteration 7120 : model1 loss : 0.445590 model2 loss : 0.023753
[23:37:44.796] iteration 7121 : model1 loss : 0.438392 model2 loss : 0.027661
[23:37:44.975] iteration 7122 : model1 loss : 0.437583 model2 loss : 0.024172
[23:37:45.147] iteration 7123 : model1 loss : 0.437634 model2 loss : 0.024092
[23:37:45.326] iteration 7124 : model1 loss : 0.434749 model2 loss : 0.024144
[23:37:45.498] iteration 7125 : model1 loss : 0.439562 model2 loss : 0.027213
[23:37:45.675] iteration 7126 : model1 loss : 0.437374 model2 loss : 0.024079
[23:37:45.847] iteration 7127 : model1 loss : 0.437606 model2 loss : 0.026105
[23:37:46.024] iteration 7128 : model1 loss : 0.434675 model2 loss : 0.023724
[23:37:46.195] iteration 7129 : model1 loss : 0.433464 model2 loss : 0.023959
[23:37:46.371] iteration 7130 : model1 loss : 0.440373 model2 loss : 0.026491
[23:37:46.542] iteration 7131 : model1 loss : 0.439902 model2 loss : 0.025149
[23:37:46.718] iteration 7132 : model1 loss : 0.439357 model2 loss : 0.026944
[23:37:46.890] iteration 7133 : model1 loss : 0.440064 model2 loss : 0.025227
[23:37:47.067] iteration 7134 : model1 loss : 0.437381 model2 loss : 0.026705
[23:37:47.245] iteration 7135 : model1 loss : 0.433616 model2 loss : 0.021695
[23:37:47.427] iteration 7136 : model1 loss : 0.435491 model2 loss : 0.024950
[23:37:47.608] iteration 7137 : model1 loss : 0.434291 model2 loss : 0.023147
[23:37:47.783] iteration 7138 : model1 loss : 0.440008 model2 loss : 0.022139
[23:37:47.954] iteration 7139 : model1 loss : 0.436494 model2 loss : 0.023792
[23:37:48.128] iteration 7140 : model1 loss : 0.436309 model2 loss : 0.026563
[23:37:50.273] iteration 7141 : model1 loss : 0.436866 model2 loss : 0.026188
[23:37:50.449] iteration 7142 : model1 loss : 0.436192 model2 loss : 0.024950
[23:37:50.630] iteration 7143 : model1 loss : 0.439191 model2 loss : 0.024356
[23:37:50.802] iteration 7144 : model1 loss : 0.437634 model2 loss : 0.024450
[23:37:50.976] iteration 7145 : model1 loss : 0.436401 model2 loss : 0.023100
[23:37:51.148] iteration 7146 : model1 loss : 0.440955 model2 loss : 0.025650
[23:37:51.329] iteration 7147 : model1 loss : 0.440326 model2 loss : 0.029442
[23:37:51.500] iteration 7148 : model1 loss : 0.440563 model2 loss : 0.027715
[23:37:51.676] iteration 7149 : model1 loss : 0.439616 model2 loss : 0.028244
[23:37:51.847] iteration 7150 : model1 loss : 0.437646 model2 loss : 0.025829
[23:37:52.023] iteration 7151 : model1 loss : 0.435821 model2 loss : 0.022429
[23:37:52.196] iteration 7152 : model1 loss : 0.438549 model2 loss : 0.024514
[23:37:52.370] iteration 7153 : model1 loss : 0.433993 model2 loss : 0.022446
[23:37:52.541] iteration 7154 : model1 loss : 0.436689 model2 loss : 0.022812
[23:37:52.719] iteration 7155 : model1 loss : 0.430216 model2 loss : 0.020761
[23:37:52.890] iteration 7156 : model1 loss : 0.436299 model2 loss : 0.024107
[23:37:53.065] iteration 7157 : model1 loss : 0.437238 model2 loss : 0.033370
[23:37:53.238] iteration 7158 : model1 loss : 0.440157 model2 loss : 0.030952
[23:37:53.416] iteration 7159 : model1 loss : 0.441150 model2 loss : 0.028445
[23:37:53.585] iteration 7160 : model1 loss : 0.438582 model2 loss : 0.023944
[23:37:53.762] iteration 7161 : model1 loss : 0.436274 model2 loss : 0.023463
[23:37:55.925] iteration 7162 : model1 loss : 0.437218 model2 loss : 0.023039
[23:37:56.099] iteration 7163 : model1 loss : 0.440259 model2 loss : 0.026848
[23:37:56.277] iteration 7164 : model1 loss : 0.435220 model2 loss : 0.026092
[23:37:56.448] iteration 7165 : model1 loss : 0.437761 model2 loss : 0.025184
[23:37:56.627] iteration 7166 : model1 loss : 0.437751 model2 loss : 0.030156
[23:37:56.798] iteration 7167 : model1 loss : 0.439128 model2 loss : 0.024142
[23:37:56.973] iteration 7168 : model1 loss : 0.437666 model2 loss : 0.028556
[23:37:57.145] iteration 7169 : model1 loss : 0.441947 model2 loss : 0.026376
[23:37:57.325] iteration 7170 : model1 loss : 0.437317 model2 loss : 0.022275
[23:37:57.504] iteration 7171 : model1 loss : 0.436509 model2 loss : 0.023986
[23:37:57.680] iteration 7172 : model1 loss : 0.438401 model2 loss : 0.022531
[23:37:57.852] iteration 7173 : model1 loss : 0.435009 model2 loss : 0.024795
[23:37:58.028] iteration 7174 : model1 loss : 0.435787 model2 loss : 0.024877
[23:37:58.202] iteration 7175 : model1 loss : 0.436797 model2 loss : 0.025259
[23:37:58.377] iteration 7176 : model1 loss : 0.436552 model2 loss : 0.023023
[23:37:58.548] iteration 7177 : model1 loss : 0.438213 model2 loss : 0.025962
[23:37:58.725] iteration 7178 : model1 loss : 0.441127 model2 loss : 0.027847
[23:37:58.896] iteration 7179 : model1 loss : 0.439812 model2 loss : 0.026991
[23:37:59.074] iteration 7180 : model1 loss : 0.440029 model2 loss : 0.025261
[23:37:59.247] iteration 7181 : model1 loss : 0.437836 model2 loss : 0.023468
[23:37:59.423] iteration 7182 : model1 loss : 0.435686 model2 loss : 0.024958
[23:38:01.574] iteration 7183 : model1 loss : 0.434718 model2 loss : 0.024266
[23:38:01.750] iteration 7184 : model1 loss : 0.436557 model2 loss : 0.021036
[23:38:01.931] iteration 7185 : model1 loss : 0.439467 model2 loss : 0.026133
[23:38:02.104] iteration 7186 : model1 loss : 0.437668 model2 loss : 0.025960
[23:38:02.280] iteration 7187 : model1 loss : 0.440498 model2 loss : 0.027793
[23:38:02.459] iteration 7188 : model1 loss : 0.444240 model2 loss : 0.026592
[23:38:02.640] iteration 7189 : model1 loss : 0.443265 model2 loss : 0.028867
[23:38:02.810] iteration 7190 : model1 loss : 0.435006 model2 loss : 0.022315
[23:38:02.999] iteration 7191 : model1 loss : 0.436020 model2 loss : 0.024119
[23:38:03.175] iteration 7192 : model1 loss : 0.440445 model2 loss : 0.026102
[23:38:03.353] iteration 7193 : model1 loss : 0.435017 model2 loss : 0.022746
[23:38:03.524] iteration 7194 : model1 loss : 0.441221 model2 loss : 0.025267
[23:38:03.702] iteration 7195 : model1 loss : 0.434663 model2 loss : 0.021334
[23:38:03.874] iteration 7196 : model1 loss : 0.434763 model2 loss : 0.024346
[23:38:04.049] iteration 7197 : model1 loss : 0.436403 model2 loss : 0.024045
[23:38:04.220] iteration 7198 : model1 loss : 0.434308 model2 loss : 0.024772
[23:38:04.397] iteration 7199 : model1 loss : 0.440687 model2 loss : 0.031443
[23:38:04.574] iteration 7200 : model1 loss : 0.435416 model2 loss : 0.023348
[23:38:04.747] iteration 7201 : model1 loss : 0.438861 model2 loss : 0.027924
[23:38:04.916] iteration 7202 : model1 loss : 0.437314 model2 loss : 0.027029
[23:38:05.091] iteration 7203 : model1 loss : 0.433301 model2 loss : 0.022210
[23:38:07.276] iteration 7204 : model1 loss : 0.440994 model2 loss : 0.024829
[23:38:07.453] iteration 7205 : model1 loss : 0.435522 model2 loss : 0.025211
[23:38:07.635] iteration 7206 : model1 loss : 0.435492 model2 loss : 0.023474
[23:38:07.805] iteration 7207 : model1 loss : 0.433052 model2 loss : 0.021928
[23:38:07.982] iteration 7208 : model1 loss : 0.441378 model2 loss : 0.029371
[23:38:08.155] iteration 7209 : model1 loss : 0.441632 model2 loss : 0.025800
[23:38:08.332] iteration 7210 : model1 loss : 0.437056 model2 loss : 0.023970
[23:38:08.505] iteration 7211 : model1 loss : 0.436196 model2 loss : 0.025202
[23:38:08.683] iteration 7212 : model1 loss : 0.438710 model2 loss : 0.024363
[23:38:08.855] iteration 7213 : model1 loss : 0.433852 model2 loss : 0.024838
[23:38:09.030] iteration 7214 : model1 loss : 0.440074 model2 loss : 0.027762
[23:38:09.204] iteration 7215 : model1 loss : 0.435822 model2 loss : 0.024268
[23:38:09.380] iteration 7216 : model1 loss : 0.437655 model2 loss : 0.020824
[23:38:09.550] iteration 7217 : model1 loss : 0.437489 model2 loss : 0.023236
[23:38:09.728] iteration 7218 : model1 loss : 0.441839 model2 loss : 0.029471
[23:38:09.900] iteration 7219 : model1 loss : 0.437963 model2 loss : 0.025721
[23:38:10.074] iteration 7220 : model1 loss : 0.436065 model2 loss : 0.022817
[23:38:10.247] iteration 7221 : model1 loss : 0.436615 model2 loss : 0.027716
[23:38:10.424] iteration 7222 : model1 loss : 0.436853 model2 loss : 0.023591
[23:38:10.596] iteration 7223 : model1 loss : 0.437912 model2 loss : 0.026214
[23:38:10.769] iteration 7224 : model1 loss : 0.435798 model2 loss : 0.026418
[23:38:12.933] iteration 7225 : model1 loss : 0.440682 model2 loss : 0.026407
[23:38:13.106] iteration 7226 : model1 loss : 0.432758 model2 loss : 0.020356
[23:38:13.285] iteration 7227 : model1 loss : 0.435522 model2 loss : 0.024462
[23:38:13.456] iteration 7228 : model1 loss : 0.440402 model2 loss : 0.025602
[23:38:13.634] iteration 7229 : model1 loss : 0.438327 model2 loss : 0.024920
[23:38:13.809] iteration 7230 : model1 loss : 0.438778 model2 loss : 0.028057
[23:38:13.985] iteration 7231 : model1 loss : 0.436780 model2 loss : 0.026476
[23:38:14.156] iteration 7232 : model1 loss : 0.436504 model2 loss : 0.024341
[23:38:14.339] iteration 7233 : model1 loss : 0.444080 model2 loss : 0.028599
[23:38:14.511] iteration 7234 : model1 loss : 0.431695 model2 loss : 0.023786
[23:38:14.689] iteration 7235 : model1 loss : 0.433203 model2 loss : 0.025892
[23:38:14.861] iteration 7236 : model1 loss : 0.437211 model2 loss : 0.023948
[23:38:15.035] iteration 7237 : model1 loss : 0.435062 model2 loss : 0.022740
[23:38:15.209] iteration 7238 : model1 loss : 0.433757 model2 loss : 0.020329
[23:38:15.388] iteration 7239 : model1 loss : 0.446367 model2 loss : 0.029994
[23:38:15.557] iteration 7240 : model1 loss : 0.438713 model2 loss : 0.029035
[23:38:15.732] iteration 7241 : model1 loss : 0.444707 model2 loss : 0.024085
[23:38:15.906] iteration 7242 : model1 loss : 0.436005 model2 loss : 0.026085
[23:38:16.082] iteration 7243 : model1 loss : 0.439101 model2 loss : 0.024683
[23:38:16.253] iteration 7244 : model1 loss : 0.437418 model2 loss : 0.031012
[23:38:16.427] iteration 7245 : model1 loss : 0.435799 model2 loss : 0.023672
[23:38:18.583] iteration 7246 : model1 loss : 0.439798 model2 loss : 0.026925
[23:38:18.761] iteration 7247 : model1 loss : 0.434498 model2 loss : 0.021540
[23:38:18.941] iteration 7248 : model1 loss : 0.435447 model2 loss : 0.024056
[23:38:19.112] iteration 7249 : model1 loss : 0.437039 model2 loss : 0.027488
[23:38:19.289] iteration 7250 : model1 loss : 0.435454 model2 loss : 0.023764
[23:38:19.464] iteration 7251 : model1 loss : 0.441679 model2 loss : 0.031650
[23:38:19.641] iteration 7252 : model1 loss : 0.436329 model2 loss : 0.023026
[23:38:19.815] iteration 7253 : model1 loss : 0.441340 model2 loss : 0.025048
[23:38:19.992] iteration 7254 : model1 loss : 0.434239 model2 loss : 0.022669
[23:38:20.163] iteration 7255 : model1 loss : 0.432337 model2 loss : 0.024897
[23:38:20.344] iteration 7256 : model1 loss : 0.439119 model2 loss : 0.028442
[23:38:20.516] iteration 7257 : model1 loss : 0.439886 model2 loss : 0.024219
[23:38:20.693] iteration 7258 : model1 loss : 0.439506 model2 loss : 0.026571
[23:38:20.866] iteration 7259 : model1 loss : 0.439916 model2 loss : 0.024283
[23:38:21.041] iteration 7260 : model1 loss : 0.434946 model2 loss : 0.023041
[23:38:21.215] iteration 7261 : model1 loss : 0.438381 model2 loss : 0.026721
[23:38:21.412] iteration 7262 : model1 loss : 0.438414 model2 loss : 0.025024
[23:38:21.584] iteration 7263 : model1 loss : 0.443073 model2 loss : 0.026243
[23:38:21.760] iteration 7264 : model1 loss : 0.436436 model2 loss : 0.025119
[23:38:21.929] iteration 7265 : model1 loss : 0.438334 model2 loss : 0.026397
[23:38:22.103] iteration 7266 : model1 loss : 0.437234 model2 loss : 0.026795
[23:38:24.235] iteration 7267 : model1 loss : 0.434845 model2 loss : 0.023241
[23:38:24.408] iteration 7268 : model1 loss : 0.437000 model2 loss : 0.025059
[23:38:24.585] iteration 7269 : model1 loss : 0.440231 model2 loss : 0.027139
[23:38:24.759] iteration 7270 : model1 loss : 0.435285 model2 loss : 0.021780
[23:38:24.935] iteration 7271 : model1 loss : 0.440210 model2 loss : 0.026673
[23:38:25.106] iteration 7272 : model1 loss : 0.440277 model2 loss : 0.029519
[23:38:25.279] iteration 7273 : model1 loss : 0.438861 model2 loss : 0.027785
[23:38:25.452] iteration 7274 : model1 loss : 0.434204 model2 loss : 0.023734
[23:38:25.630] iteration 7275 : model1 loss : 0.437758 model2 loss : 0.025968
[23:38:25.806] iteration 7276 : model1 loss : 0.439892 model2 loss : 0.027833
[23:38:25.980] iteration 7277 : model1 loss : 0.437478 model2 loss : 0.026304
[23:38:26.153] iteration 7278 : model1 loss : 0.432735 model2 loss : 0.021910
[23:38:26.333] iteration 7279 : model1 loss : 0.438954 model2 loss : 0.026478
[23:38:26.504] iteration 7280 : model1 loss : 0.438205 model2 loss : 0.025892
[23:38:26.680] iteration 7281 : model1 loss : 0.434452 model2 loss : 0.025176
[23:38:26.852] iteration 7282 : model1 loss : 0.436172 model2 loss : 0.023072
[23:38:27.029] iteration 7283 : model1 loss : 0.439562 model2 loss : 0.031777
[23:38:27.203] iteration 7284 : model1 loss : 0.435771 model2 loss : 0.026341
[23:38:27.379] iteration 7285 : model1 loss : 0.434660 model2 loss : 0.022874
[23:38:27.551] iteration 7286 : model1 loss : 0.441002 model2 loss : 0.027064
[23:38:27.724] iteration 7287 : model1 loss : 0.434844 model2 loss : 0.021823
[23:38:29.848] iteration 7288 : model1 loss : 0.436577 model2 loss : 0.023709
[23:38:30.019] iteration 7289 : model1 loss : 0.437637 model2 loss : 0.023697
[23:38:30.200] iteration 7290 : model1 loss : 0.440279 model2 loss : 0.026550
[23:38:30.370] iteration 7291 : model1 loss : 0.436345 model2 loss : 0.024097
[23:38:30.542] iteration 7292 : model1 loss : 0.436021 model2 loss : 0.023104
[23:38:30.714] iteration 7293 : model1 loss : 0.435792 model2 loss : 0.021335
[23:38:30.891] iteration 7294 : model1 loss : 0.436090 model2 loss : 0.024444
[23:38:31.062] iteration 7295 : model1 loss : 0.435329 model2 loss : 0.026965
[23:38:31.238] iteration 7296 : model1 loss : 0.436512 model2 loss : 0.021512
[23:38:31.409] iteration 7297 : model1 loss : 0.437991 model2 loss : 0.025453
[23:38:31.589] iteration 7298 : model1 loss : 0.435213 model2 loss : 0.025859
[23:38:31.762] iteration 7299 : model1 loss : 0.432555 model2 loss : 0.023104
[23:38:31.941] iteration 7300 : model1 loss : 0.439267 model2 loss : 0.024348
[23:38:32.112] iteration 7301 : model1 loss : 0.436321 model2 loss : 0.024019
[23:38:32.290] iteration 7302 : model1 loss : 0.440955 model2 loss : 0.025068
[23:38:32.463] iteration 7303 : model1 loss : 0.439533 model2 loss : 0.028514
[23:38:32.640] iteration 7304 : model1 loss : 0.439601 model2 loss : 0.025025
[23:38:32.814] iteration 7305 : model1 loss : 0.442140 model2 loss : 0.029762
[23:38:32.991] iteration 7306 : model1 loss : 0.437889 model2 loss : 0.026571
[23:38:33.160] iteration 7307 : model1 loss : 0.439761 model2 loss : 0.024601
[23:38:33.336] iteration 7308 : model1 loss : 0.439739 model2 loss : 0.033421
[23:38:35.460] iteration 7309 : model1 loss : 0.432256 model2 loss : 0.023928
[23:38:35.632] iteration 7310 : model1 loss : 0.437515 model2 loss : 0.023823
[23:38:35.810] iteration 7311 : model1 loss : 0.438743 model2 loss : 0.029146
[23:38:35.980] iteration 7312 : model1 loss : 0.435561 model2 loss : 0.026659
[23:38:36.156] iteration 7313 : model1 loss : 0.436721 model2 loss : 0.023686
[23:38:36.333] iteration 7314 : model1 loss : 0.434708 model2 loss : 0.020471
[23:38:36.507] iteration 7315 : model1 loss : 0.438444 model2 loss : 0.024900
[23:38:36.680] iteration 7316 : model1 loss : 0.435976 model2 loss : 0.024726
[23:38:36.860] iteration 7317 : model1 loss : 0.441704 model2 loss : 0.028101
[23:38:37.030] iteration 7318 : model1 loss : 0.438225 model2 loss : 0.022810
[23:38:37.207] iteration 7319 : model1 loss : 0.439166 model2 loss : 0.023139
[23:38:37.381] iteration 7320 : model1 loss : 0.435732 model2 loss : 0.023214
[23:38:37.561] iteration 7321 : model1 loss : 0.438402 model2 loss : 0.029676
[23:38:37.734] iteration 7322 : model1 loss : 0.438572 model2 loss : 0.026467
[23:38:37.912] iteration 7323 : model1 loss : 0.437856 model2 loss : 0.023641
[23:38:38.083] iteration 7324 : model1 loss : 0.437501 model2 loss : 0.023562
[23:38:38.260] iteration 7325 : model1 loss : 0.433085 model2 loss : 0.024291
[23:38:38.434] iteration 7326 : model1 loss : 0.438839 model2 loss : 0.026462
[23:38:38.614] iteration 7327 : model1 loss : 0.440099 model2 loss : 0.027464
[23:38:38.785] iteration 7328 : model1 loss : 0.436013 model2 loss : 0.023244
[23:38:38.960] iteration 7329 : model1 loss : 0.440559 model2 loss : 0.027484
[23:38:41.077] iteration 7330 : model1 loss : 0.438239 model2 loss : 0.024099
[23:38:41.254] iteration 7331 : model1 loss : 0.436912 model2 loss : 0.024716
[23:38:41.428] iteration 7332 : model1 loss : 0.438298 model2 loss : 0.024973
[23:38:41.602] iteration 7333 : model1 loss : 0.436750 model2 loss : 0.032464
[23:38:41.780] iteration 7334 : model1 loss : 0.439950 model2 loss : 0.026349
[23:38:41.953] iteration 7335 : model1 loss : 0.434379 model2 loss : 0.023178
[23:38:42.129] iteration 7336 : model1 loss : 0.437804 model2 loss : 0.024597
[23:38:42.302] iteration 7337 : model1 loss : 0.437077 model2 loss : 0.026303
[23:38:42.481] iteration 7338 : model1 loss : 0.439742 model2 loss : 0.022905
[23:38:42.655] iteration 7339 : model1 loss : 0.435832 model2 loss : 0.022438
[23:38:42.832] iteration 7340 : model1 loss : 0.437097 model2 loss : 0.025980
[23:38:43.003] iteration 7341 : model1 loss : 0.436426 model2 loss : 0.023844
[23:38:43.177] iteration 7342 : model1 loss : 0.433670 model2 loss : 0.024015
[23:38:43.356] iteration 7343 : model1 loss : 0.436040 model2 loss : 0.026205
[23:38:43.535] iteration 7344 : model1 loss : 0.435974 model2 loss : 0.025676
[23:38:43.707] iteration 7345 : model1 loss : 0.433966 model2 loss : 0.023201
[23:38:43.881] iteration 7346 : model1 loss : 0.435042 model2 loss : 0.023645
[23:38:44.052] iteration 7347 : model1 loss : 0.441363 model2 loss : 0.024094
[23:38:44.229] iteration 7348 : model1 loss : 0.438538 model2 loss : 0.027705
[23:38:44.400] iteration 7349 : model1 loss : 0.436837 model2 loss : 0.025430
[23:38:44.576] iteration 7350 : model1 loss : 0.442473 model2 loss : 0.025499
[23:38:46.721] iteration 7351 : model1 loss : 0.436018 model2 loss : 0.022370
[23:38:46.897] iteration 7352 : model1 loss : 0.435737 model2 loss : 0.020310
[23:38:47.076] iteration 7353 : model1 loss : 0.438660 model2 loss : 0.025479
[23:38:47.248] iteration 7354 : model1 loss : 0.436146 model2 loss : 0.026627
[23:38:47.427] iteration 7355 : model1 loss : 0.439745 model2 loss : 0.024240
[23:38:47.604] iteration 7356 : model1 loss : 0.441600 model2 loss : 0.026106
[23:38:47.782] iteration 7357 : model1 loss : 0.436846 model2 loss : 0.023251
[23:38:47.953] iteration 7358 : model1 loss : 0.435179 model2 loss : 0.025036
[23:38:48.131] iteration 7359 : model1 loss : 0.438245 model2 loss : 0.021984
[23:38:48.305] iteration 7360 : model1 loss : 0.433323 model2 loss : 0.023058
[23:38:48.481] iteration 7361 : model1 loss : 0.432956 model2 loss : 0.024365
[23:38:48.651] iteration 7362 : model1 loss : 0.438487 model2 loss : 0.027884
[23:38:48.827] iteration 7363 : model1 loss : 0.434985 model2 loss : 0.022445
[23:38:48.998] iteration 7364 : model1 loss : 0.436870 model2 loss : 0.024968
[23:38:49.172] iteration 7365 : model1 loss : 0.439916 model2 loss : 0.030193
[23:38:49.349] iteration 7366 : model1 loss : 0.434214 model2 loss : 0.024037
[23:38:49.531] iteration 7367 : model1 loss : 0.435537 model2 loss : 0.022319
[23:38:49.702] iteration 7368 : model1 loss : 0.439624 model2 loss : 0.027122
[23:38:49.880] iteration 7369 : model1 loss : 0.443408 model2 loss : 0.026558
[23:38:50.050] iteration 7370 : model1 loss : 0.432349 model2 loss : 0.022301
[23:38:50.225] iteration 7371 : model1 loss : 0.438743 model2 loss : 0.025437
[23:38:52.338] iteration 7372 : model1 loss : 0.433939 model2 loss : 0.022250
[23:38:52.513] iteration 7373 : model1 loss : 0.434821 model2 loss : 0.023066
[23:38:52.693] iteration 7374 : model1 loss : 0.435332 model2 loss : 0.023171
[23:38:52.866] iteration 7375 : model1 loss : 0.441113 model2 loss : 0.024870
[23:38:53.040] iteration 7376 : model1 loss : 0.441397 model2 loss : 0.025674
[23:38:53.212] iteration 7377 : model1 loss : 0.444668 model2 loss : 0.028697
[23:38:53.390] iteration 7378 : model1 loss : 0.435047 model2 loss : 0.021362
[23:38:53.562] iteration 7379 : model1 loss : 0.438015 model2 loss : 0.024127
[23:38:53.738] iteration 7380 : model1 loss : 0.438188 model2 loss : 0.027025
[23:38:53.910] iteration 7381 : model1 loss : 0.435491 model2 loss : 0.024230
[23:38:54.086] iteration 7382 : model1 loss : 0.440703 model2 loss : 0.026947
[23:38:54.259] iteration 7383 : model1 loss : 0.436711 model2 loss : 0.024601
[23:38:54.434] iteration 7384 : model1 loss : 0.437182 model2 loss : 0.023108
[23:38:54.609] iteration 7385 : model1 loss : 0.431756 model2 loss : 0.022972
[23:38:54.790] iteration 7386 : model1 loss : 0.437458 model2 loss : 0.025612
[23:38:54.961] iteration 7387 : model1 loss : 0.438605 model2 loss : 0.026753
[23:38:55.134] iteration 7388 : model1 loss : 0.436899 model2 loss : 0.024545
[23:38:55.310] iteration 7389 : model1 loss : 0.437422 model2 loss : 0.028011
[23:38:55.485] iteration 7390 : model1 loss : 0.437924 model2 loss : 0.025570
[23:38:55.656] iteration 7391 : model1 loss : 0.438863 model2 loss : 0.025329
[23:38:55.830] iteration 7392 : model1 loss : 0.433896 model2 loss : 0.024929
[23:38:57.931] iteration 7393 : model1 loss : 0.435128 model2 loss : 0.022646
[23:38:58.106] iteration 7394 : model1 loss : 0.433836 model2 loss : 0.022554
[23:38:58.286] iteration 7395 : model1 loss : 0.434217 model2 loss : 0.025563
[23:38:58.458] iteration 7396 : model1 loss : 0.437181 model2 loss : 0.024326
[23:38:58.635] iteration 7397 : model1 loss : 0.434460 model2 loss : 0.021026
[23:38:58.809] iteration 7398 : model1 loss : 0.438399 model2 loss : 0.024436
[23:38:58.983] iteration 7399 : model1 loss : 0.432675 model2 loss : 0.019635
[23:38:59.153] iteration 7400 : model1 loss : 0.439607 model2 loss : 0.025746
[23:38:59.332] iteration 7401 : model1 loss : 0.444106 model2 loss : 0.030899
[23:38:59.505] iteration 7402 : model1 loss : 0.435704 model2 loss : 0.022328
[23:38:59.681] iteration 7403 : model1 loss : 0.434901 model2 loss : 0.023251
[23:38:59.855] iteration 7404 : model1 loss : 0.438950 model2 loss : 0.028082
[23:39:00.032] iteration 7405 : model1 loss : 0.436738 model2 loss : 0.022334
[23:39:00.207] iteration 7406 : model1 loss : 0.436894 model2 loss : 0.021396
[23:39:00.388] iteration 7407 : model1 loss : 0.437032 model2 loss : 0.028392
[23:39:00.558] iteration 7408 : model1 loss : 0.436738 model2 loss : 0.025242
[23:39:00.736] iteration 7409 : model1 loss : 0.441078 model2 loss : 0.024879
[23:39:00.907] iteration 7410 : model1 loss : 0.440016 model2 loss : 0.026595
[23:39:01.080] iteration 7411 : model1 loss : 0.434383 model2 loss : 0.019410
[23:39:01.252] iteration 7412 : model1 loss : 0.442586 model2 loss : 0.029443
[23:39:01.427] iteration 7413 : model1 loss : 0.438601 model2 loss : 0.024520
[23:39:03.571] iteration 7414 : model1 loss : 0.437887 model2 loss : 0.024955
[23:39:03.743] iteration 7415 : model1 loss : 0.441692 model2 loss : 0.024717
[23:39:03.924] iteration 7416 : model1 loss : 0.437725 model2 loss : 0.025843
[23:39:04.095] iteration 7417 : model1 loss : 0.438332 model2 loss : 0.027859
[23:39:04.273] iteration 7418 : model1 loss : 0.434625 model2 loss : 0.023704
[23:39:04.444] iteration 7419 : model1 loss : 0.435165 model2 loss : 0.025029
[23:39:04.622] iteration 7420 : model1 loss : 0.433547 model2 loss : 0.023182
[23:39:04.794] iteration 7421 : model1 loss : 0.438793 model2 loss : 0.026759
[23:39:04.970] iteration 7422 : model1 loss : 0.437227 model2 loss : 0.025813
[23:39:05.140] iteration 7423 : model1 loss : 0.436479 model2 loss : 0.022254
[23:39:05.322] iteration 7424 : model1 loss : 0.441477 model2 loss : 0.027126
[23:39:05.494] iteration 7425 : model1 loss : 0.440327 model2 loss : 0.024364
[23:39:05.668] iteration 7426 : model1 loss : 0.439423 model2 loss : 0.021976
[23:39:05.842] iteration 7427 : model1 loss : 0.437334 model2 loss : 0.025537
[23:39:06.019] iteration 7428 : model1 loss : 0.438442 model2 loss : 0.024125
[23:39:06.190] iteration 7429 : model1 loss : 0.434670 model2 loss : 0.022734
[23:39:06.368] iteration 7430 : model1 loss : 0.437406 model2 loss : 0.025001
[23:39:06.539] iteration 7431 : model1 loss : 0.435959 model2 loss : 0.024532
[23:39:06.713] iteration 7432 : model1 loss : 0.440426 model2 loss : 0.025288
[23:39:06.886] iteration 7433 : model1 loss : 0.437071 model2 loss : 0.022351
[23:39:07.060] iteration 7434 : model1 loss : 0.437243 model2 loss : 0.022804
[23:39:09.194] iteration 7435 : model1 loss : 0.437495 model2 loss : 0.024616
[23:39:09.373] iteration 7436 : model1 loss : 0.435210 model2 loss : 0.022260
[23:39:09.547] iteration 7437 : model1 loss : 0.436884 model2 loss : 0.026772
[23:39:09.717] iteration 7438 : model1 loss : 0.433520 model2 loss : 0.021964
[23:39:09.895] iteration 7439 : model1 loss : 0.434944 model2 loss : 0.021333
[23:39:10.065] iteration 7440 : model1 loss : 0.438161 model2 loss : 0.025658
[23:39:10.239] iteration 7441 : model1 loss : 0.435185 model2 loss : 0.023252
[23:39:10.410] iteration 7442 : model1 loss : 0.439252 model2 loss : 0.027787
[23:39:10.586] iteration 7443 : model1 loss : 0.439499 model2 loss : 0.026222
[23:39:10.758] iteration 7444 : model1 loss : 0.439689 model2 loss : 0.027583
[23:39:10.937] iteration 7445 : model1 loss : 0.437895 model2 loss : 0.023661
[23:39:11.109] iteration 7446 : model1 loss : 0.435960 model2 loss : 0.025069
[23:39:11.285] iteration 7447 : model1 loss : 0.438502 model2 loss : 0.023221
[23:39:11.458] iteration 7448 : model1 loss : 0.445307 model2 loss : 0.025615
[23:39:11.635] iteration 7449 : model1 loss : 0.436861 model2 loss : 0.024103
[23:39:11.808] iteration 7450 : model1 loss : 0.436789 model2 loss : 0.022741
[23:39:11.982] iteration 7451 : model1 loss : 0.436139 model2 loss : 0.024691
[23:39:12.155] iteration 7452 : model1 loss : 0.438674 model2 loss : 0.024327
[23:39:12.333] iteration 7453 : model1 loss : 0.437572 model2 loss : 0.024751
[23:39:12.504] iteration 7454 : model1 loss : 0.434311 model2 loss : 0.023834
[23:39:12.676] iteration 7455 : model1 loss : 0.437868 model2 loss : 0.025681
[23:39:14.796] iteration 7456 : model1 loss : 0.439647 model2 loss : 0.033703
[23:39:14.974] iteration 7457 : model1 loss : 0.441596 model2 loss : 0.026266
[23:39:15.150] iteration 7458 : model1 loss : 0.436243 model2 loss : 0.024137
[23:39:15.327] iteration 7459 : model1 loss : 0.440690 model2 loss : 0.026195
[23:39:15.509] iteration 7460 : model1 loss : 0.435497 model2 loss : 0.020802
[23:39:15.683] iteration 7461 : model1 loss : 0.436358 model2 loss : 0.024839
[23:39:15.862] iteration 7462 : model1 loss : 0.437703 model2 loss : 0.021594
[23:39:16.033] iteration 7463 : model1 loss : 0.437076 model2 loss : 0.024420
[23:39:16.207] iteration 7464 : model1 loss : 0.439033 model2 loss : 0.025452
[23:39:16.380] iteration 7465 : model1 loss : 0.437077 model2 loss : 0.024306
[23:39:16.555] iteration 7466 : model1 loss : 0.436337 model2 loss : 0.026257
[23:39:16.727] iteration 7467 : model1 loss : 0.436594 model2 loss : 0.024215
[23:39:16.903] iteration 7468 : model1 loss : 0.432745 model2 loss : 0.020948
[23:39:17.077] iteration 7469 : model1 loss : 0.434701 model2 loss : 0.026187
[23:39:17.255] iteration 7470 : model1 loss : 0.435113 model2 loss : 0.021814
[23:39:17.432] iteration 7471 : model1 loss : 0.437432 model2 loss : 0.024769
[23:39:17.614] iteration 7472 : model1 loss : 0.438827 model2 loss : 0.023914
[23:39:17.784] iteration 7473 : model1 loss : 0.437936 model2 loss : 0.024386
[23:39:17.961] iteration 7474 : model1 loss : 0.437626 model2 loss : 0.025213
[23:39:18.132] iteration 7475 : model1 loss : 0.437974 model2 loss : 0.025282
[23:39:18.309] iteration 7476 : model1 loss : 0.440083 model2 loss : 0.025431
[23:39:20.467] iteration 7477 : model1 loss : 0.435543 model2 loss : 0.025661
[23:39:20.640] iteration 7478 : model1 loss : 0.437540 model2 loss : 0.025126
[23:39:20.820] iteration 7479 : model1 loss : 0.435602 model2 loss : 0.024713
[23:39:20.992] iteration 7480 : model1 loss : 0.437457 model2 loss : 0.022974
[23:39:21.167] iteration 7481 : model1 loss : 0.437633 model2 loss : 0.023516
[23:39:21.342] iteration 7482 : model1 loss : 0.437830 model2 loss : 0.026221
[23:39:21.519] iteration 7483 : model1 loss : 0.436766 model2 loss : 0.023956
[23:39:21.690] iteration 7484 : model1 loss : 0.436794 model2 loss : 0.022921
[23:39:21.866] iteration 7485 : model1 loss : 0.437619 model2 loss : 0.025807
[23:39:22.037] iteration 7486 : model1 loss : 0.433340 model2 loss : 0.023874
[23:39:22.213] iteration 7487 : model1 loss : 0.438485 model2 loss : 0.026057
[23:39:22.387] iteration 7488 : model1 loss : 0.433976 model2 loss : 0.023783
[23:39:22.565] iteration 7489 : model1 loss : 0.436401 model2 loss : 0.024887
[23:39:22.734] iteration 7490 : model1 loss : 0.440940 model2 loss : 0.026047
[23:39:22.912] iteration 7491 : model1 loss : 0.439322 model2 loss : 0.026286
[23:39:23.083] iteration 7492 : model1 loss : 0.439533 model2 loss : 0.023103
[23:39:23.259] iteration 7493 : model1 loss : 0.437231 model2 loss : 0.026706
[23:39:23.433] iteration 7494 : model1 loss : 0.442533 model2 loss : 0.033597
[23:39:23.613] iteration 7495 : model1 loss : 0.443829 model2 loss : 0.022723
[23:39:23.785] iteration 7496 : model1 loss : 0.436447 model2 loss : 0.027397
[23:39:23.960] iteration 7497 : model1 loss : 0.441463 model2 loss : 0.027164
[23:39:26.088] iteration 7498 : model1 loss : 0.435346 model2 loss : 0.022164
[23:39:26.263] iteration 7499 : model1 loss : 0.435759 model2 loss : 0.024057
[23:39:26.442] iteration 7500 : model1 loss : 0.439618 model2 loss : 0.020467
[23:39:26.616] iteration 7501 : model1 loss : 0.441233 model2 loss : 0.029572
[23:39:26.795] iteration 7502 : model1 loss : 0.438594 model2 loss : 0.023067
[23:39:26.966] iteration 7503 : model1 loss : 0.436401 model2 loss : 0.022089
[23:39:27.141] iteration 7504 : model1 loss : 0.443400 model2 loss : 0.026666
[23:39:27.318] iteration 7505 : model1 loss : 0.437887 model2 loss : 0.026837
[23:39:27.499] iteration 7506 : model1 loss : 0.436652 model2 loss : 0.024938
[23:39:27.672] iteration 7507 : model1 loss : 0.438848 model2 loss : 0.023497
[23:39:27.851] iteration 7508 : model1 loss : 0.437846 model2 loss : 0.024580
[23:39:28.022] iteration 7509 : model1 loss : 0.440839 model2 loss : 0.029478
[23:39:28.198] iteration 7510 : model1 loss : 0.438951 model2 loss : 0.025509
[23:39:28.371] iteration 7511 : model1 loss : 0.436624 model2 loss : 0.024029
[23:39:28.546] iteration 7512 : model1 loss : 0.437020 model2 loss : 0.028998
[23:39:28.717] iteration 7513 : model1 loss : 0.437539 model2 loss : 0.025482
[23:39:28.895] iteration 7514 : model1 loss : 0.437762 model2 loss : 0.026462
[23:39:29.066] iteration 7515 : model1 loss : 0.438772 model2 loss : 0.028736
[23:39:29.240] iteration 7516 : model1 loss : 0.437349 model2 loss : 0.026460
[23:39:29.412] iteration 7517 : model1 loss : 0.436836 model2 loss : 0.025071
[23:39:29.591] iteration 7518 : model1 loss : 0.435943 model2 loss : 0.027499
[23:39:31.723] iteration 7519 : model1 loss : 0.438731 model2 loss : 0.027056
[23:39:31.905] iteration 7520 : model1 loss : 0.433756 model2 loss : 0.020863
[23:39:32.081] iteration 7521 : model1 loss : 0.438162 model2 loss : 0.022332
[23:39:32.253] iteration 7522 : model1 loss : 0.441693 model2 loss : 0.028098
[23:39:32.436] iteration 7523 : model1 loss : 0.432828 model2 loss : 0.024001
[23:39:32.610] iteration 7524 : model1 loss : 0.438280 model2 loss : 0.024808
[23:39:32.787] iteration 7525 : model1 loss : 0.439563 model2 loss : 0.027011
[23:39:32.960] iteration 7526 : model1 loss : 0.440686 model2 loss : 0.031111
[23:39:33.136] iteration 7527 : model1 loss : 0.441643 model2 loss : 0.030865
[23:39:33.313] iteration 7528 : model1 loss : 0.437968 model2 loss : 0.023930
[23:39:33.487] iteration 7529 : model1 loss : 0.438153 model2 loss : 0.024431
[23:39:33.657] iteration 7530 : model1 loss : 0.436806 model2 loss : 0.025094
[23:39:33.843] iteration 7531 : model1 loss : 0.435569 model2 loss : 0.022851
[23:39:34.015] iteration 7532 : model1 loss : 0.437974 model2 loss : 0.023022
[23:39:34.191] iteration 7533 : model1 loss : 0.438424 model2 loss : 0.028795
[23:39:34.365] iteration 7534 : model1 loss : 0.437907 model2 loss : 0.023611
[23:39:34.542] iteration 7535 : model1 loss : 0.437283 model2 loss : 0.024439
[23:39:34.712] iteration 7536 : model1 loss : 0.441585 model2 loss : 0.027542
[23:39:34.889] iteration 7537 : model1 loss : 0.435370 model2 loss : 0.022471
[23:39:35.057] iteration 7538 : model1 loss : 0.430925 model2 loss : 0.022486
[23:39:35.231] iteration 7539 : model1 loss : 0.437684 model2 loss : 0.030160
[23:39:37.413] iteration 7540 : model1 loss : 0.438641 model2 loss : 0.026583
[23:39:37.589] iteration 7541 : model1 loss : 0.439863 model2 loss : 0.025677
[23:39:37.768] iteration 7542 : model1 loss : 0.433216 model2 loss : 0.023273
[23:39:37.943] iteration 7543 : model1 loss : 0.432929 model2 loss : 0.027708
[23:39:38.121] iteration 7544 : model1 loss : 0.439441 model2 loss : 0.022292
[23:39:38.293] iteration 7545 : model1 loss : 0.439109 model2 loss : 0.027868
[23:39:38.469] iteration 7546 : model1 loss : 0.438653 model2 loss : 0.026651
[23:39:38.641] iteration 7547 : model1 loss : 0.436043 model2 loss : 0.023199
[23:39:38.819] iteration 7548 : model1 loss : 0.435278 model2 loss : 0.026060
[23:39:38.990] iteration 7549 : model1 loss : 0.435672 model2 loss : 0.027694
[23:39:39.166] iteration 7550 : model1 loss : 0.436517 model2 loss : 0.021941
[23:39:39.341] iteration 7551 : model1 loss : 0.442036 model2 loss : 0.025893
[23:39:39.516] iteration 7552 : model1 loss : 0.435391 model2 loss : 0.024004
[23:39:39.689] iteration 7553 : model1 loss : 0.435049 model2 loss : 0.023654
[23:39:39.867] iteration 7554 : model1 loss : 0.435863 model2 loss : 0.024770
[23:39:40.037] iteration 7555 : model1 loss : 0.442145 model2 loss : 0.027338
[23:39:40.214] iteration 7556 : model1 loss : 0.434733 model2 loss : 0.023391
[23:39:40.388] iteration 7557 : model1 loss : 0.437627 model2 loss : 0.026466
[23:39:40.563] iteration 7558 : model1 loss : 0.439811 model2 loss : 0.025973
[23:39:40.732] iteration 7559 : model1 loss : 0.438435 model2 loss : 0.025144
[23:39:40.906] iteration 7560 : model1 loss : 0.439040 model2 loss : 0.023888
[23:39:43.023] iteration 7561 : model1 loss : 0.437376 model2 loss : 0.021238
[23:39:43.194] iteration 7562 : model1 loss : 0.435281 model2 loss : 0.024898
[23:39:43.373] iteration 7563 : model1 loss : 0.438282 model2 loss : 0.027149
[23:39:43.543] iteration 7564 : model1 loss : 0.442960 model2 loss : 0.026976
[23:39:43.719] iteration 7565 : model1 loss : 0.436583 model2 loss : 0.022468
[23:39:43.892] iteration 7566 : model1 loss : 0.435463 model2 loss : 0.025855
[23:39:44.068] iteration 7567 : model1 loss : 0.440667 model2 loss : 0.025073
[23:39:44.239] iteration 7568 : model1 loss : 0.436107 model2 loss : 0.023749
[23:39:44.414] iteration 7569 : model1 loss : 0.441599 model2 loss : 0.028918
[23:39:44.589] iteration 7570 : model1 loss : 0.438208 model2 loss : 0.024676
[23:39:44.766] iteration 7571 : model1 loss : 0.438377 model2 loss : 0.024908
[23:39:44.941] iteration 7572 : model1 loss : 0.439147 model2 loss : 0.029127
[23:39:45.117] iteration 7573 : model1 loss : 0.433183 model2 loss : 0.021102
[23:39:45.287] iteration 7574 : model1 loss : 0.434087 model2 loss : 0.025155
[23:39:45.465] iteration 7575 : model1 loss : 0.438645 model2 loss : 0.025497
[23:39:45.639] iteration 7576 : model1 loss : 0.436492 model2 loss : 0.025123
[23:39:45.816] iteration 7577 : model1 loss : 0.435172 model2 loss : 0.026101
[23:39:45.989] iteration 7578 : model1 loss : 0.437373 model2 loss : 0.023871
[23:39:46.162] iteration 7579 : model1 loss : 0.439833 model2 loss : 0.022767
[23:39:46.337] iteration 7580 : model1 loss : 0.437676 model2 loss : 0.021206
[23:39:46.511] iteration 7581 : model1 loss : 0.438009 model2 loss : 0.027283
[23:39:48.621] iteration 7582 : model1 loss : 0.440238 model2 loss : 0.023823
[23:39:48.792] iteration 7583 : model1 loss : 0.434759 model2 loss : 0.022749
[23:39:48.975] iteration 7584 : model1 loss : 0.436113 model2 loss : 0.027565
[23:39:49.145] iteration 7585 : model1 loss : 0.437778 model2 loss : 0.026139
[23:39:49.326] iteration 7586 : model1 loss : 0.438084 model2 loss : 0.023833
[23:39:49.501] iteration 7587 : model1 loss : 0.433244 model2 loss : 0.021835
[23:39:49.676] iteration 7588 : model1 loss : 0.433440 model2 loss : 0.024006
[23:39:49.848] iteration 7589 : model1 loss : 0.437122 model2 loss : 0.023301
[23:39:50.026] iteration 7590 : model1 loss : 0.438905 model2 loss : 0.026319
[23:39:50.195] iteration 7591 : model1 loss : 0.441657 model2 loss : 0.032543
[23:39:50.373] iteration 7592 : model1 loss : 0.434299 model2 loss : 0.023658
[23:39:50.544] iteration 7593 : model1 loss : 0.437099 model2 loss : 0.021710
[23:39:50.720] iteration 7594 : model1 loss : 0.435579 model2 loss : 0.023528
[23:39:50.893] iteration 7595 : model1 loss : 0.436136 model2 loss : 0.022194
[23:39:51.070] iteration 7596 : model1 loss : 0.441619 model2 loss : 0.030515
[23:39:51.240] iteration 7597 : model1 loss : 0.441161 model2 loss : 0.025578
[23:39:51.416] iteration 7598 : model1 loss : 0.436237 model2 loss : 0.021435
[23:39:51.588] iteration 7599 : model1 loss : 0.435407 model2 loss : 0.023657
[23:39:51.769] iteration 7600 : model1 loss : 0.437621 model2 loss : 0.023155
[23:39:51.943] iteration 7601 : model1 loss : 0.436853 model2 loss : 0.025580
[23:39:52.119] iteration 7602 : model1 loss : 0.441216 model2 loss : 0.024792
[23:39:54.252] iteration 7603 : model1 loss : 0.435968 model2 loss : 0.024304
[23:39:54.433] iteration 7604 : model1 loss : 0.440165 model2 loss : 0.043288
[23:39:54.610] iteration 7605 : model1 loss : 0.435922 model2 loss : 0.023332
[23:39:54.780] iteration 7606 : model1 loss : 0.437316 model2 loss : 0.025974
[23:39:54.958] iteration 7607 : model1 loss : 0.436922 model2 loss : 0.026530
[23:39:55.128] iteration 7608 : model1 loss : 0.441603 model2 loss : 0.024144
[23:39:55.308] iteration 7609 : model1 loss : 0.436096 model2 loss : 0.025683
[23:39:55.481] iteration 7610 : model1 loss : 0.437255 model2 loss : 0.025203
[23:39:55.661] iteration 7611 : model1 loss : 0.439551 model2 loss : 0.027356
[23:39:55.834] iteration 7612 : model1 loss : 0.439889 model2 loss : 0.032642
[23:39:56.011] iteration 7613 : model1 loss : 0.441149 model2 loss : 0.035128
[23:39:56.180] iteration 7614 : model1 loss : 0.439866 model2 loss : 0.026414
[23:39:56.361] iteration 7615 : model1 loss : 0.438019 model2 loss : 0.027567
[23:39:56.535] iteration 7616 : model1 loss : 0.436537 model2 loss : 0.023077
[23:39:56.710] iteration 7617 : model1 loss : 0.440676 model2 loss : 0.025067
[23:39:56.885] iteration 7618 : model1 loss : 0.437083 model2 loss : 0.027704
[23:39:57.060] iteration 7619 : model1 loss : 0.433744 model2 loss : 0.025259
[23:39:57.229] iteration 7620 : model1 loss : 0.437190 model2 loss : 0.029340
[23:39:57.410] iteration 7621 : model1 loss : 0.433994 model2 loss : 0.024637
[23:39:57.578] iteration 7622 : model1 loss : 0.436430 model2 loss : 0.021765
[23:39:57.751] iteration 7623 : model1 loss : 0.433670 model2 loss : 0.022109
[23:39:59.903] iteration 7624 : model1 loss : 0.433790 model2 loss : 0.022515
[23:40:00.078] iteration 7625 : model1 loss : 0.436539 model2 loss : 0.027761
[23:40:00.256] iteration 7626 : model1 loss : 0.439465 model2 loss : 0.027537
[23:40:00.431] iteration 7627 : model1 loss : 0.437428 model2 loss : 0.025286
[23:40:00.608] iteration 7628 : model1 loss : 0.434042 model2 loss : 0.021947
[23:40:00.779] iteration 7629 : model1 loss : 0.434255 model2 loss : 0.023428
[23:40:00.955] iteration 7630 : model1 loss : 0.436777 model2 loss : 0.028441
[23:40:01.124] iteration 7631 : model1 loss : 0.437620 model2 loss : 0.028884
[23:40:01.301] iteration 7632 : model1 loss : 0.437139 model2 loss : 0.024643
[23:40:01.475] iteration 7633 : model1 loss : 0.436397 model2 loss : 0.024233
[23:40:01.650] iteration 7634 : model1 loss : 0.434542 model2 loss : 0.022866
[23:40:01.820] iteration 7635 : model1 loss : 0.443199 model2 loss : 0.026402
[23:40:01.999] iteration 7636 : model1 loss : 0.437003 model2 loss : 0.024508
[23:40:02.170] iteration 7637 : model1 loss : 0.439206 model2 loss : 0.026666
[23:40:02.350] iteration 7638 : model1 loss : 0.436065 model2 loss : 0.024356
[23:40:02.526] iteration 7639 : model1 loss : 0.436908 model2 loss : 0.025565
[23:40:02.699] iteration 7640 : model1 loss : 0.439766 model2 loss : 0.025005
[23:40:02.874] iteration 7641 : model1 loss : 0.438103 model2 loss : 0.026740
[23:40:03.048] iteration 7642 : model1 loss : 0.437555 model2 loss : 0.025283
[23:40:03.218] iteration 7643 : model1 loss : 0.438992 model2 loss : 0.023807
[23:40:03.395] iteration 7644 : model1 loss : 0.438637 model2 loss : 0.024261
[23:40:05.547] iteration 7645 : model1 loss : 0.437548 model2 loss : 0.025808
[23:40:05.719] iteration 7646 : model1 loss : 0.436683 model2 loss : 0.026114
[23:40:05.898] iteration 7647 : model1 loss : 0.434077 model2 loss : 0.023215
[23:40:06.074] iteration 7648 : model1 loss : 0.436848 model2 loss : 0.025599
[23:40:06.249] iteration 7649 : model1 loss : 0.434874 model2 loss : 0.026196
[23:40:06.423] iteration 7650 : model1 loss : 0.435559 model2 loss : 0.025635
[23:40:06.603] iteration 7651 : model1 loss : 0.437275 model2 loss : 0.025002
[23:40:06.774] iteration 7652 : model1 loss : 0.442184 model2 loss : 0.027413
[23:40:06.951] iteration 7653 : model1 loss : 0.436934 model2 loss : 0.022618
[23:40:07.122] iteration 7654 : model1 loss : 0.438429 model2 loss : 0.023838
[23:40:07.301] iteration 7655 : model1 loss : 0.435095 model2 loss : 0.022821
[23:40:07.481] iteration 7656 : model1 loss : 0.432818 model2 loss : 0.021673
[23:40:07.661] iteration 7657 : model1 loss : 0.435612 model2 loss : 0.024785
[23:40:07.831] iteration 7658 : model1 loss : 0.441660 model2 loss : 0.030360
[23:40:08.008] iteration 7659 : model1 loss : 0.435618 model2 loss : 0.022720
[23:40:08.179] iteration 7660 : model1 loss : 0.439749 model2 loss : 0.025478
[23:40:08.363] iteration 7661 : model1 loss : 0.443287 model2 loss : 0.029916
[23:40:08.536] iteration 7662 : model1 loss : 0.441188 model2 loss : 0.027484
[23:40:08.709] iteration 7663 : model1 loss : 0.434578 model2 loss : 0.024433
[23:40:08.880] iteration 7664 : model1 loss : 0.439908 model2 loss : 0.026722
[23:40:09.055] iteration 7665 : model1 loss : 0.437918 model2 loss : 0.023779
[23:40:11.171] iteration 7666 : model1 loss : 0.438447 model2 loss : 0.024398
[23:40:11.346] iteration 7667 : model1 loss : 0.440711 model2 loss : 0.025929
[23:40:11.524] iteration 7668 : model1 loss : 0.436113 model2 loss : 0.025003
[23:40:11.695] iteration 7669 : model1 loss : 0.436044 model2 loss : 0.021667
[23:40:11.875] iteration 7670 : model1 loss : 0.438031 model2 loss : 0.027219
[23:40:12.048] iteration 7671 : model1 loss : 0.429703 model2 loss : 0.023288
[23:40:12.222] iteration 7672 : model1 loss : 0.440380 model2 loss : 0.027321
[23:40:12.395] iteration 7673 : model1 loss : 0.437943 model2 loss : 0.023643
[23:40:12.571] iteration 7674 : model1 loss : 0.439003 model2 loss : 0.025624
[23:40:12.741] iteration 7675 : model1 loss : 0.440168 model2 loss : 0.024504
[23:40:12.919] iteration 7676 : model1 loss : 0.438615 model2 loss : 0.025012
[23:40:13.090] iteration 7677 : model1 loss : 0.434827 model2 loss : 0.023356
[23:40:13.263] iteration 7678 : model1 loss : 0.435834 model2 loss : 0.024126
[23:40:13.442] iteration 7679 : model1 loss : 0.436531 model2 loss : 0.023332
[23:40:13.622] iteration 7680 : model1 loss : 0.436175 model2 loss : 0.022684
[23:40:13.793] iteration 7681 : model1 loss : 0.436735 model2 loss : 0.025448
[23:40:13.969] iteration 7682 : model1 loss : 0.439310 model2 loss : 0.023075
[23:40:14.139] iteration 7683 : model1 loss : 0.436051 model2 loss : 0.025408
[23:40:14.317] iteration 7684 : model1 loss : 0.435788 model2 loss : 0.022710
[23:40:14.490] iteration 7685 : model1 loss : 0.441185 model2 loss : 0.027389
[23:40:14.665] iteration 7686 : model1 loss : 0.433944 model2 loss : 0.024976
[23:40:16.759] iteration 7687 : model1 loss : 0.438093 model2 loss : 0.023815
[23:40:16.933] iteration 7688 : model1 loss : 0.439358 model2 loss : 0.027366
[23:40:17.110] iteration 7689 : model1 loss : 0.432993 model2 loss : 0.023314
[23:40:17.280] iteration 7690 : model1 loss : 0.438114 model2 loss : 0.022902
[23:40:17.460] iteration 7691 : model1 loss : 0.433806 model2 loss : 0.022908
[23:40:17.635] iteration 7692 : model1 loss : 0.437942 model2 loss : 0.024521
[23:40:17.808] iteration 7693 : model1 loss : 0.430806 model2 loss : 0.021752
[23:40:17.980] iteration 7694 : model1 loss : 0.435234 model2 loss : 0.024582
[23:40:18.157] iteration 7695 : model1 loss : 0.432160 model2 loss : 0.023251
[23:40:18.329] iteration 7696 : model1 loss : 0.436051 model2 loss : 0.020044
[23:40:18.508] iteration 7697 : model1 loss : 0.432692 model2 loss : 0.021987
[23:40:18.683] iteration 7698 : model1 loss : 0.438456 model2 loss : 0.025868
[23:40:18.866] iteration 7699 : model1 loss : 0.441410 model2 loss : 0.026495
[23:40:19.039] iteration 7700 : model1 loss : 0.441132 model2 loss : 0.024531
[23:40:19.216] iteration 7701 : model1 loss : 0.440920 model2 loss : 0.026670
[23:40:19.388] iteration 7702 : model1 loss : 0.443719 model2 loss : 0.030502
[23:40:19.567] iteration 7703 : model1 loss : 0.438149 model2 loss : 0.021944
[23:40:19.739] iteration 7704 : model1 loss : 0.440795 model2 loss : 0.024339
[23:40:19.917] iteration 7705 : model1 loss : 0.439976 model2 loss : 0.031717
[23:40:20.086] iteration 7706 : model1 loss : 0.437432 model2 loss : 0.023232
[23:40:20.258] iteration 7707 : model1 loss : 0.439201 model2 loss : 0.027771
[23:40:22.359] iteration 7708 : model1 loss : 0.438643 model2 loss : 0.025981
[23:40:22.542] iteration 7709 : model1 loss : 0.435631 model2 loss : 0.023638
[23:40:22.718] iteration 7710 : model1 loss : 0.438266 model2 loss : 0.024857
[23:40:22.891] iteration 7711 : model1 loss : 0.435973 model2 loss : 0.022947
[23:40:23.068] iteration 7712 : model1 loss : 0.433789 model2 loss : 0.021386
[23:40:23.239] iteration 7713 : model1 loss : 0.437517 model2 loss : 0.025506
[23:40:23.417] iteration 7714 : model1 loss : 0.439222 model2 loss : 0.022082
[23:40:23.593] iteration 7715 : model1 loss : 0.439845 model2 loss : 0.025546
[23:40:23.770] iteration 7716 : model1 loss : 0.435304 model2 loss : 0.027335
[23:40:23.946] iteration 7717 : model1 loss : 0.441047 model2 loss : 0.024541
[23:40:24.128] iteration 7718 : model1 loss : 0.438638 model2 loss : 0.027537
[23:40:24.301] iteration 7719 : model1 loss : 0.437285 model2 loss : 0.022268
[23:40:24.477] iteration 7720 : model1 loss : 0.436638 model2 loss : 0.025968
[23:40:24.647] iteration 7721 : model1 loss : 0.434699 model2 loss : 0.023270
[23:40:24.824] iteration 7722 : model1 loss : 0.436738 model2 loss : 0.023938
[23:40:24.998] iteration 7723 : model1 loss : 0.438100 model2 loss : 0.022164
[23:40:25.173] iteration 7724 : model1 loss : 0.439901 model2 loss : 0.023968
[23:40:25.345] iteration 7725 : model1 loss : 0.440154 model2 loss : 0.024842
[23:40:25.523] iteration 7726 : model1 loss : 0.439499 model2 loss : 0.025158
[23:40:25.692] iteration 7727 : model1 loss : 0.436425 model2 loss : 0.023016
[23:40:25.867] iteration 7728 : model1 loss : 0.437590 model2 loss : 0.025033
[23:40:27.990] iteration 7729 : model1 loss : 0.435599 model2 loss : 0.022279
[23:40:28.165] iteration 7730 : model1 loss : 0.438385 model2 loss : 0.023553
[23:40:28.347] iteration 7731 : model1 loss : 0.437373 model2 loss : 0.025762
[23:40:28.519] iteration 7732 : model1 loss : 0.437612 model2 loss : 0.027164
[23:40:28.695] iteration 7733 : model1 loss : 0.439883 model2 loss : 0.025955
[23:40:28.865] iteration 7734 : model1 loss : 0.435129 model2 loss : 0.023667
[23:40:29.041] iteration 7735 : model1 loss : 0.439425 model2 loss : 0.022786
[23:40:29.209] iteration 7736 : model1 loss : 0.437916 model2 loss : 0.024784
[23:40:29.385] iteration 7737 : model1 loss : 0.431893 model2 loss : 0.022729
[23:40:29.560] iteration 7738 : model1 loss : 0.440983 model2 loss : 0.025082
[23:40:29.737] iteration 7739 : model1 loss : 0.439031 model2 loss : 0.021634
[23:40:29.910] iteration 7740 : model1 loss : 0.434853 model2 loss : 0.023388
[23:40:30.087] iteration 7741 : model1 loss : 0.437397 model2 loss : 0.023095
[23:40:30.257] iteration 7742 : model1 loss : 0.437436 model2 loss : 0.029746
[23:40:30.434] iteration 7743 : model1 loss : 0.433773 model2 loss : 0.022139
[23:40:30.608] iteration 7744 : model1 loss : 0.439048 model2 loss : 0.029894
[23:40:30.784] iteration 7745 : model1 loss : 0.436092 model2 loss : 0.025071
[23:40:30.960] iteration 7746 : model1 loss : 0.438312 model2 loss : 0.025209
[23:40:31.138] iteration 7747 : model1 loss : 0.440123 model2 loss : 0.023460
[23:40:31.308] iteration 7748 : model1 loss : 0.439637 model2 loss : 0.024970
[23:40:31.483] iteration 7749 : model1 loss : 0.438094 model2 loss : 0.022363
[23:40:33.640] iteration 7750 : model1 loss : 0.439051 model2 loss : 0.029562
[23:40:33.812] iteration 7751 : model1 loss : 0.436910 model2 loss : 0.024708
[23:40:33.994] iteration 7752 : model1 loss : 0.432930 model2 loss : 0.023608
[23:40:34.164] iteration 7753 : model1 loss : 0.441003 model2 loss : 0.027604
[23:40:34.340] iteration 7754 : model1 loss : 0.434808 model2 loss : 0.028218
[23:40:34.514] iteration 7755 : model1 loss : 0.436157 model2 loss : 0.028233
[23:40:34.692] iteration 7756 : model1 loss : 0.438704 model2 loss : 0.023912
[23:40:34.864] iteration 7757 : model1 loss : 0.439475 model2 loss : 0.026881
[23:40:35.040] iteration 7758 : model1 loss : 0.439510 model2 loss : 0.027710
[23:40:35.210] iteration 7759 : model1 loss : 0.437916 model2 loss : 0.022541
[23:40:35.387] iteration 7760 : model1 loss : 0.435746 model2 loss : 0.022264
[23:40:35.562] iteration 7761 : model1 loss : 0.440480 model2 loss : 0.030007
[23:40:35.736] iteration 7762 : model1 loss : 0.437290 model2 loss : 0.024678
[23:40:35.908] iteration 7763 : model1 loss : 0.434441 model2 loss : 0.025818
[23:40:36.087] iteration 7764 : model1 loss : 0.440315 model2 loss : 0.028709
[23:40:36.257] iteration 7765 : model1 loss : 0.439652 model2 loss : 0.024957
[23:40:36.435] iteration 7766 : model1 loss : 0.438149 model2 loss : 0.025686
[23:40:36.609] iteration 7767 : model1 loss : 0.436155 model2 loss : 0.024279
[23:40:36.783] iteration 7768 : model1 loss : 0.432905 model2 loss : 0.021958
[23:40:36.956] iteration 7769 : model1 loss : 0.437081 model2 loss : 0.026180
[23:40:37.131] iteration 7770 : model1 loss : 0.437446 model2 loss : 0.024338
[23:40:39.328] iteration 7771 : model1 loss : 0.437730 model2 loss : 0.029396
[23:40:39.506] iteration 7772 : model1 loss : 0.435228 model2 loss : 0.026634
[23:40:39.682] iteration 7773 : model1 loss : 0.433398 model2 loss : 0.023201
[23:40:39.852] iteration 7774 : model1 loss : 0.435851 model2 loss : 0.025986
[23:40:40.027] iteration 7775 : model1 loss : 0.434862 model2 loss : 0.021997
[23:40:40.198] iteration 7776 : model1 loss : 0.438418 model2 loss : 0.024929
[23:40:40.375] iteration 7777 : model1 loss : 0.439164 model2 loss : 0.024231
[23:40:40.548] iteration 7778 : model1 loss : 0.436774 model2 loss : 0.020461
[23:40:40.722] iteration 7779 : model1 loss : 0.437061 model2 loss : 0.023897
[23:40:40.893] iteration 7780 : model1 loss : 0.437864 model2 loss : 0.022428
[23:40:41.070] iteration 7781 : model1 loss : 0.438672 model2 loss : 0.024610
[23:40:41.240] iteration 7782 : model1 loss : 0.440582 model2 loss : 0.027337
[23:40:41.416] iteration 7783 : model1 loss : 0.436278 model2 loss : 0.026408
[23:40:41.593] iteration 7784 : model1 loss : 0.440937 model2 loss : 0.024257
[23:40:41.769] iteration 7785 : model1 loss : 0.437155 model2 loss : 0.026059
[23:40:41.944] iteration 7786 : model1 loss : 0.437052 model2 loss : 0.024638
[23:40:42.122] iteration 7787 : model1 loss : 0.438908 model2 loss : 0.025387
[23:40:42.292] iteration 7788 : model1 loss : 0.438672 model2 loss : 0.023629
[23:40:42.477] iteration 7789 : model1 loss : 0.437791 model2 loss : 0.027548
[23:40:42.645] iteration 7790 : model1 loss : 0.435066 model2 loss : 0.023360
[23:40:42.818] iteration 7791 : model1 loss : 0.435233 model2 loss : 0.025240
[23:40:44.960] iteration 7792 : model1 loss : 0.438512 model2 loss : 0.021356
[23:40:45.136] iteration 7793 : model1 loss : 0.439698 model2 loss : 0.025658
[23:40:45.312] iteration 7794 : model1 loss : 0.434240 model2 loss : 0.022114
[23:40:45.485] iteration 7795 : model1 loss : 0.437002 model2 loss : 0.025062
[23:40:45.663] iteration 7796 : model1 loss : 0.435409 model2 loss : 0.027889
[23:40:45.834] iteration 7797 : model1 loss : 0.443011 model2 loss : 0.029940
[23:40:46.013] iteration 7798 : model1 loss : 0.437466 model2 loss : 0.023149
[23:40:46.183] iteration 7799 : model1 loss : 0.438098 model2 loss : 0.023200
[23:40:46.361] iteration 7800 : model1 loss : 0.438351 model2 loss : 0.024608
[23:40:46.538] iteration 7801 : model1 loss : 0.439248 model2 loss : 0.028510
[23:40:46.714] iteration 7802 : model1 loss : 0.433041 model2 loss : 0.024958
[23:40:46.885] iteration 7803 : model1 loss : 0.437139 model2 loss : 0.024072
[23:40:47.062] iteration 7804 : model1 loss : 0.437737 model2 loss : 0.024486
[23:40:47.233] iteration 7805 : model1 loss : 0.436937 model2 loss : 0.021203
[23:40:47.410] iteration 7806 : model1 loss : 0.438368 model2 loss : 0.024132
[23:40:47.590] iteration 7807 : model1 loss : 0.435584 model2 loss : 0.025037
[23:40:47.765] iteration 7808 : model1 loss : 0.437049 model2 loss : 0.025599
[23:40:47.937] iteration 7809 : model1 loss : 0.434563 model2 loss : 0.023933
[23:40:48.117] iteration 7810 : model1 loss : 0.434605 model2 loss : 0.023488
[23:40:48.285] iteration 7811 : model1 loss : 0.437228 model2 loss : 0.025904
[23:40:48.461] iteration 7812 : model1 loss : 0.440593 model2 loss : 0.022411
[23:40:50.588] iteration 7813 : model1 loss : 0.435862 model2 loss : 0.022136
[23:40:50.763] iteration 7814 : model1 loss : 0.437223 model2 loss : 0.026182
[23:40:50.971] iteration 7815 : model1 loss : 0.433236 model2 loss : 0.022241
[23:40:51.142] iteration 7816 : model1 loss : 0.437632 model2 loss : 0.021690
[23:40:51.318] iteration 7817 : model1 loss : 0.434729 model2 loss : 0.021983
[23:40:51.491] iteration 7818 : model1 loss : 0.437365 model2 loss : 0.024215
[23:40:51.671] iteration 7819 : model1 loss : 0.437217 model2 loss : 0.025015
[23:40:51.840] iteration 7820 : model1 loss : 0.434468 model2 loss : 0.022103
[23:40:52.016] iteration 7821 : model1 loss : 0.437404 model2 loss : 0.026676
[23:40:52.189] iteration 7822 : model1 loss : 0.439894 model2 loss : 0.025923
[23:40:52.369] iteration 7823 : model1 loss : 0.438836 model2 loss : 0.022686
[23:40:52.543] iteration 7824 : model1 loss : 0.437917 model2 loss : 0.024504
[23:40:52.720] iteration 7825 : model1 loss : 0.438719 model2 loss : 0.025454
[23:40:52.893] iteration 7826 : model1 loss : 0.434696 model2 loss : 0.021134
[23:40:53.071] iteration 7827 : model1 loss : 0.439723 model2 loss : 0.028305
[23:40:53.241] iteration 7828 : model1 loss : 0.437060 model2 loss : 0.025794
[23:40:53.417] iteration 7829 : model1 loss : 0.438937 model2 loss : 0.026253
[23:40:53.595] iteration 7830 : model1 loss : 0.438938 model2 loss : 0.024586
[23:40:53.769] iteration 7831 : model1 loss : 0.437982 model2 loss : 0.027507
[23:40:53.942] iteration 7832 : model1 loss : 0.440776 model2 loss : 0.028250
[23:40:54.121] iteration 7833 : model1 loss : 0.436022 model2 loss : 0.020801
[23:40:56.279] iteration 7834 : model1 loss : 0.434609 model2 loss : 0.021614
[23:40:56.456] iteration 7835 : model1 loss : 0.437335 model2 loss : 0.025739
[23:40:56.637] iteration 7836 : model1 loss : 0.444622 model2 loss : 0.025382
[23:40:56.806] iteration 7837 : model1 loss : 0.441939 model2 loss : 0.027758
[23:40:56.982] iteration 7838 : model1 loss : 0.437751 model2 loss : 0.021613
[23:40:57.155] iteration 7839 : model1 loss : 0.438907 model2 loss : 0.028871
[23:40:57.334] iteration 7840 : model1 loss : 0.439046 model2 loss : 0.024539
[23:40:57.514] iteration 7841 : model1 loss : 0.435811 model2 loss : 0.022284
[23:40:57.705] iteration 7842 : model1 loss : 0.438806 model2 loss : 0.022841
[23:40:57.876] iteration 7843 : model1 loss : 0.432993 model2 loss : 0.023425
[23:40:58.050] iteration 7844 : model1 loss : 0.436079 model2 loss : 0.027987
[23:40:58.223] iteration 7845 : model1 loss : 0.439332 model2 loss : 0.026206
[23:40:58.400] iteration 7846 : model1 loss : 0.438168 model2 loss : 0.024790
[23:40:58.576] iteration 7847 : model1 loss : 0.436060 model2 loss : 0.023037
[23:40:58.751] iteration 7848 : model1 loss : 0.440648 model2 loss : 0.026747
[23:40:58.923] iteration 7849 : model1 loss : 0.440101 model2 loss : 0.029795
[23:40:59.098] iteration 7850 : model1 loss : 0.434947 model2 loss : 0.024416
[23:40:59.270] iteration 7851 : model1 loss : 0.436048 model2 loss : 0.028293
[23:40:59.451] iteration 7852 : model1 loss : 0.438245 model2 loss : 0.028491
[23:40:59.624] iteration 7853 : model1 loss : 0.437728 model2 loss : 0.025800
[23:40:59.798] iteration 7854 : model1 loss : 0.439123 model2 loss : 0.025655
[23:41:01.953] iteration 7855 : model1 loss : 0.440132 model2 loss : 0.025043
[23:41:02.129] iteration 7856 : model1 loss : 0.437144 model2 loss : 0.024007
[23:41:02.309] iteration 7857 : model1 loss : 0.433292 model2 loss : 0.022481
[23:41:02.488] iteration 7858 : model1 loss : 0.435469 model2 loss : 0.026283
[23:41:02.664] iteration 7859 : model1 loss : 0.437461 model2 loss : 0.023493
[23:41:02.836] iteration 7860 : model1 loss : 0.437725 model2 loss : 0.023572
[23:41:03.012] iteration 7861 : model1 loss : 0.434959 model2 loss : 0.026244
[23:41:03.183] iteration 7862 : model1 loss : 0.439870 model2 loss : 0.025172
[23:41:03.363] iteration 7863 : model1 loss : 0.437633 model2 loss : 0.024548
[23:41:03.538] iteration 7864 : model1 loss : 0.441779 model2 loss : 0.027245
[23:41:03.712] iteration 7865 : model1 loss : 0.443912 model2 loss : 0.027747
[23:41:03.884] iteration 7866 : model1 loss : 0.436071 model2 loss : 0.025485
[23:41:04.064] iteration 7867 : model1 loss : 0.439381 model2 loss : 0.028022
[23:41:04.235] iteration 7868 : model1 loss : 0.442586 model2 loss : 0.026552
[23:41:04.411] iteration 7869 : model1 loss : 0.440817 model2 loss : 0.026742
[23:41:04.589] iteration 7870 : model1 loss : 0.436440 model2 loss : 0.023962
[23:41:04.764] iteration 7871 : model1 loss : 0.437478 model2 loss : 0.024802
[23:41:04.941] iteration 7872 : model1 loss : 0.433334 model2 loss : 0.020754
[23:41:05.128] iteration 7873 : model1 loss : 0.435013 model2 loss : 0.024125
[23:41:05.298] iteration 7874 : model1 loss : 0.441412 model2 loss : 0.026829
[23:41:05.472] iteration 7875 : model1 loss : 0.437475 model2 loss : 0.027647
[23:41:07.609] iteration 7876 : model1 loss : 0.438688 model2 loss : 0.027261
[23:41:07.780] iteration 7877 : model1 loss : 0.435097 model2 loss : 0.021989
[23:41:07.962] iteration 7878 : model1 loss : 0.437544 model2 loss : 0.023826
[23:41:08.136] iteration 7879 : model1 loss : 0.437495 model2 loss : 0.021763
[23:41:08.315] iteration 7880 : model1 loss : 0.438164 model2 loss : 0.021937
[23:41:08.490] iteration 7881 : model1 loss : 0.434988 model2 loss : 0.023711
[23:41:08.665] iteration 7882 : model1 loss : 0.441759 model2 loss : 0.024646
[23:41:08.836] iteration 7883 : model1 loss : 0.439725 model2 loss : 0.026159
[23:41:09.012] iteration 7884 : model1 loss : 0.439009 model2 loss : 0.023018
[23:41:09.183] iteration 7885 : model1 loss : 0.439025 model2 loss : 0.021689
[23:41:09.359] iteration 7886 : model1 loss : 0.432403 model2 loss : 0.021692
[23:41:09.534] iteration 7887 : model1 loss : 0.436123 model2 loss : 0.022456
[23:41:09.708] iteration 7888 : model1 loss : 0.437993 model2 loss : 0.022669
[23:41:09.881] iteration 7889 : model1 loss : 0.439366 model2 loss : 0.025954
[23:41:10.058] iteration 7890 : model1 loss : 0.440609 model2 loss : 0.028532
[23:41:10.229] iteration 7891 : model1 loss : 0.439791 model2 loss : 0.022978
[23:41:10.405] iteration 7892 : model1 loss : 0.435263 model2 loss : 0.025650
[23:41:10.580] iteration 7893 : model1 loss : 0.435863 model2 loss : 0.024674
[23:41:10.755] iteration 7894 : model1 loss : 0.438593 model2 loss : 0.022257
[23:41:10.924] iteration 7895 : model1 loss : 0.436488 model2 loss : 0.024886
[23:41:11.098] iteration 7896 : model1 loss : 0.433190 model2 loss : 0.023765
[23:41:13.257] iteration 7897 : model1 loss : 0.441677 model2 loss : 0.024647
[23:41:13.431] iteration 7898 : model1 loss : 0.436547 model2 loss : 0.022987
[23:41:13.611] iteration 7899 : model1 loss : 0.432255 model2 loss : 0.023493
[23:41:13.783] iteration 7900 : model1 loss : 0.437993 model2 loss : 0.026376
[23:41:13.961] iteration 7901 : model1 loss : 0.439010 model2 loss : 0.027530
[23:41:14.135] iteration 7902 : model1 loss : 0.432623 model2 loss : 0.022959
[23:41:14.313] iteration 7903 : model1 loss : 0.438046 model2 loss : 0.020902
[23:41:14.487] iteration 7904 : model1 loss : 0.436251 model2 loss : 0.024817
[23:41:14.665] iteration 7905 : model1 loss : 0.431498 model2 loss : 0.025041
[23:41:14.836] iteration 7906 : model1 loss : 0.434262 model2 loss : 0.022324
[23:41:15.013] iteration 7907 : model1 loss : 0.443761 model2 loss : 0.029002
[23:41:15.184] iteration 7908 : model1 loss : 0.433147 model2 loss : 0.023710
[23:41:15.360] iteration 7909 : model1 loss : 0.434543 model2 loss : 0.020663
[23:41:15.535] iteration 7910 : model1 loss : 0.433847 model2 loss : 0.021914
[23:41:15.709] iteration 7911 : model1 loss : 0.436086 model2 loss : 0.021398
[23:41:15.880] iteration 7912 : model1 loss : 0.444412 model2 loss : 0.032388
[23:41:16.057] iteration 7913 : model1 loss : 0.440492 model2 loss : 0.031667
[23:41:16.229] iteration 7914 : model1 loss : 0.439645 model2 loss : 0.027718
[23:41:16.405] iteration 7915 : model1 loss : 0.440431 model2 loss : 0.023112
[23:41:16.578] iteration 7916 : model1 loss : 0.440872 model2 loss : 0.025246
[23:41:16.750] iteration 7917 : model1 loss : 0.433991 model2 loss : 0.021360
[23:41:18.879] iteration 7918 : model1 loss : 0.440603 model2 loss : 0.034748
[23:41:19.053] iteration 7919 : model1 loss : 0.435867 model2 loss : 0.023009
[23:41:19.231] iteration 7920 : model1 loss : 0.438550 model2 loss : 0.027927
[23:41:19.407] iteration 7921 : model1 loss : 0.439226 model2 loss : 0.028488
[23:41:19.589] iteration 7922 : model1 loss : 0.438580 model2 loss : 0.025928
[23:41:19.759] iteration 7923 : model1 loss : 0.438392 model2 loss : 0.026164
[23:41:19.935] iteration 7924 : model1 loss : 0.437962 model2 loss : 0.023803
[23:41:20.109] iteration 7925 : model1 loss : 0.440827 model2 loss : 0.026973
[23:41:20.284] iteration 7926 : model1 loss : 0.432267 model2 loss : 0.021117
[23:41:20.455] iteration 7927 : model1 loss : 0.436364 model2 loss : 0.024921
[23:41:20.633] iteration 7928 : model1 loss : 0.436877 model2 loss : 0.020529
[23:41:20.802] iteration 7929 : model1 loss : 0.437731 model2 loss : 0.023542
[23:41:20.980] iteration 7930 : model1 loss : 0.437586 model2 loss : 0.028687
[23:41:21.152] iteration 7931 : model1 loss : 0.442589 model2 loss : 0.024118
[23:41:21.333] iteration 7932 : model1 loss : 0.446870 model2 loss : 0.025643
[23:41:21.506] iteration 7933 : model1 loss : 0.434285 model2 loss : 0.020983
[23:41:21.684] iteration 7934 : model1 loss : 0.437715 model2 loss : 0.025093
[23:41:21.854] iteration 7935 : model1 loss : 0.438489 model2 loss : 0.022595
[23:41:22.032] iteration 7936 : model1 loss : 0.435629 model2 loss : 0.021486
[23:41:22.203] iteration 7937 : model1 loss : 0.438009 model2 loss : 0.026517
[23:41:22.377] iteration 7938 : model1 loss : 0.437389 model2 loss : 0.023796
[23:41:24.519] iteration 7939 : model1 loss : 0.441347 model2 loss : 0.023872
[23:41:24.692] iteration 7940 : model1 loss : 0.437198 model2 loss : 0.022928
[23:41:24.872] iteration 7941 : model1 loss : 0.440410 model2 loss : 0.028290
[23:41:25.044] iteration 7942 : model1 loss : 0.438693 model2 loss : 0.023283
[23:41:25.229] iteration 7943 : model1 loss : 0.439395 model2 loss : 0.021737
[23:41:25.401] iteration 7944 : model1 loss : 0.437358 model2 loss : 0.026221
[23:41:25.579] iteration 7945 : model1 loss : 0.435401 model2 loss : 0.022159
[23:41:25.751] iteration 7946 : model1 loss : 0.438337 model2 loss : 0.023737
[23:41:25.931] iteration 7947 : model1 loss : 0.433766 model2 loss : 0.024404
[23:41:26.104] iteration 7948 : model1 loss : 0.438000 model2 loss : 0.026916
[23:41:26.280] iteration 7949 : model1 loss : 0.436160 model2 loss : 0.021901
[23:41:26.452] iteration 7950 : model1 loss : 0.437590 model2 loss : 0.024594
[23:41:26.632] iteration 7951 : model1 loss : 0.438602 model2 loss : 0.024950
[23:41:26.801] iteration 7952 : model1 loss : 0.437480 model2 loss : 0.025203
[23:41:26.979] iteration 7953 : model1 loss : 0.434068 model2 loss : 0.023685
[23:41:27.152] iteration 7954 : model1 loss : 0.436800 model2 loss : 0.024597
[23:41:27.333] iteration 7955 : model1 loss : 0.437653 model2 loss : 0.024523
[23:41:27.509] iteration 7956 : model1 loss : 0.436951 model2 loss : 0.022015
[23:41:27.688] iteration 7957 : model1 loss : 0.438480 model2 loss : 0.026639
[23:41:27.859] iteration 7958 : model1 loss : 0.442564 model2 loss : 0.025346
[23:41:28.034] iteration 7959 : model1 loss : 0.436923 model2 loss : 0.022812
[23:41:30.166] iteration 7960 : model1 loss : 0.442589 model2 loss : 0.027698
[23:41:30.346] iteration 7961 : model1 loss : 0.438243 model2 loss : 0.026109
[23:41:30.524] iteration 7962 : model1 loss : 0.437947 model2 loss : 0.022848
[23:41:30.696] iteration 7963 : model1 loss : 0.435562 model2 loss : 0.023390
[23:41:30.869] iteration 7964 : model1 loss : 0.440953 model2 loss : 0.024303
[23:41:31.043] iteration 7965 : model1 loss : 0.440933 model2 loss : 0.024761
[23:41:31.219] iteration 7966 : model1 loss : 0.437778 model2 loss : 0.022986
[23:41:31.391] iteration 7967 : model1 loss : 0.436338 model2 loss : 0.022105
[23:41:31.569] iteration 7968 : model1 loss : 0.440039 model2 loss : 0.024886
[23:41:31.742] iteration 7969 : model1 loss : 0.436810 model2 loss : 0.024452
[23:41:31.918] iteration 7970 : model1 loss : 0.440816 model2 loss : 0.022693
[23:41:32.090] iteration 7971 : model1 loss : 0.437853 model2 loss : 0.021748
[23:41:32.266] iteration 7972 : model1 loss : 0.436337 model2 loss : 0.020846
[23:41:32.444] iteration 7973 : model1 loss : 0.437112 model2 loss : 0.026047
[23:41:32.623] iteration 7974 : model1 loss : 0.438708 model2 loss : 0.027343
[23:41:32.794] iteration 7975 : model1 loss : 0.438525 model2 loss : 0.024627
[23:41:32.969] iteration 7976 : model1 loss : 0.440211 model2 loss : 0.024645
[23:41:33.141] iteration 7977 : model1 loss : 0.440069 model2 loss : 0.024313
[23:41:33.320] iteration 7978 : model1 loss : 0.439870 model2 loss : 0.022975
[23:41:33.489] iteration 7979 : model1 loss : 0.438008 model2 loss : 0.022218
[23:41:33.666] iteration 7980 : model1 loss : 0.436630 model2 loss : 0.024846
[23:41:35.775] iteration 7981 : model1 loss : 0.441103 model2 loss : 0.026698
[23:41:35.952] iteration 7982 : model1 loss : 0.440373 model2 loss : 0.025250
[23:41:36.130] iteration 7983 : model1 loss : 0.436539 model2 loss : 0.024190
[23:41:36.301] iteration 7984 : model1 loss : 0.436468 model2 loss : 0.023697
[23:41:36.480] iteration 7985 : model1 loss : 0.435635 model2 loss : 0.023302
[23:41:36.652] iteration 7986 : model1 loss : 0.439071 model2 loss : 0.024032
[23:41:36.828] iteration 7987 : model1 loss : 0.440123 model2 loss : 0.023650
[23:41:36.999] iteration 7988 : model1 loss : 0.441130 model2 loss : 0.026541
[23:41:37.179] iteration 7989 : model1 loss : 0.437805 model2 loss : 0.021872
[23:41:37.356] iteration 7990 : model1 loss : 0.438733 model2 loss : 0.027015
[23:41:37.544] iteration 7991 : model1 loss : 0.439433 model2 loss : 0.024233
[23:41:37.715] iteration 7992 : model1 loss : 0.435150 model2 loss : 0.022764
[23:41:37.891] iteration 7993 : model1 loss : 0.436028 model2 loss : 0.022686
[23:41:38.061] iteration 7994 : model1 loss : 0.440515 model2 loss : 0.028061
[23:41:38.239] iteration 7995 : model1 loss : 0.439123 model2 loss : 0.024474
[23:41:38.412] iteration 7996 : model1 loss : 0.438480 model2 loss : 0.026501
[23:41:38.591] iteration 7997 : model1 loss : 0.434572 model2 loss : 0.022120
[23:41:38.765] iteration 7998 : model1 loss : 0.441653 model2 loss : 0.027949
[23:41:38.947] iteration 7999 : model1 loss : 0.434977 model2 loss : 0.021333
[23:41:39.118] iteration 8000 : model1 loss : 0.438800 model2 loss : 0.019973
[23:41:48.272] iteration 8000 : model1_mean_dice : 0.803336 model1_mean_hd95 : 11.367626
[23:41:57.401] iteration 8000 : model2_mean_dice : 0.840798 model2_mean_hd95 : 10.131577
[23:41:57.581] iteration 8001 : model1 loss : 0.433853 model2 loss : 0.020636
[23:41:59.723] iteration 8002 : model1 loss : 0.436823 model2 loss : 0.023541
[23:41:59.898] iteration 8003 : model1 loss : 0.441657 model2 loss : 0.022361
[23:42:00.079] iteration 8004 : model1 loss : 0.442048 model2 loss : 0.024733
[23:42:00.251] iteration 8005 : model1 loss : 0.440527 model2 loss : 0.027201
[23:42:00.429] iteration 8006 : model1 loss : 0.435281 model2 loss : 0.023900
[23:42:00.605] iteration 8007 : model1 loss : 0.439967 model2 loss : 0.026133
[23:42:00.777] iteration 8008 : model1 loss : 0.438408 model2 loss : 0.023778
[23:42:00.947] iteration 8009 : model1 loss : 0.436982 model2 loss : 0.021344
[23:42:01.123] iteration 8010 : model1 loss : 0.435982 model2 loss : 0.026327
[23:42:01.294] iteration 8011 : model1 loss : 0.435445 model2 loss : 0.021618
[23:42:01.469] iteration 8012 : model1 loss : 0.439927 model2 loss : 0.028436
[23:42:01.644] iteration 8013 : model1 loss : 0.440087 model2 loss : 0.025069
[23:42:01.820] iteration 8014 : model1 loss : 0.436917 model2 loss : 0.022782
[23:42:01.990] iteration 8015 : model1 loss : 0.434303 model2 loss : 0.021622
[23:42:02.167] iteration 8016 : model1 loss : 0.434559 model2 loss : 0.025173
[23:42:02.339] iteration 8017 : model1 loss : 0.437428 model2 loss : 0.022560
[23:42:02.519] iteration 8018 : model1 loss : 0.433563 model2 loss : 0.021134
[23:42:02.691] iteration 8019 : model1 loss : 0.430459 model2 loss : 0.022425
[23:42:02.866] iteration 8020 : model1 loss : 0.435364 model2 loss : 0.023742
[23:42:03.034] iteration 8021 : model1 loss : 0.442683 model2 loss : 0.026650
[23:42:03.209] iteration 8022 : model1 loss : 0.439333 model2 loss : 0.024599
[23:42:05.361] iteration 8023 : model1 loss : 0.440661 model2 loss : 0.023627
[23:42:05.533] iteration 8024 : model1 loss : 0.438837 model2 loss : 0.025928
[23:42:05.710] iteration 8025 : model1 loss : 0.435727 model2 loss : 0.026364
[23:42:05.881] iteration 8026 : model1 loss : 0.435308 model2 loss : 0.023844
[23:42:06.055] iteration 8027 : model1 loss : 0.436824 model2 loss : 0.023338
[23:42:06.230] iteration 8028 : model1 loss : 0.442182 model2 loss : 0.028317
[23:42:06.406] iteration 8029 : model1 loss : 0.438854 model2 loss : 0.025829
[23:42:06.580] iteration 8030 : model1 loss : 0.438041 model2 loss : 0.023459
[23:42:06.764] iteration 8031 : model1 loss : 0.435495 model2 loss : 0.024078
[23:42:06.935] iteration 8032 : model1 loss : 0.444372 model2 loss : 0.029673
[23:42:07.111] iteration 8033 : model1 loss : 0.435103 model2 loss : 0.022104
[23:42:07.283] iteration 8034 : model1 loss : 0.437962 model2 loss : 0.025192
[23:42:07.461] iteration 8035 : model1 loss : 0.435427 model2 loss : 0.027919
[23:42:07.634] iteration 8036 : model1 loss : 0.431659 model2 loss : 0.021998
[23:42:07.809] iteration 8037 : model1 loss : 0.437111 model2 loss : 0.023925
[23:42:07.981] iteration 8038 : model1 loss : 0.435528 model2 loss : 0.019338
[23:42:08.161] iteration 8039 : model1 loss : 0.430487 model2 loss : 0.021210
[23:42:08.337] iteration 8040 : model1 loss : 0.439418 model2 loss : 0.026051
[23:42:08.518] iteration 8041 : model1 loss : 0.438622 model2 loss : 0.026055
[23:42:08.690] iteration 8042 : model1 loss : 0.437714 model2 loss : 0.027236
[23:42:08.862] iteration 8043 : model1 loss : 0.440090 model2 loss : 0.024309
[23:42:10.978] iteration 8044 : model1 loss : 0.433859 model2 loss : 0.023702
[23:42:11.151] iteration 8045 : model1 loss : 0.436250 model2 loss : 0.025797
[23:42:11.332] iteration 8046 : model1 loss : 0.437069 model2 loss : 0.025010
[23:42:11.503] iteration 8047 : model1 loss : 0.439444 model2 loss : 0.024013
[23:42:11.681] iteration 8048 : model1 loss : 0.433041 model2 loss : 0.021424
[23:42:11.854] iteration 8049 : model1 loss : 0.439606 model2 loss : 0.025392
[23:42:12.032] iteration 8050 : model1 loss : 0.435534 model2 loss : 0.021143
[23:42:12.204] iteration 8051 : model1 loss : 0.439235 model2 loss : 0.026139
[23:42:12.381] iteration 8052 : model1 loss : 0.439593 model2 loss : 0.023832
[23:42:12.553] iteration 8053 : model1 loss : 0.436995 model2 loss : 0.025309
[23:42:12.731] iteration 8054 : model1 loss : 0.438129 model2 loss : 0.027375
[23:42:12.902] iteration 8055 : model1 loss : 0.440195 model2 loss : 0.026922
[23:42:13.078] iteration 8056 : model1 loss : 0.436391 model2 loss : 0.027303
[23:42:13.251] iteration 8057 : model1 loss : 0.444443 model2 loss : 0.030906
[23:42:13.427] iteration 8058 : model1 loss : 0.431408 model2 loss : 0.020995
[23:42:13.605] iteration 8059 : model1 loss : 0.440563 model2 loss : 0.031242
[23:42:13.780] iteration 8060 : model1 loss : 0.438365 model2 loss : 0.026546
[23:42:13.953] iteration 8061 : model1 loss : 0.438469 model2 loss : 0.027640
[23:42:14.133] iteration 8062 : model1 loss : 0.435817 model2 loss : 0.022034
[23:42:14.306] iteration 8063 : model1 loss : 0.439678 model2 loss : 0.024358
[23:42:14.480] iteration 8064 : model1 loss : 0.434301 model2 loss : 0.021109
[23:42:16.618] iteration 8065 : model1 loss : 0.437992 model2 loss : 0.026439
[23:42:16.792] iteration 8066 : model1 loss : 0.436574 model2 loss : 0.020601
[23:42:16.974] iteration 8067 : model1 loss : 0.436963 model2 loss : 0.023605
[23:42:17.147] iteration 8068 : model1 loss : 0.435326 model2 loss : 0.022548
[23:42:17.333] iteration 8069 : model1 loss : 0.443802 model2 loss : 0.027176
[23:42:17.509] iteration 8070 : model1 loss : 0.438401 model2 loss : 0.028581
[23:42:17.684] iteration 8071 : model1 loss : 0.435582 model2 loss : 0.023673
[23:42:17.854] iteration 8072 : model1 loss : 0.439561 model2 loss : 0.023419
[23:42:18.031] iteration 8073 : model1 loss : 0.435271 model2 loss : 0.023040
[23:42:18.203] iteration 8074 : model1 loss : 0.437786 model2 loss : 0.027703
[23:42:18.377] iteration 8075 : model1 loss : 0.443104 model2 loss : 0.029536
[23:42:18.551] iteration 8076 : model1 loss : 0.436198 model2 loss : 0.023507
[23:42:18.729] iteration 8077 : model1 loss : 0.443215 model2 loss : 0.026473
[23:42:18.899] iteration 8078 : model1 loss : 0.436104 model2 loss : 0.023909
[23:42:19.074] iteration 8079 : model1 loss : 0.432532 model2 loss : 0.024428
[23:42:19.247] iteration 8080 : model1 loss : 0.438259 model2 loss : 0.024621
[23:42:19.425] iteration 8081 : model1 loss : 0.437584 model2 loss : 0.022839
[23:42:19.607] iteration 8082 : model1 loss : 0.434455 model2 loss : 0.024310
[23:42:19.785] iteration 8083 : model1 loss : 0.435837 model2 loss : 0.020937
[23:42:19.954] iteration 8084 : model1 loss : 0.435892 model2 loss : 0.024312
[23:42:20.132] iteration 8085 : model1 loss : 0.439958 model2 loss : 0.024277
[23:42:22.248] iteration 8086 : model1 loss : 0.439474 model2 loss : 0.024976
[23:42:22.430] iteration 8087 : model1 loss : 0.436640 model2 loss : 0.023090
[23:42:22.609] iteration 8088 : model1 loss : 0.435523 model2 loss : 0.022498
[23:42:22.780] iteration 8089 : model1 loss : 0.437838 model2 loss : 0.021876
[23:42:22.959] iteration 8090 : model1 loss : 0.435860 model2 loss : 0.025217
[23:42:23.130] iteration 8091 : model1 loss : 0.437422 model2 loss : 0.025707
[23:42:23.309] iteration 8092 : model1 loss : 0.437251 model2 loss : 0.023079
[23:42:23.481] iteration 8093 : model1 loss : 0.439147 model2 loss : 0.027153
[23:42:23.659] iteration 8094 : model1 loss : 0.438123 model2 loss : 0.022622
[23:42:23.829] iteration 8095 : model1 loss : 0.434469 model2 loss : 0.020937
[23:42:24.006] iteration 8096 : model1 loss : 0.435365 model2 loss : 0.021969
[23:42:24.180] iteration 8097 : model1 loss : 0.433699 model2 loss : 0.025143
[23:42:24.356] iteration 8098 : model1 loss : 0.437118 model2 loss : 0.025017
[23:42:24.526] iteration 8099 : model1 loss : 0.438039 model2 loss : 0.024272
[23:42:24.702] iteration 8100 : model1 loss : 0.437691 model2 loss : 0.027637
[23:42:24.873] iteration 8101 : model1 loss : 0.439924 model2 loss : 0.025492
[23:42:25.047] iteration 8102 : model1 loss : 0.441853 model2 loss : 0.023291
[23:42:25.220] iteration 8103 : model1 loss : 0.436490 model2 loss : 0.025434
[23:42:25.399] iteration 8104 : model1 loss : 0.435375 model2 loss : 0.024015
[23:42:25.571] iteration 8105 : model1 loss : 0.435409 model2 loss : 0.022434
[23:42:25.745] iteration 8106 : model1 loss : 0.438598 model2 loss : 0.025810
[23:42:27.915] iteration 8107 : model1 loss : 0.437169 model2 loss : 0.022401
[23:42:28.087] iteration 8108 : model1 loss : 0.438234 model2 loss : 0.021267
[23:42:28.267] iteration 8109 : model1 loss : 0.437280 model2 loss : 0.025510
[23:42:28.438] iteration 8110 : model1 loss : 0.439775 model2 loss : 0.025154
[23:42:28.621] iteration 8111 : model1 loss : 0.435790 model2 loss : 0.035361
[23:42:28.794] iteration 8112 : model1 loss : 0.437899 model2 loss : 0.022682
[23:42:28.969] iteration 8113 : model1 loss : 0.437856 model2 loss : 0.024065
[23:42:29.139] iteration 8114 : model1 loss : 0.435122 model2 loss : 0.024824
[23:42:29.318] iteration 8115 : model1 loss : 0.433452 model2 loss : 0.022916
[23:42:29.488] iteration 8116 : model1 loss : 0.439389 model2 loss : 0.025951
[23:42:29.666] iteration 8117 : model1 loss : 0.434467 model2 loss : 0.024003
[23:42:29.838] iteration 8118 : model1 loss : 0.434666 model2 loss : 0.025815
[23:42:30.014] iteration 8119 : model1 loss : 0.438151 model2 loss : 0.023088
[23:42:30.187] iteration 8120 : model1 loss : 0.435726 model2 loss : 0.026867
[23:42:30.363] iteration 8121 : model1 loss : 0.439321 model2 loss : 0.025494
[23:42:30.536] iteration 8122 : model1 loss : 0.437135 model2 loss : 0.026103
[23:42:30.712] iteration 8123 : model1 loss : 0.437523 model2 loss : 0.026534
[23:42:30.884] iteration 8124 : model1 loss : 0.435691 model2 loss : 0.024336
[23:42:31.060] iteration 8125 : model1 loss : 0.441064 model2 loss : 0.025699
[23:42:31.230] iteration 8126 : model1 loss : 0.435165 model2 loss : 0.024691
[23:42:31.404] iteration 8127 : model1 loss : 0.437283 model2 loss : 0.019829
[23:42:33.529] iteration 8128 : model1 loss : 0.437384 model2 loss : 0.027255
[23:42:33.703] iteration 8129 : model1 loss : 0.435763 model2 loss : 0.023816
[23:42:33.882] iteration 8130 : model1 loss : 0.437522 model2 loss : 0.023856
[23:42:34.053] iteration 8131 : model1 loss : 0.439134 model2 loss : 0.028354
[23:42:34.231] iteration 8132 : model1 loss : 0.437328 model2 loss : 0.023481
[23:42:34.402] iteration 8133 : model1 loss : 0.439059 model2 loss : 0.024680
[23:42:34.580] iteration 8134 : model1 loss : 0.432684 model2 loss : 0.028195
[23:42:34.754] iteration 8135 : model1 loss : 0.437451 model2 loss : 0.028359
[23:42:34.928] iteration 8136 : model1 loss : 0.433798 model2 loss : 0.024585
[23:42:35.099] iteration 8137 : model1 loss : 0.438173 model2 loss : 0.023650
[23:42:35.277] iteration 8138 : model1 loss : 0.439503 model2 loss : 0.027591
[23:42:35.448] iteration 8139 : model1 loss : 0.441197 model2 loss : 0.028917
[23:42:35.631] iteration 8140 : model1 loss : 0.434854 model2 loss : 0.022400
[23:42:35.803] iteration 8141 : model1 loss : 0.435252 model2 loss : 0.029864
[23:42:35.981] iteration 8142 : model1 loss : 0.439424 model2 loss : 0.029252
[23:42:36.154] iteration 8143 : model1 loss : 0.434070 model2 loss : 0.023039
[23:42:36.334] iteration 8144 : model1 loss : 0.439872 model2 loss : 0.024957
[23:42:36.507] iteration 8145 : model1 loss : 0.436809 model2 loss : 0.026091
[23:42:36.683] iteration 8146 : model1 loss : 0.439526 model2 loss : 0.027284
[23:42:36.853] iteration 8147 : model1 loss : 0.433453 model2 loss : 0.029429
[23:42:37.028] iteration 8148 : model1 loss : 0.435138 model2 loss : 0.022569
[23:42:39.148] iteration 8149 : model1 loss : 0.441921 model2 loss : 0.028535
[23:42:39.322] iteration 8150 : model1 loss : 0.439749 model2 loss : 0.026366
[23:42:39.500] iteration 8151 : model1 loss : 0.436895 model2 loss : 0.023303
[23:42:39.674] iteration 8152 : model1 loss : 0.438754 model2 loss : 0.023957
[23:42:39.848] iteration 8153 : model1 loss : 0.439579 model2 loss : 0.022679
[23:42:40.020] iteration 8154 : model1 loss : 0.437620 model2 loss : 0.028652
[23:42:40.197] iteration 8155 : model1 loss : 0.433852 model2 loss : 0.024909
[23:42:40.367] iteration 8156 : model1 loss : 0.437864 model2 loss : 0.025362
[23:42:40.544] iteration 8157 : model1 loss : 0.437085 model2 loss : 0.024844
[23:42:40.717] iteration 8158 : model1 loss : 0.437663 model2 loss : 0.026433
[23:42:40.894] iteration 8159 : model1 loss : 0.440777 model2 loss : 0.027111
[23:42:41.065] iteration 8160 : model1 loss : 0.432734 model2 loss : 0.021119
[23:42:41.239] iteration 8161 : model1 loss : 0.439327 model2 loss : 0.026358
[23:42:41.409] iteration 8162 : model1 loss : 0.434520 model2 loss : 0.024471
[23:42:41.587] iteration 8163 : model1 loss : 0.436755 model2 loss : 0.023295
[23:42:41.762] iteration 8164 : model1 loss : 0.439415 model2 loss : 0.026644
[23:42:41.939] iteration 8165 : model1 loss : 0.431940 model2 loss : 0.021007
[23:42:42.109] iteration 8166 : model1 loss : 0.440324 model2 loss : 0.025040
[23:42:42.286] iteration 8167 : model1 loss : 0.440257 model2 loss : 0.025106
[23:42:42.459] iteration 8168 : model1 loss : 0.431720 model2 loss : 0.025073
[23:42:42.636] iteration 8169 : model1 loss : 0.437808 model2 loss : 0.028150
[23:42:44.775] iteration 8170 : model1 loss : 0.434809 model2 loss : 0.027253
[23:42:44.950] iteration 8171 : model1 loss : 0.442107 model2 loss : 0.028833
[23:42:45.128] iteration 8172 : model1 loss : 0.437933 model2 loss : 0.021992
[23:42:45.302] iteration 8173 : model1 loss : 0.438423 model2 loss : 0.029983
[23:42:45.479] iteration 8174 : model1 loss : 0.436502 model2 loss : 0.022511
[23:42:45.652] iteration 8175 : model1 loss : 0.436008 model2 loss : 0.023298
[23:42:45.829] iteration 8176 : model1 loss : 0.437565 model2 loss : 0.028211
[23:42:45.999] iteration 8177 : model1 loss : 0.435670 model2 loss : 0.024919
[23:42:46.175] iteration 8178 : model1 loss : 0.437244 model2 loss : 0.027389
[23:42:46.348] iteration 8179 : model1 loss : 0.438947 model2 loss : 0.025277
[23:42:46.525] iteration 8180 : model1 loss : 0.437041 model2 loss : 0.027014
[23:42:46.696] iteration 8181 : model1 loss : 0.436983 model2 loss : 0.028873
[23:42:46.877] iteration 8182 : model1 loss : 0.437615 model2 loss : 0.023110
[23:42:47.046] iteration 8183 : model1 loss : 0.437504 model2 loss : 0.023436
[23:42:47.222] iteration 8184 : model1 loss : 0.437838 model2 loss : 0.022540
[23:42:47.393] iteration 8185 : model1 loss : 0.439140 model2 loss : 0.029366
[23:42:47.569] iteration 8186 : model1 loss : 0.437494 model2 loss : 0.026099
[23:42:47.741] iteration 8187 : model1 loss : 0.435127 model2 loss : 0.026069
[23:42:47.916] iteration 8188 : model1 loss : 0.434540 model2 loss : 0.023837
[23:42:48.085] iteration 8189 : model1 loss : 0.437849 model2 loss : 0.022670
[23:42:48.258] iteration 8190 : model1 loss : 0.439098 model2 loss : 0.026977
[23:42:50.402] iteration 8191 : model1 loss : 0.439147 model2 loss : 0.026322
[23:42:50.573] iteration 8192 : model1 loss : 0.435720 model2 loss : 0.024634
[23:42:50.748] iteration 8193 : model1 loss : 0.436798 model2 loss : 0.024715
[23:42:50.918] iteration 8194 : model1 loss : 0.437291 model2 loss : 0.025724
[23:42:51.094] iteration 8195 : model1 loss : 0.437639 model2 loss : 0.027819
[23:42:51.267] iteration 8196 : model1 loss : 0.437463 model2 loss : 0.027110
[23:42:51.442] iteration 8197 : model1 loss : 0.438482 model2 loss : 0.026982
[23:42:51.614] iteration 8198 : model1 loss : 0.434217 model2 loss : 0.023204
[23:42:51.792] iteration 8199 : model1 loss : 0.436527 model2 loss : 0.024201
[23:42:51.964] iteration 8200 : model1 loss : 0.440242 model2 loss : 0.032196
[23:42:52.141] iteration 8201 : model1 loss : 0.439152 model2 loss : 0.025987
[23:42:52.315] iteration 8202 : model1 loss : 0.434022 model2 loss : 0.024685
[23:42:52.497] iteration 8203 : model1 loss : 0.434348 model2 loss : 0.025664
[23:42:52.670] iteration 8204 : model1 loss : 0.435906 model2 loss : 0.025250
[23:42:52.846] iteration 8205 : model1 loss : 0.439592 model2 loss : 0.037464
[23:42:53.017] iteration 8206 : model1 loss : 0.439004 model2 loss : 0.025002
[23:42:53.195] iteration 8207 : model1 loss : 0.437372 model2 loss : 0.021066
[23:42:53.366] iteration 8208 : model1 loss : 0.434952 model2 loss : 0.026248
[23:42:53.542] iteration 8209 : model1 loss : 0.440129 model2 loss : 0.025517
[23:42:53.712] iteration 8210 : model1 loss : 0.433390 model2 loss : 0.021290
[23:42:53.887] iteration 8211 : model1 loss : 0.436520 model2 loss : 0.021952
[23:42:56.019] iteration 8212 : model1 loss : 0.436359 model2 loss : 0.022218
[23:42:56.195] iteration 8213 : model1 loss : 0.438059 model2 loss : 0.026460
[23:42:56.374] iteration 8214 : model1 loss : 0.436724 model2 loss : 0.023098
[23:42:56.545] iteration 8215 : model1 loss : 0.436018 model2 loss : 0.024515
[23:42:56.724] iteration 8216 : model1 loss : 0.440065 model2 loss : 0.022943
[23:42:56.895] iteration 8217 : model1 loss : 0.440639 model2 loss : 0.025918
[23:42:57.071] iteration 8218 : model1 loss : 0.436077 model2 loss : 0.024662
[23:42:57.245] iteration 8219 : model1 loss : 0.439674 model2 loss : 0.028182
[23:42:57.428] iteration 8220 : model1 loss : 0.434776 model2 loss : 0.022003
[23:42:57.603] iteration 8221 : model1 loss : 0.438054 model2 loss : 0.022627
[23:42:57.779] iteration 8222 : model1 loss : 0.438929 model2 loss : 0.024837
[23:42:57.949] iteration 8223 : model1 loss : 0.434636 model2 loss : 0.024416
[23:42:58.130] iteration 8224 : model1 loss : 0.434428 model2 loss : 0.022848
[23:42:58.305] iteration 8225 : model1 loss : 0.438574 model2 loss : 0.021825
[23:42:58.480] iteration 8226 : model1 loss : 0.436331 model2 loss : 0.026664
[23:42:58.654] iteration 8227 : model1 loss : 0.437494 model2 loss : 0.027407
[23:42:58.834] iteration 8228 : model1 loss : 0.434947 model2 loss : 0.021773
[23:42:59.004] iteration 8229 : model1 loss : 0.434050 model2 loss : 0.022235
[23:42:59.182] iteration 8230 : model1 loss : 0.438702 model2 loss : 0.024561
[23:42:59.352] iteration 8231 : model1 loss : 0.435654 model2 loss : 0.030078
[23:42:59.527] iteration 8232 : model1 loss : 0.439057 model2 loss : 0.023405
[23:43:01.678] iteration 8233 : model1 loss : 0.441080 model2 loss : 0.022410
[23:43:01.850] iteration 8234 : model1 loss : 0.435922 model2 loss : 0.027034
[23:43:02.028] iteration 8235 : model1 loss : 0.439307 model2 loss : 0.023096
[23:43:02.202] iteration 8236 : model1 loss : 0.439427 model2 loss : 0.024018
[23:43:02.381] iteration 8237 : model1 loss : 0.435491 model2 loss : 0.023215
[23:43:02.553] iteration 8238 : model1 loss : 0.433015 model2 loss : 0.023873
[23:43:02.730] iteration 8239 : model1 loss : 0.439966 model2 loss : 0.021941
[23:43:02.901] iteration 8240 : model1 loss : 0.435116 model2 loss : 0.022511
[23:43:03.076] iteration 8241 : model1 loss : 0.432861 model2 loss : 0.022483
[23:43:03.248] iteration 8242 : model1 loss : 0.440078 model2 loss : 0.028188
[23:43:03.427] iteration 8243 : model1 loss : 0.435567 model2 loss : 0.021121
[23:43:03.601] iteration 8244 : model1 loss : 0.437974 model2 loss : 0.024998
[23:43:03.776] iteration 8245 : model1 loss : 0.436789 model2 loss : 0.022743
[23:43:03.946] iteration 8246 : model1 loss : 0.435967 model2 loss : 0.021226
[23:43:04.123] iteration 8247 : model1 loss : 0.439979 model2 loss : 0.026411
[23:43:04.298] iteration 8248 : model1 loss : 0.440719 model2 loss : 0.034765
[23:43:04.475] iteration 8249 : model1 loss : 0.439066 model2 loss : 0.021983
[23:43:04.647] iteration 8250 : model1 loss : 0.440210 model2 loss : 0.024689
[23:43:04.824] iteration 8251 : model1 loss : 0.439189 model2 loss : 0.025748
[23:43:04.994] iteration 8252 : model1 loss : 0.432360 model2 loss : 0.023737
[23:43:05.169] iteration 8253 : model1 loss : 0.435207 model2 loss : 0.023384
[23:43:07.310] iteration 8254 : model1 loss : 0.434259 model2 loss : 0.022621
[23:43:07.489] iteration 8255 : model1 loss : 0.438366 model2 loss : 0.023567
[23:43:07.666] iteration 8256 : model1 loss : 0.435674 model2 loss : 0.024744
[23:43:07.840] iteration 8257 : model1 loss : 0.441402 model2 loss : 0.026856
[23:43:08.017] iteration 8258 : model1 loss : 0.435149 model2 loss : 0.023672
[23:43:08.189] iteration 8259 : model1 loss : 0.434744 model2 loss : 0.025477
[23:43:08.371] iteration 8260 : model1 loss : 0.441111 model2 loss : 0.029068
[23:43:08.544] iteration 8261 : model1 loss : 0.439088 model2 loss : 0.022886
[23:43:08.720] iteration 8262 : model1 loss : 0.438415 model2 loss : 0.026924
[23:43:08.893] iteration 8263 : model1 loss : 0.436980 model2 loss : 0.022474
[23:43:09.068] iteration 8264 : model1 loss : 0.436990 model2 loss : 0.025597
[23:43:09.242] iteration 8265 : model1 loss : 0.433130 model2 loss : 0.025237
[23:43:09.420] iteration 8266 : model1 loss : 0.434954 model2 loss : 0.021026
[23:43:09.591] iteration 8267 : model1 loss : 0.437623 model2 loss : 0.024993
[23:43:09.767] iteration 8268 : model1 loss : 0.435666 model2 loss : 0.020803
[23:43:09.939] iteration 8269 : model1 loss : 0.438769 model2 loss : 0.025282
[23:43:10.116] iteration 8270 : model1 loss : 0.437887 model2 loss : 0.026159
[23:43:10.288] iteration 8271 : model1 loss : 0.438181 model2 loss : 0.025562
[23:43:10.468] iteration 8272 : model1 loss : 0.435774 model2 loss : 0.022230
[23:43:10.637] iteration 8273 : model1 loss : 0.437740 model2 loss : 0.023647
[23:43:10.813] iteration 8274 : model1 loss : 0.436486 model2 loss : 0.022144
[23:43:12.973] iteration 8275 : model1 loss : 0.437104 model2 loss : 0.024755
[23:43:13.146] iteration 8276 : model1 loss : 0.433918 model2 loss : 0.023574
[23:43:13.329] iteration 8277 : model1 loss : 0.442269 model2 loss : 0.028715
[23:43:13.500] iteration 8278 : model1 loss : 0.436668 model2 loss : 0.023364
[23:43:13.676] iteration 8279 : model1 loss : 0.439561 model2 loss : 0.026079
[23:43:13.848] iteration 8280 : model1 loss : 0.440593 model2 loss : 0.025810
[23:43:14.026] iteration 8281 : model1 loss : 0.436439 model2 loss : 0.023773
[23:43:14.198] iteration 8282 : model1 loss : 0.433628 model2 loss : 0.024224
[23:43:14.375] iteration 8283 : model1 loss : 0.436275 model2 loss : 0.023425
[23:43:14.546] iteration 8284 : model1 loss : 0.435483 model2 loss : 0.023039
[23:43:14.724] iteration 8285 : model1 loss : 0.437669 model2 loss : 0.022478
[23:43:14.896] iteration 8286 : model1 loss : 0.440105 model2 loss : 0.024335
[23:43:15.071] iteration 8287 : model1 loss : 0.436941 model2 loss : 0.024650
[23:43:15.247] iteration 8288 : model1 loss : 0.434057 model2 loss : 0.021215
[23:43:15.426] iteration 8289 : model1 loss : 0.438766 model2 loss : 0.023614
[23:43:15.602] iteration 8290 : model1 loss : 0.435466 model2 loss : 0.022250
[23:43:15.780] iteration 8291 : model1 loss : 0.436818 model2 loss : 0.023258
[23:43:15.951] iteration 8292 : model1 loss : 0.434995 model2 loss : 0.022894
[23:43:16.132] iteration 8293 : model1 loss : 0.435336 model2 loss : 0.022634
[23:43:16.305] iteration 8294 : model1 loss : 0.440497 model2 loss : 0.026422
[23:43:16.479] iteration 8295 : model1 loss : 0.437138 model2 loss : 0.025137
[23:43:18.623] iteration 8296 : model1 loss : 0.439870 model2 loss : 0.025969
[23:43:18.796] iteration 8297 : model1 loss : 0.437404 model2 loss : 0.025903
[23:43:18.975] iteration 8298 : model1 loss : 0.437445 model2 loss : 0.021667
[23:43:19.151] iteration 8299 : model1 loss : 0.435706 model2 loss : 0.023371
[23:43:19.335] iteration 8300 : model1 loss : 0.430758 model2 loss : 0.019617
[23:43:19.508] iteration 8301 : model1 loss : 0.433833 model2 loss : 0.024633
[23:43:19.682] iteration 8302 : model1 loss : 0.437350 model2 loss : 0.023420
[23:43:19.856] iteration 8303 : model1 loss : 0.437713 model2 loss : 0.022879
[23:43:20.031] iteration 8304 : model1 loss : 0.435949 model2 loss : 0.022795
[23:43:20.205] iteration 8305 : model1 loss : 0.430678 model2 loss : 0.022636
[23:43:20.383] iteration 8306 : model1 loss : 0.442275 model2 loss : 0.025558
[23:43:20.554] iteration 8307 : model1 loss : 0.440269 model2 loss : 0.024241
[23:43:20.732] iteration 8308 : model1 loss : 0.440341 model2 loss : 0.025047
[23:43:20.903] iteration 8309 : model1 loss : 0.436938 model2 loss : 0.026214
[23:43:21.080] iteration 8310 : model1 loss : 0.437353 model2 loss : 0.023481
[23:43:21.254] iteration 8311 : model1 loss : 0.435792 model2 loss : 0.023005
[23:43:21.435] iteration 8312 : model1 loss : 0.437269 model2 loss : 0.026629
[23:43:21.610] iteration 8313 : model1 loss : 0.439285 model2 loss : 0.024889
[23:43:21.788] iteration 8314 : model1 loss : 0.434985 model2 loss : 0.023542
[23:43:21.959] iteration 8315 : model1 loss : 0.433839 model2 loss : 0.022825
[23:43:22.133] iteration 8316 : model1 loss : 0.440101 model2 loss : 0.025409
[23:43:24.268] iteration 8317 : model1 loss : 0.439217 model2 loss : 0.022655
[23:43:24.443] iteration 8318 : model1 loss : 0.436223 model2 loss : 0.022596
[23:43:24.624] iteration 8319 : model1 loss : 0.438730 model2 loss : 0.023419
[23:43:24.797] iteration 8320 : model1 loss : 0.431987 model2 loss : 0.023195
[23:43:24.973] iteration 8321 : model1 loss : 0.441928 model2 loss : 0.026784
[23:43:25.144] iteration 8322 : model1 loss : 0.441568 model2 loss : 0.026656
[23:43:25.320] iteration 8323 : model1 loss : 0.434764 model2 loss : 0.020826
[23:43:25.491] iteration 8324 : model1 loss : 0.437892 model2 loss : 0.024840
[23:43:25.669] iteration 8325 : model1 loss : 0.435374 model2 loss : 0.023805
[23:43:25.843] iteration 8326 : model1 loss : 0.434159 model2 loss : 0.022445
[23:43:26.019] iteration 8327 : model1 loss : 0.438168 model2 loss : 0.024181
[23:43:26.190] iteration 8328 : model1 loss : 0.434750 model2 loss : 0.023911
[23:43:26.369] iteration 8329 : model1 loss : 0.433904 model2 loss : 0.021900
[23:43:26.542] iteration 8330 : model1 loss : 0.436983 model2 loss : 0.023117
[23:43:26.720] iteration 8331 : model1 loss : 0.441732 model2 loss : 0.030354
[23:43:26.906] iteration 8332 : model1 loss : 0.441711 model2 loss : 0.025939
[23:43:27.081] iteration 8333 : model1 loss : 0.434910 model2 loss : 0.028531
[23:43:27.255] iteration 8334 : model1 loss : 0.436888 model2 loss : 0.026301
[23:43:27.432] iteration 8335 : model1 loss : 0.437142 model2 loss : 0.029778
[23:43:27.608] iteration 8336 : model1 loss : 0.435268 model2 loss : 0.027076
[23:43:27.784] iteration 8337 : model1 loss : 0.437458 model2 loss : 0.025622
[23:43:29.929] iteration 8338 : model1 loss : 0.435509 model2 loss : 0.028139
[23:43:30.100] iteration 8339 : model1 loss : 0.433818 model2 loss : 0.023183
[23:43:30.279] iteration 8340 : model1 loss : 0.437022 model2 loss : 0.023796
[23:43:30.454] iteration 8341 : model1 loss : 0.436252 model2 loss : 0.027851
[23:43:30.633] iteration 8342 : model1 loss : 0.437534 model2 loss : 0.024115
[23:43:30.806] iteration 8343 : model1 loss : 0.439709 model2 loss : 0.026023
[23:43:30.983] iteration 8344 : model1 loss : 0.436280 model2 loss : 0.023734
[23:43:31.153] iteration 8345 : model1 loss : 0.434630 model2 loss : 0.022596
[23:43:31.335] iteration 8346 : model1 loss : 0.438510 model2 loss : 0.026405
[23:43:31.506] iteration 8347 : model1 loss : 0.438165 model2 loss : 0.028884
[23:43:31.680] iteration 8348 : model1 loss : 0.432397 model2 loss : 0.025329
[23:43:31.853] iteration 8349 : model1 loss : 0.432905 model2 loss : 0.027107
[23:43:32.031] iteration 8350 : model1 loss : 0.435653 model2 loss : 0.023588
[23:43:32.202] iteration 8351 : model1 loss : 0.437354 model2 loss : 0.027313
[23:43:32.380] iteration 8352 : model1 loss : 0.440136 model2 loss : 0.025392
[23:43:32.551] iteration 8353 : model1 loss : 0.442875 model2 loss : 0.026860
[23:43:32.728] iteration 8354 : model1 loss : 0.434366 model2 loss : 0.023409
[23:43:32.902] iteration 8355 : model1 loss : 0.435682 model2 loss : 0.026169
[23:43:33.074] iteration 8356 : model1 loss : 0.441299 model2 loss : 0.030426
[23:43:33.246] iteration 8357 : model1 loss : 0.437633 model2 loss : 0.025921
[23:43:33.422] iteration 8358 : model1 loss : 0.440778 model2 loss : 0.026942
[23:43:35.533] iteration 8359 : model1 loss : 0.435944 model2 loss : 0.025765
[23:43:35.706] iteration 8360 : model1 loss : 0.435627 model2 loss : 0.026518
[23:43:35.885] iteration 8361 : model1 loss : 0.439296 model2 loss : 0.024240
[23:43:36.069] iteration 8362 : model1 loss : 0.435661 model2 loss : 0.028032
[23:43:36.246] iteration 8363 : model1 loss : 0.437679 model2 loss : 0.024731
[23:43:36.421] iteration 8364 : model1 loss : 0.442601 model2 loss : 0.028419
[23:43:36.604] iteration 8365 : model1 loss : 0.438164 model2 loss : 0.026277
[23:43:36.778] iteration 8366 : model1 loss : 0.435944 model2 loss : 0.020925
[23:43:36.954] iteration 8367 : model1 loss : 0.433624 model2 loss : 0.024277
[23:43:37.125] iteration 8368 : model1 loss : 0.438929 model2 loss : 0.032844
[23:43:37.302] iteration 8369 : model1 loss : 0.439213 model2 loss : 0.021477
[23:43:37.479] iteration 8370 : model1 loss : 0.436483 model2 loss : 0.028305
[23:43:37.655] iteration 8371 : model1 loss : 0.437477 model2 loss : 0.024436
[23:43:37.827] iteration 8372 : model1 loss : 0.435295 model2 loss : 0.024479
[23:43:38.004] iteration 8373 : model1 loss : 0.432840 model2 loss : 0.022954
[23:43:38.175] iteration 8374 : model1 loss : 0.439955 model2 loss : 0.024738
[23:43:38.354] iteration 8375 : model1 loss : 0.433865 model2 loss : 0.025244
[23:43:38.526] iteration 8376 : model1 loss : 0.436226 model2 loss : 0.023874
[23:43:38.700] iteration 8377 : model1 loss : 0.434068 model2 loss : 0.024479
[23:43:38.872] iteration 8378 : model1 loss : 0.440390 model2 loss : 0.029708
[23:43:39.044] iteration 8379 : model1 loss : 0.431117 model2 loss : 0.021797
[23:43:41.168] iteration 8380 : model1 loss : 0.437752 model2 loss : 0.025642
[23:43:41.351] iteration 8381 : model1 loss : 0.436634 model2 loss : 0.024116
[23:43:41.528] iteration 8382 : model1 loss : 0.437557 model2 loss : 0.023951
[23:43:41.698] iteration 8383 : model1 loss : 0.439838 model2 loss : 0.024646
[23:43:41.877] iteration 8384 : model1 loss : 0.437412 model2 loss : 0.027821
[23:43:42.047] iteration 8385 : model1 loss : 0.438700 model2 loss : 0.025216
[23:43:42.226] iteration 8386 : model1 loss : 0.433208 model2 loss : 0.021670
[23:43:42.399] iteration 8387 : model1 loss : 0.435818 model2 loss : 0.025926
[23:43:42.576] iteration 8388 : model1 loss : 0.440007 model2 loss : 0.025068
[23:43:42.750] iteration 8389 : model1 loss : 0.432585 model2 loss : 0.024038
[23:43:42.931] iteration 8390 : model1 loss : 0.436661 model2 loss : 0.024928
[23:43:43.101] iteration 8391 : model1 loss : 0.436263 model2 loss : 0.021960
[23:43:43.277] iteration 8392 : model1 loss : 0.439863 model2 loss : 0.022345
[23:43:43.449] iteration 8393 : model1 loss : 0.435591 model2 loss : 0.022064
[23:43:43.627] iteration 8394 : model1 loss : 0.436228 model2 loss : 0.021533
[23:43:43.800] iteration 8395 : model1 loss : 0.440483 model2 loss : 0.024596
[23:43:43.980] iteration 8396 : model1 loss : 0.439144 model2 loss : 0.022893
[23:43:44.149] iteration 8397 : model1 loss : 0.433680 model2 loss : 0.025053
[23:43:44.328] iteration 8398 : model1 loss : 0.434000 model2 loss : 0.023759
[23:43:44.497] iteration 8399 : model1 loss : 0.437476 model2 loss : 0.025214
[23:43:44.670] iteration 8400 : model1 loss : 0.434796 model2 loss : 0.024798
[23:43:46.827] iteration 8401 : model1 loss : 0.434363 model2 loss : 0.021430
[23:43:47.001] iteration 8402 : model1 loss : 0.438169 model2 loss : 0.025249
[23:43:47.177] iteration 8403 : model1 loss : 0.438822 model2 loss : 0.024766
[23:43:47.351] iteration 8404 : model1 loss : 0.434756 model2 loss : 0.021808
[23:43:47.532] iteration 8405 : model1 loss : 0.440486 model2 loss : 0.022986
[23:43:47.700] iteration 8406 : model1 loss : 0.433826 model2 loss : 0.023062
[23:43:47.878] iteration 8407 : model1 loss : 0.440602 model2 loss : 0.025973
[23:43:48.050] iteration 8408 : model1 loss : 0.437340 model2 loss : 0.024469
[23:43:48.228] iteration 8409 : model1 loss : 0.437070 model2 loss : 0.021494
[23:43:48.404] iteration 8410 : model1 loss : 0.434741 model2 loss : 0.024923
[23:43:48.581] iteration 8411 : model1 loss : 0.435460 model2 loss : 0.021534
[23:43:48.754] iteration 8412 : model1 loss : 0.438857 model2 loss : 0.026623
[23:43:48.932] iteration 8413 : model1 loss : 0.433521 model2 loss : 0.022107
[23:43:49.101] iteration 8414 : model1 loss : 0.439069 model2 loss : 0.021038
[23:43:49.280] iteration 8415 : model1 loss : 0.434783 model2 loss : 0.021262
[23:43:49.452] iteration 8416 : model1 loss : 0.434528 model2 loss : 0.024916
[23:43:49.630] iteration 8417 : model1 loss : 0.437341 model2 loss : 0.026657
[23:43:49.807] iteration 8418 : model1 loss : 0.441759 model2 loss : 0.027274
[23:43:49.984] iteration 8419 : model1 loss : 0.437998 model2 loss : 0.023765
[23:43:50.152] iteration 8420 : model1 loss : 0.439688 model2 loss : 0.031243
[23:43:50.331] iteration 8421 : model1 loss : 0.437765 model2 loss : 0.026440
[23:43:52.475] iteration 8422 : model1 loss : 0.432962 model2 loss : 0.018691
[23:43:52.648] iteration 8423 : model1 loss : 0.439277 model2 loss : 0.025425
[23:43:52.825] iteration 8424 : model1 loss : 0.433692 model2 loss : 0.024414
[23:43:52.998] iteration 8425 : model1 loss : 0.436990 model2 loss : 0.025863
[23:43:53.172] iteration 8426 : model1 loss : 0.437841 model2 loss : 0.023976
[23:43:53.348] iteration 8427 : model1 loss : 0.432348 model2 loss : 0.019975
[23:43:53.526] iteration 8428 : model1 loss : 0.437948 model2 loss : 0.030667
[23:43:53.695] iteration 8429 : model1 loss : 0.437096 model2 loss : 0.026090
[23:43:53.868] iteration 8430 : model1 loss : 0.436845 model2 loss : 0.025836
[23:43:54.047] iteration 8431 : model1 loss : 0.438545 model2 loss : 0.028919
[23:43:54.222] iteration 8432 : model1 loss : 0.435716 model2 loss : 0.021873
[23:43:54.397] iteration 8433 : model1 loss : 0.445922 model2 loss : 0.029158
[23:43:54.577] iteration 8434 : model1 loss : 0.440350 model2 loss : 0.027102
[23:43:54.748] iteration 8435 : model1 loss : 0.440472 model2 loss : 0.032549
[23:43:54.929] iteration 8436 : model1 loss : 0.440410 model2 loss : 0.024077
[23:43:55.098] iteration 8437 : model1 loss : 0.437169 model2 loss : 0.026397
[23:43:55.275] iteration 8438 : model1 loss : 0.435871 model2 loss : 0.023360
[23:43:55.449] iteration 8439 : model1 loss : 0.434235 model2 loss : 0.026881
[23:43:55.627] iteration 8440 : model1 loss : 0.438684 model2 loss : 0.026294
[23:43:55.798] iteration 8441 : model1 loss : 0.436789 model2 loss : 0.027556
[23:43:55.971] iteration 8442 : model1 loss : 0.439417 model2 loss : 0.026661
[23:43:58.124] iteration 8443 : model1 loss : 0.437512 model2 loss : 0.025479
[23:43:58.305] iteration 8444 : model1 loss : 0.435951 model2 loss : 0.022543
[23:43:58.483] iteration 8445 : model1 loss : 0.436241 model2 loss : 0.023687
[23:43:58.654] iteration 8446 : model1 loss : 0.443415 model2 loss : 0.025956
[23:43:58.831] iteration 8447 : model1 loss : 0.439375 model2 loss : 0.025647
[23:43:59.004] iteration 8448 : model1 loss : 0.437045 model2 loss : 0.022755
[23:43:59.181] iteration 8449 : model1 loss : 0.435263 model2 loss : 0.020205
[23:43:59.356] iteration 8450 : model1 loss : 0.434209 model2 loss : 0.024518
[23:43:59.533] iteration 8451 : model1 loss : 0.436130 model2 loss : 0.027162
[23:43:59.705] iteration 8452 : model1 loss : 0.434018 model2 loss : 0.026093
[23:43:59.884] iteration 8453 : model1 loss : 0.437098 model2 loss : 0.021217
[23:44:00.057] iteration 8454 : model1 loss : 0.434864 model2 loss : 0.023647
[23:44:00.234] iteration 8455 : model1 loss : 0.437015 model2 loss : 0.026529
[23:44:00.411] iteration 8456 : model1 loss : 0.435322 model2 loss : 0.024374
[23:44:00.592] iteration 8457 : model1 loss : 0.439634 model2 loss : 0.026750
[23:44:00.771] iteration 8458 : model1 loss : 0.437565 model2 loss : 0.025782
[23:44:00.952] iteration 8459 : model1 loss : 0.440923 model2 loss : 0.032754
[23:44:01.124] iteration 8460 : model1 loss : 0.441175 model2 loss : 0.025992
[23:44:01.303] iteration 8461 : model1 loss : 0.437307 model2 loss : 0.025603
[23:44:01.476] iteration 8462 : model1 loss : 0.439205 model2 loss : 0.025252
[23:44:01.650] iteration 8463 : model1 loss : 0.440427 model2 loss : 0.028376
[23:44:03.798] iteration 8464 : model1 loss : 0.437641 model2 loss : 0.028605
[23:44:03.972] iteration 8465 : model1 loss : 0.435833 model2 loss : 0.024202
[23:44:04.152] iteration 8466 : model1 loss : 0.439090 model2 loss : 0.029255
[23:44:04.334] iteration 8467 : model1 loss : 0.436786 model2 loss : 0.026163
[23:44:04.510] iteration 8468 : model1 loss : 0.435187 model2 loss : 0.024445
[23:44:04.680] iteration 8469 : model1 loss : 0.437771 model2 loss : 0.024191
[23:44:04.858] iteration 8470 : model1 loss : 0.438199 model2 loss : 0.023446
[23:44:05.032] iteration 8471 : model1 loss : 0.435347 model2 loss : 0.022942
[23:44:05.207] iteration 8472 : model1 loss : 0.439855 model2 loss : 0.025150
[23:44:05.381] iteration 8473 : model1 loss : 0.435956 model2 loss : 0.023385
[23:44:05.562] iteration 8474 : model1 loss : 0.433558 model2 loss : 0.023944
[23:44:05.732] iteration 8475 : model1 loss : 0.437491 model2 loss : 0.026955
[23:44:05.910] iteration 8476 : model1 loss : 0.433118 model2 loss : 0.025123
[23:44:06.084] iteration 8477 : model1 loss : 0.438605 model2 loss : 0.024203
[23:44:06.264] iteration 8478 : model1 loss : 0.440230 model2 loss : 0.023818
[23:44:06.440] iteration 8479 : model1 loss : 0.437742 model2 loss : 0.023949
[23:44:06.617] iteration 8480 : model1 loss : 0.435720 model2 loss : 0.021416
[23:44:06.791] iteration 8481 : model1 loss : 0.441079 model2 loss : 0.025641
[23:44:06.971] iteration 8482 : model1 loss : 0.439979 model2 loss : 0.026364
[23:44:07.142] iteration 8483 : model1 loss : 0.437985 model2 loss : 0.025555
[23:44:07.324] iteration 8484 : model1 loss : 0.437684 model2 loss : 0.026732
[23:44:09.542] iteration 8485 : model1 loss : 0.433308 model2 loss : 0.023356
[23:44:09.716] iteration 8486 : model1 loss : 0.436344 model2 loss : 0.024112
[23:44:09.894] iteration 8487 : model1 loss : 0.440182 model2 loss : 0.025072
[23:44:10.068] iteration 8488 : model1 loss : 0.438983 model2 loss : 0.024663
[23:44:10.244] iteration 8489 : model1 loss : 0.439121 model2 loss : 0.026177
[23:44:10.419] iteration 8490 : model1 loss : 0.438525 model2 loss : 0.025806
[23:44:10.599] iteration 8491 : model1 loss : 0.440235 model2 loss : 0.022885
[23:44:10.769] iteration 8492 : model1 loss : 0.436501 model2 loss : 0.026952
[23:44:10.950] iteration 8493 : model1 loss : 0.434280 model2 loss : 0.023940
[23:44:11.121] iteration 8494 : model1 loss : 0.432882 model2 loss : 0.024115
[23:44:11.301] iteration 8495 : model1 loss : 0.433376 model2 loss : 0.025172
[23:44:11.475] iteration 8496 : model1 loss : 0.434340 model2 loss : 0.023359
[23:44:11.650] iteration 8497 : model1 loss : 0.435905 model2 loss : 0.022711
[23:44:11.824] iteration 8498 : model1 loss : 0.443322 model2 loss : 0.029987
[23:44:12.001] iteration 8499 : model1 loss : 0.441114 model2 loss : 0.028955
[23:44:12.174] iteration 8500 : model1 loss : 0.434099 model2 loss : 0.022953
[23:44:12.356] iteration 8501 : model1 loss : 0.437319 model2 loss : 0.020844
[23:44:12.530] iteration 8502 : model1 loss : 0.437316 model2 loss : 0.024361
[23:44:12.705] iteration 8503 : model1 loss : 0.440833 model2 loss : 0.027376
[23:44:12.881] iteration 8504 : model1 loss : 0.437429 model2 loss : 0.023860
[23:44:13.059] iteration 8505 : model1 loss : 0.438020 model2 loss : 0.029976
[23:44:15.194] iteration 8506 : model1 loss : 0.440069 model2 loss : 0.027593
[23:44:15.374] iteration 8507 : model1 loss : 0.436497 model2 loss : 0.021674
[23:44:15.553] iteration 8508 : model1 loss : 0.438543 model2 loss : 0.020946
[23:44:15.725] iteration 8509 : model1 loss : 0.434759 model2 loss : 0.023703
[23:44:15.907] iteration 8510 : model1 loss : 0.436241 model2 loss : 0.024815
[23:44:16.083] iteration 8511 : model1 loss : 0.433807 model2 loss : 0.023940
[23:44:16.263] iteration 8512 : model1 loss : 0.435734 model2 loss : 0.023732
[23:44:16.436] iteration 8513 : model1 loss : 0.438489 model2 loss : 0.023385
[23:44:16.613] iteration 8514 : model1 loss : 0.437126 model2 loss : 0.025117
[23:44:16.785] iteration 8515 : model1 loss : 0.431050 model2 loss : 0.021887
[23:44:16.965] iteration 8516 : model1 loss : 0.437735 model2 loss : 0.029928
[23:44:17.137] iteration 8517 : model1 loss : 0.435381 model2 loss : 0.022342
[23:44:17.318] iteration 8518 : model1 loss : 0.435919 model2 loss : 0.022299
[23:44:17.499] iteration 8519 : model1 loss : 0.436566 model2 loss : 0.021346
[23:44:17.674] iteration 8520 : model1 loss : 0.435430 model2 loss : 0.023777
[23:44:17.848] iteration 8521 : model1 loss : 0.441659 model2 loss : 0.026128
[23:44:18.029] iteration 8522 : model1 loss : 0.438954 model2 loss : 0.022779
[23:44:18.202] iteration 8523 : model1 loss : 0.437844 model2 loss : 0.025608
[23:44:18.382] iteration 8524 : model1 loss : 0.438182 model2 loss : 0.024048
[23:44:18.553] iteration 8525 : model1 loss : 0.439576 model2 loss : 0.025985
[23:44:18.726] iteration 8526 : model1 loss : 0.436749 model2 loss : 0.024488
[23:44:20.887] iteration 8527 : model1 loss : 0.437025 model2 loss : 0.025891
[23:44:21.065] iteration 8528 : model1 loss : 0.437759 model2 loss : 0.023624
[23:44:21.245] iteration 8529 : model1 loss : 0.438171 model2 loss : 0.024356
[23:44:21.419] iteration 8530 : model1 loss : 0.436374 model2 loss : 0.019510
[23:44:21.598] iteration 8531 : model1 loss : 0.440180 model2 loss : 0.023846
[23:44:21.768] iteration 8532 : model1 loss : 0.434110 model2 loss : 0.021908
[23:44:21.948] iteration 8533 : model1 loss : 0.432674 model2 loss : 0.022866
[23:44:22.122] iteration 8534 : model1 loss : 0.435201 model2 loss : 0.023248
[23:44:22.306] iteration 8535 : model1 loss : 0.437457 model2 loss : 0.024599
[23:44:22.486] iteration 8536 : model1 loss : 0.439302 model2 loss : 0.029932
[23:44:22.663] iteration 8537 : model1 loss : 0.439528 model2 loss : 0.022229
[23:44:22.838] iteration 8538 : model1 loss : 0.433966 model2 loss : 0.022917
[23:44:23.016] iteration 8539 : model1 loss : 0.440300 model2 loss : 0.026067
[23:44:23.189] iteration 8540 : model1 loss : 0.440518 model2 loss : 0.027861
[23:44:23.371] iteration 8541 : model1 loss : 0.434666 model2 loss : 0.029716
[23:44:23.543] iteration 8542 : model1 loss : 0.437332 model2 loss : 0.022516
[23:44:23.718] iteration 8543 : model1 loss : 0.434122 model2 loss : 0.023293
[23:44:23.894] iteration 8544 : model1 loss : 0.438733 model2 loss : 0.022886
[23:44:24.070] iteration 8545 : model1 loss : 0.433743 model2 loss : 0.023258
[23:44:24.243] iteration 8546 : model1 loss : 0.437344 model2 loss : 0.025647
[23:44:24.419] iteration 8547 : model1 loss : 0.436571 model2 loss : 0.024190
[23:44:26.595] iteration 8548 : model1 loss : 0.436290 model2 loss : 0.024271
[23:44:26.768] iteration 8549 : model1 loss : 0.433727 model2 loss : 0.023295
[23:44:26.947] iteration 8550 : model1 loss : 0.439440 model2 loss : 0.025923
[23:44:27.117] iteration 8551 : model1 loss : 0.439574 model2 loss : 0.023008
[23:44:27.293] iteration 8552 : model1 loss : 0.433880 model2 loss : 0.023319
[23:44:27.470] iteration 8553 : model1 loss : 0.434659 model2 loss : 0.024704
[23:44:27.643] iteration 8554 : model1 loss : 0.440833 model2 loss : 0.025023
[23:44:27.816] iteration 8555 : model1 loss : 0.436402 model2 loss : 0.022410
[23:44:27.995] iteration 8556 : model1 loss : 0.439401 model2 loss : 0.025830
[23:44:28.167] iteration 8557 : model1 loss : 0.436553 model2 loss : 0.024192
[23:44:28.348] iteration 8558 : model1 loss : 0.436323 model2 loss : 0.020677
[23:44:28.521] iteration 8559 : model1 loss : 0.435094 model2 loss : 0.025462
[23:44:28.699] iteration 8560 : model1 loss : 0.435173 model2 loss : 0.021679
[23:44:28.873] iteration 8561 : model1 loss : 0.436227 model2 loss : 0.025313
[23:44:29.052] iteration 8562 : model1 loss : 0.435979 model2 loss : 0.026735
[23:44:29.227] iteration 8563 : model1 loss : 0.439881 model2 loss : 0.025408
[23:44:29.407] iteration 8564 : model1 loss : 0.440063 model2 loss : 0.028451
[23:44:29.578] iteration 8565 : model1 loss : 0.432686 model2 loss : 0.025333
[23:44:29.755] iteration 8566 : model1 loss : 0.440082 model2 loss : 0.023316
[23:44:29.929] iteration 8567 : model1 loss : 0.438180 model2 loss : 0.025041
[23:44:30.106] iteration 8568 : model1 loss : 0.436533 model2 loss : 0.025036
[23:44:32.269] iteration 8569 : model1 loss : 0.434165 model2 loss : 0.022550
[23:44:32.451] iteration 8570 : model1 loss : 0.437208 model2 loss : 0.024902
[23:44:32.630] iteration 8571 : model1 loss : 0.437997 model2 loss : 0.020269
[23:44:32.802] iteration 8572 : model1 loss : 0.433432 model2 loss : 0.021287
[23:44:32.984] iteration 8573 : model1 loss : 0.437791 model2 loss : 0.026684
[23:44:33.157] iteration 8574 : model1 loss : 0.439010 model2 loss : 0.027051
[23:44:33.340] iteration 8575 : model1 loss : 0.442792 model2 loss : 0.027430
[23:44:33.515] iteration 8576 : model1 loss : 0.435079 model2 loss : 0.022114
[23:44:33.690] iteration 8577 : model1 loss : 0.441098 model2 loss : 0.024958
[23:44:33.864] iteration 8578 : model1 loss : 0.430466 model2 loss : 0.022340
[23:44:34.043] iteration 8579 : model1 loss : 0.437531 model2 loss : 0.025859
[23:44:34.216] iteration 8580 : model1 loss : 0.433401 model2 loss : 0.018853
[23:44:34.398] iteration 8581 : model1 loss : 0.434081 model2 loss : 0.025447
[23:44:34.576] iteration 8582 : model1 loss : 0.435654 model2 loss : 0.021670
[23:44:34.754] iteration 8583 : model1 loss : 0.438137 model2 loss : 0.029164
[23:44:34.929] iteration 8584 : model1 loss : 0.438822 model2 loss : 0.024005
[23:44:35.105] iteration 8585 : model1 loss : 0.436358 model2 loss : 0.021118
[23:44:35.279] iteration 8586 : model1 loss : 0.437299 model2 loss : 0.022683
[23:44:35.460] iteration 8587 : model1 loss : 0.438455 model2 loss : 0.024584
[23:44:35.629] iteration 8588 : model1 loss : 0.436313 model2 loss : 0.025320
[23:44:35.804] iteration 8589 : model1 loss : 0.436295 model2 loss : 0.022580
[23:44:37.989] iteration 8590 : model1 loss : 0.430919 model2 loss : 0.022212
[23:44:38.163] iteration 8591 : model1 loss : 0.438740 model2 loss : 0.030797
[23:44:38.348] iteration 8592 : model1 loss : 0.435718 model2 loss : 0.025812
[23:44:38.520] iteration 8593 : model1 loss : 0.431043 model2 loss : 0.021858
[23:44:38.695] iteration 8594 : model1 loss : 0.436472 model2 loss : 0.023103
[23:44:38.868] iteration 8595 : model1 loss : 0.437261 model2 loss : 0.025801
[23:44:39.046] iteration 8596 : model1 loss : 0.435099 model2 loss : 0.024541
[23:44:39.219] iteration 8597 : model1 loss : 0.438842 model2 loss : 0.022952
[23:44:39.399] iteration 8598 : model1 loss : 0.435439 model2 loss : 0.021703
[23:44:39.571] iteration 8599 : model1 loss : 0.440748 model2 loss : 0.030410
[23:44:39.747] iteration 8600 : model1 loss : 0.439577 model2 loss : 0.030191
[23:44:39.920] iteration 8601 : model1 loss : 0.436173 model2 loss : 0.022806
[23:44:40.101] iteration 8602 : model1 loss : 0.435054 model2 loss : 0.020600
[23:44:40.274] iteration 8603 : model1 loss : 0.438954 model2 loss : 0.025049
[23:44:40.451] iteration 8604 : model1 loss : 0.440483 model2 loss : 0.028671
[23:44:40.621] iteration 8605 : model1 loss : 0.440554 model2 loss : 0.025013
[23:44:40.798] iteration 8606 : model1 loss : 0.438926 model2 loss : 0.026727
[23:44:40.976] iteration 8607 : model1 loss : 0.437049 model2 loss : 0.025431
[23:44:41.152] iteration 8608 : model1 loss : 0.437246 model2 loss : 0.024223
[23:44:41.331] iteration 8609 : model1 loss : 0.430958 model2 loss : 0.022295
[23:44:41.507] iteration 8610 : model1 loss : 0.440175 model2 loss : 0.025312
[23:44:43.636] iteration 8611 : model1 loss : 0.441663 model2 loss : 0.025551
[23:44:43.811] iteration 8612 : model1 loss : 0.435002 model2 loss : 0.021775
[23:44:43.996] iteration 8613 : model1 loss : 0.441826 model2 loss : 0.029594
[23:44:44.170] iteration 8614 : model1 loss : 0.434083 model2 loss : 0.022659
[23:44:44.353] iteration 8615 : model1 loss : 0.435717 model2 loss : 0.023221
[23:44:44.528] iteration 8616 : model1 loss : 0.434687 model2 loss : 0.022998
[23:44:44.704] iteration 8617 : model1 loss : 0.437658 model2 loss : 0.022345
[23:44:44.877] iteration 8618 : model1 loss : 0.434262 model2 loss : 0.021556
[23:44:45.055] iteration 8619 : model1 loss : 0.439408 model2 loss : 0.025885
[23:44:45.228] iteration 8620 : model1 loss : 0.439476 model2 loss : 0.027618
[23:44:45.405] iteration 8621 : model1 loss : 0.439536 model2 loss : 0.029526
[23:44:45.578] iteration 8622 : model1 loss : 0.439442 model2 loss : 0.022178
[23:44:45.754] iteration 8623 : model1 loss : 0.435802 model2 loss : 0.025971
[23:44:45.928] iteration 8624 : model1 loss : 0.436514 model2 loss : 0.022634
[23:44:46.108] iteration 8625 : model1 loss : 0.432662 model2 loss : 0.023905
[23:44:46.281] iteration 8626 : model1 loss : 0.439858 model2 loss : 0.025082
[23:44:46.458] iteration 8627 : model1 loss : 0.434996 model2 loss : 0.024092
[23:44:46.630] iteration 8628 : model1 loss : 0.436710 model2 loss : 0.024931
[23:44:46.805] iteration 8629 : model1 loss : 0.438063 model2 loss : 0.023547
[23:44:46.977] iteration 8630 : model1 loss : 0.431660 model2 loss : 0.024145
[23:44:47.154] iteration 8631 : model1 loss : 0.439949 model2 loss : 0.024094
[23:44:49.308] iteration 8632 : model1 loss : 0.436992 model2 loss : 0.027089
[23:44:49.484] iteration 8633 : model1 loss : 0.430591 model2 loss : 0.021112
[23:44:49.660] iteration 8634 : model1 loss : 0.436493 model2 loss : 0.025940
[23:44:49.832] iteration 8635 : model1 loss : 0.434915 model2 loss : 0.025072
[23:44:50.013] iteration 8636 : model1 loss : 0.442388 model2 loss : 0.028351
[23:44:50.185] iteration 8637 : model1 loss : 0.442669 model2 loss : 0.028846
[23:44:50.365] iteration 8638 : model1 loss : 0.438124 model2 loss : 0.024340
[23:44:50.540] iteration 8639 : model1 loss : 0.437916 model2 loss : 0.023034
[23:44:50.714] iteration 8640 : model1 loss : 0.442132 model2 loss : 0.026081
[23:44:50.886] iteration 8641 : model1 loss : 0.438545 model2 loss : 0.023794
[23:44:51.065] iteration 8642 : model1 loss : 0.431151 model2 loss : 0.022835
[23:44:51.237] iteration 8643 : model1 loss : 0.435439 model2 loss : 0.024946
[23:44:51.420] iteration 8644 : model1 loss : 0.437903 model2 loss : 0.027352
[23:44:51.593] iteration 8645 : model1 loss : 0.435534 model2 loss : 0.023581
[23:44:51.769] iteration 8646 : model1 loss : 0.437881 model2 loss : 0.023960
[23:44:51.942] iteration 8647 : model1 loss : 0.436906 model2 loss : 0.023527
[23:44:52.122] iteration 8648 : model1 loss : 0.434081 model2 loss : 0.024609
[23:44:52.295] iteration 8649 : model1 loss : 0.436650 model2 loss : 0.022113
[23:44:52.479] iteration 8650 : model1 loss : 0.435226 model2 loss : 0.022484
[23:44:52.648] iteration 8651 : model1 loss : 0.437173 model2 loss : 0.020760
[23:44:52.823] iteration 8652 : model1 loss : 0.438107 model2 loss : 0.023844
[23:44:54.945] iteration 8653 : model1 loss : 0.440709 model2 loss : 0.026901
[23:44:55.119] iteration 8654 : model1 loss : 0.435606 model2 loss : 0.022571
[23:44:55.299] iteration 8655 : model1 loss : 0.439456 model2 loss : 0.021431
[23:44:55.473] iteration 8656 : model1 loss : 0.435504 model2 loss : 0.025557
[23:44:55.649] iteration 8657 : model1 loss : 0.435141 model2 loss : 0.020043
[23:44:55.819] iteration 8658 : model1 loss : 0.437965 model2 loss : 0.023216
[23:44:56.000] iteration 8659 : model1 loss : 0.436927 model2 loss : 0.027364
[23:44:56.172] iteration 8660 : model1 loss : 0.439934 model2 loss : 0.024492
[23:44:56.351] iteration 8661 : model1 loss : 0.439307 model2 loss : 0.029415
[23:44:56.525] iteration 8662 : model1 loss : 0.433906 model2 loss : 0.025077
[23:44:56.698] iteration 8663 : model1 loss : 0.434718 model2 loss : 0.019481
[23:44:56.871] iteration 8664 : model1 loss : 0.436448 model2 loss : 0.020650
[23:44:57.047] iteration 8665 : model1 loss : 0.434551 model2 loss : 0.026450
[23:44:57.221] iteration 8666 : model1 loss : 0.435864 model2 loss : 0.023272
[23:44:57.401] iteration 8667 : model1 loss : 0.436815 model2 loss : 0.023204
[23:44:57.574] iteration 8668 : model1 loss : 0.436444 model2 loss : 0.022738
[23:44:57.748] iteration 8669 : model1 loss : 0.439925 model2 loss : 0.024400
[23:44:57.922] iteration 8670 : model1 loss : 0.437315 model2 loss : 0.022965
[23:44:58.097] iteration 8671 : model1 loss : 0.436519 model2 loss : 0.024954
[23:44:58.268] iteration 8672 : model1 loss : 0.439055 model2 loss : 0.025442
[23:44:58.445] iteration 8673 : model1 loss : 0.435652 model2 loss : 0.029993
[23:45:00.604] iteration 8674 : model1 loss : 0.437172 model2 loss : 0.022298
[23:45:00.778] iteration 8675 : model1 loss : 0.440988 model2 loss : 0.023906
[23:45:00.960] iteration 8676 : model1 loss : 0.439060 model2 loss : 0.024523
[23:45:01.132] iteration 8677 : model1 loss : 0.437358 model2 loss : 0.022261
[23:45:01.310] iteration 8678 : model1 loss : 0.435242 model2 loss : 0.024485
[23:45:01.485] iteration 8679 : model1 loss : 0.434415 model2 loss : 0.023865
[23:45:01.659] iteration 8680 : model1 loss : 0.437528 model2 loss : 0.027795
[23:45:01.832] iteration 8681 : model1 loss : 0.434473 model2 loss : 0.022056
[23:45:02.015] iteration 8682 : model1 loss : 0.434753 model2 loss : 0.020015
[23:45:02.187] iteration 8683 : model1 loss : 0.437102 model2 loss : 0.024837
[23:45:02.369] iteration 8684 : model1 loss : 0.434742 model2 loss : 0.024085
[23:45:02.543] iteration 8685 : model1 loss : 0.435985 model2 loss : 0.023076
[23:45:02.717] iteration 8686 : model1 loss : 0.434533 model2 loss : 0.021926
[23:45:02.891] iteration 8687 : model1 loss : 0.437797 model2 loss : 0.023222
[23:45:03.069] iteration 8688 : model1 loss : 0.433839 model2 loss : 0.022971
[23:45:03.241] iteration 8689 : model1 loss : 0.437045 model2 loss : 0.026661
[23:45:03.420] iteration 8690 : model1 loss : 0.440539 model2 loss : 0.026014
[23:45:03.596] iteration 8691 : model1 loss : 0.438317 model2 loss : 0.024252
[23:45:03.771] iteration 8692 : model1 loss : 0.438555 model2 loss : 0.027351
[23:45:03.946] iteration 8693 : model1 loss : 0.436029 model2 loss : 0.020496
[23:45:04.126] iteration 8694 : model1 loss : 0.434190 model2 loss : 0.021202
[23:45:06.270] iteration 8695 : model1 loss : 0.436957 model2 loss : 0.024926
[23:45:06.445] iteration 8696 : model1 loss : 0.435742 model2 loss : 0.022354
[23:45:06.627] iteration 8697 : model1 loss : 0.437848 model2 loss : 0.024202
[23:45:06.800] iteration 8698 : model1 loss : 0.440097 model2 loss : 0.023211
[23:45:06.980] iteration 8699 : model1 loss : 0.437036 model2 loss : 0.023017
[23:45:07.151] iteration 8700 : model1 loss : 0.434145 model2 loss : 0.021561
[23:45:07.336] iteration 8701 : model1 loss : 0.435716 model2 loss : 0.023652
[23:45:07.516] iteration 8702 : model1 loss : 0.436547 model2 loss : 0.024783
[23:45:07.693] iteration 8703 : model1 loss : 0.434518 model2 loss : 0.024757
[23:45:07.867] iteration 8704 : model1 loss : 0.433158 model2 loss : 0.020846
[23:45:08.047] iteration 8705 : model1 loss : 0.437838 model2 loss : 0.023805
[23:45:08.222] iteration 8706 : model1 loss : 0.438869 model2 loss : 0.024541
[23:45:08.404] iteration 8707 : model1 loss : 0.436158 model2 loss : 0.021661
[23:45:08.577] iteration 8708 : model1 loss : 0.434221 model2 loss : 0.023064
[23:45:08.755] iteration 8709 : model1 loss : 0.439316 model2 loss : 0.031195
[23:45:08.927] iteration 8710 : model1 loss : 0.439459 model2 loss : 0.022247
[23:45:09.105] iteration 8711 : model1 loss : 0.435269 model2 loss : 0.020028
[23:45:09.277] iteration 8712 : model1 loss : 0.441912 model2 loss : 0.024996
[23:45:09.458] iteration 8713 : model1 loss : 0.437505 model2 loss : 0.026010
[23:45:09.629] iteration 8714 : model1 loss : 0.436547 model2 loss : 0.024384
[23:45:09.800] iteration 8715 : model1 loss : 0.436428 model2 loss : 0.027593
[23:45:11.939] iteration 8716 : model1 loss : 0.438345 model2 loss : 0.024355
[23:45:12.117] iteration 8717 : model1 loss : 0.438335 model2 loss : 0.024090
[23:45:12.295] iteration 8718 : model1 loss : 0.438243 model2 loss : 0.019899
[23:45:12.475] iteration 8719 : model1 loss : 0.433917 model2 loss : 0.024574
[23:45:12.649] iteration 8720 : model1 loss : 0.434396 model2 loss : 0.024921
[23:45:12.821] iteration 8721 : model1 loss : 0.435605 model2 loss : 0.026157
[23:45:12.998] iteration 8722 : model1 loss : 0.432018 model2 loss : 0.023828
[23:45:13.171] iteration 8723 : model1 loss : 0.438137 model2 loss : 0.024205
[23:45:13.352] iteration 8724 : model1 loss : 0.435242 model2 loss : 0.025211
[23:45:13.529] iteration 8725 : model1 loss : 0.438050 model2 loss : 0.026463
[23:45:13.704] iteration 8726 : model1 loss : 0.437449 model2 loss : 0.024114
[23:45:13.878] iteration 8727 : model1 loss : 0.438378 model2 loss : 0.027318
[23:45:14.058] iteration 8728 : model1 loss : 0.439377 model2 loss : 0.025777
[23:45:14.234] iteration 8729 : model1 loss : 0.437509 model2 loss : 0.022855
[23:45:14.413] iteration 8730 : model1 loss : 0.438820 model2 loss : 0.023786
[23:45:14.589] iteration 8731 : model1 loss : 0.436371 model2 loss : 0.024975
[23:45:14.763] iteration 8732 : model1 loss : 0.438783 model2 loss : 0.024182
[23:45:14.939] iteration 8733 : model1 loss : 0.437131 model2 loss : 0.023740
[23:45:15.117] iteration 8734 : model1 loss : 0.440812 model2 loss : 0.024809
[23:45:15.287] iteration 8735 : model1 loss : 0.435932 model2 loss : 0.022567
[23:45:15.463] iteration 8736 : model1 loss : 0.437419 model2 loss : 0.023043
[23:45:17.612] iteration 8737 : model1 loss : 0.435953 model2 loss : 0.024469
[23:45:17.783] iteration 8738 : model1 loss : 0.439652 model2 loss : 0.026406
[23:45:17.963] iteration 8739 : model1 loss : 0.438765 model2 loss : 0.023746
[23:45:18.135] iteration 8740 : model1 loss : 0.435959 model2 loss : 0.022194
[23:45:18.315] iteration 8741 : model1 loss : 0.435809 model2 loss : 0.024374
[23:45:18.491] iteration 8742 : model1 loss : 0.434937 model2 loss : 0.024201
[23:45:18.665] iteration 8743 : model1 loss : 0.438090 model2 loss : 0.023358
[23:45:18.837] iteration 8744 : model1 loss : 0.440239 model2 loss : 0.024859
[23:45:19.015] iteration 8745 : model1 loss : 0.434402 model2 loss : 0.019735
[23:45:19.187] iteration 8746 : model1 loss : 0.437038 model2 loss : 0.025953
[23:45:19.364] iteration 8747 : model1 loss : 0.437169 model2 loss : 0.023494
[23:45:19.539] iteration 8748 : model1 loss : 0.442651 model2 loss : 0.024013
[23:45:19.716] iteration 8749 : model1 loss : 0.438117 model2 loss : 0.025059
[23:45:19.888] iteration 8750 : model1 loss : 0.434168 model2 loss : 0.021252
[23:45:20.067] iteration 8751 : model1 loss : 0.437776 model2 loss : 0.024573
[23:45:20.239] iteration 8752 : model1 loss : 0.436675 model2 loss : 0.025012
[23:45:20.420] iteration 8753 : model1 loss : 0.436897 model2 loss : 0.024887
[23:45:20.595] iteration 8754 : model1 loss : 0.440211 model2 loss : 0.026396
[23:45:20.771] iteration 8755 : model1 loss : 0.439065 model2 loss : 0.023653
[23:45:20.943] iteration 8756 : model1 loss : 0.435918 model2 loss : 0.023301
[23:45:21.117] iteration 8757 : model1 loss : 0.435175 model2 loss : 0.022539
[23:45:23.279] iteration 8758 : model1 loss : 0.435302 model2 loss : 0.022545
[23:45:23.460] iteration 8759 : model1 loss : 0.441817 model2 loss : 0.028490
[23:45:23.637] iteration 8760 : model1 loss : 0.442023 model2 loss : 0.027777
[23:45:23.805] iteration 8761 : model1 loss : 0.441444 model2 loss : 0.023785
[23:45:23.990] iteration 8762 : model1 loss : 0.438489 model2 loss : 0.026325
[23:45:24.163] iteration 8763 : model1 loss : 0.438054 model2 loss : 0.025341
[23:45:24.342] iteration 8764 : model1 loss : 0.437525 model2 loss : 0.024202
[23:45:24.518] iteration 8765 : model1 loss : 0.443914 model2 loss : 0.030126
[23:45:24.695] iteration 8766 : model1 loss : 0.435591 model2 loss : 0.023753
[23:45:24.866] iteration 8767 : model1 loss : 0.432285 model2 loss : 0.022385
[23:45:25.043] iteration 8768 : model1 loss : 0.436510 model2 loss : 0.024700
[23:45:25.216] iteration 8769 : model1 loss : 0.430817 model2 loss : 0.022699
[23:45:25.396] iteration 8770 : model1 loss : 0.439975 model2 loss : 0.023223
[23:45:25.570] iteration 8771 : model1 loss : 0.436287 model2 loss : 0.024244
[23:45:25.745] iteration 8772 : model1 loss : 0.439327 model2 loss : 0.026182
[23:45:25.920] iteration 8773 : model1 loss : 0.437810 model2 loss : 0.022045
[23:45:26.099] iteration 8774 : model1 loss : 0.440001 model2 loss : 0.025145
[23:45:26.272] iteration 8775 : model1 loss : 0.435274 model2 loss : 0.020351
[23:45:26.452] iteration 8776 : model1 loss : 0.432233 model2 loss : 0.023113
[23:45:26.620] iteration 8777 : model1 loss : 0.433180 model2 loss : 0.022272
[23:45:26.792] iteration 8778 : model1 loss : 0.436730 model2 loss : 0.020879
[23:45:28.965] iteration 8779 : model1 loss : 0.432711 model2 loss : 0.023484
[23:45:29.138] iteration 8780 : model1 loss : 0.439653 model2 loss : 0.027167
[23:45:29.317] iteration 8781 : model1 loss : 0.436051 model2 loss : 0.022728
[23:45:29.492] iteration 8782 : model1 loss : 0.435640 model2 loss : 0.019811
[23:45:29.669] iteration 8783 : model1 loss : 0.437195 model2 loss : 0.022422
[23:45:29.839] iteration 8784 : model1 loss : 0.442573 model2 loss : 0.026496
[23:45:30.017] iteration 8785 : model1 loss : 0.438857 model2 loss : 0.025169
[23:45:30.190] iteration 8786 : model1 loss : 0.439820 model2 loss : 0.022554
[23:45:30.366] iteration 8787 : model1 loss : 0.439226 model2 loss : 0.026333
[23:45:30.544] iteration 8788 : model1 loss : 0.440406 model2 loss : 0.025366
[23:45:30.721] iteration 8789 : model1 loss : 0.431751 model2 loss : 0.024151
[23:45:30.891] iteration 8790 : model1 loss : 0.437858 model2 loss : 0.023871
[23:45:31.071] iteration 8791 : model1 loss : 0.435551 model2 loss : 0.019730
[23:45:31.244] iteration 8792 : model1 loss : 0.440501 model2 loss : 0.024709
[23:45:31.433] iteration 8793 : model1 loss : 0.434909 model2 loss : 0.025661
[23:45:31.608] iteration 8794 : model1 loss : 0.435773 model2 loss : 0.025531
[23:45:31.785] iteration 8795 : model1 loss : 0.432771 model2 loss : 0.023349
[23:45:31.958] iteration 8796 : model1 loss : 0.436715 model2 loss : 0.023132
[23:45:32.137] iteration 8797 : model1 loss : 0.438278 model2 loss : 0.023329
[23:45:32.309] iteration 8798 : model1 loss : 0.435726 model2 loss : 0.021737
[23:45:32.490] iteration 8799 : model1 loss : 0.436137 model2 loss : 0.025204
[23:45:34.659] iteration 8800 : model1 loss : 0.434624 model2 loss : 0.021725
[23:45:34.837] iteration 8801 : model1 loss : 0.438463 model2 loss : 0.024979
[23:45:35.021] iteration 8802 : model1 loss : 0.436392 model2 loss : 0.026582
[23:45:35.193] iteration 8803 : model1 loss : 0.434836 model2 loss : 0.023455
[23:45:35.368] iteration 8804 : model1 loss : 0.440173 model2 loss : 0.022997
[23:45:35.542] iteration 8805 : model1 loss : 0.437873 model2 loss : 0.022112
[23:45:35.717] iteration 8806 : model1 loss : 0.437255 model2 loss : 0.022831
[23:45:35.895] iteration 8807 : model1 loss : 0.439247 model2 loss : 0.023156
[23:45:36.072] iteration 8808 : model1 loss : 0.435513 model2 loss : 0.022919
[23:45:36.245] iteration 8809 : model1 loss : 0.439638 model2 loss : 0.023007
[23:45:36.426] iteration 8810 : model1 loss : 0.440335 model2 loss : 0.023562
[23:45:36.603] iteration 8811 : model1 loss : 0.437054 model2 loss : 0.027775
[23:45:36.778] iteration 8812 : model1 loss : 0.435528 model2 loss : 0.023632
[23:45:36.952] iteration 8813 : model1 loss : 0.439690 model2 loss : 0.025841
[23:45:37.131] iteration 8814 : model1 loss : 0.435487 model2 loss : 0.024702
[23:45:37.304] iteration 8815 : model1 loss : 0.434135 model2 loss : 0.022370
[23:45:37.484] iteration 8816 : model1 loss : 0.439649 model2 loss : 0.023534
[23:45:37.655] iteration 8817 : model1 loss : 0.437481 model2 loss : 0.021819
[23:45:37.830] iteration 8818 : model1 loss : 0.433033 model2 loss : 0.020860
[23:45:38.005] iteration 8819 : model1 loss : 0.436639 model2 loss : 0.023901
[23:45:38.179] iteration 8820 : model1 loss : 0.436639 model2 loss : 0.021396
[23:45:40.330] iteration 8821 : model1 loss : 0.436728 model2 loss : 0.025565
[23:45:40.509] iteration 8822 : model1 loss : 0.434509 model2 loss : 0.022488
[23:45:40.688] iteration 8823 : model1 loss : 0.437267 model2 loss : 0.027048
[23:45:40.858] iteration 8824 : model1 loss : 0.439390 model2 loss : 0.025046
[23:45:41.038] iteration 8825 : model1 loss : 0.441500 model2 loss : 0.026049
[23:45:41.211] iteration 8826 : model1 loss : 0.439034 model2 loss : 0.021531
[23:45:41.391] iteration 8827 : model1 loss : 0.437295 model2 loss : 0.021263
[23:45:41.565] iteration 8828 : model1 loss : 0.433077 model2 loss : 0.022880
[23:45:41.739] iteration 8829 : model1 loss : 0.438261 model2 loss : 0.023946
[23:45:41.909] iteration 8830 : model1 loss : 0.430412 model2 loss : 0.021990
[23:45:42.090] iteration 8831 : model1 loss : 0.443501 model2 loss : 0.024568
[23:45:42.265] iteration 8832 : model1 loss : 0.439271 model2 loss : 0.025854
[23:45:42.445] iteration 8833 : model1 loss : 0.436193 model2 loss : 0.023067
[23:45:42.617] iteration 8834 : model1 loss : 0.434315 model2 loss : 0.021033
[23:45:42.793] iteration 8835 : model1 loss : 0.442386 model2 loss : 0.029849
[23:45:42.969] iteration 8836 : model1 loss : 0.437934 model2 loss : 0.027705
[23:45:43.147] iteration 8837 : model1 loss : 0.440772 model2 loss : 0.025644
[23:45:43.326] iteration 8838 : model1 loss : 0.435943 model2 loss : 0.026048
[23:45:43.506] iteration 8839 : model1 loss : 0.448451 model2 loss : 0.030280
[23:45:43.675] iteration 8840 : model1 loss : 0.434615 model2 loss : 0.026888
[23:45:43.850] iteration 8841 : model1 loss : 0.436531 model2 loss : 0.021640
[23:45:45.996] iteration 8842 : model1 loss : 0.436687 model2 loss : 0.024258
[23:45:46.174] iteration 8843 : model1 loss : 0.435210 model2 loss : 0.023616
[23:45:46.355] iteration 8844 : model1 loss : 0.437157 model2 loss : 0.021440
[23:45:46.530] iteration 8845 : model1 loss : 0.439229 model2 loss : 0.023915
[23:45:46.708] iteration 8846 : model1 loss : 0.442861 model2 loss : 0.030807
[23:45:46.877] iteration 8847 : model1 loss : 0.433408 model2 loss : 0.022099
[23:45:47.055] iteration 8848 : model1 loss : 0.434703 model2 loss : 0.021720
[23:45:47.229] iteration 8849 : model1 loss : 0.439769 model2 loss : 0.024879
[23:45:47.409] iteration 8850 : model1 loss : 0.436543 model2 loss : 0.019565
[23:45:47.584] iteration 8851 : model1 loss : 0.434284 model2 loss : 0.021688
[23:45:47.762] iteration 8852 : model1 loss : 0.438820 model2 loss : 0.024162
[23:45:47.934] iteration 8853 : model1 loss : 0.439324 model2 loss : 0.024706
[23:45:48.113] iteration 8854 : model1 loss : 0.440224 model2 loss : 0.022651
[23:45:48.284] iteration 8855 : model1 loss : 0.438415 model2 loss : 0.024972
[23:45:48.463] iteration 8856 : model1 loss : 0.438686 model2 loss : 0.024646
[23:45:48.633] iteration 8857 : model1 loss : 0.435877 model2 loss : 0.024706
[23:45:48.808] iteration 8858 : model1 loss : 0.441790 model2 loss : 0.027817
[23:45:48.985] iteration 8859 : model1 loss : 0.441323 model2 loss : 0.026409
[23:45:49.164] iteration 8860 : model1 loss : 0.439199 model2 loss : 0.021066
[23:45:49.336] iteration 8861 : model1 loss : 0.436389 model2 loss : 0.023074
[23:45:49.513] iteration 8862 : model1 loss : 0.438815 model2 loss : 0.028207
[23:45:51.646] iteration 8863 : model1 loss : 0.436569 model2 loss : 0.023790
[23:45:51.818] iteration 8864 : model1 loss : 0.439759 model2 loss : 0.022061
[23:45:51.998] iteration 8865 : model1 loss : 0.439591 model2 loss : 0.025422
[23:45:52.173] iteration 8866 : model1 loss : 0.433875 model2 loss : 0.023394
[23:45:52.350] iteration 8867 : model1 loss : 0.437988 model2 loss : 0.023885
[23:45:52.529] iteration 8868 : model1 loss : 0.440225 model2 loss : 0.028055
[23:45:52.705] iteration 8869 : model1 loss : 0.435094 model2 loss : 0.022264
[23:45:52.876] iteration 8870 : model1 loss : 0.436577 model2 loss : 0.022555
[23:45:53.053] iteration 8871 : model1 loss : 0.438215 model2 loss : 0.021452
[23:45:53.227] iteration 8872 : model1 loss : 0.439232 model2 loss : 0.023173
[23:45:53.403] iteration 8873 : model1 loss : 0.437571 model2 loss : 0.024980
[23:45:53.578] iteration 8874 : model1 loss : 0.437018 model2 loss : 0.023113
[23:45:53.756] iteration 8875 : model1 loss : 0.438751 model2 loss : 0.024909
[23:45:53.928] iteration 8876 : model1 loss : 0.440210 model2 loss : 0.023634
[23:45:54.109] iteration 8877 : model1 loss : 0.435208 model2 loss : 0.023850
[23:45:54.284] iteration 8878 : model1 loss : 0.442940 model2 loss : 0.029422
[23:45:54.462] iteration 8879 : model1 loss : 0.433478 model2 loss : 0.022576
[23:45:54.634] iteration 8880 : model1 loss : 0.436342 model2 loss : 0.025529
[23:45:54.810] iteration 8881 : model1 loss : 0.436015 model2 loss : 0.024563
[23:45:54.982] iteration 8882 : model1 loss : 0.439969 model2 loss : 0.024415
[23:45:55.161] iteration 8883 : model1 loss : 0.437817 model2 loss : 0.023819
[23:45:57.298] iteration 8884 : model1 loss : 0.437920 model2 loss : 0.022023
[23:45:57.475] iteration 8885 : model1 loss : 0.438252 model2 loss : 0.023091
[23:45:57.651] iteration 8886 : model1 loss : 0.435917 model2 loss : 0.023813
[23:45:57.820] iteration 8887 : model1 loss : 0.439903 model2 loss : 0.023510
[23:45:58.001] iteration 8888 : model1 loss : 0.436330 model2 loss : 0.021966
[23:45:58.171] iteration 8889 : model1 loss : 0.439522 model2 loss : 0.022457
[23:45:58.354] iteration 8890 : model1 loss : 0.437540 model2 loss : 0.022636
[23:45:58.529] iteration 8891 : model1 loss : 0.436847 model2 loss : 0.021849
[23:45:58.706] iteration 8892 : model1 loss : 0.434284 model2 loss : 0.023505
[23:45:58.877] iteration 8893 : model1 loss : 0.441197 model2 loss : 0.025812
[23:45:59.058] iteration 8894 : model1 loss : 0.437771 model2 loss : 0.024464
[23:45:59.232] iteration 8895 : model1 loss : 0.440122 model2 loss : 0.022607
[23:45:59.410] iteration 8896 : model1 loss : 0.434795 model2 loss : 0.022974
[23:45:59.586] iteration 8897 : model1 loss : 0.435614 model2 loss : 0.024076
[23:45:59.764] iteration 8898 : model1 loss : 0.441208 model2 loss : 0.025432
[23:45:59.935] iteration 8899 : model1 loss : 0.429980 model2 loss : 0.020862
[23:46:00.118] iteration 8900 : model1 loss : 0.436834 model2 loss : 0.025570
[23:46:00.292] iteration 8901 : model1 loss : 0.435657 model2 loss : 0.020591
[23:46:00.473] iteration 8902 : model1 loss : 0.441319 model2 loss : 0.026079
[23:46:00.642] iteration 8903 : model1 loss : 0.438385 model2 loss : 0.023414
[23:46:00.819] iteration 8904 : model1 loss : 0.435534 model2 loss : 0.020989
[23:46:02.998] iteration 8905 : model1 loss : 0.435510 model2 loss : 0.024019
[23:46:03.172] iteration 8906 : model1 loss : 0.436229 model2 loss : 0.025582
[23:46:03.353] iteration 8907 : model1 loss : 0.436237 model2 loss : 0.024213
[23:46:03.528] iteration 8908 : model1 loss : 0.437367 model2 loss : 0.022171
[23:46:03.702] iteration 8909 : model1 loss : 0.438296 model2 loss : 0.025902
[23:46:03.872] iteration 8910 : model1 loss : 0.438354 model2 loss : 0.025820
[23:46:04.052] iteration 8911 : model1 loss : 0.438235 model2 loss : 0.025033
[23:46:04.226] iteration 8912 : model1 loss : 0.436233 model2 loss : 0.023737
[23:46:04.402] iteration 8913 : model1 loss : 0.443035 model2 loss : 0.029835
[23:46:04.577] iteration 8914 : model1 loss : 0.438235 model2 loss : 0.024813
[23:46:04.754] iteration 8915 : model1 loss : 0.436757 model2 loss : 0.022668
[23:46:04.926] iteration 8916 : model1 loss : 0.436076 model2 loss : 0.024545
[23:46:05.103] iteration 8917 : model1 loss : 0.437858 model2 loss : 0.028668
[23:46:05.279] iteration 8918 : model1 loss : 0.436133 model2 loss : 0.022541
[23:46:05.457] iteration 8919 : model1 loss : 0.436989 model2 loss : 0.022597
[23:46:05.629] iteration 8920 : model1 loss : 0.438007 model2 loss : 0.022826
[23:46:05.805] iteration 8921 : model1 loss : 0.432017 model2 loss : 0.021643
[23:46:05.975] iteration 8922 : model1 loss : 0.439656 model2 loss : 0.024374
[23:46:06.156] iteration 8923 : model1 loss : 0.435642 model2 loss : 0.024726
[23:46:06.328] iteration 8924 : model1 loss : 0.435428 model2 loss : 0.022983
[23:46:06.506] iteration 8925 : model1 loss : 0.439021 model2 loss : 0.022390
[23:46:08.670] iteration 8926 : model1 loss : 0.436375 model2 loss : 0.021710
[23:46:08.841] iteration 8927 : model1 loss : 0.432647 model2 loss : 0.021207
[23:46:09.019] iteration 8928 : model1 loss : 0.440522 model2 loss : 0.027195
[23:46:09.191] iteration 8929 : model1 loss : 0.436310 model2 loss : 0.024417
[23:46:09.371] iteration 8930 : model1 loss : 0.438861 model2 loss : 0.025907
[23:46:09.544] iteration 8931 : model1 loss : 0.433895 model2 loss : 0.022257
[23:46:09.720] iteration 8932 : model1 loss : 0.436271 model2 loss : 0.023904
[23:46:09.892] iteration 8933 : model1 loss : 0.436728 model2 loss : 0.023553
[23:46:10.070] iteration 8934 : model1 loss : 0.438780 model2 loss : 0.024105
[23:46:10.243] iteration 8935 : model1 loss : 0.440030 model2 loss : 0.025909
[23:46:10.422] iteration 8936 : model1 loss : 0.434802 model2 loss : 0.023421
[23:46:10.599] iteration 8937 : model1 loss : 0.437647 model2 loss : 0.022724
[23:46:10.778] iteration 8938 : model1 loss : 0.436277 model2 loss : 0.026399
[23:46:10.948] iteration 8939 : model1 loss : 0.433745 model2 loss : 0.023388
[23:46:11.127] iteration 8940 : model1 loss : 0.436872 model2 loss : 0.024013
[23:46:11.303] iteration 8941 : model1 loss : 0.438131 model2 loss : 0.024113
[23:46:11.483] iteration 8942 : model1 loss : 0.438160 model2 loss : 0.024735
[23:46:11.657] iteration 8943 : model1 loss : 0.435844 model2 loss : 0.025477
[23:46:11.835] iteration 8944 : model1 loss : 0.436351 model2 loss : 0.024305
[23:46:12.008] iteration 8945 : model1 loss : 0.438833 model2 loss : 0.024165
[23:46:12.186] iteration 8946 : model1 loss : 0.441110 model2 loss : 0.026938
[23:46:14.371] iteration 8947 : model1 loss : 0.440466 model2 loss : 0.024648
[23:46:14.550] iteration 8948 : model1 loss : 0.431871 model2 loss : 0.023121
[23:46:14.726] iteration 8949 : model1 loss : 0.437198 model2 loss : 0.022286
[23:46:14.897] iteration 8950 : model1 loss : 0.440367 model2 loss : 0.026069
[23:46:15.075] iteration 8951 : model1 loss : 0.441468 model2 loss : 0.024783
[23:46:15.249] iteration 8952 : model1 loss : 0.441271 model2 loss : 0.028345
[23:46:15.427] iteration 8953 : model1 loss : 0.437301 model2 loss : 0.024260
[23:46:15.602] iteration 8954 : model1 loss : 0.441540 model2 loss : 0.024639
[23:46:15.777] iteration 8955 : model1 loss : 0.437516 model2 loss : 0.022701
[23:46:15.947] iteration 8956 : model1 loss : 0.437673 model2 loss : 0.022705
[23:46:16.129] iteration 8957 : model1 loss : 0.437508 model2 loss : 0.021800
[23:46:16.303] iteration 8958 : model1 loss : 0.434380 model2 loss : 0.023011
[23:46:16.480] iteration 8959 : model1 loss : 0.443931 model2 loss : 0.022108
[23:46:16.655] iteration 8960 : model1 loss : 0.437631 model2 loss : 0.024060
[23:46:16.831] iteration 8961 : model1 loss : 0.439146 model2 loss : 0.023599
[23:46:17.007] iteration 8962 : model1 loss : 0.437824 model2 loss : 0.023649
[23:46:17.184] iteration 8963 : model1 loss : 0.442125 model2 loss : 0.023269
[23:46:17.360] iteration 8964 : model1 loss : 0.441821 model2 loss : 0.025025
[23:46:17.539] iteration 8965 : model1 loss : 0.444391 model2 loss : 0.025492
[23:46:17.710] iteration 8966 : model1 loss : 0.436093 model2 loss : 0.020998
[23:46:17.883] iteration 8967 : model1 loss : 0.436321 model2 loss : 0.021713
[23:46:20.012] iteration 8968 : model1 loss : 0.437415 model2 loss : 0.020958
[23:46:20.187] iteration 8969 : model1 loss : 0.440734 model2 loss : 0.022324
[23:46:20.369] iteration 8970 : model1 loss : 0.435539 model2 loss : 0.020748
[23:46:20.544] iteration 8971 : model1 loss : 0.444148 model2 loss : 0.021556
[23:46:20.721] iteration 8972 : model1 loss : 0.440417 model2 loss : 0.023898
[23:46:20.890] iteration 8973 : model1 loss : 0.438440 model2 loss : 0.020811
[23:46:21.071] iteration 8974 : model1 loss : 0.437057 model2 loss : 0.021929
[23:46:21.242] iteration 8975 : model1 loss : 0.442574 model2 loss : 0.023026
[23:46:21.421] iteration 8976 : model1 loss : 0.438455 model2 loss : 0.022960
[23:46:21.597] iteration 8977 : model1 loss : 0.442745 model2 loss : 0.023895
[23:46:21.773] iteration 8978 : model1 loss : 0.436677 model2 loss : 0.022684
[23:46:21.944] iteration 8979 : model1 loss : 0.439446 model2 loss : 0.026619
[23:46:22.122] iteration 8980 : model1 loss : 0.440876 model2 loss : 0.025688
[23:46:22.296] iteration 8981 : model1 loss : 0.441055 model2 loss : 0.025244
[23:46:22.478] iteration 8982 : model1 loss : 0.432340 model2 loss : 0.020754
[23:46:22.650] iteration 8983 : model1 loss : 0.435789 model2 loss : 0.022551
[23:46:22.827] iteration 8984 : model1 loss : 0.446865 model2 loss : 0.026601
[23:46:23.000] iteration 8985 : model1 loss : 0.435387 model2 loss : 0.020621
[23:46:23.178] iteration 8986 : model1 loss : 0.441415 model2 loss : 0.024116
[23:46:23.355] iteration 8987 : model1 loss : 0.437517 model2 loss : 0.024215
[23:46:23.533] iteration 8988 : model1 loss : 0.439894 model2 loss : 0.022431
[23:46:25.671] iteration 8989 : model1 loss : 0.438969 model2 loss : 0.022993
[23:46:25.843] iteration 8990 : model1 loss : 0.436246 model2 loss : 0.022163
[23:46:26.023] iteration 8991 : model1 loss : 0.437836 model2 loss : 0.024568
[23:46:26.198] iteration 8992 : model1 loss : 0.441589 model2 loss : 0.023594
[23:46:26.374] iteration 8993 : model1 loss : 0.437201 model2 loss : 0.022160
[23:46:26.549] iteration 8994 : model1 loss : 0.440647 model2 loss : 0.029735
[23:46:26.728] iteration 8995 : model1 loss : 0.439394 model2 loss : 0.021541
[23:46:26.898] iteration 8996 : model1 loss : 0.432309 model2 loss : 0.021739
[23:46:27.075] iteration 8997 : model1 loss : 0.438275 model2 loss : 0.022944
[23:46:27.250] iteration 8998 : model1 loss : 0.439516 model2 loss : 0.023820
[23:46:27.430] iteration 8999 : model1 loss : 0.442129 model2 loss : 0.024542
[23:46:27.608] iteration 9000 : model1 loss : 0.438563 model2 loss : 0.021703
[23:46:36.811] iteration 9000 : model1_mean_dice : 0.800582 model1_mean_hd95 : 16.096895
[23:46:46.043] iteration 9000 : model2_mean_dice : 0.847010 model2_mean_hd95 : 12.602932
[23:46:46.072] save model1 to ../model/ACDC/EVILv1_kl0.5_tau0.25_14_1337/unet\model1_iter_9000.pth
[23:46:46.100] save model2 to ../model/ACDC/EVILv1_kl0.5_tau0.25_14_1337/unet\model2_iter_9000.pth
[23:46:46.283] iteration 9001 : model1 loss : 0.438310 model2 loss : 0.025162
[23:46:46.458] iteration 9002 : model1 loss : 0.434468 model2 loss : 0.023081
[23:46:46.639] iteration 9003 : model1 loss : 0.440584 model2 loss : 0.026308
[23:46:46.809] iteration 9004 : model1 loss : 0.440638 model2 loss : 0.023383
[23:46:46.985] iteration 9005 : model1 loss : 0.433889 model2 loss : 0.020371
[23:46:47.158] iteration 9006 : model1 loss : 0.437552 model2 loss : 0.022924
[23:46:47.334] iteration 9007 : model1 loss : 0.433845 model2 loss : 0.021953
[23:46:47.505] iteration 9008 : model1 loss : 0.441759 model2 loss : 0.029263
[23:46:47.676] iteration 9009 : model1 loss : 0.435660 model2 loss : 0.021454
[23:46:49.849] iteration 9010 : model1 loss : 0.435988 model2 loss : 0.022885
[23:46:50.026] iteration 9011 : model1 loss : 0.436651 model2 loss : 0.022245
[23:46:50.205] iteration 9012 : model1 loss : 0.438220 model2 loss : 0.021064
[23:46:50.377] iteration 9013 : model1 loss : 0.433586 model2 loss : 0.023852
[23:46:50.556] iteration 9014 : model1 loss : 0.436117 model2 loss : 0.023162
[23:46:50.729] iteration 9015 : model1 loss : 0.434156 model2 loss : 0.022257
[23:46:50.902] iteration 9016 : model1 loss : 0.437202 model2 loss : 0.024386
[23:46:51.071] iteration 9017 : model1 loss : 0.438528 model2 loss : 0.022282
[23:46:51.247] iteration 9018 : model1 loss : 0.435722 model2 loss : 0.023195
[23:46:51.420] iteration 9019 : model1 loss : 0.437244 model2 loss : 0.021486
[23:46:51.599] iteration 9020 : model1 loss : 0.441694 model2 loss : 0.027234
[23:46:51.769] iteration 9021 : model1 loss : 0.441573 model2 loss : 0.024543
[23:46:51.946] iteration 9022 : model1 loss : 0.442084 model2 loss : 0.023394
[23:46:52.118] iteration 9023 : model1 loss : 0.437296 model2 loss : 0.023659
[23:46:52.297] iteration 9024 : model1 loss : 0.433311 model2 loss : 0.021016
[23:46:52.474] iteration 9025 : model1 loss : 0.441356 model2 loss : 0.022917
[23:46:52.652] iteration 9026 : model1 loss : 0.436980 model2 loss : 0.022386
[23:46:52.833] iteration 9027 : model1 loss : 0.436712 model2 loss : 0.024086
[23:46:53.007] iteration 9028 : model1 loss : 0.436026 model2 loss : 0.020844
[23:46:53.184] iteration 9029 : model1 loss : 0.437260 model2 loss : 0.025656
[23:46:53.360] iteration 9030 : model1 loss : 0.439512 model2 loss : 0.024004
[23:46:55.519] iteration 9031 : model1 loss : 0.435706 model2 loss : 0.023761
[23:46:55.694] iteration 9032 : model1 loss : 0.434337 model2 loss : 0.020579
[23:46:55.871] iteration 9033 : model1 loss : 0.436344 model2 loss : 0.022601
[23:46:56.044] iteration 9034 : model1 loss : 0.440968 model2 loss : 0.022772
[23:46:56.222] iteration 9035 : model1 loss : 0.435177 model2 loss : 0.021413
[23:46:56.394] iteration 9036 : model1 loss : 0.435053 model2 loss : 0.020435
[23:46:56.570] iteration 9037 : model1 loss : 0.435172 model2 loss : 0.021831
[23:46:56.744] iteration 9038 : model1 loss : 0.440122 model2 loss : 0.026366
[23:46:56.921] iteration 9039 : model1 loss : 0.442796 model2 loss : 0.024119
[23:46:57.098] iteration 9040 : model1 loss : 0.436039 model2 loss : 0.021881
[23:46:57.275] iteration 9041 : model1 loss : 0.436548 model2 loss : 0.023097
[23:46:57.449] iteration 9042 : model1 loss : 0.438498 model2 loss : 0.023030
[23:46:57.630] iteration 9043 : model1 loss : 0.441436 model2 loss : 0.028013
[23:46:57.801] iteration 9044 : model1 loss : 0.440576 model2 loss : 0.024638
[23:46:57.974] iteration 9045 : model1 loss : 0.438148 model2 loss : 0.022779
[23:46:58.146] iteration 9046 : model1 loss : 0.437763 model2 loss : 0.022626
[23:46:58.324] iteration 9047 : model1 loss : 0.433806 model2 loss : 0.023580
[23:46:58.493] iteration 9048 : model1 loss : 0.440769 model2 loss : 0.021480
[23:46:58.669] iteration 9049 : model1 loss : 0.433517 model2 loss : 0.020784
[23:46:58.839] iteration 9050 : model1 loss : 0.433550 model2 loss : 0.022081
[23:46:59.013] iteration 9051 : model1 loss : 0.436128 model2 loss : 0.021760
[23:47:01.177] iteration 9052 : model1 loss : 0.433534 model2 loss : 0.021728
[23:47:01.349] iteration 9053 : model1 loss : 0.429650 model2 loss : 0.020958
[23:47:01.526] iteration 9054 : model1 loss : 0.437624 model2 loss : 0.021554
[23:47:01.698] iteration 9055 : model1 loss : 0.438809 model2 loss : 0.024096
[23:47:01.872] iteration 9056 : model1 loss : 0.436324 model2 loss : 0.020820
[23:47:02.045] iteration 9057 : model1 loss : 0.439296 model2 loss : 0.024360
[23:47:02.223] iteration 9058 : model1 loss : 0.439592 model2 loss : 0.023626
[23:47:02.395] iteration 9059 : model1 loss : 0.442468 model2 loss : 0.026148
[23:47:02.571] iteration 9060 : model1 loss : 0.441314 model2 loss : 0.023826
[23:47:02.744] iteration 9061 : model1 loss : 0.437445 model2 loss : 0.023155
[23:47:02.920] iteration 9062 : model1 loss : 0.438052 model2 loss : 0.025900
[23:47:03.095] iteration 9063 : model1 loss : 0.436626 model2 loss : 0.020819
[23:47:03.271] iteration 9064 : model1 loss : 0.434753 model2 loss : 0.021680
[23:47:03.440] iteration 9065 : model1 loss : 0.438014 model2 loss : 0.024794
[23:47:03.619] iteration 9066 : model1 loss : 0.435685 model2 loss : 0.023050
[23:47:03.790] iteration 9067 : model1 loss : 0.442097 model2 loss : 0.025835
[23:47:03.968] iteration 9068 : model1 loss : 0.435444 model2 loss : 0.024501
[23:47:04.138] iteration 9069 : model1 loss : 0.437043 model2 loss : 0.020984
[23:47:04.323] iteration 9070 : model1 loss : 0.434450 model2 loss : 0.021426
[23:47:04.504] iteration 9071 : model1 loss : 0.438282 model2 loss : 0.025044
[23:47:04.681] iteration 9072 : model1 loss : 0.434255 model2 loss : 0.021392
[23:47:06.829] iteration 9073 : model1 loss : 0.433335 model2 loss : 0.024790
[23:47:07.006] iteration 9074 : model1 loss : 0.438138 model2 loss : 0.021679
[23:47:07.185] iteration 9075 : model1 loss : 0.441538 model2 loss : 0.025256
[23:47:07.357] iteration 9076 : model1 loss : 0.442314 model2 loss : 0.022911
[23:47:07.536] iteration 9077 : model1 loss : 0.433168 model2 loss : 0.025776
[23:47:07.710] iteration 9078 : model1 loss : 0.435091 model2 loss : 0.022167
[23:47:07.885] iteration 9079 : model1 loss : 0.438238 model2 loss : 0.029039
[23:47:08.056] iteration 9080 : model1 loss : 0.434627 model2 loss : 0.023268
[23:47:08.231] iteration 9081 : model1 loss : 0.436924 model2 loss : 0.022167
[23:47:08.403] iteration 9082 : model1 loss : 0.435652 model2 loss : 0.023485
[23:47:08.589] iteration 9083 : model1 loss : 0.438282 model2 loss : 0.025406
[23:47:08.762] iteration 9084 : model1 loss : 0.433327 model2 loss : 0.024737
[23:47:08.937] iteration 9085 : model1 loss : 0.438433 model2 loss : 0.023486
[23:47:09.108] iteration 9086 : model1 loss : 0.436116 model2 loss : 0.022104
[23:47:09.287] iteration 9087 : model1 loss : 0.436935 model2 loss : 0.021694
[23:47:09.460] iteration 9088 : model1 loss : 0.433237 model2 loss : 0.018279
[23:47:09.639] iteration 9089 : model1 loss : 0.441356 model2 loss : 0.021364
[23:47:09.812] iteration 9090 : model1 loss : 0.440077 model2 loss : 0.027070
[23:47:09.990] iteration 9091 : model1 loss : 0.437200 model2 loss : 0.024312
[23:47:10.161] iteration 9092 : model1 loss : 0.433546 model2 loss : 0.022378
[23:47:10.337] iteration 9093 : model1 loss : 0.439629 model2 loss : 0.024698
[23:47:12.481] iteration 9094 : model1 loss : 0.439400 model2 loss : 0.021873
[23:47:12.655] iteration 9095 : model1 loss : 0.435381 model2 loss : 0.022063
[23:47:12.834] iteration 9096 : model1 loss : 0.436002 model2 loss : 0.021478
[23:47:13.004] iteration 9097 : model1 loss : 0.437860 model2 loss : 0.021241
[23:47:13.185] iteration 9098 : model1 loss : 0.439077 model2 loss : 0.023838
[23:47:13.358] iteration 9099 : model1 loss : 0.433202 model2 loss : 0.022235
[23:47:13.533] iteration 9100 : model1 loss : 0.438550 model2 loss : 0.024153
[23:47:13.706] iteration 9101 : model1 loss : 0.437699 model2 loss : 0.024192
[23:47:13.882] iteration 9102 : model1 loss : 0.438937 model2 loss : 0.024254
[23:47:14.055] iteration 9103 : model1 loss : 0.434879 model2 loss : 0.024133
[23:47:14.231] iteration 9104 : model1 loss : 0.435530 model2 loss : 0.021166
[23:47:14.406] iteration 9105 : model1 loss : 0.432797 model2 loss : 0.020829
[23:47:14.582] iteration 9106 : model1 loss : 0.436982 model2 loss : 0.021507
[23:47:14.760] iteration 9107 : model1 loss : 0.436503 model2 loss : 0.021320
[23:47:14.935] iteration 9108 : model1 loss : 0.436702 model2 loss : 0.022984
[23:47:15.105] iteration 9109 : model1 loss : 0.443394 model2 loss : 0.028195
[23:47:15.284] iteration 9110 : model1 loss : 0.434250 model2 loss : 0.021833
[23:47:15.456] iteration 9111 : model1 loss : 0.434778 model2 loss : 0.022378
[23:47:15.633] iteration 9112 : model1 loss : 0.438498 model2 loss : 0.020736
[23:47:15.804] iteration 9113 : model1 loss : 0.436709 model2 loss : 0.022108
[23:47:15.980] iteration 9114 : model1 loss : 0.438310 model2 loss : 0.024401
[23:47:18.136] iteration 9115 : model1 loss : 0.434943 model2 loss : 0.024795
[23:47:18.313] iteration 9116 : model1 loss : 0.436130 model2 loss : 0.022712
[23:47:18.489] iteration 9117 : model1 loss : 0.436268 model2 loss : 0.022599
[23:47:18.660] iteration 9118 : model1 loss : 0.436286 model2 loss : 0.022955
[23:47:18.832] iteration 9119 : model1 loss : 0.437546 model2 loss : 0.020640
[23:47:19.004] iteration 9120 : model1 loss : 0.438596 model2 loss : 0.024737
[23:47:19.184] iteration 9121 : model1 loss : 0.442651 model2 loss : 0.025764
[23:47:19.356] iteration 9122 : model1 loss : 0.436648 model2 loss : 0.022201
[23:47:19.534] iteration 9123 : model1 loss : 0.433227 model2 loss : 0.023726
[23:47:19.708] iteration 9124 : model1 loss : 0.433128 model2 loss : 0.022305
[23:47:19.884] iteration 9125 : model1 loss : 0.435349 model2 loss : 0.023488
[23:47:20.056] iteration 9126 : model1 loss : 0.437028 model2 loss : 0.023776
[23:47:20.232] iteration 9127 : model1 loss : 0.439020 model2 loss : 0.024120
[23:47:20.411] iteration 9128 : model1 loss : 0.436231 model2 loss : 0.022283
[23:47:20.592] iteration 9129 : model1 loss : 0.439516 model2 loss : 0.022886
[23:47:20.763] iteration 9130 : model1 loss : 0.436614 model2 loss : 0.023237
[23:47:20.940] iteration 9131 : model1 loss : 0.432644 model2 loss : 0.021547
[23:47:21.109] iteration 9132 : model1 loss : 0.437155 model2 loss : 0.023889
[23:47:21.287] iteration 9133 : model1 loss : 0.438207 model2 loss : 0.022630
[23:47:21.455] iteration 9134 : model1 loss : 0.436612 model2 loss : 0.023851
[23:47:21.630] iteration 9135 : model1 loss : 0.439607 model2 loss : 0.021156
[23:47:23.769] iteration 9136 : model1 loss : 0.438284 model2 loss : 0.020870
[23:47:23.941] iteration 9137 : model1 loss : 0.440538 model2 loss : 0.023856
[23:47:24.120] iteration 9138 : model1 loss : 0.436583 model2 loss : 0.021454
[23:47:24.293] iteration 9139 : model1 loss : 0.438930 model2 loss : 0.023937
[23:47:24.468] iteration 9140 : model1 loss : 0.434054 model2 loss : 0.021651
[23:47:24.640] iteration 9141 : model1 loss : 0.438896 model2 loss : 0.021867
[23:47:24.818] iteration 9142 : model1 loss : 0.435111 model2 loss : 0.024224
[23:47:24.990] iteration 9143 : model1 loss : 0.437816 model2 loss : 0.024196
[23:47:25.167] iteration 9144 : model1 loss : 0.435550 model2 loss : 0.022117
[23:47:25.341] iteration 9145 : model1 loss : 0.432724 model2 loss : 0.025313
[23:47:25.520] iteration 9146 : model1 loss : 0.436469 model2 loss : 0.021940
[23:47:25.695] iteration 9147 : model1 loss : 0.434887 model2 loss : 0.023775
[23:47:25.869] iteration 9148 : model1 loss : 0.438300 model2 loss : 0.023947
[23:47:26.043] iteration 9149 : model1 loss : 0.439750 model2 loss : 0.025157
[23:47:26.223] iteration 9150 : model1 loss : 0.436710 model2 loss : 0.024719
[23:47:26.396] iteration 9151 : model1 loss : 0.433870 model2 loss : 0.022067
[23:47:26.571] iteration 9152 : model1 loss : 0.435196 model2 loss : 0.023709
[23:47:26.744] iteration 9153 : model1 loss : 0.434146 model2 loss : 0.021225
[23:47:26.918] iteration 9154 : model1 loss : 0.439211 model2 loss : 0.025021
[23:47:27.087] iteration 9155 : model1 loss : 0.440529 model2 loss : 0.024551
[23:47:27.263] iteration 9156 : model1 loss : 0.437179 model2 loss : 0.023801
[23:47:29.476] iteration 9157 : model1 loss : 0.437137 model2 loss : 0.023870
[23:47:29.644] iteration 9158 : model1 loss : 0.438340 model2 loss : 0.022349
[23:47:29.825] iteration 9159 : model1 loss : 0.442012 model2 loss : 0.026890
[23:47:30.001] iteration 9160 : model1 loss : 0.433372 model2 loss : 0.022237
[23:47:30.177] iteration 9161 : model1 loss : 0.437333 model2 loss : 0.019808
[23:47:30.352] iteration 9162 : model1 loss : 0.434004 model2 loss : 0.019843
[23:47:30.531] iteration 9163 : model1 loss : 0.435345 model2 loss : 0.021569
[23:47:30.705] iteration 9164 : model1 loss : 0.437109 model2 loss : 0.023262
[23:47:30.882] iteration 9165 : model1 loss : 0.441157 model2 loss : 0.030393
[23:47:31.053] iteration 9166 : model1 loss : 0.434118 model2 loss : 0.020079
[23:47:31.231] iteration 9167 : model1 loss : 0.439723 model2 loss : 0.024382
[23:47:31.402] iteration 9168 : model1 loss : 0.437685 model2 loss : 0.024831
[23:47:31.580] iteration 9169 : model1 loss : 0.435374 model2 loss : 0.023009
[23:47:31.753] iteration 9170 : model1 loss : 0.436867 model2 loss : 0.025186
[23:47:31.931] iteration 9171 : model1 loss : 0.438872 model2 loss : 0.021076
[23:47:32.102] iteration 9172 : model1 loss : 0.438334 model2 loss : 0.021939
[23:47:32.276] iteration 9173 : model1 loss : 0.438870 model2 loss : 0.022407
[23:47:32.449] iteration 9174 : model1 loss : 0.433533 model2 loss : 0.023500
[23:47:32.628] iteration 9175 : model1 loss : 0.437652 model2 loss : 0.023641
[23:47:32.799] iteration 9176 : model1 loss : 0.436982 model2 loss : 0.022351
[23:47:32.975] iteration 9177 : model1 loss : 0.435241 model2 loss : 0.021348
[23:47:35.098] iteration 9178 : model1 loss : 0.433747 model2 loss : 0.023308
[23:47:35.277] iteration 9179 : model1 loss : 0.434252 model2 loss : 0.022641
[23:47:35.453] iteration 9180 : model1 loss : 0.435924 model2 loss : 0.021176
[23:47:35.626] iteration 9181 : model1 loss : 0.435385 model2 loss : 0.023362
[23:47:35.804] iteration 9182 : model1 loss : 0.440387 model2 loss : 0.024493
[23:47:35.976] iteration 9183 : model1 loss : 0.436292 model2 loss : 0.025219
[23:47:36.153] iteration 9184 : model1 loss : 0.433785 model2 loss : 0.021406
[23:47:36.331] iteration 9185 : model1 loss : 0.442071 model2 loss : 0.023806
[23:47:36.508] iteration 9186 : model1 loss : 0.435662 model2 loss : 0.023430
[23:47:36.681] iteration 9187 : model1 loss : 0.436726 model2 loss : 0.022319
[23:47:36.857] iteration 9188 : model1 loss : 0.440823 model2 loss : 0.022540
[23:47:37.027] iteration 9189 : model1 loss : 0.441891 model2 loss : 0.023136
[23:47:37.204] iteration 9190 : model1 loss : 0.436152 model2 loss : 0.022204
[23:47:37.380] iteration 9191 : model1 loss : 0.433008 model2 loss : 0.020782
[23:47:37.559] iteration 9192 : model1 loss : 0.439420 model2 loss : 0.023335
[23:47:37.732] iteration 9193 : model1 loss : 0.431688 model2 loss : 0.020588
[23:47:37.907] iteration 9194 : model1 loss : 0.438367 model2 loss : 0.025157
[23:47:38.079] iteration 9195 : model1 loss : 0.441201 model2 loss : 0.026786
[23:47:38.258] iteration 9196 : model1 loss : 0.440498 model2 loss : 0.021656
[23:47:38.431] iteration 9197 : model1 loss : 0.435387 model2 loss : 0.023098
[23:47:38.608] iteration 9198 : model1 loss : 0.442658 model2 loss : 0.024347
[23:47:40.767] iteration 9199 : model1 loss : 0.440930 model2 loss : 0.022406
[23:47:40.941] iteration 9200 : model1 loss : 0.438567 model2 loss : 0.022561
[23:47:41.117] iteration 9201 : model1 loss : 0.436836 model2 loss : 0.025433
[23:47:41.293] iteration 9202 : model1 loss : 0.437009 model2 loss : 0.023076
[23:47:41.468] iteration 9203 : model1 loss : 0.432142 model2 loss : 0.024171
[23:47:41.643] iteration 9204 : model1 loss : 0.445263 model2 loss : 0.022670
[23:47:41.817] iteration 9205 : model1 loss : 0.433036 model2 loss : 0.021325
[23:47:41.988] iteration 9206 : model1 loss : 0.436856 model2 loss : 0.021494
[23:47:42.165] iteration 9207 : model1 loss : 0.439807 model2 loss : 0.024546
[23:47:42.341] iteration 9208 : model1 loss : 0.438268 model2 loss : 0.022626
[23:47:42.521] iteration 9209 : model1 loss : 0.434067 model2 loss : 0.022421
[23:47:42.692] iteration 9210 : model1 loss : 0.441378 model2 loss : 0.027335
[23:47:42.868] iteration 9211 : model1 loss : 0.438838 model2 loss : 0.021242
[23:47:43.042] iteration 9212 : model1 loss : 0.440475 model2 loss : 0.021940
[23:47:43.221] iteration 9213 : model1 loss : 0.441228 model2 loss : 0.022355
[23:47:43.394] iteration 9214 : model1 loss : 0.437394 model2 loss : 0.022590
[23:47:43.570] iteration 9215 : model1 loss : 0.439945 model2 loss : 0.025604
[23:47:43.742] iteration 9216 : model1 loss : 0.437804 model2 loss : 0.026910
[23:47:43.918] iteration 9217 : model1 loss : 0.436515 model2 loss : 0.021238
[23:47:44.089] iteration 9218 : model1 loss : 0.436077 model2 loss : 0.021770
[23:47:44.263] iteration 9219 : model1 loss : 0.435413 model2 loss : 0.024228
[23:47:46.404] iteration 9220 : model1 loss : 0.439789 model2 loss : 0.022614
[23:47:46.574] iteration 9221 : model1 loss : 0.436852 model2 loss : 0.021270
[23:47:46.756] iteration 9222 : model1 loss : 0.438790 model2 loss : 0.023372
[23:47:46.927] iteration 9223 : model1 loss : 0.435082 model2 loss : 0.020654
[23:47:47.103] iteration 9224 : model1 loss : 0.444002 model2 loss : 0.024999
[23:47:47.275] iteration 9225 : model1 loss : 0.437121 model2 loss : 0.021739
[23:47:47.456] iteration 9226 : model1 loss : 0.437509 model2 loss : 0.025488
[23:47:47.629] iteration 9227 : model1 loss : 0.440213 model2 loss : 0.024384
[23:47:47.805] iteration 9228 : model1 loss : 0.434640 model2 loss : 0.026363
[23:47:47.976] iteration 9229 : model1 loss : 0.438736 model2 loss : 0.024872
[23:47:48.150] iteration 9230 : model1 loss : 0.436235 model2 loss : 0.022346
[23:47:48.328] iteration 9231 : model1 loss : 0.435459 model2 loss : 0.019876
[23:47:48.505] iteration 9232 : model1 loss : 0.440327 model2 loss : 0.024041
[23:47:48.676] iteration 9233 : model1 loss : 0.443220 model2 loss : 0.025538
[23:47:48.855] iteration 9234 : model1 loss : 0.438956 model2 loss : 0.024510
[23:47:49.028] iteration 9235 : model1 loss : 0.435951 model2 loss : 0.023697
[23:47:49.204] iteration 9236 : model1 loss : 0.438617 model2 loss : 0.021840
[23:47:49.377] iteration 9237 : model1 loss : 0.436048 model2 loss : 0.023374
[23:47:49.553] iteration 9238 : model1 loss : 0.437546 model2 loss : 0.024052
[23:47:49.724] iteration 9239 : model1 loss : 0.433074 model2 loss : 0.020907
[23:47:49.897] iteration 9240 : model1 loss : 0.438921 model2 loss : 0.023012
[23:47:52.043] iteration 9241 : model1 loss : 0.438875 model2 loss : 0.024820
[23:47:52.224] iteration 9242 : model1 loss : 0.440811 model2 loss : 0.022457
[23:47:52.400] iteration 9243 : model1 loss : 0.433444 model2 loss : 0.022354
[23:47:52.572] iteration 9244 : model1 loss : 0.437116 model2 loss : 0.023547
[23:47:52.749] iteration 9245 : model1 loss : 0.436897 model2 loss : 0.024130
[23:47:52.920] iteration 9246 : model1 loss : 0.436138 model2 loss : 0.020865
[23:47:53.096] iteration 9247 : model1 loss : 0.435672 model2 loss : 0.022521
[23:47:53.271] iteration 9248 : model1 loss : 0.436836 model2 loss : 0.020314
[23:47:53.448] iteration 9249 : model1 loss : 0.436112 model2 loss : 0.021292
[23:47:53.620] iteration 9250 : model1 loss : 0.440070 model2 loss : 0.030689
[23:47:53.797] iteration 9251 : model1 loss : 0.434655 model2 loss : 0.022103
[23:47:53.968] iteration 9252 : model1 loss : 0.436435 model2 loss : 0.022627
[23:47:54.141] iteration 9253 : model1 loss : 0.435924 model2 loss : 0.023419
[23:47:54.318] iteration 9254 : model1 loss : 0.437442 model2 loss : 0.025875
[23:47:54.494] iteration 9255 : model1 loss : 0.432972 model2 loss : 0.021890
[23:47:54.666] iteration 9256 : model1 loss : 0.438724 model2 loss : 0.022024
[23:47:54.843] iteration 9257 : model1 loss : 0.439724 model2 loss : 0.021574
[23:47:55.017] iteration 9258 : model1 loss : 0.443469 model2 loss : 0.024566
[23:47:55.195] iteration 9259 : model1 loss : 0.435938 model2 loss : 0.023406
[23:47:55.368] iteration 9260 : model1 loss : 0.440966 model2 loss : 0.022506
[23:47:55.541] iteration 9261 : model1 loss : 0.441080 model2 loss : 0.023557
[23:47:57.698] iteration 9262 : model1 loss : 0.439126 model2 loss : 0.022281
[23:47:57.876] iteration 9263 : model1 loss : 0.441465 model2 loss : 0.025020
[23:47:58.054] iteration 9264 : model1 loss : 0.438480 model2 loss : 0.024696
[23:47:58.226] iteration 9265 : model1 loss : 0.430608 model2 loss : 0.022771
[23:47:58.402] iteration 9266 : model1 loss : 0.436853 model2 loss : 0.024375
[23:47:58.574] iteration 9267 : model1 loss : 0.438002 model2 loss : 0.022582
[23:47:58.751] iteration 9268 : model1 loss : 0.434332 model2 loss : 0.022540
[23:47:58.925] iteration 9269 : model1 loss : 0.434840 model2 loss : 0.023269
[23:47:59.101] iteration 9270 : model1 loss : 0.434781 model2 loss : 0.021338
[23:47:59.274] iteration 9271 : model1 loss : 0.433892 model2 loss : 0.022313
[23:47:59.451] iteration 9272 : model1 loss : 0.435810 model2 loss : 0.022950
[23:47:59.625] iteration 9273 : model1 loss : 0.442047 model2 loss : 0.025192
[23:47:59.801] iteration 9274 : model1 loss : 0.439015 model2 loss : 0.023246
[23:47:59.974] iteration 9275 : model1 loss : 0.440306 model2 loss : 0.021741
[23:48:00.152] iteration 9276 : model1 loss : 0.440259 model2 loss : 0.022964
[23:48:00.328] iteration 9277 : model1 loss : 0.440168 model2 loss : 0.026492
[23:48:00.505] iteration 9278 : model1 loss : 0.437401 model2 loss : 0.024070
[23:48:00.675] iteration 9279 : model1 loss : 0.445124 model2 loss : 0.025550
[23:48:00.851] iteration 9280 : model1 loss : 0.437556 model2 loss : 0.023442
[23:48:01.020] iteration 9281 : model1 loss : 0.438341 model2 loss : 0.026806
[23:48:01.194] iteration 9282 : model1 loss : 0.438348 model2 loss : 0.026798
[23:48:03.365] iteration 9283 : model1 loss : 0.435797 model2 loss : 0.023252
[23:48:03.538] iteration 9284 : model1 loss : 0.437565 model2 loss : 0.024164
[23:48:03.715] iteration 9285 : model1 loss : 0.439121 model2 loss : 0.024776
[23:48:03.887] iteration 9286 : model1 loss : 0.446017 model2 loss : 0.049384
[23:48:04.060] iteration 9287 : model1 loss : 0.441666 model2 loss : 0.071462
[23:48:04.233] iteration 9288 : model1 loss : 0.437879 model2 loss : 0.024483
[23:48:04.409] iteration 9289 : model1 loss : 0.437159 model2 loss : 0.040955
[23:48:04.579] iteration 9290 : model1 loss : 0.437518 model2 loss : 0.028764
[23:48:04.756] iteration 9291 : model1 loss : 0.438050 model2 loss : 0.027589
[23:48:04.927] iteration 9292 : model1 loss : 0.440864 model2 loss : 0.047028
[23:48:05.104] iteration 9293 : model1 loss : 0.437505 model2 loss : 0.025209
[23:48:05.278] iteration 9294 : model1 loss : 0.436233 model2 loss : 0.029053
[23:48:05.456] iteration 9295 : model1 loss : 0.436518 model2 loss : 0.031156
[23:48:05.628] iteration 9296 : model1 loss : 0.433079 model2 loss : 0.032874
[23:48:05.804] iteration 9297 : model1 loss : 0.440422 model2 loss : 0.029056
[23:48:05.976] iteration 9298 : model1 loss : 0.437694 model2 loss : 0.029696
[23:48:06.154] iteration 9299 : model1 loss : 0.440244 model2 loss : 0.045637
[23:48:06.330] iteration 9300 : model1 loss : 0.432558 model2 loss : 0.027217
[23:48:06.505] iteration 9301 : model1 loss : 0.441618 model2 loss : 0.029336
[23:48:06.675] iteration 9302 : model1 loss : 0.436633 model2 loss : 0.029551
[23:48:06.850] iteration 9303 : model1 loss : 0.433797 model2 loss : 0.025258
[23:48:09.073] iteration 9304 : model1 loss : 0.439110 model2 loss : 0.027638
[23:48:09.249] iteration 9305 : model1 loss : 0.440773 model2 loss : 0.036327
[23:48:09.425] iteration 9306 : model1 loss : 0.435190 model2 loss : 0.028743
[23:48:09.600] iteration 9307 : model1 loss : 0.436632 model2 loss : 0.026376
[23:48:09.776] iteration 9308 : model1 loss : 0.438555 model2 loss : 0.034537
[23:48:09.946] iteration 9309 : model1 loss : 0.437592 model2 loss : 0.034935
[23:48:10.125] iteration 9310 : model1 loss : 0.434645 model2 loss : 0.025048
[23:48:10.295] iteration 9311 : model1 loss : 0.434508 model2 loss : 0.028742
[23:48:10.472] iteration 9312 : model1 loss : 0.442002 model2 loss : 0.035859
[23:48:10.643] iteration 9313 : model1 loss : 0.436603 model2 loss : 0.029574
[23:48:10.823] iteration 9314 : model1 loss : 0.441094 model2 loss : 0.035260
[23:48:10.995] iteration 9315 : model1 loss : 0.440066 model2 loss : 0.026997
[23:48:11.168] iteration 9316 : model1 loss : 0.440186 model2 loss : 0.028488
[23:48:11.343] iteration 9317 : model1 loss : 0.435603 model2 loss : 0.034597
[23:48:11.521] iteration 9318 : model1 loss : 0.435994 model2 loss : 0.024618
[23:48:11.692] iteration 9319 : model1 loss : 0.439547 model2 loss : 0.033341
[23:48:11.868] iteration 9320 : model1 loss : 0.437521 model2 loss : 0.030416
[23:48:12.041] iteration 9321 : model1 loss : 0.438945 model2 loss : 0.030681
[23:48:12.216] iteration 9322 : model1 loss : 0.439248 model2 loss : 0.030466
[23:48:12.389] iteration 9323 : model1 loss : 0.441261 model2 loss : 0.027828
[23:48:12.564] iteration 9324 : model1 loss : 0.431870 model2 loss : 0.028557
[23:48:14.701] iteration 9325 : model1 loss : 0.432550 model2 loss : 0.024453
[23:48:14.875] iteration 9326 : model1 loss : 0.431052 model2 loss : 0.025479
[23:48:15.054] iteration 9327 : model1 loss : 0.439026 model2 loss : 0.029684
[23:48:15.226] iteration 9328 : model1 loss : 0.434197 model2 loss : 0.026516
[23:48:15.401] iteration 9329 : model1 loss : 0.437697 model2 loss : 0.026827
[23:48:15.575] iteration 9330 : model1 loss : 0.436220 model2 loss : 0.021362
[23:48:15.754] iteration 9331 : model1 loss : 0.438119 model2 loss : 0.027540
[23:48:15.927] iteration 9332 : model1 loss : 0.437362 model2 loss : 0.028575
[23:48:16.102] iteration 9333 : model1 loss : 0.439341 model2 loss : 0.025448
[23:48:16.274] iteration 9334 : model1 loss : 0.436652 model2 loss : 0.024161
[23:48:16.452] iteration 9335 : model1 loss : 0.441882 model2 loss : 0.028528
[23:48:16.625] iteration 9336 : model1 loss : 0.438238 model2 loss : 0.025947
[23:48:16.804] iteration 9337 : model1 loss : 0.442577 model2 loss : 0.029713
[23:48:16.983] iteration 9338 : model1 loss : 0.437476 model2 loss : 0.028959
[23:48:17.159] iteration 9339 : model1 loss : 0.437442 model2 loss : 0.027475
[23:48:17.335] iteration 9340 : model1 loss : 0.439353 model2 loss : 0.026788
[23:48:17.515] iteration 9341 : model1 loss : 0.435603 model2 loss : 0.027262
[23:48:17.685] iteration 9342 : model1 loss : 0.436864 model2 loss : 0.024664
[23:48:17.862] iteration 9343 : model1 loss : 0.433480 model2 loss : 0.024080
[23:48:18.030] iteration 9344 : model1 loss : 0.437670 model2 loss : 0.026710
[23:48:18.202] iteration 9345 : model1 loss : 0.440457 model2 loss : 0.030868
[23:48:20.376] iteration 9346 : model1 loss : 0.439548 model2 loss : 0.025832
[23:48:20.553] iteration 9347 : model1 loss : 0.433512 model2 loss : 0.023717
[23:48:20.729] iteration 9348 : model1 loss : 0.435718 model2 loss : 0.026673
[23:48:20.903] iteration 9349 : model1 loss : 0.439822 model2 loss : 0.025988
[23:48:21.080] iteration 9350 : model1 loss : 0.442196 model2 loss : 0.032965
[23:48:21.252] iteration 9351 : model1 loss : 0.439475 model2 loss : 0.028107
[23:48:21.431] iteration 9352 : model1 loss : 0.435009 model2 loss : 0.023619
[23:48:21.605] iteration 9353 : model1 loss : 0.436966 model2 loss : 0.023194
[23:48:21.783] iteration 9354 : model1 loss : 0.439532 model2 loss : 0.024804
[23:48:21.954] iteration 9355 : model1 loss : 0.437632 model2 loss : 0.024701
[23:48:22.132] iteration 9356 : model1 loss : 0.432983 model2 loss : 0.021956
[23:48:22.308] iteration 9357 : model1 loss : 0.439858 model2 loss : 0.029092
[23:48:22.490] iteration 9358 : model1 loss : 0.437725 model2 loss : 0.025991
[23:48:22.660] iteration 9359 : model1 loss : 0.432542 model2 loss : 0.026740
[23:48:22.838] iteration 9360 : model1 loss : 0.437557 model2 loss : 0.025185
[23:48:23.008] iteration 9361 : model1 loss : 0.437139 model2 loss : 0.024122
[23:48:23.183] iteration 9362 : model1 loss : 0.438889 model2 loss : 0.026906
[23:48:23.360] iteration 9363 : model1 loss : 0.437573 model2 loss : 0.026082
[23:48:23.537] iteration 9364 : model1 loss : 0.437888 model2 loss : 0.025090
[23:48:23.707] iteration 9365 : model1 loss : 0.437798 model2 loss : 0.026581
[23:48:23.882] iteration 9366 : model1 loss : 0.439509 model2 loss : 0.030881
[23:48:26.010] iteration 9367 : model1 loss : 0.436583 model2 loss : 0.024313
[23:48:26.185] iteration 9368 : model1 loss : 0.436069 model2 loss : 0.025299
[23:48:26.366] iteration 9369 : model1 loss : 0.440014 model2 loss : 0.024990
[23:48:26.537] iteration 9370 : model1 loss : 0.439619 model2 loss : 0.028067
[23:48:26.714] iteration 9371 : model1 loss : 0.437860 model2 loss : 0.026507
[23:48:26.888] iteration 9372 : model1 loss : 0.435943 model2 loss : 0.023467
[23:48:27.065] iteration 9373 : model1 loss : 0.439014 model2 loss : 0.022462
[23:48:27.234] iteration 9374 : model1 loss : 0.438284 model2 loss : 0.023811
[23:48:27.413] iteration 9375 : model1 loss : 0.436933 model2 loss : 0.023391
[23:48:27.585] iteration 9376 : model1 loss : 0.433008 model2 loss : 0.021911
[23:48:27.766] iteration 9377 : model1 loss : 0.438617 model2 loss : 0.030176
[23:48:27.936] iteration 9378 : model1 loss : 0.437256 model2 loss : 0.025161
[23:48:28.110] iteration 9379 : model1 loss : 0.436304 model2 loss : 0.024319
[23:48:28.284] iteration 9380 : model1 loss : 0.438419 model2 loss : 0.026201
[23:48:28.464] iteration 9381 : model1 loss : 0.439560 model2 loss : 0.021936
[23:48:28.637] iteration 9382 : model1 loss : 0.432466 model2 loss : 0.022955
[23:48:28.814] iteration 9383 : model1 loss : 0.433189 model2 loss : 0.022740
[23:48:28.986] iteration 9384 : model1 loss : 0.440734 model2 loss : 0.028844
[23:48:29.162] iteration 9385 : model1 loss : 0.441484 model2 loss : 0.025594
[23:48:29.337] iteration 9386 : model1 loss : 0.434125 model2 loss : 0.029445
[23:48:29.514] iteration 9387 : model1 loss : 0.436209 model2 loss : 0.023814
[23:48:31.632] iteration 9388 : model1 loss : 0.434130 model2 loss : 0.022581
[23:48:31.811] iteration 9389 : model1 loss : 0.437031 model2 loss : 0.026184
[23:48:31.990] iteration 9390 : model1 loss : 0.438501 model2 loss : 0.022644
[23:48:32.160] iteration 9391 : model1 loss : 0.436186 model2 loss : 0.023268
[23:48:32.340] iteration 9392 : model1 loss : 0.432875 model2 loss : 0.020388
[23:48:32.517] iteration 9393 : model1 loss : 0.436430 model2 loss : 0.022673
[23:48:32.694] iteration 9394 : model1 loss : 0.434314 model2 loss : 0.021704
[23:48:32.867] iteration 9395 : model1 loss : 0.437176 model2 loss : 0.021729
[23:48:33.043] iteration 9396 : model1 loss : 0.437781 model2 loss : 0.021525
[23:48:33.214] iteration 9397 : model1 loss : 0.436857 model2 loss : 0.025673
[23:48:33.390] iteration 9398 : model1 loss : 0.435085 model2 loss : 0.021346
[23:48:33.561] iteration 9399 : model1 loss : 0.439816 model2 loss : 0.026189
[23:48:33.734] iteration 9400 : model1 loss : 0.438749 model2 loss : 0.026794
[23:48:33.906] iteration 9401 : model1 loss : 0.438711 model2 loss : 0.027280
[23:48:34.084] iteration 9402 : model1 loss : 0.439001 model2 loss : 0.022972
[23:48:34.254] iteration 9403 : model1 loss : 0.436395 model2 loss : 0.021430
[23:48:34.433] iteration 9404 : model1 loss : 0.433805 model2 loss : 0.028226
[23:48:34.608] iteration 9405 : model1 loss : 0.439374 model2 loss : 0.021870
[23:48:34.785] iteration 9406 : model1 loss : 0.436772 model2 loss : 0.023835
[23:48:34.957] iteration 9407 : model1 loss : 0.437144 model2 loss : 0.026642
[23:48:35.130] iteration 9408 : model1 loss : 0.440540 model2 loss : 0.026531
[23:48:37.275] iteration 9409 : model1 loss : 0.435727 model2 loss : 0.022669
[23:48:37.455] iteration 9410 : model1 loss : 0.433869 model2 loss : 0.023877
[23:48:37.632] iteration 9411 : model1 loss : 0.439023 model2 loss : 0.025048
[23:48:37.805] iteration 9412 : model1 loss : 0.437454 model2 loss : 0.024461
[23:48:37.982] iteration 9413 : model1 loss : 0.436749 model2 loss : 0.025612
[23:48:38.152] iteration 9414 : model1 loss : 0.436484 model2 loss : 0.022508
[23:48:38.330] iteration 9415 : model1 loss : 0.437162 model2 loss : 0.021748
[23:48:38.503] iteration 9416 : model1 loss : 0.441943 model2 loss : 0.025532
[23:48:38.678] iteration 9417 : model1 loss : 0.434771 model2 loss : 0.021402
[23:48:38.851] iteration 9418 : model1 loss : 0.439267 model2 loss : 0.022270
[23:48:39.029] iteration 9419 : model1 loss : 0.439322 model2 loss : 0.024102
[23:48:39.199] iteration 9420 : model1 loss : 0.438461 model2 loss : 0.024849
[23:48:39.377] iteration 9421 : model1 loss : 0.433677 model2 loss : 0.018438
[23:48:39.547] iteration 9422 : model1 loss : 0.436048 model2 loss : 0.026694
[23:48:39.723] iteration 9423 : model1 loss : 0.434097 model2 loss : 0.024081
[23:48:39.897] iteration 9424 : model1 loss : 0.436206 model2 loss : 0.025967
[23:48:40.071] iteration 9425 : model1 loss : 0.438456 model2 loss : 0.027008
[23:48:40.242] iteration 9426 : model1 loss : 0.437441 model2 loss : 0.025733
[23:48:40.420] iteration 9427 : model1 loss : 0.436073 model2 loss : 0.026909
[23:48:40.593] iteration 9428 : model1 loss : 0.439489 model2 loss : 0.026135
[23:48:40.768] iteration 9429 : model1 loss : 0.439181 model2 loss : 0.025676
[23:48:42.898] iteration 9430 : model1 loss : 0.438895 model2 loss : 0.025285
[23:48:43.080] iteration 9431 : model1 loss : 0.436436 model2 loss : 0.023037
[23:48:43.256] iteration 9432 : model1 loss : 0.438648 model2 loss : 0.027842
[23:48:43.429] iteration 9433 : model1 loss : 0.433394 model2 loss : 0.024169
[23:48:43.609] iteration 9434 : model1 loss : 0.437524 model2 loss : 0.022959
[23:48:43.779] iteration 9435 : model1 loss : 0.435408 model2 loss : 0.020307
[23:48:43.959] iteration 9436 : model1 loss : 0.439850 model2 loss : 0.028311
[23:48:44.132] iteration 9437 : model1 loss : 0.439091 model2 loss : 0.027877
[23:48:44.311] iteration 9438 : model1 loss : 0.439140 model2 loss : 0.024560
[23:48:44.486] iteration 9439 : model1 loss : 0.437240 model2 loss : 0.022841
[23:48:44.663] iteration 9440 : model1 loss : 0.437935 model2 loss : 0.023111
[23:48:44.837] iteration 9441 : model1 loss : 0.435486 model2 loss : 0.019741
[23:48:45.014] iteration 9442 : model1 loss : 0.439708 model2 loss : 0.023394
[23:48:45.188] iteration 9443 : model1 loss : 0.439984 model2 loss : 0.024134
[23:48:45.371] iteration 9444 : model1 loss : 0.439311 model2 loss : 0.024012
[23:48:45.545] iteration 9445 : model1 loss : 0.438515 model2 loss : 0.024047
[23:48:45.725] iteration 9446 : model1 loss : 0.432040 model2 loss : 0.023220
[23:48:45.900] iteration 9447 : model1 loss : 0.434179 model2 loss : 0.026239
[23:48:46.076] iteration 9448 : model1 loss : 0.435266 model2 loss : 0.020508
[23:48:46.244] iteration 9449 : model1 loss : 0.437219 model2 loss : 0.024706
[23:48:46.419] iteration 9450 : model1 loss : 0.433985 model2 loss : 0.022620
[23:48:48.546] iteration 9451 : model1 loss : 0.434128 model2 loss : 0.023754
[23:48:48.718] iteration 9452 : model1 loss : 0.439449 model2 loss : 0.026412
[23:48:48.897] iteration 9453 : model1 loss : 0.436425 model2 loss : 0.023773
[23:48:49.069] iteration 9454 : model1 loss : 0.436423 model2 loss : 0.020555
[23:48:49.242] iteration 9455 : model1 loss : 0.443280 model2 loss : 0.032798
[23:48:49.416] iteration 9456 : model1 loss : 0.441408 model2 loss : 0.023827
[23:48:49.596] iteration 9457 : model1 loss : 0.439324 model2 loss : 0.026161
[23:48:49.767] iteration 9458 : model1 loss : 0.438062 model2 loss : 0.022311
[23:48:49.940] iteration 9459 : model1 loss : 0.434225 model2 loss : 0.024108
[23:48:50.113] iteration 9460 : model1 loss : 0.433425 model2 loss : 0.021335
[23:48:50.290] iteration 9461 : model1 loss : 0.437528 model2 loss : 0.022642
[23:48:50.464] iteration 9462 : model1 loss : 0.435213 model2 loss : 0.023134
[23:48:50.642] iteration 9463 : model1 loss : 0.440454 model2 loss : 0.028635
[23:48:50.813] iteration 9464 : model1 loss : 0.436375 model2 loss : 0.022251
[23:48:50.991] iteration 9465 : model1 loss : 0.438965 model2 loss : 0.020959
[23:48:51.162] iteration 9466 : model1 loss : 0.439850 model2 loss : 0.021817
[23:48:51.341] iteration 9467 : model1 loss : 0.435655 model2 loss : 0.022269
[23:48:51.513] iteration 9468 : model1 loss : 0.432179 model2 loss : 0.026433
[23:48:51.689] iteration 9469 : model1 loss : 0.436778 model2 loss : 0.023009
[23:48:51.862] iteration 9470 : model1 loss : 0.437404 model2 loss : 0.024403
[23:48:52.037] iteration 9471 : model1 loss : 0.435612 model2 loss : 0.021968
[23:48:54.165] iteration 9472 : model1 loss : 0.437356 model2 loss : 0.025735
[23:48:54.344] iteration 9473 : model1 loss : 0.439415 model2 loss : 0.022723
[23:48:54.520] iteration 9474 : model1 loss : 0.437595 model2 loss : 0.020428
[23:48:54.688] iteration 9475 : model1 loss : 0.440427 model2 loss : 0.023924
[23:48:54.865] iteration 9476 : model1 loss : 0.436548 model2 loss : 0.024936
[23:48:55.037] iteration 9477 : model1 loss : 0.436286 model2 loss : 0.019548
[23:48:55.215] iteration 9478 : model1 loss : 0.436423 model2 loss : 0.023462
[23:48:55.389] iteration 9479 : model1 loss : 0.432486 model2 loss : 0.020952
[23:48:55.570] iteration 9480 : model1 loss : 0.433889 model2 loss : 0.022732
[23:48:55.741] iteration 9481 : model1 loss : 0.435131 model2 loss : 0.022819
[23:48:55.918] iteration 9482 : model1 loss : 0.439237 model2 loss : 0.025572
[23:48:56.088] iteration 9483 : model1 loss : 0.437015 model2 loss : 0.021852
[23:48:56.264] iteration 9484 : model1 loss : 0.438658 model2 loss : 0.023366
[23:48:56.437] iteration 9485 : model1 loss : 0.438459 model2 loss : 0.026700
[23:48:56.618] iteration 9486 : model1 loss : 0.435738 model2 loss : 0.020983
[23:48:56.790] iteration 9487 : model1 loss : 0.431396 model2 loss : 0.020821
[23:48:56.972] iteration 9488 : model1 loss : 0.436230 model2 loss : 0.022280
[23:48:57.143] iteration 9489 : model1 loss : 0.434537 model2 loss : 0.024425
[23:48:57.326] iteration 9490 : model1 loss : 0.434041 model2 loss : 0.018683
[23:48:57.500] iteration 9491 : model1 loss : 0.441401 model2 loss : 0.025153
[23:48:57.675] iteration 9492 : model1 loss : 0.435851 model2 loss : 0.023711
[23:48:59.808] iteration 9493 : model1 loss : 0.436698 model2 loss : 0.022743
[23:48:59.983] iteration 9494 : model1 loss : 0.442197 model2 loss : 0.022903
[23:49:00.161] iteration 9495 : model1 loss : 0.438750 model2 loss : 0.020252
[23:49:00.333] iteration 9496 : model1 loss : 0.436753 model2 loss : 0.025291
[23:49:00.510] iteration 9497 : model1 loss : 0.442099 model2 loss : 0.027043
[23:49:00.681] iteration 9498 : model1 loss : 0.435969 model2 loss : 0.024074
[23:49:00.858] iteration 9499 : model1 loss : 0.432471 model2 loss : 0.021486
[23:49:01.031] iteration 9500 : model1 loss : 0.431958 model2 loss : 0.021625
[23:49:01.206] iteration 9501 : model1 loss : 0.437023 model2 loss : 0.025308
[23:49:01.380] iteration 9502 : model1 loss : 0.435463 model2 loss : 0.023568
[23:49:01.567] iteration 9503 : model1 loss : 0.434279 model2 loss : 0.021543
[23:49:01.737] iteration 9504 : model1 loss : 0.441357 model2 loss : 0.026313
[23:49:01.915] iteration 9505 : model1 loss : 0.438138 model2 loss : 0.022485
[23:49:02.088] iteration 9506 : model1 loss : 0.440132 model2 loss : 0.021113
[23:49:02.264] iteration 9507 : model1 loss : 0.433782 model2 loss : 0.022094
[23:49:02.442] iteration 9508 : model1 loss : 0.437961 model2 loss : 0.025436
[23:49:02.622] iteration 9509 : model1 loss : 0.434087 model2 loss : 0.020267
[23:49:02.792] iteration 9510 : model1 loss : 0.439331 model2 loss : 0.025234
[23:49:02.966] iteration 9511 : model1 loss : 0.433608 model2 loss : 0.022017
[23:49:03.135] iteration 9512 : model1 loss : 0.436413 model2 loss : 0.026033
[23:49:03.310] iteration 9513 : model1 loss : 0.436868 model2 loss : 0.026209
[23:49:05.436] iteration 9514 : model1 loss : 0.438867 model2 loss : 0.022751
[23:49:05.614] iteration 9515 : model1 loss : 0.434274 model2 loss : 0.022476
[23:49:05.790] iteration 9516 : model1 loss : 0.437603 model2 loss : 0.023891
[23:49:05.965] iteration 9517 : model1 loss : 0.434980 model2 loss : 0.020577
[23:49:06.138] iteration 9518 : model1 loss : 0.441807 model2 loss : 0.026233
[23:49:06.310] iteration 9519 : model1 loss : 0.436079 model2 loss : 0.021750
[23:49:06.486] iteration 9520 : model1 loss : 0.438700 model2 loss : 0.022584
[23:49:06.659] iteration 9521 : model1 loss : 0.437051 model2 loss : 0.021572
[23:49:06.834] iteration 9522 : model1 loss : 0.433304 model2 loss : 0.022501
[23:49:07.008] iteration 9523 : model1 loss : 0.438994 model2 loss : 0.024055
[23:49:07.184] iteration 9524 : model1 loss : 0.440109 model2 loss : 0.029040
[23:49:07.357] iteration 9525 : model1 loss : 0.439654 model2 loss : 0.020454
[23:49:07.537] iteration 9526 : model1 loss : 0.433732 model2 loss : 0.023198
[23:49:07.709] iteration 9527 : model1 loss : 0.437299 model2 loss : 0.022286
[23:49:07.885] iteration 9528 : model1 loss : 0.435118 model2 loss : 0.023078
[23:49:08.060] iteration 9529 : model1 loss : 0.437296 model2 loss : 0.021353
[23:49:08.239] iteration 9530 : model1 loss : 0.437075 model2 loss : 0.024714
[23:49:08.414] iteration 9531 : model1 loss : 0.433393 model2 loss : 0.020475
[23:49:08.594] iteration 9532 : model1 loss : 0.436149 model2 loss : 0.022218
[23:49:08.764] iteration 9533 : model1 loss : 0.436758 model2 loss : 0.025279
[23:49:08.940] iteration 9534 : model1 loss : 0.435418 model2 loss : 0.021426
[23:49:11.074] iteration 9535 : model1 loss : 0.436612 model2 loss : 0.021868
[23:49:11.247] iteration 9536 : model1 loss : 0.434629 model2 loss : 0.020481
[23:49:11.427] iteration 9537 : model1 loss : 0.435909 model2 loss : 0.024321
[23:49:11.602] iteration 9538 : model1 loss : 0.435928 model2 loss : 0.024179
[23:49:11.784] iteration 9539 : model1 loss : 0.439103 model2 loss : 0.021464
[23:49:11.959] iteration 9540 : model1 loss : 0.442222 model2 loss : 0.026181
[23:49:12.135] iteration 9541 : model1 loss : 0.436686 model2 loss : 0.021490
[23:49:12.304] iteration 9542 : model1 loss : 0.442086 model2 loss : 0.024807
[23:49:12.486] iteration 9543 : model1 loss : 0.438601 model2 loss : 0.023642
[23:49:12.657] iteration 9544 : model1 loss : 0.435791 model2 loss : 0.021755
[23:49:12.832] iteration 9545 : model1 loss : 0.435155 model2 loss : 0.024784
[23:49:13.006] iteration 9546 : model1 loss : 0.434369 model2 loss : 0.023004
[23:49:13.180] iteration 9547 : model1 loss : 0.435126 model2 loss : 0.022530
[23:49:13.354] iteration 9548 : model1 loss : 0.440080 model2 loss : 0.024272
[23:49:13.534] iteration 9549 : model1 loss : 0.436543 model2 loss : 0.026025
[23:49:13.704] iteration 9550 : model1 loss : 0.435456 model2 loss : 0.022747
[23:49:13.882] iteration 9551 : model1 loss : 0.431806 model2 loss : 0.022792
[23:49:14.062] iteration 9552 : model1 loss : 0.434233 model2 loss : 0.020825
[23:49:14.237] iteration 9553 : model1 loss : 0.438535 model2 loss : 0.020725
[23:49:14.410] iteration 9554 : model1 loss : 0.435294 model2 loss : 0.022234
[23:49:14.588] iteration 9555 : model1 loss : 0.439090 model2 loss : 0.024032
[23:49:16.761] iteration 9556 : model1 loss : 0.439406 model2 loss : 0.019875
[23:49:16.935] iteration 9557 : model1 loss : 0.438493 model2 loss : 0.021634
[23:49:17.115] iteration 9558 : model1 loss : 0.434054 model2 loss : 0.023713
[23:49:17.286] iteration 9559 : model1 loss : 0.436762 model2 loss : 0.023433
[23:49:17.467] iteration 9560 : model1 loss : 0.440146 model2 loss : 0.021640
[23:49:17.639] iteration 9561 : model1 loss : 0.434782 model2 loss : 0.022848
[23:49:17.815] iteration 9562 : model1 loss : 0.437902 model2 loss : 0.023498
[23:49:17.989] iteration 9563 : model1 loss : 0.439564 model2 loss : 0.025546
[23:49:18.166] iteration 9564 : model1 loss : 0.434711 model2 loss : 0.022174
[23:49:18.343] iteration 9565 : model1 loss : 0.436219 model2 loss : 0.022382
[23:49:18.524] iteration 9566 : model1 loss : 0.434908 model2 loss : 0.022493
[23:49:18.693] iteration 9567 : model1 loss : 0.437480 model2 loss : 0.025044
[23:49:18.868] iteration 9568 : model1 loss : 0.434735 model2 loss : 0.019073
[23:49:19.044] iteration 9569 : model1 loss : 0.437733 model2 loss : 0.023536
[23:49:19.227] iteration 9570 : model1 loss : 0.432222 model2 loss : 0.022087
[23:49:19.401] iteration 9571 : model1 loss : 0.435099 model2 loss : 0.023411
[23:49:19.579] iteration 9572 : model1 loss : 0.435776 model2 loss : 0.021713
[23:49:19.750] iteration 9573 : model1 loss : 0.436866 model2 loss : 0.023653
[23:49:19.929] iteration 9574 : model1 loss : 0.435792 model2 loss : 0.023472
[23:49:20.101] iteration 9575 : model1 loss : 0.441443 model2 loss : 0.023959
[23:49:20.276] iteration 9576 : model1 loss : 0.438154 model2 loss : 0.023356
[23:49:22.399] iteration 9577 : model1 loss : 0.433162 model2 loss : 0.019228
[23:49:22.580] iteration 9578 : model1 loss : 0.435534 model2 loss : 0.021792
[23:49:22.756] iteration 9579 : model1 loss : 0.437024 model2 loss : 0.022841
[23:49:22.927] iteration 9580 : model1 loss : 0.438702 model2 loss : 0.023015
[23:49:23.103] iteration 9581 : model1 loss : 0.434080 model2 loss : 0.022983
[23:49:23.273] iteration 9582 : model1 loss : 0.440159 model2 loss : 0.022124
[23:49:23.452] iteration 9583 : model1 loss : 0.435603 model2 loss : 0.020555
[23:49:23.628] iteration 9584 : model1 loss : 0.433786 model2 loss : 0.022531
[23:49:23.804] iteration 9585 : model1 loss : 0.438542 model2 loss : 0.022613
[23:49:23.978] iteration 9586 : model1 loss : 0.435997 model2 loss : 0.022989
[23:49:24.153] iteration 9587 : model1 loss : 0.436935 model2 loss : 0.025285
[23:49:24.327] iteration 9588 : model1 loss : 0.435102 model2 loss : 0.021380
[23:49:24.502] iteration 9589 : model1 loss : 0.436513 model2 loss : 0.025090
[23:49:24.672] iteration 9590 : model1 loss : 0.438120 model2 loss : 0.025195
[23:49:24.847] iteration 9591 : model1 loss : 0.436929 model2 loss : 0.023593
[23:49:25.022] iteration 9592 : model1 loss : 0.436036 model2 loss : 0.022904
[23:49:25.200] iteration 9593 : model1 loss : 0.438887 model2 loss : 0.026829
[23:49:25.374] iteration 9594 : model1 loss : 0.438704 model2 loss : 0.023019
[23:49:25.555] iteration 9595 : model1 loss : 0.440867 model2 loss : 0.022704
[23:49:25.724] iteration 9596 : model1 loss : 0.437382 model2 loss : 0.020308
[23:49:25.900] iteration 9597 : model1 loss : 0.437063 model2 loss : 0.022334
[23:49:28.054] iteration 9598 : model1 loss : 0.440109 model2 loss : 0.025740
[23:49:28.226] iteration 9599 : model1 loss : 0.437442 model2 loss : 0.022948
[23:49:28.405] iteration 9600 : model1 loss : 0.436320 model2 loss : 0.020031
[23:49:28.577] iteration 9601 : model1 loss : 0.440771 model2 loss : 0.025506
[23:49:28.755] iteration 9602 : model1 loss : 0.437741 model2 loss : 0.023461
[23:49:28.927] iteration 9603 : model1 loss : 0.435304 model2 loss : 0.023558
[23:49:29.104] iteration 9604 : model1 loss : 0.436946 model2 loss : 0.023328
[23:49:29.276] iteration 9605 : model1 loss : 0.437586 model2 loss : 0.021831
[23:49:29.453] iteration 9606 : model1 loss : 0.432411 model2 loss : 0.022293
[23:49:29.630] iteration 9607 : model1 loss : 0.435300 model2 loss : 0.020493
[23:49:29.806] iteration 9608 : model1 loss : 0.431378 model2 loss : 0.020806
[23:49:29.982] iteration 9609 : model1 loss : 0.438395 model2 loss : 0.021775
[23:49:30.158] iteration 9610 : model1 loss : 0.434607 model2 loss : 0.025533
[23:49:30.333] iteration 9611 : model1 loss : 0.438731 model2 loss : 0.025546
[23:49:30.512] iteration 9612 : model1 loss : 0.436103 model2 loss : 0.023201
[23:49:30.685] iteration 9613 : model1 loss : 0.437602 model2 loss : 0.022944
[23:49:30.862] iteration 9614 : model1 loss : 0.438356 model2 loss : 0.023665
[23:49:31.037] iteration 9615 : model1 loss : 0.441023 model2 loss : 0.027653
[23:49:31.212] iteration 9616 : model1 loss : 0.435605 model2 loss : 0.022534
[23:49:31.384] iteration 9617 : model1 loss : 0.434078 model2 loss : 0.020635
[23:49:31.562] iteration 9618 : model1 loss : 0.438722 model2 loss : 0.024735
[23:49:33.744] iteration 9619 : model1 loss : 0.434313 model2 loss : 0.022922
[23:49:33.926] iteration 9620 : model1 loss : 0.431464 model2 loss : 0.021898
[23:49:34.104] iteration 9621 : model1 loss : 0.439619 model2 loss : 0.028458
[23:49:34.275] iteration 9622 : model1 loss : 0.443621 model2 loss : 0.026963
[23:49:34.451] iteration 9623 : model1 loss : 0.433820 model2 loss : 0.020264
[23:49:34.626] iteration 9624 : model1 loss : 0.435771 model2 loss : 0.023751
[23:49:34.799] iteration 9625 : model1 loss : 0.437341 model2 loss : 0.025048
[23:49:34.974] iteration 9626 : model1 loss : 0.441817 model2 loss : 0.023095
[23:49:35.151] iteration 9627 : model1 loss : 0.439142 model2 loss : 0.023707
[23:49:35.327] iteration 9628 : model1 loss : 0.438010 model2 loss : 0.020609
[23:49:35.506] iteration 9629 : model1 loss : 0.435335 model2 loss : 0.021375
[23:49:35.676] iteration 9630 : model1 loss : 0.440114 model2 loss : 0.023932
[23:49:35.852] iteration 9631 : model1 loss : 0.435493 model2 loss : 0.020044
[23:49:36.024] iteration 9632 : model1 loss : 0.436362 model2 loss : 0.023099
[23:49:36.199] iteration 9633 : model1 loss : 0.434457 model2 loss : 0.022457
[23:49:36.371] iteration 9634 : model1 loss : 0.436150 model2 loss : 0.022178
[23:49:36.548] iteration 9635 : model1 loss : 0.438864 model2 loss : 0.021452
[23:49:36.718] iteration 9636 : model1 loss : 0.437848 model2 loss : 0.021310
[23:49:36.896] iteration 9637 : model1 loss : 0.436427 model2 loss : 0.026009
[23:49:37.072] iteration 9638 : model1 loss : 0.435886 model2 loss : 0.021182
[23:49:37.245] iteration 9639 : model1 loss : 0.433486 model2 loss : 0.024874
[23:49:39.401] iteration 9640 : model1 loss : 0.439389 model2 loss : 0.022479
[23:49:39.577] iteration 9641 : model1 loss : 0.435445 model2 loss : 0.021378
[23:49:39.755] iteration 9642 : model1 loss : 0.443713 model2 loss : 0.030295
[23:49:39.927] iteration 9643 : model1 loss : 0.433874 model2 loss : 0.019562
[23:49:40.105] iteration 9644 : model1 loss : 0.438470 model2 loss : 0.023294
[23:49:40.274] iteration 9645 : model1 loss : 0.436212 model2 loss : 0.022575
[23:49:40.452] iteration 9646 : model1 loss : 0.434338 model2 loss : 0.021133
[23:49:40.629] iteration 9647 : model1 loss : 0.440284 model2 loss : 0.025297
[23:49:40.804] iteration 9648 : model1 loss : 0.432957 model2 loss : 0.023098
[23:49:40.977] iteration 9649 : model1 loss : 0.439927 model2 loss : 0.028332
[23:49:41.156] iteration 9650 : model1 loss : 0.432773 model2 loss : 0.024555
[23:49:41.334] iteration 9651 : model1 loss : 0.440064 model2 loss : 0.024359
[23:49:41.518] iteration 9652 : model1 loss : 0.440196 model2 loss : 0.025547
[23:49:41.690] iteration 9653 : model1 loss : 0.438813 model2 loss : 0.024229
[23:49:41.864] iteration 9654 : model1 loss : 0.440271 model2 loss : 0.027007
[23:49:42.038] iteration 9655 : model1 loss : 0.434307 model2 loss : 0.019720
[23:49:42.214] iteration 9656 : model1 loss : 0.437558 model2 loss : 0.024124
[23:49:42.385] iteration 9657 : model1 loss : 0.436510 model2 loss : 0.023978
[23:49:42.566] iteration 9658 : model1 loss : 0.436576 model2 loss : 0.024559
[23:49:42.735] iteration 9659 : model1 loss : 0.430925 model2 loss : 0.023063
[23:49:42.908] iteration 9660 : model1 loss : 0.437149 model2 loss : 0.024769
[23:49:45.031] iteration 9661 : model1 loss : 0.435315 model2 loss : 0.022585
[23:49:45.211] iteration 9662 : model1 loss : 0.438177 model2 loss : 0.022113
[23:49:45.388] iteration 9663 : model1 loss : 0.437485 model2 loss : 0.025752
[23:49:45.562] iteration 9664 : model1 loss : 0.442125 model2 loss : 0.028329
[23:49:45.736] iteration 9665 : model1 loss : 0.435732 model2 loss : 0.025170
[23:49:45.907] iteration 9666 : model1 loss : 0.432885 model2 loss : 0.020351
[23:49:46.084] iteration 9667 : model1 loss : 0.438087 model2 loss : 0.024611
[23:49:46.255] iteration 9668 : model1 loss : 0.436953 model2 loss : 0.024992
[23:49:46.433] iteration 9669 : model1 loss : 0.438011 model2 loss : 0.021342
[23:49:46.607] iteration 9670 : model1 loss : 0.435769 model2 loss : 0.021628
[23:49:46.780] iteration 9671 : model1 loss : 0.437929 model2 loss : 0.024525
[23:49:46.953] iteration 9672 : model1 loss : 0.438129 model2 loss : 0.022018
[23:49:47.128] iteration 9673 : model1 loss : 0.433516 model2 loss : 0.023368
[23:49:47.300] iteration 9674 : model1 loss : 0.441353 model2 loss : 0.026487
[23:49:47.484] iteration 9675 : model1 loss : 0.436655 model2 loss : 0.021289
[23:49:47.656] iteration 9676 : model1 loss : 0.434133 model2 loss : 0.023469
[23:49:47.833] iteration 9677 : model1 loss : 0.436070 model2 loss : 0.024851
[23:49:48.008] iteration 9678 : model1 loss : 0.434383 model2 loss : 0.023391
[23:49:48.186] iteration 9679 : model1 loss : 0.435850 model2 loss : 0.022656
[23:49:48.355] iteration 9680 : model1 loss : 0.436693 model2 loss : 0.025330
[23:49:48.533] iteration 9681 : model1 loss : 0.437825 model2 loss : 0.023878
[23:49:50.641] iteration 9682 : model1 loss : 0.440885 model2 loss : 0.030952
[23:49:50.812] iteration 9683 : model1 loss : 0.437191 model2 loss : 0.023268
[23:49:50.993] iteration 9684 : model1 loss : 0.438161 model2 loss : 0.025713
[23:49:51.167] iteration 9685 : model1 loss : 0.436606 model2 loss : 0.021174
[23:49:51.345] iteration 9686 : model1 loss : 0.436423 model2 loss : 0.021896
[23:49:51.523] iteration 9687 : model1 loss : 0.435380 model2 loss : 0.023045
[23:49:51.698] iteration 9688 : model1 loss : 0.438446 model2 loss : 0.025895
[23:49:51.870] iteration 9689 : model1 loss : 0.437176 model2 loss : 0.023756
[23:49:52.045] iteration 9690 : model1 loss : 0.435976 model2 loss : 0.024551
[23:49:52.216] iteration 9691 : model1 loss : 0.438615 model2 loss : 0.023181
[23:49:52.398] iteration 9692 : model1 loss : 0.437366 model2 loss : 0.020767
[23:49:52.574] iteration 9693 : model1 loss : 0.438371 model2 loss : 0.024094
[23:49:52.750] iteration 9694 : model1 loss : 0.440357 model2 loss : 0.027995
[23:49:52.920] iteration 9695 : model1 loss : 0.436894 model2 loss : 0.023895
[23:49:53.098] iteration 9696 : model1 loss : 0.437954 model2 loss : 0.021709
[23:49:53.270] iteration 9697 : model1 loss : 0.438661 model2 loss : 0.022450
[23:49:53.447] iteration 9698 : model1 loss : 0.436760 model2 loss : 0.025338
[23:49:53.622] iteration 9699 : model1 loss : 0.433319 model2 loss : 0.020710
[23:49:53.797] iteration 9700 : model1 loss : 0.435276 model2 loss : 0.022912
[23:49:53.970] iteration 9701 : model1 loss : 0.430860 model2 loss : 0.018366
[23:49:54.142] iteration 9702 : model1 loss : 0.437776 model2 loss : 0.022457
[23:49:56.275] iteration 9703 : model1 loss : 0.437806 model2 loss : 0.022666
[23:49:56.454] iteration 9704 : model1 loss : 0.440370 model2 loss : 0.025285
[23:49:56.635] iteration 9705 : model1 loss : 0.439498 model2 loss : 0.023051
[23:49:56.807] iteration 9706 : model1 loss : 0.437191 model2 loss : 0.021213
[23:49:56.982] iteration 9707 : model1 loss : 0.435526 model2 loss : 0.021006
[23:49:57.153] iteration 9708 : model1 loss : 0.435031 model2 loss : 0.023624
[23:49:57.331] iteration 9709 : model1 loss : 0.438337 model2 loss : 0.024766
[23:49:57.508] iteration 9710 : model1 loss : 0.439342 model2 loss : 0.025560
[23:49:57.687] iteration 9711 : model1 loss : 0.435674 model2 loss : 0.022997
[23:49:57.858] iteration 9712 : model1 loss : 0.436297 model2 loss : 0.021593
[23:49:58.035] iteration 9713 : model1 loss : 0.435649 model2 loss : 0.021137
[23:49:58.206] iteration 9714 : model1 loss : 0.438178 model2 loss : 0.024341
[23:49:58.381] iteration 9715 : model1 loss : 0.433842 model2 loss : 0.020738
[23:49:58.555] iteration 9716 : model1 loss : 0.437102 model2 loss : 0.019796
[23:49:58.730] iteration 9717 : model1 loss : 0.438548 model2 loss : 0.023964
[23:49:58.901] iteration 9718 : model1 loss : 0.437216 model2 loss : 0.022533
[23:49:59.081] iteration 9719 : model1 loss : 0.436801 model2 loss : 0.022494
[23:49:59.252] iteration 9720 : model1 loss : 0.438496 model2 loss : 0.025683
[23:49:59.429] iteration 9721 : model1 loss : 0.432805 model2 loss : 0.022293
[23:49:59.603] iteration 9722 : model1 loss : 0.433471 model2 loss : 0.023358
[23:49:59.781] iteration 9723 : model1 loss : 0.437746 model2 loss : 0.022304
[23:50:01.914] iteration 9724 : model1 loss : 0.438370 model2 loss : 0.021147
[23:50:02.094] iteration 9725 : model1 loss : 0.434503 model2 loss : 0.022675
[23:50:02.270] iteration 9726 : model1 loss : 0.436754 model2 loss : 0.021834
[23:50:02.445] iteration 9727 : model1 loss : 0.435960 model2 loss : 0.021033
[23:50:02.628] iteration 9728 : model1 loss : 0.437198 model2 loss : 0.024151
[23:50:02.799] iteration 9729 : model1 loss : 0.438864 model2 loss : 0.024551
[23:50:02.976] iteration 9730 : model1 loss : 0.436686 model2 loss : 0.026960
[23:50:03.147] iteration 9731 : model1 loss : 0.436407 model2 loss : 0.020680
[23:50:03.329] iteration 9732 : model1 loss : 0.436183 model2 loss : 0.023910
[23:50:03.505] iteration 9733 : model1 loss : 0.436759 model2 loss : 0.021166
[23:50:03.682] iteration 9734 : model1 loss : 0.437025 model2 loss : 0.019645
[23:50:03.852] iteration 9735 : model1 loss : 0.442401 model2 loss : 0.027048
[23:50:04.032] iteration 9736 : model1 loss : 0.440250 model2 loss : 0.025145
[23:50:04.202] iteration 9737 : model1 loss : 0.433697 model2 loss : 0.025503
[23:50:04.376] iteration 9738 : model1 loss : 0.440013 model2 loss : 0.026777
[23:50:04.551] iteration 9739 : model1 loss : 0.439725 model2 loss : 0.027363
[23:50:04.728] iteration 9740 : model1 loss : 0.438612 model2 loss : 0.023494
[23:50:04.898] iteration 9741 : model1 loss : 0.438440 model2 loss : 0.022586
[23:50:05.076] iteration 9742 : model1 loss : 0.439310 model2 loss : 0.023927
[23:50:05.246] iteration 9743 : model1 loss : 0.436931 model2 loss : 0.022995
[23:50:05.425] iteration 9744 : model1 loss : 0.433483 model2 loss : 0.021036
[23:50:07.633] iteration 9745 : model1 loss : 0.437528 model2 loss : 0.024264
[23:50:07.803] iteration 9746 : model1 loss : 0.434673 model2 loss : 0.021913
[23:50:07.984] iteration 9747 : model1 loss : 0.440945 model2 loss : 0.021989
[23:50:08.156] iteration 9748 : model1 loss : 0.437308 model2 loss : 0.022100
[23:50:08.337] iteration 9749 : model1 loss : 0.440464 model2 loss : 0.023280
[23:50:08.513] iteration 9750 : model1 loss : 0.433768 model2 loss : 0.025334
[23:50:08.691] iteration 9751 : model1 loss : 0.435531 model2 loss : 0.025394
[23:50:08.861] iteration 9752 : model1 loss : 0.437623 model2 loss : 0.023789
[23:50:09.038] iteration 9753 : model1 loss : 0.434945 model2 loss : 0.022883
[23:50:09.209] iteration 9754 : model1 loss : 0.433924 model2 loss : 0.025004
[23:50:09.387] iteration 9755 : model1 loss : 0.434811 model2 loss : 0.021711
[23:50:09.562] iteration 9756 : model1 loss : 0.440602 model2 loss : 0.023322
[23:50:09.742] iteration 9757 : model1 loss : 0.436294 model2 loss : 0.023280
[23:50:09.913] iteration 9758 : model1 loss : 0.435482 model2 loss : 0.020277
[23:50:10.093] iteration 9759 : model1 loss : 0.441855 model2 loss : 0.022997
[23:50:10.264] iteration 9760 : model1 loss : 0.438052 model2 loss : 0.029471
[23:50:10.439] iteration 9761 : model1 loss : 0.437635 model2 loss : 0.022704
[23:50:10.615] iteration 9762 : model1 loss : 0.435192 model2 loss : 0.022758
[23:50:10.792] iteration 9763 : model1 loss : 0.440622 model2 loss : 0.023852
[23:50:10.962] iteration 9764 : model1 loss : 0.431951 model2 loss : 0.019419
[23:50:11.140] iteration 9765 : model1 loss : 0.433345 model2 loss : 0.018397
[23:50:13.303] iteration 9766 : model1 loss : 0.432745 model2 loss : 0.022024
[23:50:13.478] iteration 9767 : model1 loss : 0.436603 model2 loss : 0.020698
[23:50:13.659] iteration 9768 : model1 loss : 0.439158 model2 loss : 0.020657
[23:50:13.830] iteration 9769 : model1 loss : 0.437866 model2 loss : 0.023866
[23:50:14.011] iteration 9770 : model1 loss : 0.438133 model2 loss : 0.024875
[23:50:14.181] iteration 9771 : model1 loss : 0.434736 model2 loss : 0.022412
[23:50:14.359] iteration 9772 : model1 loss : 0.434072 model2 loss : 0.022305
[23:50:14.531] iteration 9773 : model1 loss : 0.440806 model2 loss : 0.027650
[23:50:14.706] iteration 9774 : model1 loss : 0.441660 model2 loss : 0.025010
[23:50:14.879] iteration 9775 : model1 loss : 0.435468 model2 loss : 0.024761
[23:50:15.057] iteration 9776 : model1 loss : 0.438814 model2 loss : 0.022024
[23:50:15.228] iteration 9777 : model1 loss : 0.436131 model2 loss : 0.020413
[23:50:15.403] iteration 9778 : model1 loss : 0.432713 model2 loss : 0.020906
[23:50:15.576] iteration 9779 : model1 loss : 0.438839 model2 loss : 0.027156
[23:50:15.753] iteration 9780 : model1 loss : 0.443375 model2 loss : 0.024453
[23:50:15.924] iteration 9781 : model1 loss : 0.435301 model2 loss : 0.021323
[23:50:16.103] iteration 9782 : model1 loss : 0.432515 model2 loss : 0.024435
[23:50:16.273] iteration 9783 : model1 loss : 0.434997 model2 loss : 0.020756
[23:50:16.448] iteration 9784 : model1 loss : 0.438876 model2 loss : 0.025914
[23:50:16.623] iteration 9785 : model1 loss : 0.436538 model2 loss : 0.023157
[23:50:16.796] iteration 9786 : model1 loss : 0.434817 model2 loss : 0.022454
[23:50:18.923] iteration 9787 : model1 loss : 0.437139 model2 loss : 0.023869
[23:50:19.100] iteration 9788 : model1 loss : 0.437391 model2 loss : 0.024653
[23:50:19.279] iteration 9789 : model1 loss : 0.433661 model2 loss : 0.022478
[23:50:19.449] iteration 9790 : model1 loss : 0.434694 model2 loss : 0.021171
[23:50:19.629] iteration 9791 : model1 loss : 0.432279 model2 loss : 0.020644
[23:50:19.800] iteration 9792 : model1 loss : 0.436997 model2 loss : 0.025300
[23:50:19.977] iteration 9793 : model1 loss : 0.436236 model2 loss : 0.023413
[23:50:20.152] iteration 9794 : model1 loss : 0.438546 model2 loss : 0.023645
[23:50:20.330] iteration 9795 : model1 loss : 0.436806 model2 loss : 0.023348
[23:50:20.504] iteration 9796 : model1 loss : 0.440021 model2 loss : 0.022291
[23:50:20.685] iteration 9797 : model1 loss : 0.434640 model2 loss : 0.018698
[23:50:20.855] iteration 9798 : model1 loss : 0.434801 model2 loss : 0.022838
[23:50:21.032] iteration 9799 : model1 loss : 0.440465 model2 loss : 0.025073
[23:50:21.204] iteration 9800 : model1 loss : 0.437781 model2 loss : 0.022161
[23:50:21.381] iteration 9801 : model1 loss : 0.441878 model2 loss : 0.025274
[23:50:21.554] iteration 9802 : model1 loss : 0.435736 model2 loss : 0.022490
[23:50:21.733] iteration 9803 : model1 loss : 0.438787 model2 loss : 0.023995
[23:50:21.904] iteration 9804 : model1 loss : 0.436050 model2 loss : 0.023022
[23:50:22.081] iteration 9805 : model1 loss : 0.435195 model2 loss : 0.022095
[23:50:22.251] iteration 9806 : model1 loss : 0.431426 model2 loss : 0.021395
[23:50:22.429] iteration 9807 : model1 loss : 0.435442 model2 loss : 0.022071
[23:50:24.537] iteration 9808 : model1 loss : 0.435385 model2 loss : 0.019860
[23:50:24.709] iteration 9809 : model1 loss : 0.437559 model2 loss : 0.023527
[23:50:24.885] iteration 9810 : model1 loss : 0.441678 model2 loss : 0.025089
[23:50:25.059] iteration 9811 : model1 loss : 0.433647 model2 loss : 0.023506
[23:50:25.235] iteration 9812 : model1 loss : 0.436107 model2 loss : 0.023411
[23:50:25.405] iteration 9813 : model1 loss : 0.439214 model2 loss : 0.024724
[23:50:25.587] iteration 9814 : model1 loss : 0.436450 model2 loss : 0.021153
[23:50:25.755] iteration 9815 : model1 loss : 0.436465 model2 loss : 0.023111
[23:50:25.931] iteration 9816 : model1 loss : 0.437093 model2 loss : 0.023312
[23:50:26.106] iteration 9817 : model1 loss : 0.434851 model2 loss : 0.022336
[23:50:26.281] iteration 9818 : model1 loss : 0.435804 model2 loss : 0.025051
[23:50:26.452] iteration 9819 : model1 loss : 0.438613 model2 loss : 0.021993
[23:50:26.633] iteration 9820 : model1 loss : 0.442389 model2 loss : 0.025087
[23:50:26.804] iteration 9821 : model1 loss : 0.433245 model2 loss : 0.020946
[23:50:26.980] iteration 9822 : model1 loss : 0.433472 model2 loss : 0.023831
[23:50:27.155] iteration 9823 : model1 loss : 0.439950 model2 loss : 0.025434
[23:50:27.335] iteration 9824 : model1 loss : 0.438341 model2 loss : 0.019411
[23:50:27.514] iteration 9825 : model1 loss : 0.440601 model2 loss : 0.024987
[23:50:27.693] iteration 9826 : model1 loss : 0.434882 model2 loss : 0.023206
[23:50:27.863] iteration 9827 : model1 loss : 0.433063 model2 loss : 0.020343
[23:50:28.041] iteration 9828 : model1 loss : 0.435823 model2 loss : 0.020151
[23:50:30.133] iteration 9829 : model1 loss : 0.437818 model2 loss : 0.020769
[23:50:30.305] iteration 9830 : model1 loss : 0.437120 model2 loss : 0.022086
[23:50:30.482] iteration 9831 : model1 loss : 0.434837 model2 loss : 0.022470
[23:50:30.656] iteration 9832 : model1 loss : 0.436655 model2 loss : 0.021293
[23:50:30.829] iteration 9833 : model1 loss : 0.438225 model2 loss : 0.022500
[23:50:31.001] iteration 9834 : model1 loss : 0.435984 model2 loss : 0.022275
[23:50:31.179] iteration 9835 : model1 loss : 0.441409 model2 loss : 0.027583
[23:50:31.351] iteration 9836 : model1 loss : 0.434436 model2 loss : 0.023931
[23:50:31.527] iteration 9837 : model1 loss : 0.436993 model2 loss : 0.025167
[23:50:31.699] iteration 9838 : model1 loss : 0.437316 model2 loss : 0.020532
[23:50:31.874] iteration 9839 : model1 loss : 0.440056 model2 loss : 0.022801
[23:50:32.046] iteration 9840 : model1 loss : 0.437046 model2 loss : 0.025836
[23:50:32.224] iteration 9841 : model1 loss : 0.438997 model2 loss : 0.025294
[23:50:32.396] iteration 9842 : model1 loss : 0.438293 model2 loss : 0.023585
[23:50:32.574] iteration 9843 : model1 loss : 0.434508 model2 loss : 0.022886
[23:50:32.745] iteration 9844 : model1 loss : 0.433874 model2 loss : 0.020352
[23:50:32.920] iteration 9845 : model1 loss : 0.440278 model2 loss : 0.021632
[23:50:33.093] iteration 9846 : model1 loss : 0.435791 model2 loss : 0.022992
[23:50:33.270] iteration 9847 : model1 loss : 0.436050 model2 loss : 0.020504
[23:50:33.439] iteration 9848 : model1 loss : 0.440878 model2 loss : 0.023673
[23:50:33.617] iteration 9849 : model1 loss : 0.434195 model2 loss : 0.020722
[23:50:35.720] iteration 9850 : model1 loss : 0.436492 model2 loss : 0.021938
[23:50:35.890] iteration 9851 : model1 loss : 0.435797 model2 loss : 0.021317
[23:50:36.066] iteration 9852 : model1 loss : 0.442020 model2 loss : 0.022376
[23:50:36.237] iteration 9853 : model1 loss : 0.439343 model2 loss : 0.024707
[23:50:36.415] iteration 9854 : model1 loss : 0.439476 model2 loss : 0.026992
[23:50:36.590] iteration 9855 : model1 loss : 0.438032 model2 loss : 0.023531
[23:50:36.767] iteration 9856 : model1 loss : 0.433689 model2 loss : 0.022167
[23:50:36.937] iteration 9857 : model1 loss : 0.432119 model2 loss : 0.020386
[23:50:37.117] iteration 9858 : model1 loss : 0.439502 model2 loss : 0.024531
[23:50:37.288] iteration 9859 : model1 loss : 0.439016 model2 loss : 0.023677
[23:50:37.468] iteration 9860 : model1 loss : 0.436327 model2 loss : 0.025114
[23:50:37.643] iteration 9861 : model1 loss : 0.439245 model2 loss : 0.023445
[23:50:37.821] iteration 9862 : model1 loss : 0.438911 model2 loss : 0.019650
[23:50:37.991] iteration 9863 : model1 loss : 0.436525 model2 loss : 0.024498
[23:50:38.169] iteration 9864 : model1 loss : 0.440151 model2 loss : 0.019907
[23:50:38.341] iteration 9865 : model1 loss : 0.430038 model2 loss : 0.019123
[23:50:38.519] iteration 9866 : model1 loss : 0.438098 model2 loss : 0.022580
[23:50:38.692] iteration 9867 : model1 loss : 0.439765 model2 loss : 0.022528
[23:50:38.869] iteration 9868 : model1 loss : 0.436714 model2 loss : 0.019872
[23:50:39.042] iteration 9869 : model1 loss : 0.436575 model2 loss : 0.021375
[23:50:39.218] iteration 9870 : model1 loss : 0.441425 model2 loss : 0.028525
[23:50:41.337] iteration 9871 : model1 loss : 0.435752 model2 loss : 0.019717
[23:50:41.506] iteration 9872 : model1 loss : 0.440269 model2 loss : 0.022370
[23:50:41.688] iteration 9873 : model1 loss : 0.434328 model2 loss : 0.021878
[23:50:41.861] iteration 9874 : model1 loss : 0.436834 model2 loss : 0.022146
[23:50:42.041] iteration 9875 : model1 loss : 0.438427 model2 loss : 0.025261
[23:50:42.212] iteration 9876 : model1 loss : 0.439358 model2 loss : 0.027489
[23:50:42.389] iteration 9877 : model1 loss : 0.436680 model2 loss : 0.021297
[23:50:42.568] iteration 9878 : model1 loss : 0.437255 model2 loss : 0.021941
[23:50:42.743] iteration 9879 : model1 loss : 0.436099 model2 loss : 0.021104
[23:50:42.914] iteration 9880 : model1 loss : 0.436335 model2 loss : 0.020755
[23:50:43.092] iteration 9881 : model1 loss : 0.437320 model2 loss : 0.023217
[23:50:43.263] iteration 9882 : model1 loss : 0.440212 model2 loss : 0.030654
[23:50:43.438] iteration 9883 : model1 loss : 0.436644 model2 loss : 0.023972
[23:50:43.615] iteration 9884 : model1 loss : 0.438347 model2 loss : 0.023069
[23:50:43.790] iteration 9885 : model1 loss : 0.437044 model2 loss : 0.026032
[23:50:43.965] iteration 9886 : model1 loss : 0.435144 model2 loss : 0.020269
[23:50:44.142] iteration 9887 : model1 loss : 0.440224 model2 loss : 0.022998
[23:50:44.317] iteration 9888 : model1 loss : 0.435540 model2 loss : 0.021248
[23:50:44.496] iteration 9889 : model1 loss : 0.433733 model2 loss : 0.021762
[23:50:44.669] iteration 9890 : model1 loss : 0.433453 model2 loss : 0.022084
[23:50:44.842] iteration 9891 : model1 loss : 0.441136 model2 loss : 0.026032
[23:50:46.976] iteration 9892 : model1 loss : 0.432943 model2 loss : 0.021334
[23:50:47.154] iteration 9893 : model1 loss : 0.436296 model2 loss : 0.024718
[23:50:47.367] iteration 9894 : model1 loss : 0.435355 model2 loss : 0.023544
[23:50:47.542] iteration 9895 : model1 loss : 0.439655 model2 loss : 0.022573
[23:50:47.718] iteration 9896 : model1 loss : 0.437533 model2 loss : 0.023758
[23:50:47.889] iteration 9897 : model1 loss : 0.439311 model2 loss : 0.025440
[23:50:48.067] iteration 9898 : model1 loss : 0.432518 model2 loss : 0.019571
[23:50:48.238] iteration 9899 : model1 loss : 0.436105 model2 loss : 0.022872
[23:50:48.412] iteration 9900 : model1 loss : 0.439288 model2 loss : 0.026303
[23:50:48.587] iteration 9901 : model1 loss : 0.437493 model2 loss : 0.022326
[23:50:48.764] iteration 9902 : model1 loss : 0.434287 model2 loss : 0.023178
[23:50:48.934] iteration 9903 : model1 loss : 0.437318 model2 loss : 0.024462
[23:50:49.115] iteration 9904 : model1 loss : 0.437447 model2 loss : 0.021912
[23:50:49.285] iteration 9905 : model1 loss : 0.432879 model2 loss : 0.021722
[23:50:49.460] iteration 9906 : model1 loss : 0.437783 model2 loss : 0.020995
[23:50:49.635] iteration 9907 : model1 loss : 0.441582 model2 loss : 0.023594
[23:50:49.812] iteration 9908 : model1 loss : 0.435268 model2 loss : 0.021048
[23:50:49.983] iteration 9909 : model1 loss : 0.436014 model2 loss : 0.023578
[23:50:50.160] iteration 9910 : model1 loss : 0.434996 model2 loss : 0.024081
[23:50:50.334] iteration 9911 : model1 loss : 0.435603 model2 loss : 0.021345
[23:50:50.506] iteration 9912 : model1 loss : 0.442368 model2 loss : 0.022279
[23:50:52.668] iteration 9913 : model1 loss : 0.435427 model2 loss : 0.022324
[23:50:52.839] iteration 9914 : model1 loss : 0.438595 model2 loss : 0.027829
[23:50:53.017] iteration 9915 : model1 loss : 0.436698 model2 loss : 0.023533
[23:50:53.192] iteration 9916 : model1 loss : 0.435190 model2 loss : 0.021099
[23:50:53.368] iteration 9917 : model1 loss : 0.434333 model2 loss : 0.022799
[23:50:53.538] iteration 9918 : model1 loss : 0.437947 model2 loss : 0.019655
[23:50:53.717] iteration 9919 : model1 loss : 0.436745 model2 loss : 0.023754
[23:50:53.886] iteration 9920 : model1 loss : 0.436469 model2 loss : 0.024440
[23:50:54.063] iteration 9921 : model1 loss : 0.432183 model2 loss : 0.020894
[23:50:54.235] iteration 9922 : model1 loss : 0.437909 model2 loss : 0.022247
[23:50:54.411] iteration 9923 : model1 loss : 0.437182 model2 loss : 0.022185
[23:50:54.584] iteration 9924 : model1 loss : 0.439961 model2 loss : 0.024651
[23:50:54.761] iteration 9925 : model1 loss : 0.437786 model2 loss : 0.022809
[23:50:54.932] iteration 9926 : model1 loss : 0.438669 model2 loss : 0.023600
[23:50:55.110] iteration 9927 : model1 loss : 0.439921 model2 loss : 0.025461
[23:50:55.282] iteration 9928 : model1 loss : 0.436765 model2 loss : 0.022700
[23:50:55.460] iteration 9929 : model1 loss : 0.436948 model2 loss : 0.022983
[23:50:55.637] iteration 9930 : model1 loss : 0.438672 model2 loss : 0.023493
[23:50:55.812] iteration 9931 : model1 loss : 0.434653 model2 loss : 0.021091
[23:50:55.982] iteration 9932 : model1 loss : 0.436684 model2 loss : 0.022390
[23:50:56.159] iteration 9933 : model1 loss : 0.436187 model2 loss : 0.023169
[23:50:58.330] iteration 9934 : model1 loss : 0.437390 model2 loss : 0.019785
[23:50:58.505] iteration 9935 : model1 loss : 0.442387 model2 loss : 0.026572
[23:50:58.683] iteration 9936 : model1 loss : 0.436581 model2 loss : 0.021646
[23:50:58.857] iteration 9937 : model1 loss : 0.432368 model2 loss : 0.020049
[23:50:59.032] iteration 9938 : model1 loss : 0.439453 model2 loss : 0.022563
[23:50:59.207] iteration 9939 : model1 loss : 0.436896 model2 loss : 0.024252
[23:50:59.384] iteration 9940 : model1 loss : 0.440509 model2 loss : 0.024251
[23:50:59.554] iteration 9941 : model1 loss : 0.436746 model2 loss : 0.020825
[23:50:59.732] iteration 9942 : model1 loss : 0.434767 model2 loss : 0.024481
[23:50:59.903] iteration 9943 : model1 loss : 0.433599 model2 loss : 0.022731
[23:51:00.083] iteration 9944 : model1 loss : 0.439197 model2 loss : 0.022364
[23:51:00.259] iteration 9945 : model1 loss : 0.436684 model2 loss : 0.022479
[23:51:00.434] iteration 9946 : model1 loss : 0.436619 model2 loss : 0.020775
[23:51:00.613] iteration 9947 : model1 loss : 0.433315 model2 loss : 0.024022
[23:51:00.793] iteration 9948 : model1 loss : 0.435400 model2 loss : 0.021538
[23:51:00.964] iteration 9949 : model1 loss : 0.437951 model2 loss : 0.027656
[23:51:01.142] iteration 9950 : model1 loss : 0.438638 model2 loss : 0.025355
[23:51:01.317] iteration 9951 : model1 loss : 0.433556 model2 loss : 0.020689
[23:51:01.496] iteration 9952 : model1 loss : 0.434804 model2 loss : 0.022586
[23:51:01.669] iteration 9953 : model1 loss : 0.440553 model2 loss : 0.023376
[23:51:01.840] iteration 9954 : model1 loss : 0.435229 model2 loss : 0.022765
[23:51:04.005] iteration 9955 : model1 loss : 0.439796 model2 loss : 0.020689
[23:51:04.177] iteration 9956 : model1 loss : 0.432835 model2 loss : 0.022461
[23:51:04.354] iteration 9957 : model1 loss : 0.435408 model2 loss : 0.023056
[23:51:04.525] iteration 9958 : model1 loss : 0.438911 model2 loss : 0.020254
[23:51:04.698] iteration 9959 : model1 loss : 0.438462 model2 loss : 0.022796
[23:51:04.868] iteration 9960 : model1 loss : 0.434297 model2 loss : 0.020839
[23:51:05.043] iteration 9961 : model1 loss : 0.432938 model2 loss : 0.021700
[23:51:05.217] iteration 9962 : model1 loss : 0.439577 model2 loss : 0.024492
[23:51:05.396] iteration 9963 : model1 loss : 0.436349 model2 loss : 0.022014
[23:51:05.571] iteration 9964 : model1 loss : 0.438489 model2 loss : 0.022026
[23:51:05.747] iteration 9965 : model1 loss : 0.440071 model2 loss : 0.024125
[23:51:05.918] iteration 9966 : model1 loss : 0.432599 model2 loss : 0.020921
[23:51:06.098] iteration 9967 : model1 loss : 0.437338 model2 loss : 0.023473
[23:51:06.269] iteration 9968 : model1 loss : 0.435148 model2 loss : 0.021701
[23:51:06.447] iteration 9969 : model1 loss : 0.437594 model2 loss : 0.021591
[23:51:06.623] iteration 9970 : model1 loss : 0.435480 model2 loss : 0.022415
[23:51:06.801] iteration 9971 : model1 loss : 0.437339 model2 loss : 0.020872
[23:51:06.974] iteration 9972 : model1 loss : 0.436739 model2 loss : 0.020395
[23:51:07.155] iteration 9973 : model1 loss : 0.439161 model2 loss : 0.024704
[23:51:07.328] iteration 9974 : model1 loss : 0.435015 model2 loss : 0.021347
[23:51:07.505] iteration 9975 : model1 loss : 0.438152 model2 loss : 0.024080
[23:51:09.627] iteration 9976 : model1 loss : 0.437483 model2 loss : 0.020970
[23:51:09.800] iteration 9977 : model1 loss : 0.442034 model2 loss : 0.025599
[23:51:09.979] iteration 9978 : model1 loss : 0.436513 model2 loss : 0.021690
[23:51:10.152] iteration 9979 : model1 loss : 0.435741 model2 loss : 0.022192
[23:51:10.331] iteration 9980 : model1 loss : 0.436705 model2 loss : 0.021820
[23:51:10.502] iteration 9981 : model1 loss : 0.435188 model2 loss : 0.020756
[23:51:10.679] iteration 9982 : model1 loss : 0.435257 model2 loss : 0.021379
[23:51:10.848] iteration 9983 : model1 loss : 0.434879 model2 loss : 0.025217
[23:51:11.024] iteration 9984 : model1 loss : 0.435802 model2 loss : 0.022604
[23:51:11.199] iteration 9985 : model1 loss : 0.439516 model2 loss : 0.022775
[23:51:11.373] iteration 9986 : model1 loss : 0.435716 model2 loss : 0.022948
[23:51:11.546] iteration 9987 : model1 loss : 0.438595 model2 loss : 0.023906
[23:51:11.723] iteration 9988 : model1 loss : 0.434722 model2 loss : 0.023981
[23:51:11.895] iteration 9989 : model1 loss : 0.435216 model2 loss : 0.021338
[23:51:12.072] iteration 9990 : model1 loss : 0.433051 model2 loss : 0.021848
[23:51:12.246] iteration 9991 : model1 loss : 0.442868 model2 loss : 0.028639
[23:51:12.427] iteration 9992 : model1 loss : 0.440523 model2 loss : 0.026021
[23:51:12.606] iteration 9993 : model1 loss : 0.438374 model2 loss : 0.020683
[23:51:12.782] iteration 9994 : model1 loss : 0.438840 model2 loss : 0.020541
[23:51:12.951] iteration 9995 : model1 loss : 0.434113 model2 loss : 0.020988
[23:51:13.126] iteration 9996 : model1 loss : 0.434132 model2 loss : 0.023235
[23:51:15.272] iteration 9997 : model1 loss : 0.436761 model2 loss : 0.020482
[23:51:15.448] iteration 9998 : model1 loss : 0.433034 model2 loss : 0.023918
[23:51:15.631] iteration 9999 : model1 loss : 0.434308 model2 loss : 0.020997
[23:51:15.802] iteration 10000 : model1 loss : 0.436814 model2 loss : 0.021072
[23:51:24.929] iteration 10000 : model1_mean_dice : 0.823855 model1_mean_hd95 : 11.299500
[23:51:34.039] iteration 10000 : model2_mean_dice : 0.857189 model2_mean_hd95 : 3.946421
[23:51:34.221] iteration 10001 : model1 loss : 0.437906 model2 loss : 0.022647
[23:51:34.400] iteration 10002 : model1 loss : 0.435950 model2 loss : 0.021282
[23:51:34.575] iteration 10003 : model1 loss : 0.435661 model2 loss : 0.025112
[23:51:34.750] iteration 10004 : model1 loss : 0.440638 model2 loss : 0.021484
[23:51:34.919] iteration 10005 : model1 loss : 0.433322 model2 loss : 0.023303
[23:51:35.095] iteration 10006 : model1 loss : 0.441767 model2 loss : 0.026526
[23:51:35.266] iteration 10007 : model1 loss : 0.440151 model2 loss : 0.025142
[23:51:35.440] iteration 10008 : model1 loss : 0.435534 model2 loss : 0.020197
[23:51:35.614] iteration 10009 : model1 loss : 0.435720 model2 loss : 0.021558
[23:51:35.795] iteration 10010 : model1 loss : 0.438558 model2 loss : 0.022235
[23:51:35.964] iteration 10011 : model1 loss : 0.437075 model2 loss : 0.022933
[23:51:36.140] iteration 10012 : model1 loss : 0.436092 model2 loss : 0.022084
[23:51:36.318] iteration 10013 : model1 loss : 0.441723 model2 loss : 0.021194
[23:51:36.494] iteration 10014 : model1 loss : 0.436110 model2 loss : 0.022400
[23:51:36.666] iteration 10015 : model1 loss : 0.439178 model2 loss : 0.023746
[23:51:36.840] iteration 10016 : model1 loss : 0.435495 model2 loss : 0.021037
[23:51:37.009] iteration 10017 : model1 loss : 0.435308 model2 loss : 0.022496
[23:51:39.188] iteration 10018 : model1 loss : 0.438473 model2 loss : 0.025693
[23:51:39.362] iteration 10019 : model1 loss : 0.435938 model2 loss : 0.021406
[23:51:39.541] iteration 10020 : model1 loss : 0.436841 model2 loss : 0.024564
[23:51:39.713] iteration 10021 : model1 loss : 0.437029 model2 loss : 0.018984
[23:51:39.892] iteration 10022 : model1 loss : 0.436426 model2 loss : 0.024347
[23:51:40.064] iteration 10023 : model1 loss : 0.437557 model2 loss : 0.022662
[23:51:40.240] iteration 10024 : model1 loss : 0.433653 model2 loss : 0.021433
[23:51:40.411] iteration 10025 : model1 loss : 0.434546 model2 loss : 0.022178
[23:51:40.588] iteration 10026 : model1 loss : 0.436835 model2 loss : 0.022213
[23:51:40.762] iteration 10027 : model1 loss : 0.441190 model2 loss : 0.023215
[23:51:40.937] iteration 10028 : model1 loss : 0.435593 model2 loss : 0.020801
[23:51:41.112] iteration 10029 : model1 loss : 0.442395 model2 loss : 0.024369
[23:51:41.290] iteration 10030 : model1 loss : 0.432961 model2 loss : 0.020769
[23:51:41.461] iteration 10031 : model1 loss : 0.438026 model2 loss : 0.026724
[23:51:41.637] iteration 10032 : model1 loss : 0.439610 model2 loss : 0.024643
[23:51:41.810] iteration 10033 : model1 loss : 0.436005 model2 loss : 0.023197
[23:51:41.990] iteration 10034 : model1 loss : 0.438668 model2 loss : 0.026764
[23:51:42.163] iteration 10035 : model1 loss : 0.437463 model2 loss : 0.020911
[23:51:42.341] iteration 10036 : model1 loss : 0.433909 model2 loss : 0.023715
[23:51:42.510] iteration 10037 : model1 loss : 0.434361 model2 loss : 0.020766
[23:51:42.687] iteration 10038 : model1 loss : 0.436626 model2 loss : 0.022664
[23:51:44.799] iteration 10039 : model1 loss : 0.436070 model2 loss : 0.024862
[23:51:44.976] iteration 10040 : model1 loss : 0.431176 model2 loss : 0.021482
[23:51:45.154] iteration 10041 : model1 loss : 0.436801 model2 loss : 0.021599
[23:51:45.329] iteration 10042 : model1 loss : 0.437349 model2 loss : 0.020810
[23:51:45.503] iteration 10043 : model1 loss : 0.437496 model2 loss : 0.022622
[23:51:45.677] iteration 10044 : model1 loss : 0.440478 model2 loss : 0.023574
[23:51:45.851] iteration 10045 : model1 loss : 0.435227 model2 loss : 0.022598
[23:51:46.022] iteration 10046 : model1 loss : 0.433574 model2 loss : 0.024542
[23:51:46.198] iteration 10047 : model1 loss : 0.439990 model2 loss : 0.023709
[23:51:46.369] iteration 10048 : model1 loss : 0.439521 model2 loss : 0.023254
[23:51:46.544] iteration 10049 : model1 loss : 0.438695 model2 loss : 0.022049
[23:51:46.716] iteration 10050 : model1 loss : 0.435836 model2 loss : 0.022743
[23:51:46.900] iteration 10051 : model1 loss : 0.439007 model2 loss : 0.025127
[23:51:47.070] iteration 10052 : model1 loss : 0.437267 model2 loss : 0.021605
[23:51:47.246] iteration 10053 : model1 loss : 0.439988 model2 loss : 0.025525
[23:51:47.422] iteration 10054 : model1 loss : 0.437239 model2 loss : 0.021885
[23:51:47.597] iteration 10055 : model1 loss : 0.435964 model2 loss : 0.021644
[23:51:47.769] iteration 10056 : model1 loss : 0.439736 model2 loss : 0.027074
[23:51:47.946] iteration 10057 : model1 loss : 0.435197 model2 loss : 0.023443
[23:51:48.118] iteration 10058 : model1 loss : 0.434634 model2 loss : 0.021257
[23:51:48.293] iteration 10059 : model1 loss : 0.435566 model2 loss : 0.024351
[23:51:50.416] iteration 10060 : model1 loss : 0.440116 model2 loss : 0.023327
[23:51:50.588] iteration 10061 : model1 loss : 0.442610 model2 loss : 0.023782
[23:51:50.766] iteration 10062 : model1 loss : 0.439427 model2 loss : 0.021611
[23:51:50.936] iteration 10063 : model1 loss : 0.433403 model2 loss : 0.022290
[23:51:51.110] iteration 10064 : model1 loss : 0.438104 model2 loss : 0.024101
[23:51:51.284] iteration 10065 : model1 loss : 0.436679 model2 loss : 0.023305
[23:51:51.461] iteration 10066 : model1 loss : 0.435343 model2 loss : 0.021823
[23:51:51.638] iteration 10067 : model1 loss : 0.437265 model2 loss : 0.024705
[23:51:51.818] iteration 10068 : model1 loss : 0.432726 model2 loss : 0.021017
[23:51:51.987] iteration 10069 : model1 loss : 0.437674 model2 loss : 0.020238
[23:51:52.161] iteration 10070 : model1 loss : 0.439562 model2 loss : 0.025655
[23:51:52.336] iteration 10071 : model1 loss : 0.436250 model2 loss : 0.021977
[23:51:52.512] iteration 10072 : model1 loss : 0.432097 model2 loss : 0.020552
[23:51:52.683] iteration 10073 : model1 loss : 0.434736 model2 loss : 0.019381
[23:51:52.861] iteration 10074 : model1 loss : 0.439132 model2 loss : 0.022726
[23:51:53.033] iteration 10075 : model1 loss : 0.437540 model2 loss : 0.023864
[23:51:53.210] iteration 10076 : model1 loss : 0.432003 model2 loss : 0.022782
[23:51:53.381] iteration 10077 : model1 loss : 0.440875 model2 loss : 0.025003
[23:51:53.555] iteration 10078 : model1 loss : 0.436248 model2 loss : 0.023720
[23:51:53.724] iteration 10079 : model1 loss : 0.438199 model2 loss : 0.027531
[23:51:53.897] iteration 10080 : model1 loss : 0.433622 model2 loss : 0.020208
[23:51:56.014] iteration 10081 : model1 loss : 0.438399 model2 loss : 0.023439
[23:51:56.190] iteration 10082 : model1 loss : 0.438031 model2 loss : 0.024919
[23:51:56.372] iteration 10083 : model1 loss : 0.436322 model2 loss : 0.025622
[23:51:56.542] iteration 10084 : model1 loss : 0.438921 model2 loss : 0.023367
[23:51:56.718] iteration 10085 : model1 loss : 0.432846 model2 loss : 0.020438
[23:51:56.890] iteration 10086 : model1 loss : 0.437528 model2 loss : 0.023122
[23:51:57.065] iteration 10087 : model1 loss : 0.435489 model2 loss : 0.021942
[23:51:57.239] iteration 10088 : model1 loss : 0.433980 model2 loss : 0.022441
[23:51:57.416] iteration 10089 : model1 loss : 0.436753 model2 loss : 0.022256
[23:51:57.586] iteration 10090 : model1 loss : 0.436500 model2 loss : 0.022814
[23:51:57.762] iteration 10091 : model1 loss : 0.444986 model2 loss : 0.027569
[23:51:57.931] iteration 10092 : model1 loss : 0.436272 model2 loss : 0.022842
[23:51:58.106] iteration 10093 : model1 loss : 0.435366 model2 loss : 0.023739
[23:51:58.280] iteration 10094 : model1 loss : 0.434536 model2 loss : 0.022716
[23:51:58.456] iteration 10095 : model1 loss : 0.431991 model2 loss : 0.019574
[23:51:58.630] iteration 10096 : model1 loss : 0.436683 model2 loss : 0.024212
[23:51:58.804] iteration 10097 : model1 loss : 0.437841 model2 loss : 0.024101
[23:51:58.976] iteration 10098 : model1 loss : 0.436230 model2 loss : 0.021339
[23:51:59.152] iteration 10099 : model1 loss : 0.440646 model2 loss : 0.023812
[23:51:59.329] iteration 10100 : model1 loss : 0.437026 model2 loss : 0.021370
[23:51:59.504] iteration 10101 : model1 loss : 0.435953 model2 loss : 0.020247
[23:52:01.642] iteration 10102 : model1 loss : 0.437395 model2 loss : 0.022397
[23:52:01.817] iteration 10103 : model1 loss : 0.437993 model2 loss : 0.022981
[23:52:01.995] iteration 10104 : model1 loss : 0.440186 model2 loss : 0.022697
[23:52:02.175] iteration 10105 : model1 loss : 0.435497 model2 loss : 0.021669
[23:52:02.355] iteration 10106 : model1 loss : 0.438058 model2 loss : 0.026788
[23:52:02.530] iteration 10107 : model1 loss : 0.436637 model2 loss : 0.022894
[23:52:02.708] iteration 10108 : model1 loss : 0.436721 model2 loss : 0.023369
[23:52:02.879] iteration 10109 : model1 loss : 0.442952 model2 loss : 0.026111
[23:52:03.054] iteration 10110 : model1 loss : 0.439918 model2 loss : 0.023910
[23:52:03.231] iteration 10111 : model1 loss : 0.434305 model2 loss : 0.021604
[23:52:03.407] iteration 10112 : model1 loss : 0.433173 model2 loss : 0.023607
[23:52:03.578] iteration 10113 : model1 loss : 0.434985 model2 loss : 0.022947
[23:52:03.754] iteration 10114 : model1 loss : 0.435376 model2 loss : 0.022138
[23:52:03.926] iteration 10115 : model1 loss : 0.436613 model2 loss : 0.022827
[23:52:04.101] iteration 10116 : model1 loss : 0.438307 model2 loss : 0.023062
[23:52:04.275] iteration 10117 : model1 loss : 0.435390 model2 loss : 0.021946
[23:52:04.450] iteration 10118 : model1 loss : 0.436653 model2 loss : 0.022864
[23:52:04.623] iteration 10119 : model1 loss : 0.435147 model2 loss : 0.023124
[23:52:04.799] iteration 10120 : model1 loss : 0.435684 model2 loss : 0.023627
[23:52:04.972] iteration 10121 : model1 loss : 0.437730 model2 loss : 0.022516
[23:52:05.147] iteration 10122 : model1 loss : 0.440867 model2 loss : 0.027432
[23:52:07.271] iteration 10123 : model1 loss : 0.437044 model2 loss : 0.023130
[23:52:07.444] iteration 10124 : model1 loss : 0.436098 model2 loss : 0.023195
[23:52:07.627] iteration 10125 : model1 loss : 0.440975 model2 loss : 0.024735
[23:52:07.803] iteration 10126 : model1 loss : 0.435169 model2 loss : 0.022965
[23:52:07.980] iteration 10127 : model1 loss : 0.435068 model2 loss : 0.021327
[23:52:08.153] iteration 10128 : model1 loss : 0.435380 model2 loss : 0.022362
[23:52:08.331] iteration 10129 : model1 loss : 0.437335 model2 loss : 0.025742
[23:52:08.502] iteration 10130 : model1 loss : 0.435888 model2 loss : 0.020878
[23:52:08.676] iteration 10131 : model1 loss : 0.434435 model2 loss : 0.021414
[23:52:08.852] iteration 10132 : model1 loss : 0.435576 model2 loss : 0.023563
[23:52:09.031] iteration 10133 : model1 loss : 0.440551 model2 loss : 0.024876
[23:52:09.203] iteration 10134 : model1 loss : 0.435161 model2 loss : 0.025945
[23:52:09.381] iteration 10135 : model1 loss : 0.439967 model2 loss : 0.028116
[23:52:09.551] iteration 10136 : model1 loss : 0.436466 model2 loss : 0.021765
[23:52:09.727] iteration 10137 : model1 loss : 0.435384 model2 loss : 0.025827
[23:52:09.900] iteration 10138 : model1 loss : 0.435449 model2 loss : 0.020631
[23:52:10.076] iteration 10139 : model1 loss : 0.439724 model2 loss : 0.025853
[23:52:10.249] iteration 10140 : model1 loss : 0.438813 model2 loss : 0.024266
[23:52:10.428] iteration 10141 : model1 loss : 0.437610 model2 loss : 0.021279
[23:52:10.599] iteration 10142 : model1 loss : 0.432701 model2 loss : 0.021181
[23:52:10.776] iteration 10143 : model1 loss : 0.440689 model2 loss : 0.025196
[23:52:12.923] iteration 10144 : model1 loss : 0.435144 model2 loss : 0.021391
[23:52:13.101] iteration 10145 : model1 loss : 0.434548 model2 loss : 0.019892
[23:52:13.280] iteration 10146 : model1 loss : 0.438949 model2 loss : 0.025253
[23:52:13.450] iteration 10147 : model1 loss : 0.436507 model2 loss : 0.022458
[23:52:13.631] iteration 10148 : model1 loss : 0.438097 model2 loss : 0.021880
[23:52:13.804] iteration 10149 : model1 loss : 0.436225 model2 loss : 0.021170
[23:52:13.980] iteration 10150 : model1 loss : 0.439754 model2 loss : 0.025471
[23:52:14.150] iteration 10151 : model1 loss : 0.438710 model2 loss : 0.023663
[23:52:14.332] iteration 10152 : model1 loss : 0.438060 model2 loss : 0.023435
[23:52:14.503] iteration 10153 : model1 loss : 0.435145 model2 loss : 0.022029
[23:52:14.677] iteration 10154 : model1 loss : 0.436244 model2 loss : 0.020563
[23:52:14.851] iteration 10155 : model1 loss : 0.437257 model2 loss : 0.025234
[23:52:15.030] iteration 10156 : model1 loss : 0.437368 model2 loss : 0.025286
[23:52:15.200] iteration 10157 : model1 loss : 0.434237 model2 loss : 0.022783
[23:52:15.375] iteration 10158 : model1 loss : 0.435571 model2 loss : 0.021016
[23:52:15.545] iteration 10159 : model1 loss : 0.438781 model2 loss : 0.027819
[23:52:15.722] iteration 10160 : model1 loss : 0.438191 model2 loss : 0.026865
[23:52:15.896] iteration 10161 : model1 loss : 0.433734 model2 loss : 0.026348
[23:52:16.073] iteration 10162 : model1 loss : 0.433512 model2 loss : 0.021448
[23:52:16.244] iteration 10163 : model1 loss : 0.438524 model2 loss : 0.022012
[23:52:16.424] iteration 10164 : model1 loss : 0.439758 model2 loss : 0.024002
[23:52:18.564] iteration 10165 : model1 loss : 0.437597 model2 loss : 0.024125
[23:52:18.739] iteration 10166 : model1 loss : 0.437873 model2 loss : 0.028207
[23:52:18.919] iteration 10167 : model1 loss : 0.437085 model2 loss : 0.025443
[23:52:19.089] iteration 10168 : model1 loss : 0.434676 model2 loss : 0.025009
[23:52:19.267] iteration 10169 : model1 loss : 0.438173 model2 loss : 0.022500
[23:52:19.437] iteration 10170 : model1 loss : 0.438900 model2 loss : 0.023791
[23:52:19.616] iteration 10171 : model1 loss : 0.436185 model2 loss : 0.020873
[23:52:19.789] iteration 10172 : model1 loss : 0.437637 model2 loss : 0.027762
[23:52:19.967] iteration 10173 : model1 loss : 0.434343 model2 loss : 0.021116
[23:52:20.139] iteration 10174 : model1 loss : 0.433683 model2 loss : 0.022533
[23:52:20.318] iteration 10175 : model1 loss : 0.436504 model2 loss : 0.021310
[23:52:20.490] iteration 10176 : model1 loss : 0.438945 model2 loss : 0.025394
[23:52:20.668] iteration 10177 : model1 loss : 0.437832 model2 loss : 0.025684
[23:52:20.839] iteration 10178 : model1 loss : 0.435979 model2 loss : 0.023683
[23:52:21.015] iteration 10179 : model1 loss : 0.437961 model2 loss : 0.022246
[23:52:21.185] iteration 10180 : model1 loss : 0.435282 model2 loss : 0.025101
[23:52:21.364] iteration 10181 : model1 loss : 0.434381 model2 loss : 0.022007
[23:52:21.537] iteration 10182 : model1 loss : 0.438246 model2 loss : 0.022145
[23:52:21.713] iteration 10183 : model1 loss : 0.440678 model2 loss : 0.029812
[23:52:21.884] iteration 10184 : model1 loss : 0.435875 model2 loss : 0.022262
[23:52:22.058] iteration 10185 : model1 loss : 0.435144 model2 loss : 0.023194
[23:52:24.193] iteration 10186 : model1 loss : 0.434560 model2 loss : 0.023346
[23:52:24.367] iteration 10187 : model1 loss : 0.435426 model2 loss : 0.020687
[23:52:24.544] iteration 10188 : model1 loss : 0.437509 model2 loss : 0.021878
[23:52:24.714] iteration 10189 : model1 loss : 0.436630 model2 loss : 0.022203
[23:52:24.892] iteration 10190 : model1 loss : 0.436581 model2 loss : 0.022245
[23:52:25.064] iteration 10191 : model1 loss : 0.438391 model2 loss : 0.022060
[23:52:25.242] iteration 10192 : model1 loss : 0.435781 model2 loss : 0.021533
[23:52:25.413] iteration 10193 : model1 loss : 0.436371 model2 loss : 0.024276
[23:52:25.592] iteration 10194 : model1 loss : 0.439335 model2 loss : 0.025473
[23:52:25.765] iteration 10195 : model1 loss : 0.436811 model2 loss : 0.023089
[23:52:25.942] iteration 10196 : model1 loss : 0.430910 model2 loss : 0.021652
[23:52:26.117] iteration 10197 : model1 loss : 0.435158 model2 loss : 0.020624
[23:52:26.297] iteration 10198 : model1 loss : 0.438820 model2 loss : 0.023536
[23:52:26.468] iteration 10199 : model1 loss : 0.440363 model2 loss : 0.023945
[23:52:26.646] iteration 10200 : model1 loss : 0.435832 model2 loss : 0.020801
[23:52:26.820] iteration 10201 : model1 loss : 0.438441 model2 loss : 0.023955
[23:52:26.998] iteration 10202 : model1 loss : 0.438089 model2 loss : 0.023510
[23:52:27.168] iteration 10203 : model1 loss : 0.434777 model2 loss : 0.022553
[23:52:27.349] iteration 10204 : model1 loss : 0.435076 model2 loss : 0.025542
[23:52:27.520] iteration 10205 : model1 loss : 0.433633 model2 loss : 0.022635
[23:52:27.692] iteration 10206 : model1 loss : 0.437082 model2 loss : 0.020678
[23:52:29.832] iteration 10207 : model1 loss : 0.434491 model2 loss : 0.021650
[23:52:30.004] iteration 10208 : model1 loss : 0.437620 model2 loss : 0.024474
[23:52:30.183] iteration 10209 : model1 loss : 0.434632 model2 loss : 0.021756
[23:52:30.357] iteration 10210 : model1 loss : 0.439239 model2 loss : 0.024434
[23:52:30.534] iteration 10211 : model1 loss : 0.435615 model2 loss : 0.022423
[23:52:30.705] iteration 10212 : model1 loss : 0.438400 model2 loss : 0.021949
[23:52:30.878] iteration 10213 : model1 loss : 0.433874 model2 loss : 0.020791
[23:52:31.049] iteration 10214 : model1 loss : 0.438034 model2 loss : 0.022500
[23:52:31.228] iteration 10215 : model1 loss : 0.433788 model2 loss : 0.020834
[23:52:31.400] iteration 10216 : model1 loss : 0.438338 model2 loss : 0.022596
[23:52:31.575] iteration 10217 : model1 loss : 0.432549 model2 loss : 0.023012
[23:52:31.749] iteration 10218 : model1 loss : 0.438805 model2 loss : 0.022535
[23:52:31.926] iteration 10219 : model1 loss : 0.437315 model2 loss : 0.024766
[23:52:32.098] iteration 10220 : model1 loss : 0.434779 model2 loss : 0.022940
[23:52:32.277] iteration 10221 : model1 loss : 0.435027 model2 loss : 0.023501
[23:52:32.450] iteration 10222 : model1 loss : 0.436857 model2 loss : 0.021700
[23:52:32.630] iteration 10223 : model1 loss : 0.437387 model2 loss : 0.023753
[23:52:32.805] iteration 10224 : model1 loss : 0.438466 model2 loss : 0.026028
[23:52:32.980] iteration 10225 : model1 loss : 0.434636 model2 loss : 0.022651
[23:52:33.149] iteration 10226 : model1 loss : 0.437429 model2 loss : 0.022105
[23:52:33.329] iteration 10227 : model1 loss : 0.440751 model2 loss : 0.023556
[23:52:35.481] iteration 10228 : model1 loss : 0.436276 model2 loss : 0.020979
[23:52:35.658] iteration 10229 : model1 loss : 0.439388 model2 loss : 0.022301
[23:52:35.836] iteration 10230 : model1 loss : 0.435422 model2 loss : 0.020653
[23:52:36.009] iteration 10231 : model1 loss : 0.435985 model2 loss : 0.023169
[23:52:36.185] iteration 10232 : model1 loss : 0.441595 model2 loss : 0.023071
[23:52:36.359] iteration 10233 : model1 loss : 0.436416 model2 loss : 0.020901
[23:52:36.536] iteration 10234 : model1 loss : 0.434985 model2 loss : 0.022791
[23:52:36.708] iteration 10235 : model1 loss : 0.432294 model2 loss : 0.024555
[23:52:36.884] iteration 10236 : model1 loss : 0.438604 model2 loss : 0.022915
[23:52:37.056] iteration 10237 : model1 loss : 0.437002 model2 loss : 0.022981
[23:52:37.229] iteration 10238 : model1 loss : 0.437593 model2 loss : 0.025893
[23:52:37.405] iteration 10239 : model1 loss : 0.435369 model2 loss : 0.022403
[23:52:37.588] iteration 10240 : model1 loss : 0.436183 model2 loss : 0.024040
[23:52:37.761] iteration 10241 : model1 loss : 0.432976 model2 loss : 0.021122
[23:52:37.942] iteration 10242 : model1 loss : 0.436639 model2 loss : 0.026793
[23:52:38.117] iteration 10243 : model1 loss : 0.435055 model2 loss : 0.021555
[23:52:38.296] iteration 10244 : model1 loss : 0.440753 model2 loss : 0.025137
[23:52:38.469] iteration 10245 : model1 loss : 0.437012 model2 loss : 0.024684
[23:52:38.645] iteration 10246 : model1 loss : 0.434574 model2 loss : 0.024668
[23:52:38.817] iteration 10247 : model1 loss : 0.437705 model2 loss : 0.022653
[23:52:38.990] iteration 10248 : model1 loss : 0.438098 model2 loss : 0.023199
[23:52:41.136] iteration 10249 : model1 loss : 0.433315 model2 loss : 0.022421
[23:52:41.314] iteration 10250 : model1 loss : 0.436016 model2 loss : 0.024851
[23:52:41.492] iteration 10251 : model1 loss : 0.438398 model2 loss : 0.021397
[23:52:41.663] iteration 10252 : model1 loss : 0.432125 model2 loss : 0.020347
[23:52:41.839] iteration 10253 : model1 loss : 0.439004 model2 loss : 0.022089
[23:52:42.012] iteration 10254 : model1 loss : 0.437740 model2 loss : 0.022003
[23:52:42.186] iteration 10255 : model1 loss : 0.434753 model2 loss : 0.019040
[23:52:42.360] iteration 10256 : model1 loss : 0.437086 model2 loss : 0.023521
[23:52:42.536] iteration 10257 : model1 loss : 0.437620 model2 loss : 0.025124
[23:52:42.707] iteration 10258 : model1 loss : 0.435450 model2 loss : 0.022764
[23:52:42.882] iteration 10259 : model1 loss : 0.435977 model2 loss : 0.021578
[23:52:43.052] iteration 10260 : model1 loss : 0.432636 model2 loss : 0.020044
[23:52:43.228] iteration 10261 : model1 loss : 0.438928 model2 loss : 0.024984
[23:52:43.403] iteration 10262 : model1 loss : 0.437101 model2 loss : 0.023218
[23:52:43.580] iteration 10263 : model1 loss : 0.441252 model2 loss : 0.024187
[23:52:43.751] iteration 10264 : model1 loss : 0.443822 model2 loss : 0.024749
[23:52:43.928] iteration 10265 : model1 loss : 0.437678 model2 loss : 0.021940
[23:52:44.104] iteration 10266 : model1 loss : 0.434641 model2 loss : 0.021040
[23:52:44.280] iteration 10267 : model1 loss : 0.435325 model2 loss : 0.023139
[23:52:44.451] iteration 10268 : model1 loss : 0.437320 model2 loss : 0.022566
[23:52:44.629] iteration 10269 : model1 loss : 0.438407 model2 loss : 0.023985
[23:52:46.748] iteration 10270 : model1 loss : 0.432468 model2 loss : 0.020515
[23:52:46.922] iteration 10271 : model1 loss : 0.438052 model2 loss : 0.020654
[23:52:47.100] iteration 10272 : model1 loss : 0.431693 model2 loss : 0.020648
[23:52:47.273] iteration 10273 : model1 loss : 0.436483 model2 loss : 0.023993
[23:52:47.454] iteration 10274 : model1 loss : 0.439367 model2 loss : 0.021321
[23:52:47.628] iteration 10275 : model1 loss : 0.434360 model2 loss : 0.023233
[23:52:47.806] iteration 10276 : model1 loss : 0.438391 model2 loss : 0.022827
[23:52:47.975] iteration 10277 : model1 loss : 0.435861 model2 loss : 0.021517
[23:52:48.153] iteration 10278 : model1 loss : 0.430776 model2 loss : 0.021760
[23:52:48.333] iteration 10279 : model1 loss : 0.439404 model2 loss : 0.023115
[23:52:48.511] iteration 10280 : model1 loss : 0.436799 model2 loss : 0.020247
[23:52:48.681] iteration 10281 : model1 loss : 0.438241 model2 loss : 0.026085
[23:52:48.857] iteration 10282 : model1 loss : 0.441191 model2 loss : 0.025862
[23:52:49.028] iteration 10283 : model1 loss : 0.433827 model2 loss : 0.019260
[23:52:49.202] iteration 10284 : model1 loss : 0.438016 model2 loss : 0.022536
[23:52:49.377] iteration 10285 : model1 loss : 0.437221 model2 loss : 0.021821
[23:52:49.555] iteration 10286 : model1 loss : 0.435773 model2 loss : 0.023426
[23:52:49.727] iteration 10287 : model1 loss : 0.444130 model2 loss : 0.027228
[23:52:49.903] iteration 10288 : model1 loss : 0.439741 model2 loss : 0.023780
[23:52:50.073] iteration 10289 : model1 loss : 0.434643 model2 loss : 0.020670
[23:52:50.247] iteration 10290 : model1 loss : 0.435213 model2 loss : 0.023105
[23:52:52.380] iteration 10291 : model1 loss : 0.433615 model2 loss : 0.021307
[23:52:52.558] iteration 10292 : model1 loss : 0.436036 model2 loss : 0.023305
[23:52:52.736] iteration 10293 : model1 loss : 0.439254 model2 loss : 0.025844
[23:52:52.911] iteration 10294 : model1 loss : 0.435487 model2 loss : 0.021356
[23:52:53.087] iteration 10295 : model1 loss : 0.433068 model2 loss : 0.021419
[23:52:53.258] iteration 10296 : model1 loss : 0.436595 model2 loss : 0.019414
[23:52:53.440] iteration 10297 : model1 loss : 0.440832 model2 loss : 0.028267
[23:52:53.613] iteration 10298 : model1 loss : 0.436068 model2 loss : 0.021427
[23:52:53.793] iteration 10299 : model1 loss : 0.435373 model2 loss : 0.022012
[23:52:53.966] iteration 10300 : model1 loss : 0.434318 model2 loss : 0.024291
[23:52:54.142] iteration 10301 : model1 loss : 0.433772 model2 loss : 0.021037
[23:52:54.318] iteration 10302 : model1 loss : 0.436545 model2 loss : 0.022973
[23:52:54.497] iteration 10303 : model1 loss : 0.439171 model2 loss : 0.021841
[23:52:54.669] iteration 10304 : model1 loss : 0.436187 model2 loss : 0.020125
[23:52:54.843] iteration 10305 : model1 loss : 0.434337 model2 loss : 0.021298
[23:52:55.014] iteration 10306 : model1 loss : 0.441687 model2 loss : 0.023858
[23:52:55.190] iteration 10307 : model1 loss : 0.438746 model2 loss : 0.026844
[23:52:55.366] iteration 10308 : model1 loss : 0.437777 model2 loss : 0.024268
[23:52:55.542] iteration 10309 : model1 loss : 0.433777 model2 loss : 0.020350
[23:52:55.712] iteration 10310 : model1 loss : 0.438346 model2 loss : 0.023667
[23:52:55.892] iteration 10311 : model1 loss : 0.439295 model2 loss : 0.023575
[23:52:58.020] iteration 10312 : model1 loss : 0.441179 model2 loss : 0.023720
[23:52:58.196] iteration 10313 : model1 loss : 0.435331 model2 loss : 0.020988
[23:52:58.375] iteration 10314 : model1 loss : 0.433419 model2 loss : 0.019942
[23:52:58.545] iteration 10315 : model1 loss : 0.433730 model2 loss : 0.020821
[23:52:58.723] iteration 10316 : model1 loss : 0.433627 model2 loss : 0.021957
[23:52:58.902] iteration 10317 : model1 loss : 0.441323 model2 loss : 0.025159
[23:52:59.080] iteration 10318 : model1 loss : 0.437594 model2 loss : 0.021391
[23:52:59.253] iteration 10319 : model1 loss : 0.435616 model2 loss : 0.021656
[23:52:59.435] iteration 10320 : model1 loss : 0.437185 model2 loss : 0.022065
[23:52:59.611] iteration 10321 : model1 loss : 0.440462 model2 loss : 0.022354
[23:52:59.790] iteration 10322 : model1 loss : 0.436702 model2 loss : 0.023306
[23:52:59.963] iteration 10323 : model1 loss : 0.438256 model2 loss : 0.020327
[23:53:00.147] iteration 10324 : model1 loss : 0.437177 model2 loss : 0.022439
[23:53:00.326] iteration 10325 : model1 loss : 0.432748 model2 loss : 0.021829
[23:53:00.503] iteration 10326 : model1 loss : 0.437650 model2 loss : 0.025054
[23:53:00.673] iteration 10327 : model1 loss : 0.434789 model2 loss : 0.021693
[23:53:00.852] iteration 10328 : model1 loss : 0.435224 model2 loss : 0.020465
[23:53:01.025] iteration 10329 : model1 loss : 0.438489 model2 loss : 0.022052
[23:53:01.200] iteration 10330 : model1 loss : 0.434878 model2 loss : 0.023352
[23:53:01.374] iteration 10331 : model1 loss : 0.439075 model2 loss : 0.023927
[23:53:01.548] iteration 10332 : model1 loss : 0.435354 model2 loss : 0.021110
[23:53:03.685] iteration 10333 : model1 loss : 0.437782 model2 loss : 0.023197
[23:53:03.859] iteration 10334 : model1 loss : 0.439180 model2 loss : 0.023511
[23:53:04.041] iteration 10335 : model1 loss : 0.433876 model2 loss : 0.023749
[23:53:04.210] iteration 10336 : model1 loss : 0.436841 model2 loss : 0.025458
[23:53:04.391] iteration 10337 : model1 loss : 0.434884 model2 loss : 0.023169
[23:53:04.565] iteration 10338 : model1 loss : 0.435978 model2 loss : 0.021557
[23:53:04.739] iteration 10339 : model1 loss : 0.439380 model2 loss : 0.025144
[23:53:04.909] iteration 10340 : model1 loss : 0.434906 model2 loss : 0.023479
[23:53:05.088] iteration 10341 : model1 loss : 0.433027 model2 loss : 0.020118
[23:53:05.257] iteration 10342 : model1 loss : 0.437008 model2 loss : 0.021449
[23:53:05.436] iteration 10343 : model1 loss : 0.439381 model2 loss : 0.025946
[23:53:05.613] iteration 10344 : model1 loss : 0.436342 model2 loss : 0.022311
[23:53:05.790] iteration 10345 : model1 loss : 0.434888 model2 loss : 0.020763
[23:53:05.964] iteration 10346 : model1 loss : 0.442831 model2 loss : 0.024369
[23:53:06.143] iteration 10347 : model1 loss : 0.435763 model2 loss : 0.023491
[23:53:06.319] iteration 10348 : model1 loss : 0.436448 model2 loss : 0.022543
[23:53:06.499] iteration 10349 : model1 loss : 0.434253 model2 loss : 0.024525
[23:53:06.671] iteration 10350 : model1 loss : 0.435447 model2 loss : 0.021363
[23:53:06.847] iteration 10351 : model1 loss : 0.437877 model2 loss : 0.023483
[23:53:07.016] iteration 10352 : model1 loss : 0.434783 model2 loss : 0.021186
[23:53:07.193] iteration 10353 : model1 loss : 0.442338 model2 loss : 0.022423
[23:53:09.361] iteration 10354 : model1 loss : 0.438896 model2 loss : 0.024450
[23:53:09.535] iteration 10355 : model1 loss : 0.438130 model2 loss : 0.020056
[23:53:09.713] iteration 10356 : model1 loss : 0.434065 model2 loss : 0.024566
[23:53:09.887] iteration 10357 : model1 loss : 0.437184 model2 loss : 0.022595
[23:53:10.063] iteration 10358 : model1 loss : 0.439606 model2 loss : 0.023262
[23:53:10.234] iteration 10359 : model1 loss : 0.433560 model2 loss : 0.024098
[23:53:10.411] iteration 10360 : model1 loss : 0.438933 model2 loss : 0.022480
[23:53:10.582] iteration 10361 : model1 loss : 0.435948 model2 loss : 0.018341
[23:53:10.758] iteration 10362 : model1 loss : 0.432894 model2 loss : 0.020765
[23:53:10.930] iteration 10363 : model1 loss : 0.431849 model2 loss : 0.020759
[23:53:11.107] iteration 10364 : model1 loss : 0.436273 model2 loss : 0.023351
[23:53:11.277] iteration 10365 : model1 loss : 0.437343 model2 loss : 0.025626
[23:53:11.455] iteration 10366 : model1 loss : 0.434708 model2 loss : 0.020414
[23:53:11.629] iteration 10367 : model1 loss : 0.436917 model2 loss : 0.020562
[23:53:11.806] iteration 10368 : model1 loss : 0.441390 model2 loss : 0.023585
[23:53:11.980] iteration 10369 : model1 loss : 0.441284 model2 loss : 0.031575
[23:53:12.157] iteration 10370 : model1 loss : 0.434318 model2 loss : 0.020087
[23:53:12.335] iteration 10371 : model1 loss : 0.437023 model2 loss : 0.024023
[23:53:12.517] iteration 10372 : model1 loss : 0.439043 model2 loss : 0.025033
[23:53:12.686] iteration 10373 : model1 loss : 0.432791 model2 loss : 0.022180
[23:53:12.863] iteration 10374 : model1 loss : 0.437494 model2 loss : 0.027822
[23:53:14.968] iteration 10375 : model1 loss : 0.436725 model2 loss : 0.024056
[23:53:15.141] iteration 10376 : model1 loss : 0.434560 model2 loss : 0.025271
[23:53:15.323] iteration 10377 : model1 loss : 0.432848 model2 loss : 0.022687
[23:53:15.498] iteration 10378 : model1 loss : 0.438920 model2 loss : 0.024529
[23:53:15.673] iteration 10379 : model1 loss : 0.435377 model2 loss : 0.020953
[23:53:15.846] iteration 10380 : model1 loss : 0.438009 model2 loss : 0.025158
[23:53:16.026] iteration 10381 : model1 loss : 0.433245 model2 loss : 0.024268
[23:53:16.198] iteration 10382 : model1 loss : 0.438770 model2 loss : 0.024013
[23:53:16.377] iteration 10383 : model1 loss : 0.438822 model2 loss : 0.023021
[23:53:16.552] iteration 10384 : model1 loss : 0.440771 model2 loss : 0.030887
[23:53:16.738] iteration 10385 : model1 loss : 0.439667 model2 loss : 0.026157
[23:53:16.911] iteration 10386 : model1 loss : 0.437693 model2 loss : 0.023833
[23:53:17.089] iteration 10387 : model1 loss : 0.437727 model2 loss : 0.025481
[23:53:17.260] iteration 10388 : model1 loss : 0.437091 model2 loss : 0.024588
[23:53:17.442] iteration 10389 : model1 loss : 0.436734 model2 loss : 0.027616
[23:53:17.617] iteration 10390 : model1 loss : 0.434744 model2 loss : 0.024474
[23:53:17.793] iteration 10391 : model1 loss : 0.433897 model2 loss : 0.022582
[23:53:17.967] iteration 10392 : model1 loss : 0.439692 model2 loss : 0.025771
[23:53:18.143] iteration 10393 : model1 loss : 0.434207 model2 loss : 0.023522
[23:53:18.319] iteration 10394 : model1 loss : 0.434804 model2 loss : 0.027018
[23:53:18.497] iteration 10395 : model1 loss : 0.437189 model2 loss : 0.023510
[23:53:20.626] iteration 10396 : model1 loss : 0.437698 model2 loss : 0.025165
[23:53:20.798] iteration 10397 : model1 loss : 0.434860 model2 loss : 0.030406
[23:53:20.977] iteration 10398 : model1 loss : 0.436589 model2 loss : 0.027395
[23:53:21.148] iteration 10399 : model1 loss : 0.433113 model2 loss : 0.023404
[23:53:21.332] iteration 10400 : model1 loss : 0.436484 model2 loss : 0.025586
[23:53:21.506] iteration 10401 : model1 loss : 0.438409 model2 loss : 0.023742
[23:53:21.681] iteration 10402 : model1 loss : 0.429573 model2 loss : 0.024134
[23:53:21.854] iteration 10403 : model1 loss : 0.434278 model2 loss : 0.023250
[23:53:22.032] iteration 10404 : model1 loss : 0.439947 model2 loss : 0.028563
[23:53:22.204] iteration 10405 : model1 loss : 0.436394 model2 loss : 0.024592
[23:53:22.381] iteration 10406 : model1 loss : 0.440816 model2 loss : 0.053567
[23:53:22.563] iteration 10407 : model1 loss : 0.437860 model2 loss : 0.023824
[23:53:22.740] iteration 10408 : model1 loss : 0.435346 model2 loss : 0.027697
[23:53:22.913] iteration 10409 : model1 loss : 0.437030 model2 loss : 0.025008
[23:53:23.091] iteration 10410 : model1 loss : 0.436912 model2 loss : 0.038894
[23:53:23.262] iteration 10411 : model1 loss : 0.437136 model2 loss : 0.028693
[23:53:23.437] iteration 10412 : model1 loss : 0.439291 model2 loss : 0.030116
[23:53:23.612] iteration 10413 : model1 loss : 0.438171 model2 loss : 0.028713
[23:53:23.789] iteration 10414 : model1 loss : 0.437178 model2 loss : 0.029070
[23:53:23.962] iteration 10415 : model1 loss : 0.434814 model2 loss : 0.025177
[23:53:24.138] iteration 10416 : model1 loss : 0.441333 model2 loss : 0.029801
[23:53:26.290] iteration 10417 : model1 loss : 0.435030 model2 loss : 0.031403
[23:53:26.470] iteration 10418 : model1 loss : 0.436303 model2 loss : 0.030553
[23:53:26.648] iteration 10419 : model1 loss : 0.439417 model2 loss : 0.028031
[23:53:26.817] iteration 10420 : model1 loss : 0.433405 model2 loss : 0.027994
[23:53:26.996] iteration 10421 : model1 loss : 0.431512 model2 loss : 0.025402
[23:53:27.165] iteration 10422 : model1 loss : 0.435798 model2 loss : 0.027839
[23:53:27.345] iteration 10423 : model1 loss : 0.439901 model2 loss : 0.055801
[23:53:27.519] iteration 10424 : model1 loss : 0.438981 model2 loss : 0.029569
[23:53:27.697] iteration 10425 : model1 loss : 0.435242 model2 loss : 0.028305
[23:53:27.869] iteration 10426 : model1 loss : 0.436478 model2 loss : 0.028801
[23:53:28.046] iteration 10427 : model1 loss : 0.436276 model2 loss : 0.027631
[23:53:28.214] iteration 10428 : model1 loss : 0.438458 model2 loss : 0.036591
[23:53:28.391] iteration 10429 : model1 loss : 0.437490 model2 loss : 0.041868
[23:53:28.563] iteration 10430 : model1 loss : 0.436947 model2 loss : 0.023197
[23:53:28.737] iteration 10431 : model1 loss : 0.437683 model2 loss : 0.039495
[23:53:28.910] iteration 10432 : model1 loss : 0.440954 model2 loss : 0.033118
[23:53:29.087] iteration 10433 : model1 loss : 0.434591 model2 loss : 0.032578
[23:53:29.258] iteration 10434 : model1 loss : 0.432615 model2 loss : 0.023256
[23:53:29.436] iteration 10435 : model1 loss : 0.434483 model2 loss : 0.028200
[23:53:29.609] iteration 10436 : model1 loss : 0.439712 model2 loss : 0.031577
[23:53:29.784] iteration 10437 : model1 loss : 0.435459 model2 loss : 0.030656
[23:53:31.914] iteration 10438 : model1 loss : 0.441190 model2 loss : 0.029263
[23:53:32.089] iteration 10439 : model1 loss : 0.437739 model2 loss : 0.025783
[23:53:32.267] iteration 10440 : model1 loss : 0.430757 model2 loss : 0.024007
[23:53:32.444] iteration 10441 : model1 loss : 0.438416 model2 loss : 0.036167
[23:53:32.626] iteration 10442 : model1 loss : 0.436934 model2 loss : 0.036998
[23:53:32.796] iteration 10443 : model1 loss : 0.434551 model2 loss : 0.027979
[23:53:32.973] iteration 10444 : model1 loss : 0.436527 model2 loss : 0.033533
[23:53:33.144] iteration 10445 : model1 loss : 0.439583 model2 loss : 0.028879
[23:53:33.321] iteration 10446 : model1 loss : 0.443118 model2 loss : 0.040039
[23:53:33.494] iteration 10447 : model1 loss : 0.440870 model2 loss : 0.031258
[23:53:33.669] iteration 10448 : model1 loss : 0.434054 model2 loss : 0.030782
[23:53:33.840] iteration 10449 : model1 loss : 0.439113 model2 loss : 0.032421
[23:53:34.016] iteration 10450 : model1 loss : 0.434499 model2 loss : 0.034433
[23:53:34.188] iteration 10451 : model1 loss : 0.433939 model2 loss : 0.027189
[23:53:34.363] iteration 10452 : model1 loss : 0.436924 model2 loss : 0.027510
[23:53:34.536] iteration 10453 : model1 loss : 0.430894 model2 loss : 0.023682
[23:53:34.711] iteration 10454 : model1 loss : 0.438712 model2 loss : 0.034038
[23:53:34.884] iteration 10455 : model1 loss : 0.433407 model2 loss : 0.025384
[23:53:35.060] iteration 10456 : model1 loss : 0.434462 model2 loss : 0.025665
[23:53:35.228] iteration 10457 : model1 loss : 0.437070 model2 loss : 0.034974
[23:53:35.403] iteration 10458 : model1 loss : 0.439917 model2 loss : 0.031504
[23:53:37.546] iteration 10459 : model1 loss : 0.436144 model2 loss : 0.023563
[23:53:37.720] iteration 10460 : model1 loss : 0.437658 model2 loss : 0.025419
[23:53:37.901] iteration 10461 : model1 loss : 0.439438 model2 loss : 0.028523
[23:53:38.073] iteration 10462 : model1 loss : 0.441237 model2 loss : 0.028388
[23:53:38.248] iteration 10463 : model1 loss : 0.437673 model2 loss : 0.029064
[23:53:38.425] iteration 10464 : model1 loss : 0.436902 model2 loss : 0.028216
[23:53:38.604] iteration 10465 : model1 loss : 0.436455 model2 loss : 0.029317
[23:53:38.774] iteration 10466 : model1 loss : 0.435544 model2 loss : 0.026859
[23:53:38.953] iteration 10467 : model1 loss : 0.433546 model2 loss : 0.026799
[23:53:39.124] iteration 10468 : model1 loss : 0.436339 model2 loss : 0.031555
[23:53:39.298] iteration 10469 : model1 loss : 0.440045 model2 loss : 0.032697
[23:53:39.473] iteration 10470 : model1 loss : 0.436993 model2 loss : 0.030024
[23:53:39.650] iteration 10471 : model1 loss : 0.442348 model2 loss : 0.035700
[23:53:39.822] iteration 10472 : model1 loss : 0.437351 model2 loss : 0.024049
[23:53:40.001] iteration 10473 : model1 loss : 0.430474 model2 loss : 0.030277
[23:53:40.172] iteration 10474 : model1 loss : 0.434512 model2 loss : 0.025287
[23:53:40.350] iteration 10475 : model1 loss : 0.433025 model2 loss : 0.023016
[23:53:40.524] iteration 10476 : model1 loss : 0.431378 model2 loss : 0.026578
[23:53:40.700] iteration 10477 : model1 loss : 0.439413 model2 loss : 0.024238
[23:53:40.872] iteration 10478 : model1 loss : 0.435046 model2 loss : 0.027617
[23:53:41.045] iteration 10479 : model1 loss : 0.439789 model2 loss : 0.027945
[23:53:43.226] iteration 10480 : model1 loss : 0.434889 model2 loss : 0.026003
[23:53:43.407] iteration 10481 : model1 loss : 0.434940 model2 loss : 0.025435
[23:53:43.583] iteration 10482 : model1 loss : 0.438064 model2 loss : 0.028990
[23:53:43.755] iteration 10483 : model1 loss : 0.437671 model2 loss : 0.035203
[23:53:43.929] iteration 10484 : model1 loss : 0.436775 model2 loss : 0.023199
[23:53:44.103] iteration 10485 : model1 loss : 0.439397 model2 loss : 0.033179
[23:53:44.277] iteration 10486 : model1 loss : 0.439999 model2 loss : 0.024447
[23:53:44.453] iteration 10487 : model1 loss : 0.433202 model2 loss : 0.024289
[23:53:44.633] iteration 10488 : model1 loss : 0.438188 model2 loss : 0.031267
[23:53:44.805] iteration 10489 : model1 loss : 0.434983 model2 loss : 0.023338
[23:53:44.981] iteration 10490 : model1 loss : 0.438003 model2 loss : 0.032184
[23:53:45.151] iteration 10491 : model1 loss : 0.435241 model2 loss : 0.022502
[23:53:45.330] iteration 10492 : model1 loss : 0.436413 model2 loss : 0.027781
[23:53:45.503] iteration 10493 : model1 loss : 0.434627 model2 loss : 0.022668
[23:53:45.678] iteration 10494 : model1 loss : 0.435883 model2 loss : 0.024948
[23:53:45.850] iteration 10495 : model1 loss : 0.438075 model2 loss : 0.023386
[23:53:46.028] iteration 10496 : model1 loss : 0.433454 model2 loss : 0.021832
[23:53:46.201] iteration 10497 : model1 loss : 0.441776 model2 loss : 0.027660
[23:53:46.379] iteration 10498 : model1 loss : 0.434456 model2 loss : 0.028676
[23:53:46.550] iteration 10499 : model1 loss : 0.439412 model2 loss : 0.030373
[23:53:46.720] iteration 10500 : model1 loss : 0.437063 model2 loss : 0.027946
[23:53:48.841] iteration 10501 : model1 loss : 0.434136 model2 loss : 0.022097
[23:53:49.020] iteration 10502 : model1 loss : 0.432426 model2 loss : 0.024585
[23:53:49.196] iteration 10503 : model1 loss : 0.437957 model2 loss : 0.027421
[23:53:49.375] iteration 10504 : model1 loss : 0.433806 model2 loss : 0.021492
[23:53:49.552] iteration 10505 : model1 loss : 0.438770 model2 loss : 0.025919
[23:53:49.723] iteration 10506 : model1 loss : 0.435879 model2 loss : 0.023424
[23:53:49.902] iteration 10507 : model1 loss : 0.439531 model2 loss : 0.025640
[23:53:50.072] iteration 10508 : model1 loss : 0.436478 model2 loss : 0.026420
[23:53:50.248] iteration 10509 : model1 loss : 0.437698 model2 loss : 0.027303
[23:53:50.423] iteration 10510 : model1 loss : 0.437854 model2 loss : 0.026268
[23:53:50.604] iteration 10511 : model1 loss : 0.435661 model2 loss : 0.028150
[23:53:50.774] iteration 10512 : model1 loss : 0.434985 model2 loss : 0.025759
[23:53:50.951] iteration 10513 : model1 loss : 0.439751 model2 loss : 0.027125
[23:53:51.125] iteration 10514 : model1 loss : 0.439002 model2 loss : 0.023784
[23:53:51.302] iteration 10515 : model1 loss : 0.434340 model2 loss : 0.022640
[23:53:51.475] iteration 10516 : model1 loss : 0.437174 model2 loss : 0.024082
[23:53:51.651] iteration 10517 : model1 loss : 0.438924 model2 loss : 0.024253
[23:53:51.822] iteration 10518 : model1 loss : 0.438982 model2 loss : 0.025041
[23:53:51.996] iteration 10519 : model1 loss : 0.437122 model2 loss : 0.024428
[23:53:52.167] iteration 10520 : model1 loss : 0.439316 model2 loss : 0.026724
[23:53:52.346] iteration 10521 : model1 loss : 0.434492 model2 loss : 0.024443
[23:53:54.519] iteration 10522 : model1 loss : 0.436412 model2 loss : 0.023899
[23:53:54.691] iteration 10523 : model1 loss : 0.439705 model2 loss : 0.025636
[23:53:54.871] iteration 10524 : model1 loss : 0.437845 model2 loss : 0.022553
[23:53:55.044] iteration 10525 : model1 loss : 0.439691 model2 loss : 0.024122
[23:53:55.220] iteration 10526 : model1 loss : 0.431893 model2 loss : 0.021157
[23:53:55.394] iteration 10527 : model1 loss : 0.434255 model2 loss : 0.026193
[23:53:55.574] iteration 10528 : model1 loss : 0.438153 model2 loss : 0.022714
[23:53:55.746] iteration 10529 : model1 loss : 0.437585 model2 loss : 0.024215
[23:53:55.922] iteration 10530 : model1 loss : 0.438171 model2 loss : 0.024219
[23:53:56.095] iteration 10531 : model1 loss : 0.438753 model2 loss : 0.023949
[23:53:56.270] iteration 10532 : model1 loss : 0.437954 model2 loss : 0.021689
[23:53:56.446] iteration 10533 : model1 loss : 0.436338 model2 loss : 0.021831
[23:53:56.628] iteration 10534 : model1 loss : 0.433523 model2 loss : 0.021295
[23:53:56.799] iteration 10535 : model1 loss : 0.435531 model2 loss : 0.022047
[23:53:56.976] iteration 10536 : model1 loss : 0.436723 model2 loss : 0.021752
[23:53:57.148] iteration 10537 : model1 loss : 0.438776 model2 loss : 0.023318
[23:53:57.325] iteration 10538 : model1 loss : 0.433859 model2 loss : 0.021963
[23:53:57.503] iteration 10539 : model1 loss : 0.439949 model2 loss : 0.026822
[23:53:57.680] iteration 10540 : model1 loss : 0.437511 model2 loss : 0.026529
[23:53:57.848] iteration 10541 : model1 loss : 0.438301 model2 loss : 0.021539
[23:53:58.025] iteration 10542 : model1 loss : 0.433590 model2 loss : 0.021682
[23:54:00.152] iteration 10543 : model1 loss : 0.434492 model2 loss : 0.021076
[23:54:00.328] iteration 10544 : model1 loss : 0.438201 model2 loss : 0.024887
[23:54:00.508] iteration 10545 : model1 loss : 0.439682 model2 loss : 0.028045
[23:54:00.680] iteration 10546 : model1 loss : 0.441291 model2 loss : 0.024037
[23:54:00.856] iteration 10547 : model1 loss : 0.434531 model2 loss : 0.021284
[23:54:01.031] iteration 10548 : model1 loss : 0.438367 model2 loss : 0.026567
[23:54:01.206] iteration 10549 : model1 loss : 0.435631 model2 loss : 0.021684
[23:54:01.378] iteration 10550 : model1 loss : 0.438680 model2 loss : 0.021820
[23:54:01.557] iteration 10551 : model1 loss : 0.434640 model2 loss : 0.021794
[23:54:01.728] iteration 10552 : model1 loss : 0.436946 model2 loss : 0.026225
[23:54:01.915] iteration 10553 : model1 loss : 0.433024 model2 loss : 0.022878
[23:54:02.086] iteration 10554 : model1 loss : 0.437842 model2 loss : 0.021604
[23:54:02.262] iteration 10555 : model1 loss : 0.440067 model2 loss : 0.023820
[23:54:02.440] iteration 10556 : model1 loss : 0.435830 model2 loss : 0.023287
[23:54:02.621] iteration 10557 : model1 loss : 0.435670 model2 loss : 0.022907
[23:54:02.793] iteration 10558 : model1 loss : 0.436770 model2 loss : 0.024944
[23:54:02.970] iteration 10559 : model1 loss : 0.435838 model2 loss : 0.024112
[23:54:03.141] iteration 10560 : model1 loss : 0.436271 model2 loss : 0.021014
[23:54:03.320] iteration 10561 : model1 loss : 0.435235 model2 loss : 0.024461
[23:54:03.495] iteration 10562 : model1 loss : 0.433855 model2 loss : 0.021499
[23:54:03.670] iteration 10563 : model1 loss : 0.438918 model2 loss : 0.024924
[23:54:05.806] iteration 10564 : model1 loss : 0.436005 model2 loss : 0.021340
[23:54:05.984] iteration 10565 : model1 loss : 0.436768 model2 loss : 0.022087
[23:54:06.162] iteration 10566 : model1 loss : 0.437117 model2 loss : 0.021760
[23:54:06.335] iteration 10567 : model1 loss : 0.439714 model2 loss : 0.029198
[23:54:06.510] iteration 10568 : model1 loss : 0.438780 model2 loss : 0.021214
[23:54:06.692] iteration 10569 : model1 loss : 0.435614 model2 loss : 0.024056
[23:54:06.868] iteration 10570 : model1 loss : 0.436301 model2 loss : 0.027041
[23:54:07.042] iteration 10571 : model1 loss : 0.437885 model2 loss : 0.026099
[23:54:07.220] iteration 10572 : model1 loss : 0.433579 model2 loss : 0.020390
[23:54:07.391] iteration 10573 : model1 loss : 0.436579 model2 loss : 0.024975
[23:54:07.570] iteration 10574 : model1 loss : 0.437366 model2 loss : 0.023588
[23:54:07.741] iteration 10575 : model1 loss : 0.438390 model2 loss : 0.026723
[23:54:07.917] iteration 10576 : model1 loss : 0.435149 model2 loss : 0.023621
[23:54:08.092] iteration 10577 : model1 loss : 0.436065 model2 loss : 0.022419
[23:54:08.266] iteration 10578 : model1 loss : 0.440102 model2 loss : 0.021382
[23:54:08.441] iteration 10579 : model1 loss : 0.434001 model2 loss : 0.023479
[23:54:08.626] iteration 10580 : model1 loss : 0.434130 model2 loss : 0.020321
[23:54:08.796] iteration 10581 : model1 loss : 0.436507 model2 loss : 0.022593
[23:54:08.973] iteration 10582 : model1 loss : 0.435128 model2 loss : 0.023747
[23:54:09.143] iteration 10583 : model1 loss : 0.434278 model2 loss : 0.026815
[23:54:09.321] iteration 10584 : model1 loss : 0.442433 model2 loss : 0.024403
[23:54:11.451] iteration 10585 : model1 loss : 0.440985 model2 loss : 0.026010
[23:54:11.624] iteration 10586 : model1 loss : 0.433672 model2 loss : 0.022329
[23:54:11.802] iteration 10587 : model1 loss : 0.437754 model2 loss : 0.026290
[23:54:11.976] iteration 10588 : model1 loss : 0.438971 model2 loss : 0.024215
[23:54:12.153] iteration 10589 : model1 loss : 0.442099 model2 loss : 0.026631
[23:54:12.327] iteration 10590 : model1 loss : 0.436553 model2 loss : 0.021991
[23:54:12.513] iteration 10591 : model1 loss : 0.436596 model2 loss : 0.022587
[23:54:12.684] iteration 10592 : model1 loss : 0.440168 model2 loss : 0.023248
[23:54:12.859] iteration 10593 : model1 loss : 0.432647 model2 loss : 0.022732
[23:54:13.033] iteration 10594 : model1 loss : 0.435987 model2 loss : 0.023334
[23:54:13.210] iteration 10595 : model1 loss : 0.437065 model2 loss : 0.024324
[23:54:13.383] iteration 10596 : model1 loss : 0.437765 model2 loss : 0.024512
[23:54:13.562] iteration 10597 : model1 loss : 0.439721 model2 loss : 0.027280
[23:54:13.733] iteration 10598 : model1 loss : 0.434263 model2 loss : 0.022542
[23:54:13.909] iteration 10599 : model1 loss : 0.435173 model2 loss : 0.020951
[23:54:14.083] iteration 10600 : model1 loss : 0.433509 model2 loss : 0.023869
[23:54:14.261] iteration 10601 : model1 loss : 0.437622 model2 loss : 0.022427
[23:54:14.436] iteration 10602 : model1 loss : 0.434205 model2 loss : 0.023582
[23:54:14.616] iteration 10603 : model1 loss : 0.437794 model2 loss : 0.024411
[23:54:14.788] iteration 10604 : model1 loss : 0.433611 model2 loss : 0.022142
[23:54:14.964] iteration 10605 : model1 loss : 0.432643 model2 loss : 0.026623
[23:54:17.098] iteration 10606 : model1 loss : 0.437933 model2 loss : 0.024245
[23:54:17.269] iteration 10607 : model1 loss : 0.437090 model2 loss : 0.023562
[23:54:17.449] iteration 10608 : model1 loss : 0.435708 model2 loss : 0.023161
[23:54:17.625] iteration 10609 : model1 loss : 0.434109 model2 loss : 0.021491
[23:54:17.803] iteration 10610 : model1 loss : 0.438670 model2 loss : 0.023399
[23:54:17.976] iteration 10611 : model1 loss : 0.438984 model2 loss : 0.023537
[23:54:18.154] iteration 10612 : model1 loss : 0.432967 model2 loss : 0.022406
[23:54:18.327] iteration 10613 : model1 loss : 0.433699 model2 loss : 0.025231
[23:54:18.505] iteration 10614 : model1 loss : 0.435477 model2 loss : 0.022993
[23:54:18.676] iteration 10615 : model1 loss : 0.440952 model2 loss : 0.026815
[23:54:18.852] iteration 10616 : model1 loss : 0.441776 model2 loss : 0.022548
[23:54:19.026] iteration 10617 : model1 loss : 0.436519 model2 loss : 0.025556
[23:54:19.203] iteration 10618 : model1 loss : 0.436300 model2 loss : 0.022284
[23:54:19.374] iteration 10619 : model1 loss : 0.431429 model2 loss : 0.023182
[23:54:19.552] iteration 10620 : model1 loss : 0.433773 model2 loss : 0.020646
[23:54:19.724] iteration 10621 : model1 loss : 0.432351 model2 loss : 0.019983
[23:54:19.900] iteration 10622 : model1 loss : 0.438298 model2 loss : 0.026918
[23:54:20.076] iteration 10623 : model1 loss : 0.440024 model2 loss : 0.028278
[23:54:20.253] iteration 10624 : model1 loss : 0.439731 model2 loss : 0.021528
[23:54:20.423] iteration 10625 : model1 loss : 0.441918 model2 loss : 0.031925
[23:54:20.603] iteration 10626 : model1 loss : 0.434597 model2 loss : 0.023163
[23:54:22.785] iteration 10627 : model1 loss : 0.437509 model2 loss : 0.023143
[23:54:22.962] iteration 10628 : model1 loss : 0.434993 model2 loss : 0.023994
[23:54:23.142] iteration 10629 : model1 loss : 0.437420 model2 loss : 0.020987
[23:54:23.314] iteration 10630 : model1 loss : 0.435236 model2 loss : 0.022872
[23:54:23.491] iteration 10631 : model1 loss : 0.435132 model2 loss : 0.022248
[23:54:23.662] iteration 10632 : model1 loss : 0.435470 model2 loss : 0.024778
[23:54:23.837] iteration 10633 : model1 loss : 0.438111 model2 loss : 0.024026
[23:54:24.012] iteration 10634 : model1 loss : 0.434796 model2 loss : 0.021498
[23:54:24.190] iteration 10635 : model1 loss : 0.438985 model2 loss : 0.022275
[23:54:24.361] iteration 10636 : model1 loss : 0.439094 model2 loss : 0.023403
[23:54:24.538] iteration 10637 : model1 loss : 0.439347 model2 loss : 0.028037
[23:54:24.708] iteration 10638 : model1 loss : 0.436286 model2 loss : 0.023333
[23:54:24.883] iteration 10639 : model1 loss : 0.431919 model2 loss : 0.022142
[23:54:25.057] iteration 10640 : model1 loss : 0.438562 model2 loss : 0.018798
[23:54:25.233] iteration 10641 : model1 loss : 0.432851 model2 loss : 0.021188
[23:54:25.407] iteration 10642 : model1 loss : 0.439134 model2 loss : 0.025099
[23:54:25.589] iteration 10643 : model1 loss : 0.439566 model2 loss : 0.028405
[23:54:25.759] iteration 10644 : model1 loss : 0.437817 model2 loss : 0.021195
[23:54:25.937] iteration 10645 : model1 loss : 0.435350 model2 loss : 0.026295
[23:54:26.108] iteration 10646 : model1 loss : 0.435444 model2 loss : 0.026282
[23:54:26.282] iteration 10647 : model1 loss : 0.438770 model2 loss : 0.025044
[23:54:28.438] iteration 10648 : model1 loss : 0.440120 model2 loss : 0.024178
[23:54:28.611] iteration 10649 : model1 loss : 0.435620 model2 loss : 0.021784
[23:54:28.786] iteration 10650 : model1 loss : 0.439464 model2 loss : 0.024774
[23:54:28.958] iteration 10651 : model1 loss : 0.435408 model2 loss : 0.026545
[23:54:29.135] iteration 10652 : model1 loss : 0.437266 model2 loss : 0.022772
[23:54:29.307] iteration 10653 : model1 loss : 0.441259 model2 loss : 0.021990
[23:54:29.487] iteration 10654 : model1 loss : 0.438097 model2 loss : 0.026338
[23:54:29.658] iteration 10655 : model1 loss : 0.437486 model2 loss : 0.023476
[23:54:29.833] iteration 10656 : model1 loss : 0.439258 model2 loss : 0.028524
[23:54:30.008] iteration 10657 : model1 loss : 0.434455 model2 loss : 0.021756
[23:54:30.187] iteration 10658 : model1 loss : 0.433366 model2 loss : 0.024011
[23:54:30.358] iteration 10659 : model1 loss : 0.432797 model2 loss : 0.025274
[23:54:30.539] iteration 10660 : model1 loss : 0.437963 model2 loss : 0.023594
[23:54:30.711] iteration 10661 : model1 loss : 0.435227 model2 loss : 0.024549
[23:54:30.888] iteration 10662 : model1 loss : 0.433794 model2 loss : 0.025893
[23:54:31.064] iteration 10663 : model1 loss : 0.443786 model2 loss : 0.045022
[23:54:31.245] iteration 10664 : model1 loss : 0.437421 model2 loss : 0.024531
[23:54:31.418] iteration 10665 : model1 loss : 0.436549 model2 loss : 0.024848
[23:54:31.601] iteration 10666 : model1 loss : 0.442984 model2 loss : 0.042150
[23:54:31.770] iteration 10667 : model1 loss : 0.431488 model2 loss : 0.026032
[23:54:31.946] iteration 10668 : model1 loss : 0.430311 model2 loss : 0.025014
[23:54:34.104] iteration 10669 : model1 loss : 0.434108 model2 loss : 0.024135
[23:54:34.282] iteration 10670 : model1 loss : 0.440224 model2 loss : 0.026219
[23:54:34.460] iteration 10671 : model1 loss : 0.437461 model2 loss : 0.025050
[23:54:34.632] iteration 10672 : model1 loss : 0.438757 model2 loss : 0.025949
[23:54:34.808] iteration 10673 : model1 loss : 0.435387 model2 loss : 0.025698
[23:54:34.980] iteration 10674 : model1 loss : 0.438427 model2 loss : 0.025196
[23:54:35.158] iteration 10675 : model1 loss : 0.437305 model2 loss : 0.027397
[23:54:35.336] iteration 10676 : model1 loss : 0.434174 model2 loss : 0.021301
[23:54:35.515] iteration 10677 : model1 loss : 0.436680 model2 loss : 0.026832
[23:54:35.687] iteration 10678 : model1 loss : 0.439251 model2 loss : 0.024663
[23:54:35.864] iteration 10679 : model1 loss : 0.438782 model2 loss : 0.025055
[23:54:36.040] iteration 10680 : model1 loss : 0.433671 model2 loss : 0.023928
[23:54:36.215] iteration 10681 : model1 loss : 0.437305 model2 loss : 0.025793
[23:54:36.389] iteration 10682 : model1 loss : 0.431156 model2 loss : 0.025947
[23:54:36.568] iteration 10683 : model1 loss : 0.437111 model2 loss : 0.025181
[23:54:36.739] iteration 10684 : model1 loss : 0.435162 model2 loss : 0.025925
[23:54:36.915] iteration 10685 : model1 loss : 0.434404 model2 loss : 0.022217
[23:54:37.089] iteration 10686 : model1 loss : 0.443098 model2 loss : 0.030104
[23:54:37.267] iteration 10687 : model1 loss : 0.439130 model2 loss : 0.025817
[23:54:37.440] iteration 10688 : model1 loss : 0.437689 model2 loss : 0.029633
[23:54:37.617] iteration 10689 : model1 loss : 0.435675 model2 loss : 0.023364
[23:54:39.768] iteration 10690 : model1 loss : 0.435438 model2 loss : 0.021209
[23:54:39.940] iteration 10691 : model1 loss : 0.432738 model2 loss : 0.019050
[23:54:40.123] iteration 10692 : model1 loss : 0.438763 model2 loss : 0.025998
[23:54:40.294] iteration 10693 : model1 loss : 0.439826 model2 loss : 0.023933
[23:54:40.472] iteration 10694 : model1 loss : 0.434324 model2 loss : 0.022072
[23:54:40.649] iteration 10695 : model1 loss : 0.436115 model2 loss : 0.024253
[23:54:40.825] iteration 10696 : model1 loss : 0.434832 model2 loss : 0.026550
[23:54:40.998] iteration 10697 : model1 loss : 0.433831 model2 loss : 0.026390
[23:54:41.173] iteration 10698 : model1 loss : 0.441317 model2 loss : 0.023156
[23:54:41.347] iteration 10699 : model1 loss : 0.433597 model2 loss : 0.022107
[23:54:41.527] iteration 10700 : model1 loss : 0.440948 model2 loss : 0.027543
[23:54:41.698] iteration 10701 : model1 loss : 0.438444 model2 loss : 0.023448
[23:54:41.872] iteration 10702 : model1 loss : 0.438201 model2 loss : 0.022261
[23:54:42.048] iteration 10703 : model1 loss : 0.436006 model2 loss : 0.024353
[23:54:42.226] iteration 10704 : model1 loss : 0.440467 model2 loss : 0.026505
[23:54:42.398] iteration 10705 : model1 loss : 0.432719 model2 loss : 0.024185
[23:54:42.580] iteration 10706 : model1 loss : 0.437937 model2 loss : 0.028454
[23:54:42.750] iteration 10707 : model1 loss : 0.439110 model2 loss : 0.025164
[23:54:42.925] iteration 10708 : model1 loss : 0.431516 model2 loss : 0.022658
[23:54:43.099] iteration 10709 : model1 loss : 0.436362 model2 loss : 0.026795
[23:54:43.274] iteration 10710 : model1 loss : 0.438276 model2 loss : 0.026805
[23:54:45.427] iteration 10711 : model1 loss : 0.439534 model2 loss : 0.024120
[23:54:45.607] iteration 10712 : model1 loss : 0.438974 model2 loss : 0.023618
[23:54:45.785] iteration 10713 : model1 loss : 0.432891 model2 loss : 0.022421
[23:54:45.958] iteration 10714 : model1 loss : 0.433453 model2 loss : 0.021892
[23:54:46.136] iteration 10715 : model1 loss : 0.436128 model2 loss : 0.022732
[23:54:46.309] iteration 10716 : model1 loss : 0.440720 model2 loss : 0.027913
[23:54:46.489] iteration 10717 : model1 loss : 0.437302 model2 loss : 0.025491
[23:54:46.661] iteration 10718 : model1 loss : 0.439472 model2 loss : 0.022897
[23:54:46.835] iteration 10719 : model1 loss : 0.433120 model2 loss : 0.022923
[23:54:47.009] iteration 10720 : model1 loss : 0.435148 model2 loss : 0.024349
[23:54:47.189] iteration 10721 : model1 loss : 0.438098 model2 loss : 0.027155
[23:54:47.361] iteration 10722 : model1 loss : 0.438416 model2 loss : 0.024994
[23:54:47.541] iteration 10723 : model1 loss : 0.433562 model2 loss : 0.022346
[23:54:47.712] iteration 10724 : model1 loss : 0.436243 model2 loss : 0.021100
[23:54:47.888] iteration 10725 : model1 loss : 0.433334 model2 loss : 0.022626
[23:54:48.061] iteration 10726 : model1 loss : 0.440844 model2 loss : 0.027148
[23:54:48.235] iteration 10727 : model1 loss : 0.439451 model2 loss : 0.023671
[23:54:48.407] iteration 10728 : model1 loss : 0.433706 model2 loss : 0.023673
[23:54:48.587] iteration 10729 : model1 loss : 0.438114 model2 loss : 0.025551
[23:54:48.757] iteration 10730 : model1 loss : 0.438682 model2 loss : 0.024030
[23:54:48.931] iteration 10731 : model1 loss : 0.434452 model2 loss : 0.023183
[23:54:51.075] iteration 10732 : model1 loss : 0.437557 model2 loss : 0.026818
[23:54:51.250] iteration 10733 : model1 loss : 0.434297 model2 loss : 0.021718
[23:54:51.428] iteration 10734 : model1 loss : 0.437095 model2 loss : 0.023259
[23:54:51.606] iteration 10735 : model1 loss : 0.434537 model2 loss : 0.022545
[23:54:51.781] iteration 10736 : model1 loss : 0.435861 model2 loss : 0.025249
[23:54:51.953] iteration 10737 : model1 loss : 0.436737 model2 loss : 0.023213
[23:54:52.135] iteration 10738 : model1 loss : 0.432456 model2 loss : 0.024896
[23:54:52.307] iteration 10739 : model1 loss : 0.440288 model2 loss : 0.024938
[23:54:52.491] iteration 10740 : model1 loss : 0.435914 model2 loss : 0.025424
[23:54:52.662] iteration 10741 : model1 loss : 0.434961 model2 loss : 0.023761
[23:54:52.838] iteration 10742 : model1 loss : 0.435915 model2 loss : 0.024063
[23:54:53.010] iteration 10743 : model1 loss : 0.438354 model2 loss : 0.024478
[23:54:53.186] iteration 10744 : model1 loss : 0.438545 model2 loss : 0.022563
[23:54:53.357] iteration 10745 : model1 loss : 0.437470 model2 loss : 0.021596
[23:54:53.535] iteration 10746 : model1 loss : 0.437782 model2 loss : 0.025911
[23:54:53.707] iteration 10747 : model1 loss : 0.435144 model2 loss : 0.022025
[23:54:53.881] iteration 10748 : model1 loss : 0.440601 model2 loss : 0.032783
[23:54:54.054] iteration 10749 : model1 loss : 0.436195 model2 loss : 0.023676
[23:54:54.234] iteration 10750 : model1 loss : 0.434699 model2 loss : 0.021346
[23:54:54.405] iteration 10751 : model1 loss : 0.436636 model2 loss : 0.019651
[23:54:54.580] iteration 10752 : model1 loss : 0.436745 model2 loss : 0.022029
[23:54:56.749] iteration 10753 : model1 loss : 0.436780 model2 loss : 0.027393
[23:54:56.919] iteration 10754 : model1 loss : 0.434408 model2 loss : 0.024221
[23:54:57.097] iteration 10755 : model1 loss : 0.437113 model2 loss : 0.024500
[23:54:57.266] iteration 10756 : model1 loss : 0.437952 model2 loss : 0.026046
[23:54:57.444] iteration 10757 : model1 loss : 0.433368 model2 loss : 0.022633
[23:54:57.620] iteration 10758 : model1 loss : 0.437072 model2 loss : 0.025186
[23:54:57.796] iteration 10759 : model1 loss : 0.436909 model2 loss : 0.024653
[23:54:57.966] iteration 10760 : model1 loss : 0.435507 model2 loss : 0.019939
[23:54:58.146] iteration 10761 : model1 loss : 0.434912 model2 loss : 0.024254
[23:54:58.319] iteration 10762 : model1 loss : 0.435997 model2 loss : 0.024004
[23:54:58.498] iteration 10763 : model1 loss : 0.437325 model2 loss : 0.022365
[23:54:58.669] iteration 10764 : model1 loss : 0.433360 model2 loss : 0.022900
[23:54:58.844] iteration 10765 : model1 loss : 0.430163 model2 loss : 0.020752
[23:54:59.018] iteration 10766 : model1 loss : 0.437875 model2 loss : 0.022559
[23:54:59.198] iteration 10767 : model1 loss : 0.438130 model2 loss : 0.024698
[23:54:59.369] iteration 10768 : model1 loss : 0.441095 model2 loss : 0.021622
[23:54:59.548] iteration 10769 : model1 loss : 0.438745 model2 loss : 0.020783
[23:54:59.718] iteration 10770 : model1 loss : 0.440392 model2 loss : 0.027225
[23:54:59.895] iteration 10771 : model1 loss : 0.437398 model2 loss : 0.022247
[23:55:00.070] iteration 10772 : model1 loss : 0.436942 model2 loss : 0.025704
[23:55:00.244] iteration 10773 : model1 loss : 0.438430 model2 loss : 0.024937
[23:55:02.373] iteration 10774 : model1 loss : 0.432866 model2 loss : 0.019896
[23:55:02.549] iteration 10775 : model1 loss : 0.435716 model2 loss : 0.023903
[23:55:02.728] iteration 10776 : model1 loss : 0.437153 model2 loss : 0.024841
[23:55:02.900] iteration 10777 : model1 loss : 0.435234 model2 loss : 0.020897
[23:55:03.076] iteration 10778 : model1 loss : 0.434547 model2 loss : 0.020821
[23:55:03.245] iteration 10779 : model1 loss : 0.432441 model2 loss : 0.023077
[23:55:03.423] iteration 10780 : model1 loss : 0.435071 model2 loss : 0.022264
[23:55:03.599] iteration 10781 : model1 loss : 0.440402 model2 loss : 0.029926
[23:55:03.776] iteration 10782 : model1 loss : 0.440842 model2 loss : 0.028788
[23:55:03.946] iteration 10783 : model1 loss : 0.438957 model2 loss : 0.028427
[23:55:04.131] iteration 10784 : model1 loss : 0.436108 model2 loss : 0.024079
[23:55:04.303] iteration 10785 : model1 loss : 0.437250 model2 loss : 0.021962
[23:55:04.481] iteration 10786 : model1 loss : 0.436625 model2 loss : 0.025023
[23:55:04.654] iteration 10787 : model1 loss : 0.438329 model2 loss : 0.024418
[23:55:04.830] iteration 10788 : model1 loss : 0.436853 model2 loss : 0.022916
[23:55:05.007] iteration 10789 : model1 loss : 0.434505 model2 loss : 0.022408
[23:55:05.183] iteration 10790 : model1 loss : 0.437148 model2 loss : 0.024586
[23:55:05.357] iteration 10791 : model1 loss : 0.437825 model2 loss : 0.022623
[23:55:05.534] iteration 10792 : model1 loss : 0.436586 model2 loss : 0.021042
[23:55:05.704] iteration 10793 : model1 loss : 0.435855 model2 loss : 0.023369
[23:55:05.878] iteration 10794 : model1 loss : 0.440705 model2 loss : 0.025177
[23:55:08.168] iteration 10795 : model1 loss : 0.441146 model2 loss : 0.021952
[23:55:08.341] iteration 10796 : model1 loss : 0.434934 model2 loss : 0.021938
[23:55:08.520] iteration 10797 : model1 loss : 0.438179 model2 loss : 0.023368
[23:55:08.692] iteration 10798 : model1 loss : 0.436081 model2 loss : 0.023008
[23:55:08.866] iteration 10799 : model1 loss : 0.435348 model2 loss : 0.025054
[23:55:09.040] iteration 10800 : model1 loss : 0.434276 model2 loss : 0.021383
[23:55:09.215] iteration 10801 : model1 loss : 0.437629 model2 loss : 0.021705
[23:55:09.389] iteration 10802 : model1 loss : 0.436907 model2 loss : 0.022233
[23:55:09.566] iteration 10803 : model1 loss : 0.438067 model2 loss : 0.022872
[23:55:09.737] iteration 10804 : model1 loss : 0.442603 model2 loss : 0.026220
[23:55:09.915] iteration 10805 : model1 loss : 0.431272 model2 loss : 0.019894
[23:55:10.087] iteration 10806 : model1 loss : 0.435473 model2 loss : 0.025439
[23:55:10.264] iteration 10807 : model1 loss : 0.439554 model2 loss : 0.022287
[23:55:10.436] iteration 10808 : model1 loss : 0.433263 model2 loss : 0.022315
[23:55:10.617] iteration 10809 : model1 loss : 0.439625 model2 loss : 0.024714
[23:55:10.789] iteration 10810 : model1 loss : 0.436876 model2 loss : 0.023529
[23:55:10.964] iteration 10811 : model1 loss : 0.438336 model2 loss : 0.024186
[23:55:11.138] iteration 10812 : model1 loss : 0.440037 model2 loss : 0.026097
[23:55:11.318] iteration 10813 : model1 loss : 0.438056 model2 loss : 0.024228
[23:55:11.486] iteration 10814 : model1 loss : 0.436609 model2 loss : 0.022906
[23:55:11.666] iteration 10815 : model1 loss : 0.438803 model2 loss : 0.024769
[23:55:13.816] iteration 10816 : model1 loss : 0.440224 model2 loss : 0.022560
[23:55:13.991] iteration 10817 : model1 loss : 0.441799 model2 loss : 0.024820
[23:55:14.175] iteration 10818 : model1 loss : 0.439651 model2 loss : 0.020519
[23:55:14.353] iteration 10819 : model1 loss : 0.436255 model2 loss : 0.022423
[23:55:14.529] iteration 10820 : model1 loss : 0.437641 model2 loss : 0.023501
[23:55:14.701] iteration 10821 : model1 loss : 0.436589 model2 loss : 0.021100
[23:55:14.876] iteration 10822 : model1 loss : 0.436696 model2 loss : 0.024021
[23:55:15.049] iteration 10823 : model1 loss : 0.437961 model2 loss : 0.021001
[23:55:15.226] iteration 10824 : model1 loss : 0.438310 model2 loss : 0.023852
[23:55:15.397] iteration 10825 : model1 loss : 0.439566 model2 loss : 0.022778
[23:55:15.574] iteration 10826 : model1 loss : 0.433281 model2 loss : 0.019948
[23:55:15.746] iteration 10827 : model1 loss : 0.434593 model2 loss : 0.026086
[23:55:15.923] iteration 10828 : model1 loss : 0.438817 model2 loss : 0.022790
[23:55:16.096] iteration 10829 : model1 loss : 0.439692 model2 loss : 0.024878
[23:55:16.276] iteration 10830 : model1 loss : 0.436762 model2 loss : 0.023319
[23:55:16.449] iteration 10831 : model1 loss : 0.434486 model2 loss : 0.020593
[23:55:16.628] iteration 10832 : model1 loss : 0.437621 model2 loss : 0.020350
[23:55:16.798] iteration 10833 : model1 loss : 0.434754 model2 loss : 0.022953
[23:55:16.975] iteration 10834 : model1 loss : 0.436009 model2 loss : 0.023593
[23:55:17.147] iteration 10835 : model1 loss : 0.434223 model2 loss : 0.021414
[23:55:17.324] iteration 10836 : model1 loss : 0.440149 model2 loss : 0.026092
[23:55:19.473] iteration 10837 : model1 loss : 0.439493 model2 loss : 0.025212
[23:55:19.646] iteration 10838 : model1 loss : 0.434881 model2 loss : 0.026286
[23:55:19.826] iteration 10839 : model1 loss : 0.437474 model2 loss : 0.024319
[23:55:19.997] iteration 10840 : model1 loss : 0.438249 model2 loss : 0.024029
[23:55:20.178] iteration 10841 : model1 loss : 0.436394 model2 loss : 0.022852
[23:55:20.353] iteration 10842 : model1 loss : 0.436496 model2 loss : 0.023882
[23:55:20.533] iteration 10843 : model1 loss : 0.437964 model2 loss : 0.022929
[23:55:20.707] iteration 10844 : model1 loss : 0.441790 model2 loss : 0.024278
[23:55:20.883] iteration 10845 : model1 loss : 0.436674 model2 loss : 0.022021
[23:55:21.058] iteration 10846 : model1 loss : 0.437347 model2 loss : 0.024695
[23:55:21.239] iteration 10847 : model1 loss : 0.437850 model2 loss : 0.027436
[23:55:21.412] iteration 10848 : model1 loss : 0.437660 model2 loss : 0.022281
[23:55:21.595] iteration 10849 : model1 loss : 0.430358 model2 loss : 0.025785
[23:55:21.767] iteration 10850 : model1 loss : 0.446175 model2 loss : 0.023567
[23:55:21.943] iteration 10851 : model1 loss : 0.433828 model2 loss : 0.024027
[23:55:22.120] iteration 10852 : model1 loss : 0.437343 model2 loss : 0.025115
[23:55:22.298] iteration 10853 : model1 loss : 0.435842 model2 loss : 0.023081
[23:55:22.475] iteration 10854 : model1 loss : 0.434091 model2 loss : 0.020797
[23:55:22.653] iteration 10855 : model1 loss : 0.443022 model2 loss : 0.027110
[23:55:22.825] iteration 10856 : model1 loss : 0.434182 model2 loss : 0.024646
[23:55:23.000] iteration 10857 : model1 loss : 0.441634 model2 loss : 0.022908
[23:55:25.135] iteration 10858 : model1 loss : 0.439969 model2 loss : 0.023956
[23:55:25.314] iteration 10859 : model1 loss : 0.434877 model2 loss : 0.024035
[23:55:25.490] iteration 10860 : model1 loss : 0.439483 model2 loss : 0.024580
[23:55:25.663] iteration 10861 : model1 loss : 0.434754 model2 loss : 0.024111
[23:55:25.837] iteration 10862 : model1 loss : 0.436067 model2 loss : 0.021520
[23:55:26.010] iteration 10863 : model1 loss : 0.442205 model2 loss : 0.024687
[23:55:26.191] iteration 10864 : model1 loss : 0.437210 model2 loss : 0.026007
[23:55:26.365] iteration 10865 : model1 loss : 0.439565 model2 loss : 0.025541
[23:55:26.548] iteration 10866 : model1 loss : 0.439221 model2 loss : 0.022587
[23:55:26.721] iteration 10867 : model1 loss : 0.437442 model2 loss : 0.020332
[23:55:26.897] iteration 10868 : model1 loss : 0.439983 model2 loss : 0.023540
[23:55:27.071] iteration 10869 : model1 loss : 0.438575 model2 loss : 0.022797
[23:55:27.245] iteration 10870 : model1 loss : 0.441174 model2 loss : 0.023704
[23:55:27.418] iteration 10871 : model1 loss : 0.432906 model2 loss : 0.022982
[23:55:27.598] iteration 10872 : model1 loss : 0.440305 model2 loss : 0.022050
[23:55:27.770] iteration 10873 : model1 loss : 0.436497 model2 loss : 0.021862
[23:55:27.945] iteration 10874 : model1 loss : 0.440682 model2 loss : 0.024376
[23:55:28.121] iteration 10875 : model1 loss : 0.434635 model2 loss : 0.020659
[23:55:28.300] iteration 10876 : model1 loss : 0.436696 model2 loss : 0.023954
[23:55:28.469] iteration 10877 : model1 loss : 0.434701 model2 loss : 0.024311
[23:55:28.642] iteration 10878 : model1 loss : 0.433699 model2 loss : 0.020438
[23:55:30.779] iteration 10879 : model1 loss : 0.436812 model2 loss : 0.023406
[23:55:30.953] iteration 10880 : model1 loss : 0.434737 model2 loss : 0.019624
[23:55:31.137] iteration 10881 : model1 loss : 0.436175 model2 loss : 0.022556
[23:55:31.308] iteration 10882 : model1 loss : 0.434869 model2 loss : 0.023892
[23:55:31.486] iteration 10883 : model1 loss : 0.437616 model2 loss : 0.023093
[23:55:31.665] iteration 10884 : model1 loss : 0.441275 model2 loss : 0.023129
[23:55:31.840] iteration 10885 : model1 loss : 0.436664 model2 loss : 0.020859
[23:55:32.010] iteration 10886 : model1 loss : 0.431141 model2 loss : 0.023319
[23:55:32.191] iteration 10887 : model1 loss : 0.441356 model2 loss : 0.025956
[23:55:32.364] iteration 10888 : model1 loss : 0.437012 model2 loss : 0.023384
[23:55:32.543] iteration 10889 : model1 loss : 0.434673 model2 loss : 0.022114
[23:55:32.717] iteration 10890 : model1 loss : 0.437088 model2 loss : 0.025181
[23:55:32.895] iteration 10891 : model1 loss : 0.441955 model2 loss : 0.021424
[23:55:33.068] iteration 10892 : model1 loss : 0.439392 model2 loss : 0.021178
[23:55:33.244] iteration 10893 : model1 loss : 0.439538 model2 loss : 0.025925
[23:55:33.415] iteration 10894 : model1 loss : 0.437345 model2 loss : 0.025059
[23:55:33.597] iteration 10895 : model1 loss : 0.434552 model2 loss : 0.020809
[23:55:33.770] iteration 10896 : model1 loss : 0.436266 model2 loss : 0.022944
[23:55:33.944] iteration 10897 : model1 loss : 0.438658 model2 loss : 0.022354
[23:55:34.121] iteration 10898 : model1 loss : 0.435999 model2 loss : 0.020778
[23:55:34.295] iteration 10899 : model1 loss : 0.436324 model2 loss : 0.021543
[23:55:36.419] iteration 10900 : model1 loss : 0.434137 model2 loss : 0.020631
[23:55:36.605] iteration 10901 : model1 loss : 0.432486 model2 loss : 0.020443
[23:55:36.782] iteration 10902 : model1 loss : 0.438930 model2 loss : 0.023232
[23:55:36.953] iteration 10903 : model1 loss : 0.433600 model2 loss : 0.021137
[23:55:37.132] iteration 10904 : model1 loss : 0.433205 model2 loss : 0.017315
[23:55:37.306] iteration 10905 : model1 loss : 0.435824 model2 loss : 0.021582
[23:55:37.485] iteration 10906 : model1 loss : 0.439447 model2 loss : 0.022574
[23:55:37.657] iteration 10907 : model1 loss : 0.440211 model2 loss : 0.026620
[23:55:37.835] iteration 10908 : model1 loss : 0.439645 model2 loss : 0.023505
[23:55:38.006] iteration 10909 : model1 loss : 0.440532 model2 loss : 0.023005
[23:55:38.184] iteration 10910 : model1 loss : 0.438969 model2 loss : 0.021309
[23:55:38.359] iteration 10911 : model1 loss : 0.437085 model2 loss : 0.020597
[23:55:38.537] iteration 10912 : model1 loss : 0.437601 model2 loss : 0.022090
[23:55:38.710] iteration 10913 : model1 loss : 0.436041 model2 loss : 0.021704
[23:55:38.888] iteration 10914 : model1 loss : 0.436867 model2 loss : 0.020454
[23:55:39.062] iteration 10915 : model1 loss : 0.437530 model2 loss : 0.022409
[23:55:39.237] iteration 10916 : model1 loss : 0.437036 model2 loss : 0.019640
[23:55:39.407] iteration 10917 : model1 loss : 0.436505 model2 loss : 0.024226
[23:55:39.587] iteration 10918 : model1 loss : 0.435669 model2 loss : 0.019823
[23:55:39.758] iteration 10919 : model1 loss : 0.437230 model2 loss : 0.021694
[23:55:39.930] iteration 10920 : model1 loss : 0.438346 model2 loss : 0.023975
[23:55:42.074] iteration 10921 : model1 loss : 0.436025 model2 loss : 0.024210
[23:55:42.252] iteration 10922 : model1 loss : 0.439557 model2 loss : 0.022485
[23:55:42.430] iteration 10923 : model1 loss : 0.435153 model2 loss : 0.022721
[23:55:42.608] iteration 10924 : model1 loss : 0.435870 model2 loss : 0.019880
[23:55:42.784] iteration 10925 : model1 loss : 0.435642 model2 loss : 0.020668
[23:55:42.955] iteration 10926 : model1 loss : 0.436316 model2 loss : 0.023023
[23:55:43.132] iteration 10927 : model1 loss : 0.439295 model2 loss : 0.022850
[23:55:43.305] iteration 10928 : model1 loss : 0.434600 model2 loss : 0.020973
[23:55:43.483] iteration 10929 : model1 loss : 0.431072 model2 loss : 0.021208
[23:55:43.657] iteration 10930 : model1 loss : 0.438442 model2 loss : 0.023469
[23:55:43.831] iteration 10931 : model1 loss : 0.437735 model2 loss : 0.022834
[23:55:44.004] iteration 10932 : model1 loss : 0.437988 model2 loss : 0.024146
[23:55:44.181] iteration 10933 : model1 loss : 0.436152 model2 loss : 0.021469
[23:55:44.356] iteration 10934 : model1 loss : 0.439762 model2 loss : 0.026581
[23:55:44.533] iteration 10935 : model1 loss : 0.439899 model2 loss : 0.022659
[23:55:44.706] iteration 10936 : model1 loss : 0.436482 model2 loss : 0.023372
[23:55:44.882] iteration 10937 : model1 loss : 0.438185 model2 loss : 0.021711
[23:55:45.053] iteration 10938 : model1 loss : 0.435254 model2 loss : 0.022770
[23:55:45.229] iteration 10939 : model1 loss : 0.434981 model2 loss : 0.022841
[23:55:45.401] iteration 10940 : model1 loss : 0.439999 model2 loss : 0.022659
[23:55:45.576] iteration 10941 : model1 loss : 0.439385 model2 loss : 0.025704
[23:55:47.756] iteration 10942 : model1 loss : 0.442088 model2 loss : 0.025449
[23:55:47.930] iteration 10943 : model1 loss : 0.435412 model2 loss : 0.022090
[23:55:48.120] iteration 10944 : model1 loss : 0.438524 model2 loss : 0.022495
[23:55:48.293] iteration 10945 : model1 loss : 0.437551 model2 loss : 0.023447
[23:55:48.473] iteration 10946 : model1 loss : 0.433454 model2 loss : 0.019463
[23:55:48.646] iteration 10947 : model1 loss : 0.438166 model2 loss : 0.023655
[23:55:48.824] iteration 10948 : model1 loss : 0.436875 model2 loss : 0.019242
[23:55:48.996] iteration 10949 : model1 loss : 0.445947 model2 loss : 0.023839
[23:55:49.173] iteration 10950 : model1 loss : 0.439795 model2 loss : 0.023131
[23:55:49.347] iteration 10951 : model1 loss : 0.437782 model2 loss : 0.025614
[23:55:49.524] iteration 10952 : model1 loss : 0.434683 model2 loss : 0.022955
[23:55:49.698] iteration 10953 : model1 loss : 0.433989 model2 loss : 0.022148
[23:55:49.873] iteration 10954 : model1 loss : 0.439289 model2 loss : 0.022108
[23:55:50.043] iteration 10955 : model1 loss : 0.436144 model2 loss : 0.020452
[23:55:50.220] iteration 10956 : model1 loss : 0.434958 model2 loss : 0.021900
[23:55:50.397] iteration 10957 : model1 loss : 0.439519 model2 loss : 0.023375
[23:55:50.577] iteration 10958 : model1 loss : 0.434963 model2 loss : 0.021527
[23:55:50.750] iteration 10959 : model1 loss : 0.435137 model2 loss : 0.021389
[23:55:50.928] iteration 10960 : model1 loss : 0.433396 model2 loss : 0.021341
[23:55:51.101] iteration 10961 : model1 loss : 0.436746 model2 loss : 0.023321
[23:55:51.276] iteration 10962 : model1 loss : 0.436961 model2 loss : 0.023488
[23:55:53.460] iteration 10963 : model1 loss : 0.433586 model2 loss : 0.022936
[23:55:53.639] iteration 10964 : model1 loss : 0.439438 model2 loss : 0.022329
[23:55:53.817] iteration 10965 : model1 loss : 0.436689 model2 loss : 0.021533
[23:55:53.990] iteration 10966 : model1 loss : 0.436080 model2 loss : 0.020615
[23:55:54.168] iteration 10967 : model1 loss : 0.436932 model2 loss : 0.021158
[23:55:54.343] iteration 10968 : model1 loss : 0.437272 model2 loss : 0.021988
[23:55:54.519] iteration 10969 : model1 loss : 0.440233 model2 loss : 0.024725
[23:55:54.697] iteration 10970 : model1 loss : 0.441564 model2 loss : 0.024074
[23:55:54.875] iteration 10971 : model1 loss : 0.432692 model2 loss : 0.026392
[23:55:55.046] iteration 10972 : model1 loss : 0.435971 model2 loss : 0.021275
[23:55:55.227] iteration 10973 : model1 loss : 0.436752 model2 loss : 0.021794
[23:55:55.398] iteration 10974 : model1 loss : 0.439438 model2 loss : 0.021169
[23:55:55.578] iteration 10975 : model1 loss : 0.436558 model2 loss : 0.022568
[23:55:55.751] iteration 10976 : model1 loss : 0.432377 model2 loss : 0.020015
[23:55:55.933] iteration 10977 : model1 loss : 0.437733 model2 loss : 0.022712
[23:55:56.108] iteration 10978 : model1 loss : 0.436699 model2 loss : 0.019805
[23:55:56.285] iteration 10979 : model1 loss : 0.437742 model2 loss : 0.024547
[23:55:56.460] iteration 10980 : model1 loss : 0.436672 model2 loss : 0.023243
[23:55:56.643] iteration 10981 : model1 loss : 0.435980 model2 loss : 0.020681
[23:55:56.813] iteration 10982 : model1 loss : 0.442199 model2 loss : 0.024970
[23:55:56.990] iteration 10983 : model1 loss : 0.432525 model2 loss : 0.023494
[23:55:59.163] iteration 10984 : model1 loss : 0.439827 model2 loss : 0.024350
[23:55:59.336] iteration 10985 : model1 loss : 0.429986 model2 loss : 0.022539
[23:55:59.513] iteration 10986 : model1 loss : 0.438401 model2 loss : 0.023401
[23:55:59.685] iteration 10987 : model1 loss : 0.441574 model2 loss : 0.028540
[23:55:59.861] iteration 10988 : model1 loss : 0.431974 model2 loss : 0.020749
[23:56:00.033] iteration 10989 : model1 loss : 0.436961 model2 loss : 0.019334
[23:56:00.215] iteration 10990 : model1 loss : 0.437110 model2 loss : 0.025179
[23:56:00.398] iteration 10991 : model1 loss : 0.436548 model2 loss : 0.021710
[23:56:00.588] iteration 10992 : model1 loss : 0.439395 model2 loss : 0.024496
[23:56:00.760] iteration 10993 : model1 loss : 0.435869 model2 loss : 0.024243
[23:56:00.936] iteration 10994 : model1 loss : 0.437837 model2 loss : 0.022733
[23:56:01.113] iteration 10995 : model1 loss : 0.437719 model2 loss : 0.022397
[23:56:01.292] iteration 10996 : model1 loss : 0.439189 model2 loss : 0.022326
[23:56:01.470] iteration 10997 : model1 loss : 0.435367 model2 loss : 0.022539
[23:56:01.648] iteration 10998 : model1 loss : 0.438666 model2 loss : 0.023357
[23:56:01.819] iteration 10999 : model1 loss : 0.433155 model2 loss : 0.021599
[23:56:01.995] iteration 11000 : model1 loss : 0.437301 model2 loss : 0.026401
[23:56:11.288] iteration 11000 : model1_mean_dice : 0.829056 model1_mean_hd95 : 10.342794
[23:56:20.525] iteration 11000 : model2_mean_dice : 0.855256 model2_mean_hd95 : 10.485036
[23:56:20.709] iteration 11001 : model1 loss : 0.437160 model2 loss : 0.023005
[23:56:20.889] iteration 11002 : model1 loss : 0.434367 model2 loss : 0.022547
[23:56:21.066] iteration 11003 : model1 loss : 0.434802 model2 loss : 0.022145
[23:56:21.240] iteration 11004 : model1 loss : 0.437174 model2 loss : 0.022550
[23:56:23.415] iteration 11005 : model1 loss : 0.433681 model2 loss : 0.020966
[23:56:23.589] iteration 11006 : model1 loss : 0.436860 model2 loss : 0.021391
[23:56:23.768] iteration 11007 : model1 loss : 0.435930 model2 loss : 0.021693
[23:56:23.939] iteration 11008 : model1 loss : 0.434102 model2 loss : 0.019792
[23:56:24.115] iteration 11009 : model1 loss : 0.437589 model2 loss : 0.023287
[23:56:24.289] iteration 11010 : model1 loss : 0.436271 model2 loss : 0.022587
[23:56:24.464] iteration 11011 : model1 loss : 0.437201 model2 loss : 0.021663
[23:56:24.638] iteration 11012 : model1 loss : 0.437083 model2 loss : 0.020874
[23:56:24.815] iteration 11013 : model1 loss : 0.436569 model2 loss : 0.021760
[23:56:24.984] iteration 11014 : model1 loss : 0.438066 model2 loss : 0.023342
[23:56:25.162] iteration 11015 : model1 loss : 0.435311 model2 loss : 0.019188
[23:56:25.338] iteration 11016 : model1 loss : 0.436712 model2 loss : 0.022385
[23:56:25.514] iteration 11017 : model1 loss : 0.438660 model2 loss : 0.025493
[23:56:25.687] iteration 11018 : model1 loss : 0.437236 model2 loss : 0.021306
[23:56:25.863] iteration 11019 : model1 loss : 0.431235 model2 loss : 0.021463
[23:56:26.037] iteration 11020 : model1 loss : 0.435874 model2 loss : 0.022357
[23:56:26.215] iteration 11021 : model1 loss : 0.439166 model2 loss : 0.022408
[23:56:26.385] iteration 11022 : model1 loss : 0.439444 model2 loss : 0.026100
[23:56:26.563] iteration 11023 : model1 loss : 0.443719 model2 loss : 0.025127
[23:56:26.735] iteration 11024 : model1 loss : 0.438868 model2 loss : 0.023564
[23:56:26.910] iteration 11025 : model1 loss : 0.434872 model2 loss : 0.023536
[23:56:29.081] iteration 11026 : model1 loss : 0.430777 model2 loss : 0.022006
[23:56:29.257] iteration 11027 : model1 loss : 0.441805 model2 loss : 0.028490
[23:56:29.436] iteration 11028 : model1 loss : 0.439075 model2 loss : 0.034359
[23:56:29.608] iteration 11029 : model1 loss : 0.437645 model2 loss : 0.025577
[23:56:29.785] iteration 11030 : model1 loss : 0.440395 model2 loss : 0.024556
[23:56:29.956] iteration 11031 : model1 loss : 0.440306 model2 loss : 0.025084
[23:56:30.136] iteration 11032 : model1 loss : 0.436293 model2 loss : 0.021355
[23:56:30.309] iteration 11033 : model1 loss : 0.435309 model2 loss : 0.021646
[23:56:30.484] iteration 11034 : model1 loss : 0.436623 model2 loss : 0.020415
[23:56:30.656] iteration 11035 : model1 loss : 0.438194 model2 loss : 0.022830
[23:56:30.832] iteration 11036 : model1 loss : 0.433095 model2 loss : 0.022397
[23:56:31.003] iteration 11037 : model1 loss : 0.434304 model2 loss : 0.023648
[23:56:31.179] iteration 11038 : model1 loss : 0.437482 model2 loss : 0.022508
[23:56:31.352] iteration 11039 : model1 loss : 0.436206 model2 loss : 0.023339
[23:56:31.529] iteration 11040 : model1 loss : 0.438327 model2 loss : 0.022699
[23:56:31.701] iteration 11041 : model1 loss : 0.434366 model2 loss : 0.021680
[23:56:31.878] iteration 11042 : model1 loss : 0.436542 model2 loss : 0.021518
[23:56:32.048] iteration 11043 : model1 loss : 0.434774 model2 loss : 0.020493
[23:56:32.226] iteration 11044 : model1 loss : 0.436361 model2 loss : 0.020465
[23:56:32.398] iteration 11045 : model1 loss : 0.436569 model2 loss : 0.023655
[23:56:32.569] iteration 11046 : model1 loss : 0.433904 model2 loss : 0.020990
[23:56:34.720] iteration 11047 : model1 loss : 0.444116 model2 loss : 0.023297
[23:56:34.890] iteration 11048 : model1 loss : 0.439234 model2 loss : 0.026009
[23:56:35.070] iteration 11049 : model1 loss : 0.439630 model2 loss : 0.023072
[23:56:35.242] iteration 11050 : model1 loss : 0.433737 model2 loss : 0.021742
[23:56:35.420] iteration 11051 : model1 loss : 0.437845 model2 loss : 0.021515
[23:56:35.595] iteration 11052 : model1 loss : 0.435984 model2 loss : 0.024730
[23:56:35.770] iteration 11053 : model1 loss : 0.438294 model2 loss : 0.022344
[23:56:35.942] iteration 11054 : model1 loss : 0.436606 model2 loss : 0.023540
[23:56:36.119] iteration 11055 : model1 loss : 0.440006 model2 loss : 0.024278
[23:56:36.295] iteration 11056 : model1 loss : 0.437193 model2 loss : 0.023877
[23:56:36.471] iteration 11057 : model1 loss : 0.435189 model2 loss : 0.021088
[23:56:36.644] iteration 11058 : model1 loss : 0.439990 model2 loss : 0.025307
[23:56:36.822] iteration 11059 : model1 loss : 0.438463 model2 loss : 0.023147
[23:56:36.994] iteration 11060 : model1 loss : 0.438706 model2 loss : 0.024110
[23:56:37.170] iteration 11061 : model1 loss : 0.438644 model2 loss : 0.022291
[23:56:37.344] iteration 11062 : model1 loss : 0.438510 model2 loss : 0.021697
[23:56:37.523] iteration 11063 : model1 loss : 0.438990 model2 loss : 0.023380
[23:56:37.696] iteration 11064 : model1 loss : 0.438485 model2 loss : 0.021990
[23:56:37.873] iteration 11065 : model1 loss : 0.432906 model2 loss : 0.022983
[23:56:38.043] iteration 11066 : model1 loss : 0.437496 model2 loss : 0.023340
[23:56:38.218] iteration 11067 : model1 loss : 0.437108 model2 loss : 0.021575
[23:56:40.357] iteration 11068 : model1 loss : 0.430090 model2 loss : 0.021449
[23:56:40.536] iteration 11069 : model1 loss : 0.432463 model2 loss : 0.023229
[23:56:40.713] iteration 11070 : model1 loss : 0.439863 model2 loss : 0.023543
[23:56:40.885] iteration 11071 : model1 loss : 0.435348 model2 loss : 0.022665
[23:56:41.060] iteration 11072 : model1 loss : 0.438318 model2 loss : 0.023471
[23:56:41.234] iteration 11073 : model1 loss : 0.438162 model2 loss : 0.021609
[23:56:41.408] iteration 11074 : model1 loss : 0.437813 model2 loss : 0.021584
[23:56:41.581] iteration 11075 : model1 loss : 0.440484 model2 loss : 0.024425
[23:56:41.759] iteration 11076 : model1 loss : 0.440035 model2 loss : 0.021477
[23:56:41.930] iteration 11077 : model1 loss : 0.436647 model2 loss : 0.023090
[23:56:42.105] iteration 11078 : model1 loss : 0.434600 model2 loss : 0.019883
[23:56:42.279] iteration 11079 : model1 loss : 0.439493 model2 loss : 0.024885
[23:56:42.457] iteration 11080 : model1 loss : 0.437477 model2 loss : 0.020536
[23:56:42.628] iteration 11081 : model1 loss : 0.437299 model2 loss : 0.022566
[23:56:42.808] iteration 11082 : model1 loss : 0.439670 model2 loss : 0.024265
[23:56:42.979] iteration 11083 : model1 loss : 0.434126 model2 loss : 0.022096
[23:56:43.158] iteration 11084 : model1 loss : 0.438120 model2 loss : 0.023175
[23:56:43.334] iteration 11085 : model1 loss : 0.439437 model2 loss : 0.027512
[23:56:43.510] iteration 11086 : model1 loss : 0.438508 model2 loss : 0.023514
[23:56:43.683] iteration 11087 : model1 loss : 0.441826 model2 loss : 0.029467
[23:56:43.856] iteration 11088 : model1 loss : 0.432286 model2 loss : 0.022795
[23:56:45.975] iteration 11089 : model1 loss : 0.439900 model2 loss : 0.021406
[23:56:46.150] iteration 11090 : model1 loss : 0.438286 model2 loss : 0.023755
[23:56:46.334] iteration 11091 : model1 loss : 0.435602 model2 loss : 0.020496
[23:56:46.506] iteration 11092 : model1 loss : 0.434101 model2 loss : 0.020560
[23:56:46.684] iteration 11093 : model1 loss : 0.436462 model2 loss : 0.022362
[23:56:46.856] iteration 11094 : model1 loss : 0.433942 model2 loss : 0.019239
[23:56:47.031] iteration 11095 : model1 loss : 0.436300 model2 loss : 0.022458
[23:56:47.207] iteration 11096 : model1 loss : 0.434027 model2 loss : 0.020848
[23:56:47.381] iteration 11097 : model1 loss : 0.443544 model2 loss : 0.027656
[23:56:47.552] iteration 11098 : model1 loss : 0.437114 model2 loss : 0.021978
[23:56:47.729] iteration 11099 : model1 loss : 0.439218 model2 loss : 0.023228
[23:56:47.900] iteration 11100 : model1 loss : 0.436578 model2 loss : 0.018691
[23:56:48.079] iteration 11101 : model1 loss : 0.435854 model2 loss : 0.023272
[23:56:48.253] iteration 11102 : model1 loss : 0.434973 model2 loss : 0.023484
[23:56:48.430] iteration 11103 : model1 loss : 0.439539 model2 loss : 0.020579
[23:56:48.603] iteration 11104 : model1 loss : 0.436395 model2 loss : 0.023095
[23:56:48.780] iteration 11105 : model1 loss : 0.432130 model2 loss : 0.021812
[23:56:48.951] iteration 11106 : model1 loss : 0.436481 model2 loss : 0.023593
[23:56:49.127] iteration 11107 : model1 loss : 0.434188 model2 loss : 0.021092
[23:56:49.300] iteration 11108 : model1 loss : 0.437423 model2 loss : 0.022847
[23:56:49.474] iteration 11109 : model1 loss : 0.439528 model2 loss : 0.028094
[23:56:51.625] iteration 11110 : model1 loss : 0.433241 model2 loss : 0.022508
[23:56:51.802] iteration 11111 : model1 loss : 0.438570 model2 loss : 0.028285
[23:56:51.979] iteration 11112 : model1 loss : 0.437571 model2 loss : 0.020944
[23:56:52.152] iteration 11113 : model1 loss : 0.431709 model2 loss : 0.021274
[23:56:52.334] iteration 11114 : model1 loss : 0.435507 model2 loss : 0.021411
[23:56:52.511] iteration 11115 : model1 loss : 0.436698 model2 loss : 0.021395
[23:56:52.688] iteration 11116 : model1 loss : 0.435601 model2 loss : 0.020540
[23:56:52.861] iteration 11117 : model1 loss : 0.434592 model2 loss : 0.023007
[23:56:53.038] iteration 11118 : model1 loss : 0.438621 model2 loss : 0.023828
[23:56:53.212] iteration 11119 : model1 loss : 0.439874 model2 loss : 0.023534
[23:56:53.390] iteration 11120 : model1 loss : 0.438750 model2 loss : 0.022514
[23:56:53.561] iteration 11121 : model1 loss : 0.434908 model2 loss : 0.023247
[23:56:53.738] iteration 11122 : model1 loss : 0.437088 model2 loss : 0.026032
[23:56:53.914] iteration 11123 : model1 loss : 0.434011 model2 loss : 0.022700
[23:56:54.092] iteration 11124 : model1 loss : 0.440267 model2 loss : 0.021876
[23:56:54.267] iteration 11125 : model1 loss : 0.436966 model2 loss : 0.023796
[23:56:54.442] iteration 11126 : model1 loss : 0.438393 model2 loss : 0.024056
[23:56:54.618] iteration 11127 : model1 loss : 0.438541 model2 loss : 0.027462
[23:56:54.796] iteration 11128 : model1 loss : 0.435506 model2 loss : 0.020197
[23:56:54.965] iteration 11129 : model1 loss : 0.439324 model2 loss : 0.023291
[23:56:55.140] iteration 11130 : model1 loss : 0.433761 model2 loss : 0.022970
[23:56:57.297] iteration 11131 : model1 loss : 0.434402 model2 loss : 0.022103
[23:56:57.475] iteration 11132 : model1 loss : 0.433570 model2 loss : 0.022755
[23:56:57.650] iteration 11133 : model1 loss : 0.438246 model2 loss : 0.024128
[23:56:57.823] iteration 11134 : model1 loss : 0.433130 model2 loss : 0.019537
[23:56:57.997] iteration 11135 : model1 loss : 0.440541 model2 loss : 0.026862
[23:56:58.172] iteration 11136 : model1 loss : 0.438126 model2 loss : 0.018668
[23:56:58.351] iteration 11137 : model1 loss : 0.435108 model2 loss : 0.022790
[23:56:58.523] iteration 11138 : model1 loss : 0.435777 model2 loss : 0.020815
[23:56:58.703] iteration 11139 : model1 loss : 0.439895 model2 loss : 0.022263
[23:56:58.876] iteration 11140 : model1 loss : 0.438961 model2 loss : 0.025264
[23:56:59.050] iteration 11141 : model1 loss : 0.438404 model2 loss : 0.023353
[23:56:59.223] iteration 11142 : model1 loss : 0.435314 model2 loss : 0.023440
[23:56:59.400] iteration 11143 : model1 loss : 0.434841 model2 loss : 0.020848
[23:56:59.572] iteration 11144 : model1 loss : 0.435856 model2 loss : 0.020085
[23:56:59.749] iteration 11145 : model1 loss : 0.437014 model2 loss : 0.021227
[23:56:59.922] iteration 11146 : model1 loss : 0.436838 model2 loss : 0.021841
[23:57:00.099] iteration 11147 : model1 loss : 0.438583 model2 loss : 0.023062
[23:57:00.275] iteration 11148 : model1 loss : 0.439383 model2 loss : 0.022715
[23:57:00.451] iteration 11149 : model1 loss : 0.433719 model2 loss : 0.020492
[23:57:00.623] iteration 11150 : model1 loss : 0.433935 model2 loss : 0.021894
[23:57:00.798] iteration 11151 : model1 loss : 0.436977 model2 loss : 0.021425
[23:57:02.962] iteration 11152 : model1 loss : 0.437683 model2 loss : 0.021628
[23:57:03.137] iteration 11153 : model1 loss : 0.439059 model2 loss : 0.023774
[23:57:03.317] iteration 11154 : model1 loss : 0.437658 model2 loss : 0.022323
[23:57:03.488] iteration 11155 : model1 loss : 0.433343 model2 loss : 0.019909
[23:57:03.669] iteration 11156 : model1 loss : 0.436442 model2 loss : 0.022367
[23:57:03.842] iteration 11157 : model1 loss : 0.440530 model2 loss : 0.023341
[23:57:04.020] iteration 11158 : model1 loss : 0.437489 model2 loss : 0.023549
[23:57:04.193] iteration 11159 : model1 loss : 0.438370 model2 loss : 0.024689
[23:57:04.371] iteration 11160 : model1 loss : 0.438089 model2 loss : 0.023512
[23:57:04.542] iteration 11161 : model1 loss : 0.434208 model2 loss : 0.023187
[23:57:04.720] iteration 11162 : model1 loss : 0.435939 model2 loss : 0.023620
[23:57:04.891] iteration 11163 : model1 loss : 0.437636 model2 loss : 0.024383
[23:57:05.071] iteration 11164 : model1 loss : 0.436696 model2 loss : 0.020797
[23:57:05.244] iteration 11165 : model1 loss : 0.439055 model2 loss : 0.023497
[23:57:05.423] iteration 11166 : model1 loss : 0.432130 model2 loss : 0.022721
[23:57:05.595] iteration 11167 : model1 loss : 0.434665 model2 loss : 0.019028
[23:57:05.773] iteration 11168 : model1 loss : 0.434796 model2 loss : 0.020744
[23:57:05.943] iteration 11169 : model1 loss : 0.439155 model2 loss : 0.021549
[23:57:06.126] iteration 11170 : model1 loss : 0.438973 model2 loss : 0.026706
[23:57:06.300] iteration 11171 : model1 loss : 0.431565 model2 loss : 0.022189
[23:57:06.474] iteration 11172 : model1 loss : 0.434489 model2 loss : 0.021511
[23:57:08.652] iteration 11173 : model1 loss : 0.430603 model2 loss : 0.023582
[23:57:08.830] iteration 11174 : model1 loss : 0.435835 model2 loss : 0.021642
[23:57:09.005] iteration 11175 : model1 loss : 0.435175 model2 loss : 0.021786
[23:57:09.179] iteration 11176 : model1 loss : 0.435853 model2 loss : 0.026739
[23:57:09.359] iteration 11177 : model1 loss : 0.434805 model2 loss : 0.028268
[23:57:09.529] iteration 11178 : model1 loss : 0.441097 model2 loss : 0.022837
[23:57:09.706] iteration 11179 : model1 loss : 0.433232 model2 loss : 0.021644
[23:57:09.878] iteration 11180 : model1 loss : 0.433848 model2 loss : 0.020072
[23:57:10.056] iteration 11181 : model1 loss : 0.436008 model2 loss : 0.022958
[23:57:10.227] iteration 11182 : model1 loss : 0.439529 model2 loss : 0.024170
[23:57:10.404] iteration 11183 : model1 loss : 0.433772 model2 loss : 0.021165
[23:57:10.574] iteration 11184 : model1 loss : 0.440740 model2 loss : 0.025362
[23:57:10.755] iteration 11185 : model1 loss : 0.441824 model2 loss : 0.023618
[23:57:10.925] iteration 11186 : model1 loss : 0.432807 model2 loss : 0.021367
[23:57:11.099] iteration 11187 : model1 loss : 0.439317 model2 loss : 0.023528
[23:57:11.273] iteration 11188 : model1 loss : 0.441128 model2 loss : 0.024731
[23:57:11.448] iteration 11189 : model1 loss : 0.437527 model2 loss : 0.022354
[23:57:11.623] iteration 11190 : model1 loss : 0.435614 model2 loss : 0.027214
[23:57:11.800] iteration 11191 : model1 loss : 0.439485 model2 loss : 0.022923
[23:57:11.968] iteration 11192 : model1 loss : 0.440405 model2 loss : 0.021467
[23:57:12.143] iteration 11193 : model1 loss : 0.434898 model2 loss : 0.019996
[23:57:14.315] iteration 11194 : model1 loss : 0.433785 model2 loss : 0.020624
[23:57:14.488] iteration 11195 : model1 loss : 0.440960 model2 loss : 0.024875
[23:57:14.666] iteration 11196 : model1 loss : 0.435496 model2 loss : 0.021098
[23:57:14.840] iteration 11197 : model1 loss : 0.434962 model2 loss : 0.021535
[23:57:15.016] iteration 11198 : model1 loss : 0.439333 model2 loss : 0.026788
[23:57:15.187] iteration 11199 : model1 loss : 0.437137 model2 loss : 0.025517
[23:57:15.366] iteration 11200 : model1 loss : 0.439089 model2 loss : 0.023411
[23:57:15.537] iteration 11201 : model1 loss : 0.432976 model2 loss : 0.021308
[23:57:15.715] iteration 11202 : model1 loss : 0.436006 model2 loss : 0.020957
[23:57:15.890] iteration 11203 : model1 loss : 0.435534 model2 loss : 0.020461
[23:57:16.070] iteration 11204 : model1 loss : 0.438053 model2 loss : 0.025567
[23:57:16.243] iteration 11205 : model1 loss : 0.439006 model2 loss : 0.022617
[23:57:16.425] iteration 11206 : model1 loss : 0.438153 model2 loss : 0.023786
[23:57:16.599] iteration 11207 : model1 loss : 0.437039 model2 loss : 0.018984
[23:57:16.776] iteration 11208 : model1 loss : 0.436380 model2 loss : 0.020712
[23:57:16.947] iteration 11209 : model1 loss : 0.433922 model2 loss : 0.021082
[23:57:17.125] iteration 11210 : model1 loss : 0.436725 model2 loss : 0.023413
[23:57:17.299] iteration 11211 : model1 loss : 0.436505 model2 loss : 0.021293
[23:57:17.478] iteration 11212 : model1 loss : 0.433773 model2 loss : 0.022786
[23:57:17.649] iteration 11213 : model1 loss : 0.439797 model2 loss : 0.026595
[23:57:17.822] iteration 11214 : model1 loss : 0.439039 model2 loss : 0.023578
[23:57:19.990] iteration 11215 : model1 loss : 0.431697 model2 loss : 0.021170
[23:57:20.168] iteration 11216 : model1 loss : 0.440261 model2 loss : 0.024181
[23:57:20.349] iteration 11217 : model1 loss : 0.434476 model2 loss : 0.019914
[23:57:20.519] iteration 11218 : model1 loss : 0.433746 model2 loss : 0.020746
[23:57:20.695] iteration 11219 : model1 loss : 0.434911 model2 loss : 0.019171
[23:57:20.869] iteration 11220 : model1 loss : 0.433935 model2 loss : 0.021910
[23:57:21.045] iteration 11221 : model1 loss : 0.438143 model2 loss : 0.022204
[23:57:21.217] iteration 11222 : model1 loss : 0.437492 model2 loss : 0.024412
[23:57:21.398] iteration 11223 : model1 loss : 0.440677 model2 loss : 0.023439
[23:57:21.567] iteration 11224 : model1 loss : 0.440123 model2 loss : 0.026517
[23:57:21.744] iteration 11225 : model1 loss : 0.433593 model2 loss : 0.018919
[23:57:21.917] iteration 11226 : model1 loss : 0.433200 model2 loss : 0.020398
[23:57:22.095] iteration 11227 : model1 loss : 0.441085 model2 loss : 0.023641
[23:57:22.269] iteration 11228 : model1 loss : 0.439191 model2 loss : 0.022063
[23:57:22.447] iteration 11229 : model1 loss : 0.438264 model2 loss : 0.022216
[23:57:22.621] iteration 11230 : model1 loss : 0.433178 model2 loss : 0.019963
[23:57:22.800] iteration 11231 : model1 loss : 0.436156 model2 loss : 0.022022
[23:57:22.972] iteration 11232 : model1 loss : 0.440238 model2 loss : 0.024364
[23:57:23.150] iteration 11233 : model1 loss : 0.440006 model2 loss : 0.027231
[23:57:23.325] iteration 11234 : model1 loss : 0.430495 model2 loss : 0.021036
[23:57:23.498] iteration 11235 : model1 loss : 0.439848 model2 loss : 0.025034
[23:57:25.620] iteration 11236 : model1 loss : 0.437275 model2 loss : 0.020260
[23:57:25.797] iteration 11237 : model1 loss : 0.436239 model2 loss : 0.022687
[23:57:25.975] iteration 11238 : model1 loss : 0.434976 model2 loss : 0.021245
[23:57:26.149] iteration 11239 : model1 loss : 0.432920 model2 loss : 0.020838
[23:57:26.330] iteration 11240 : model1 loss : 0.436468 model2 loss : 0.022681
[23:57:26.504] iteration 11241 : model1 loss : 0.433656 model2 loss : 0.020425
[23:57:26.681] iteration 11242 : model1 loss : 0.436909 model2 loss : 0.022870
[23:57:26.857] iteration 11243 : model1 loss : 0.439441 model2 loss : 0.024291
[23:57:27.033] iteration 11244 : model1 loss : 0.439911 model2 loss : 0.025533
[23:57:27.207] iteration 11245 : model1 loss : 0.435822 model2 loss : 0.022271
[23:57:27.385] iteration 11246 : model1 loss : 0.433456 model2 loss : 0.022061
[23:57:27.556] iteration 11247 : model1 loss : 0.440870 model2 loss : 0.021136
[23:57:27.731] iteration 11248 : model1 loss : 0.433474 model2 loss : 0.023005
[23:57:27.903] iteration 11249 : model1 loss : 0.434374 model2 loss : 0.019758
[23:57:28.080] iteration 11250 : model1 loss : 0.436944 model2 loss : 0.022528
[23:57:28.253] iteration 11251 : model1 loss : 0.432815 model2 loss : 0.020642
[23:57:28.430] iteration 11252 : model1 loss : 0.437866 model2 loss : 0.022554
[23:57:28.604] iteration 11253 : model1 loss : 0.441814 model2 loss : 0.029789
[23:57:28.784] iteration 11254 : model1 loss : 0.436421 model2 loss : 0.023251
[23:57:28.953] iteration 11255 : model1 loss : 0.439794 model2 loss : 0.026117
[23:57:29.130] iteration 11256 : model1 loss : 0.437452 model2 loss : 0.025636
[23:57:31.298] iteration 11257 : model1 loss : 0.436097 model2 loss : 0.023969
[23:57:31.471] iteration 11258 : model1 loss : 0.437294 model2 loss : 0.022712
[23:57:31.650] iteration 11259 : model1 loss : 0.434795 model2 loss : 0.021963
[23:57:31.824] iteration 11260 : model1 loss : 0.438006 model2 loss : 0.023763
[23:57:32.002] iteration 11261 : model1 loss : 0.437145 model2 loss : 0.024061
[23:57:32.173] iteration 11262 : model1 loss : 0.435695 model2 loss : 0.021005
[23:57:32.352] iteration 11263 : model1 loss : 0.437754 model2 loss : 0.023671
[23:57:32.525] iteration 11264 : model1 loss : 0.434016 model2 loss : 0.021395
[23:57:32.700] iteration 11265 : model1 loss : 0.436278 model2 loss : 0.022447
[23:57:32.875] iteration 11266 : model1 loss : 0.436890 model2 loss : 0.023089
[23:57:33.052] iteration 11267 : model1 loss : 0.434787 model2 loss : 0.022922
[23:57:33.224] iteration 11268 : model1 loss : 0.434415 model2 loss : 0.020495
[23:57:33.401] iteration 11269 : model1 loss : 0.435922 model2 loss : 0.022519
[23:57:33.572] iteration 11270 : model1 loss : 0.440663 model2 loss : 0.027594
[23:57:33.747] iteration 11271 : model1 loss : 0.441704 model2 loss : 0.028671
[23:57:33.920] iteration 11272 : model1 loss : 0.439506 model2 loss : 0.024166
[23:57:34.096] iteration 11273 : model1 loss : 0.438501 model2 loss : 0.023664
[23:57:34.267] iteration 11274 : model1 loss : 0.437306 model2 loss : 0.021231
[23:57:34.444] iteration 11275 : model1 loss : 0.432949 model2 loss : 0.026080
[23:57:34.614] iteration 11276 : model1 loss : 0.433443 model2 loss : 0.019145
[23:57:34.793] iteration 11277 : model1 loss : 0.438374 model2 loss : 0.020254
[23:57:36.924] iteration 11278 : model1 loss : 0.432945 model2 loss : 0.021312
[23:57:37.098] iteration 11279 : model1 loss : 0.440847 model2 loss : 0.023001
[23:57:37.279] iteration 11280 : model1 loss : 0.436132 model2 loss : 0.022097
[23:57:37.451] iteration 11281 : model1 loss : 0.437455 model2 loss : 0.025143
[23:57:37.631] iteration 11282 : model1 loss : 0.437141 model2 loss : 0.025106
[23:57:37.806] iteration 11283 : model1 loss : 0.439691 model2 loss : 0.023741
[23:57:37.983] iteration 11284 : model1 loss : 0.436842 model2 loss : 0.020653
[23:57:38.156] iteration 11285 : model1 loss : 0.437143 model2 loss : 0.023590
[23:57:38.336] iteration 11286 : model1 loss : 0.439440 model2 loss : 0.024902
[23:57:38.508] iteration 11287 : model1 loss : 0.435564 model2 loss : 0.024366
[23:57:38.682] iteration 11288 : model1 loss : 0.436828 model2 loss : 0.022403
[23:57:38.856] iteration 11289 : model1 loss : 0.432060 model2 loss : 0.019740
[23:57:39.031] iteration 11290 : model1 loss : 0.439386 model2 loss : 0.025537
[23:57:39.203] iteration 11291 : model1 loss : 0.440505 model2 loss : 0.022017
[23:57:39.382] iteration 11292 : model1 loss : 0.435312 model2 loss : 0.022262
[23:57:39.552] iteration 11293 : model1 loss : 0.431228 model2 loss : 0.020565
[23:57:39.727] iteration 11294 : model1 loss : 0.434358 model2 loss : 0.021923
[23:57:39.904] iteration 11295 : model1 loss : 0.438937 model2 loss : 0.021895
[23:57:40.078] iteration 11296 : model1 loss : 0.436019 model2 loss : 0.022150
[23:57:40.247] iteration 11297 : model1 loss : 0.436683 model2 loss : 0.022903
[23:57:40.424] iteration 11298 : model1 loss : 0.437004 model2 loss : 0.021577
[23:57:42.589] iteration 11299 : model1 loss : 0.432364 model2 loss : 0.020269
[23:57:42.765] iteration 11300 : model1 loss : 0.434933 model2 loss : 0.021605
[23:57:42.944] iteration 11301 : model1 loss : 0.434322 model2 loss : 0.024066
[23:57:43.116] iteration 11302 : model1 loss : 0.441831 model2 loss : 0.024598
[23:57:43.294] iteration 11303 : model1 loss : 0.436327 model2 loss : 0.020784
[23:57:43.465] iteration 11304 : model1 loss : 0.439516 model2 loss : 0.023771
[23:57:43.641] iteration 11305 : model1 loss : 0.437773 model2 loss : 0.020684
[23:57:43.814] iteration 11306 : model1 loss : 0.435841 model2 loss : 0.021451
[23:57:43.992] iteration 11307 : model1 loss : 0.433357 model2 loss : 0.022038
[23:57:44.165] iteration 11308 : model1 loss : 0.437538 model2 loss : 0.024133
[23:57:44.343] iteration 11309 : model1 loss : 0.439195 model2 loss : 0.019155
[23:57:44.515] iteration 11310 : model1 loss : 0.433098 model2 loss : 0.022716
[23:57:44.695] iteration 11311 : model1 loss : 0.439100 model2 loss : 0.024082
[23:57:44.867] iteration 11312 : model1 loss : 0.434760 model2 loss : 0.022851
[23:57:45.044] iteration 11313 : model1 loss : 0.434057 model2 loss : 0.022679
[23:57:45.213] iteration 11314 : model1 loss : 0.441062 model2 loss : 0.022257
[23:57:45.390] iteration 11315 : model1 loss : 0.442136 model2 loss : 0.023682
[23:57:45.560] iteration 11316 : model1 loss : 0.434913 model2 loss : 0.021903
[23:57:45.735] iteration 11317 : model1 loss : 0.435571 model2 loss : 0.020850
[23:57:45.906] iteration 11318 : model1 loss : 0.432253 model2 loss : 0.018887
[23:57:46.084] iteration 11319 : model1 loss : 0.435510 model2 loss : 0.021905
[23:57:48.244] iteration 11320 : model1 loss : 0.439981 model2 loss : 0.023690
[23:57:48.418] iteration 11321 : model1 loss : 0.432319 model2 loss : 0.019937
[23:57:48.597] iteration 11322 : model1 loss : 0.436445 model2 loss : 0.019376
[23:57:48.767] iteration 11323 : model1 loss : 0.437315 model2 loss : 0.020558
[23:57:48.943] iteration 11324 : model1 loss : 0.432222 model2 loss : 0.021581
[23:57:49.114] iteration 11325 : model1 loss : 0.439615 model2 loss : 0.022310
[23:57:49.291] iteration 11326 : model1 loss : 0.439422 model2 loss : 0.024880
[23:57:49.465] iteration 11327 : model1 loss : 0.439705 model2 loss : 0.022621
[23:57:49.643] iteration 11328 : model1 loss : 0.439717 model2 loss : 0.022898
[23:57:49.816] iteration 11329 : model1 loss : 0.437619 model2 loss : 0.022278
[23:57:49.996] iteration 11330 : model1 loss : 0.435554 model2 loss : 0.023020
[23:57:50.167] iteration 11331 : model1 loss : 0.437796 model2 loss : 0.020408
[23:57:50.344] iteration 11332 : model1 loss : 0.433599 model2 loss : 0.021529
[23:57:50.518] iteration 11333 : model1 loss : 0.435759 model2 loss : 0.018934
[23:57:50.696] iteration 11334 : model1 loss : 0.435712 model2 loss : 0.023281
[23:57:50.868] iteration 11335 : model1 loss : 0.432032 model2 loss : 0.021366
[23:57:51.043] iteration 11336 : model1 loss : 0.437457 model2 loss : 0.024232
[23:57:51.218] iteration 11337 : model1 loss : 0.440520 model2 loss : 0.024089
[23:57:51.394] iteration 11338 : model1 loss : 0.440098 model2 loss : 0.023157
[23:57:51.563] iteration 11339 : model1 loss : 0.438658 model2 loss : 0.023845
[23:57:51.737] iteration 11340 : model1 loss : 0.433371 model2 loss : 0.019237
[23:57:53.887] iteration 11341 : model1 loss : 0.434820 model2 loss : 0.022957
[23:57:54.063] iteration 11342 : model1 loss : 0.436751 model2 loss : 0.024013
[23:57:54.240] iteration 11343 : model1 loss : 0.437669 model2 loss : 0.019729
[23:57:54.415] iteration 11344 : model1 loss : 0.436373 model2 loss : 0.020155
[23:57:54.594] iteration 11345 : model1 loss : 0.433737 model2 loss : 0.023992
[23:57:54.765] iteration 11346 : model1 loss : 0.434719 model2 loss : 0.021206
[23:57:54.939] iteration 11347 : model1 loss : 0.443660 model2 loss : 0.031492
[23:57:55.111] iteration 11348 : model1 loss : 0.440676 model2 loss : 0.022418
[23:57:55.286] iteration 11349 : model1 loss : 0.435333 model2 loss : 0.024104
[23:57:55.462] iteration 11350 : model1 loss : 0.437077 model2 loss : 0.027654
[23:57:55.640] iteration 11351 : model1 loss : 0.439149 model2 loss : 0.022082
[23:57:55.813] iteration 11352 : model1 loss : 0.438577 model2 loss : 0.022684
[23:57:55.990] iteration 11353 : model1 loss : 0.432694 model2 loss : 0.023350
[23:57:56.163] iteration 11354 : model1 loss : 0.434094 model2 loss : 0.019740
[23:57:56.346] iteration 11355 : model1 loss : 0.443002 model2 loss : 0.028322
[23:57:56.518] iteration 11356 : model1 loss : 0.432526 model2 loss : 0.020038
[23:57:56.691] iteration 11357 : model1 loss : 0.433459 model2 loss : 0.022628
[23:57:56.865] iteration 11358 : model1 loss : 0.439564 model2 loss : 0.022155
[23:57:57.041] iteration 11359 : model1 loss : 0.434528 model2 loss : 0.023859
[23:57:57.211] iteration 11360 : model1 loss : 0.436181 model2 loss : 0.022048
[23:57:57.391] iteration 11361 : model1 loss : 0.439188 model2 loss : 0.024733
[23:57:59.546] iteration 11362 : model1 loss : 0.436655 model2 loss : 0.022037
[23:57:59.720] iteration 11363 : model1 loss : 0.437789 model2 loss : 0.023419
[23:57:59.898] iteration 11364 : model1 loss : 0.438128 model2 loss : 0.022726
[23:58:00.071] iteration 11365 : model1 loss : 0.440261 model2 loss : 0.022724
[23:58:00.246] iteration 11366 : model1 loss : 0.435959 model2 loss : 0.023804
[23:58:00.421] iteration 11367 : model1 loss : 0.437735 model2 loss : 0.022567
[23:58:00.600] iteration 11368 : model1 loss : 0.436990 model2 loss : 0.022834
[23:58:00.771] iteration 11369 : model1 loss : 0.437968 model2 loss : 0.022003
[23:58:00.948] iteration 11370 : model1 loss : 0.441220 model2 loss : 0.026493
[23:58:01.120] iteration 11371 : model1 loss : 0.434658 model2 loss : 0.022253
[23:58:01.294] iteration 11372 : model1 loss : 0.436683 model2 loss : 0.021560
[23:58:01.470] iteration 11373 : model1 loss : 0.433392 model2 loss : 0.020947
[23:58:01.646] iteration 11374 : model1 loss : 0.433553 model2 loss : 0.021717
[23:58:01.818] iteration 11375 : model1 loss : 0.435367 model2 loss : 0.019016
[23:58:01.998] iteration 11376 : model1 loss : 0.432629 model2 loss : 0.019679
[23:58:02.168] iteration 11377 : model1 loss : 0.436944 model2 loss : 0.024197
[23:58:02.345] iteration 11378 : model1 loss : 0.436044 model2 loss : 0.020436
[23:58:02.523] iteration 11379 : model1 loss : 0.433130 model2 loss : 0.020619
[23:58:02.697] iteration 11380 : model1 loss : 0.438692 model2 loss : 0.022262
[23:58:02.870] iteration 11381 : model1 loss : 0.442233 model2 loss : 0.023999
[23:58:03.045] iteration 11382 : model1 loss : 0.440431 model2 loss : 0.021884
[23:58:05.195] iteration 11383 : model1 loss : 0.435875 model2 loss : 0.022046
[23:58:05.367] iteration 11384 : model1 loss : 0.439142 model2 loss : 0.021248
[23:58:05.547] iteration 11385 : model1 loss : 0.436812 model2 loss : 0.020306
[23:58:05.716] iteration 11386 : model1 loss : 0.436982 model2 loss : 0.024424
[23:58:05.894] iteration 11387 : model1 loss : 0.434055 model2 loss : 0.020040
[23:58:06.067] iteration 11388 : model1 loss : 0.435402 model2 loss : 0.022812
[23:58:06.242] iteration 11389 : model1 loss : 0.434003 model2 loss : 0.019635
[23:58:06.418] iteration 11390 : model1 loss : 0.434577 model2 loss : 0.022076
[23:58:06.599] iteration 11391 : model1 loss : 0.441707 model2 loss : 0.024065
[23:58:06.770] iteration 11392 : model1 loss : 0.437211 model2 loss : 0.021405
[23:58:06.949] iteration 11393 : model1 loss : 0.436833 model2 loss : 0.021340
[23:58:07.124] iteration 11394 : model1 loss : 0.437779 model2 loss : 0.023369
[23:58:07.298] iteration 11395 : model1 loss : 0.438224 model2 loss : 0.023950
[23:58:07.476] iteration 11396 : model1 loss : 0.439408 model2 loss : 0.021565
[23:58:07.653] iteration 11397 : model1 loss : 0.439189 model2 loss : 0.023707
[23:58:07.824] iteration 11398 : model1 loss : 0.433243 model2 loss : 0.020476
[23:58:08.001] iteration 11399 : model1 loss : 0.436762 model2 loss : 0.022442
[23:58:08.175] iteration 11400 : model1 loss : 0.438664 model2 loss : 0.022400
[23:58:08.354] iteration 11401 : model1 loss : 0.433506 model2 loss : 0.021789
[23:58:08.525] iteration 11402 : model1 loss : 0.435313 model2 loss : 0.020831
[23:58:08.700] iteration 11403 : model1 loss : 0.437377 model2 loss : 0.023935
[23:58:10.862] iteration 11404 : model1 loss : 0.435684 model2 loss : 0.022133
[23:58:11.042] iteration 11405 : model1 loss : 0.437479 model2 loss : 0.027265
[23:58:11.218] iteration 11406 : model1 loss : 0.437575 model2 loss : 0.021216
[23:58:11.393] iteration 11407 : model1 loss : 0.432442 model2 loss : 0.021342
[23:58:11.568] iteration 11408 : model1 loss : 0.439572 model2 loss : 0.022821
[23:58:11.741] iteration 11409 : model1 loss : 0.441443 model2 loss : 0.023759
[23:58:11.919] iteration 11410 : model1 loss : 0.433476 model2 loss : 0.021607
[23:58:12.094] iteration 11411 : model1 loss : 0.439135 model2 loss : 0.024126
[23:58:12.269] iteration 11412 : model1 loss : 0.437988 model2 loss : 0.023314
[23:58:12.445] iteration 11413 : model1 loss : 0.436828 model2 loss : 0.019536
[23:58:12.624] iteration 11414 : model1 loss : 0.432870 model2 loss : 0.021618
[23:58:12.794] iteration 11415 : model1 loss : 0.433712 model2 loss : 0.020335
[23:58:12.970] iteration 11416 : model1 loss : 0.435484 model2 loss : 0.019706
[23:58:13.144] iteration 11417 : model1 loss : 0.439115 model2 loss : 0.023573
[23:58:13.324] iteration 11418 : model1 loss : 0.435825 model2 loss : 0.020438
[23:58:13.499] iteration 11419 : model1 loss : 0.439805 model2 loss : 0.021220
[23:58:13.676] iteration 11420 : model1 loss : 0.434995 model2 loss : 0.021325
[23:58:13.847] iteration 11421 : model1 loss : 0.440268 model2 loss : 0.022484
[23:58:14.023] iteration 11422 : model1 loss : 0.436931 model2 loss : 0.024190
[23:58:14.192] iteration 11423 : model1 loss : 0.435667 model2 loss : 0.021028
[23:58:14.368] iteration 11424 : model1 loss : 0.437507 model2 loss : 0.022143
[23:58:16.537] iteration 11425 : model1 loss : 0.436194 model2 loss : 0.023595
[23:58:16.709] iteration 11426 : model1 loss : 0.438538 model2 loss : 0.021621
[23:58:16.887] iteration 11427 : model1 loss : 0.435015 model2 loss : 0.019675
[23:58:17.059] iteration 11428 : model1 loss : 0.440129 model2 loss : 0.021441
[23:58:17.235] iteration 11429 : model1 loss : 0.436151 model2 loss : 0.020970
[23:58:17.413] iteration 11430 : model1 loss : 0.440651 model2 loss : 0.024098
[23:58:17.593] iteration 11431 : model1 loss : 0.437421 model2 loss : 0.024088
[23:58:17.765] iteration 11432 : model1 loss : 0.436913 model2 loss : 0.022096
[23:58:17.942] iteration 11433 : model1 loss : 0.433882 model2 loss : 0.023096
[23:58:18.115] iteration 11434 : model1 loss : 0.439712 model2 loss : 0.022824
[23:58:18.291] iteration 11435 : model1 loss : 0.436022 model2 loss : 0.019759
[23:58:18.466] iteration 11436 : model1 loss : 0.439813 model2 loss : 0.020919
[23:58:18.643] iteration 11437 : model1 loss : 0.434661 model2 loss : 0.021910
[23:58:18.814] iteration 11438 : model1 loss : 0.439509 model2 loss : 0.024990
[23:58:18.994] iteration 11439 : model1 loss : 0.437762 model2 loss : 0.021619
[23:58:19.166] iteration 11440 : model1 loss : 0.432804 model2 loss : 0.022214
[23:58:19.343] iteration 11441 : model1 loss : 0.439772 model2 loss : 0.022687
[23:58:19.517] iteration 11442 : model1 loss : 0.431366 model2 loss : 0.021084
[23:58:19.694] iteration 11443 : model1 loss : 0.437616 model2 loss : 0.023461
[23:58:19.868] iteration 11444 : model1 loss : 0.434180 model2 loss : 0.024238
[23:58:20.042] iteration 11445 : model1 loss : 0.434360 model2 loss : 0.020412
[23:58:22.188] iteration 11446 : model1 loss : 0.434234 model2 loss : 0.021722
[23:58:22.359] iteration 11447 : model1 loss : 0.436217 model2 loss : 0.025576
[23:58:22.542] iteration 11448 : model1 loss : 0.435278 model2 loss : 0.020129
[23:58:22.712] iteration 11449 : model1 loss : 0.436576 model2 loss : 0.024086
[23:58:22.890] iteration 11450 : model1 loss : 0.439050 model2 loss : 0.021527
[23:58:23.064] iteration 11451 : model1 loss : 0.433408 model2 loss : 0.020067
[23:58:23.239] iteration 11452 : model1 loss : 0.435587 model2 loss : 0.022427
[23:58:23.415] iteration 11453 : model1 loss : 0.438996 model2 loss : 0.022094
[23:58:23.594] iteration 11454 : model1 loss : 0.437555 model2 loss : 0.022388
[23:58:23.763] iteration 11455 : model1 loss : 0.432622 model2 loss : 0.020241
[23:58:23.941] iteration 11456 : model1 loss : 0.436716 model2 loss : 0.023724
[23:58:24.114] iteration 11457 : model1 loss : 0.434464 model2 loss : 0.019699
[23:58:24.291] iteration 11458 : model1 loss : 0.438071 model2 loss : 0.021563
[23:58:24.463] iteration 11459 : model1 loss : 0.435616 model2 loss : 0.021997
[23:58:24.642] iteration 11460 : model1 loss : 0.443011 model2 loss : 0.025458
[23:58:24.813] iteration 11461 : model1 loss : 0.438890 model2 loss : 0.021760
[23:58:24.990] iteration 11462 : model1 loss : 0.440994 model2 loss : 0.025919
[23:58:25.163] iteration 11463 : model1 loss : 0.438007 model2 loss : 0.022198
[23:58:25.343] iteration 11464 : model1 loss : 0.433380 model2 loss : 0.020178
[23:58:25.515] iteration 11465 : model1 loss : 0.437249 model2 loss : 0.020578
[23:58:25.689] iteration 11466 : model1 loss : 0.436272 model2 loss : 0.019669
[23:58:27.844] iteration 11467 : model1 loss : 0.441562 model2 loss : 0.024440
[23:58:28.019] iteration 11468 : model1 loss : 0.440264 model2 loss : 0.023641
[23:58:28.197] iteration 11469 : model1 loss : 0.442135 model2 loss : 0.025166
[23:58:28.373] iteration 11470 : model1 loss : 0.433546 model2 loss : 0.021060
[23:58:28.551] iteration 11471 : model1 loss : 0.432317 model2 loss : 0.021900
[23:58:28.721] iteration 11472 : model1 loss : 0.438934 model2 loss : 0.021061
[23:58:28.899] iteration 11473 : model1 loss : 0.436120 model2 loss : 0.022825
[23:58:29.070] iteration 11474 : model1 loss : 0.433092 model2 loss : 0.018679
[23:58:29.252] iteration 11475 : model1 loss : 0.433293 model2 loss : 0.020237
[23:58:29.425] iteration 11476 : model1 loss : 0.435001 model2 loss : 0.020469
[23:58:29.601] iteration 11477 : model1 loss : 0.434333 model2 loss : 0.020841
[23:58:29.771] iteration 11478 : model1 loss : 0.437717 model2 loss : 0.024928
[23:58:29.949] iteration 11479 : model1 loss : 0.435757 model2 loss : 0.022381
[23:58:30.123] iteration 11480 : model1 loss : 0.438545 model2 loss : 0.021114
[23:58:30.302] iteration 11481 : model1 loss : 0.439799 model2 loss : 0.022634
[23:58:30.478] iteration 11482 : model1 loss : 0.437638 model2 loss : 0.020108
[23:58:30.656] iteration 11483 : model1 loss : 0.429680 model2 loss : 0.019631
[23:58:30.827] iteration 11484 : model1 loss : 0.437748 model2 loss : 0.025364
[23:58:31.002] iteration 11485 : model1 loss : 0.437000 model2 loss : 0.021031
[23:58:31.176] iteration 11486 : model1 loss : 0.437046 model2 loss : 0.023071
[23:58:31.351] iteration 11487 : model1 loss : 0.436830 model2 loss : 0.021002
[23:58:33.541] iteration 11488 : model1 loss : 0.436666 model2 loss : 0.023495
[23:58:33.712] iteration 11489 : model1 loss : 0.438816 model2 loss : 0.021862
[23:58:33.888] iteration 11490 : model1 loss : 0.437367 model2 loss : 0.022000
[23:58:34.061] iteration 11491 : model1 loss : 0.432237 model2 loss : 0.021703
[23:58:34.235] iteration 11492 : model1 loss : 0.434162 model2 loss : 0.020451
[23:58:34.408] iteration 11493 : model1 loss : 0.433947 model2 loss : 0.021832
[23:58:34.586] iteration 11494 : model1 loss : 0.437437 model2 loss : 0.023771
[23:58:34.756] iteration 11495 : model1 loss : 0.436547 model2 loss : 0.022310
[23:58:34.934] iteration 11496 : model1 loss : 0.439340 model2 loss : 0.021124
[23:58:35.107] iteration 11497 : model1 loss : 0.437439 model2 loss : 0.024939
[23:58:35.281] iteration 11498 : model1 loss : 0.437539 model2 loss : 0.026395
[23:58:35.453] iteration 11499 : model1 loss : 0.436762 model2 loss : 0.025110
[23:58:35.632] iteration 11500 : model1 loss : 0.437119 model2 loss : 0.024892
[23:58:35.804] iteration 11501 : model1 loss : 0.435906 model2 loss : 0.025427
[23:58:35.983] iteration 11502 : model1 loss : 0.436347 model2 loss : 0.021993
[23:58:36.155] iteration 11503 : model1 loss : 0.437713 model2 loss : 0.025606
[23:58:36.335] iteration 11504 : model1 loss : 0.436426 model2 loss : 0.022110
[23:58:36.508] iteration 11505 : model1 loss : 0.437018 model2 loss : 0.026657
[23:58:36.684] iteration 11506 : model1 loss : 0.436412 model2 loss : 0.019292
[23:58:36.854] iteration 11507 : model1 loss : 0.437710 model2 loss : 0.020206
[23:58:37.031] iteration 11508 : model1 loss : 0.437900 model2 loss : 0.026859
[23:58:39.170] iteration 11509 : model1 loss : 0.437540 model2 loss : 0.025811
[23:58:39.353] iteration 11510 : model1 loss : 0.431862 model2 loss : 0.020481
[23:58:39.532] iteration 11511 : model1 loss : 0.432799 model2 loss : 0.023694
[23:58:39.704] iteration 11512 : model1 loss : 0.437241 model2 loss : 0.022282
[23:58:39.880] iteration 11513 : model1 loss : 0.437863 model2 loss : 0.024774
[23:58:40.055] iteration 11514 : model1 loss : 0.438212 model2 loss : 0.022080
[23:58:40.231] iteration 11515 : model1 loss : 0.437949 model2 loss : 0.021313
[23:58:40.402] iteration 11516 : model1 loss : 0.435061 model2 loss : 0.023669
[23:58:40.578] iteration 11517 : model1 loss : 0.437294 model2 loss : 0.024737
[23:58:40.749] iteration 11518 : model1 loss : 0.433788 model2 loss : 0.021798
[23:58:40.928] iteration 11519 : model1 loss : 0.437434 model2 loss : 0.022475
[23:58:41.101] iteration 11520 : model1 loss : 0.436113 model2 loss : 0.026423
[23:58:41.278] iteration 11521 : model1 loss : 0.439765 model2 loss : 0.024726
[23:58:41.451] iteration 11522 : model1 loss : 0.438321 model2 loss : 0.024956
[23:58:41.629] iteration 11523 : model1 loss : 0.436096 model2 loss : 0.024700
[23:58:41.799] iteration 11524 : model1 loss : 0.440780 model2 loss : 0.021763
[23:58:41.975] iteration 11525 : model1 loss : 0.434726 model2 loss : 0.023478
[23:58:42.150] iteration 11526 : model1 loss : 0.433886 model2 loss : 0.021195
[23:58:42.331] iteration 11527 : model1 loss : 0.441587 model2 loss : 0.027104
[23:58:42.506] iteration 11528 : model1 loss : 0.437146 model2 loss : 0.020422
[23:58:42.680] iteration 11529 : model1 loss : 0.438994 model2 loss : 0.024737
[23:58:44.814] iteration 11530 : model1 loss : 0.436360 model2 loss : 0.021641
[23:58:44.989] iteration 11531 : model1 loss : 0.441147 model2 loss : 0.023425
[23:58:45.167] iteration 11532 : model1 loss : 0.439208 model2 loss : 0.024237
[23:58:45.341] iteration 11533 : model1 loss : 0.431392 model2 loss : 0.020682
[23:58:45.518] iteration 11534 : model1 loss : 0.434697 model2 loss : 0.019310
[23:58:45.688] iteration 11535 : model1 loss : 0.434149 model2 loss : 0.021429
[23:58:45.862] iteration 11536 : model1 loss : 0.438552 model2 loss : 0.026288
[23:58:46.035] iteration 11537 : model1 loss : 0.437677 model2 loss : 0.019991
[23:58:46.210] iteration 11538 : model1 loss : 0.435847 model2 loss : 0.025294
[23:58:46.383] iteration 11539 : model1 loss : 0.439501 model2 loss : 0.023662
[23:58:46.561] iteration 11540 : model1 loss : 0.438589 model2 loss : 0.023005
[23:58:46.732] iteration 11541 : model1 loss : 0.438186 model2 loss : 0.024031
[23:58:46.907] iteration 11542 : model1 loss : 0.439903 model2 loss : 0.024023
[23:58:47.082] iteration 11543 : model1 loss : 0.437539 model2 loss : 0.023482
[23:58:47.258] iteration 11544 : model1 loss : 0.435612 model2 loss : 0.019467
[23:58:47.435] iteration 11545 : model1 loss : 0.439866 model2 loss : 0.021801
[23:58:47.615] iteration 11546 : model1 loss : 0.440223 model2 loss : 0.024205
[23:58:47.785] iteration 11547 : model1 loss : 0.434519 model2 loss : 0.021078
[23:58:47.963] iteration 11548 : model1 loss : 0.434922 model2 loss : 0.022174
[23:58:48.133] iteration 11549 : model1 loss : 0.437546 model2 loss : 0.023670
[23:58:48.308] iteration 11550 : model1 loss : 0.435082 model2 loss : 0.020908
[23:58:50.451] iteration 11551 : model1 loss : 0.438099 model2 loss : 0.020854
[23:58:50.626] iteration 11552 : model1 loss : 0.434981 model2 loss : 0.022435
[23:58:50.801] iteration 11553 : model1 loss : 0.437654 model2 loss : 0.023332
[23:58:50.975] iteration 11554 : model1 loss : 0.434579 model2 loss : 0.022592
[23:58:51.155] iteration 11555 : model1 loss : 0.438971 model2 loss : 0.022491
[23:58:51.330] iteration 11556 : model1 loss : 0.435917 model2 loss : 0.025102
[23:58:51.508] iteration 11557 : model1 loss : 0.437697 model2 loss : 0.020917
[23:58:51.681] iteration 11558 : model1 loss : 0.439836 model2 loss : 0.023058
[23:58:51.858] iteration 11559 : model1 loss : 0.439337 model2 loss : 0.021630
[23:58:52.031] iteration 11560 : model1 loss : 0.436020 model2 loss : 0.022356
[23:58:52.207] iteration 11561 : model1 loss : 0.434004 model2 loss : 0.022163
[23:58:52.381] iteration 11562 : model1 loss : 0.436120 model2 loss : 0.022039
[23:58:52.558] iteration 11563 : model1 loss : 0.440253 model2 loss : 0.023964
[23:58:52.728] iteration 11564 : model1 loss : 0.441632 model2 loss : 0.022208
[23:58:52.903] iteration 11565 : model1 loss : 0.441155 model2 loss : 0.022090
[23:58:53.078] iteration 11566 : model1 loss : 0.433959 model2 loss : 0.022422
[23:58:53.255] iteration 11567 : model1 loss : 0.437514 model2 loss : 0.021265
[23:58:53.426] iteration 11568 : model1 loss : 0.437177 model2 loss : 0.023786
[23:58:53.605] iteration 11569 : model1 loss : 0.435918 model2 loss : 0.021622
[23:58:53.775] iteration 11570 : model1 loss : 0.435966 model2 loss : 0.018588
[23:58:53.950] iteration 11571 : model1 loss : 0.439528 model2 loss : 0.021255
[23:58:56.074] iteration 11572 : model1 loss : 0.438364 model2 loss : 0.023933
[23:58:56.247] iteration 11573 : model1 loss : 0.437843 model2 loss : 0.022028
[23:58:56.425] iteration 11574 : model1 loss : 0.436433 model2 loss : 0.021803
[23:58:56.600] iteration 11575 : model1 loss : 0.435280 model2 loss : 0.022157
[23:58:56.776] iteration 11576 : model1 loss : 0.438204 model2 loss : 0.021961
[23:58:56.947] iteration 11577 : model1 loss : 0.437394 model2 loss : 0.021253
[23:58:57.126] iteration 11578 : model1 loss : 0.436467 model2 loss : 0.023744
[23:58:57.299] iteration 11579 : model1 loss : 0.433651 model2 loss : 0.020666
[23:58:57.480] iteration 11580 : model1 loss : 0.440059 model2 loss : 0.022379
[23:58:57.652] iteration 11581 : model1 loss : 0.440164 model2 loss : 0.020022
[23:58:57.831] iteration 11582 : model1 loss : 0.433746 model2 loss : 0.019314
[23:58:58.004] iteration 11583 : model1 loss : 0.436413 model2 loss : 0.020793
[23:58:58.180] iteration 11584 : model1 loss : 0.435332 model2 loss : 0.020109
[23:58:58.353] iteration 11585 : model1 loss : 0.438737 model2 loss : 0.023278
[23:58:58.531] iteration 11586 : model1 loss : 0.436919 model2 loss : 0.021909
[23:58:58.704] iteration 11587 : model1 loss : 0.439858 model2 loss : 0.022225
[23:58:58.879] iteration 11588 : model1 loss : 0.437710 model2 loss : 0.023077
[23:58:59.053] iteration 11589 : model1 loss : 0.434088 model2 loss : 0.018609
[23:58:59.230] iteration 11590 : model1 loss : 0.443758 model2 loss : 0.028859
[23:58:59.400] iteration 11591 : model1 loss : 0.435489 model2 loss : 0.022534
[23:58:59.572] iteration 11592 : model1 loss : 0.437245 model2 loss : 0.020903
[23:59:01.729] iteration 11593 : model1 loss : 0.431924 model2 loss : 0.021168
[23:59:01.906] iteration 11594 : model1 loss : 0.438740 model2 loss : 0.020921
[23:59:02.084] iteration 11595 : model1 loss : 0.436988 model2 loss : 0.021670
[23:59:02.257] iteration 11596 : model1 loss : 0.437620 model2 loss : 0.021129
[23:59:02.434] iteration 11597 : model1 loss : 0.435873 model2 loss : 0.023686
[23:59:02.614] iteration 11598 : model1 loss : 0.438909 model2 loss : 0.025937
[23:59:02.791] iteration 11599 : model1 loss : 0.440980 model2 loss : 0.026848
[23:59:02.962] iteration 11600 : model1 loss : 0.435056 model2 loss : 0.021362
[23:59:03.139] iteration 11601 : model1 loss : 0.438268 model2 loss : 0.022378
[23:59:03.315] iteration 11602 : model1 loss : 0.441709 model2 loss : 0.024234
[23:59:03.495] iteration 11603 : model1 loss : 0.437195 model2 loss : 0.022398
[23:59:03.667] iteration 11604 : model1 loss : 0.435598 model2 loss : 0.021951
[23:59:03.842] iteration 11605 : model1 loss : 0.439367 model2 loss : 0.022335
[23:59:04.018] iteration 11606 : model1 loss : 0.432120 model2 loss : 0.018224
[23:59:04.198] iteration 11607 : model1 loss : 0.436278 model2 loss : 0.021600
[23:59:04.369] iteration 11608 : model1 loss : 0.440148 model2 loss : 0.019888
[23:59:04.548] iteration 11609 : model1 loss : 0.438452 model2 loss : 0.021811
[23:59:04.718] iteration 11610 : model1 loss : 0.434529 model2 loss : 0.022181
[23:59:04.896] iteration 11611 : model1 loss : 0.437348 model2 loss : 0.023110
[23:59:05.069] iteration 11612 : model1 loss : 0.433226 model2 loss : 0.017702
[23:59:05.241] iteration 11613 : model1 loss : 0.435902 model2 loss : 0.022048
[23:59:07.360] iteration 11614 : model1 loss : 0.440715 model2 loss : 0.022605
[23:59:07.537] iteration 11615 : model1 loss : 0.439467 model2 loss : 0.021251
[23:59:07.715] iteration 11616 : model1 loss : 0.439177 model2 loss : 0.020474
[23:59:07.886] iteration 11617 : model1 loss : 0.438161 model2 loss : 0.020442
[23:59:08.060] iteration 11618 : model1 loss : 0.438052 model2 loss : 0.023497
[23:59:08.231] iteration 11619 : model1 loss : 0.438938 model2 loss : 0.023881
[23:59:08.406] iteration 11620 : model1 loss : 0.437926 model2 loss : 0.021754
[23:59:08.582] iteration 11621 : model1 loss : 0.437596 model2 loss : 0.023811
[23:59:08.762] iteration 11622 : model1 loss : 0.438748 model2 loss : 0.020807
[23:59:08.932] iteration 11623 : model1 loss : 0.434120 model2 loss : 0.022883
[23:59:09.113] iteration 11624 : model1 loss : 0.436614 model2 loss : 0.023927
[23:59:09.285] iteration 11625 : model1 loss : 0.437052 model2 loss : 0.021085
[23:59:09.463] iteration 11626 : model1 loss : 0.437529 model2 loss : 0.020561
[23:59:09.637] iteration 11627 : model1 loss : 0.435074 model2 loss : 0.022112
[23:59:09.814] iteration 11628 : model1 loss : 0.435240 model2 loss : 0.020640
[23:59:09.988] iteration 11629 : model1 loss : 0.436182 model2 loss : 0.019663
[23:59:10.169] iteration 11630 : model1 loss : 0.434233 model2 loss : 0.023071
[23:59:10.342] iteration 11631 : model1 loss : 0.435487 model2 loss : 0.022421
[23:59:10.519] iteration 11632 : model1 loss : 0.432346 model2 loss : 0.020204
[23:59:10.688] iteration 11633 : model1 loss : 0.434838 model2 loss : 0.020912
[23:59:10.863] iteration 11634 : model1 loss : 0.434208 model2 loss : 0.021749
[23:59:13.013] iteration 11635 : model1 loss : 0.436359 model2 loss : 0.021673
[23:59:13.187] iteration 11636 : model1 loss : 0.438834 model2 loss : 0.024425
[23:59:13.367] iteration 11637 : model1 loss : 0.434846 model2 loss : 0.022263
[23:59:13.541] iteration 11638 : model1 loss : 0.438891 model2 loss : 0.022959
[23:59:13.718] iteration 11639 : model1 loss : 0.433445 model2 loss : 0.020194
[23:59:13.889] iteration 11640 : model1 loss : 0.437116 model2 loss : 0.021995
[23:59:14.067] iteration 11641 : model1 loss : 0.436332 model2 loss : 0.020847
[23:59:14.237] iteration 11642 : model1 loss : 0.431798 model2 loss : 0.020188
[23:59:14.412] iteration 11643 : model1 loss : 0.441748 model2 loss : 0.023454
[23:59:14.584] iteration 11644 : model1 loss : 0.434523 model2 loss : 0.021542
[23:59:14.762] iteration 11645 : model1 loss : 0.437842 model2 loss : 0.023785
[23:59:14.932] iteration 11646 : model1 loss : 0.436514 model2 loss : 0.021175
[23:59:15.109] iteration 11647 : model1 loss : 0.436529 model2 loss : 0.019624
[23:59:15.280] iteration 11648 : model1 loss : 0.438508 model2 loss : 0.024787
[23:59:15.456] iteration 11649 : model1 loss : 0.436632 model2 loss : 0.020843
[23:59:15.632] iteration 11650 : model1 loss : 0.437359 model2 loss : 0.023611
[23:59:15.809] iteration 11651 : model1 loss : 0.436785 model2 loss : 0.024557
[23:59:15.982] iteration 11652 : model1 loss : 0.429722 model2 loss : 0.020142
[23:59:16.160] iteration 11653 : model1 loss : 0.441468 model2 loss : 0.024709
[23:59:16.339] iteration 11654 : model1 loss : 0.439895 model2 loss : 0.020719
[23:59:16.514] iteration 11655 : model1 loss : 0.431677 model2 loss : 0.019250
[23:59:18.651] iteration 11656 : model1 loss : 0.436960 model2 loss : 0.022364
[23:59:18.828] iteration 11657 : model1 loss : 0.434850 model2 loss : 0.022218
[23:59:19.010] iteration 11658 : model1 loss : 0.436539 model2 loss : 0.021123
[23:59:19.181] iteration 11659 : model1 loss : 0.437485 model2 loss : 0.023090
[23:59:19.359] iteration 11660 : model1 loss : 0.438895 model2 loss : 0.023063
[23:59:19.534] iteration 11661 : model1 loss : 0.440808 model2 loss : 0.024890
[23:59:19.719] iteration 11662 : model1 loss : 0.439001 model2 loss : 0.023551
[23:59:19.889] iteration 11663 : model1 loss : 0.437022 model2 loss : 0.024256
[23:59:20.067] iteration 11664 : model1 loss : 0.435334 model2 loss : 0.023731
[23:59:20.236] iteration 11665 : model1 loss : 0.435836 model2 loss : 0.022851
[23:59:20.410] iteration 11666 : model1 loss : 0.438157 model2 loss : 0.020215
[23:59:20.584] iteration 11667 : model1 loss : 0.434275 model2 loss : 0.020672
[23:59:20.761] iteration 11668 : model1 loss : 0.435983 model2 loss : 0.021110
[23:59:20.932] iteration 11669 : model1 loss : 0.437510 model2 loss : 0.022618
[23:59:21.109] iteration 11670 : model1 loss : 0.434004 model2 loss : 0.020085
[23:59:21.280] iteration 11671 : model1 loss : 0.439887 model2 loss : 0.021171
[23:59:21.457] iteration 11672 : model1 loss : 0.434907 model2 loss : 0.020241
[23:59:21.634] iteration 11673 : model1 loss : 0.435900 model2 loss : 0.022165
[23:59:21.808] iteration 11674 : model1 loss : 0.433812 model2 loss : 0.019975
[23:59:21.979] iteration 11675 : model1 loss : 0.436712 model2 loss : 0.020655
[23:59:22.155] iteration 11676 : model1 loss : 0.434746 model2 loss : 0.020762
[23:59:24.290] iteration 11677 : model1 loss : 0.439681 model2 loss : 0.023610
[23:59:24.462] iteration 11678 : model1 loss : 0.436309 model2 loss : 0.017838
[23:59:24.643] iteration 11679 : model1 loss : 0.440052 model2 loss : 0.023381
[23:59:24.813] iteration 11680 : model1 loss : 0.434942 model2 loss : 0.023629
[23:59:24.991] iteration 11681 : model1 loss : 0.437401 model2 loss : 0.022523
[23:59:25.166] iteration 11682 : model1 loss : 0.437732 model2 loss : 0.022147
[23:59:25.343] iteration 11683 : model1 loss : 0.432397 model2 loss : 0.020862
[23:59:25.514] iteration 11684 : model1 loss : 0.437688 model2 loss : 0.021912
[23:59:25.690] iteration 11685 : model1 loss : 0.435466 model2 loss : 0.021113
[23:59:25.862] iteration 11686 : model1 loss : 0.433908 model2 loss : 0.019734
[23:59:26.038] iteration 11687 : model1 loss : 0.435493 model2 loss : 0.020275
[23:59:26.210] iteration 11688 : model1 loss : 0.438652 model2 loss : 0.024020
[23:59:26.388] iteration 11689 : model1 loss : 0.440062 model2 loss : 0.024240
[23:59:26.562] iteration 11690 : model1 loss : 0.436546 model2 loss : 0.022594
[23:59:26.739] iteration 11691 : model1 loss : 0.437516 model2 loss : 0.023484
[23:59:26.912] iteration 11692 : model1 loss : 0.434549 model2 loss : 0.022203
[23:59:27.090] iteration 11693 : model1 loss : 0.436303 model2 loss : 0.020110
[23:59:27.262] iteration 11694 : model1 loss : 0.439458 model2 loss : 0.022228
[23:59:27.438] iteration 11695 : model1 loss : 0.432825 model2 loss : 0.021216
[23:59:27.612] iteration 11696 : model1 loss : 0.434489 model2 loss : 0.022258
[23:59:27.787] iteration 11697 : model1 loss : 0.437480 model2 loss : 0.022473
[23:59:29.890] iteration 11698 : model1 loss : 0.438214 model2 loss : 0.023832
[23:59:30.067] iteration 11699 : model1 loss : 0.435070 model2 loss : 0.020151
[23:59:30.243] iteration 11700 : model1 loss : 0.430939 model2 loss : 0.020620
[23:59:30.415] iteration 11701 : model1 loss : 0.441346 model2 loss : 0.025324
[23:59:30.594] iteration 11702 : model1 loss : 0.437691 model2 loss : 0.026253
[23:59:30.769] iteration 11703 : model1 loss : 0.435515 model2 loss : 0.025579
[23:59:30.946] iteration 11704 : model1 loss : 0.436140 model2 loss : 0.022317
[23:59:31.123] iteration 11705 : model1 loss : 0.436051 model2 loss : 0.021327
[23:59:31.303] iteration 11706 : model1 loss : 0.433565 model2 loss : 0.021675
[23:59:31.474] iteration 11707 : model1 loss : 0.439109 model2 loss : 0.021488
[23:59:31.651] iteration 11708 : model1 loss : 0.435821 model2 loss : 0.021272
[23:59:31.823] iteration 11709 : model1 loss : 0.440283 model2 loss : 0.021672
[23:59:31.999] iteration 11710 : model1 loss : 0.437551 model2 loss : 0.018543
[23:59:32.171] iteration 11711 : model1 loss : 0.437317 model2 loss : 0.022737
[23:59:32.352] iteration 11712 : model1 loss : 0.435217 model2 loss : 0.020771
[23:59:32.525] iteration 11713 : model1 loss : 0.434920 model2 loss : 0.017819
[23:59:32.701] iteration 11714 : model1 loss : 0.437244 model2 loss : 0.021823
[23:59:32.873] iteration 11715 : model1 loss : 0.436216 model2 loss : 0.022023
[23:59:33.051] iteration 11716 : model1 loss : 0.439092 model2 loss : 0.023161
[23:59:33.221] iteration 11717 : model1 loss : 0.434772 model2 loss : 0.023547
[23:59:33.397] iteration 11718 : model1 loss : 0.437344 model2 loss : 0.022239
[23:59:35.556] iteration 11719 : model1 loss : 0.436672 model2 loss : 0.018794
[23:59:35.729] iteration 11720 : model1 loss : 0.438187 model2 loss : 0.022648
[23:59:35.910] iteration 11721 : model1 loss : 0.435999 model2 loss : 0.020278
[23:59:36.084] iteration 11722 : model1 loss : 0.438152 model2 loss : 0.020717
[23:59:36.275] iteration 11723 : model1 loss : 0.434906 model2 loss : 0.022454
[23:59:36.445] iteration 11724 : model1 loss : 0.433976 model2 loss : 0.021234
[23:59:36.624] iteration 11725 : model1 loss : 0.438309 model2 loss : 0.025507
[23:59:36.794] iteration 11726 : model1 loss : 0.443224 model2 loss : 0.022251
[23:59:36.969] iteration 11727 : model1 loss : 0.435459 model2 loss : 0.021149
[23:59:37.142] iteration 11728 : model1 loss : 0.435759 model2 loss : 0.021602
[23:59:37.325] iteration 11729 : model1 loss : 0.436470 model2 loss : 0.023439
[23:59:37.501] iteration 11730 : model1 loss : 0.435188 model2 loss : 0.023127
[23:59:37.678] iteration 11731 : model1 loss : 0.435793 model2 loss : 0.018924
[23:59:37.847] iteration 11732 : model1 loss : 0.437961 model2 loss : 0.025387
[23:59:38.026] iteration 11733 : model1 loss : 0.438564 model2 loss : 0.023746
[23:59:38.197] iteration 11734 : model1 loss : 0.433395 model2 loss : 0.021910
[23:59:38.372] iteration 11735 : model1 loss : 0.437115 model2 loss : 0.024049
[23:59:38.547] iteration 11736 : model1 loss : 0.439831 model2 loss : 0.024765
[23:59:38.725] iteration 11737 : model1 loss : 0.434176 model2 loss : 0.021255
[23:59:38.894] iteration 11738 : model1 loss : 0.435974 model2 loss : 0.021477
[23:59:39.071] iteration 11739 : model1 loss : 0.432859 model2 loss : 0.020638
[23:59:41.198] iteration 11740 : model1 loss : 0.442520 model2 loss : 0.029325
[23:59:41.374] iteration 11741 : model1 loss : 0.436107 model2 loss : 0.019503
[23:59:41.552] iteration 11742 : model1 loss : 0.437434 model2 loss : 0.021222
[23:59:41.723] iteration 11743 : model1 loss : 0.435895 model2 loss : 0.020584
[23:59:41.898] iteration 11744 : model1 loss : 0.432828 model2 loss : 0.022441
[23:59:42.072] iteration 11745 : model1 loss : 0.439826 model2 loss : 0.024372
[23:59:42.247] iteration 11746 : model1 loss : 0.433255 model2 loss : 0.020670
[23:59:42.421] iteration 11747 : model1 loss : 0.439645 model2 loss : 0.023931
[23:59:42.601] iteration 11748 : model1 loss : 0.436356 model2 loss : 0.021086
[23:59:42.772] iteration 11749 : model1 loss : 0.436711 model2 loss : 0.024109
[23:59:42.948] iteration 11750 : model1 loss : 0.433343 model2 loss : 0.021461
[23:59:43.122] iteration 11751 : model1 loss : 0.438512 model2 loss : 0.022841
[23:59:43.299] iteration 11752 : model1 loss : 0.436675 model2 loss : 0.020669
[23:59:43.470] iteration 11753 : model1 loss : 0.437335 model2 loss : 0.029928
[23:59:43.649] iteration 11754 : model1 loss : 0.434456 model2 loss : 0.021075
[23:59:43.819] iteration 11755 : model1 loss : 0.437322 model2 loss : 0.022561
[23:59:43.995] iteration 11756 : model1 loss : 0.434923 model2 loss : 0.021808
[23:59:44.173] iteration 11757 : model1 loss : 0.440829 model2 loss : 0.024382
[23:59:44.351] iteration 11758 : model1 loss : 0.434554 model2 loss : 0.021972
[23:59:44.521] iteration 11759 : model1 loss : 0.436973 model2 loss : 0.021196
[23:59:44.697] iteration 11760 : model1 loss : 0.439427 model2 loss : 0.019847
[23:59:46.819] iteration 11761 : model1 loss : 0.436430 model2 loss : 0.023889
[23:59:46.992] iteration 11762 : model1 loss : 0.436537 model2 loss : 0.022498
[23:59:47.179] iteration 11763 : model1 loss : 0.433336 model2 loss : 0.022001
[23:59:47.353] iteration 11764 : model1 loss : 0.437043 model2 loss : 0.023665
[23:59:47.535] iteration 11765 : model1 loss : 0.434261 model2 loss : 0.023573
[23:59:47.705] iteration 11766 : model1 loss : 0.439259 model2 loss : 0.021653
[23:59:47.881] iteration 11767 : model1 loss : 0.438292 model2 loss : 0.020667
[23:59:48.054] iteration 11768 : model1 loss : 0.440121 model2 loss : 0.020126
[23:59:48.231] iteration 11769 : model1 loss : 0.437499 model2 loss : 0.023632
[23:59:48.401] iteration 11770 : model1 loss : 0.439870 model2 loss : 0.023863
[23:59:48.579] iteration 11771 : model1 loss : 0.438833 model2 loss : 0.020273
[23:59:48.752] iteration 11772 : model1 loss : 0.437390 model2 loss : 0.021838
[23:59:48.929] iteration 11773 : model1 loss : 0.437398 model2 loss : 0.019327
[23:59:49.101] iteration 11774 : model1 loss : 0.437593 model2 loss : 0.022193
[23:59:49.280] iteration 11775 : model1 loss : 0.438455 model2 loss : 0.021605
[23:59:49.450] iteration 11776 : model1 loss : 0.431865 model2 loss : 0.022150
[23:59:49.628] iteration 11777 : model1 loss : 0.432832 model2 loss : 0.020397
[23:59:49.799] iteration 11778 : model1 loss : 0.436503 model2 loss : 0.021851
[23:59:49.973] iteration 11779 : model1 loss : 0.434416 model2 loss : 0.021048
[23:59:50.144] iteration 11780 : model1 loss : 0.435455 model2 loss : 0.025048
[23:59:50.322] iteration 11781 : model1 loss : 0.438643 model2 loss : 0.020322
[23:59:52.450] iteration 11782 : model1 loss : 0.433685 model2 loss : 0.018743
[23:59:52.624] iteration 11783 : model1 loss : 0.432783 model2 loss : 0.019648
[23:59:52.802] iteration 11784 : model1 loss : 0.435378 model2 loss : 0.020513
[23:59:52.972] iteration 11785 : model1 loss : 0.438199 model2 loss : 0.020567
[23:59:53.152] iteration 11786 : model1 loss : 0.435634 model2 loss : 0.021403
[23:59:53.327] iteration 11787 : model1 loss : 0.441424 model2 loss : 0.022839
[23:59:53.502] iteration 11788 : model1 loss : 0.435646 model2 loss : 0.021675
[23:59:53.676] iteration 11789 : model1 loss : 0.438915 model2 loss : 0.022560
[23:59:53.852] iteration 11790 : model1 loss : 0.437359 model2 loss : 0.019710
[23:59:54.024] iteration 11791 : model1 loss : 0.437755 model2 loss : 0.023155
[23:59:54.201] iteration 11792 : model1 loss : 0.439951 model2 loss : 0.023954
[23:59:54.374] iteration 11793 : model1 loss : 0.434962 model2 loss : 0.021334
[23:59:54.551] iteration 11794 : model1 loss : 0.435516 model2 loss : 0.020479
[23:59:54.724] iteration 11795 : model1 loss : 0.437023 model2 loss : 0.022420
[23:59:54.898] iteration 11796 : model1 loss : 0.437994 model2 loss : 0.022581
[23:59:55.073] iteration 11797 : model1 loss : 0.438412 model2 loss : 0.023904
[23:59:55.248] iteration 11798 : model1 loss : 0.434164 model2 loss : 0.018336
[23:59:55.418] iteration 11799 : model1 loss : 0.441034 model2 loss : 0.020959
[23:59:55.598] iteration 11800 : model1 loss : 0.434139 model2 loss : 0.023932
[23:59:55.768] iteration 11801 : model1 loss : 0.439518 model2 loss : 0.022317
[23:59:55.939] iteration 11802 : model1 loss : 0.434092 model2 loss : 0.022558
[23:59:58.090] iteration 11803 : model1 loss : 0.437971 model2 loss : 0.023752
[23:59:58.265] iteration 11804 : model1 loss : 0.432956 model2 loss : 0.019660
[23:59:58.445] iteration 11805 : model1 loss : 0.440322 model2 loss : 0.026215
[23:59:58.619] iteration 11806 : model1 loss : 0.436358 model2 loss : 0.020914
[23:59:58.798] iteration 11807 : model1 loss : 0.438992 model2 loss : 0.019336
[23:59:58.968] iteration 11808 : model1 loss : 0.435446 model2 loss : 0.023219
[23:59:59.144] iteration 11809 : model1 loss : 0.440352 model2 loss : 0.024767
[23:59:59.318] iteration 11810 : model1 loss : 0.432466 model2 loss : 0.020019
[23:59:59.495] iteration 11811 : model1 loss : 0.437153 model2 loss : 0.021244
[23:59:59.668] iteration 11812 : model1 loss : 0.438968 model2 loss : 0.020167
[23:59:59.843] iteration 11813 : model1 loss : 0.437128 model2 loss : 0.022046
[00:00:00.016] iteration 11814 : model1 loss : 0.436341 model2 loss : 0.019918
[00:00:00.198] iteration 11815 : model1 loss : 0.434048 model2 loss : 0.022331
[00:00:00.369] iteration 11816 : model1 loss : 0.434443 model2 loss : 0.021226
[00:00:00.547] iteration 11817 : model1 loss : 0.437789 model2 loss : 0.023071
[00:00:00.719] iteration 11818 : model1 loss : 0.437854 model2 loss : 0.021169
[00:00:00.898] iteration 11819 : model1 loss : 0.435764 model2 loss : 0.021073
[00:00:01.073] iteration 11820 : model1 loss : 0.436636 model2 loss : 0.022911
[00:00:01.246] iteration 11821 : model1 loss : 0.440030 model2 loss : 0.021860
[00:00:01.417] iteration 11822 : model1 loss : 0.438368 model2 loss : 0.021550
[00:00:01.597] iteration 11823 : model1 loss : 0.433324 model2 loss : 0.020500
[00:00:03.754] iteration 11824 : model1 loss : 0.442855 model2 loss : 0.026266
[00:00:03.927] iteration 11825 : model1 loss : 0.436226 model2 loss : 0.022211
[00:00:04.106] iteration 11826 : model1 loss : 0.433819 model2 loss : 0.021200
[00:00:04.278] iteration 11827 : model1 loss : 0.440258 model2 loss : 0.021908
[00:00:04.455] iteration 11828 : model1 loss : 0.435218 model2 loss : 0.021956
[00:00:04.631] iteration 11829 : model1 loss : 0.438201 model2 loss : 0.022678
[00:00:04.806] iteration 11830 : model1 loss : 0.434808 model2 loss : 0.021681
[00:00:04.978] iteration 11831 : model1 loss : 0.442177 model2 loss : 0.023039
[00:00:05.160] iteration 11832 : model1 loss : 0.438078 model2 loss : 0.024576
[00:00:05.334] iteration 11833 : model1 loss : 0.439130 model2 loss : 0.022430
[00:00:05.507] iteration 11834 : model1 loss : 0.434020 model2 loss : 0.019049
[00:00:05.679] iteration 11835 : model1 loss : 0.433597 model2 loss : 0.021947
[00:00:05.856] iteration 11836 : model1 loss : 0.438452 model2 loss : 0.021313
[00:00:06.027] iteration 11837 : model1 loss : 0.436951 model2 loss : 0.022842
[00:00:06.204] iteration 11838 : model1 loss : 0.440529 model2 loss : 0.025542
[00:00:06.378] iteration 11839 : model1 loss : 0.434896 model2 loss : 0.021264
[00:00:06.554] iteration 11840 : model1 loss : 0.435109 model2 loss : 0.019626
[00:00:06.727] iteration 11841 : model1 loss : 0.437722 model2 loss : 0.018259
[00:00:06.902] iteration 11842 : model1 loss : 0.433473 model2 loss : 0.020580
[00:00:07.072] iteration 11843 : model1 loss : 0.433432 model2 loss : 0.022773
[00:00:07.248] iteration 11844 : model1 loss : 0.434050 model2 loss : 0.020616
[00:00:09.504] iteration 11845 : model1 loss : 0.438495 model2 loss : 0.022139
[00:00:09.680] iteration 11846 : model1 loss : 0.436563 model2 loss : 0.020366
[00:00:09.855] iteration 11847 : model1 loss : 0.441529 model2 loss : 0.025372
[00:00:10.025] iteration 11848 : model1 loss : 0.437688 model2 loss : 0.023286
[00:00:10.202] iteration 11849 : model1 loss : 0.431509 model2 loss : 0.020316
[00:00:10.374] iteration 11850 : model1 loss : 0.436959 model2 loss : 0.019765
[00:00:10.551] iteration 11851 : model1 loss : 0.435246 model2 loss : 0.021866
[00:00:10.726] iteration 11852 : model1 loss : 0.438974 model2 loss : 0.022214
[00:00:10.902] iteration 11853 : model1 loss : 0.439997 model2 loss : 0.024632
[00:00:11.075] iteration 11854 : model1 loss : 0.435238 model2 loss : 0.021332
[00:00:11.255] iteration 11855 : model1 loss : 0.436311 model2 loss : 0.021689
[00:00:11.427] iteration 11856 : model1 loss : 0.435237 model2 loss : 0.023324
[00:00:11.608] iteration 11857 : model1 loss : 0.436666 model2 loss : 0.020146
[00:00:11.783] iteration 11858 : model1 loss : 0.435697 model2 loss : 0.020980
[00:00:11.961] iteration 11859 : model1 loss : 0.434548 model2 loss : 0.020469
[00:00:12.135] iteration 11860 : model1 loss : 0.431978 model2 loss : 0.020008
[00:00:12.316] iteration 11861 : model1 loss : 0.435670 model2 loss : 0.020202
[00:00:12.489] iteration 11862 : model1 loss : 0.436724 model2 loss : 0.021021
[00:00:12.668] iteration 11863 : model1 loss : 0.439504 model2 loss : 0.021773
[00:00:12.837] iteration 11864 : model1 loss : 0.434974 model2 loss : 0.022272
[00:00:13.010] iteration 11865 : model1 loss : 0.438927 model2 loss : 0.025166
[00:00:15.174] iteration 11866 : model1 loss : 0.441265 model2 loss : 0.024112
[00:00:15.346] iteration 11867 : model1 loss : 0.438737 model2 loss : 0.019377
[00:00:15.523] iteration 11868 : model1 loss : 0.438157 model2 loss : 0.022938
[00:00:15.696] iteration 11869 : model1 loss : 0.432061 model2 loss : 0.022106
[00:00:15.870] iteration 11870 : model1 loss : 0.435447 model2 loss : 0.023483
[00:00:16.041] iteration 11871 : model1 loss : 0.438662 model2 loss : 0.025985
[00:00:16.218] iteration 11872 : model1 loss : 0.437452 model2 loss : 0.021405
[00:00:16.389] iteration 11873 : model1 loss : 0.436214 model2 loss : 0.022089
[00:00:16.565] iteration 11874 : model1 loss : 0.434216 model2 loss : 0.018825
[00:00:16.738] iteration 11875 : model1 loss : 0.434368 model2 loss : 0.022218
[00:00:16.913] iteration 11876 : model1 loss : 0.437670 model2 loss : 0.021543
[00:00:17.087] iteration 11877 : model1 loss : 0.437854 model2 loss : 0.021771
[00:00:17.264] iteration 11878 : model1 loss : 0.432137 model2 loss : 0.019064
[00:00:17.436] iteration 11879 : model1 loss : 0.437387 model2 loss : 0.021432
[00:00:17.617] iteration 11880 : model1 loss : 0.437195 model2 loss : 0.023457
[00:00:17.788] iteration 11881 : model1 loss : 0.442700 model2 loss : 0.027283
[00:00:17.963] iteration 11882 : model1 loss : 0.433853 model2 loss : 0.022401
[00:00:18.137] iteration 11883 : model1 loss : 0.432244 model2 loss : 0.019603
[00:00:18.314] iteration 11884 : model1 loss : 0.438815 model2 loss : 0.020442
[00:00:18.483] iteration 11885 : model1 loss : 0.436941 model2 loss : 0.023260
[00:00:18.661] iteration 11886 : model1 loss : 0.434335 model2 loss : 0.020573
[00:00:20.784] iteration 11887 : model1 loss : 0.435978 model2 loss : 0.023388
[00:00:20.954] iteration 11888 : model1 loss : 0.442669 model2 loss : 0.023537
[00:00:21.134] iteration 11889 : model1 loss : 0.436343 model2 loss : 0.020362
[00:00:21.308] iteration 11890 : model1 loss : 0.435888 model2 loss : 0.020409
[00:00:21.483] iteration 11891 : model1 loss : 0.440773 model2 loss : 0.024044
[00:00:21.657] iteration 11892 : model1 loss : 0.440948 model2 loss : 0.026942
[00:00:21.832] iteration 11893 : model1 loss : 0.436417 model2 loss : 0.023184
[00:00:22.008] iteration 11894 : model1 loss : 0.435379 model2 loss : 0.021716
[00:00:22.187] iteration 11895 : model1 loss : 0.434624 model2 loss : 0.022969
[00:00:22.358] iteration 11896 : model1 loss : 0.433850 model2 loss : 0.022838
[00:00:22.537] iteration 11897 : model1 loss : 0.438563 model2 loss : 0.022367
[00:00:22.709] iteration 11898 : model1 loss : 0.431077 model2 loss : 0.023885
[00:00:22.887] iteration 11899 : model1 loss : 0.433352 model2 loss : 0.019450
[00:00:23.057] iteration 11900 : model1 loss : 0.434619 model2 loss : 0.019972
[00:00:23.239] iteration 11901 : model1 loss : 0.436193 model2 loss : 0.023742
[00:00:23.409] iteration 11902 : model1 loss : 0.435737 model2 loss : 0.021048
[00:00:23.586] iteration 11903 : model1 loss : 0.442962 model2 loss : 0.029702
[00:00:23.760] iteration 11904 : model1 loss : 0.435527 model2 loss : 0.019374
[00:00:23.937] iteration 11905 : model1 loss : 0.439677 model2 loss : 0.023961
[00:00:24.111] iteration 11906 : model1 loss : 0.435795 model2 loss : 0.024989
[00:00:24.288] iteration 11907 : model1 loss : 0.435047 model2 loss : 0.022846
[00:00:26.418] iteration 11908 : model1 loss : 0.437132 model2 loss : 0.022386
[00:00:26.600] iteration 11909 : model1 loss : 0.436182 model2 loss : 0.022176
[00:00:26.777] iteration 11910 : model1 loss : 0.437354 model2 loss : 0.021339
[00:00:26.948] iteration 11911 : model1 loss : 0.439309 model2 loss : 0.020274
[00:00:27.130] iteration 11912 : model1 loss : 0.435581 model2 loss : 0.017632
[00:00:27.304] iteration 11913 : model1 loss : 0.432873 model2 loss : 0.021065
[00:00:27.485] iteration 11914 : model1 loss : 0.432636 model2 loss : 0.019340
[00:00:27.656] iteration 11915 : model1 loss : 0.435196 model2 loss : 0.022425
[00:00:27.834] iteration 11916 : model1 loss : 0.438855 model2 loss : 0.021710
[00:00:28.003] iteration 11917 : model1 loss : 0.436601 model2 loss : 0.024625
[00:00:28.181] iteration 11918 : model1 loss : 0.436049 model2 loss : 0.021271
[00:00:28.351] iteration 11919 : model1 loss : 0.433569 model2 loss : 0.019958
[00:00:28.530] iteration 11920 : model1 loss : 0.438651 model2 loss : 0.021777
[00:00:28.705] iteration 11921 : model1 loss : 0.440636 model2 loss : 0.024662
[00:00:28.882] iteration 11922 : model1 loss : 0.440245 model2 loss : 0.022630
[00:00:29.053] iteration 11923 : model1 loss : 0.435016 model2 loss : 0.020462
[00:00:29.234] iteration 11924 : model1 loss : 0.439408 model2 loss : 0.022100
[00:00:29.405] iteration 11925 : model1 loss : 0.431909 model2 loss : 0.021558
[00:00:29.579] iteration 11926 : model1 loss : 0.437601 model2 loss : 0.023415
[00:00:29.752] iteration 11927 : model1 loss : 0.438413 model2 loss : 0.022781
[00:00:29.927] iteration 11928 : model1 loss : 0.435004 model2 loss : 0.018327
[00:00:32.050] iteration 11929 : model1 loss : 0.437598 model2 loss : 0.020814
[00:00:32.229] iteration 11930 : model1 loss : 0.437485 model2 loss : 0.020162
[00:00:32.404] iteration 11931 : model1 loss : 0.438762 model2 loss : 0.022575
[00:00:32.575] iteration 11932 : model1 loss : 0.431527 model2 loss : 0.021512
[00:00:32.751] iteration 11933 : model1 loss : 0.434080 model2 loss : 0.022162
[00:00:32.922] iteration 11934 : model1 loss : 0.434435 model2 loss : 0.019775
[00:00:33.100] iteration 11935 : model1 loss : 0.437847 model2 loss : 0.024617
[00:00:33.275] iteration 11936 : model1 loss : 0.437892 model2 loss : 0.019306
[00:00:33.451] iteration 11937 : model1 loss : 0.434096 model2 loss : 0.023565
[00:00:33.625] iteration 11938 : model1 loss : 0.437609 model2 loss : 0.021632
[00:00:33.801] iteration 11939 : model1 loss : 0.436941 model2 loss : 0.023224
[00:00:33.971] iteration 11940 : model1 loss : 0.435001 model2 loss : 0.020034
[00:00:34.151] iteration 11941 : model1 loss : 0.434445 model2 loss : 0.019150
[00:00:34.327] iteration 11942 : model1 loss : 0.438766 model2 loss : 0.020365
[00:00:34.503] iteration 11943 : model1 loss : 0.435525 model2 loss : 0.020661
[00:00:34.677] iteration 11944 : model1 loss : 0.437716 model2 loss : 0.018856
[00:00:34.855] iteration 11945 : model1 loss : 0.438798 model2 loss : 0.020908
[00:00:35.028] iteration 11946 : model1 loss : 0.440490 model2 loss : 0.022309
[00:00:35.208] iteration 11947 : model1 loss : 0.437436 model2 loss : 0.021445
[00:00:35.377] iteration 11948 : model1 loss : 0.436368 model2 loss : 0.020858
[00:00:35.553] iteration 11949 : model1 loss : 0.435839 model2 loss : 0.022999
[00:00:37.695] iteration 11950 : model1 loss : 0.438254 model2 loss : 0.022894
[00:00:37.867] iteration 11951 : model1 loss : 0.435746 model2 loss : 0.021990
[00:00:38.047] iteration 11952 : model1 loss : 0.436169 model2 loss : 0.021105
[00:00:38.222] iteration 11953 : model1 loss : 0.432124 model2 loss : 0.017771
[00:00:38.403] iteration 11954 : model1 loss : 0.435138 model2 loss : 0.020929
[00:00:38.575] iteration 11955 : model1 loss : 0.432482 model2 loss : 0.020290
[00:00:38.752] iteration 11956 : model1 loss : 0.437576 model2 loss : 0.021149
[00:00:38.922] iteration 11957 : model1 loss : 0.435301 model2 loss : 0.020765
[00:00:39.097] iteration 11958 : model1 loss : 0.440518 model2 loss : 0.023147
[00:00:39.272] iteration 11959 : model1 loss : 0.437471 model2 loss : 0.024459
[00:00:39.446] iteration 11960 : model1 loss : 0.440748 model2 loss : 0.023302
[00:00:39.619] iteration 11961 : model1 loss : 0.437404 model2 loss : 0.020709
[00:00:39.797] iteration 11962 : model1 loss : 0.437153 model2 loss : 0.022298
[00:00:39.968] iteration 11963 : model1 loss : 0.440787 model2 loss : 0.026759
[00:00:40.145] iteration 11964 : model1 loss : 0.437931 model2 loss : 0.019182
[00:00:40.318] iteration 11965 : model1 loss : 0.434604 model2 loss : 0.020439
[00:00:40.495] iteration 11966 : model1 loss : 0.436456 model2 loss : 0.022344
[00:00:40.669] iteration 11967 : model1 loss : 0.438811 model2 loss : 0.022625
[00:00:40.844] iteration 11968 : model1 loss : 0.433174 model2 loss : 0.021358
[00:00:41.014] iteration 11969 : model1 loss : 0.437621 model2 loss : 0.021429
[00:00:41.191] iteration 11970 : model1 loss : 0.436455 model2 loss : 0.021505
[00:00:43.342] iteration 11971 : model1 loss : 0.438542 model2 loss : 0.020532
[00:00:43.515] iteration 11972 : model1 loss : 0.433684 model2 loss : 0.020992
[00:00:43.694] iteration 11973 : model1 loss : 0.436799 model2 loss : 0.021511
[00:00:43.868] iteration 11974 : model1 loss : 0.431776 model2 loss : 0.020461
[00:00:44.043] iteration 11975 : model1 loss : 0.435877 model2 loss : 0.019764
[00:00:44.216] iteration 11976 : model1 loss : 0.435109 model2 loss : 0.020622
[00:00:44.392] iteration 11977 : model1 loss : 0.434864 model2 loss : 0.018375
[00:00:44.564] iteration 11978 : model1 loss : 0.436649 model2 loss : 0.019894
[00:00:44.752] iteration 11979 : model1 loss : 0.440805 model2 loss : 0.022708
[00:00:44.923] iteration 11980 : model1 loss : 0.439925 model2 loss : 0.024344
[00:00:45.098] iteration 11981 : model1 loss : 0.435050 model2 loss : 0.019641
[00:00:45.271] iteration 11982 : model1 loss : 0.439044 model2 loss : 0.022109
[00:00:45.450] iteration 11983 : model1 loss : 0.438176 model2 loss : 0.021907
[00:00:45.623] iteration 11984 : model1 loss : 0.438275 model2 loss : 0.023047
[00:00:45.801] iteration 11985 : model1 loss : 0.435857 model2 loss : 0.022504
[00:00:45.974] iteration 11986 : model1 loss : 0.434536 model2 loss : 0.018753
[00:00:46.149] iteration 11987 : model1 loss : 0.437008 model2 loss : 0.020762
[00:00:46.324] iteration 11988 : model1 loss : 0.434503 model2 loss : 0.019364
[00:00:46.499] iteration 11989 : model1 loss : 0.438952 model2 loss : 0.023510
[00:00:46.671] iteration 11990 : model1 loss : 0.436804 model2 loss : 0.019337
[00:00:46.846] iteration 11991 : model1 loss : 0.435581 model2 loss : 0.021549
[00:00:48.984] iteration 11992 : model1 loss : 0.435875 model2 loss : 0.020499
[00:00:49.163] iteration 11993 : model1 loss : 0.438749 model2 loss : 0.022331
[00:00:49.345] iteration 11994 : model1 loss : 0.438205 model2 loss : 0.021263
[00:00:49.517] iteration 11995 : model1 loss : 0.441377 model2 loss : 0.022949
[00:00:49.698] iteration 11996 : model1 loss : 0.434362 model2 loss : 0.020784
[00:00:49.871] iteration 11997 : model1 loss : 0.433745 model2 loss : 0.022609
[00:00:50.045] iteration 11998 : model1 loss : 0.435491 model2 loss : 0.021013
[00:00:50.219] iteration 11999 : model1 loss : 0.439644 model2 loss : 0.024609
[00:00:50.396] iteration 12000 : model1 loss : 0.437649 model2 loss : 0.023052
[00:00:59.568] iteration 12000 : model1_mean_dice : 0.847070 model1_mean_hd95 : 7.925318
[00:01:08.714] iteration 12000 : model2_mean_dice : 0.858830 model2_mean_hd95 : 4.352037
[00:01:08.744] save model1 to ../model/ACDC/EVILv1_kl0.5_tau0.25_14_1337/unet\model1_iter_12000.pth
[00:01:08.771] save model2 to ../model/ACDC/EVILv1_kl0.5_tau0.25_14_1337/unet\model2_iter_12000.pth
[00:01:08.952] iteration 12001 : model1 loss : 0.440599 model2 loss : 0.026915
[00:01:09.128] iteration 12002 : model1 loss : 0.436278 model2 loss : 0.024153
[00:01:09.307] iteration 12003 : model1 loss : 0.435376 model2 loss : 0.019072
[00:01:09.480] iteration 12004 : model1 loss : 0.435065 model2 loss : 0.022896
[00:01:09.657] iteration 12005 : model1 loss : 0.432677 model2 loss : 0.019276
[00:01:09.830] iteration 12006 : model1 loss : 0.439810 model2 loss : 0.021081
[00:01:10.005] iteration 12007 : model1 loss : 0.440878 model2 loss : 0.026769
[00:01:10.177] iteration 12008 : model1 loss : 0.436500 model2 loss : 0.020145
[00:01:10.353] iteration 12009 : model1 loss : 0.434073 model2 loss : 0.022233
[00:01:10.522] iteration 12010 : model1 loss : 0.438307 model2 loss : 0.021647
[00:01:10.695] iteration 12011 : model1 loss : 0.435449 model2 loss : 0.021823
[00:01:10.865] iteration 12012 : model1 loss : 0.435114 model2 loss : 0.019931
[00:01:13.011] iteration 12013 : model1 loss : 0.434148 model2 loss : 0.021776
[00:01:13.182] iteration 12014 : model1 loss : 0.436015 model2 loss : 0.021404
[00:01:13.360] iteration 12015 : model1 loss : 0.434854 model2 loss : 0.023429
[00:01:13.532] iteration 12016 : model1 loss : 0.440715 model2 loss : 0.025411
[00:01:13.706] iteration 12017 : model1 loss : 0.437446 model2 loss : 0.019980
[00:01:13.880] iteration 12018 : model1 loss : 0.437999 model2 loss : 0.020742
[00:01:14.056] iteration 12019 : model1 loss : 0.435333 model2 loss : 0.019942
[00:01:14.229] iteration 12020 : model1 loss : 0.433351 model2 loss : 0.022743
[00:01:14.405] iteration 12021 : model1 loss : 0.435192 model2 loss : 0.020745
[00:01:14.577] iteration 12022 : model1 loss : 0.440239 model2 loss : 0.025249
[00:01:14.756] iteration 12023 : model1 loss : 0.434529 model2 loss : 0.022294
[00:01:14.927] iteration 12024 : model1 loss : 0.436724 model2 loss : 0.021037
[00:01:15.101] iteration 12025 : model1 loss : 0.438286 model2 loss : 0.020963
[00:01:15.274] iteration 12026 : model1 loss : 0.439314 model2 loss : 0.021690
[00:01:15.451] iteration 12027 : model1 loss : 0.442039 model2 loss : 0.024535
[00:01:15.623] iteration 12028 : model1 loss : 0.435571 model2 loss : 0.021444
[00:01:15.798] iteration 12029 : model1 loss : 0.438113 model2 loss : 0.022188
[00:01:15.970] iteration 12030 : model1 loss : 0.436745 model2 loss : 0.021320
[00:01:16.145] iteration 12031 : model1 loss : 0.433951 model2 loss : 0.021400
[00:01:16.319] iteration 12032 : model1 loss : 0.436895 model2 loss : 0.021935
[00:01:16.495] iteration 12033 : model1 loss : 0.435397 model2 loss : 0.022736
[00:01:18.661] iteration 12034 : model1 loss : 0.439450 model2 loss : 0.020517
[00:01:18.838] iteration 12035 : model1 loss : 0.436739 model2 loss : 0.023164
[00:01:19.014] iteration 12036 : model1 loss : 0.436915 model2 loss : 0.021941
[00:01:19.185] iteration 12037 : model1 loss : 0.435887 model2 loss : 0.020708
[00:01:19.365] iteration 12038 : model1 loss : 0.436138 model2 loss : 0.020170
[00:01:19.537] iteration 12039 : model1 loss : 0.435722 model2 loss : 0.019698
[00:01:19.714] iteration 12040 : model1 loss : 0.435160 model2 loss : 0.019961
[00:01:19.884] iteration 12041 : model1 loss : 0.432416 model2 loss : 0.019476
[00:01:20.060] iteration 12042 : model1 loss : 0.437922 model2 loss : 0.022543
[00:01:20.233] iteration 12043 : model1 loss : 0.437236 model2 loss : 0.019376
[00:01:20.406] iteration 12044 : model1 loss : 0.436514 model2 loss : 0.020388
[00:01:20.578] iteration 12045 : model1 loss : 0.436660 model2 loss : 0.020732
[00:01:20.756] iteration 12046 : model1 loss : 0.436507 model2 loss : 0.022921
[00:01:20.927] iteration 12047 : model1 loss : 0.436738 model2 loss : 0.024632
[00:01:21.102] iteration 12048 : model1 loss : 0.438413 model2 loss : 0.021197
[00:01:21.276] iteration 12049 : model1 loss : 0.435666 model2 loss : 0.021861
[00:01:21.452] iteration 12050 : model1 loss : 0.437290 model2 loss : 0.024761
[00:01:21.626] iteration 12051 : model1 loss : 0.438680 model2 loss : 0.022312
[00:01:21.803] iteration 12052 : model1 loss : 0.437238 model2 loss : 0.019176
[00:01:21.972] iteration 12053 : model1 loss : 0.438330 model2 loss : 0.020477
[00:01:22.146] iteration 12054 : model1 loss : 0.434848 model2 loss : 0.019926
[00:01:24.285] iteration 12055 : model1 loss : 0.438985 model2 loss : 0.023068
[00:01:24.460] iteration 12056 : model1 loss : 0.435454 model2 loss : 0.020614
[00:01:24.638] iteration 12057 : model1 loss : 0.436632 model2 loss : 0.021324
[00:01:24.810] iteration 12058 : model1 loss : 0.438306 model2 loss : 0.021857
[00:01:24.985] iteration 12059 : model1 loss : 0.435668 model2 loss : 0.021516
[00:01:25.157] iteration 12060 : model1 loss : 0.436653 model2 loss : 0.020403
[00:01:25.337] iteration 12061 : model1 loss : 0.434573 model2 loss : 0.022084
[00:01:25.509] iteration 12062 : model1 loss : 0.438314 model2 loss : 0.019946
[00:01:25.686] iteration 12063 : model1 loss : 0.442247 model2 loss : 0.021619
[00:01:25.860] iteration 12064 : model1 loss : 0.436670 model2 loss : 0.019646
[00:01:26.034] iteration 12065 : model1 loss : 0.434356 model2 loss : 0.021744
[00:01:26.206] iteration 12066 : model1 loss : 0.434157 model2 loss : 0.022006
[00:01:26.383] iteration 12067 : model1 loss : 0.435323 model2 loss : 0.022249
[00:01:26.555] iteration 12068 : model1 loss : 0.436621 model2 loss : 0.020186
[00:01:26.731] iteration 12069 : model1 loss : 0.436898 model2 loss : 0.021020
[00:01:26.904] iteration 12070 : model1 loss : 0.434432 model2 loss : 0.020244
[00:01:27.079] iteration 12071 : model1 loss : 0.431441 model2 loss : 0.019793
[00:01:27.250] iteration 12072 : model1 loss : 0.439810 model2 loss : 0.022435
[00:01:27.431] iteration 12073 : model1 loss : 0.438288 model2 loss : 0.023569
[00:01:27.604] iteration 12074 : model1 loss : 0.439880 model2 loss : 0.023224
[00:01:27.780] iteration 12075 : model1 loss : 0.435964 model2 loss : 0.020294
[00:01:29.922] iteration 12076 : model1 loss : 0.435903 model2 loss : 0.020878
[00:01:30.094] iteration 12077 : model1 loss : 0.438278 model2 loss : 0.024701
[00:01:30.273] iteration 12078 : model1 loss : 0.436616 model2 loss : 0.019590
[00:01:30.444] iteration 12079 : model1 loss : 0.436182 model2 loss : 0.020058
[00:01:30.621] iteration 12080 : model1 loss : 0.441268 model2 loss : 0.022639
[00:01:30.794] iteration 12081 : model1 loss : 0.437738 model2 loss : 0.019345
[00:01:30.969] iteration 12082 : model1 loss : 0.436336 model2 loss : 0.020809
[00:01:31.139] iteration 12083 : model1 loss : 0.438323 model2 loss : 0.021040
[00:01:31.323] iteration 12084 : model1 loss : 0.432511 model2 loss : 0.020595
[00:01:31.494] iteration 12085 : model1 loss : 0.439793 model2 loss : 0.023675
[00:01:31.671] iteration 12086 : model1 loss : 0.434196 model2 loss : 0.022376
[00:01:31.844] iteration 12087 : model1 loss : 0.435369 model2 loss : 0.021013
[00:01:32.020] iteration 12088 : model1 loss : 0.431811 model2 loss : 0.019616
[00:01:32.190] iteration 12089 : model1 loss : 0.435250 model2 loss : 0.024553
[00:01:32.368] iteration 12090 : model1 loss : 0.435293 model2 loss : 0.019311
[00:01:32.541] iteration 12091 : model1 loss : 0.436976 model2 loss : 0.020741
[00:01:32.715] iteration 12092 : model1 loss : 0.437274 model2 loss : 0.020811
[00:01:32.889] iteration 12093 : model1 loss : 0.438775 model2 loss : 0.025165
[00:01:33.065] iteration 12094 : model1 loss : 0.436969 model2 loss : 0.021800
[00:01:33.237] iteration 12095 : model1 loss : 0.434438 model2 loss : 0.020591
[00:01:33.410] iteration 12096 : model1 loss : 0.444901 model2 loss : 0.024508
[00:01:35.542] iteration 12097 : model1 loss : 0.437362 model2 loss : 0.022624
[00:01:35.713] iteration 12098 : model1 loss : 0.436446 model2 loss : 0.020995
[00:01:35.896] iteration 12099 : model1 loss : 0.438978 model2 loss : 0.022740
[00:01:36.070] iteration 12100 : model1 loss : 0.435139 model2 loss : 0.021500
[00:01:36.248] iteration 12101 : model1 loss : 0.434322 model2 loss : 0.022664
[00:01:36.420] iteration 12102 : model1 loss : 0.435402 model2 loss : 0.021994
[00:01:36.602] iteration 12103 : model1 loss : 0.436161 model2 loss : 0.022070
[00:01:36.773] iteration 12104 : model1 loss : 0.440230 model2 loss : 0.021732
[00:01:36.950] iteration 12105 : model1 loss : 0.434775 model2 loss : 0.019965
[00:01:37.122] iteration 12106 : model1 loss : 0.439171 model2 loss : 0.021139
[00:01:37.301] iteration 12107 : model1 loss : 0.434109 model2 loss : 0.020909
[00:01:37.475] iteration 12108 : model1 loss : 0.437689 model2 loss : 0.022259
[00:01:37.655] iteration 12109 : model1 loss : 0.440407 model2 loss : 0.022053
[00:01:37.829] iteration 12110 : model1 loss : 0.434919 model2 loss : 0.020304
[00:01:38.002] iteration 12111 : model1 loss : 0.438407 model2 loss : 0.023861
[00:01:38.175] iteration 12112 : model1 loss : 0.436620 model2 loss : 0.022247
[00:01:38.355] iteration 12113 : model1 loss : 0.436823 model2 loss : 0.021204
[00:01:38.527] iteration 12114 : model1 loss : 0.434933 model2 loss : 0.021194
[00:01:38.703] iteration 12115 : model1 loss : 0.433372 model2 loss : 0.019875
[00:01:38.876] iteration 12116 : model1 loss : 0.439690 model2 loss : 0.024789
[00:01:39.048] iteration 12117 : model1 loss : 0.438604 model2 loss : 0.024442
[00:01:41.170] iteration 12118 : model1 loss : 0.438204 model2 loss : 0.021918
[00:01:41.347] iteration 12119 : model1 loss : 0.434273 model2 loss : 0.023934
[00:01:41.523] iteration 12120 : model1 loss : 0.436163 model2 loss : 0.024386
[00:01:41.691] iteration 12121 : model1 loss : 0.438766 model2 loss : 0.019241
[00:01:41.867] iteration 12122 : model1 loss : 0.436831 model2 loss : 0.024697
[00:01:42.038] iteration 12123 : model1 loss : 0.435739 model2 loss : 0.021480
[00:01:42.212] iteration 12124 : model1 loss : 0.439490 model2 loss : 0.023786
[00:01:42.388] iteration 12125 : model1 loss : 0.437326 model2 loss : 0.021351
[00:01:42.566] iteration 12126 : model1 loss : 0.439347 model2 loss : 0.021185
[00:01:42.736] iteration 12127 : model1 loss : 0.435327 model2 loss : 0.020521
[00:01:42.914] iteration 12128 : model1 loss : 0.436602 model2 loss : 0.021592
[00:01:43.083] iteration 12129 : model1 loss : 0.438049 model2 loss : 0.023357
[00:01:43.261] iteration 12130 : model1 loss : 0.436343 model2 loss : 0.020762
[00:01:43.434] iteration 12131 : model1 loss : 0.435088 model2 loss : 0.022251
[00:01:43.615] iteration 12132 : model1 loss : 0.435624 model2 loss : 0.024077
[00:01:43.787] iteration 12133 : model1 loss : 0.441248 model2 loss : 0.026944
[00:01:43.965] iteration 12134 : model1 loss : 0.433517 model2 loss : 0.021941
[00:01:44.135] iteration 12135 : model1 loss : 0.440262 model2 loss : 0.025391
[00:01:44.312] iteration 12136 : model1 loss : 0.437244 model2 loss : 0.020586
[00:01:44.483] iteration 12137 : model1 loss : 0.429431 model2 loss : 0.021745
[00:01:44.661] iteration 12138 : model1 loss : 0.439144 model2 loss : 0.023156
[00:01:46.781] iteration 12139 : model1 loss : 0.431144 model2 loss : 0.018958
[00:01:46.959] iteration 12140 : model1 loss : 0.435581 model2 loss : 0.021879
[00:01:47.136] iteration 12141 : model1 loss : 0.436404 model2 loss : 0.024564
[00:01:47.312] iteration 12142 : model1 loss : 0.433600 model2 loss : 0.021876
[00:01:47.494] iteration 12143 : model1 loss : 0.435087 model2 loss : 0.020936
[00:01:47.665] iteration 12144 : model1 loss : 0.435410 model2 loss : 0.021129
[00:01:47.844] iteration 12145 : model1 loss : 0.438402 model2 loss : 0.022026
[00:01:48.014] iteration 12146 : model1 loss : 0.433461 model2 loss : 0.021316
[00:01:48.194] iteration 12147 : model1 loss : 0.439646 model2 loss : 0.024487
[00:01:48.368] iteration 12148 : model1 loss : 0.438109 model2 loss : 0.021099
[00:01:48.544] iteration 12149 : model1 loss : 0.435540 model2 loss : 0.019398
[00:01:48.714] iteration 12150 : model1 loss : 0.443267 model2 loss : 0.027599
[00:01:48.890] iteration 12151 : model1 loss : 0.436605 model2 loss : 0.019879
[00:01:49.061] iteration 12152 : model1 loss : 0.434999 model2 loss : 0.021650
[00:01:49.238] iteration 12153 : model1 loss : 0.439074 model2 loss : 0.022068
[00:01:49.414] iteration 12154 : model1 loss : 0.436450 model2 loss : 0.022712
[00:01:49.595] iteration 12155 : model1 loss : 0.431159 model2 loss : 0.021429
[00:01:49.770] iteration 12156 : model1 loss : 0.439277 model2 loss : 0.023237
[00:01:49.945] iteration 12157 : model1 loss : 0.444414 model2 loss : 0.029331
[00:01:50.114] iteration 12158 : model1 loss : 0.435014 model2 loss : 0.018514
[00:01:50.290] iteration 12159 : model1 loss : 0.437882 model2 loss : 0.022075
[00:01:52.443] iteration 12160 : model1 loss : 0.437693 model2 loss : 0.022646
[00:01:52.617] iteration 12161 : model1 loss : 0.435024 model2 loss : 0.019985
[00:01:52.796] iteration 12162 : model1 loss : 0.435941 model2 loss : 0.021328
[00:01:52.967] iteration 12163 : model1 loss : 0.436018 model2 loss : 0.022449
[00:01:53.142] iteration 12164 : model1 loss : 0.438671 model2 loss : 0.025178
[00:01:53.319] iteration 12165 : model1 loss : 0.432451 model2 loss : 0.020682
[00:01:53.496] iteration 12166 : model1 loss : 0.440358 model2 loss : 0.025031
[00:01:53.667] iteration 12167 : model1 loss : 0.436688 model2 loss : 0.022128
[00:01:53.841] iteration 12168 : model1 loss : 0.434697 model2 loss : 0.017704
[00:01:54.013] iteration 12169 : model1 loss : 0.436417 model2 loss : 0.021728
[00:01:54.191] iteration 12170 : model1 loss : 0.436122 model2 loss : 0.022488
[00:01:54.366] iteration 12171 : model1 loss : 0.437931 model2 loss : 0.022847
[00:01:54.540] iteration 12172 : model1 loss : 0.437399 model2 loss : 0.022817
[00:01:54.711] iteration 12173 : model1 loss : 0.433473 model2 loss : 0.021247
[00:01:54.886] iteration 12174 : model1 loss : 0.440495 model2 loss : 0.022773
[00:01:55.057] iteration 12175 : model1 loss : 0.442434 model2 loss : 0.025669
[00:01:55.233] iteration 12176 : model1 loss : 0.436141 model2 loss : 0.024298
[00:01:55.409] iteration 12177 : model1 loss : 0.437409 model2 loss : 0.024880
[00:01:55.587] iteration 12178 : model1 loss : 0.435100 model2 loss : 0.019681
[00:01:55.756] iteration 12179 : model1 loss : 0.435213 model2 loss : 0.023758
[00:01:55.932] iteration 12180 : model1 loss : 0.437547 model2 loss : 0.022144
[00:01:58.072] iteration 12181 : model1 loss : 0.434342 model2 loss : 0.020998
[00:01:58.245] iteration 12182 : model1 loss : 0.439482 model2 loss : 0.026191
[00:01:58.427] iteration 12183 : model1 loss : 0.439448 model2 loss : 0.023644
[00:01:58.604] iteration 12184 : model1 loss : 0.435970 model2 loss : 0.022274
[00:01:58.782] iteration 12185 : model1 loss : 0.436364 model2 loss : 0.021301
[00:01:58.955] iteration 12186 : model1 loss : 0.437895 model2 loss : 0.022087
[00:01:59.129] iteration 12187 : model1 loss : 0.433834 model2 loss : 0.020621
[00:01:59.303] iteration 12188 : model1 loss : 0.437378 model2 loss : 0.019796
[00:01:59.492] iteration 12189 : model1 loss : 0.436422 model2 loss : 0.022337
[00:01:59.662] iteration 12190 : model1 loss : 0.435423 model2 loss : 0.023086
[00:01:59.840] iteration 12191 : model1 loss : 0.437540 model2 loss : 0.022601
[00:02:00.009] iteration 12192 : model1 loss : 0.437912 model2 loss : 0.021394
[00:02:00.193] iteration 12193 : model1 loss : 0.433987 model2 loss : 0.020477
[00:02:00.367] iteration 12194 : model1 loss : 0.439295 model2 loss : 0.022851
[00:02:00.543] iteration 12195 : model1 loss : 0.440175 model2 loss : 0.024537
[00:02:00.713] iteration 12196 : model1 loss : 0.433439 model2 loss : 0.020209
[00:02:00.891] iteration 12197 : model1 loss : 0.441296 model2 loss : 0.019965
[00:02:01.061] iteration 12198 : model1 loss : 0.431858 model2 loss : 0.019250
[00:02:01.238] iteration 12199 : model1 loss : 0.435948 model2 loss : 0.020558
[00:02:01.411] iteration 12200 : model1 loss : 0.438644 model2 loss : 0.024384
[00:02:01.587] iteration 12201 : model1 loss : 0.436059 model2 loss : 0.021179
[00:02:03.727] iteration 12202 : model1 loss : 0.438695 model2 loss : 0.021615
[00:02:03.909] iteration 12203 : model1 loss : 0.434915 model2 loss : 0.018945
[00:02:04.084] iteration 12204 : model1 loss : 0.438689 model2 loss : 0.020651
[00:02:04.256] iteration 12205 : model1 loss : 0.439814 model2 loss : 0.022228
[00:02:04.432] iteration 12206 : model1 loss : 0.437820 model2 loss : 0.019476
[00:02:04.608] iteration 12207 : model1 loss : 0.434872 model2 loss : 0.022086
[00:02:04.782] iteration 12208 : model1 loss : 0.437296 model2 loss : 0.021271
[00:02:04.956] iteration 12209 : model1 loss : 0.435048 model2 loss : 0.021498
[00:02:05.131] iteration 12210 : model1 loss : 0.438325 model2 loss : 0.023151
[00:02:05.308] iteration 12211 : model1 loss : 0.437706 model2 loss : 0.021469
[00:02:05.486] iteration 12212 : model1 loss : 0.437165 model2 loss : 0.021977
[00:02:05.658] iteration 12213 : model1 loss : 0.432401 model2 loss : 0.021643
[00:02:05.837] iteration 12214 : model1 loss : 0.435002 model2 loss : 0.019142
[00:02:06.009] iteration 12215 : model1 loss : 0.437581 model2 loss : 0.019129
[00:02:06.187] iteration 12216 : model1 loss : 0.433578 model2 loss : 0.022040
[00:02:06.360] iteration 12217 : model1 loss : 0.439694 model2 loss : 0.022055
[00:02:06.539] iteration 12218 : model1 loss : 0.435217 model2 loss : 0.020433
[00:02:06.709] iteration 12219 : model1 loss : 0.437256 model2 loss : 0.023175
[00:02:06.885] iteration 12220 : model1 loss : 0.435206 model2 loss : 0.020496
[00:02:07.054] iteration 12221 : model1 loss : 0.438219 model2 loss : 0.022537
[00:02:07.228] iteration 12222 : model1 loss : 0.436096 model2 loss : 0.022985
[00:02:09.385] iteration 12223 : model1 loss : 0.440125 model2 loss : 0.020731
[00:02:09.558] iteration 12224 : model1 loss : 0.435351 model2 loss : 0.020767
[00:02:09.735] iteration 12225 : model1 loss : 0.436756 model2 loss : 0.023772
[00:02:09.908] iteration 12226 : model1 loss : 0.438212 model2 loss : 0.023184
[00:02:10.082] iteration 12227 : model1 loss : 0.437201 model2 loss : 0.023999
[00:02:10.253] iteration 12228 : model1 loss : 0.435516 model2 loss : 0.020171
[00:02:10.436] iteration 12229 : model1 loss : 0.433725 model2 loss : 0.021501
[00:02:10.609] iteration 12230 : model1 loss : 0.436438 model2 loss : 0.020864
[00:02:10.784] iteration 12231 : model1 loss : 0.437677 model2 loss : 0.020395
[00:02:10.957] iteration 12232 : model1 loss : 0.437040 model2 loss : 0.021390
[00:02:11.133] iteration 12233 : model1 loss : 0.432926 model2 loss : 0.017914
[00:02:11.307] iteration 12234 : model1 loss : 0.435841 model2 loss : 0.019650
[00:02:11.485] iteration 12235 : model1 loss : 0.437603 model2 loss : 0.020551
[00:02:11.657] iteration 12236 : model1 loss : 0.434786 model2 loss : 0.019501
[00:02:11.838] iteration 12237 : model1 loss : 0.435692 model2 loss : 0.021943
[00:02:12.009] iteration 12238 : model1 loss : 0.438062 model2 loss : 0.021207
[00:02:12.188] iteration 12239 : model1 loss : 0.435367 model2 loss : 0.020480
[00:02:12.361] iteration 12240 : model1 loss : 0.439159 model2 loss : 0.023255
[00:02:12.539] iteration 12241 : model1 loss : 0.438975 model2 loss : 0.021761
[00:02:12.710] iteration 12242 : model1 loss : 0.434855 model2 loss : 0.018469
[00:02:12.886] iteration 12243 : model1 loss : 0.440472 model2 loss : 0.020737
[00:02:15.013] iteration 12244 : model1 loss : 0.436201 model2 loss : 0.018715
[00:02:15.187] iteration 12245 : model1 loss : 0.438688 model2 loss : 0.021795
[00:02:15.368] iteration 12246 : model1 loss : 0.436066 model2 loss : 0.019808
[00:02:15.540] iteration 12247 : model1 loss : 0.436908 model2 loss : 0.020327
[00:02:15.716] iteration 12248 : model1 loss : 0.434335 model2 loss : 0.020420
[00:02:15.889] iteration 12249 : model1 loss : 0.436528 model2 loss : 0.022580
[00:02:16.065] iteration 12250 : model1 loss : 0.429491 model2 loss : 0.020783
[00:02:16.236] iteration 12251 : model1 loss : 0.434624 model2 loss : 0.020096
[00:02:16.413] iteration 12252 : model1 loss : 0.436152 model2 loss : 0.020249
[00:02:16.587] iteration 12253 : model1 loss : 0.438940 model2 loss : 0.022965
[00:02:16.762] iteration 12254 : model1 loss : 0.437908 model2 loss : 0.025558
[00:02:16.935] iteration 12255 : model1 loss : 0.432391 model2 loss : 0.021967
[00:02:17.111] iteration 12256 : model1 loss : 0.436822 model2 loss : 0.021715
[00:02:17.279] iteration 12257 : model1 loss : 0.435520 model2 loss : 0.021651
[00:02:17.462] iteration 12258 : model1 loss : 0.436393 model2 loss : 0.020273
[00:02:17.637] iteration 12259 : model1 loss : 0.436116 model2 loss : 0.020227
[00:02:17.816] iteration 12260 : model1 loss : 0.442585 model2 loss : 0.023752
[00:02:17.988] iteration 12261 : model1 loss : 0.441099 model2 loss : 0.023348
[00:02:18.167] iteration 12262 : model1 loss : 0.434472 model2 loss : 0.020825
[00:02:18.340] iteration 12263 : model1 loss : 0.438202 model2 loss : 0.022345
[00:02:18.513] iteration 12264 : model1 loss : 0.439793 model2 loss : 0.024536
[00:02:20.621] iteration 12265 : model1 loss : 0.437150 model2 loss : 0.024883
[00:02:20.792] iteration 12266 : model1 loss : 0.439333 model2 loss : 0.020466
[00:02:20.972] iteration 12267 : model1 loss : 0.437005 model2 loss : 0.020280
[00:02:21.143] iteration 12268 : model1 loss : 0.435770 model2 loss : 0.020788
[00:02:21.324] iteration 12269 : model1 loss : 0.437175 model2 loss : 0.021432
[00:02:21.497] iteration 12270 : model1 loss : 0.435293 model2 loss : 0.024017
[00:02:21.670] iteration 12271 : model1 loss : 0.432871 model2 loss : 0.018603
[00:02:21.843] iteration 12272 : model1 loss : 0.437223 model2 loss : 0.023207
[00:02:22.020] iteration 12273 : model1 loss : 0.436318 model2 loss : 0.024486
[00:02:22.192] iteration 12274 : model1 loss : 0.435649 model2 loss : 0.021306
[00:02:22.372] iteration 12275 : model1 loss : 0.437849 model2 loss : 0.019836
[00:02:22.543] iteration 12276 : model1 loss : 0.435132 model2 loss : 0.021856
[00:02:22.719] iteration 12277 : model1 loss : 0.437294 model2 loss : 0.021409
[00:02:22.893] iteration 12278 : model1 loss : 0.433832 model2 loss : 0.018277
[00:02:23.067] iteration 12279 : model1 loss : 0.435617 model2 loss : 0.018210
[00:02:23.238] iteration 12280 : model1 loss : 0.437630 model2 loss : 0.020685
[00:02:23.415] iteration 12281 : model1 loss : 0.437097 model2 loss : 0.021762
[00:02:23.589] iteration 12282 : model1 loss : 0.440629 model2 loss : 0.020282
[00:02:23.764] iteration 12283 : model1 loss : 0.434322 model2 loss : 0.021816
[00:02:23.937] iteration 12284 : model1 loss : 0.437977 model2 loss : 0.016499
[00:02:24.114] iteration 12285 : model1 loss : 0.436706 model2 loss : 0.021349
[00:02:26.216] iteration 12286 : model1 loss : 0.438319 model2 loss : 0.020163
[00:02:26.391] iteration 12287 : model1 loss : 0.437870 model2 loss : 0.022010
[00:02:26.567] iteration 12288 : model1 loss : 0.439462 model2 loss : 0.019620
[00:02:26.738] iteration 12289 : model1 loss : 0.436070 model2 loss : 0.022692
[00:02:26.914] iteration 12290 : model1 loss : 0.439170 model2 loss : 0.020618
[00:02:27.085] iteration 12291 : model1 loss : 0.435851 model2 loss : 0.019671
[00:02:27.264] iteration 12292 : model1 loss : 0.438123 model2 loss : 0.022240
[00:02:27.438] iteration 12293 : model1 loss : 0.432880 model2 loss : 0.020689
[00:02:27.620] iteration 12294 : model1 loss : 0.440610 model2 loss : 0.024090
[00:02:27.791] iteration 12295 : model1 loss : 0.439228 model2 loss : 0.019910
[00:02:27.969] iteration 12296 : model1 loss : 0.432618 model2 loss : 0.021233
[00:02:28.140] iteration 12297 : model1 loss : 0.437510 model2 loss : 0.023200
[00:02:28.320] iteration 12298 : model1 loss : 0.433662 model2 loss : 0.020368
[00:02:28.493] iteration 12299 : model1 loss : 0.436260 model2 loss : 0.025060
[00:02:28.669] iteration 12300 : model1 loss : 0.440372 model2 loss : 0.026985
[00:02:28.842] iteration 12301 : model1 loss : 0.435081 model2 loss : 0.022971
[00:02:29.019] iteration 12302 : model1 loss : 0.439473 model2 loss : 0.021558
[00:02:29.190] iteration 12303 : model1 loss : 0.443719 model2 loss : 0.026074
[00:02:29.370] iteration 12304 : model1 loss : 0.432780 model2 loss : 0.020795
[00:02:29.541] iteration 12305 : model1 loss : 0.430921 model2 loss : 0.020142
[00:02:29.714] iteration 12306 : model1 loss : 0.436003 model2 loss : 0.022468
[00:02:31.860] iteration 12307 : model1 loss : 0.438516 model2 loss : 0.022193
[00:02:32.037] iteration 12308 : model1 loss : 0.444033 model2 loss : 0.023567
[00:02:32.217] iteration 12309 : model1 loss : 0.434632 model2 loss : 0.019157
[00:02:32.392] iteration 12310 : model1 loss : 0.438510 model2 loss : 0.021554
[00:02:32.571] iteration 12311 : model1 loss : 0.434112 model2 loss : 0.019864
[00:02:32.740] iteration 12312 : model1 loss : 0.432676 model2 loss : 0.020685
[00:02:32.915] iteration 12313 : model1 loss : 0.439422 model2 loss : 0.021087
[00:02:33.087] iteration 12314 : model1 loss : 0.435143 model2 loss : 0.022480
[00:02:33.261] iteration 12315 : model1 loss : 0.431858 model2 loss : 0.020544
[00:02:33.435] iteration 12316 : model1 loss : 0.430272 model2 loss : 0.018659
[00:02:33.612] iteration 12317 : model1 loss : 0.433891 model2 loss : 0.020593
[00:02:33.784] iteration 12318 : model1 loss : 0.437308 model2 loss : 0.021151
[00:02:33.961] iteration 12319 : model1 loss : 0.440726 model2 loss : 0.021545
[00:02:34.134] iteration 12320 : model1 loss : 0.439420 model2 loss : 0.020606
[00:02:34.308] iteration 12321 : model1 loss : 0.438794 model2 loss : 0.020342
[00:02:34.480] iteration 12322 : model1 loss : 0.435814 model2 loss : 0.021198
[00:02:34.661] iteration 12323 : model1 loss : 0.439998 model2 loss : 0.022879
[00:02:34.832] iteration 12324 : model1 loss : 0.438950 model2 loss : 0.025315
[00:02:35.011] iteration 12325 : model1 loss : 0.434324 model2 loss : 0.020518
[00:02:35.181] iteration 12326 : model1 loss : 0.438946 model2 loss : 0.021317
[00:02:35.359] iteration 12327 : model1 loss : 0.434237 model2 loss : 0.022022
[00:02:37.547] iteration 12328 : model1 loss : 0.434965 model2 loss : 0.019230
[00:02:37.720] iteration 12329 : model1 loss : 0.438752 model2 loss : 0.020357
[00:02:37.900] iteration 12330 : model1 loss : 0.436922 model2 loss : 0.022269
[00:02:38.073] iteration 12331 : model1 loss : 0.436096 model2 loss : 0.022788
[00:02:38.247] iteration 12332 : model1 loss : 0.434792 model2 loss : 0.021771
[00:02:38.422] iteration 12333 : model1 loss : 0.441732 model2 loss : 0.023467
[00:02:38.602] iteration 12334 : model1 loss : 0.431706 model2 loss : 0.021129
[00:02:38.773] iteration 12335 : model1 loss : 0.436177 model2 loss : 0.019775
[00:02:38.949] iteration 12336 : model1 loss : 0.435120 model2 loss : 0.020368
[00:02:39.121] iteration 12337 : model1 loss : 0.438523 model2 loss : 0.021082
[00:02:39.299] iteration 12338 : model1 loss : 0.439738 model2 loss : 0.020960
[00:02:39.472] iteration 12339 : model1 loss : 0.432300 model2 loss : 0.018595
[00:02:39.654] iteration 12340 : model1 loss : 0.437625 model2 loss : 0.018822
[00:02:39.824] iteration 12341 : model1 loss : 0.440899 model2 loss : 0.019453
[00:02:40.001] iteration 12342 : model1 loss : 0.436956 model2 loss : 0.021400
[00:02:40.172] iteration 12343 : model1 loss : 0.439379 model2 loss : 0.022030
[00:02:40.350] iteration 12344 : model1 loss : 0.435019 model2 loss : 0.023552
[00:02:40.523] iteration 12345 : model1 loss : 0.435100 model2 loss : 0.021899
[00:02:40.700] iteration 12346 : model1 loss : 0.438342 model2 loss : 0.021287
[00:02:40.870] iteration 12347 : model1 loss : 0.435128 model2 loss : 0.020711
[00:02:41.044] iteration 12348 : model1 loss : 0.431777 model2 loss : 0.021098
[00:02:43.180] iteration 12349 : model1 loss : 0.438096 model2 loss : 0.023824
[00:02:43.352] iteration 12350 : model1 loss : 0.440862 model2 loss : 0.021848
[00:02:43.531] iteration 12351 : model1 loss : 0.437996 model2 loss : 0.021374
[00:02:43.703] iteration 12352 : model1 loss : 0.437303 model2 loss : 0.020916
[00:02:43.880] iteration 12353 : model1 loss : 0.437572 model2 loss : 0.022493
[00:02:44.051] iteration 12354 : model1 loss : 0.433392 model2 loss : 0.020119
[00:02:44.228] iteration 12355 : model1 loss : 0.432731 model2 loss : 0.018436
[00:02:44.404] iteration 12356 : model1 loss : 0.440446 model2 loss : 0.024279
[00:02:44.584] iteration 12357 : model1 loss : 0.438917 model2 loss : 0.019823
[00:02:44.754] iteration 12358 : model1 loss : 0.436897 model2 loss : 0.021777
[00:02:44.932] iteration 12359 : model1 loss : 0.434381 model2 loss : 0.020147
[00:02:45.103] iteration 12360 : model1 loss : 0.441079 model2 loss : 0.020928
[00:02:45.278] iteration 12361 : model1 loss : 0.436912 model2 loss : 0.020715
[00:02:45.450] iteration 12362 : model1 loss : 0.437575 model2 loss : 0.024257
[00:02:45.631] iteration 12363 : model1 loss : 0.437766 model2 loss : 0.021955
[00:02:45.803] iteration 12364 : model1 loss : 0.436008 model2 loss : 0.021103
[00:02:45.975] iteration 12365 : model1 loss : 0.433545 model2 loss : 0.020613
[00:02:46.147] iteration 12366 : model1 loss : 0.435880 model2 loss : 0.022189
[00:02:46.327] iteration 12367 : model1 loss : 0.431772 model2 loss : 0.020633
[00:02:46.499] iteration 12368 : model1 loss : 0.438687 model2 loss : 0.020386
[00:02:46.675] iteration 12369 : model1 loss : 0.435487 model2 loss : 0.021311
[00:02:48.786] iteration 12370 : model1 loss : 0.437771 model2 loss : 0.019481
[00:02:48.967] iteration 12371 : model1 loss : 0.435867 model2 loss : 0.019213
[00:02:49.143] iteration 12372 : model1 loss : 0.433522 model2 loss : 0.020263
[00:02:49.315] iteration 12373 : model1 loss : 0.440107 model2 loss : 0.019157
[00:02:49.496] iteration 12374 : model1 loss : 0.437223 model2 loss : 0.019829
[00:02:49.668] iteration 12375 : model1 loss : 0.432243 model2 loss : 0.020813
[00:02:49.843] iteration 12376 : model1 loss : 0.429327 model2 loss : 0.018595
[00:02:50.015] iteration 12377 : model1 loss : 0.431417 model2 loss : 0.018931
[00:02:50.195] iteration 12378 : model1 loss : 0.437766 model2 loss : 0.021295
[00:02:50.369] iteration 12379 : model1 loss : 0.439369 model2 loss : 0.019972
[00:02:50.545] iteration 12380 : model1 loss : 0.440338 model2 loss : 0.021975
[00:02:50.715] iteration 12381 : model1 loss : 0.435441 model2 loss : 0.019337
[00:02:50.893] iteration 12382 : model1 loss : 0.436831 model2 loss : 0.020917
[00:02:51.065] iteration 12383 : model1 loss : 0.438845 model2 loss : 0.020549
[00:02:51.241] iteration 12384 : model1 loss : 0.436995 model2 loss : 0.021297
[00:02:51.415] iteration 12385 : model1 loss : 0.435994 model2 loss : 0.021845
[00:02:51.594] iteration 12386 : model1 loss : 0.438532 model2 loss : 0.020937
[00:02:51.767] iteration 12387 : model1 loss : 0.436555 model2 loss : 0.021142
[00:02:51.945] iteration 12388 : model1 loss : 0.435601 model2 loss : 0.022379
[00:02:52.118] iteration 12389 : model1 loss : 0.437411 model2 loss : 0.023228
[00:02:52.295] iteration 12390 : model1 loss : 0.437932 model2 loss : 0.021566
[00:02:54.474] iteration 12391 : model1 loss : 0.437007 model2 loss : 0.023985
[00:02:54.645] iteration 12392 : model1 loss : 0.441297 model2 loss : 0.021959
[00:02:54.824] iteration 12393 : model1 loss : 0.433969 model2 loss : 0.022077
[00:02:54.998] iteration 12394 : model1 loss : 0.438746 model2 loss : 0.019643
[00:02:55.171] iteration 12395 : model1 loss : 0.438779 model2 loss : 0.023211
[00:02:55.344] iteration 12396 : model1 loss : 0.438142 model2 loss : 0.021791
[00:02:55.523] iteration 12397 : model1 loss : 0.433740 model2 loss : 0.021771
[00:02:55.693] iteration 12398 : model1 loss : 0.436564 model2 loss : 0.017786
[00:02:55.869] iteration 12399 : model1 loss : 0.435536 model2 loss : 0.021314
[00:02:56.042] iteration 12400 : model1 loss : 0.437879 model2 loss : 0.022166
[00:02:56.220] iteration 12401 : model1 loss : 0.434728 model2 loss : 0.022255
[00:02:56.392] iteration 12402 : model1 loss : 0.437246 model2 loss : 0.023230
[00:02:56.569] iteration 12403 : model1 loss : 0.435404 model2 loss : 0.020804
[00:02:56.739] iteration 12404 : model1 loss : 0.432607 model2 loss : 0.017937
[00:02:56.917] iteration 12405 : model1 loss : 0.435082 model2 loss : 0.021017
[00:02:57.090] iteration 12406 : model1 loss : 0.434962 model2 loss : 0.019728
[00:02:57.266] iteration 12407 : model1 loss : 0.439625 model2 loss : 0.024374
[00:02:57.441] iteration 12408 : model1 loss : 0.435659 model2 loss : 0.019831
[00:02:57.621] iteration 12409 : model1 loss : 0.440042 model2 loss : 0.019370
[00:02:57.790] iteration 12410 : model1 loss : 0.435949 model2 loss : 0.022086
[00:02:57.966] iteration 12411 : model1 loss : 0.434906 model2 loss : 0.020108
[00:03:00.089] iteration 12412 : model1 loss : 0.435045 model2 loss : 0.018174
[00:03:00.265] iteration 12413 : model1 loss : 0.440036 model2 loss : 0.023873
[00:03:00.444] iteration 12414 : model1 loss : 0.440291 model2 loss : 0.022892
[00:03:00.616] iteration 12415 : model1 loss : 0.433951 model2 loss : 0.020752
[00:03:00.794] iteration 12416 : model1 loss : 0.437592 model2 loss : 0.020684
[00:03:00.966] iteration 12417 : model1 loss : 0.428996 model2 loss : 0.019046
[00:03:01.143] iteration 12418 : model1 loss : 0.440261 model2 loss : 0.021159
[00:03:01.315] iteration 12419 : model1 loss : 0.436102 model2 loss : 0.021799
[00:03:01.495] iteration 12420 : model1 loss : 0.435405 model2 loss : 0.021320
[00:03:01.666] iteration 12421 : model1 loss : 0.438604 model2 loss : 0.020710
[00:03:01.840] iteration 12422 : model1 loss : 0.435411 model2 loss : 0.022170
[00:03:02.012] iteration 12423 : model1 loss : 0.443438 model2 loss : 0.024166
[00:03:02.191] iteration 12424 : model1 loss : 0.437739 model2 loss : 0.019378
[00:03:02.365] iteration 12425 : model1 loss : 0.435902 model2 loss : 0.018801
[00:03:02.545] iteration 12426 : model1 loss : 0.438408 model2 loss : 0.022587
[00:03:02.715] iteration 12427 : model1 loss : 0.438333 model2 loss : 0.023420
[00:03:02.893] iteration 12428 : model1 loss : 0.438016 model2 loss : 0.022805
[00:03:03.066] iteration 12429 : model1 loss : 0.443078 model2 loss : 0.022731
[00:03:03.241] iteration 12430 : model1 loss : 0.437343 model2 loss : 0.019539
[00:03:03.414] iteration 12431 : model1 loss : 0.437266 model2 loss : 0.020751
[00:03:03.591] iteration 12432 : model1 loss : 0.441450 model2 loss : 0.021971
[00:03:05.725] iteration 12433 : model1 loss : 0.434435 model2 loss : 0.020243
[00:03:05.900] iteration 12434 : model1 loss : 0.438328 model2 loss : 0.021085
[00:03:06.083] iteration 12435 : model1 loss : 0.437040 model2 loss : 0.021381
[00:03:06.254] iteration 12436 : model1 loss : 0.436707 model2 loss : 0.021046
[00:03:06.431] iteration 12437 : model1 loss : 0.438222 model2 loss : 0.021992
[00:03:06.609] iteration 12438 : model1 loss : 0.433482 model2 loss : 0.021696
[00:03:06.785] iteration 12439 : model1 loss : 0.437112 model2 loss : 0.019733
[00:03:06.958] iteration 12440 : model1 loss : 0.435940 model2 loss : 0.022568
[00:03:07.133] iteration 12441 : model1 loss : 0.437733 model2 loss : 0.025434
[00:03:07.307] iteration 12442 : model1 loss : 0.434167 model2 loss : 0.020600
[00:03:07.490] iteration 12443 : model1 loss : 0.437736 model2 loss : 0.024869
[00:03:07.663] iteration 12444 : model1 loss : 0.439582 model2 loss : 0.023387
[00:03:07.838] iteration 12445 : model1 loss : 0.439356 model2 loss : 0.021555
[00:03:08.011] iteration 12446 : model1 loss : 0.439699 model2 loss : 0.023255
[00:03:08.193] iteration 12447 : model1 loss : 0.439507 model2 loss : 0.021644
[00:03:08.385] iteration 12448 : model1 loss : 0.433485 model2 loss : 0.019909
[00:03:08.565] iteration 12449 : model1 loss : 0.434869 model2 loss : 0.021851
[00:03:08.735] iteration 12450 : model1 loss : 0.438442 model2 loss : 0.019870
[00:03:08.917] iteration 12451 : model1 loss : 0.442644 model2 loss : 0.024286
[00:03:09.090] iteration 12452 : model1 loss : 0.437801 model2 loss : 0.020688
[00:03:09.265] iteration 12453 : model1 loss : 0.437511 model2 loss : 0.019736
[00:03:11.395] iteration 12454 : model1 loss : 0.439550 model2 loss : 0.021350
[00:03:11.571] iteration 12455 : model1 loss : 0.436015 model2 loss : 0.021763
[00:03:11.750] iteration 12456 : model1 loss : 0.435371 model2 loss : 0.019674
[00:03:11.922] iteration 12457 : model1 loss : 0.440371 model2 loss : 0.022965
[00:03:12.101] iteration 12458 : model1 loss : 0.436666 model2 loss : 0.019515
[00:03:12.273] iteration 12459 : model1 loss : 0.432721 model2 loss : 0.018114
[00:03:12.454] iteration 12460 : model1 loss : 0.434371 model2 loss : 0.019348
[00:03:12.628] iteration 12461 : model1 loss : 0.435046 model2 loss : 0.020191
[00:03:12.803] iteration 12462 : model1 loss : 0.436952 model2 loss : 0.025501
[00:03:12.975] iteration 12463 : model1 loss : 0.438796 model2 loss : 0.024224
[00:03:13.150] iteration 12464 : model1 loss : 0.438163 model2 loss : 0.022830
[00:03:13.325] iteration 12465 : model1 loss : 0.439355 model2 loss : 0.021629
[00:03:13.508] iteration 12466 : model1 loss : 0.433925 model2 loss : 0.020089
[00:03:13.680] iteration 12467 : model1 loss : 0.437501 model2 loss : 0.018868
[00:03:13.856] iteration 12468 : model1 loss : 0.434794 model2 loss : 0.020068
[00:03:14.029] iteration 12469 : model1 loss : 0.437725 model2 loss : 0.021974
[00:03:14.208] iteration 12470 : model1 loss : 0.437698 model2 loss : 0.021074
[00:03:14.384] iteration 12471 : model1 loss : 0.439749 model2 loss : 0.022825
[00:03:14.564] iteration 12472 : model1 loss : 0.440192 model2 loss : 0.022552
[00:03:14.735] iteration 12473 : model1 loss : 0.439888 model2 loss : 0.021318
[00:03:14.909] iteration 12474 : model1 loss : 0.432781 model2 loss : 0.020158
[00:03:17.063] iteration 12475 : model1 loss : 0.438052 model2 loss : 0.023417
[00:03:17.234] iteration 12476 : model1 loss : 0.437079 model2 loss : 0.022576
[00:03:17.413] iteration 12477 : model1 loss : 0.437005 model2 loss : 0.024381
[00:03:17.589] iteration 12478 : model1 loss : 0.440580 model2 loss : 0.026437
[00:03:17.764] iteration 12479 : model1 loss : 0.435348 model2 loss : 0.021719
[00:03:17.937] iteration 12480 : model1 loss : 0.436490 model2 loss : 0.021501
[00:03:18.112] iteration 12481 : model1 loss : 0.444030 model2 loss : 0.027298
[00:03:18.283] iteration 12482 : model1 loss : 0.435494 model2 loss : 0.021121
[00:03:18.463] iteration 12483 : model1 loss : 0.436569 model2 loss : 0.023840
[00:03:18.633] iteration 12484 : model1 loss : 0.437453 model2 loss : 0.021803
[00:03:18.809] iteration 12485 : model1 loss : 0.438952 model2 loss : 0.020892
[00:03:18.984] iteration 12486 : model1 loss : 0.436219 model2 loss : 0.022095
[00:03:19.163] iteration 12487 : model1 loss : 0.434142 model2 loss : 0.020997
[00:03:19.339] iteration 12488 : model1 loss : 0.437112 model2 loss : 0.019178
[00:03:19.517] iteration 12489 : model1 loss : 0.437258 model2 loss : 0.020176
[00:03:19.687] iteration 12490 : model1 loss : 0.434128 model2 loss : 0.018523
[00:03:19.863] iteration 12491 : model1 loss : 0.434026 model2 loss : 0.023712
[00:03:20.036] iteration 12492 : model1 loss : 0.435970 model2 loss : 0.021001
[00:03:20.211] iteration 12493 : model1 loss : 0.436176 model2 loss : 0.021370
[00:03:20.383] iteration 12494 : model1 loss : 0.435470 model2 loss : 0.020001
[00:03:20.563] iteration 12495 : model1 loss : 0.437971 model2 loss : 0.022336
[00:03:22.690] iteration 12496 : model1 loss : 0.442812 model2 loss : 0.023356
[00:03:22.868] iteration 12497 : model1 loss : 0.435170 model2 loss : 0.019834
[00:03:23.047] iteration 12498 : model1 loss : 0.436426 model2 loss : 0.020419
[00:03:23.217] iteration 12499 : model1 loss : 0.434363 model2 loss : 0.021802
[00:03:23.395] iteration 12500 : model1 loss : 0.433352 model2 loss : 0.021067
[00:03:23.570] iteration 12501 : model1 loss : 0.437554 model2 loss : 0.024515
[00:03:23.747] iteration 12502 : model1 loss : 0.435788 model2 loss : 0.020814
[00:03:23.917] iteration 12503 : model1 loss : 0.438548 model2 loss : 0.019076
[00:03:24.096] iteration 12504 : model1 loss : 0.438603 model2 loss : 0.024154
[00:03:24.265] iteration 12505 : model1 loss : 0.436755 model2 loss : 0.020604
[00:03:24.444] iteration 12506 : model1 loss : 0.435683 model2 loss : 0.022780
[00:03:24.619] iteration 12507 : model1 loss : 0.436715 model2 loss : 0.021242
[00:03:24.796] iteration 12508 : model1 loss : 0.436789 model2 loss : 0.022020
[00:03:24.971] iteration 12509 : model1 loss : 0.438551 model2 loss : 0.024546
[00:03:25.148] iteration 12510 : model1 loss : 0.439616 model2 loss : 0.024030
[00:03:25.320] iteration 12511 : model1 loss : 0.437608 model2 loss : 0.021914
[00:03:25.499] iteration 12512 : model1 loss : 0.435075 model2 loss : 0.022332
[00:03:25.671] iteration 12513 : model1 loss : 0.436615 model2 loss : 0.021450
[00:03:25.846] iteration 12514 : model1 loss : 0.436714 model2 loss : 0.021438
[00:03:26.017] iteration 12515 : model1 loss : 0.433622 model2 loss : 0.018289
[00:03:26.198] iteration 12516 : model1 loss : 0.436015 model2 loss : 0.021208
[00:03:28.334] iteration 12517 : model1 loss : 0.439876 model2 loss : 0.025056
[00:03:28.509] iteration 12518 : model1 loss : 0.441084 model2 loss : 0.024332
[00:03:28.685] iteration 12519 : model1 loss : 0.436160 model2 loss : 0.022962
[00:03:28.855] iteration 12520 : model1 loss : 0.439147 model2 loss : 0.021937
[00:03:29.032] iteration 12521 : model1 loss : 0.432686 model2 loss : 0.018171
[00:03:29.204] iteration 12522 : model1 loss : 0.437786 model2 loss : 0.022393
[00:03:29.379] iteration 12523 : model1 loss : 0.440412 model2 loss : 0.023364
[00:03:29.554] iteration 12524 : model1 loss : 0.437054 model2 loss : 0.023317
[00:03:29.729] iteration 12525 : model1 loss : 0.433502 model2 loss : 0.018397
[00:03:29.900] iteration 12526 : model1 loss : 0.440835 model2 loss : 0.021867
[00:03:30.080] iteration 12527 : model1 loss : 0.432796 model2 loss : 0.020680
[00:03:30.253] iteration 12528 : model1 loss : 0.438079 model2 loss : 0.024765
[00:03:30.430] iteration 12529 : model1 loss : 0.434660 model2 loss : 0.019201
[00:03:30.608] iteration 12530 : model1 loss : 0.434010 model2 loss : 0.020794
[00:03:30.783] iteration 12531 : model1 loss : 0.439361 model2 loss : 0.025717
[00:03:30.956] iteration 12532 : model1 loss : 0.434926 model2 loss : 0.021283
[00:03:31.136] iteration 12533 : model1 loss : 0.435939 model2 loss : 0.022334
[00:03:31.308] iteration 12534 : model1 loss : 0.435279 model2 loss : 0.019877
[00:03:31.486] iteration 12535 : model1 loss : 0.441706 model2 loss : 0.023774
[00:03:31.661] iteration 12536 : model1 loss : 0.433011 model2 loss : 0.019801
[00:03:31.837] iteration 12537 : model1 loss : 0.432931 model2 loss : 0.019048
[00:03:33.953] iteration 12538 : model1 loss : 0.431011 model2 loss : 0.017306
[00:03:34.131] iteration 12539 : model1 loss : 0.440245 model2 loss : 0.023731
[00:03:34.309] iteration 12540 : model1 loss : 0.433629 model2 loss : 0.019139
[00:03:34.483] iteration 12541 : model1 loss : 0.436326 model2 loss : 0.022405
[00:03:34.659] iteration 12542 : model1 loss : 0.435645 model2 loss : 0.021843
[00:03:34.830] iteration 12543 : model1 loss : 0.433356 model2 loss : 0.020577
[00:03:35.008] iteration 12544 : model1 loss : 0.436324 model2 loss : 0.020382
[00:03:35.180] iteration 12545 : model1 loss : 0.438510 model2 loss : 0.022381
[00:03:35.364] iteration 12546 : model1 loss : 0.436888 model2 loss : 0.022194
[00:03:35.537] iteration 12547 : model1 loss : 0.438462 model2 loss : 0.020537
[00:03:35.713] iteration 12548 : model1 loss : 0.433896 model2 loss : 0.018256
[00:03:35.885] iteration 12549 : model1 loss : 0.437645 model2 loss : 0.020392
[00:03:36.059] iteration 12550 : model1 loss : 0.437383 model2 loss : 0.022358
[00:03:36.230] iteration 12551 : model1 loss : 0.439434 model2 loss : 0.022627
[00:03:36.405] iteration 12552 : model1 loss : 0.440710 model2 loss : 0.023085
[00:03:36.581] iteration 12553 : model1 loss : 0.436629 model2 loss : 0.021514
[00:03:36.757] iteration 12554 : model1 loss : 0.436873 model2 loss : 0.021365
[00:03:36.928] iteration 12555 : model1 loss : 0.434893 model2 loss : 0.020438
[00:03:37.106] iteration 12556 : model1 loss : 0.438847 model2 loss : 0.022170
[00:03:37.276] iteration 12557 : model1 loss : 0.434748 model2 loss : 0.019243
[00:03:37.453] iteration 12558 : model1 loss : 0.436240 model2 loss : 0.019488
[00:03:39.629] iteration 12559 : model1 loss : 0.437371 model2 loss : 0.022297
[00:03:39.805] iteration 12560 : model1 loss : 0.437687 model2 loss : 0.016251
[00:03:39.989] iteration 12561 : model1 loss : 0.437640 model2 loss : 0.019485
[00:03:40.161] iteration 12562 : model1 loss : 0.436089 model2 loss : 0.022372
[00:03:40.344] iteration 12563 : model1 loss : 0.434731 model2 loss : 0.020642
[00:03:40.518] iteration 12564 : model1 loss : 0.436374 model2 loss : 0.020338
[00:03:40.694] iteration 12565 : model1 loss : 0.436518 model2 loss : 0.022170
[00:03:40.866] iteration 12566 : model1 loss : 0.433339 model2 loss : 0.020312
[00:03:41.042] iteration 12567 : model1 loss : 0.437998 model2 loss : 0.020829
[00:03:41.212] iteration 12568 : model1 loss : 0.440449 model2 loss : 0.021904
[00:03:41.389] iteration 12569 : model1 loss : 0.436589 model2 loss : 0.020384
[00:03:41.564] iteration 12570 : model1 loss : 0.432463 model2 loss : 0.019391
[00:03:41.741] iteration 12571 : model1 loss : 0.437927 model2 loss : 0.019406
[00:03:41.915] iteration 12572 : model1 loss : 0.437310 model2 loss : 0.020814
[00:03:42.092] iteration 12573 : model1 loss : 0.434615 model2 loss : 0.020011
[00:03:42.264] iteration 12574 : model1 loss : 0.436154 model2 loss : 0.021686
[00:03:42.443] iteration 12575 : model1 loss : 0.435167 model2 loss : 0.021229
[00:03:42.619] iteration 12576 : model1 loss : 0.437233 model2 loss : 0.021505
[00:03:42.795] iteration 12577 : model1 loss : 0.438461 model2 loss : 0.019732
[00:03:42.969] iteration 12578 : model1 loss : 0.436993 model2 loss : 0.019852
[00:03:43.143] iteration 12579 : model1 loss : 0.436932 model2 loss : 0.021813
[00:03:45.268] iteration 12580 : model1 loss : 0.438273 model2 loss : 0.019807
[00:03:45.440] iteration 12581 : model1 loss : 0.433247 model2 loss : 0.021135
[00:03:45.622] iteration 12582 : model1 loss : 0.435275 model2 loss : 0.022593
[00:03:45.792] iteration 12583 : model1 loss : 0.437707 model2 loss : 0.022987
[00:03:45.971] iteration 12584 : model1 loss : 0.439586 model2 loss : 0.018321
[00:03:46.144] iteration 12585 : model1 loss : 0.437166 model2 loss : 0.022210
[00:03:46.320] iteration 12586 : model1 loss : 0.434004 model2 loss : 0.021977
[00:03:46.494] iteration 12587 : model1 loss : 0.437574 model2 loss : 0.019604
[00:03:46.672] iteration 12588 : model1 loss : 0.433345 model2 loss : 0.018800
[00:03:46.843] iteration 12589 : model1 loss : 0.436886 model2 loss : 0.021081
[00:03:47.018] iteration 12590 : model1 loss : 0.435569 model2 loss : 0.021110
[00:03:47.191] iteration 12591 : model1 loss : 0.433499 model2 loss : 0.020467
[00:03:47.367] iteration 12592 : model1 loss : 0.438655 model2 loss : 0.023028
[00:03:47.543] iteration 12593 : model1 loss : 0.441457 model2 loss : 0.023540
[00:03:47.719] iteration 12594 : model1 loss : 0.437704 model2 loss : 0.020612
[00:03:47.891] iteration 12595 : model1 loss : 0.440634 model2 loss : 0.023852
[00:03:48.067] iteration 12596 : model1 loss : 0.434093 model2 loss : 0.021163
[00:03:48.239] iteration 12597 : model1 loss : 0.432574 model2 loss : 0.019109
[00:03:48.416] iteration 12598 : model1 loss : 0.439530 model2 loss : 0.020786
[00:03:48.591] iteration 12599 : model1 loss : 0.434019 model2 loss : 0.019925
[00:03:48.766] iteration 12600 : model1 loss : 0.437680 model2 loss : 0.023218
[00:03:50.892] iteration 12601 : model1 loss : 0.434197 model2 loss : 0.020377
[00:03:51.067] iteration 12602 : model1 loss : 0.440968 model2 loss : 0.023874
[00:03:51.244] iteration 12603 : model1 loss : 0.437093 model2 loss : 0.022075
[00:03:51.416] iteration 12604 : model1 loss : 0.435480 model2 loss : 0.019491
[00:03:51.597] iteration 12605 : model1 loss : 0.434420 model2 loss : 0.018311
[00:03:51.769] iteration 12606 : model1 loss : 0.436732 model2 loss : 0.021924
[00:03:51.945] iteration 12607 : model1 loss : 0.436486 model2 loss : 0.018381
[00:03:52.124] iteration 12608 : model1 loss : 0.436532 model2 loss : 0.018930
[00:03:52.302] iteration 12609 : model1 loss : 0.438157 model2 loss : 0.019841
[00:03:52.479] iteration 12610 : model1 loss : 0.433079 model2 loss : 0.020157
[00:03:52.658] iteration 12611 : model1 loss : 0.438988 model2 loss : 0.023461
[00:03:52.827] iteration 12612 : model1 loss : 0.436658 model2 loss : 0.021732
[00:03:53.004] iteration 12613 : model1 loss : 0.435333 model2 loss : 0.019628
[00:03:53.177] iteration 12614 : model1 loss : 0.437688 model2 loss : 0.022480
[00:03:53.357] iteration 12615 : model1 loss : 0.436279 model2 loss : 0.020244
[00:03:53.529] iteration 12616 : model1 loss : 0.434018 model2 loss : 0.019673
[00:03:53.706] iteration 12617 : model1 loss : 0.438358 model2 loss : 0.021692
[00:03:53.876] iteration 12618 : model1 loss : 0.435777 model2 loss : 0.020549
[00:03:54.055] iteration 12619 : model1 loss : 0.436008 model2 loss : 0.021148
[00:03:54.224] iteration 12620 : model1 loss : 0.438775 model2 loss : 0.022916
[00:03:54.398] iteration 12621 : model1 loss : 0.432837 model2 loss : 0.020477
[00:03:56.544] iteration 12622 : model1 loss : 0.436903 model2 loss : 0.021191
[00:03:56.715] iteration 12623 : model1 loss : 0.438525 model2 loss : 0.021351
[00:03:56.895] iteration 12624 : model1 loss : 0.436908 model2 loss : 0.021887
[00:03:57.069] iteration 12625 : model1 loss : 0.433899 model2 loss : 0.021206
[00:03:57.245] iteration 12626 : model1 loss : 0.432577 model2 loss : 0.020352
[00:03:57.419] iteration 12627 : model1 loss : 0.434494 model2 loss : 0.020772
[00:03:57.601] iteration 12628 : model1 loss : 0.434556 model2 loss : 0.019806
[00:03:57.772] iteration 12629 : model1 loss : 0.442261 model2 loss : 0.026306
[00:03:57.949] iteration 12630 : model1 loss : 0.434012 model2 loss : 0.022023
[00:03:58.124] iteration 12631 : model1 loss : 0.436020 model2 loss : 0.022885
[00:03:58.302] iteration 12632 : model1 loss : 0.436954 model2 loss : 0.021588
[00:03:58.474] iteration 12633 : model1 loss : 0.436846 model2 loss : 0.020537
[00:03:58.655] iteration 12634 : model1 loss : 0.438471 model2 loss : 0.022028
[00:03:58.826] iteration 12635 : model1 loss : 0.434758 model2 loss : 0.021434
[00:03:59.003] iteration 12636 : model1 loss : 0.437828 model2 loss : 0.021352
[00:03:59.176] iteration 12637 : model1 loss : 0.435542 model2 loss : 0.018401
[00:03:59.354] iteration 12638 : model1 loss : 0.433782 model2 loss : 0.020454
[00:03:59.529] iteration 12639 : model1 loss : 0.442262 model2 loss : 0.022409
[00:03:59.704] iteration 12640 : model1 loss : 0.437474 model2 loss : 0.020365
[00:03:59.875] iteration 12641 : model1 loss : 0.436024 model2 loss : 0.020787
[00:04:00.052] iteration 12642 : model1 loss : 0.438348 model2 loss : 0.019633
[00:04:02.203] iteration 12643 : model1 loss : 0.434551 model2 loss : 0.020412
[00:04:02.378] iteration 12644 : model1 loss : 0.439919 model2 loss : 0.021469
[00:04:02.557] iteration 12645 : model1 loss : 0.435015 model2 loss : 0.020289
[00:04:02.728] iteration 12646 : model1 loss : 0.436163 model2 loss : 0.022863
[00:04:02.901] iteration 12647 : model1 loss : 0.436333 model2 loss : 0.021984
[00:04:03.075] iteration 12648 : model1 loss : 0.435490 model2 loss : 0.018775
[00:04:03.251] iteration 12649 : model1 loss : 0.437987 model2 loss : 0.018979
[00:04:03.425] iteration 12650 : model1 loss : 0.435125 model2 loss : 0.019553
[00:04:03.604] iteration 12651 : model1 loss : 0.438746 model2 loss : 0.023743
[00:04:03.774] iteration 12652 : model1 loss : 0.435968 model2 loss : 0.020924
[00:04:03.951] iteration 12653 : model1 loss : 0.439002 model2 loss : 0.020949
[00:04:04.128] iteration 12654 : model1 loss : 0.433922 model2 loss : 0.020403
[00:04:04.306] iteration 12655 : model1 loss : 0.436677 model2 loss : 0.023063
[00:04:04.479] iteration 12656 : model1 loss : 0.437569 model2 loss : 0.019552
[00:04:04.660] iteration 12657 : model1 loss : 0.437761 model2 loss : 0.021286
[00:04:04.832] iteration 12658 : model1 loss : 0.442741 model2 loss : 0.034216
[00:04:05.008] iteration 12659 : model1 loss : 0.431670 model2 loss : 0.020001
[00:04:05.182] iteration 12660 : model1 loss : 0.436718 model2 loss : 0.024986
[00:04:05.362] iteration 12661 : model1 loss : 0.439586 model2 loss : 0.033683
[00:04:05.535] iteration 12662 : model1 loss : 0.435242 model2 loss : 0.023322
[00:04:05.711] iteration 12663 : model1 loss : 0.437741 model2 loss : 0.024019
[00:04:07.894] iteration 12664 : model1 loss : 0.442419 model2 loss : 0.031816
[00:04:08.067] iteration 12665 : model1 loss : 0.439432 model2 loss : 0.025478
[00:04:08.244] iteration 12666 : model1 loss : 0.437746 model2 loss : 0.041396
[00:04:08.418] iteration 12667 : model1 loss : 0.437826 model2 loss : 0.033575
[00:04:08.601] iteration 12668 : model1 loss : 0.434971 model2 loss : 0.027942
[00:04:08.772] iteration 12669 : model1 loss : 0.435801 model2 loss : 0.027464
[00:04:08.947] iteration 12670 : model1 loss : 0.438941 model2 loss : 0.027326
[00:04:09.122] iteration 12671 : model1 loss : 0.435893 model2 loss : 0.026272
[00:04:09.301] iteration 12672 : model1 loss : 0.436155 model2 loss : 0.024170
[00:04:09.472] iteration 12673 : model1 loss : 0.437862 model2 loss : 0.028931
[00:04:09.652] iteration 12674 : model1 loss : 0.433911 model2 loss : 0.026545
[00:04:09.823] iteration 12675 : model1 loss : 0.444109 model2 loss : 0.040182
[00:04:10.002] iteration 12676 : model1 loss : 0.434067 model2 loss : 0.031370
[00:04:10.174] iteration 12677 : model1 loss : 0.437487 model2 loss : 0.035127
[00:04:10.356] iteration 12678 : model1 loss : 0.436389 model2 loss : 0.028631
[00:04:10.531] iteration 12679 : model1 loss : 0.440796 model2 loss : 0.030330
[00:04:10.713] iteration 12680 : model1 loss : 0.438965 model2 loss : 0.029897
[00:04:10.884] iteration 12681 : model1 loss : 0.437155 model2 loss : 0.022854
[00:04:11.066] iteration 12682 : model1 loss : 0.436591 model2 loss : 0.028064
[00:04:11.236] iteration 12683 : model1 loss : 0.435891 model2 loss : 0.035170
[00:04:11.411] iteration 12684 : model1 loss : 0.431841 model2 loss : 0.033134
[00:04:13.585] iteration 12685 : model1 loss : 0.430993 model2 loss : 0.024141
[00:04:13.763] iteration 12686 : model1 loss : 0.438752 model2 loss : 0.033786
[00:04:13.941] iteration 12687 : model1 loss : 0.435982 model2 loss : 0.027806
[00:04:14.118] iteration 12688 : model1 loss : 0.438249 model2 loss : 0.040296
[00:04:14.297] iteration 12689 : model1 loss : 0.440121 model2 loss : 0.028151
[00:04:14.470] iteration 12690 : model1 loss : 0.440049 model2 loss : 0.026678
[00:04:14.647] iteration 12691 : model1 loss : 0.435786 model2 loss : 0.029367
[00:04:14.817] iteration 12692 : model1 loss : 0.440154 model2 loss : 0.030289
[00:04:14.994] iteration 12693 : model1 loss : 0.437537 model2 loss : 0.028629
[00:04:15.170] iteration 12694 : model1 loss : 0.438162 model2 loss : 0.026802
[00:04:15.352] iteration 12695 : model1 loss : 0.434901 model2 loss : 0.024955
[00:04:15.524] iteration 12696 : model1 loss : 0.435722 model2 loss : 0.026309
[00:04:15.702] iteration 12697 : model1 loss : 0.436648 model2 loss : 0.027056
[00:04:15.873] iteration 12698 : model1 loss : 0.432550 model2 loss : 0.024845
[00:04:16.049] iteration 12699 : model1 loss : 0.440059 model2 loss : 0.028003
[00:04:16.222] iteration 12700 : model1 loss : 0.440239 model2 loss : 0.025758
[00:04:16.396] iteration 12701 : model1 loss : 0.435313 model2 loss : 0.027309
[00:04:16.569] iteration 12702 : model1 loss : 0.435041 model2 loss : 0.026500
[00:04:16.745] iteration 12703 : model1 loss : 0.438283 model2 loss : 0.032661
[00:04:16.913] iteration 12704 : model1 loss : 0.440716 model2 loss : 0.025223
[00:04:17.089] iteration 12705 : model1 loss : 0.435456 model2 loss : 0.028402
[00:04:19.252] iteration 12706 : model1 loss : 0.435716 model2 loss : 0.030626
[00:04:19.424] iteration 12707 : model1 loss : 0.437321 model2 loss : 0.029159
[00:04:19.608] iteration 12708 : model1 loss : 0.438288 model2 loss : 0.025931
[00:04:19.779] iteration 12709 : model1 loss : 0.438498 model2 loss : 0.026021
[00:04:19.954] iteration 12710 : model1 loss : 0.437122 model2 loss : 0.027753
[00:04:20.132] iteration 12711 : model1 loss : 0.442326 model2 loss : 0.056253
[00:04:20.310] iteration 12712 : model1 loss : 0.435481 model2 loss : 0.028094
[00:04:20.482] iteration 12713 : model1 loss : 0.435402 model2 loss : 0.022389
[00:04:20.663] iteration 12714 : model1 loss : 0.435696 model2 loss : 0.025277
[00:04:20.833] iteration 12715 : model1 loss : 0.435583 model2 loss : 0.026272
[00:04:21.009] iteration 12716 : model1 loss : 0.434220 model2 loss : 0.022077
[00:04:21.184] iteration 12717 : model1 loss : 0.439075 model2 loss : 0.026387
[00:04:21.360] iteration 12718 : model1 loss : 0.437769 model2 loss : 0.025384
[00:04:21.535] iteration 12719 : model1 loss : 0.434702 model2 loss : 0.036022
[00:04:21.713] iteration 12720 : model1 loss : 0.441425 model2 loss : 0.024088
[00:04:21.885] iteration 12721 : model1 loss : 0.435566 model2 loss : 0.025518
[00:04:22.064] iteration 12722 : model1 loss : 0.437693 model2 loss : 0.036259
[00:04:22.236] iteration 12723 : model1 loss : 0.434453 model2 loss : 0.025155
[00:04:22.410] iteration 12724 : model1 loss : 0.435984 model2 loss : 0.026227
[00:04:22.584] iteration 12725 : model1 loss : 0.436589 model2 loss : 0.025784
[00:04:22.761] iteration 12726 : model1 loss : 0.437632 model2 loss : 0.028367
[00:04:24.883] iteration 12727 : model1 loss : 0.437862 model2 loss : 0.030264
[00:04:25.063] iteration 12728 : model1 loss : 0.439383 model2 loss : 0.029196
[00:04:25.241] iteration 12729 : model1 loss : 0.437840 model2 loss : 0.034287
[00:04:25.414] iteration 12730 : model1 loss : 0.439353 model2 loss : 0.031533
[00:04:25.595] iteration 12731 : model1 loss : 0.442123 model2 loss : 0.023597
[00:04:25.769] iteration 12732 : model1 loss : 0.433454 model2 loss : 0.029551
[00:04:25.944] iteration 12733 : model1 loss : 0.433677 model2 loss : 0.025813
[00:04:26.120] iteration 12734 : model1 loss : 0.440204 model2 loss : 0.029334
[00:04:26.300] iteration 12735 : model1 loss : 0.439191 model2 loss : 0.025170
[00:04:26.474] iteration 12736 : model1 loss : 0.435383 model2 loss : 0.022864
[00:04:26.648] iteration 12737 : model1 loss : 0.432189 model2 loss : 0.024709
[00:04:26.820] iteration 12738 : model1 loss : 0.436371 model2 loss : 0.031663
[00:04:26.996] iteration 12739 : model1 loss : 0.438942 model2 loss : 0.026950
[00:04:27.170] iteration 12740 : model1 loss : 0.436886 model2 loss : 0.025554
[00:04:27.350] iteration 12741 : model1 loss : 0.436658 model2 loss : 0.027596
[00:04:27.525] iteration 12742 : model1 loss : 0.432816 model2 loss : 0.029573
[00:04:27.702] iteration 12743 : model1 loss : 0.435004 model2 loss : 0.024531
[00:04:27.871] iteration 12744 : model1 loss : 0.440390 model2 loss : 0.027992
[00:04:28.050] iteration 12745 : model1 loss : 0.440025 model2 loss : 0.031632
[00:04:28.222] iteration 12746 : model1 loss : 0.435950 model2 loss : 0.024792
[00:04:28.398] iteration 12747 : model1 loss : 0.436460 model2 loss : 0.024277
[00:04:30.571] iteration 12748 : model1 loss : 0.436944 model2 loss : 0.026991
[00:04:30.745] iteration 12749 : model1 loss : 0.437030 model2 loss : 0.023258
[00:04:30.922] iteration 12750 : model1 loss : 0.438843 model2 loss : 0.023219
[00:04:31.093] iteration 12751 : model1 loss : 0.435101 model2 loss : 0.023605
[00:04:31.270] iteration 12752 : model1 loss : 0.433362 model2 loss : 0.020108
[00:04:31.442] iteration 12753 : model1 loss : 0.438743 model2 loss : 0.027635
[00:04:31.623] iteration 12754 : model1 loss : 0.440826 model2 loss : 0.027182
[00:04:31.806] iteration 12755 : model1 loss : 0.433504 model2 loss : 0.022344
[00:04:31.982] iteration 12756 : model1 loss : 0.439938 model2 loss : 0.026567
[00:04:32.156] iteration 12757 : model1 loss : 0.442152 model2 loss : 0.028873
[00:04:32.332] iteration 12758 : model1 loss : 0.430032 model2 loss : 0.024437
[00:04:32.510] iteration 12759 : model1 loss : 0.441776 model2 loss : 0.025557
[00:04:32.688] iteration 12760 : model1 loss : 0.438263 model2 loss : 0.024387
[00:04:32.860] iteration 12761 : model1 loss : 0.433191 model2 loss : 0.023320
[00:04:33.034] iteration 12762 : model1 loss : 0.435077 model2 loss : 0.028748
[00:04:33.212] iteration 12763 : model1 loss : 0.437503 model2 loss : 0.026948
[00:04:33.390] iteration 12764 : model1 loss : 0.438247 model2 loss : 0.024290
[00:04:33.564] iteration 12765 : model1 loss : 0.438164 model2 loss : 0.025808
[00:04:33.738] iteration 12766 : model1 loss : 0.438830 model2 loss : 0.026834
[00:04:33.909] iteration 12767 : model1 loss : 0.433413 model2 loss : 0.024132
[00:04:34.084] iteration 12768 : model1 loss : 0.438967 model2 loss : 0.026814
[00:04:36.229] iteration 12769 : model1 loss : 0.433937 model2 loss : 0.023655
[00:04:36.401] iteration 12770 : model1 loss : 0.435474 model2 loss : 0.024033
[00:04:36.583] iteration 12771 : model1 loss : 0.437247 model2 loss : 0.025432
[00:04:36.753] iteration 12772 : model1 loss : 0.440029 model2 loss : 0.028492
[00:04:36.930] iteration 12773 : model1 loss : 0.432341 model2 loss : 0.022710
[00:04:37.103] iteration 12774 : model1 loss : 0.434477 model2 loss : 0.022005
[00:04:37.279] iteration 12775 : model1 loss : 0.439592 model2 loss : 0.030231
[00:04:37.454] iteration 12776 : model1 loss : 0.433608 model2 loss : 0.023601
[00:04:37.636] iteration 12777 : model1 loss : 0.438571 model2 loss : 0.021073
[00:04:37.806] iteration 12778 : model1 loss : 0.435946 model2 loss : 0.021502
[00:04:37.982] iteration 12779 : model1 loss : 0.436980 model2 loss : 0.026138
[00:04:38.156] iteration 12780 : model1 loss : 0.440806 model2 loss : 0.028579
[00:04:38.341] iteration 12781 : model1 loss : 0.437502 model2 loss : 0.026711
[00:04:38.513] iteration 12782 : model1 loss : 0.436441 model2 loss : 0.025628
[00:04:38.691] iteration 12783 : model1 loss : 0.438682 model2 loss : 0.026093
[00:04:38.861] iteration 12784 : model1 loss : 0.437437 model2 loss : 0.022273
[00:04:39.038] iteration 12785 : model1 loss : 0.442244 model2 loss : 0.026424
[00:04:39.213] iteration 12786 : model1 loss : 0.434224 model2 loss : 0.021712
[00:04:39.391] iteration 12787 : model1 loss : 0.438161 model2 loss : 0.024244
[00:04:39.562] iteration 12788 : model1 loss : 0.436684 model2 loss : 0.023515
[00:04:39.738] iteration 12789 : model1 loss : 0.438664 model2 loss : 0.020695
[00:04:41.914] iteration 12790 : model1 loss : 0.434865 model2 loss : 0.019399
[00:04:42.088] iteration 12791 : model1 loss : 0.438862 model2 loss : 0.023887
[00:04:42.269] iteration 12792 : model1 loss : 0.436147 model2 loss : 0.029435
[00:04:42.443] iteration 12793 : model1 loss : 0.439003 model2 loss : 0.024890
[00:04:42.629] iteration 12794 : model1 loss : 0.436082 model2 loss : 0.022906
[00:04:42.802] iteration 12795 : model1 loss : 0.437544 model2 loss : 0.023816
[00:04:42.977] iteration 12796 : model1 loss : 0.438336 model2 loss : 0.025229
[00:04:43.151] iteration 12797 : model1 loss : 0.440663 model2 loss : 0.024960
[00:04:43.336] iteration 12798 : model1 loss : 0.436319 model2 loss : 0.025517
[00:04:43.511] iteration 12799 : model1 loss : 0.433958 model2 loss : 0.020624
[00:04:43.687] iteration 12800 : model1 loss : 0.437530 model2 loss : 0.027828
[00:04:43.858] iteration 12801 : model1 loss : 0.434960 model2 loss : 0.022423
[00:04:44.032] iteration 12802 : model1 loss : 0.438103 model2 loss : 0.022644
[00:04:44.207] iteration 12803 : model1 loss : 0.439814 model2 loss : 0.024584
[00:04:44.384] iteration 12804 : model1 loss : 0.439580 model2 loss : 0.026113
[00:04:44.556] iteration 12805 : model1 loss : 0.438473 model2 loss : 0.027708
[00:04:44.734] iteration 12806 : model1 loss : 0.434086 model2 loss : 0.027347
[00:04:44.905] iteration 12807 : model1 loss : 0.435717 model2 loss : 0.024610
[00:04:45.082] iteration 12808 : model1 loss : 0.434710 model2 loss : 0.023928
[00:04:45.255] iteration 12809 : model1 loss : 0.438147 model2 loss : 0.022324
[00:04:45.438] iteration 12810 : model1 loss : 0.437005 model2 loss : 0.025720
[00:04:47.597] iteration 12811 : model1 loss : 0.435475 model2 loss : 0.022887
[00:04:47.771] iteration 12812 : model1 loss : 0.441739 model2 loss : 0.033531
[00:04:47.948] iteration 12813 : model1 loss : 0.431906 model2 loss : 0.023765
[00:04:48.123] iteration 12814 : model1 loss : 0.434236 model2 loss : 0.021430
[00:04:48.303] iteration 12815 : model1 loss : 0.433130 model2 loss : 0.020560
[00:04:48.476] iteration 12816 : model1 loss : 0.436719 model2 loss : 0.024319
[00:04:48.655] iteration 12817 : model1 loss : 0.438696 model2 loss : 0.027981
[00:04:48.826] iteration 12818 : model1 loss : 0.431804 model2 loss : 0.023309
[00:04:49.000] iteration 12819 : model1 loss : 0.440764 model2 loss : 0.023880
[00:04:49.176] iteration 12820 : model1 loss : 0.434619 model2 loss : 0.023578
[00:04:49.357] iteration 12821 : model1 loss : 0.439054 model2 loss : 0.024532
[00:04:49.529] iteration 12822 : model1 loss : 0.436080 model2 loss : 0.029792
[00:04:49.705] iteration 12823 : model1 loss : 0.434015 model2 loss : 0.024405
[00:04:49.874] iteration 12824 : model1 loss : 0.435458 model2 loss : 0.020336
[00:04:50.050] iteration 12825 : model1 loss : 0.441300 model2 loss : 0.031566
[00:04:50.224] iteration 12826 : model1 loss : 0.437249 model2 loss : 0.024658
[00:04:50.402] iteration 12827 : model1 loss : 0.437957 model2 loss : 0.020764
[00:04:50.576] iteration 12828 : model1 loss : 0.439175 model2 loss : 0.024488
[00:04:50.754] iteration 12829 : model1 loss : 0.437951 model2 loss : 0.026519
[00:04:50.924] iteration 12830 : model1 loss : 0.441447 model2 loss : 0.024746
[00:04:51.098] iteration 12831 : model1 loss : 0.437689 model2 loss : 0.026301
[00:04:53.281] iteration 12832 : model1 loss : 0.435577 model2 loss : 0.023398
[00:04:53.454] iteration 12833 : model1 loss : 0.438133 model2 loss : 0.031309
[00:04:53.636] iteration 12834 : model1 loss : 0.436893 model2 loss : 0.022470
[00:04:53.809] iteration 12835 : model1 loss : 0.439704 model2 loss : 0.029111
[00:04:53.986] iteration 12836 : model1 loss : 0.433013 model2 loss : 0.023434
[00:04:54.161] iteration 12837 : model1 loss : 0.437520 model2 loss : 0.027432
[00:04:54.341] iteration 12838 : model1 loss : 0.437469 model2 loss : 0.022436
[00:04:54.513] iteration 12839 : model1 loss : 0.439183 model2 loss : 0.025961
[00:04:54.691] iteration 12840 : model1 loss : 0.431755 model2 loss : 0.024386
[00:04:54.861] iteration 12841 : model1 loss : 0.434384 model2 loss : 0.022205
[00:04:55.036] iteration 12842 : model1 loss : 0.436859 model2 loss : 0.025165
[00:04:55.212] iteration 12843 : model1 loss : 0.440429 model2 loss : 0.029505
[00:04:55.389] iteration 12844 : model1 loss : 0.439873 model2 loss : 0.026631
[00:04:55.563] iteration 12845 : model1 loss : 0.438630 model2 loss : 0.024481
[00:04:55.741] iteration 12846 : model1 loss : 0.439479 model2 loss : 0.025485
[00:04:55.914] iteration 12847 : model1 loss : 0.437397 model2 loss : 0.028396
[00:04:56.092] iteration 12848 : model1 loss : 0.436865 model2 loss : 0.021750
[00:04:56.267] iteration 12849 : model1 loss : 0.437159 model2 loss : 0.026318
[00:04:56.444] iteration 12850 : model1 loss : 0.439136 model2 loss : 0.025639
[00:04:56.617] iteration 12851 : model1 loss : 0.434757 model2 loss : 0.022856
[00:04:56.793] iteration 12852 : model1 loss : 0.431098 model2 loss : 0.023461
[00:04:58.982] iteration 12853 : model1 loss : 0.437494 model2 loss : 0.019924
[00:04:59.160] iteration 12854 : model1 loss : 0.440121 model2 loss : 0.028502
[00:04:59.343] iteration 12855 : model1 loss : 0.435716 model2 loss : 0.023206
[00:04:59.514] iteration 12856 : model1 loss : 0.439002 model2 loss : 0.022863
[00:04:59.692] iteration 12857 : model1 loss : 0.437856 model2 loss : 0.021664
[00:04:59.863] iteration 12858 : model1 loss : 0.434632 model2 loss : 0.025167
[00:05:00.039] iteration 12859 : model1 loss : 0.441118 model2 loss : 0.023778
[00:05:00.215] iteration 12860 : model1 loss : 0.437033 model2 loss : 0.024526
[00:05:00.391] iteration 12861 : model1 loss : 0.433492 model2 loss : 0.022062
[00:05:00.562] iteration 12862 : model1 loss : 0.434904 model2 loss : 0.023323
[00:05:00.740] iteration 12863 : model1 loss : 0.433925 model2 loss : 0.021262
[00:05:00.911] iteration 12864 : model1 loss : 0.439444 model2 loss : 0.026132
[00:05:01.089] iteration 12865 : model1 loss : 0.434236 model2 loss : 0.023878
[00:05:01.264] iteration 12866 : model1 loss : 0.436940 model2 loss : 0.023342
[00:05:01.442] iteration 12867 : model1 loss : 0.440933 model2 loss : 0.024801
[00:05:01.618] iteration 12868 : model1 loss : 0.438925 model2 loss : 0.023065
[00:05:01.795] iteration 12869 : model1 loss : 0.437290 model2 loss : 0.023967
[00:05:01.966] iteration 12870 : model1 loss : 0.430604 model2 loss : 0.025062
[00:05:02.141] iteration 12871 : model1 loss : 0.434823 model2 loss : 0.023142
[00:05:02.313] iteration 12872 : model1 loss : 0.439670 model2 loss : 0.023297
[00:05:02.496] iteration 12873 : model1 loss : 0.438139 model2 loss : 0.024775
[00:05:04.665] iteration 12874 : model1 loss : 0.433668 model2 loss : 0.018409
[00:05:04.841] iteration 12875 : model1 loss : 0.436854 model2 loss : 0.021571
[00:05:05.019] iteration 12876 : model1 loss : 0.436002 model2 loss : 0.021635
[00:05:05.193] iteration 12877 : model1 loss : 0.441107 model2 loss : 0.029661
[00:05:05.374] iteration 12878 : model1 loss : 0.441430 model2 loss : 0.024294
[00:05:05.546] iteration 12879 : model1 loss : 0.438312 model2 loss : 0.021962
[00:05:05.724] iteration 12880 : model1 loss : 0.443247 model2 loss : 0.026563
[00:05:05.895] iteration 12881 : model1 loss : 0.435744 model2 loss : 0.022455
[00:05:06.074] iteration 12882 : model1 loss : 0.437755 model2 loss : 0.019802
[00:05:06.249] iteration 12883 : model1 loss : 0.433201 model2 loss : 0.020552
[00:05:06.427] iteration 12884 : model1 loss : 0.433537 model2 loss : 0.022647
[00:05:06.603] iteration 12885 : model1 loss : 0.439302 model2 loss : 0.022669
[00:05:06.780] iteration 12886 : model1 loss : 0.440084 model2 loss : 0.022007
[00:05:06.949] iteration 12887 : model1 loss : 0.434426 model2 loss : 0.025577
[00:05:07.129] iteration 12888 : model1 loss : 0.434452 model2 loss : 0.021536
[00:05:07.303] iteration 12889 : model1 loss : 0.440812 model2 loss : 0.024264
[00:05:07.487] iteration 12890 : model1 loss : 0.438719 model2 loss : 0.026250
[00:05:07.659] iteration 12891 : model1 loss : 0.433718 model2 loss : 0.023890
[00:05:07.835] iteration 12892 : model1 loss : 0.432799 model2 loss : 0.022726
[00:05:08.006] iteration 12893 : model1 loss : 0.433351 model2 loss : 0.023702
[00:05:08.183] iteration 12894 : model1 loss : 0.436133 model2 loss : 0.022441
[00:05:10.397] iteration 12895 : model1 loss : 0.435943 model2 loss : 0.022233
[00:05:10.572] iteration 12896 : model1 loss : 0.437002 model2 loss : 0.024144
[00:05:10.751] iteration 12897 : model1 loss : 0.435397 model2 loss : 0.022775
[00:05:10.922] iteration 12898 : model1 loss : 0.440711 model2 loss : 0.026830
[00:05:11.097] iteration 12899 : model1 loss : 0.438866 model2 loss : 0.024632
[00:05:11.271] iteration 12900 : model1 loss : 0.438265 model2 loss : 0.022333
[00:05:11.447] iteration 12901 : model1 loss : 0.432949 model2 loss : 0.019459
[00:05:11.622] iteration 12902 : model1 loss : 0.435096 model2 loss : 0.023483
[00:05:11.801] iteration 12903 : model1 loss : 0.439957 model2 loss : 0.031051
[00:05:11.972] iteration 12904 : model1 loss : 0.440295 model2 loss : 0.023998
[00:05:12.150] iteration 12905 : model1 loss : 0.435780 model2 loss : 0.021862
[00:05:12.324] iteration 12906 : model1 loss : 0.439505 model2 loss : 0.024280
[00:05:12.505] iteration 12907 : model1 loss : 0.435160 model2 loss : 0.024244
[00:05:12.679] iteration 12908 : model1 loss : 0.440925 model2 loss : 0.025043
[00:05:12.857] iteration 12909 : model1 loss : 0.435392 model2 loss : 0.021671
[00:05:13.029] iteration 12910 : model1 loss : 0.432850 model2 loss : 0.017468
[00:05:13.209] iteration 12911 : model1 loss : 0.437261 model2 loss : 0.024251
[00:05:13.381] iteration 12912 : model1 loss : 0.433093 model2 loss : 0.023115
[00:05:13.561] iteration 12913 : model1 loss : 0.439580 model2 loss : 0.028340
[00:05:13.731] iteration 12914 : model1 loss : 0.435929 model2 loss : 0.021769
[00:05:13.905] iteration 12915 : model1 loss : 0.436048 model2 loss : 0.024153
[00:05:16.035] iteration 12916 : model1 loss : 0.435792 model2 loss : 0.019417
[00:05:16.210] iteration 12917 : model1 loss : 0.438008 model2 loss : 0.022529
[00:05:16.387] iteration 12918 : model1 loss : 0.434888 model2 loss : 0.022995
[00:05:16.560] iteration 12919 : model1 loss : 0.435505 model2 loss : 0.021095
[00:05:16.737] iteration 12920 : model1 loss : 0.434940 model2 loss : 0.022162
[00:05:16.905] iteration 12921 : model1 loss : 0.437616 model2 loss : 0.026420
[00:05:17.082] iteration 12922 : model1 loss : 0.435229 model2 loss : 0.023369
[00:05:17.259] iteration 12923 : model1 loss : 0.439127 model2 loss : 0.021352
[00:05:17.438] iteration 12924 : model1 loss : 0.436941 model2 loss : 0.023611
[00:05:17.612] iteration 12925 : model1 loss : 0.436625 model2 loss : 0.020869
[00:05:17.792] iteration 12926 : model1 loss : 0.438554 model2 loss : 0.025790
[00:05:17.964] iteration 12927 : model1 loss : 0.436892 model2 loss : 0.021766
[00:05:18.143] iteration 12928 : model1 loss : 0.436964 model2 loss : 0.023307
[00:05:18.318] iteration 12929 : model1 loss : 0.433748 model2 loss : 0.024391
[00:05:18.498] iteration 12930 : model1 loss : 0.435087 model2 loss : 0.026125
[00:05:18.670] iteration 12931 : model1 loss : 0.436001 model2 loss : 0.023284
[00:05:18.849] iteration 12932 : model1 loss : 0.438371 model2 loss : 0.023429
[00:05:19.019] iteration 12933 : model1 loss : 0.439619 model2 loss : 0.023658
[00:05:19.198] iteration 12934 : model1 loss : 0.435277 model2 loss : 0.023052
[00:05:19.372] iteration 12935 : model1 loss : 0.439428 model2 loss : 0.021915
[00:05:19.547] iteration 12936 : model1 loss : 0.438266 model2 loss : 0.024386
[00:05:21.688] iteration 12937 : model1 loss : 0.436243 model2 loss : 0.022397
[00:05:21.861] iteration 12938 : model1 loss : 0.436134 model2 loss : 0.019455
[00:05:22.040] iteration 12939 : model1 loss : 0.434798 model2 loss : 0.020240
[00:05:22.217] iteration 12940 : model1 loss : 0.435696 model2 loss : 0.021463
[00:05:22.398] iteration 12941 : model1 loss : 0.441160 model2 loss : 0.025045
[00:05:22.572] iteration 12942 : model1 loss : 0.440237 model2 loss : 0.022408
[00:05:22.748] iteration 12943 : model1 loss : 0.438757 model2 loss : 0.024683
[00:05:22.919] iteration 12944 : model1 loss : 0.433774 model2 loss : 0.019503
[00:05:23.096] iteration 12945 : model1 loss : 0.437146 model2 loss : 0.023237
[00:05:23.272] iteration 12946 : model1 loss : 0.438620 model2 loss : 0.021366
[00:05:23.450] iteration 12947 : model1 loss : 0.436611 model2 loss : 0.021947
[00:05:23.623] iteration 12948 : model1 loss : 0.440162 model2 loss : 0.021520
[00:05:23.803] iteration 12949 : model1 loss : 0.438309 model2 loss : 0.021279
[00:05:23.974] iteration 12950 : model1 loss : 0.436423 model2 loss : 0.024232
[00:05:24.152] iteration 12951 : model1 loss : 0.436170 model2 loss : 0.022379
[00:05:24.327] iteration 12952 : model1 loss : 0.434754 model2 loss : 0.022319
[00:05:24.507] iteration 12953 : model1 loss : 0.435818 model2 loss : 0.022025
[00:05:24.680] iteration 12954 : model1 loss : 0.433539 model2 loss : 0.020647
[00:05:24.859] iteration 12955 : model1 loss : 0.435571 model2 loss : 0.024002
[00:05:25.028] iteration 12956 : model1 loss : 0.435863 model2 loss : 0.019943
[00:05:25.203] iteration 12957 : model1 loss : 0.435142 model2 loss : 0.020913
[00:05:27.341] iteration 12958 : model1 loss : 0.433205 model2 loss : 0.019814
[00:05:27.518] iteration 12959 : model1 loss : 0.436821 model2 loss : 0.019411
[00:05:27.701] iteration 12960 : model1 loss : 0.436197 model2 loss : 0.020378
[00:05:27.871] iteration 12961 : model1 loss : 0.442756 model2 loss : 0.025540
[00:05:28.045] iteration 12962 : model1 loss : 0.433618 model2 loss : 0.021917
[00:05:28.220] iteration 12963 : model1 loss : 0.437390 model2 loss : 0.020635
[00:05:28.398] iteration 12964 : model1 loss : 0.437023 model2 loss : 0.020536
[00:05:28.573] iteration 12965 : model1 loss : 0.436155 model2 loss : 0.025100
[00:05:28.753] iteration 12966 : model1 loss : 0.437294 model2 loss : 0.021435
[00:05:28.923] iteration 12967 : model1 loss : 0.433817 model2 loss : 0.024430
[00:05:29.098] iteration 12968 : model1 loss : 0.436372 model2 loss : 0.024517
[00:05:29.271] iteration 12969 : model1 loss : 0.438966 model2 loss : 0.020918
[00:05:29.448] iteration 12970 : model1 loss : 0.442047 model2 loss : 0.021908
[00:05:29.620] iteration 12971 : model1 loss : 0.437371 model2 loss : 0.022181
[00:05:29.800] iteration 12972 : model1 loss : 0.434863 model2 loss : 0.021407
[00:05:29.971] iteration 12973 : model1 loss : 0.439012 model2 loss : 0.024599
[00:05:30.148] iteration 12974 : model1 loss : 0.434639 model2 loss : 0.020590
[00:05:30.326] iteration 12975 : model1 loss : 0.439685 model2 loss : 0.021352
[00:05:30.505] iteration 12976 : model1 loss : 0.437902 model2 loss : 0.019979
[00:05:30.676] iteration 12977 : model1 loss : 0.434793 model2 loss : 0.024838
[00:05:30.851] iteration 12978 : model1 loss : 0.432134 model2 loss : 0.020035
[00:05:33.052] iteration 12979 : model1 loss : 0.437155 model2 loss : 0.020734
[00:05:33.226] iteration 12980 : model1 loss : 0.439110 model2 loss : 0.025394
[00:05:33.407] iteration 12981 : model1 loss : 0.435488 model2 loss : 0.023415
[00:05:33.580] iteration 12982 : model1 loss : 0.439105 model2 loss : 0.024100
[00:05:33.755] iteration 12983 : model1 loss : 0.438307 model2 loss : 0.022095
[00:05:33.925] iteration 12984 : model1 loss : 0.432379 model2 loss : 0.019697
[00:05:34.101] iteration 12985 : model1 loss : 0.438700 model2 loss : 0.021195
[00:05:34.275] iteration 12986 : model1 loss : 0.433810 model2 loss : 0.019722
[00:05:34.453] iteration 12987 : model1 loss : 0.439559 model2 loss : 0.026275
[00:05:34.626] iteration 12988 : model1 loss : 0.438317 model2 loss : 0.019010
[00:05:34.803] iteration 12989 : model1 loss : 0.433128 model2 loss : 0.019554
[00:05:34.972] iteration 12990 : model1 loss : 0.439925 model2 loss : 0.024672
[00:05:35.149] iteration 12991 : model1 loss : 0.434273 model2 loss : 0.022432
[00:05:35.327] iteration 12992 : model1 loss : 0.435703 model2 loss : 0.021633
[00:05:35.507] iteration 12993 : model1 loss : 0.437089 model2 loss : 0.022433
[00:05:35.680] iteration 12994 : model1 loss : 0.437420 model2 loss : 0.022369
[00:05:35.857] iteration 12995 : model1 loss : 0.440193 model2 loss : 0.024128
[00:05:36.028] iteration 12996 : model1 loss : 0.432850 model2 loss : 0.020480
[00:05:36.209] iteration 12997 : model1 loss : 0.434456 model2 loss : 0.021795
[00:05:36.380] iteration 12998 : model1 loss : 0.437937 model2 loss : 0.020212
[00:05:36.557] iteration 12999 : model1 loss : 0.434104 model2 loss : 0.018316
[00:05:38.736] iteration 13000 : model1 loss : 0.435840 model2 loss : 0.021886
[00:05:47.969] iteration 13000 : model1_mean_dice : 0.840342 model1_mean_hd95 : 7.170529
[00:05:57.273] iteration 13000 : model2_mean_dice : 0.872465 model2_mean_hd95 : 5.111236
[00:05:57.455] iteration 13001 : model1 loss : 0.433104 model2 loss : 0.020448
[00:05:57.638] iteration 13002 : model1 loss : 0.436746 model2 loss : 0.020312
[00:05:57.812] iteration 13003 : model1 loss : 0.439220 model2 loss : 0.024266
[00:05:57.987] iteration 13004 : model1 loss : 0.438426 model2 loss : 0.022943
[00:05:58.158] iteration 13005 : model1 loss : 0.432825 model2 loss : 0.020549
[00:05:58.335] iteration 13006 : model1 loss : 0.434971 model2 loss : 0.020596
[00:05:58.505] iteration 13007 : model1 loss : 0.439418 model2 loss : 0.021800
[00:05:58.679] iteration 13008 : model1 loss : 0.432127 model2 loss : 0.019648
[00:05:58.852] iteration 13009 : model1 loss : 0.434785 model2 loss : 0.022789
[00:05:59.026] iteration 13010 : model1 loss : 0.436077 model2 loss : 0.023214
[00:05:59.196] iteration 13011 : model1 loss : 0.435694 model2 loss : 0.020934
[00:05:59.374] iteration 13012 : model1 loss : 0.439547 model2 loss : 0.023622
[00:05:59.545] iteration 13013 : model1 loss : 0.437385 model2 loss : 0.021884
[00:05:59.721] iteration 13014 : model1 loss : 0.433988 model2 loss : 0.021940
[00:05:59.894] iteration 13015 : model1 loss : 0.442367 model2 loss : 0.022538
[00:06:00.069] iteration 13016 : model1 loss : 0.435755 model2 loss : 0.022189
[00:06:00.245] iteration 13017 : model1 loss : 0.439631 model2 loss : 0.026447
[00:06:00.421] iteration 13018 : model1 loss : 0.443066 model2 loss : 0.024710
[00:06:00.594] iteration 13019 : model1 loss : 0.436722 model2 loss : 0.023256
[00:06:00.768] iteration 13020 : model1 loss : 0.438923 model2 loss : 0.019891
[00:06:02.966] iteration 13021 : model1 loss : 0.437950 model2 loss : 0.023796
[00:06:03.136] iteration 13022 : model1 loss : 0.435963 model2 loss : 0.021582
[00:06:03.317] iteration 13023 : model1 loss : 0.433081 model2 loss : 0.019695
[00:06:03.489] iteration 13024 : model1 loss : 0.438612 model2 loss : 0.022131
[00:06:03.664] iteration 13025 : model1 loss : 0.437622 model2 loss : 0.025743
[00:06:03.838] iteration 13026 : model1 loss : 0.438571 model2 loss : 0.023160
[00:06:04.016] iteration 13027 : model1 loss : 0.438124 model2 loss : 0.021200
[00:06:04.186] iteration 13028 : model1 loss : 0.435443 model2 loss : 0.022851
[00:06:04.364] iteration 13029 : model1 loss : 0.434481 model2 loss : 0.019635
[00:06:04.535] iteration 13030 : model1 loss : 0.436238 model2 loss : 0.019774
[00:06:04.710] iteration 13031 : model1 loss : 0.439445 model2 loss : 0.020830
[00:06:04.884] iteration 13032 : model1 loss : 0.435082 model2 loss : 0.020687
[00:06:05.058] iteration 13033 : model1 loss : 0.433356 model2 loss : 0.021617
[00:06:05.227] iteration 13034 : model1 loss : 0.436563 model2 loss : 0.028202
[00:06:05.404] iteration 13035 : model1 loss : 0.437371 model2 loss : 0.020774
[00:06:05.575] iteration 13036 : model1 loss : 0.436110 model2 loss : 0.020586
[00:06:05.751] iteration 13037 : model1 loss : 0.437085 model2 loss : 0.023011
[00:06:05.922] iteration 13038 : model1 loss : 0.437107 model2 loss : 0.022692
[00:06:06.101] iteration 13039 : model1 loss : 0.437872 model2 loss : 0.020328
[00:06:06.274] iteration 13040 : model1 loss : 0.433449 model2 loss : 0.020464
[00:06:06.448] iteration 13041 : model1 loss : 0.439120 model2 loss : 0.021738
[00:06:08.649] iteration 13042 : model1 loss : 0.440423 model2 loss : 0.022965
[00:06:08.824] iteration 13043 : model1 loss : 0.441676 model2 loss : 0.035774
[00:06:09.000] iteration 13044 : model1 loss : 0.437567 model2 loss : 0.021036
[00:06:09.170] iteration 13045 : model1 loss : 0.434924 model2 loss : 0.023885
[00:06:09.348] iteration 13046 : model1 loss : 0.431099 model2 loss : 0.020310
[00:06:09.519] iteration 13047 : model1 loss : 0.435792 model2 loss : 0.021161
[00:06:09.698] iteration 13048 : model1 loss : 0.435391 model2 loss : 0.023139
[00:06:09.870] iteration 13049 : model1 loss : 0.440461 model2 loss : 0.022319
[00:06:10.045] iteration 13050 : model1 loss : 0.434575 model2 loss : 0.021353
[00:06:10.217] iteration 13051 : model1 loss : 0.436772 model2 loss : 0.025462
[00:06:10.396] iteration 13052 : model1 loss : 0.437272 model2 loss : 0.022210
[00:06:10.568] iteration 13053 : model1 loss : 0.436182 model2 loss : 0.024325
[00:06:10.743] iteration 13054 : model1 loss : 0.440550 model2 loss : 0.025052
[00:06:10.915] iteration 13055 : model1 loss : 0.435006 model2 loss : 0.022267
[00:06:11.093] iteration 13056 : model1 loss : 0.434285 model2 loss : 0.021194
[00:06:11.265] iteration 13057 : model1 loss : 0.440076 model2 loss : 0.024661
[00:06:11.441] iteration 13058 : model1 loss : 0.437826 model2 loss : 0.023374
[00:06:11.614] iteration 13059 : model1 loss : 0.431096 model2 loss : 0.020216
[00:06:11.795] iteration 13060 : model1 loss : 0.439199 model2 loss : 0.024594
[00:06:11.964] iteration 13061 : model1 loss : 0.437832 model2 loss : 0.025155
[00:06:12.137] iteration 13062 : model1 loss : 0.438485 model2 loss : 0.022390
[00:06:14.326] iteration 13063 : model1 loss : 0.436560 model2 loss : 0.022324
[00:06:14.497] iteration 13064 : model1 loss : 0.438870 model2 loss : 0.026725
[00:06:14.675] iteration 13065 : model1 loss : 0.437117 model2 loss : 0.023075
[00:06:14.852] iteration 13066 : model1 loss : 0.431749 model2 loss : 0.020047
[00:06:15.029] iteration 13067 : model1 loss : 0.440316 model2 loss : 0.023317
[00:06:15.199] iteration 13068 : model1 loss : 0.434285 model2 loss : 0.020607
[00:06:15.376] iteration 13069 : model1 loss : 0.436485 model2 loss : 0.022243
[00:06:15.547] iteration 13070 : model1 loss : 0.440892 model2 loss : 0.023691
[00:06:15.721] iteration 13071 : model1 loss : 0.439856 model2 loss : 0.022311
[00:06:15.895] iteration 13072 : model1 loss : 0.436678 model2 loss : 0.022888
[00:06:16.072] iteration 13073 : model1 loss : 0.435727 model2 loss : 0.021285
[00:06:16.244] iteration 13074 : model1 loss : 0.430086 model2 loss : 0.019365
[00:06:16.423] iteration 13075 : model1 loss : 0.438168 model2 loss : 0.023106
[00:06:16.596] iteration 13076 : model1 loss : 0.436590 model2 loss : 0.022265
[00:06:16.773] iteration 13077 : model1 loss : 0.441361 model2 loss : 0.020936
[00:06:16.945] iteration 13078 : model1 loss : 0.435548 model2 loss : 0.020381
[00:06:17.119] iteration 13079 : model1 loss : 0.438010 model2 loss : 0.022687
[00:06:17.291] iteration 13080 : model1 loss : 0.442124 model2 loss : 0.026373
[00:06:17.472] iteration 13081 : model1 loss : 0.434338 model2 loss : 0.016935
[00:06:17.641] iteration 13082 : model1 loss : 0.435779 model2 loss : 0.019690
[00:06:17.819] iteration 13083 : model1 loss : 0.436847 model2 loss : 0.023380
[00:06:19.960] iteration 13084 : model1 loss : 0.435664 model2 loss : 0.020560
[00:06:20.135] iteration 13085 : model1 loss : 0.439399 model2 loss : 0.024880
[00:06:20.317] iteration 13086 : model1 loss : 0.440218 model2 loss : 0.023065
[00:06:20.490] iteration 13087 : model1 loss : 0.437925 model2 loss : 0.024703
[00:06:20.667] iteration 13088 : model1 loss : 0.435473 model2 loss : 0.022901
[00:06:20.841] iteration 13089 : model1 loss : 0.437137 model2 loss : 0.020643
[00:06:21.016] iteration 13090 : model1 loss : 0.441657 model2 loss : 0.020905
[00:06:21.188] iteration 13091 : model1 loss : 0.436938 model2 loss : 0.018906
[00:06:21.364] iteration 13092 : model1 loss : 0.438425 model2 loss : 0.023899
[00:06:21.535] iteration 13093 : model1 loss : 0.438829 model2 loss : 0.021380
[00:06:21.712] iteration 13094 : model1 loss : 0.436610 model2 loss : 0.024294
[00:06:21.889] iteration 13095 : model1 loss : 0.429319 model2 loss : 0.020912
[00:06:22.067] iteration 13096 : model1 loss : 0.438323 model2 loss : 0.020877
[00:06:22.238] iteration 13097 : model1 loss : 0.436167 model2 loss : 0.022328
[00:06:22.418] iteration 13098 : model1 loss : 0.435635 model2 loss : 0.019242
[00:06:22.591] iteration 13099 : model1 loss : 0.436777 model2 loss : 0.019892
[00:06:22.767] iteration 13100 : model1 loss : 0.439314 model2 loss : 0.023624
[00:06:22.941] iteration 13101 : model1 loss : 0.435132 model2 loss : 0.020641
[00:06:23.115] iteration 13102 : model1 loss : 0.437649 model2 loss : 0.020466
[00:06:23.286] iteration 13103 : model1 loss : 0.431455 model2 loss : 0.023274
[00:06:23.462] iteration 13104 : model1 loss : 0.439166 model2 loss : 0.022595
[00:06:25.621] iteration 13105 : model1 loss : 0.434454 model2 loss : 0.019981
[00:06:25.796] iteration 13106 : model1 loss : 0.439886 model2 loss : 0.025943
[00:06:25.974] iteration 13107 : model1 loss : 0.433973 model2 loss : 0.019858
[00:06:26.145] iteration 13108 : model1 loss : 0.434402 model2 loss : 0.021142
[00:06:26.325] iteration 13109 : model1 loss : 0.438714 model2 loss : 0.023925
[00:06:26.501] iteration 13110 : model1 loss : 0.437674 model2 loss : 0.018549
[00:06:26.676] iteration 13111 : model1 loss : 0.439474 model2 loss : 0.022281
[00:06:26.849] iteration 13112 : model1 loss : 0.438554 model2 loss : 0.020639
[00:06:27.027] iteration 13113 : model1 loss : 0.435377 model2 loss : 0.021088
[00:06:27.200] iteration 13114 : model1 loss : 0.435759 model2 loss : 0.020783
[00:06:27.379] iteration 13115 : model1 loss : 0.433741 model2 loss : 0.017668
[00:06:27.551] iteration 13116 : model1 loss : 0.433775 model2 loss : 0.019337
[00:06:27.727] iteration 13117 : model1 loss : 0.441481 model2 loss : 0.022022
[00:06:27.901] iteration 13118 : model1 loss : 0.442523 model2 loss : 0.027413
[00:06:28.076] iteration 13119 : model1 loss : 0.437028 model2 loss : 0.023309
[00:06:28.250] iteration 13120 : model1 loss : 0.437232 model2 loss : 0.021214
[00:06:28.427] iteration 13121 : model1 loss : 0.435678 model2 loss : 0.018664
[00:06:28.603] iteration 13122 : model1 loss : 0.439592 model2 loss : 0.025222
[00:06:28.779] iteration 13123 : model1 loss : 0.433132 model2 loss : 0.020214
[00:06:28.953] iteration 13124 : model1 loss : 0.435318 model2 loss : 0.023292
[00:06:29.128] iteration 13125 : model1 loss : 0.433029 model2 loss : 0.019525
[00:06:31.276] iteration 13126 : model1 loss : 0.436644 model2 loss : 0.022912
[00:06:31.452] iteration 13127 : model1 loss : 0.433330 model2 loss : 0.018714
[00:06:31.629] iteration 13128 : model1 loss : 0.436734 model2 loss : 0.024302
[00:06:31.803] iteration 13129 : model1 loss : 0.439025 model2 loss : 0.020958
[00:06:31.978] iteration 13130 : model1 loss : 0.440059 model2 loss : 0.024208
[00:06:32.149] iteration 13131 : model1 loss : 0.438970 model2 loss : 0.021464
[00:06:32.329] iteration 13132 : model1 loss : 0.435486 model2 loss : 0.019636
[00:06:32.508] iteration 13133 : model1 loss : 0.434928 model2 loss : 0.021565
[00:06:32.685] iteration 13134 : model1 loss : 0.439601 model2 loss : 0.022191
[00:06:32.861] iteration 13135 : model1 loss : 0.436504 model2 loss : 0.022676
[00:06:33.038] iteration 13136 : model1 loss : 0.436550 model2 loss : 0.019606
[00:06:33.210] iteration 13137 : model1 loss : 0.434928 model2 loss : 0.021939
[00:06:33.389] iteration 13138 : model1 loss : 0.442442 model2 loss : 0.023543
[00:06:33.563] iteration 13139 : model1 loss : 0.435172 model2 loss : 0.020615
[00:06:33.736] iteration 13140 : model1 loss : 0.437456 model2 loss : 0.020441
[00:06:33.910] iteration 13141 : model1 loss : 0.435945 model2 loss : 0.019343
[00:06:34.087] iteration 13142 : model1 loss : 0.433257 model2 loss : 0.020813
[00:06:34.258] iteration 13143 : model1 loss : 0.439945 model2 loss : 0.019717
[00:06:34.435] iteration 13144 : model1 loss : 0.432742 model2 loss : 0.022173
[00:06:34.607] iteration 13145 : model1 loss : 0.437532 model2 loss : 0.021857
[00:06:34.782] iteration 13146 : model1 loss : 0.433624 model2 loss : 0.021598
[00:06:36.901] iteration 13147 : model1 loss : 0.432027 model2 loss : 0.020744
[00:06:37.072] iteration 13148 : model1 loss : 0.436685 model2 loss : 0.022816
[00:06:37.250] iteration 13149 : model1 loss : 0.438502 model2 loss : 0.023624
[00:06:37.426] iteration 13150 : model1 loss : 0.437448 model2 loss : 0.021873
[00:06:37.607] iteration 13151 : model1 loss : 0.438082 model2 loss : 0.022081
[00:06:37.777] iteration 13152 : model1 loss : 0.435455 model2 loss : 0.023611
[00:06:37.956] iteration 13153 : model1 loss : 0.436814 model2 loss : 0.021979
[00:06:38.128] iteration 13154 : model1 loss : 0.439139 model2 loss : 0.023055
[00:06:38.305] iteration 13155 : model1 loss : 0.436301 model2 loss : 0.021406
[00:06:38.482] iteration 13156 : model1 loss : 0.434211 model2 loss : 0.022445
[00:06:38.659] iteration 13157 : model1 loss : 0.439347 model2 loss : 0.023836
[00:06:38.831] iteration 13158 : model1 loss : 0.434126 model2 loss : 0.020413
[00:06:39.006] iteration 13159 : model1 loss : 0.436874 model2 loss : 0.020855
[00:06:39.177] iteration 13160 : model1 loss : 0.436642 model2 loss : 0.019167
[00:06:39.356] iteration 13161 : model1 loss : 0.439059 model2 loss : 0.021736
[00:06:39.527] iteration 13162 : model1 loss : 0.436597 model2 loss : 0.019585
[00:06:39.699] iteration 13163 : model1 loss : 0.436435 model2 loss : 0.019846
[00:06:39.873] iteration 13164 : model1 loss : 0.440289 model2 loss : 0.022430
[00:06:40.050] iteration 13165 : model1 loss : 0.430714 model2 loss : 0.017484
[00:06:40.218] iteration 13166 : model1 loss : 0.435702 model2 loss : 0.021835
[00:06:40.394] iteration 13167 : model1 loss : 0.441890 model2 loss : 0.025976
[00:06:42.559] iteration 13168 : model1 loss : 0.442066 model2 loss : 0.026936
[00:06:42.732] iteration 13169 : model1 loss : 0.439577 model2 loss : 0.021759
[00:06:42.911] iteration 13170 : model1 loss : 0.439388 model2 loss : 0.024544
[00:06:43.081] iteration 13171 : model1 loss : 0.434747 model2 loss : 0.020443
[00:06:43.256] iteration 13172 : model1 loss : 0.436525 model2 loss : 0.020434
[00:06:43.432] iteration 13173 : model1 loss : 0.434852 model2 loss : 0.021689
[00:06:43.611] iteration 13174 : model1 loss : 0.435886 model2 loss : 0.020787
[00:06:43.783] iteration 13175 : model1 loss : 0.435537 model2 loss : 0.020751
[00:06:43.961] iteration 13176 : model1 loss : 0.439451 model2 loss : 0.020871
[00:06:44.131] iteration 13177 : model1 loss : 0.433095 model2 loss : 0.019204
[00:06:44.310] iteration 13178 : model1 loss : 0.432941 model2 loss : 0.018818
[00:06:44.487] iteration 13179 : model1 loss : 0.437933 model2 loss : 0.021475
[00:06:44.664] iteration 13180 : model1 loss : 0.437914 model2 loss : 0.019985
[00:06:44.835] iteration 13181 : model1 loss : 0.439256 model2 loss : 0.020415
[00:06:45.014] iteration 13182 : model1 loss : 0.438122 model2 loss : 0.021256
[00:06:45.185] iteration 13183 : model1 loss : 0.438623 model2 loss : 0.023594
[00:06:45.362] iteration 13184 : model1 loss : 0.435026 model2 loss : 0.021294
[00:06:45.534] iteration 13185 : model1 loss : 0.434565 model2 loss : 0.022049
[00:06:45.710] iteration 13186 : model1 loss : 0.438241 model2 loss : 0.022301
[00:06:45.882] iteration 13187 : model1 loss : 0.433170 model2 loss : 0.021900
[00:06:46.056] iteration 13188 : model1 loss : 0.436866 model2 loss : 0.022128
[00:06:48.218] iteration 13189 : model1 loss : 0.439188 model2 loss : 0.022216
[00:06:48.393] iteration 13190 : model1 loss : 0.435956 model2 loss : 0.023405
[00:06:48.571] iteration 13191 : model1 loss : 0.436880 model2 loss : 0.020620
[00:06:48.742] iteration 13192 : model1 loss : 0.437018 model2 loss : 0.019714
[00:06:48.919] iteration 13193 : model1 loss : 0.440262 model2 loss : 0.020202
[00:06:49.091] iteration 13194 : model1 loss : 0.438152 model2 loss : 0.020800
[00:06:49.265] iteration 13195 : model1 loss : 0.436226 model2 loss : 0.020369
[00:06:49.438] iteration 13196 : model1 loss : 0.435012 model2 loss : 0.020432
[00:06:49.617] iteration 13197 : model1 loss : 0.435013 model2 loss : 0.021762
[00:06:49.788] iteration 13198 : model1 loss : 0.433382 model2 loss : 0.020369
[00:06:49.962] iteration 13199 : model1 loss : 0.438894 model2 loss : 0.020753
[00:06:50.136] iteration 13200 : model1 loss : 0.437989 model2 loss : 0.020798
[00:06:50.316] iteration 13201 : model1 loss : 0.441344 model2 loss : 0.025009
[00:06:50.490] iteration 13202 : model1 loss : 0.431941 model2 loss : 0.021679
[00:06:50.667] iteration 13203 : model1 loss : 0.437071 model2 loss : 0.021384
[00:06:50.851] iteration 13204 : model1 loss : 0.430355 model2 loss : 0.019374
[00:06:51.029] iteration 13205 : model1 loss : 0.438522 model2 loss : 0.020797
[00:06:51.200] iteration 13206 : model1 loss : 0.436493 model2 loss : 0.022420
[00:06:51.376] iteration 13207 : model1 loss : 0.440904 model2 loss : 0.022289
[00:06:51.545] iteration 13208 : model1 loss : 0.438407 model2 loss : 0.022731
[00:06:51.724] iteration 13209 : model1 loss : 0.441071 model2 loss : 0.022158
[00:06:53.884] iteration 13210 : model1 loss : 0.439219 model2 loss : 0.021023
[00:06:54.062] iteration 13211 : model1 loss : 0.435647 model2 loss : 0.020287
[00:06:54.238] iteration 13212 : model1 loss : 0.435375 model2 loss : 0.021611
[00:06:54.412] iteration 13213 : model1 loss : 0.438274 model2 loss : 0.020228
[00:06:54.593] iteration 13214 : model1 loss : 0.436430 model2 loss : 0.021180
[00:06:54.764] iteration 13215 : model1 loss : 0.441287 model2 loss : 0.025134
[00:06:54.940] iteration 13216 : model1 loss : 0.436184 model2 loss : 0.023030
[00:06:55.111] iteration 13217 : model1 loss : 0.433962 model2 loss : 0.021708
[00:06:55.288] iteration 13218 : model1 loss : 0.438381 model2 loss : 0.021875
[00:06:55.462] iteration 13219 : model1 loss : 0.434840 model2 loss : 0.018146
[00:06:55.638] iteration 13220 : model1 loss : 0.438223 model2 loss : 0.020552
[00:06:55.808] iteration 13221 : model1 loss : 0.434693 model2 loss : 0.021723
[00:06:55.985] iteration 13222 : model1 loss : 0.439503 model2 loss : 0.023710
[00:06:56.156] iteration 13223 : model1 loss : 0.435276 model2 loss : 0.021172
[00:06:56.336] iteration 13224 : model1 loss : 0.435101 model2 loss : 0.019546
[00:06:56.511] iteration 13225 : model1 loss : 0.436337 model2 loss : 0.021151
[00:06:56.690] iteration 13226 : model1 loss : 0.439459 model2 loss : 0.020167
[00:06:56.863] iteration 13227 : model1 loss : 0.436052 model2 loss : 0.023043
[00:06:57.039] iteration 13228 : model1 loss : 0.436352 model2 loss : 0.022261
[00:06:57.208] iteration 13229 : model1 loss : 0.435529 model2 loss : 0.022148
[00:06:57.385] iteration 13230 : model1 loss : 0.436025 model2 loss : 0.023559
[00:06:59.555] iteration 13231 : model1 loss : 0.439389 model2 loss : 0.019676
[00:06:59.728] iteration 13232 : model1 loss : 0.434020 model2 loss : 0.021517
[00:06:59.907] iteration 13233 : model1 loss : 0.442605 model2 loss : 0.024743
[00:07:00.078] iteration 13234 : model1 loss : 0.432031 model2 loss : 0.021936
[00:07:00.255] iteration 13235 : model1 loss : 0.434578 model2 loss : 0.022818
[00:07:00.429] iteration 13236 : model1 loss : 0.436394 model2 loss : 0.019762
[00:07:00.610] iteration 13237 : model1 loss : 0.440147 model2 loss : 0.023894
[00:07:00.780] iteration 13238 : model1 loss : 0.440286 model2 loss : 0.025055
[00:07:00.957] iteration 13239 : model1 loss : 0.432116 model2 loss : 0.020244
[00:07:01.128] iteration 13240 : model1 loss : 0.436721 model2 loss : 0.020233
[00:07:01.305] iteration 13241 : model1 loss : 0.434557 model2 loss : 0.019849
[00:07:01.479] iteration 13242 : model1 loss : 0.443204 model2 loss : 0.025998
[00:07:01.658] iteration 13243 : model1 loss : 0.433465 model2 loss : 0.021145
[00:07:01.828] iteration 13244 : model1 loss : 0.432893 model2 loss : 0.019237
[00:07:02.006] iteration 13245 : model1 loss : 0.437518 model2 loss : 0.021428
[00:07:02.178] iteration 13246 : model1 loss : 0.438417 model2 loss : 0.020840
[00:07:02.359] iteration 13247 : model1 loss : 0.433122 model2 loss : 0.020382
[00:07:02.537] iteration 13248 : model1 loss : 0.434222 model2 loss : 0.022035
[00:07:02.713] iteration 13249 : model1 loss : 0.437260 model2 loss : 0.026510
[00:07:02.885] iteration 13250 : model1 loss : 0.440553 model2 loss : 0.021430
[00:07:03.061] iteration 13251 : model1 loss : 0.438763 model2 loss : 0.022392
[00:07:05.214] iteration 13252 : model1 loss : 0.436272 model2 loss : 0.018470
[00:07:05.388] iteration 13253 : model1 loss : 0.436332 model2 loss : 0.022459
[00:07:05.566] iteration 13254 : model1 loss : 0.434091 model2 loss : 0.020205
[00:07:05.738] iteration 13255 : model1 loss : 0.436442 model2 loss : 0.020937
[00:07:05.915] iteration 13256 : model1 loss : 0.438123 model2 loss : 0.020997
[00:07:06.088] iteration 13257 : model1 loss : 0.441144 model2 loss : 0.022807
[00:07:06.265] iteration 13258 : model1 loss : 0.435136 model2 loss : 0.023141
[00:07:06.440] iteration 13259 : model1 loss : 0.435349 model2 loss : 0.023256
[00:07:06.617] iteration 13260 : model1 loss : 0.437819 model2 loss : 0.022469
[00:07:06.788] iteration 13261 : model1 loss : 0.438911 model2 loss : 0.021808
[00:07:06.964] iteration 13262 : model1 loss : 0.439271 model2 loss : 0.027408
[00:07:07.134] iteration 13263 : model1 loss : 0.436865 model2 loss : 0.021268
[00:07:07.312] iteration 13264 : model1 loss : 0.440649 model2 loss : 0.026497
[00:07:07.490] iteration 13265 : model1 loss : 0.436364 model2 loss : 0.021208
[00:07:07.665] iteration 13266 : model1 loss : 0.439565 model2 loss : 0.021027
[00:07:07.836] iteration 13267 : model1 loss : 0.441276 model2 loss : 0.023441
[00:07:08.015] iteration 13268 : model1 loss : 0.435087 model2 loss : 0.022878
[00:07:08.188] iteration 13269 : model1 loss : 0.436218 model2 loss : 0.021045
[00:07:08.365] iteration 13270 : model1 loss : 0.433742 model2 loss : 0.022953
[00:07:08.537] iteration 13271 : model1 loss : 0.434593 model2 loss : 0.020112
[00:07:08.712] iteration 13272 : model1 loss : 0.432297 model2 loss : 0.019953
[00:07:10.862] iteration 13273 : model1 loss : 0.439237 model2 loss : 0.022712
[00:07:11.068] iteration 13274 : model1 loss : 0.437658 model2 loss : 0.023741
[00:07:11.242] iteration 13275 : model1 loss : 0.433699 model2 loss : 0.019721
[00:07:11.415] iteration 13276 : model1 loss : 0.434504 model2 loss : 0.020544
[00:07:11.593] iteration 13277 : model1 loss : 0.438973 model2 loss : 0.023117
[00:07:11.768] iteration 13278 : model1 loss : 0.436371 model2 loss : 0.022641
[00:07:11.946] iteration 13279 : model1 loss : 0.436818 model2 loss : 0.022873
[00:07:12.120] iteration 13280 : model1 loss : 0.435669 model2 loss : 0.020871
[00:07:12.302] iteration 13281 : model1 loss : 0.434774 model2 loss : 0.023049
[00:07:12.482] iteration 13282 : model1 loss : 0.438190 model2 loss : 0.023247
[00:07:12.661] iteration 13283 : model1 loss : 0.434505 model2 loss : 0.020846
[00:07:12.830] iteration 13284 : model1 loss : 0.438989 model2 loss : 0.022521
[00:07:13.007] iteration 13285 : model1 loss : 0.439559 model2 loss : 0.023840
[00:07:13.178] iteration 13286 : model1 loss : 0.437568 model2 loss : 0.020036
[00:07:13.362] iteration 13287 : model1 loss : 0.437008 model2 loss : 0.025221
[00:07:13.538] iteration 13288 : model1 loss : 0.439241 model2 loss : 0.022104
[00:07:13.713] iteration 13289 : model1 loss : 0.435916 model2 loss : 0.022762
[00:07:13.884] iteration 13290 : model1 loss : 0.434825 model2 loss : 0.023575
[00:07:14.064] iteration 13291 : model1 loss : 0.434951 model2 loss : 0.020701
[00:07:14.235] iteration 13292 : model1 loss : 0.435418 model2 loss : 0.020599
[00:07:14.412] iteration 13293 : model1 loss : 0.439422 model2 loss : 0.024696
[00:07:16.565] iteration 13294 : model1 loss : 0.439597 model2 loss : 0.027397
[00:07:16.735] iteration 13295 : model1 loss : 0.433946 model2 loss : 0.023242
[00:07:16.915] iteration 13296 : model1 loss : 0.433781 model2 loss : 0.020527
[00:07:17.088] iteration 13297 : model1 loss : 0.445108 model2 loss : 0.026821
[00:07:17.263] iteration 13298 : model1 loss : 0.430352 model2 loss : 0.022570
[00:07:17.440] iteration 13299 : model1 loss : 0.438524 model2 loss : 0.022805
[00:07:17.620] iteration 13300 : model1 loss : 0.436096 model2 loss : 0.021255
[00:07:17.791] iteration 13301 : model1 loss : 0.430561 model2 loss : 0.023600
[00:07:17.967] iteration 13302 : model1 loss : 0.440140 model2 loss : 0.027275
[00:07:18.139] iteration 13303 : model1 loss : 0.438768 model2 loss : 0.023876
[00:07:18.317] iteration 13304 : model1 loss : 0.434410 model2 loss : 0.021428
[00:07:18.492] iteration 13305 : model1 loss : 0.438496 model2 loss : 0.021207
[00:07:18.668] iteration 13306 : model1 loss : 0.438452 model2 loss : 0.023021
[00:07:18.839] iteration 13307 : model1 loss : 0.438455 model2 loss : 0.018580
[00:07:19.015] iteration 13308 : model1 loss : 0.433252 model2 loss : 0.021065
[00:07:19.187] iteration 13309 : model1 loss : 0.439321 model2 loss : 0.023808
[00:07:19.365] iteration 13310 : model1 loss : 0.436350 model2 loss : 0.022351
[00:07:19.540] iteration 13311 : model1 loss : 0.437741 model2 loss : 0.025485
[00:07:19.717] iteration 13312 : model1 loss : 0.436422 model2 loss : 0.023620
[00:07:19.887] iteration 13313 : model1 loss : 0.439031 model2 loss : 0.019855
[00:07:20.063] iteration 13314 : model1 loss : 0.436912 model2 loss : 0.024395
[00:07:22.216] iteration 13315 : model1 loss : 0.440132 model2 loss : 0.022256
[00:07:22.393] iteration 13316 : model1 loss : 0.439285 model2 loss : 0.022206
[00:07:22.574] iteration 13317 : model1 loss : 0.429532 model2 loss : 0.020438
[00:07:22.745] iteration 13318 : model1 loss : 0.439439 model2 loss : 0.023159
[00:07:22.921] iteration 13319 : model1 loss : 0.436046 model2 loss : 0.021657
[00:07:23.094] iteration 13320 : model1 loss : 0.438793 model2 loss : 0.024701
[00:07:23.270] iteration 13321 : model1 loss : 0.438785 model2 loss : 0.021573
[00:07:23.444] iteration 13322 : model1 loss : 0.431636 model2 loss : 0.020381
[00:07:23.627] iteration 13323 : model1 loss : 0.437753 model2 loss : 0.020646
[00:07:23.796] iteration 13324 : model1 loss : 0.436661 model2 loss : 0.021866
[00:07:23.973] iteration 13325 : model1 loss : 0.437705 model2 loss : 0.024501
[00:07:24.143] iteration 13326 : model1 loss : 0.438226 model2 loss : 0.022312
[00:07:24.322] iteration 13327 : model1 loss : 0.441304 model2 loss : 0.021066
[00:07:24.498] iteration 13328 : model1 loss : 0.430936 model2 loss : 0.022349
[00:07:24.676] iteration 13329 : model1 loss : 0.435026 model2 loss : 0.020693
[00:07:24.847] iteration 13330 : model1 loss : 0.434282 model2 loss : 0.023515
[00:07:25.022] iteration 13331 : model1 loss : 0.433921 model2 loss : 0.020294
[00:07:25.192] iteration 13332 : model1 loss : 0.435338 model2 loss : 0.021180
[00:07:25.368] iteration 13333 : model1 loss : 0.440566 model2 loss : 0.023193
[00:07:25.541] iteration 13334 : model1 loss : 0.439852 model2 loss : 0.021360
[00:07:25.717] iteration 13335 : model1 loss : 0.435352 model2 loss : 0.020964
[00:07:27.882] iteration 13336 : model1 loss : 0.435060 model2 loss : 0.020593
[00:07:28.060] iteration 13337 : model1 loss : 0.434434 model2 loss : 0.019623
[00:07:28.238] iteration 13338 : model1 loss : 0.433991 model2 loss : 0.021994
[00:07:28.411] iteration 13339 : model1 loss : 0.436291 model2 loss : 0.021460
[00:07:28.591] iteration 13340 : model1 loss : 0.435060 model2 loss : 0.020582
[00:07:28.763] iteration 13341 : model1 loss : 0.436847 model2 loss : 0.024959
[00:07:28.940] iteration 13342 : model1 loss : 0.436108 model2 loss : 0.020591
[00:07:29.111] iteration 13343 : model1 loss : 0.434164 model2 loss : 0.019517
[00:07:29.288] iteration 13344 : model1 loss : 0.441831 model2 loss : 0.022483
[00:07:29.461] iteration 13345 : model1 loss : 0.435594 model2 loss : 0.022317
[00:07:29.639] iteration 13346 : model1 loss : 0.436326 model2 loss : 0.018781
[00:07:29.809] iteration 13347 : model1 loss : 0.437344 model2 loss : 0.023382
[00:07:29.985] iteration 13348 : model1 loss : 0.436609 model2 loss : 0.023241
[00:07:30.160] iteration 13349 : model1 loss : 0.437272 model2 loss : 0.022065
[00:07:30.337] iteration 13350 : model1 loss : 0.436303 model2 loss : 0.022161
[00:07:30.510] iteration 13351 : model1 loss : 0.436971 model2 loss : 0.020956
[00:07:30.686] iteration 13352 : model1 loss : 0.436042 model2 loss : 0.022323
[00:07:30.858] iteration 13353 : model1 loss : 0.441576 model2 loss : 0.026066
[00:07:31.034] iteration 13354 : model1 loss : 0.438946 model2 loss : 0.018574
[00:07:31.204] iteration 13355 : model1 loss : 0.435952 model2 loss : 0.019592
[00:07:31.380] iteration 13356 : model1 loss : 0.437905 model2 loss : 0.021208
[00:07:33.591] iteration 13357 : model1 loss : 0.439568 model2 loss : 0.023324
[00:07:33.767] iteration 13358 : model1 loss : 0.434517 model2 loss : 0.021197
[00:07:33.944] iteration 13359 : model1 loss : 0.440685 model2 loss : 0.021630
[00:07:34.116] iteration 13360 : model1 loss : 0.437928 model2 loss : 0.020513
[00:07:34.292] iteration 13361 : model1 loss : 0.432977 model2 loss : 0.020265
[00:07:34.471] iteration 13362 : model1 loss : 0.438993 model2 loss : 0.021123
[00:07:34.648] iteration 13363 : model1 loss : 0.436568 model2 loss : 0.022344
[00:07:34.819] iteration 13364 : model1 loss : 0.437677 model2 loss : 0.023628
[00:07:34.994] iteration 13365 : model1 loss : 0.433032 model2 loss : 0.021581
[00:07:35.165] iteration 13366 : model1 loss : 0.435316 model2 loss : 0.021593
[00:07:35.346] iteration 13367 : model1 loss : 0.437666 model2 loss : 0.023543
[00:07:35.521] iteration 13368 : model1 loss : 0.441857 model2 loss : 0.023837
[00:07:35.699] iteration 13369 : model1 loss : 0.439764 model2 loss : 0.023720
[00:07:35.870] iteration 13370 : model1 loss : 0.436151 model2 loss : 0.023971
[00:07:36.046] iteration 13371 : model1 loss : 0.437721 model2 loss : 0.020470
[00:07:36.217] iteration 13372 : model1 loss : 0.438819 model2 loss : 0.021981
[00:07:36.399] iteration 13373 : model1 loss : 0.437505 model2 loss : 0.021071
[00:07:36.580] iteration 13374 : model1 loss : 0.432733 model2 loss : 0.019026
[00:07:36.759] iteration 13375 : model1 loss : 0.437390 model2 loss : 0.022427
[00:07:36.932] iteration 13376 : model1 loss : 0.432332 model2 loss : 0.017337
[00:07:37.107] iteration 13377 : model1 loss : 0.435134 model2 loss : 0.022442
[00:07:39.265] iteration 13378 : model1 loss : 0.434461 model2 loss : 0.020238
[00:07:39.439] iteration 13379 : model1 loss : 0.436431 model2 loss : 0.019928
[00:07:39.618] iteration 13380 : model1 loss : 0.437438 model2 loss : 0.022128
[00:07:39.788] iteration 13381 : model1 loss : 0.433786 model2 loss : 0.019918
[00:07:39.964] iteration 13382 : model1 loss : 0.433950 model2 loss : 0.020937
[00:07:40.136] iteration 13383 : model1 loss : 0.436863 model2 loss : 0.020904
[00:07:40.316] iteration 13384 : model1 loss : 0.433604 model2 loss : 0.020431
[00:07:40.490] iteration 13385 : model1 loss : 0.438745 model2 loss : 0.019461
[00:07:40.665] iteration 13386 : model1 loss : 0.437017 model2 loss : 0.019866
[00:07:40.837] iteration 13387 : model1 loss : 0.436841 model2 loss : 0.018990
[00:07:41.016] iteration 13388 : model1 loss : 0.433382 model2 loss : 0.018992
[00:07:41.188] iteration 13389 : model1 loss : 0.439521 model2 loss : 0.021613
[00:07:41.367] iteration 13390 : model1 loss : 0.443785 model2 loss : 0.022601
[00:07:41.539] iteration 13391 : model1 loss : 0.438723 model2 loss : 0.021793
[00:07:41.718] iteration 13392 : model1 loss : 0.436166 model2 loss : 0.020230
[00:07:41.888] iteration 13393 : model1 loss : 0.439771 model2 loss : 0.021469
[00:07:42.065] iteration 13394 : model1 loss : 0.435472 model2 loss : 0.023967
[00:07:42.237] iteration 13395 : model1 loss : 0.433654 model2 loss : 0.020049
[00:07:42.417] iteration 13396 : model1 loss : 0.435689 model2 loss : 0.020980
[00:07:42.593] iteration 13397 : model1 loss : 0.435498 model2 loss : 0.022645
[00:07:42.766] iteration 13398 : model1 loss : 0.437642 model2 loss : 0.020689
[00:07:44.918] iteration 13399 : model1 loss : 0.434712 model2 loss : 0.018007
[00:07:45.096] iteration 13400 : model1 loss : 0.436808 model2 loss : 0.020122
[00:07:45.275] iteration 13401 : model1 loss : 0.436526 model2 loss : 0.020085
[00:07:45.449] iteration 13402 : model1 loss : 0.434152 model2 loss : 0.020648
[00:07:45.629] iteration 13403 : model1 loss : 0.436582 model2 loss : 0.020684
[00:07:45.800] iteration 13404 : model1 loss : 0.433773 model2 loss : 0.021163
[00:07:45.976] iteration 13405 : model1 loss : 0.433995 model2 loss : 0.020872
[00:07:46.147] iteration 13406 : model1 loss : 0.436898 model2 loss : 0.020238
[00:07:46.327] iteration 13407 : model1 loss : 0.438463 model2 loss : 0.021843
[00:07:46.501] iteration 13408 : model1 loss : 0.437580 model2 loss : 0.020613
[00:07:46.677] iteration 13409 : model1 loss : 0.441962 model2 loss : 0.023230
[00:07:46.849] iteration 13410 : model1 loss : 0.442797 model2 loss : 0.030882
[00:07:47.029] iteration 13411 : model1 loss : 0.431188 model2 loss : 0.020249
[00:07:47.199] iteration 13412 : model1 loss : 0.439415 model2 loss : 0.023467
[00:07:47.378] iteration 13413 : model1 loss : 0.437683 model2 loss : 0.022611
[00:07:47.552] iteration 13414 : model1 loss : 0.439265 model2 loss : 0.019001
[00:07:47.730] iteration 13415 : model1 loss : 0.440251 model2 loss : 0.021008
[00:07:47.903] iteration 13416 : model1 loss : 0.436669 model2 loss : 0.022920
[00:07:48.078] iteration 13417 : model1 loss : 0.435333 model2 loss : 0.021193
[00:07:48.247] iteration 13418 : model1 loss : 0.431929 model2 loss : 0.020825
[00:07:48.422] iteration 13419 : model1 loss : 0.438330 model2 loss : 0.027179
[00:07:50.566] iteration 13420 : model1 loss : 0.436115 model2 loss : 0.020549
[00:07:50.739] iteration 13421 : model1 loss : 0.434265 model2 loss : 0.020259
[00:07:50.918] iteration 13422 : model1 loss : 0.435845 model2 loss : 0.022133
[00:07:51.092] iteration 13423 : model1 loss : 0.437048 model2 loss : 0.020152
[00:07:51.267] iteration 13424 : model1 loss : 0.433766 model2 loss : 0.022897
[00:07:51.438] iteration 13425 : model1 loss : 0.441629 model2 loss : 0.025205
[00:07:51.621] iteration 13426 : model1 loss : 0.439743 model2 loss : 0.023756
[00:07:51.792] iteration 13427 : model1 loss : 0.438175 model2 loss : 0.022944
[00:07:51.967] iteration 13428 : model1 loss : 0.436022 model2 loss : 0.019798
[00:07:52.138] iteration 13429 : model1 loss : 0.433809 model2 loss : 0.022765
[00:07:52.319] iteration 13430 : model1 loss : 0.437762 model2 loss : 0.021789
[00:07:52.499] iteration 13431 : model1 loss : 0.437042 model2 loss : 0.021067
[00:07:52.677] iteration 13432 : model1 loss : 0.434672 model2 loss : 0.023718
[00:07:52.849] iteration 13433 : model1 loss : 0.438173 model2 loss : 0.019897
[00:07:53.029] iteration 13434 : model1 loss : 0.445025 model2 loss : 0.021025
[00:07:53.203] iteration 13435 : model1 loss : 0.433025 model2 loss : 0.020161
[00:07:53.380] iteration 13436 : model1 loss : 0.437656 model2 loss : 0.025219
[00:07:53.556] iteration 13437 : model1 loss : 0.439099 model2 loss : 0.021849
[00:07:53.732] iteration 13438 : model1 loss : 0.435857 model2 loss : 0.022998
[00:07:53.902] iteration 13439 : model1 loss : 0.438660 model2 loss : 0.020533
[00:07:54.074] iteration 13440 : model1 loss : 0.439931 model2 loss : 0.019769
[00:07:56.208] iteration 13441 : model1 loss : 0.439528 model2 loss : 0.022641
[00:07:56.380] iteration 13442 : model1 loss : 0.439523 model2 loss : 0.020000
[00:07:56.557] iteration 13443 : model1 loss : 0.438471 model2 loss : 0.023649
[00:07:56.726] iteration 13444 : model1 loss : 0.442567 model2 loss : 0.021714
[00:07:56.901] iteration 13445 : model1 loss : 0.436026 model2 loss : 0.022701
[00:07:57.076] iteration 13446 : model1 loss : 0.433881 model2 loss : 0.021489
[00:07:57.251] iteration 13447 : model1 loss : 0.432862 model2 loss : 0.022326
[00:07:57.425] iteration 13448 : model1 loss : 0.438384 model2 loss : 0.018167
[00:07:57.606] iteration 13449 : model1 loss : 0.438341 model2 loss : 0.019419
[00:07:57.779] iteration 13450 : model1 loss : 0.434478 model2 loss : 0.017906
[00:07:57.958] iteration 13451 : model1 loss : 0.435716 model2 loss : 0.023265
[00:07:58.134] iteration 13452 : model1 loss : 0.437256 model2 loss : 0.020715
[00:07:58.312] iteration 13453 : model1 loss : 0.436575 model2 loss : 0.021629
[00:07:58.488] iteration 13454 : model1 loss : 0.436617 model2 loss : 0.021444
[00:07:58.665] iteration 13455 : model1 loss : 0.443525 model2 loss : 0.022773
[00:07:58.835] iteration 13456 : model1 loss : 0.438256 model2 loss : 0.025456
[00:07:59.013] iteration 13457 : model1 loss : 0.442400 model2 loss : 0.024978
[00:07:59.184] iteration 13458 : model1 loss : 0.437344 model2 loss : 0.022053
[00:07:59.362] iteration 13459 : model1 loss : 0.440898 model2 loss : 0.020294
[00:07:59.537] iteration 13460 : model1 loss : 0.434423 model2 loss : 0.019497
[00:07:59.712] iteration 13461 : model1 loss : 0.437703 model2 loss : 0.024324
[00:08:01.873] iteration 13462 : model1 loss : 0.443436 model2 loss : 0.023354
[00:08:02.054] iteration 13463 : model1 loss : 0.434418 model2 loss : 0.019977
[00:08:02.229] iteration 13464 : model1 loss : 0.432965 model2 loss : 0.021315
[00:08:02.404] iteration 13465 : model1 loss : 0.437166 model2 loss : 0.021009
[00:08:02.582] iteration 13466 : model1 loss : 0.436291 model2 loss : 0.021314
[00:08:02.751] iteration 13467 : model1 loss : 0.434486 model2 loss : 0.018956
[00:08:02.926] iteration 13468 : model1 loss : 0.434707 model2 loss : 0.021918
[00:08:03.099] iteration 13469 : model1 loss : 0.440712 model2 loss : 0.023856
[00:08:03.276] iteration 13470 : model1 loss : 0.436808 model2 loss : 0.021032
[00:08:03.449] iteration 13471 : model1 loss : 0.434221 model2 loss : 0.021551
[00:08:03.631] iteration 13472 : model1 loss : 0.434977 model2 loss : 0.020667
[00:08:03.800] iteration 13473 : model1 loss : 0.438693 model2 loss : 0.020691
[00:08:03.979] iteration 13474 : model1 loss : 0.435324 model2 loss : 0.021186
[00:08:04.151] iteration 13475 : model1 loss : 0.442418 model2 loss : 0.025015
[00:08:04.334] iteration 13476 : model1 loss : 0.438881 model2 loss : 0.020987
[00:08:04.510] iteration 13477 : model1 loss : 0.439074 model2 loss : 0.019876
[00:08:04.686] iteration 13478 : model1 loss : 0.441299 model2 loss : 0.026494
[00:08:04.857] iteration 13479 : model1 loss : 0.436198 model2 loss : 0.018575
[00:08:05.036] iteration 13480 : model1 loss : 0.439240 model2 loss : 0.023463
[00:08:05.203] iteration 13481 : model1 loss : 0.438088 model2 loss : 0.019439
[00:08:05.376] iteration 13482 : model1 loss : 0.439833 model2 loss : 0.022241
[00:08:07.545] iteration 13483 : model1 loss : 0.435423 model2 loss : 0.022471
[00:08:07.720] iteration 13484 : model1 loss : 0.440636 model2 loss : 0.022077
[00:08:07.896] iteration 13485 : model1 loss : 0.436230 model2 loss : 0.021545
[00:08:08.070] iteration 13486 : model1 loss : 0.439906 model2 loss : 0.021549
[00:08:08.246] iteration 13487 : model1 loss : 0.435217 model2 loss : 0.020972
[00:08:08.421] iteration 13488 : model1 loss : 0.437458 model2 loss : 0.020358
[00:08:08.602] iteration 13489 : model1 loss : 0.438465 model2 loss : 0.023650
[00:08:08.776] iteration 13490 : model1 loss : 0.438592 model2 loss : 0.018749
[00:08:08.956] iteration 13491 : model1 loss : 0.436780 model2 loss : 0.020794
[00:08:09.130] iteration 13492 : model1 loss : 0.436212 model2 loss : 0.021717
[00:08:09.308] iteration 13493 : model1 loss : 0.437973 model2 loss : 0.022804
[00:08:09.478] iteration 13494 : model1 loss : 0.434508 model2 loss : 0.019920
[00:08:09.657] iteration 13495 : model1 loss : 0.435216 model2 loss : 0.018456
[00:08:09.829] iteration 13496 : model1 loss : 0.437079 model2 loss : 0.020909
[00:08:10.007] iteration 13497 : model1 loss : 0.435760 model2 loss : 0.019947
[00:08:10.178] iteration 13498 : model1 loss : 0.438145 model2 loss : 0.019975
[00:08:10.359] iteration 13499 : model1 loss : 0.438256 model2 loss : 0.023581
[00:08:10.537] iteration 13500 : model1 loss : 0.436933 model2 loss : 0.018235
[00:08:10.713] iteration 13501 : model1 loss : 0.439766 model2 loss : 0.020793
[00:08:10.883] iteration 13502 : model1 loss : 0.438441 model2 loss : 0.022767
[00:08:11.058] iteration 13503 : model1 loss : 0.438036 model2 loss : 0.023357
[00:08:13.270] iteration 13504 : model1 loss : 0.434504 model2 loss : 0.019591
[00:08:13.465] iteration 13505 : model1 loss : 0.441219 model2 loss : 0.025238
[00:08:13.650] iteration 13506 : model1 loss : 0.438364 model2 loss : 0.023555
[00:08:13.841] iteration 13507 : model1 loss : 0.438531 model2 loss : 0.024242
[00:08:14.039] iteration 13508 : model1 loss : 0.434545 model2 loss : 0.020321
[00:08:14.218] iteration 13509 : model1 loss : 0.437045 model2 loss : 0.018368
[00:08:14.398] iteration 13510 : model1 loss : 0.432009 model2 loss : 0.019452
[00:08:14.577] iteration 13511 : model1 loss : 0.439524 model2 loss : 0.021171
[00:08:14.755] iteration 13512 : model1 loss : 0.439204 model2 loss : 0.022428
[00:08:14.926] iteration 13513 : model1 loss : 0.436225 model2 loss : 0.021756
[00:08:15.103] iteration 13514 : model1 loss : 0.438328 model2 loss : 0.022193
[00:08:15.275] iteration 13515 : model1 loss : 0.436115 model2 loss : 0.020725
[00:08:15.451] iteration 13516 : model1 loss : 0.437603 model2 loss : 0.021303
[00:08:15.628] iteration 13517 : model1 loss : 0.440169 model2 loss : 0.024605
[00:08:15.804] iteration 13518 : model1 loss : 0.434484 model2 loss : 0.019148
[00:08:15.974] iteration 13519 : model1 loss : 0.434718 model2 loss : 0.019831
[00:08:16.153] iteration 13520 : model1 loss : 0.437117 model2 loss : 0.021776
[00:08:16.327] iteration 13521 : model1 loss : 0.437343 model2 loss : 0.021415
[00:08:16.506] iteration 13522 : model1 loss : 0.436090 model2 loss : 0.024806
[00:08:16.675] iteration 13523 : model1 loss : 0.440507 model2 loss : 0.026182
[00:08:16.862] iteration 13524 : model1 loss : 0.433963 model2 loss : 0.022302
[00:08:19.023] iteration 13525 : model1 loss : 0.435152 model2 loss : 0.020982
[00:08:19.197] iteration 13526 : model1 loss : 0.436352 model2 loss : 0.022402
[00:08:19.378] iteration 13527 : model1 loss : 0.438049 model2 loss : 0.021994
[00:08:19.553] iteration 13528 : model1 loss : 0.440810 model2 loss : 0.020279
[00:08:19.728] iteration 13529 : model1 loss : 0.433794 model2 loss : 0.022248
[00:08:19.902] iteration 13530 : model1 loss : 0.435552 model2 loss : 0.020165
[00:08:20.080] iteration 13531 : model1 loss : 0.439617 model2 loss : 0.020185
[00:08:20.251] iteration 13532 : model1 loss : 0.439531 model2 loss : 0.020490
[00:08:20.430] iteration 13533 : model1 loss : 0.436041 model2 loss : 0.021783
[00:08:20.608] iteration 13534 : model1 loss : 0.435613 model2 loss : 0.020706
[00:08:20.784] iteration 13535 : model1 loss : 0.437308 model2 loss : 0.021150
[00:08:20.957] iteration 13536 : model1 loss : 0.435532 model2 loss : 0.020537
[00:08:21.138] iteration 13537 : model1 loss : 0.439355 model2 loss : 0.023771
[00:08:21.311] iteration 13538 : model1 loss : 0.436444 model2 loss : 0.022783
[00:08:21.487] iteration 13539 : model1 loss : 0.440404 model2 loss : 0.024555
[00:08:21.661] iteration 13540 : model1 loss : 0.440237 model2 loss : 0.022564
[00:08:21.835] iteration 13541 : model1 loss : 0.433050 model2 loss : 0.020370
[00:08:22.006] iteration 13542 : model1 loss : 0.435588 model2 loss : 0.021293
[00:08:22.185] iteration 13543 : model1 loss : 0.437553 model2 loss : 0.021862
[00:08:22.354] iteration 13544 : model1 loss : 0.435779 model2 loss : 0.023231
[00:08:22.532] iteration 13545 : model1 loss : 0.436056 model2 loss : 0.020570
[00:08:24.688] iteration 13546 : model1 loss : 0.435156 model2 loss : 0.020713
[00:08:24.863] iteration 13547 : model1 loss : 0.440119 model2 loss : 0.021014
[00:08:25.043] iteration 13548 : model1 loss : 0.439028 model2 loss : 0.024004
[00:08:25.213] iteration 13549 : model1 loss : 0.442642 model2 loss : 0.025420
[00:08:25.391] iteration 13550 : model1 loss : 0.436237 model2 loss : 0.019567
[00:08:25.566] iteration 13551 : model1 loss : 0.438142 model2 loss : 0.020445
[00:08:25.742] iteration 13552 : model1 loss : 0.440857 model2 loss : 0.022959
[00:08:25.913] iteration 13553 : model1 loss : 0.438267 model2 loss : 0.022713
[00:08:26.097] iteration 13554 : model1 loss : 0.440675 model2 loss : 0.021675
[00:08:26.269] iteration 13555 : model1 loss : 0.434730 model2 loss : 0.019062
[00:08:26.445] iteration 13556 : model1 loss : 0.435657 model2 loss : 0.020258
[00:08:26.624] iteration 13557 : model1 loss : 0.438689 model2 loss : 0.020932
[00:08:26.800] iteration 13558 : model1 loss : 0.435090 model2 loss : 0.023517
[00:08:26.972] iteration 13559 : model1 loss : 0.434141 model2 loss : 0.021152
[00:08:27.148] iteration 13560 : model1 loss : 0.432528 model2 loss : 0.021337
[00:08:27.321] iteration 13561 : model1 loss : 0.436260 model2 loss : 0.020668
[00:08:27.499] iteration 13562 : model1 loss : 0.434445 model2 loss : 0.019836
[00:08:27.673] iteration 13563 : model1 loss : 0.434230 model2 loss : 0.021662
[00:08:27.851] iteration 13564 : model1 loss : 0.434902 model2 loss : 0.021013
[00:08:28.022] iteration 13565 : model1 loss : 0.437599 model2 loss : 0.023039
[00:08:28.198] iteration 13566 : model1 loss : 0.437143 model2 loss : 0.024883
[00:08:30.340] iteration 13567 : model1 loss : 0.436539 model2 loss : 0.022142
[00:08:30.511] iteration 13568 : model1 loss : 0.436560 model2 loss : 0.023082
[00:08:30.693] iteration 13569 : model1 loss : 0.438632 model2 loss : 0.021294
[00:08:30.865] iteration 13570 : model1 loss : 0.433380 model2 loss : 0.020531
[00:08:31.043] iteration 13571 : model1 loss : 0.434149 model2 loss : 0.021738
[00:08:31.215] iteration 13572 : model1 loss : 0.437787 model2 loss : 0.020591
[00:08:31.393] iteration 13573 : model1 loss : 0.441338 model2 loss : 0.022822
[00:08:31.567] iteration 13574 : model1 loss : 0.434496 model2 loss : 0.021328
[00:08:31.743] iteration 13575 : model1 loss : 0.438336 model2 loss : 0.021062
[00:08:31.912] iteration 13576 : model1 loss : 0.439392 model2 loss : 0.021863
[00:08:32.093] iteration 13577 : model1 loss : 0.435110 model2 loss : 0.019487
[00:08:32.265] iteration 13578 : model1 loss : 0.433898 model2 loss : 0.021414
[00:08:32.443] iteration 13579 : model1 loss : 0.438441 model2 loss : 0.020858
[00:08:32.620] iteration 13580 : model1 loss : 0.436786 model2 loss : 0.021107
[00:08:32.797] iteration 13581 : model1 loss : 0.437860 model2 loss : 0.021130
[00:08:32.968] iteration 13582 : model1 loss : 0.437423 model2 loss : 0.019795
[00:08:33.144] iteration 13583 : model1 loss : 0.439056 model2 loss : 0.023457
[00:08:33.321] iteration 13584 : model1 loss : 0.436629 model2 loss : 0.023644
[00:08:33.500] iteration 13585 : model1 loss : 0.437224 model2 loss : 0.020785
[00:08:33.673] iteration 13586 : model1 loss : 0.436468 model2 loss : 0.022531
[00:08:33.845] iteration 13587 : model1 loss : 0.431037 model2 loss : 0.018968
[00:08:35.965] iteration 13588 : model1 loss : 0.439884 model2 loss : 0.021980
[00:08:36.139] iteration 13589 : model1 loss : 0.436196 model2 loss : 0.019073
[00:08:36.319] iteration 13590 : model1 loss : 0.436558 model2 loss : 0.019021
[00:08:36.491] iteration 13591 : model1 loss : 0.438061 model2 loss : 0.022728
[00:08:36.669] iteration 13592 : model1 loss : 0.438818 model2 loss : 0.024464
[00:08:36.845] iteration 13593 : model1 loss : 0.437845 model2 loss : 0.021226
[00:08:37.024] iteration 13594 : model1 loss : 0.438241 model2 loss : 0.020268
[00:08:37.197] iteration 13595 : model1 loss : 0.436420 model2 loss : 0.024360
[00:08:37.372] iteration 13596 : model1 loss : 0.437235 model2 loss : 0.020493
[00:08:37.549] iteration 13597 : model1 loss : 0.437481 model2 loss : 0.025963
[00:08:37.726] iteration 13598 : model1 loss : 0.434996 model2 loss : 0.021115
[00:08:37.898] iteration 13599 : model1 loss : 0.436536 model2 loss : 0.019772
[00:08:38.074] iteration 13600 : model1 loss : 0.437764 model2 loss : 0.022326
[00:08:38.245] iteration 13601 : model1 loss : 0.437376 model2 loss : 0.026254
[00:08:38.426] iteration 13602 : model1 loss : 0.433591 model2 loss : 0.022052
[00:08:38.604] iteration 13603 : model1 loss : 0.435860 model2 loss : 0.022810
[00:08:38.779] iteration 13604 : model1 loss : 0.435614 model2 loss : 0.020568
[00:08:38.949] iteration 13605 : model1 loss : 0.436798 model2 loss : 0.021458
[00:08:39.126] iteration 13606 : model1 loss : 0.440223 model2 loss : 0.020535
[00:08:39.298] iteration 13607 : model1 loss : 0.434910 model2 loss : 0.021269
[00:08:39.473] iteration 13608 : model1 loss : 0.437114 model2 loss : 0.021072
[00:08:41.618] iteration 13609 : model1 loss : 0.432041 model2 loss : 0.018905
[00:08:41.793] iteration 13610 : model1 loss : 0.436898 model2 loss : 0.020540
[00:08:41.971] iteration 13611 : model1 loss : 0.434158 model2 loss : 0.019028
[00:08:42.143] iteration 13612 : model1 loss : 0.432839 model2 loss : 0.019643
[00:08:42.325] iteration 13613 : model1 loss : 0.444041 model2 loss : 0.027434
[00:08:42.503] iteration 13614 : model1 loss : 0.437530 model2 loss : 0.020873
[00:08:42.681] iteration 13615 : model1 loss : 0.438592 model2 loss : 0.020551
[00:08:42.852] iteration 13616 : model1 loss : 0.439035 model2 loss : 0.024263
[00:08:43.027] iteration 13617 : model1 loss : 0.433081 model2 loss : 0.019485
[00:08:43.201] iteration 13618 : model1 loss : 0.435558 model2 loss : 0.018952
[00:08:43.379] iteration 13619 : model1 loss : 0.433932 model2 loss : 0.020353
[00:08:43.553] iteration 13620 : model1 loss : 0.438840 model2 loss : 0.020340
[00:08:43.733] iteration 13621 : model1 loss : 0.436273 model2 loss : 0.021511
[00:08:43.905] iteration 13622 : model1 loss : 0.436451 model2 loss : 0.021187
[00:08:44.081] iteration 13623 : model1 loss : 0.440784 model2 loss : 0.022023
[00:08:44.253] iteration 13624 : model1 loss : 0.439044 model2 loss : 0.023435
[00:08:44.429] iteration 13625 : model1 loss : 0.437491 model2 loss : 0.022293
[00:08:44.609] iteration 13626 : model1 loss : 0.435100 model2 loss : 0.021119
[00:08:44.784] iteration 13627 : model1 loss : 0.439458 model2 loss : 0.024888
[00:08:44.953] iteration 13628 : model1 loss : 0.436233 model2 loss : 0.024035
[00:08:45.129] iteration 13629 : model1 loss : 0.437421 model2 loss : 0.020596
[00:08:47.276] iteration 13630 : model1 loss : 0.435766 model2 loss : 0.020713
[00:08:47.448] iteration 13631 : model1 loss : 0.437622 model2 loss : 0.021784
[00:08:47.629] iteration 13632 : model1 loss : 0.436261 model2 loss : 0.021142
[00:08:47.801] iteration 13633 : model1 loss : 0.438758 model2 loss : 0.021494
[00:08:47.976] iteration 13634 : model1 loss : 0.437460 model2 loss : 0.019748
[00:08:48.147] iteration 13635 : model1 loss : 0.436856 model2 loss : 0.021227
[00:08:48.329] iteration 13636 : model1 loss : 0.436520 model2 loss : 0.019828
[00:08:48.502] iteration 13637 : model1 loss : 0.437086 model2 loss : 0.019957
[00:08:48.678] iteration 13638 : model1 loss : 0.435066 model2 loss : 0.022273
[00:08:48.849] iteration 13639 : model1 loss : 0.436894 model2 loss : 0.022992
[00:08:49.024] iteration 13640 : model1 loss : 0.438746 model2 loss : 0.019848
[00:08:49.198] iteration 13641 : model1 loss : 0.439681 model2 loss : 0.020830
[00:08:49.375] iteration 13642 : model1 loss : 0.439348 model2 loss : 0.024292
[00:08:49.548] iteration 13643 : model1 loss : 0.439821 model2 loss : 0.021400
[00:08:49.729] iteration 13644 : model1 loss : 0.437044 model2 loss : 0.020105
[00:08:49.900] iteration 13645 : model1 loss : 0.434225 model2 loss : 0.020820
[00:08:50.077] iteration 13646 : model1 loss : 0.435600 model2 loss : 0.021840
[00:08:50.247] iteration 13647 : model1 loss : 0.435006 model2 loss : 0.019615
[00:08:50.429] iteration 13648 : model1 loss : 0.438971 model2 loss : 0.019713
[00:08:50.605] iteration 13649 : model1 loss : 0.436058 model2 loss : 0.022496
[00:08:50.778] iteration 13650 : model1 loss : 0.440322 model2 loss : 0.023127
[00:08:52.946] iteration 13651 : model1 loss : 0.434959 model2 loss : 0.020316
[00:08:53.125] iteration 13652 : model1 loss : 0.437133 model2 loss : 0.019894
[00:08:53.303] iteration 13653 : model1 loss : 0.441350 model2 loss : 0.022771
[00:08:53.475] iteration 13654 : model1 loss : 0.440541 model2 loss : 0.021413
[00:08:53.650] iteration 13655 : model1 loss : 0.432958 model2 loss : 0.020726
[00:08:53.825] iteration 13656 : model1 loss : 0.436044 model2 loss : 0.021372
[00:08:53.999] iteration 13657 : model1 loss : 0.434958 model2 loss : 0.019466
[00:08:54.171] iteration 13658 : model1 loss : 0.437700 model2 loss : 0.022020
[00:08:54.352] iteration 13659 : model1 loss : 0.436174 model2 loss : 0.021666
[00:08:54.526] iteration 13660 : model1 loss : 0.437179 model2 loss : 0.019857
[00:08:54.704] iteration 13661 : model1 loss : 0.433663 model2 loss : 0.017616
[00:08:54.876] iteration 13662 : model1 loss : 0.432794 model2 loss : 0.020483
[00:08:55.054] iteration 13663 : model1 loss : 0.436185 model2 loss : 0.019743
[00:08:55.228] iteration 13664 : model1 loss : 0.438449 model2 loss : 0.021596
[00:08:55.406] iteration 13665 : model1 loss : 0.435509 model2 loss : 0.019515
[00:08:55.580] iteration 13666 : model1 loss : 0.433186 model2 loss : 0.017421
[00:08:55.757] iteration 13667 : model1 loss : 0.436991 model2 loss : 0.023110
[00:08:55.928] iteration 13668 : model1 loss : 0.439062 model2 loss : 0.021051
[00:08:56.105] iteration 13669 : model1 loss : 0.441094 model2 loss : 0.024637
[00:08:56.276] iteration 13670 : model1 loss : 0.444250 model2 loss : 0.020775
[00:08:56.452] iteration 13671 : model1 loss : 0.437616 model2 loss : 0.022007
[00:08:58.615] iteration 13672 : model1 loss : 0.440526 model2 loss : 0.023466
[00:08:58.787] iteration 13673 : model1 loss : 0.435470 model2 loss : 0.018645
[00:08:58.967] iteration 13674 : model1 loss : 0.438753 model2 loss : 0.021292
[00:08:59.141] iteration 13675 : model1 loss : 0.436401 model2 loss : 0.017925
[00:08:59.319] iteration 13676 : model1 loss : 0.436765 model2 loss : 0.019187
[00:08:59.494] iteration 13677 : model1 loss : 0.436786 model2 loss : 0.020764
[00:08:59.672] iteration 13678 : model1 loss : 0.437980 model2 loss : 0.020333
[00:08:59.842] iteration 13679 : model1 loss : 0.442103 model2 loss : 0.026546
[00:09:00.018] iteration 13680 : model1 loss : 0.437044 model2 loss : 0.020416
[00:09:00.196] iteration 13681 : model1 loss : 0.438279 model2 loss : 0.021623
[00:09:00.379] iteration 13682 : model1 loss : 0.435847 model2 loss : 0.026078
[00:09:00.553] iteration 13683 : model1 loss : 0.430347 model2 loss : 0.021183
[00:09:00.730] iteration 13684 : model1 loss : 0.436156 model2 loss : 0.021162
[00:09:00.902] iteration 13685 : model1 loss : 0.432278 model2 loss : 0.021783
[00:09:01.081] iteration 13686 : model1 loss : 0.438690 model2 loss : 0.021607
[00:09:01.253] iteration 13687 : model1 loss : 0.434385 model2 loss : 0.019456
[00:09:01.430] iteration 13688 : model1 loss : 0.435329 model2 loss : 0.020226
[00:09:01.607] iteration 13689 : model1 loss : 0.439358 model2 loss : 0.022174
[00:09:01.783] iteration 13690 : model1 loss : 0.437647 model2 loss : 0.022103
[00:09:01.952] iteration 13691 : model1 loss : 0.441621 model2 loss : 0.021586
[00:09:02.129] iteration 13692 : model1 loss : 0.435214 model2 loss : 0.021667
[00:09:04.292] iteration 13693 : model1 loss : 0.433352 model2 loss : 0.019246
[00:09:04.467] iteration 13694 : model1 loss : 0.433913 model2 loss : 0.020615
[00:09:04.646] iteration 13695 : model1 loss : 0.437176 model2 loss : 0.021872
[00:09:04.822] iteration 13696 : model1 loss : 0.436230 model2 loss : 0.022868
[00:09:04.999] iteration 13697 : model1 loss : 0.438773 model2 loss : 0.019010
[00:09:05.174] iteration 13698 : model1 loss : 0.434158 model2 loss : 0.021563
[00:09:05.350] iteration 13699 : model1 loss : 0.435534 model2 loss : 0.019980
[00:09:05.522] iteration 13700 : model1 loss : 0.440494 model2 loss : 0.023729
[00:09:05.699] iteration 13701 : model1 loss : 0.440112 model2 loss : 0.020892
[00:09:05.869] iteration 13702 : model1 loss : 0.436787 model2 loss : 0.018304
[00:09:06.046] iteration 13703 : model1 loss : 0.440064 model2 loss : 0.021243
[00:09:06.218] iteration 13704 : model1 loss : 0.439906 model2 loss : 0.018633
[00:09:06.397] iteration 13705 : model1 loss : 0.435379 model2 loss : 0.020908
[00:09:06.570] iteration 13706 : model1 loss : 0.434725 model2 loss : 0.020646
[00:09:06.750] iteration 13707 : model1 loss : 0.436657 model2 loss : 0.022120
[00:09:06.921] iteration 13708 : model1 loss : 0.438172 model2 loss : 0.021681
[00:09:07.099] iteration 13709 : model1 loss : 0.431003 model2 loss : 0.018500
[00:09:07.272] iteration 13710 : model1 loss : 0.440719 model2 loss : 0.032129
[00:09:07.452] iteration 13711 : model1 loss : 0.439064 model2 loss : 0.023932
[00:09:07.623] iteration 13712 : model1 loss : 0.439161 model2 loss : 0.021951
[00:09:07.798] iteration 13713 : model1 loss : 0.435052 model2 loss : 0.020630
[00:09:09.954] iteration 13714 : model1 loss : 0.432595 model2 loss : 0.019658
[00:09:10.130] iteration 13715 : model1 loss : 0.436124 model2 loss : 0.017372
[00:09:10.309] iteration 13716 : model1 loss : 0.434439 model2 loss : 0.022966
[00:09:10.480] iteration 13717 : model1 loss : 0.437092 model2 loss : 0.019162
[00:09:10.658] iteration 13718 : model1 loss : 0.438789 model2 loss : 0.022245
[00:09:10.828] iteration 13719 : model1 loss : 0.437786 model2 loss : 0.018597
[00:09:11.003] iteration 13720 : model1 loss : 0.435017 model2 loss : 0.020211
[00:09:11.176] iteration 13721 : model1 loss : 0.433625 model2 loss : 0.020788
[00:09:11.362] iteration 13722 : model1 loss : 0.443283 model2 loss : 0.022951
[00:09:11.535] iteration 13723 : model1 loss : 0.435468 model2 loss : 0.022260
[00:09:11.712] iteration 13724 : model1 loss : 0.438590 model2 loss : 0.022793
[00:09:11.881] iteration 13725 : model1 loss : 0.434100 model2 loss : 0.019883
[00:09:12.056] iteration 13726 : model1 loss : 0.435154 model2 loss : 0.020955
[00:09:12.229] iteration 13727 : model1 loss : 0.437387 model2 loss : 0.020280
[00:09:12.410] iteration 13728 : model1 loss : 0.436711 model2 loss : 0.020225
[00:09:12.583] iteration 13729 : model1 loss : 0.438646 model2 loss : 0.021155
[00:09:12.765] iteration 13730 : model1 loss : 0.438445 model2 loss : 0.024419
[00:09:12.935] iteration 13731 : model1 loss : 0.432953 model2 loss : 0.022081
[00:09:13.109] iteration 13732 : model1 loss : 0.438134 model2 loss : 0.022151
[00:09:13.282] iteration 13733 : model1 loss : 0.441107 model2 loss : 0.021966
[00:09:13.458] iteration 13734 : model1 loss : 0.440238 model2 loss : 0.025262
[00:09:15.566] iteration 13735 : model1 loss : 0.434420 model2 loss : 0.018876
[00:09:15.740] iteration 13736 : model1 loss : 0.431460 model2 loss : 0.019805
[00:09:15.917] iteration 13737 : model1 loss : 0.435111 model2 loss : 0.019099
[00:09:16.087] iteration 13738 : model1 loss : 0.442049 model2 loss : 0.021114
[00:09:16.265] iteration 13739 : model1 loss : 0.439195 model2 loss : 0.025165
[00:09:16.437] iteration 13740 : model1 loss : 0.443024 model2 loss : 0.020060
[00:09:16.618] iteration 13741 : model1 loss : 0.437666 model2 loss : 0.022496
[00:09:16.790] iteration 13742 : model1 loss : 0.435760 model2 loss : 0.019982
[00:09:16.964] iteration 13743 : model1 loss : 0.437701 model2 loss : 0.018109
[00:09:17.138] iteration 13744 : model1 loss : 0.441516 model2 loss : 0.023199
[00:09:17.322] iteration 13745 : model1 loss : 0.435657 model2 loss : 0.020937
[00:09:17.502] iteration 13746 : model1 loss : 0.437488 model2 loss : 0.019432
[00:09:17.678] iteration 13747 : model1 loss : 0.437444 model2 loss : 0.020277
[00:09:17.850] iteration 13748 : model1 loss : 0.436557 model2 loss : 0.020983
[00:09:18.027] iteration 13749 : model1 loss : 0.430999 model2 loss : 0.019423
[00:09:18.202] iteration 13750 : model1 loss : 0.437786 model2 loss : 0.019810
[00:09:18.381] iteration 13751 : model1 loss : 0.434398 model2 loss : 0.019871
[00:09:18.554] iteration 13752 : model1 loss : 0.436690 model2 loss : 0.019904
[00:09:18.732] iteration 13753 : model1 loss : 0.433644 model2 loss : 0.019861
[00:09:18.902] iteration 13754 : model1 loss : 0.435864 model2 loss : 0.021468
[00:09:19.073] iteration 13755 : model1 loss : 0.436738 model2 loss : 0.020938
[00:09:21.221] iteration 13756 : model1 loss : 0.436808 model2 loss : 0.019439
[00:09:21.395] iteration 13757 : model1 loss : 0.441341 model2 loss : 0.021831
[00:09:21.572] iteration 13758 : model1 loss : 0.437381 model2 loss : 0.024021
[00:09:21.745] iteration 13759 : model1 loss : 0.433342 model2 loss : 0.020294
[00:09:21.921] iteration 13760 : model1 loss : 0.438716 model2 loss : 0.021032
[00:09:22.092] iteration 13761 : model1 loss : 0.436492 model2 loss : 0.019100
[00:09:22.269] iteration 13762 : model1 loss : 0.437671 model2 loss : 0.021187
[00:09:22.445] iteration 13763 : model1 loss : 0.439844 model2 loss : 0.019547
[00:09:22.625] iteration 13764 : model1 loss : 0.434512 model2 loss : 0.019525
[00:09:22.798] iteration 13765 : model1 loss : 0.435881 model2 loss : 0.021543
[00:09:22.975] iteration 13766 : model1 loss : 0.439695 model2 loss : 0.019403
[00:09:23.148] iteration 13767 : model1 loss : 0.438767 model2 loss : 0.021888
[00:09:23.329] iteration 13768 : model1 loss : 0.433617 model2 loss : 0.020825
[00:09:23.501] iteration 13769 : model1 loss : 0.432318 model2 loss : 0.018593
[00:09:23.678] iteration 13770 : model1 loss : 0.440182 model2 loss : 0.023168
[00:09:23.849] iteration 13771 : model1 loss : 0.436751 model2 loss : 0.021642
[00:09:24.026] iteration 13772 : model1 loss : 0.432357 model2 loss : 0.021154
[00:09:24.199] iteration 13773 : model1 loss : 0.439212 model2 loss : 0.021388
[00:09:24.381] iteration 13774 : model1 loss : 0.435515 model2 loss : 0.018509
[00:09:24.551] iteration 13775 : model1 loss : 0.434570 model2 loss : 0.020619
[00:09:24.727] iteration 13776 : model1 loss : 0.437280 model2 loss : 0.020940
[00:09:26.858] iteration 13777 : model1 loss : 0.436002 model2 loss : 0.019762
[00:09:27.032] iteration 13778 : model1 loss : 0.440245 model2 loss : 0.019036
[00:09:27.211] iteration 13779 : model1 loss : 0.439677 model2 loss : 0.021788
[00:09:27.384] iteration 13780 : model1 loss : 0.436861 model2 loss : 0.018159
[00:09:27.562] iteration 13781 : model1 loss : 0.440609 model2 loss : 0.021347
[00:09:27.735] iteration 13782 : model1 loss : 0.437098 model2 loss : 0.022195
[00:09:27.911] iteration 13783 : model1 loss : 0.434952 model2 loss : 0.022233
[00:09:28.082] iteration 13784 : model1 loss : 0.433567 model2 loss : 0.021448
[00:09:28.260] iteration 13785 : model1 loss : 0.435276 model2 loss : 0.019078
[00:09:28.433] iteration 13786 : model1 loss : 0.438656 model2 loss : 0.022250
[00:09:28.611] iteration 13787 : model1 loss : 0.440453 model2 loss : 0.024308
[00:09:28.785] iteration 13788 : model1 loss : 0.433289 model2 loss : 0.020812
[00:09:28.960] iteration 13789 : model1 loss : 0.437063 model2 loss : 0.019815
[00:09:29.132] iteration 13790 : model1 loss : 0.438515 model2 loss : 0.020593
[00:09:29.314] iteration 13791 : model1 loss : 0.436772 model2 loss : 0.020251
[00:09:29.487] iteration 13792 : model1 loss : 0.435283 model2 loss : 0.022634
[00:09:29.664] iteration 13793 : model1 loss : 0.435362 model2 loss : 0.020506
[00:09:29.835] iteration 13794 : model1 loss : 0.432287 model2 loss : 0.022059
[00:09:30.011] iteration 13795 : model1 loss : 0.435296 model2 loss : 0.021937
[00:09:30.183] iteration 13796 : model1 loss : 0.437017 model2 loss : 0.021127
[00:09:30.361] iteration 13797 : model1 loss : 0.437228 model2 loss : 0.018072
[00:09:32.537] iteration 13798 : model1 loss : 0.437265 model2 loss : 0.021003
[00:09:32.711] iteration 13799 : model1 loss : 0.441101 model2 loss : 0.019982
[00:09:32.890] iteration 13800 : model1 loss : 0.439457 model2 loss : 0.020867
[00:09:33.060] iteration 13801 : model1 loss : 0.436076 model2 loss : 0.021880
[00:09:33.237] iteration 13802 : model1 loss : 0.434943 model2 loss : 0.018714
[00:09:33.409] iteration 13803 : model1 loss : 0.438965 model2 loss : 0.021594
[00:09:33.590] iteration 13804 : model1 loss : 0.436160 model2 loss : 0.021781
[00:09:33.765] iteration 13805 : model1 loss : 0.439859 model2 loss : 0.019983
[00:09:33.941] iteration 13806 : model1 loss : 0.436004 model2 loss : 0.021429
[00:09:34.111] iteration 13807 : model1 loss : 0.433641 model2 loss : 0.021358
[00:09:34.288] iteration 13808 : model1 loss : 0.439908 model2 loss : 0.022228
[00:09:34.462] iteration 13809 : model1 loss : 0.435013 model2 loss : 0.021491
[00:09:34.641] iteration 13810 : model1 loss : 0.441073 model2 loss : 0.025880
[00:09:34.815] iteration 13811 : model1 loss : 0.433203 model2 loss : 0.019084
[00:09:34.993] iteration 13812 : model1 loss : 0.436176 model2 loss : 0.024632
[00:09:35.167] iteration 13813 : model1 loss : 0.433290 model2 loss : 0.018851
[00:09:35.346] iteration 13814 : model1 loss : 0.437040 model2 loss : 0.020190
[00:09:35.517] iteration 13815 : model1 loss : 0.435288 model2 loss : 0.021382
[00:09:35.697] iteration 13816 : model1 loss : 0.436207 model2 loss : 0.022966
[00:09:35.866] iteration 13817 : model1 loss : 0.437819 model2 loss : 0.019921
[00:09:36.044] iteration 13818 : model1 loss : 0.437168 model2 loss : 0.019517
[00:09:38.312] iteration 13819 : model1 loss : 0.433233 model2 loss : 0.019823
[00:09:38.483] iteration 13820 : model1 loss : 0.440559 model2 loss : 0.022684
[00:09:38.683] iteration 13821 : model1 loss : 0.437104 model2 loss : 0.020009
[00:09:38.857] iteration 13822 : model1 loss : 0.434372 model2 loss : 0.019226
[00:09:39.035] iteration 13823 : model1 loss : 0.435682 model2 loss : 0.022734
[00:09:39.206] iteration 13824 : model1 loss : 0.435710 model2 loss : 0.022370
[00:09:39.383] iteration 13825 : model1 loss : 0.437906 model2 loss : 0.037271
[00:09:39.554] iteration 13826 : model1 loss : 0.432783 model2 loss : 0.021238
[00:09:39.732] iteration 13827 : model1 loss : 0.436768 model2 loss : 0.022879
[00:09:39.903] iteration 13828 : model1 loss : 0.439738 model2 loss : 0.022823
[00:09:40.078] iteration 13829 : model1 loss : 0.438217 model2 loss : 0.023909
[00:09:40.251] iteration 13830 : model1 loss : 0.437817 model2 loss : 0.022283
[00:09:40.430] iteration 13831 : model1 loss : 0.437997 model2 loss : 0.023317
[00:09:40.607] iteration 13832 : model1 loss : 0.440974 model2 loss : 0.026160
[00:09:40.784] iteration 13833 : model1 loss : 0.441887 model2 loss : 0.024247
[00:09:40.956] iteration 13834 : model1 loss : 0.435480 model2 loss : 0.022674
[00:09:41.130] iteration 13835 : model1 loss : 0.441747 model2 loss : 0.023405
[00:09:41.307] iteration 13836 : model1 loss : 0.439696 model2 loss : 0.023552
[00:09:41.485] iteration 13837 : model1 loss : 0.434975 model2 loss : 0.019469
[00:09:41.655] iteration 13838 : model1 loss : 0.433973 model2 loss : 0.019150
[00:09:41.830] iteration 13839 : model1 loss : 0.439640 model2 loss : 0.025509
[00:09:43.974] iteration 13840 : model1 loss : 0.434514 model2 loss : 0.020446
[00:09:44.156] iteration 13841 : model1 loss : 0.442119 model2 loss : 0.024982
[00:09:44.338] iteration 13842 : model1 loss : 0.434251 model2 loss : 0.020849
[00:09:44.508] iteration 13843 : model1 loss : 0.436031 model2 loss : 0.023767
[00:09:44.685] iteration 13844 : model1 loss : 0.438461 model2 loss : 0.023661
[00:09:44.860] iteration 13845 : model1 loss : 0.438363 model2 loss : 0.020157
[00:09:45.035] iteration 13846 : model1 loss : 0.434994 model2 loss : 0.020943
[00:09:45.205] iteration 13847 : model1 loss : 0.437299 model2 loss : 0.022538
[00:09:45.386] iteration 13848 : model1 loss : 0.432045 model2 loss : 0.021938
[00:09:45.558] iteration 13849 : model1 loss : 0.435642 model2 loss : 0.022289
[00:09:45.733] iteration 13850 : model1 loss : 0.436422 model2 loss : 0.020545
[00:09:45.903] iteration 13851 : model1 loss : 0.439893 model2 loss : 0.022594
[00:09:46.081] iteration 13852 : model1 loss : 0.440606 model2 loss : 0.024022
[00:09:46.253] iteration 13853 : model1 loss : 0.437137 model2 loss : 0.024270
[00:09:46.432] iteration 13854 : model1 loss : 0.443529 model2 loss : 0.023007
[00:09:46.606] iteration 13855 : model1 loss : 0.436113 model2 loss : 0.023614
[00:09:46.784] iteration 13856 : model1 loss : 0.439452 model2 loss : 0.020900
[00:09:46.956] iteration 13857 : model1 loss : 0.434816 model2 loss : 0.022572
[00:09:47.132] iteration 13858 : model1 loss : 0.438060 model2 loss : 0.026288
[00:09:47.306] iteration 13859 : model1 loss : 0.438959 model2 loss : 0.022981
[00:09:47.486] iteration 13860 : model1 loss : 0.435628 model2 loss : 0.020387
[00:09:49.608] iteration 13861 : model1 loss : 0.444379 model2 loss : 0.024994
[00:09:49.784] iteration 13862 : model1 loss : 0.439168 model2 loss : 0.021602
[00:09:49.960] iteration 13863 : model1 loss : 0.441520 model2 loss : 0.023593
[00:09:50.132] iteration 13864 : model1 loss : 0.441481 model2 loss : 0.023735
[00:09:50.316] iteration 13865 : model1 loss : 0.438885 model2 loss : 0.021422
[00:09:50.489] iteration 13866 : model1 loss : 0.436679 model2 loss : 0.020040
[00:09:50.665] iteration 13867 : model1 loss : 0.438558 model2 loss : 0.022586
[00:09:50.838] iteration 13868 : model1 loss : 0.434182 model2 loss : 0.017199
[00:09:51.016] iteration 13869 : model1 loss : 0.434482 model2 loss : 0.021459
[00:09:51.187] iteration 13870 : model1 loss : 0.436066 model2 loss : 0.022174
[00:09:51.370] iteration 13871 : model1 loss : 0.436595 model2 loss : 0.020144
[00:09:51.545] iteration 13872 : model1 loss : 0.434686 model2 loss : 0.020407
[00:09:51.723] iteration 13873 : model1 loss : 0.431207 model2 loss : 0.022286
[00:09:51.898] iteration 13874 : model1 loss : 0.438881 model2 loss : 0.025285
[00:09:52.074] iteration 13875 : model1 loss : 0.439073 model2 loss : 0.020320
[00:09:52.246] iteration 13876 : model1 loss : 0.436151 model2 loss : 0.019318
[00:09:52.430] iteration 13877 : model1 loss : 0.434850 model2 loss : 0.021473
[00:09:52.607] iteration 13878 : model1 loss : 0.437180 model2 loss : 0.020277
[00:09:52.784] iteration 13879 : model1 loss : 0.437513 model2 loss : 0.020320
[00:09:52.955] iteration 13880 : model1 loss : 0.434811 model2 loss : 0.020356
[00:09:53.128] iteration 13881 : model1 loss : 0.431981 model2 loss : 0.020595
[00:09:55.270] iteration 13882 : model1 loss : 0.434527 model2 loss : 0.022351
[00:09:55.442] iteration 13883 : model1 loss : 0.439997 model2 loss : 0.022262
[00:09:55.621] iteration 13884 : model1 loss : 0.441713 model2 loss : 0.028917
[00:09:55.795] iteration 13885 : model1 loss : 0.439014 model2 loss : 0.021924
[00:09:55.970] iteration 13886 : model1 loss : 0.440941 model2 loss : 0.023234
[00:09:56.141] iteration 13887 : model1 loss : 0.431899 model2 loss : 0.019812
[00:09:56.323] iteration 13888 : model1 loss : 0.437031 model2 loss : 0.019233
[00:09:56.497] iteration 13889 : model1 loss : 0.435631 model2 loss : 0.022742
[00:09:56.673] iteration 13890 : model1 loss : 0.438949 model2 loss : 0.018779
[00:09:56.845] iteration 13891 : model1 loss : 0.436245 model2 loss : 0.019331
[00:09:57.024] iteration 13892 : model1 loss : 0.440439 model2 loss : 0.019578
[00:09:57.195] iteration 13893 : model1 loss : 0.434533 model2 loss : 0.019197
[00:09:57.375] iteration 13894 : model1 loss : 0.429837 model2 loss : 0.021044
[00:09:57.547] iteration 13895 : model1 loss : 0.432094 model2 loss : 0.020677
[00:09:57.725] iteration 13896 : model1 loss : 0.438778 model2 loss : 0.021873
[00:09:57.898] iteration 13897 : model1 loss : 0.434206 model2 loss : 0.020297
[00:09:58.073] iteration 13898 : model1 loss : 0.439254 model2 loss : 0.023577
[00:09:58.244] iteration 13899 : model1 loss : 0.435456 model2 loss : 0.019428
[00:09:58.425] iteration 13900 : model1 loss : 0.437796 model2 loss : 0.020445
[00:09:58.598] iteration 13901 : model1 loss : 0.438714 model2 loss : 0.021802
[00:09:58.774] iteration 13902 : model1 loss : 0.437744 model2 loss : 0.020999
[00:10:00.902] iteration 13903 : model1 loss : 0.435727 model2 loss : 0.020705
[00:10:01.074] iteration 13904 : model1 loss : 0.439675 model2 loss : 0.018180
[00:10:01.256] iteration 13905 : model1 loss : 0.436105 model2 loss : 0.018128
[00:10:01.431] iteration 13906 : model1 loss : 0.437393 model2 loss : 0.021228
[00:10:01.610] iteration 13907 : model1 loss : 0.438467 model2 loss : 0.021284
[00:10:01.782] iteration 13908 : model1 loss : 0.434130 model2 loss : 0.023511
[00:10:01.960] iteration 13909 : model1 loss : 0.432316 model2 loss : 0.020100
[00:10:02.130] iteration 13910 : model1 loss : 0.439776 model2 loss : 0.022186
[00:10:02.312] iteration 13911 : model1 loss : 0.440031 model2 loss : 0.023416
[00:10:02.492] iteration 13912 : model1 loss : 0.436671 model2 loss : 0.022286
[00:10:02.667] iteration 13913 : model1 loss : 0.438789 model2 loss : 0.020299
[00:10:02.842] iteration 13914 : model1 loss : 0.435855 model2 loss : 0.024092
[00:10:03.018] iteration 13915 : model1 loss : 0.436605 model2 loss : 0.019570
[00:10:03.189] iteration 13916 : model1 loss : 0.435815 model2 loss : 0.019451
[00:10:03.367] iteration 13917 : model1 loss : 0.439691 model2 loss : 0.021096
[00:10:03.541] iteration 13918 : model1 loss : 0.435372 model2 loss : 0.020163
[00:10:03.716] iteration 13919 : model1 loss : 0.435973 model2 loss : 0.020669
[00:10:03.891] iteration 13920 : model1 loss : 0.439837 model2 loss : 0.020170
[00:10:04.064] iteration 13921 : model1 loss : 0.436629 model2 loss : 0.019489
[00:10:04.234] iteration 13922 : model1 loss : 0.435493 model2 loss : 0.018850
[00:10:04.412] iteration 13923 : model1 loss : 0.435049 model2 loss : 0.019587
[00:10:06.528] iteration 13924 : model1 loss : 0.437386 model2 loss : 0.019970
[00:10:06.704] iteration 13925 : model1 loss : 0.436844 model2 loss : 0.020352
[00:10:06.883] iteration 13926 : model1 loss : 0.437138 model2 loss : 0.020245
[00:10:07.053] iteration 13927 : model1 loss : 0.432394 model2 loss : 0.018735
[00:10:07.230] iteration 13928 : model1 loss : 0.433716 model2 loss : 0.019688
[00:10:07.414] iteration 13929 : model1 loss : 0.435725 model2 loss : 0.020372
[00:10:07.594] iteration 13930 : model1 loss : 0.434184 model2 loss : 0.018932
[00:10:07.767] iteration 13931 : model1 loss : 0.440012 model2 loss : 0.020673
[00:10:07.941] iteration 13932 : model1 loss : 0.439808 model2 loss : 0.020566
[00:10:08.115] iteration 13933 : model1 loss : 0.437285 model2 loss : 0.021442
[00:10:08.295] iteration 13934 : model1 loss : 0.441105 model2 loss : 0.022522
[00:10:08.469] iteration 13935 : model1 loss : 0.433263 model2 loss : 0.020496
[00:10:08.646] iteration 13936 : model1 loss : 0.436152 model2 loss : 0.021246
[00:10:08.820] iteration 13937 : model1 loss : 0.433989 model2 loss : 0.020250
[00:10:09.000] iteration 13938 : model1 loss : 0.436124 model2 loss : 0.023594
[00:10:09.171] iteration 13939 : model1 loss : 0.438321 model2 loss : 0.019081
[00:10:09.352] iteration 13940 : model1 loss : 0.437559 model2 loss : 0.021990
[00:10:09.522] iteration 13941 : model1 loss : 0.440184 model2 loss : 0.021087
[00:10:09.697] iteration 13942 : model1 loss : 0.437042 model2 loss : 0.019646
[00:10:09.869] iteration 13943 : model1 loss : 0.436813 model2 loss : 0.020654
[00:10:10.042] iteration 13944 : model1 loss : 0.436949 model2 loss : 0.020307
[00:10:12.177] iteration 13945 : model1 loss : 0.436096 model2 loss : 0.021307
[00:10:12.355] iteration 13946 : model1 loss : 0.442651 model2 loss : 0.020222
[00:10:12.536] iteration 13947 : model1 loss : 0.437826 model2 loss : 0.021480
[00:10:12.706] iteration 13948 : model1 loss : 0.435129 model2 loss : 0.019916
[00:10:12.881] iteration 13949 : model1 loss : 0.439432 model2 loss : 0.021335
[00:10:13.050] iteration 13950 : model1 loss : 0.441733 model2 loss : 0.022415
[00:10:13.226] iteration 13951 : model1 loss : 0.441151 model2 loss : 0.023047
[00:10:13.404] iteration 13952 : model1 loss : 0.430878 model2 loss : 0.019002
[00:10:13.580] iteration 13953 : model1 loss : 0.439682 model2 loss : 0.021246
[00:10:13.751] iteration 13954 : model1 loss : 0.436191 model2 loss : 0.020542
[00:10:13.929] iteration 13955 : model1 loss : 0.441520 model2 loss : 0.024118
[00:10:14.100] iteration 13956 : model1 loss : 0.437197 model2 loss : 0.021626
[00:10:14.278] iteration 13957 : model1 loss : 0.434935 model2 loss : 0.019132
[00:10:14.453] iteration 13958 : model1 loss : 0.434072 model2 loss : 0.019916
[00:10:14.633] iteration 13959 : model1 loss : 0.437241 model2 loss : 0.019433
[00:10:14.808] iteration 13960 : model1 loss : 0.438502 model2 loss : 0.020310
[00:10:14.984] iteration 13961 : model1 loss : 0.433467 model2 loss : 0.019948
[00:10:15.156] iteration 13962 : model1 loss : 0.433998 model2 loss : 0.020029
[00:10:15.336] iteration 13963 : model1 loss : 0.436473 model2 loss : 0.019347
[00:10:15.505] iteration 13964 : model1 loss : 0.440599 model2 loss : 0.022598
[00:10:15.677] iteration 13965 : model1 loss : 0.434599 model2 loss : 0.019759
[00:10:17.814] iteration 13966 : model1 loss : 0.434368 model2 loss : 0.020517
[00:10:17.986] iteration 13967 : model1 loss : 0.443168 model2 loss : 0.023600
[00:10:18.165] iteration 13968 : model1 loss : 0.436147 model2 loss : 0.018830
[00:10:18.349] iteration 13969 : model1 loss : 0.432818 model2 loss : 0.019316
[00:10:18.529] iteration 13970 : model1 loss : 0.435372 model2 loss : 0.020239
[00:10:18.700] iteration 13971 : model1 loss : 0.431777 model2 loss : 0.019278
[00:10:18.877] iteration 13972 : model1 loss : 0.437563 model2 loss : 0.018952
[00:10:19.047] iteration 13973 : model1 loss : 0.444224 model2 loss : 0.022399
[00:10:19.227] iteration 13974 : model1 loss : 0.439705 model2 loss : 0.021414
[00:10:19.403] iteration 13975 : model1 loss : 0.443898 model2 loss : 0.026254
[00:10:19.581] iteration 13976 : model1 loss : 0.437061 model2 loss : 0.017672
[00:10:19.754] iteration 13977 : model1 loss : 0.436988 model2 loss : 0.019602
[00:10:19.931] iteration 13978 : model1 loss : 0.434314 model2 loss : 0.019556
[00:10:20.102] iteration 13979 : model1 loss : 0.437614 model2 loss : 0.020462
[00:10:20.280] iteration 13980 : model1 loss : 0.438566 model2 loss : 0.018275
[00:10:20.452] iteration 13981 : model1 loss : 0.440475 model2 loss : 0.023114
[00:10:20.632] iteration 13982 : model1 loss : 0.438132 model2 loss : 0.019651
[00:10:20.806] iteration 13983 : model1 loss : 0.437345 model2 loss : 0.020860
[00:10:20.987] iteration 13984 : model1 loss : 0.434023 model2 loss : 0.020553
[00:10:21.156] iteration 13985 : model1 loss : 0.441838 model2 loss : 0.023443
[00:10:21.338] iteration 13986 : model1 loss : 0.437935 model2 loss : 0.018244
[00:10:23.492] iteration 13987 : model1 loss : 0.441091 model2 loss : 0.023328
[00:10:23.668] iteration 13988 : model1 loss : 0.435336 model2 loss : 0.020291
[00:10:23.846] iteration 13989 : model1 loss : 0.436135 model2 loss : 0.019819
[00:10:24.017] iteration 13990 : model1 loss : 0.438368 model2 loss : 0.021196
[00:10:24.193] iteration 13991 : model1 loss : 0.437172 model2 loss : 0.021754
[00:10:24.370] iteration 13992 : model1 loss : 0.438631 model2 loss : 0.020528
[00:10:24.548] iteration 13993 : model1 loss : 0.437143 model2 loss : 0.023276
[00:10:24.719] iteration 13994 : model1 loss : 0.439719 model2 loss : 0.021644
[00:10:24.897] iteration 13995 : model1 loss : 0.438024 model2 loss : 0.021779
[00:10:25.072] iteration 13996 : model1 loss : 0.437281 model2 loss : 0.020868
[00:10:25.248] iteration 13997 : model1 loss : 0.439670 model2 loss : 0.022232
[00:10:25.423] iteration 13998 : model1 loss : 0.437535 model2 loss : 0.020066
[00:10:25.605] iteration 13999 : model1 loss : 0.434595 model2 loss : 0.018216
[00:10:25.776] iteration 14000 : model1 loss : 0.439898 model2 loss : 0.021114
[00:10:34.915] iteration 14000 : model1_mean_dice : 0.824267 model1_mean_hd95 : 12.619521
[00:10:44.178] iteration 14000 : model2_mean_dice : 0.870825 model2_mean_hd95 : 7.500257
[00:10:44.367] iteration 14001 : model1 loss : 0.435375 model2 loss : 0.019901
[00:10:44.549] iteration 14002 : model1 loss : 0.435622 model2 loss : 0.021164
[00:10:44.720] iteration 14003 : model1 loss : 0.435990 model2 loss : 0.020983
[00:10:44.900] iteration 14004 : model1 loss : 0.442252 model2 loss : 0.026924
[00:10:45.070] iteration 14005 : model1 loss : 0.436267 model2 loss : 0.022545
[00:10:45.245] iteration 14006 : model1 loss : 0.435269 model2 loss : 0.023362
[00:10:45.416] iteration 14007 : model1 loss : 0.438531 model2 loss : 0.020927
[00:10:47.576] iteration 14008 : model1 loss : 0.436715 model2 loss : 0.023707
[00:10:47.751] iteration 14009 : model1 loss : 0.438182 model2 loss : 0.021559
[00:10:47.932] iteration 14010 : model1 loss : 0.435018 model2 loss : 0.023118
[00:10:48.101] iteration 14011 : model1 loss : 0.436091 model2 loss : 0.021409
[00:10:48.278] iteration 14012 : model1 loss : 0.441009 model2 loss : 0.020736
[00:10:48.448] iteration 14013 : model1 loss : 0.437633 model2 loss : 0.020940
[00:10:48.631] iteration 14014 : model1 loss : 0.438309 model2 loss : 0.023007
[00:10:48.801] iteration 14015 : model1 loss : 0.439354 model2 loss : 0.022672
[00:10:48.976] iteration 14016 : model1 loss : 0.434468 model2 loss : 0.023194
[00:10:49.148] iteration 14017 : model1 loss : 0.434757 model2 loss : 0.021134
[00:10:49.328] iteration 14018 : model1 loss : 0.438433 model2 loss : 0.019967
[00:10:49.499] iteration 14019 : model1 loss : 0.438210 model2 loss : 0.021065
[00:10:49.677] iteration 14020 : model1 loss : 0.437419 model2 loss : 0.022316
[00:10:49.854] iteration 14021 : model1 loss : 0.438097 model2 loss : 0.020834
[00:10:50.032] iteration 14022 : model1 loss : 0.436019 model2 loss : 0.021126
[00:10:50.204] iteration 14023 : model1 loss : 0.439069 model2 loss : 0.026611
[00:10:50.383] iteration 14024 : model1 loss : 0.436902 model2 loss : 0.024932
[00:10:50.555] iteration 14025 : model1 loss : 0.435636 model2 loss : 0.020285
[00:10:50.733] iteration 14026 : model1 loss : 0.436919 model2 loss : 0.019412
[00:10:50.905] iteration 14027 : model1 loss : 0.440407 model2 loss : 0.024678
[00:10:51.081] iteration 14028 : model1 loss : 0.436088 model2 loss : 0.020011
[00:10:53.261] iteration 14029 : model1 loss : 0.440850 model2 loss : 0.023454
[00:10:53.434] iteration 14030 : model1 loss : 0.437813 model2 loss : 0.021177
[00:10:53.614] iteration 14031 : model1 loss : 0.442159 model2 loss : 0.029248
[00:10:53.784] iteration 14032 : model1 loss : 0.442946 model2 loss : 0.024092
[00:10:53.983] iteration 14033 : model1 loss : 0.434789 model2 loss : 0.019898
[00:10:54.154] iteration 14034 : model1 loss : 0.434180 model2 loss : 0.021894
[00:10:54.334] iteration 14035 : model1 loss : 0.433585 model2 loss : 0.021090
[00:10:54.505] iteration 14036 : model1 loss : 0.440066 model2 loss : 0.023382
[00:10:54.683] iteration 14037 : model1 loss : 0.441607 model2 loss : 0.026083
[00:10:54.858] iteration 14038 : model1 loss : 0.439685 model2 loss : 0.022085
[00:10:55.036] iteration 14039 : model1 loss : 0.432271 model2 loss : 0.022652
[00:10:55.212] iteration 14040 : model1 loss : 0.437687 model2 loss : 0.021075
[00:10:55.388] iteration 14041 : model1 loss : 0.430650 model2 loss : 0.020925
[00:10:55.559] iteration 14042 : model1 loss : 0.432108 model2 loss : 0.019538
[00:10:55.736] iteration 14043 : model1 loss : 0.442984 model2 loss : 0.021801
[00:10:55.906] iteration 14044 : model1 loss : 0.437155 model2 loss : 0.022989
[00:10:56.081] iteration 14045 : model1 loss : 0.434853 model2 loss : 0.021382
[00:10:56.253] iteration 14046 : model1 loss : 0.434779 model2 loss : 0.019631
[00:10:56.432] iteration 14047 : model1 loss : 0.437361 model2 loss : 0.022601
[00:10:56.606] iteration 14048 : model1 loss : 0.435145 model2 loss : 0.021210
[00:10:56.782] iteration 14049 : model1 loss : 0.438812 model2 loss : 0.023251
[00:10:58.916] iteration 14050 : model1 loss : 0.434244 model2 loss : 0.021840
[00:10:59.086] iteration 14051 : model1 loss : 0.439101 model2 loss : 0.019607
[00:10:59.267] iteration 14052 : model1 loss : 0.437631 model2 loss : 0.021290
[00:10:59.440] iteration 14053 : model1 loss : 0.437254 model2 loss : 0.020850
[00:10:59.619] iteration 14054 : model1 loss : 0.434031 model2 loss : 0.021321
[00:10:59.798] iteration 14055 : model1 loss : 0.440949 model2 loss : 0.021154
[00:10:59.979] iteration 14056 : model1 loss : 0.432986 model2 loss : 0.021298
[00:11:00.154] iteration 14057 : model1 loss : 0.441549 model2 loss : 0.020590
[00:11:00.337] iteration 14058 : model1 loss : 0.437547 model2 loss : 0.020455
[00:11:00.508] iteration 14059 : model1 loss : 0.430654 model2 loss : 0.019217
[00:11:00.686] iteration 14060 : model1 loss : 0.438787 model2 loss : 0.021821
[00:11:00.857] iteration 14061 : model1 loss : 0.436965 model2 loss : 0.020255
[00:11:01.035] iteration 14062 : model1 loss : 0.437480 model2 loss : 0.022381
[00:11:01.207] iteration 14063 : model1 loss : 0.438696 model2 loss : 0.021572
[00:11:01.385] iteration 14064 : model1 loss : 0.437930 model2 loss : 0.019991
[00:11:01.559] iteration 14065 : model1 loss : 0.438770 model2 loss : 0.024033
[00:11:01.734] iteration 14066 : model1 loss : 0.438795 model2 loss : 0.024512
[00:11:01.906] iteration 14067 : model1 loss : 0.442385 model2 loss : 0.023844
[00:11:02.082] iteration 14068 : model1 loss : 0.437619 model2 loss : 0.023232
[00:11:02.253] iteration 14069 : model1 loss : 0.436785 model2 loss : 0.021386
[00:11:02.431] iteration 14070 : model1 loss : 0.431685 model2 loss : 0.018922
[00:11:04.584] iteration 14071 : model1 loss : 0.433150 model2 loss : 0.018149
[00:11:04.757] iteration 14072 : model1 loss : 0.438598 model2 loss : 0.020903
[00:11:04.941] iteration 14073 : model1 loss : 0.431429 model2 loss : 0.017640
[00:11:05.114] iteration 14074 : model1 loss : 0.438491 model2 loss : 0.021573
[00:11:05.292] iteration 14075 : model1 loss : 0.438804 model2 loss : 0.023371
[00:11:05.464] iteration 14076 : model1 loss : 0.434850 model2 loss : 0.020228
[00:11:05.644] iteration 14077 : model1 loss : 0.438995 model2 loss : 0.023608
[00:11:05.814] iteration 14078 : model1 loss : 0.439000 model2 loss : 0.023368
[00:11:05.991] iteration 14079 : model1 loss : 0.438151 model2 loss : 0.023673
[00:11:06.163] iteration 14080 : model1 loss : 0.438061 model2 loss : 0.021736
[00:11:06.343] iteration 14081 : model1 loss : 0.438578 model2 loss : 0.021491
[00:11:06.516] iteration 14082 : model1 loss : 0.435744 model2 loss : 0.020409
[00:11:06.690] iteration 14083 : model1 loss : 0.438283 model2 loss : 0.020891
[00:11:06.863] iteration 14084 : model1 loss : 0.435582 model2 loss : 0.019463
[00:11:07.041] iteration 14085 : model1 loss : 0.438565 model2 loss : 0.021310
[00:11:07.213] iteration 14086 : model1 loss : 0.435358 model2 loss : 0.021507
[00:11:07.394] iteration 14087 : model1 loss : 0.437227 model2 loss : 0.021598
[00:11:07.569] iteration 14088 : model1 loss : 0.436771 model2 loss : 0.021593
[00:11:07.745] iteration 14089 : model1 loss : 0.439960 model2 loss : 0.021939
[00:11:07.915] iteration 14090 : model1 loss : 0.434421 model2 loss : 0.019615
[00:11:08.092] iteration 14091 : model1 loss : 0.438330 model2 loss : 0.021801
[00:11:10.247] iteration 14092 : model1 loss : 0.433951 model2 loss : 0.019529
[00:11:10.424] iteration 14093 : model1 loss : 0.438607 model2 loss : 0.022884
[00:11:10.604] iteration 14094 : model1 loss : 0.436580 model2 loss : 0.019740
[00:11:10.777] iteration 14095 : model1 loss : 0.434986 model2 loss : 0.020916
[00:11:10.956] iteration 14096 : model1 loss : 0.432709 model2 loss : 0.018619
[00:11:11.126] iteration 14097 : model1 loss : 0.435717 model2 loss : 0.020631
[00:11:11.304] iteration 14098 : model1 loss : 0.436981 model2 loss : 0.021376
[00:11:11.477] iteration 14099 : model1 loss : 0.443252 model2 loss : 0.023520
[00:11:11.657] iteration 14100 : model1 loss : 0.437294 model2 loss : 0.023357
[00:11:11.829] iteration 14101 : model1 loss : 0.436212 model2 loss : 0.018352
[00:11:12.005] iteration 14102 : model1 loss : 0.443154 model2 loss : 0.024301
[00:11:12.177] iteration 14103 : model1 loss : 0.434426 model2 loss : 0.017930
[00:11:12.357] iteration 14104 : model1 loss : 0.434462 model2 loss : 0.020262
[00:11:12.530] iteration 14105 : model1 loss : 0.439462 model2 loss : 0.025478
[00:11:12.705] iteration 14106 : model1 loss : 0.438000 model2 loss : 0.020477
[00:11:12.877] iteration 14107 : model1 loss : 0.436501 model2 loss : 0.019925
[00:11:13.053] iteration 14108 : model1 loss : 0.434904 model2 loss : 0.020954
[00:11:13.225] iteration 14109 : model1 loss : 0.436025 model2 loss : 0.022821
[00:11:13.402] iteration 14110 : model1 loss : 0.439576 model2 loss : 0.020270
[00:11:13.574] iteration 14111 : model1 loss : 0.440778 model2 loss : 0.021123
[00:11:13.749] iteration 14112 : model1 loss : 0.440852 model2 loss : 0.023669
[00:11:15.883] iteration 14113 : model1 loss : 0.436946 model2 loss : 0.020031
[00:11:16.054] iteration 14114 : model1 loss : 0.434218 model2 loss : 0.022053
[00:11:16.233] iteration 14115 : model1 loss : 0.439315 model2 loss : 0.023872
[00:11:16.407] iteration 14116 : model1 loss : 0.436365 model2 loss : 0.020817
[00:11:16.585] iteration 14117 : model1 loss : 0.437470 model2 loss : 0.022035
[00:11:16.758] iteration 14118 : model1 loss : 0.440212 model2 loss : 0.021534
[00:11:16.935] iteration 14119 : model1 loss : 0.437555 model2 loss : 0.021255
[00:11:17.108] iteration 14120 : model1 loss : 0.437938 model2 loss : 0.019688
[00:11:17.287] iteration 14121 : model1 loss : 0.435783 model2 loss : 0.020994
[00:11:17.462] iteration 14122 : model1 loss : 0.442189 model2 loss : 0.022200
[00:11:17.639] iteration 14123 : model1 loss : 0.431646 model2 loss : 0.020033
[00:11:17.810] iteration 14124 : model1 loss : 0.433490 model2 loss : 0.020009
[00:11:17.988] iteration 14125 : model1 loss : 0.438939 model2 loss : 0.021789
[00:11:18.159] iteration 14126 : model1 loss : 0.443032 model2 loss : 0.021818
[00:11:18.341] iteration 14127 : model1 loss : 0.431390 model2 loss : 0.018805
[00:11:18.513] iteration 14128 : model1 loss : 0.438935 model2 loss : 0.020792
[00:11:18.691] iteration 14129 : model1 loss : 0.434061 model2 loss : 0.018219
[00:11:18.864] iteration 14130 : model1 loss : 0.439951 model2 loss : 0.023416
[00:11:19.041] iteration 14131 : model1 loss : 0.438903 model2 loss : 0.022707
[00:11:19.210] iteration 14132 : model1 loss : 0.434169 model2 loss : 0.024094
[00:11:19.387] iteration 14133 : model1 loss : 0.439011 model2 loss : 0.020692
[00:11:21.538] iteration 14134 : model1 loss : 0.438355 model2 loss : 0.021011
[00:11:21.709] iteration 14135 : model1 loss : 0.439538 model2 loss : 0.020623
[00:11:21.886] iteration 14136 : model1 loss : 0.436989 model2 loss : 0.019400
[00:11:22.059] iteration 14137 : model1 loss : 0.434178 model2 loss : 0.021458
[00:11:22.235] iteration 14138 : model1 loss : 0.435846 model2 loss : 0.018870
[00:11:22.409] iteration 14139 : model1 loss : 0.437446 model2 loss : 0.022177
[00:11:22.586] iteration 14140 : model1 loss : 0.435908 model2 loss : 0.018502
[00:11:22.757] iteration 14141 : model1 loss : 0.432815 model2 loss : 0.019320
[00:11:22.930] iteration 14142 : model1 loss : 0.442881 model2 loss : 0.020149
[00:11:23.103] iteration 14143 : model1 loss : 0.436766 model2 loss : 0.018548
[00:11:23.281] iteration 14144 : model1 loss : 0.438076 model2 loss : 0.019217
[00:11:23.452] iteration 14145 : model1 loss : 0.433876 model2 loss : 0.016822
[00:11:23.632] iteration 14146 : model1 loss : 0.435702 model2 loss : 0.020291
[00:11:23.804] iteration 14147 : model1 loss : 0.435924 model2 loss : 0.022673
[00:11:23.980] iteration 14148 : model1 loss : 0.439599 model2 loss : 0.023529
[00:11:24.151] iteration 14149 : model1 loss : 0.441269 model2 loss : 0.024189
[00:11:24.332] iteration 14150 : model1 loss : 0.438044 model2 loss : 0.021590
[00:11:24.503] iteration 14151 : model1 loss : 0.436300 model2 loss : 0.024530
[00:11:24.681] iteration 14152 : model1 loss : 0.434522 model2 loss : 0.021414
[00:11:24.851] iteration 14153 : model1 loss : 0.435449 model2 loss : 0.021095
[00:11:25.025] iteration 14154 : model1 loss : 0.436999 model2 loss : 0.022741
[00:11:27.197] iteration 14155 : model1 loss : 0.437740 model2 loss : 0.020533
[00:11:27.377] iteration 14156 : model1 loss : 0.428921 model2 loss : 0.018178
[00:11:27.557] iteration 14157 : model1 loss : 0.435965 model2 loss : 0.020997
[00:11:27.731] iteration 14158 : model1 loss : 0.434038 model2 loss : 0.021882
[00:11:27.906] iteration 14159 : model1 loss : 0.439299 model2 loss : 0.021586
[00:11:28.082] iteration 14160 : model1 loss : 0.436454 model2 loss : 0.019394
[00:11:28.260] iteration 14161 : model1 loss : 0.437838 model2 loss : 0.023659
[00:11:28.430] iteration 14162 : model1 loss : 0.436948 model2 loss : 0.019121
[00:11:28.610] iteration 14163 : model1 loss : 0.439332 model2 loss : 0.022510
[00:11:28.785] iteration 14164 : model1 loss : 0.434576 model2 loss : 0.021531
[00:11:28.964] iteration 14165 : model1 loss : 0.438381 model2 loss : 0.021232
[00:11:29.137] iteration 14166 : model1 loss : 0.438071 model2 loss : 0.020890
[00:11:29.316] iteration 14167 : model1 loss : 0.438974 model2 loss : 0.021934
[00:11:29.487] iteration 14168 : model1 loss : 0.435038 model2 loss : 0.020569
[00:11:29.667] iteration 14169 : model1 loss : 0.441673 model2 loss : 0.022632
[00:11:29.837] iteration 14170 : model1 loss : 0.436848 model2 loss : 0.021693
[00:11:30.015] iteration 14171 : model1 loss : 0.435445 model2 loss : 0.020889
[00:11:30.187] iteration 14172 : model1 loss : 0.438393 model2 loss : 0.019343
[00:11:30.369] iteration 14173 : model1 loss : 0.436927 model2 loss : 0.020310
[00:11:30.539] iteration 14174 : model1 loss : 0.436403 model2 loss : 0.018494
[00:11:30.714] iteration 14175 : model1 loss : 0.439165 model2 loss : 0.022244
[00:11:32.873] iteration 14176 : model1 loss : 0.433986 model2 loss : 0.021273
[00:11:33.049] iteration 14177 : model1 loss : 0.438363 model2 loss : 0.022320
[00:11:33.229] iteration 14178 : model1 loss : 0.437034 model2 loss : 0.021330
[00:11:33.402] iteration 14179 : model1 loss : 0.436414 model2 loss : 0.023442
[00:11:33.578] iteration 14180 : model1 loss : 0.438884 model2 loss : 0.024028
[00:11:33.753] iteration 14181 : model1 loss : 0.434726 model2 loss : 0.019858
[00:11:33.933] iteration 14182 : model1 loss : 0.433402 model2 loss : 0.020656
[00:11:34.104] iteration 14183 : model1 loss : 0.435897 model2 loss : 0.019768
[00:11:34.282] iteration 14184 : model1 loss : 0.434692 model2 loss : 0.020094
[00:11:34.452] iteration 14185 : model1 loss : 0.438742 model2 loss : 0.021137
[00:11:34.632] iteration 14186 : model1 loss : 0.435477 model2 loss : 0.020754
[00:11:34.804] iteration 14187 : model1 loss : 0.436777 model2 loss : 0.021903
[00:11:34.978] iteration 14188 : model1 loss : 0.439221 model2 loss : 0.017914
[00:11:35.150] iteration 14189 : model1 loss : 0.438859 model2 loss : 0.020290
[00:11:35.334] iteration 14190 : model1 loss : 0.433370 model2 loss : 0.020412
[00:11:35.508] iteration 14191 : model1 loss : 0.433318 model2 loss : 0.021878
[00:11:35.685] iteration 14192 : model1 loss : 0.436752 model2 loss : 0.020512
[00:11:35.860] iteration 14193 : model1 loss : 0.441319 model2 loss : 0.019494
[00:11:36.037] iteration 14194 : model1 loss : 0.439491 model2 loss : 0.020423
[00:11:36.206] iteration 14195 : model1 loss : 0.438519 model2 loss : 0.020351
[00:11:36.383] iteration 14196 : model1 loss : 0.435675 model2 loss : 0.019941
[00:11:38.530] iteration 14197 : model1 loss : 0.439162 model2 loss : 0.024368
[00:11:38.704] iteration 14198 : model1 loss : 0.436516 model2 loss : 0.019874
[00:11:38.884] iteration 14199 : model1 loss : 0.435479 model2 loss : 0.020689
[00:11:39.058] iteration 14200 : model1 loss : 0.432734 model2 loss : 0.020427
[00:11:39.238] iteration 14201 : model1 loss : 0.440989 model2 loss : 0.021211
[00:11:39.411] iteration 14202 : model1 loss : 0.433588 model2 loss : 0.018572
[00:11:39.592] iteration 14203 : model1 loss : 0.440890 model2 loss : 0.020920
[00:11:39.764] iteration 14204 : model1 loss : 0.433429 model2 loss : 0.020871
[00:11:39.940] iteration 14205 : model1 loss : 0.434121 model2 loss : 0.016946
[00:11:40.112] iteration 14206 : model1 loss : 0.437454 model2 loss : 0.020172
[00:11:40.291] iteration 14207 : model1 loss : 0.436467 model2 loss : 0.021632
[00:11:40.464] iteration 14208 : model1 loss : 0.436181 model2 loss : 0.021189
[00:11:40.641] iteration 14209 : model1 loss : 0.437053 model2 loss : 0.021459
[00:11:40.812] iteration 14210 : model1 loss : 0.439049 model2 loss : 0.021655
[00:11:40.992] iteration 14211 : model1 loss : 0.435765 model2 loss : 0.020544
[00:11:41.162] iteration 14212 : model1 loss : 0.438266 model2 loss : 0.020364
[00:11:41.343] iteration 14213 : model1 loss : 0.435734 model2 loss : 0.020752
[00:11:41.514] iteration 14214 : model1 loss : 0.441187 model2 loss : 0.026504
[00:11:41.692] iteration 14215 : model1 loss : 0.437095 model2 loss : 0.022452
[00:11:41.861] iteration 14216 : model1 loss : 0.434775 model2 loss : 0.020272
[00:11:42.035] iteration 14217 : model1 loss : 0.439065 model2 loss : 0.020886
[00:11:44.171] iteration 14218 : model1 loss : 0.435619 model2 loss : 0.018938
[00:11:44.350] iteration 14219 : model1 loss : 0.434320 model2 loss : 0.018376
[00:11:44.530] iteration 14220 : model1 loss : 0.440074 model2 loss : 0.024738
[00:11:44.704] iteration 14221 : model1 loss : 0.432234 model2 loss : 0.018285
[00:11:44.882] iteration 14222 : model1 loss : 0.439810 model2 loss : 0.021813
[00:11:45.051] iteration 14223 : model1 loss : 0.436471 model2 loss : 0.021012
[00:11:45.230] iteration 14224 : model1 loss : 0.437799 model2 loss : 0.020538
[00:11:45.403] iteration 14225 : model1 loss : 0.434728 model2 loss : 0.019809
[00:11:45.582] iteration 14226 : model1 loss : 0.435222 model2 loss : 0.021271
[00:11:45.755] iteration 14227 : model1 loss : 0.441783 model2 loss : 0.019500
[00:11:45.931] iteration 14228 : model1 loss : 0.432697 model2 loss : 0.020866
[00:11:46.104] iteration 14229 : model1 loss : 0.435908 model2 loss : 0.019278
[00:11:46.283] iteration 14230 : model1 loss : 0.438283 model2 loss : 0.020870
[00:11:46.454] iteration 14231 : model1 loss : 0.436352 model2 loss : 0.019135
[00:11:46.636] iteration 14232 : model1 loss : 0.442427 model2 loss : 0.021510
[00:11:46.806] iteration 14233 : model1 loss : 0.437028 model2 loss : 0.021654
[00:11:46.984] iteration 14234 : model1 loss : 0.430730 model2 loss : 0.019130
[00:11:47.156] iteration 14235 : model1 loss : 0.441654 model2 loss : 0.022857
[00:11:47.341] iteration 14236 : model1 loss : 0.438116 model2 loss : 0.022749
[00:11:47.514] iteration 14237 : model1 loss : 0.437527 model2 loss : 0.022660
[00:11:47.689] iteration 14238 : model1 loss : 0.436679 model2 loss : 0.022285
[00:11:49.814] iteration 14239 : model1 loss : 0.434556 model2 loss : 0.020250
[00:11:49.994] iteration 14240 : model1 loss : 0.436886 model2 loss : 0.023569
[00:11:50.171] iteration 14241 : model1 loss : 0.439551 model2 loss : 0.024905
[00:11:50.343] iteration 14242 : model1 loss : 0.441291 model2 loss : 0.022486
[00:11:50.522] iteration 14243 : model1 loss : 0.435211 model2 loss : 0.020543
[00:11:50.694] iteration 14244 : model1 loss : 0.436860 model2 loss : 0.024887
[00:11:50.872] iteration 14245 : model1 loss : 0.436667 model2 loss : 0.022521
[00:11:51.042] iteration 14246 : model1 loss : 0.435817 model2 loss : 0.021578
[00:11:51.220] iteration 14247 : model1 loss : 0.434175 model2 loss : 0.019236
[00:11:51.392] iteration 14248 : model1 loss : 0.429476 model2 loss : 0.017808
[00:11:51.569] iteration 14249 : model1 loss : 0.439909 model2 loss : 0.019697
[00:11:51.740] iteration 14250 : model1 loss : 0.433991 model2 loss : 0.022906
[00:11:51.917] iteration 14251 : model1 loss : 0.437752 model2 loss : 0.020001
[00:11:52.089] iteration 14252 : model1 loss : 0.439316 model2 loss : 0.020491
[00:11:52.266] iteration 14253 : model1 loss : 0.437337 model2 loss : 0.017925
[00:11:52.440] iteration 14254 : model1 loss : 0.436804 model2 loss : 0.019953
[00:11:52.623] iteration 14255 : model1 loss : 0.438395 model2 loss : 0.020024
[00:11:52.796] iteration 14256 : model1 loss : 0.435973 model2 loss : 0.019131
[00:11:52.972] iteration 14257 : model1 loss : 0.439029 model2 loss : 0.021041
[00:11:53.141] iteration 14258 : model1 loss : 0.441089 model2 loss : 0.023350
[00:11:53.318] iteration 14259 : model1 loss : 0.435544 model2 loss : 0.018380
[00:11:55.457] iteration 14260 : model1 loss : 0.433989 model2 loss : 0.020992
[00:11:55.631] iteration 14261 : model1 loss : 0.436946 model2 loss : 0.022952
[00:11:55.810] iteration 14262 : model1 loss : 0.436511 model2 loss : 0.019239
[00:11:55.982] iteration 14263 : model1 loss : 0.439553 model2 loss : 0.023630
[00:11:56.160] iteration 14264 : model1 loss : 0.438105 model2 loss : 0.020477
[00:11:56.337] iteration 14265 : model1 loss : 0.436534 model2 loss : 0.019710
[00:11:56.517] iteration 14266 : model1 loss : 0.432734 model2 loss : 0.019897
[00:11:56.690] iteration 14267 : model1 loss : 0.436125 model2 loss : 0.020880
[00:11:56.870] iteration 14268 : model1 loss : 0.436303 model2 loss : 0.020233
[00:11:57.041] iteration 14269 : model1 loss : 0.435660 model2 loss : 0.021036
[00:11:57.218] iteration 14270 : model1 loss : 0.435964 model2 loss : 0.020324
[00:11:57.391] iteration 14271 : model1 loss : 0.441529 model2 loss : 0.023375
[00:11:57.572] iteration 14272 : model1 loss : 0.437345 model2 loss : 0.023455
[00:11:57.743] iteration 14273 : model1 loss : 0.435562 model2 loss : 0.019012
[00:11:57.921] iteration 14274 : model1 loss : 0.438732 model2 loss : 0.021085
[00:11:58.092] iteration 14275 : model1 loss : 0.438555 model2 loss : 0.023118
[00:11:58.269] iteration 14276 : model1 loss : 0.440497 model2 loss : 0.024349
[00:11:58.441] iteration 14277 : model1 loss : 0.438654 model2 loss : 0.021270
[00:11:58.620] iteration 14278 : model1 loss : 0.435952 model2 loss : 0.019180
[00:11:58.790] iteration 14279 : model1 loss : 0.436133 model2 loss : 0.024158
[00:11:58.966] iteration 14280 : model1 loss : 0.434386 model2 loss : 0.021189
[00:12:01.089] iteration 14281 : model1 loss : 0.438796 model2 loss : 0.018863
[00:12:01.261] iteration 14282 : model1 loss : 0.434751 model2 loss : 0.020465
[00:12:01.445] iteration 14283 : model1 loss : 0.436492 model2 loss : 0.023639
[00:12:01.618] iteration 14284 : model1 loss : 0.438341 model2 loss : 0.020203
[00:12:01.794] iteration 14285 : model1 loss : 0.436262 model2 loss : 0.018393
[00:12:01.969] iteration 14286 : model1 loss : 0.434363 model2 loss : 0.021519
[00:12:02.144] iteration 14287 : model1 loss : 0.439644 model2 loss : 0.022773
[00:12:02.320] iteration 14288 : model1 loss : 0.438311 model2 loss : 0.019461
[00:12:02.506] iteration 14289 : model1 loss : 0.433620 model2 loss : 0.019000
[00:12:02.677] iteration 14290 : model1 loss : 0.438117 model2 loss : 0.019971
[00:12:02.853] iteration 14291 : model1 loss : 0.434705 model2 loss : 0.020988
[00:12:03.024] iteration 14292 : model1 loss : 0.435783 model2 loss : 0.022499
[00:12:03.200] iteration 14293 : model1 loss : 0.438573 model2 loss : 0.021219
[00:12:03.373] iteration 14294 : model1 loss : 0.436882 model2 loss : 0.020196
[00:12:03.551] iteration 14295 : model1 loss : 0.439189 model2 loss : 0.019786
[00:12:03.721] iteration 14296 : model1 loss : 0.437648 model2 loss : 0.018529
[00:12:03.898] iteration 14297 : model1 loss : 0.435379 model2 loss : 0.021624
[00:12:04.070] iteration 14298 : model1 loss : 0.436670 model2 loss : 0.023578
[00:12:04.248] iteration 14299 : model1 loss : 0.432528 model2 loss : 0.021119
[00:12:04.418] iteration 14300 : model1 loss : 0.439563 model2 loss : 0.021758
[00:12:04.596] iteration 14301 : model1 loss : 0.436749 model2 loss : 0.019934
[00:12:06.688] iteration 14302 : model1 loss : 0.433243 model2 loss : 0.020864
[00:12:06.861] iteration 14303 : model1 loss : 0.439540 model2 loss : 0.020899
[00:12:07.044] iteration 14304 : model1 loss : 0.432418 model2 loss : 0.018388
[00:12:07.217] iteration 14305 : model1 loss : 0.437335 model2 loss : 0.022756
[00:12:07.396] iteration 14306 : model1 loss : 0.434916 model2 loss : 0.020037
[00:12:07.570] iteration 14307 : model1 loss : 0.438750 model2 loss : 0.020674
[00:12:07.747] iteration 14308 : model1 loss : 0.440443 model2 loss : 0.024019
[00:12:07.919] iteration 14309 : model1 loss : 0.436820 model2 loss : 0.024486
[00:12:08.095] iteration 14310 : model1 loss : 0.433835 model2 loss : 0.021867
[00:12:08.267] iteration 14311 : model1 loss : 0.439311 model2 loss : 0.021479
[00:12:08.444] iteration 14312 : model1 loss : 0.437407 model2 loss : 0.023142
[00:12:08.619] iteration 14313 : model1 loss : 0.434426 model2 loss : 0.021405
[00:12:08.823] iteration 14314 : model1 loss : 0.439840 model2 loss : 0.021570
[00:12:08.994] iteration 14315 : model1 loss : 0.439666 model2 loss : 0.019358
[00:12:09.170] iteration 14316 : model1 loss : 0.437604 model2 loss : 0.021479
[00:12:09.344] iteration 14317 : model1 loss : 0.436805 model2 loss : 0.018198
[00:12:09.520] iteration 14318 : model1 loss : 0.438977 model2 loss : 0.021360
[00:12:09.691] iteration 14319 : model1 loss : 0.438105 model2 loss : 0.019169
[00:12:09.868] iteration 14320 : model1 loss : 0.435710 model2 loss : 0.021046
[00:12:10.037] iteration 14321 : model1 loss : 0.435986 model2 loss : 0.018280
[00:12:10.214] iteration 14322 : model1 loss : 0.433852 model2 loss : 0.020193
[00:12:12.347] iteration 14323 : model1 loss : 0.436811 model2 loss : 0.020691
[00:12:12.530] iteration 14324 : model1 loss : 0.438029 model2 loss : 0.021952
[00:12:12.707] iteration 14325 : model1 loss : 0.436785 model2 loss : 0.019573
[00:12:12.878] iteration 14326 : model1 loss : 0.436392 model2 loss : 0.020482
[00:12:13.055] iteration 14327 : model1 loss : 0.438398 model2 loss : 0.022235
[00:12:13.227] iteration 14328 : model1 loss : 0.435352 model2 loss : 0.023495
[00:12:13.408] iteration 14329 : model1 loss : 0.436370 model2 loss : 0.018303
[00:12:13.583] iteration 14330 : model1 loss : 0.432764 model2 loss : 0.020534
[00:12:13.762] iteration 14331 : model1 loss : 0.439670 model2 loss : 0.023178
[00:12:13.934] iteration 14332 : model1 loss : 0.436503 model2 loss : 0.021476
[00:12:14.111] iteration 14333 : model1 loss : 0.434550 model2 loss : 0.022260
[00:12:14.283] iteration 14334 : model1 loss : 0.440817 model2 loss : 0.020290
[00:12:14.462] iteration 14335 : model1 loss : 0.433982 model2 loss : 0.019468
[00:12:14.637] iteration 14336 : model1 loss : 0.431744 model2 loss : 0.018462
[00:12:14.818] iteration 14337 : model1 loss : 0.435469 model2 loss : 0.020760
[00:12:14.991] iteration 14338 : model1 loss : 0.439895 model2 loss : 0.022014
[00:12:15.169] iteration 14339 : model1 loss : 0.434713 model2 loss : 0.018841
[00:12:15.343] iteration 14340 : model1 loss : 0.441280 model2 loss : 0.025379
[00:12:15.519] iteration 14341 : model1 loss : 0.438800 model2 loss : 0.020865
[00:12:15.689] iteration 14342 : model1 loss : 0.438953 model2 loss : 0.020945
[00:12:15.863] iteration 14343 : model1 loss : 0.440308 model2 loss : 0.021293
[00:12:18.018] iteration 14344 : model1 loss : 0.437396 model2 loss : 0.019598
[00:12:18.191] iteration 14345 : model1 loss : 0.437885 model2 loss : 0.022149
[00:12:18.373] iteration 14346 : model1 loss : 0.437964 model2 loss : 0.020329
[00:12:18.544] iteration 14347 : model1 loss : 0.440325 model2 loss : 0.022282
[00:12:18.722] iteration 14348 : model1 loss : 0.436552 model2 loss : 0.019905
[00:12:18.894] iteration 14349 : model1 loss : 0.437456 model2 loss : 0.020329
[00:12:19.071] iteration 14350 : model1 loss : 0.438543 model2 loss : 0.020585
[00:12:19.246] iteration 14351 : model1 loss : 0.436930 model2 loss : 0.020384
[00:12:19.427] iteration 14352 : model1 loss : 0.435058 model2 loss : 0.020785
[00:12:19.603] iteration 14353 : model1 loss : 0.442601 model2 loss : 0.023742
[00:12:19.780] iteration 14354 : model1 loss : 0.434397 model2 loss : 0.022416
[00:12:19.952] iteration 14355 : model1 loss : 0.436552 model2 loss : 0.021408
[00:12:20.134] iteration 14356 : model1 loss : 0.436247 model2 loss : 0.020218
[00:12:20.306] iteration 14357 : model1 loss : 0.435427 model2 loss : 0.021546
[00:12:20.487] iteration 14358 : model1 loss : 0.435063 model2 loss : 0.021022
[00:12:20.659] iteration 14359 : model1 loss : 0.439721 model2 loss : 0.017244
[00:12:20.837] iteration 14360 : model1 loss : 0.437988 model2 loss : 0.020496
[00:12:21.015] iteration 14361 : model1 loss : 0.439118 model2 loss : 0.020535
[00:12:21.197] iteration 14362 : model1 loss : 0.435137 model2 loss : 0.020745
[00:12:21.369] iteration 14363 : model1 loss : 0.433282 model2 loss : 0.018509
[00:12:21.544] iteration 14364 : model1 loss : 0.430364 model2 loss : 0.020272
[00:12:23.680] iteration 14365 : model1 loss : 0.429616 model2 loss : 0.020302
[00:12:23.854] iteration 14366 : model1 loss : 0.434048 model2 loss : 0.021232
[00:12:24.036] iteration 14367 : model1 loss : 0.434791 model2 loss : 0.021664
[00:12:24.209] iteration 14368 : model1 loss : 0.432773 model2 loss : 0.021789
[00:12:24.389] iteration 14369 : model1 loss : 0.440931 model2 loss : 0.022607
[00:12:24.563] iteration 14370 : model1 loss : 0.440893 model2 loss : 0.020360
[00:12:24.740] iteration 14371 : model1 loss : 0.439203 model2 loss : 0.021237
[00:12:24.913] iteration 14372 : model1 loss : 0.435562 model2 loss : 0.019417
[00:12:25.093] iteration 14373 : model1 loss : 0.440935 model2 loss : 0.021407
[00:12:25.265] iteration 14374 : model1 loss : 0.437088 model2 loss : 0.019025
[00:12:25.450] iteration 14375 : model1 loss : 0.435544 model2 loss : 0.019662
[00:12:25.624] iteration 14376 : model1 loss : 0.439706 model2 loss : 0.022010
[00:12:25.801] iteration 14377 : model1 loss : 0.436240 model2 loss : 0.020153
[00:12:25.971] iteration 14378 : model1 loss : 0.434727 model2 loss : 0.018536
[00:12:26.151] iteration 14379 : model1 loss : 0.437667 model2 loss : 0.021168
[00:12:26.328] iteration 14380 : model1 loss : 0.436715 model2 loss : 0.021251
[00:12:26.506] iteration 14381 : model1 loss : 0.442265 model2 loss : 0.023822
[00:12:26.680] iteration 14382 : model1 loss : 0.436722 model2 loss : 0.021644
[00:12:26.858] iteration 14383 : model1 loss : 0.436258 model2 loss : 0.022948
[00:12:27.028] iteration 14384 : model1 loss : 0.437911 model2 loss : 0.020904
[00:12:27.203] iteration 14385 : model1 loss : 0.435217 model2 loss : 0.017833
[00:12:29.382] iteration 14386 : model1 loss : 0.437464 model2 loss : 0.020099
[00:12:29.559] iteration 14387 : model1 loss : 0.437048 model2 loss : 0.017630
[00:12:29.736] iteration 14388 : model1 loss : 0.437596 model2 loss : 0.021557
[00:12:29.907] iteration 14389 : model1 loss : 0.437357 model2 loss : 0.022643
[00:12:30.083] iteration 14390 : model1 loss : 0.435663 model2 loss : 0.020560
[00:12:30.257] iteration 14391 : model1 loss : 0.437670 model2 loss : 0.020403
[00:12:30.433] iteration 14392 : model1 loss : 0.440839 model2 loss : 0.020194
[00:12:30.608] iteration 14393 : model1 loss : 0.436636 model2 loss : 0.019625
[00:12:30.783] iteration 14394 : model1 loss : 0.437437 model2 loss : 0.022253
[00:12:30.956] iteration 14395 : model1 loss : 0.441815 model2 loss : 0.022987
[00:12:31.138] iteration 14396 : model1 loss : 0.435806 model2 loss : 0.018502
[00:12:31.311] iteration 14397 : model1 loss : 0.436164 model2 loss : 0.022293
[00:12:31.490] iteration 14398 : model1 loss : 0.436024 model2 loss : 0.020340
[00:12:31.662] iteration 14399 : model1 loss : 0.434147 model2 loss : 0.020238
[00:12:31.839] iteration 14400 : model1 loss : 0.433400 model2 loss : 0.019910
[00:12:32.010] iteration 14401 : model1 loss : 0.435003 model2 loss : 0.019907
[00:12:32.187] iteration 14402 : model1 loss : 0.439828 model2 loss : 0.023623
[00:12:32.365] iteration 14403 : model1 loss : 0.440797 model2 loss : 0.021307
[00:12:32.545] iteration 14404 : model1 loss : 0.439638 model2 loss : 0.018666
[00:12:32.716] iteration 14405 : model1 loss : 0.433392 model2 loss : 0.022575
[00:12:32.892] iteration 14406 : model1 loss : 0.434732 model2 loss : 0.019338
[00:12:35.014] iteration 14407 : model1 loss : 0.444050 model2 loss : 0.023719
[00:12:35.186] iteration 14408 : model1 loss : 0.435057 model2 loss : 0.021240
[00:12:35.371] iteration 14409 : model1 loss : 0.433086 model2 loss : 0.018098
[00:12:35.542] iteration 14410 : model1 loss : 0.434028 model2 loss : 0.019865
[00:12:35.720] iteration 14411 : model1 loss : 0.433430 model2 loss : 0.018941
[00:12:35.891] iteration 14412 : model1 loss : 0.438296 model2 loss : 0.017861
[00:12:36.073] iteration 14413 : model1 loss : 0.434050 model2 loss : 0.018267
[00:12:36.245] iteration 14414 : model1 loss : 0.437767 model2 loss : 0.023439
[00:12:36.430] iteration 14415 : model1 loss : 0.437474 model2 loss : 0.024831
[00:12:36.605] iteration 14416 : model1 loss : 0.432935 model2 loss : 0.019146
[00:12:36.781] iteration 14417 : model1 loss : 0.435626 model2 loss : 0.021376
[00:12:36.954] iteration 14418 : model1 loss : 0.440291 model2 loss : 0.019225
[00:12:37.131] iteration 14419 : model1 loss : 0.434741 model2 loss : 0.021762
[00:12:37.307] iteration 14420 : model1 loss : 0.437240 model2 loss : 0.022367
[00:12:37.490] iteration 14421 : model1 loss : 0.437785 model2 loss : 0.021863
[00:12:37.661] iteration 14422 : model1 loss : 0.440331 model2 loss : 0.019749
[00:12:37.839] iteration 14423 : model1 loss : 0.436742 model2 loss : 0.019298
[00:12:38.013] iteration 14424 : model1 loss : 0.437503 model2 loss : 0.021152
[00:12:38.192] iteration 14425 : model1 loss : 0.439897 model2 loss : 0.022988
[00:12:38.367] iteration 14426 : model1 loss : 0.437295 model2 loss : 0.021847
[00:12:38.542] iteration 14427 : model1 loss : 0.436915 model2 loss : 0.018167
[00:12:40.657] iteration 14428 : model1 loss : 0.442825 model2 loss : 0.022392
[00:12:40.832] iteration 14429 : model1 loss : 0.435110 model2 loss : 0.021604
[00:12:41.010] iteration 14430 : model1 loss : 0.439586 model2 loss : 0.021890
[00:12:41.187] iteration 14431 : model1 loss : 0.434464 model2 loss : 0.021870
[00:12:41.370] iteration 14432 : model1 loss : 0.435291 model2 loss : 0.020402
[00:12:41.545] iteration 14433 : model1 loss : 0.439110 model2 loss : 0.022661
[00:12:41.721] iteration 14434 : model1 loss : 0.434719 model2 loss : 0.017726
[00:12:41.892] iteration 14435 : model1 loss : 0.434742 model2 loss : 0.019729
[00:12:42.068] iteration 14436 : model1 loss : 0.440054 model2 loss : 0.022811
[00:12:42.240] iteration 14437 : model1 loss : 0.432315 model2 loss : 0.019338
[00:12:42.420] iteration 14438 : model1 loss : 0.436622 model2 loss : 0.019114
[00:12:42.594] iteration 14439 : model1 loss : 0.432281 model2 loss : 0.019094
[00:12:42.773] iteration 14440 : model1 loss : 0.439064 model2 loss : 0.019690
[00:12:42.944] iteration 14441 : model1 loss : 0.440068 model2 loss : 0.022477
[00:12:43.124] iteration 14442 : model1 loss : 0.436803 model2 loss : 0.019187
[00:12:43.298] iteration 14443 : model1 loss : 0.436153 model2 loss : 0.020083
[00:12:43.475] iteration 14444 : model1 loss : 0.438866 model2 loss : 0.023383
[00:12:43.650] iteration 14445 : model1 loss : 0.437701 model2 loss : 0.021595
[00:12:43.828] iteration 14446 : model1 loss : 0.435290 model2 loss : 0.019753
[00:12:43.999] iteration 14447 : model1 loss : 0.437622 model2 loss : 0.020255
[00:12:44.174] iteration 14448 : model1 loss : 0.436995 model2 loss : 0.019456
[00:12:46.301] iteration 14449 : model1 loss : 0.439983 model2 loss : 0.019087
[00:12:46.478] iteration 14450 : model1 loss : 0.434866 model2 loss : 0.020678
[00:12:46.659] iteration 14451 : model1 loss : 0.441523 model2 loss : 0.023887
[00:12:46.831] iteration 14452 : model1 loss : 0.439669 model2 loss : 0.021504
[00:12:47.007] iteration 14453 : model1 loss : 0.431698 model2 loss : 0.017500
[00:12:47.177] iteration 14454 : model1 loss : 0.436094 model2 loss : 0.022241
[00:12:47.354] iteration 14455 : model1 loss : 0.433565 model2 loss : 0.019495
[00:12:47.527] iteration 14456 : model1 loss : 0.441011 model2 loss : 0.020480
[00:12:47.708] iteration 14457 : model1 loss : 0.438960 model2 loss : 0.018724
[00:12:47.879] iteration 14458 : model1 loss : 0.435323 model2 loss : 0.019774
[00:12:48.058] iteration 14459 : model1 loss : 0.437608 model2 loss : 0.019933
[00:12:48.231] iteration 14460 : model1 loss : 0.439716 model2 loss : 0.022143
[00:12:48.410] iteration 14461 : model1 loss : 0.438241 model2 loss : 0.021567
[00:12:48.584] iteration 14462 : model1 loss : 0.432754 model2 loss : 0.020206
[00:12:48.766] iteration 14463 : model1 loss : 0.436011 model2 loss : 0.020215
[00:12:48.938] iteration 14464 : model1 loss : 0.435563 model2 loss : 0.020509
[00:12:49.115] iteration 14465 : model1 loss : 0.431214 model2 loss : 0.019038
[00:12:49.287] iteration 14466 : model1 loss : 0.440234 model2 loss : 0.021838
[00:12:49.466] iteration 14467 : model1 loss : 0.430487 model2 loss : 0.019698
[00:12:49.636] iteration 14468 : model1 loss : 0.439466 model2 loss : 0.017855
[00:12:49.813] iteration 14469 : model1 loss : 0.436812 model2 loss : 0.020305
[00:12:51.928] iteration 14470 : model1 loss : 0.435958 model2 loss : 0.019172
[00:12:52.103] iteration 14471 : model1 loss : 0.435115 model2 loss : 0.019693
[00:12:52.281] iteration 14472 : model1 loss : 0.432075 model2 loss : 0.018982
[00:12:52.453] iteration 14473 : model1 loss : 0.440277 model2 loss : 0.020159
[00:12:52.632] iteration 14474 : model1 loss : 0.434553 model2 loss : 0.020732
[00:12:52.803] iteration 14475 : model1 loss : 0.436716 model2 loss : 0.020075
[00:12:52.981] iteration 14476 : model1 loss : 0.437108 model2 loss : 0.020581
[00:12:53.152] iteration 14477 : model1 loss : 0.436608 model2 loss : 0.018288
[00:12:53.332] iteration 14478 : model1 loss : 0.434958 model2 loss : 0.020726
[00:12:53.503] iteration 14479 : model1 loss : 0.435485 model2 loss : 0.020469
[00:12:53.682] iteration 14480 : model1 loss : 0.437077 model2 loss : 0.019839
[00:12:53.856] iteration 14481 : model1 loss : 0.434731 model2 loss : 0.020272
[00:12:54.033] iteration 14482 : model1 loss : 0.436843 model2 loss : 0.020160
[00:12:54.203] iteration 14483 : model1 loss : 0.434156 model2 loss : 0.018606
[00:12:54.383] iteration 14484 : model1 loss : 0.441405 model2 loss : 0.024313
[00:12:54.555] iteration 14485 : model1 loss : 0.435530 model2 loss : 0.021334
[00:12:54.733] iteration 14486 : model1 loss : 0.437876 model2 loss : 0.020348
[00:12:54.904] iteration 14487 : model1 loss : 0.438703 model2 loss : 0.022814
[00:12:55.085] iteration 14488 : model1 loss : 0.439369 model2 loss : 0.021474
[00:12:55.256] iteration 14489 : model1 loss : 0.438228 model2 loss : 0.020889
[00:12:55.432] iteration 14490 : model1 loss : 0.438215 model2 loss : 0.021374
[00:12:57.599] iteration 14491 : model1 loss : 0.435962 model2 loss : 0.018635
[00:12:57.778] iteration 14492 : model1 loss : 0.436549 model2 loss : 0.020403
[00:12:57.957] iteration 14493 : model1 loss : 0.433102 model2 loss : 0.018614
[00:12:58.131] iteration 14494 : model1 loss : 0.434616 model2 loss : 0.020997
[00:12:58.316] iteration 14495 : model1 loss : 0.442301 model2 loss : 0.022246
[00:12:58.489] iteration 14496 : model1 loss : 0.441060 model2 loss : 0.021471
[00:12:58.671] iteration 14497 : model1 loss : 0.440014 model2 loss : 0.019326
[00:12:58.843] iteration 14498 : model1 loss : 0.433766 model2 loss : 0.022492
[00:12:59.020] iteration 14499 : model1 loss : 0.436313 model2 loss : 0.020705
[00:12:59.192] iteration 14500 : model1 loss : 0.437592 model2 loss : 0.020375
[00:12:59.377] iteration 14501 : model1 loss : 0.436459 model2 loss : 0.020392
[00:12:59.547] iteration 14502 : model1 loss : 0.438826 model2 loss : 0.024539
[00:12:59.726] iteration 14503 : model1 loss : 0.436774 model2 loss : 0.018523
[00:12:59.899] iteration 14504 : model1 loss : 0.434819 model2 loss : 0.019651
[00:13:00.077] iteration 14505 : model1 loss : 0.432347 model2 loss : 0.019611
[00:13:00.251] iteration 14506 : model1 loss : 0.435994 model2 loss : 0.020773
[00:13:00.431] iteration 14507 : model1 loss : 0.437914 model2 loss : 0.021162
[00:13:00.608] iteration 14508 : model1 loss : 0.437514 model2 loss : 0.020300
[00:13:00.785] iteration 14509 : model1 loss : 0.439254 model2 loss : 0.021535
[00:13:00.958] iteration 14510 : model1 loss : 0.436263 model2 loss : 0.023222
[00:13:01.135] iteration 14511 : model1 loss : 0.438307 model2 loss : 0.019168
[00:13:03.297] iteration 14512 : model1 loss : 0.433224 model2 loss : 0.020286
[00:13:03.467] iteration 14513 : model1 loss : 0.437011 model2 loss : 0.023466
[00:13:03.649] iteration 14514 : model1 loss : 0.432104 model2 loss : 0.018664
[00:13:03.822] iteration 14515 : model1 loss : 0.438761 model2 loss : 0.019612
[00:13:04.000] iteration 14516 : model1 loss : 0.437040 model2 loss : 0.020661
[00:13:04.170] iteration 14517 : model1 loss : 0.440104 model2 loss : 0.018393
[00:13:04.353] iteration 14518 : model1 loss : 0.436652 model2 loss : 0.019200
[00:13:04.525] iteration 14519 : model1 loss : 0.433784 model2 loss : 0.018697
[00:13:04.702] iteration 14520 : model1 loss : 0.436944 model2 loss : 0.019876
[00:13:04.874] iteration 14521 : model1 loss : 0.439441 model2 loss : 0.017872
[00:13:05.051] iteration 14522 : model1 loss : 0.438254 model2 loss : 0.024133
[00:13:05.225] iteration 14523 : model1 loss : 0.432906 model2 loss : 0.018495
[00:13:05.402] iteration 14524 : model1 loss : 0.438591 model2 loss : 0.021809
[00:13:05.574] iteration 14525 : model1 loss : 0.436034 model2 loss : 0.021532
[00:13:05.753] iteration 14526 : model1 loss : 0.441702 model2 loss : 0.020592
[00:13:05.924] iteration 14527 : model1 loss : 0.437914 model2 loss : 0.022182
[00:13:06.102] iteration 14528 : model1 loss : 0.437524 model2 loss : 0.022761
[00:13:06.274] iteration 14529 : model1 loss : 0.437853 model2 loss : 0.019523
[00:13:06.451] iteration 14530 : model1 loss : 0.438516 model2 loss : 0.020870
[00:13:06.624] iteration 14531 : model1 loss : 0.436821 model2 loss : 0.019027
[00:13:06.798] iteration 14532 : model1 loss : 0.433761 model2 loss : 0.020087
[00:13:08.921] iteration 14533 : model1 loss : 0.437402 model2 loss : 0.020321
[00:13:09.097] iteration 14534 : model1 loss : 0.434897 model2 loss : 0.019925
[00:13:09.275] iteration 14535 : model1 loss : 0.434433 model2 loss : 0.020514
[00:13:09.446] iteration 14536 : model1 loss : 0.436739 model2 loss : 0.019501
[00:13:09.627] iteration 14537 : model1 loss : 0.436570 model2 loss : 0.024322
[00:13:09.797] iteration 14538 : model1 loss : 0.441330 model2 loss : 0.020863
[00:13:09.977] iteration 14539 : model1 loss : 0.437510 model2 loss : 0.022692
[00:13:10.148] iteration 14540 : model1 loss : 0.432113 model2 loss : 0.017013
[00:13:10.330] iteration 14541 : model1 loss : 0.443457 model2 loss : 0.022055
[00:13:10.500] iteration 14542 : model1 loss : 0.438261 model2 loss : 0.019194
[00:13:10.679] iteration 14543 : model1 loss : 0.435502 model2 loss : 0.018277
[00:13:10.849] iteration 14544 : model1 loss : 0.436717 model2 loss : 0.021418
[00:13:11.028] iteration 14545 : model1 loss : 0.437726 model2 loss : 0.020681
[00:13:11.199] iteration 14546 : model1 loss : 0.439053 model2 loss : 0.021637
[00:13:11.380] iteration 14547 : model1 loss : 0.437465 model2 loss : 0.017758
[00:13:11.553] iteration 14548 : model1 loss : 0.436652 model2 loss : 0.020769
[00:13:11.733] iteration 14549 : model1 loss : 0.441459 model2 loss : 0.021553
[00:13:11.903] iteration 14550 : model1 loss : 0.435057 model2 loss : 0.019164
[00:13:12.080] iteration 14551 : model1 loss : 0.438363 model2 loss : 0.023484
[00:13:12.250] iteration 14552 : model1 loss : 0.432935 model2 loss : 0.019470
[00:13:12.427] iteration 14553 : model1 loss : 0.433892 model2 loss : 0.019513
[00:13:14.562] iteration 14554 : model1 loss : 0.429521 model2 loss : 0.019069
[00:13:14.739] iteration 14555 : model1 loss : 0.439582 model2 loss : 0.022388
[00:13:14.919] iteration 14556 : model1 loss : 0.435857 model2 loss : 0.019052
[00:13:15.091] iteration 14557 : model1 loss : 0.438344 model2 loss : 0.021491
[00:13:15.270] iteration 14558 : model1 loss : 0.432282 model2 loss : 0.022483
[00:13:15.444] iteration 14559 : model1 loss : 0.434718 model2 loss : 0.019316
[00:13:15.622] iteration 14560 : model1 loss : 0.439041 model2 loss : 0.021700
[00:13:15.794] iteration 14561 : model1 loss : 0.437342 model2 loss : 0.020422
[00:13:15.973] iteration 14562 : model1 loss : 0.437772 model2 loss : 0.021241
[00:13:16.143] iteration 14563 : model1 loss : 0.435913 model2 loss : 0.021470
[00:13:16.323] iteration 14564 : model1 loss : 0.437613 model2 loss : 0.020006
[00:13:16.497] iteration 14565 : model1 loss : 0.441789 model2 loss : 0.022786
[00:13:16.674] iteration 14566 : model1 loss : 0.435185 model2 loss : 0.019326
[00:13:16.845] iteration 14567 : model1 loss : 0.437117 model2 loss : 0.019094
[00:13:17.023] iteration 14568 : model1 loss : 0.439217 model2 loss : 0.019821
[00:13:17.195] iteration 14569 : model1 loss : 0.433160 model2 loss : 0.018680
[00:13:17.376] iteration 14570 : model1 loss : 0.438309 model2 loss : 0.021226
[00:13:17.548] iteration 14571 : model1 loss : 0.435945 model2 loss : 0.023914
[00:13:17.727] iteration 14572 : model1 loss : 0.438446 model2 loss : 0.020747
[00:13:17.896] iteration 14573 : model1 loss : 0.440968 model2 loss : 0.020289
[00:13:18.072] iteration 14574 : model1 loss : 0.438441 model2 loss : 0.021446
[00:13:20.204] iteration 14575 : model1 loss : 0.436767 model2 loss : 0.021617
[00:13:20.377] iteration 14576 : model1 loss : 0.438215 model2 loss : 0.020803
[00:13:20.555] iteration 14577 : model1 loss : 0.435120 model2 loss : 0.019207
[00:13:20.727] iteration 14578 : model1 loss : 0.434483 model2 loss : 0.021496
[00:13:20.905] iteration 14579 : model1 loss : 0.437733 model2 loss : 0.021649
[00:13:21.079] iteration 14580 : model1 loss : 0.441117 model2 loss : 0.022418
[00:13:21.258] iteration 14581 : model1 loss : 0.436626 model2 loss : 0.021355
[00:13:21.433] iteration 14582 : model1 loss : 0.434310 model2 loss : 0.019273
[00:13:21.613] iteration 14583 : model1 loss : 0.438302 model2 loss : 0.020531
[00:13:21.784] iteration 14584 : model1 loss : 0.439463 model2 loss : 0.023214
[00:13:21.963] iteration 14585 : model1 loss : 0.435379 model2 loss : 0.021866
[00:13:22.135] iteration 14586 : model1 loss : 0.442140 model2 loss : 0.024216
[00:13:22.314] iteration 14587 : model1 loss : 0.435300 model2 loss : 0.020385
[00:13:22.490] iteration 14588 : model1 loss : 0.438061 model2 loss : 0.017250
[00:13:22.670] iteration 14589 : model1 loss : 0.437093 model2 loss : 0.021076
[00:13:22.843] iteration 14590 : model1 loss : 0.437773 model2 loss : 0.022303
[00:13:23.021] iteration 14591 : model1 loss : 0.437033 model2 loss : 0.020218
[00:13:23.193] iteration 14592 : model1 loss : 0.440249 model2 loss : 0.022996
[00:13:23.373] iteration 14593 : model1 loss : 0.434782 model2 loss : 0.019529
[00:13:23.561] iteration 14594 : model1 loss : 0.437409 model2 loss : 0.021188
[00:13:23.737] iteration 14595 : model1 loss : 0.436463 model2 loss : 0.019356
[00:13:25.883] iteration 14596 : model1 loss : 0.436196 model2 loss : 0.019593
[00:13:26.058] iteration 14597 : model1 loss : 0.438738 model2 loss : 0.021121
[00:13:26.237] iteration 14598 : model1 loss : 0.437813 model2 loss : 0.020501
[00:13:26.410] iteration 14599 : model1 loss : 0.437029 model2 loss : 0.021871
[00:13:26.589] iteration 14600 : model1 loss : 0.433907 model2 loss : 0.021144
[00:13:26.760] iteration 14601 : model1 loss : 0.442711 model2 loss : 0.022076
[00:13:26.936] iteration 14602 : model1 loss : 0.436187 model2 loss : 0.021156
[00:13:27.107] iteration 14603 : model1 loss : 0.436080 model2 loss : 0.024308
[00:13:27.287] iteration 14604 : model1 loss : 0.437630 model2 loss : 0.020478
[00:13:27.461] iteration 14605 : model1 loss : 0.438027 model2 loss : 0.022757
[00:13:27.641] iteration 14606 : model1 loss : 0.435870 model2 loss : 0.020920
[00:13:27.813] iteration 14607 : model1 loss : 0.433324 model2 loss : 0.021135
[00:13:27.993] iteration 14608 : model1 loss : 0.435605 model2 loss : 0.021632
[00:13:28.168] iteration 14609 : model1 loss : 0.437607 model2 loss : 0.017920
[00:13:28.346] iteration 14610 : model1 loss : 0.437515 model2 loss : 0.020458
[00:13:28.517] iteration 14611 : model1 loss : 0.432382 model2 loss : 0.018819
[00:13:28.695] iteration 14612 : model1 loss : 0.436487 model2 loss : 0.020567
[00:13:28.868] iteration 14613 : model1 loss : 0.441599 model2 loss : 0.027815
[00:13:29.045] iteration 14614 : model1 loss : 0.438039 model2 loss : 0.023886
[00:13:29.216] iteration 14615 : model1 loss : 0.436377 model2 loss : 0.021858
[00:13:29.395] iteration 14616 : model1 loss : 0.439754 model2 loss : 0.023198
[00:13:31.532] iteration 14617 : model1 loss : 0.443945 model2 loss : 0.022643
[00:13:31.707] iteration 14618 : model1 loss : 0.439008 model2 loss : 0.023610
[00:13:31.885] iteration 14619 : model1 loss : 0.437854 model2 loss : 0.020584
[00:13:32.057] iteration 14620 : model1 loss : 0.437603 model2 loss : 0.021508
[00:13:32.235] iteration 14621 : model1 loss : 0.435984 model2 loss : 0.021683
[00:13:32.411] iteration 14622 : model1 loss : 0.437420 model2 loss : 0.019975
[00:13:32.594] iteration 14623 : model1 loss : 0.434168 model2 loss : 0.023287
[00:13:32.765] iteration 14624 : model1 loss : 0.436831 model2 loss : 0.022648
[00:13:32.941] iteration 14625 : model1 loss : 0.434403 model2 loss : 0.024273
[00:13:33.115] iteration 14626 : model1 loss : 0.437225 model2 loss : 0.023958
[00:13:33.292] iteration 14627 : model1 loss : 0.435858 model2 loss : 0.021832
[00:13:33.464] iteration 14628 : model1 loss : 0.436871 model2 loss : 0.025201
[00:13:33.643] iteration 14629 : model1 loss : 0.437360 model2 loss : 0.019666
[00:13:33.814] iteration 14630 : model1 loss : 0.434186 model2 loss : 0.020125
[00:13:33.992] iteration 14631 : model1 loss : 0.435919 model2 loss : 0.023918
[00:13:34.163] iteration 14632 : model1 loss : 0.439558 model2 loss : 0.028221
[00:13:34.344] iteration 14633 : model1 loss : 0.433154 model2 loss : 0.030577
[00:13:34.515] iteration 14634 : model1 loss : 0.437958 model2 loss : 0.023757
[00:13:34.694] iteration 14635 : model1 loss : 0.439520 model2 loss : 0.022457
[00:13:34.866] iteration 14636 : model1 loss : 0.436132 model2 loss : 0.023728
[00:13:35.043] iteration 14637 : model1 loss : 0.440471 model2 loss : 0.022557
[00:13:37.144] iteration 14638 : model1 loss : 0.434589 model2 loss : 0.022537
[00:13:37.319] iteration 14639 : model1 loss : 0.438361 model2 loss : 0.025309
[00:13:37.507] iteration 14640 : model1 loss : 0.434024 model2 loss : 0.025980
[00:13:37.677] iteration 14641 : model1 loss : 0.435538 model2 loss : 0.023561
[00:13:37.854] iteration 14642 : model1 loss : 0.436647 model2 loss : 0.027321
[00:13:38.027] iteration 14643 : model1 loss : 0.436259 model2 loss : 0.021577
[00:13:38.203] iteration 14644 : model1 loss : 0.433544 model2 loss : 0.024979
[00:13:38.378] iteration 14645 : model1 loss : 0.435548 model2 loss : 0.025316
[00:13:38.560] iteration 14646 : model1 loss : 0.433928 model2 loss : 0.024243
[00:13:38.731] iteration 14647 : model1 loss : 0.436440 model2 loss : 0.030408
[00:13:38.908] iteration 14648 : model1 loss : 0.436643 model2 loss : 0.022231
[00:13:39.082] iteration 14649 : model1 loss : 0.440819 model2 loss : 0.027999
[00:13:39.262] iteration 14650 : model1 loss : 0.437971 model2 loss : 0.024347
[00:13:39.434] iteration 14651 : model1 loss : 0.438888 model2 loss : 0.032123
[00:13:39.613] iteration 14652 : model1 loss : 0.439812 model2 loss : 0.023767
[00:13:39.786] iteration 14653 : model1 loss : 0.443006 model2 loss : 0.026149
[00:13:39.964] iteration 14654 : model1 loss : 0.439087 model2 loss : 0.023792
[00:13:40.135] iteration 14655 : model1 loss : 0.435594 model2 loss : 0.020394
[00:13:40.313] iteration 14656 : model1 loss : 0.441068 model2 loss : 0.024366
[00:13:40.485] iteration 14657 : model1 loss : 0.438763 model2 loss : 0.025169
[00:13:40.662] iteration 14658 : model1 loss : 0.437144 model2 loss : 0.027567
[00:13:42.795] iteration 14659 : model1 loss : 0.441560 model2 loss : 0.026888
[00:13:42.968] iteration 14660 : model1 loss : 0.435988 model2 loss : 0.019819
[00:13:43.144] iteration 14661 : model1 loss : 0.438714 model2 loss : 0.026931
[00:13:43.319] iteration 14662 : model1 loss : 0.435047 model2 loss : 0.021598
[00:13:43.498] iteration 14663 : model1 loss : 0.440041 model2 loss : 0.020881
[00:13:43.669] iteration 14664 : model1 loss : 0.432685 model2 loss : 0.021858
[00:13:43.847] iteration 14665 : model1 loss : 0.439878 model2 loss : 0.024999
[00:13:44.019] iteration 14666 : model1 loss : 0.434584 model2 loss : 0.022649
[00:13:44.198] iteration 14667 : model1 loss : 0.433666 model2 loss : 0.020058
[00:13:44.372] iteration 14668 : model1 loss : 0.436213 model2 loss : 0.021996
[00:13:44.552] iteration 14669 : model1 loss : 0.440238 model2 loss : 0.021151
[00:13:44.724] iteration 14670 : model1 loss : 0.440216 model2 loss : 0.026263
[00:13:44.902] iteration 14671 : model1 loss : 0.431000 model2 loss : 0.019139
[00:13:45.076] iteration 14672 : model1 loss : 0.434593 model2 loss : 0.024293
[00:13:45.253] iteration 14673 : model1 loss : 0.436578 model2 loss : 0.023073
[00:13:45.425] iteration 14674 : model1 loss : 0.439916 model2 loss : 0.024159
[00:13:45.607] iteration 14675 : model1 loss : 0.435401 model2 loss : 0.022430
[00:13:45.780] iteration 14676 : model1 loss : 0.437761 model2 loss : 0.023963
[00:13:45.958] iteration 14677 : model1 loss : 0.440738 model2 loss : 0.024307
[00:13:46.132] iteration 14678 : model1 loss : 0.439629 model2 loss : 0.023506
[00:13:46.309] iteration 14679 : model1 loss : 0.438074 model2 loss : 0.021891
[00:13:48.451] iteration 14680 : model1 loss : 0.438231 model2 loss : 0.020311
[00:13:48.630] iteration 14681 : model1 loss : 0.437148 model2 loss : 0.021317
[00:13:48.809] iteration 14682 : model1 loss : 0.432757 model2 loss : 0.023474
[00:13:48.980] iteration 14683 : model1 loss : 0.439344 model2 loss : 0.025041
[00:13:49.156] iteration 14684 : model1 loss : 0.435821 model2 loss : 0.020979
[00:13:49.332] iteration 14685 : model1 loss : 0.439146 model2 loss : 0.024909
[00:13:49.510] iteration 14686 : model1 loss : 0.438258 model2 loss : 0.022633
[00:13:49.682] iteration 14687 : model1 loss : 0.434138 model2 loss : 0.020496
[00:13:49.861] iteration 14688 : model1 loss : 0.435573 model2 loss : 0.024005
[00:13:50.033] iteration 14689 : model1 loss : 0.439036 model2 loss : 0.022518
[00:13:50.210] iteration 14690 : model1 loss : 0.436646 model2 loss : 0.020450
[00:13:50.385] iteration 14691 : model1 loss : 0.438214 model2 loss : 0.025340
[00:13:50.564] iteration 14692 : model1 loss : 0.437539 model2 loss : 0.019254
[00:13:50.736] iteration 14693 : model1 loss : 0.437653 model2 loss : 0.020773
[00:13:50.917] iteration 14694 : model1 loss : 0.437103 model2 loss : 0.020462
[00:13:51.089] iteration 14695 : model1 loss : 0.435371 model2 loss : 0.020552
[00:13:51.271] iteration 14696 : model1 loss : 0.432186 model2 loss : 0.025885
[00:13:51.440] iteration 14697 : model1 loss : 0.438799 model2 loss : 0.020981
[00:13:51.621] iteration 14698 : model1 loss : 0.438401 model2 loss : 0.021506
[00:13:51.792] iteration 14699 : model1 loss : 0.433134 model2 loss : 0.023243
[00:13:51.969] iteration 14700 : model1 loss : 0.440016 model2 loss : 0.021187
[00:13:54.112] iteration 14701 : model1 loss : 0.435369 model2 loss : 0.020675
[00:13:54.287] iteration 14702 : model1 loss : 0.437667 model2 loss : 0.020238
[00:13:54.467] iteration 14703 : model1 loss : 0.437669 model2 loss : 0.024640
[00:13:54.641] iteration 14704 : model1 loss : 0.439837 model2 loss : 0.026514
[00:13:54.817] iteration 14705 : model1 loss : 0.438582 model2 loss : 0.028018
[00:13:54.988] iteration 14706 : model1 loss : 0.441593 model2 loss : 0.024726
[00:13:55.168] iteration 14707 : model1 loss : 0.434473 model2 loss : 0.021373
[00:13:55.344] iteration 14708 : model1 loss : 0.439620 model2 loss : 0.021078
[00:13:55.525] iteration 14709 : model1 loss : 0.433757 model2 loss : 0.024084
[00:13:55.697] iteration 14710 : model1 loss : 0.433638 model2 loss : 0.022814
[00:13:55.874] iteration 14711 : model1 loss : 0.440312 model2 loss : 0.031241
[00:13:56.046] iteration 14712 : model1 loss : 0.430736 model2 loss : 0.019289
[00:13:56.225] iteration 14713 : model1 loss : 0.443287 model2 loss : 0.028153
[00:13:56.402] iteration 14714 : model1 loss : 0.437481 model2 loss : 0.021179
[00:13:56.583] iteration 14715 : model1 loss : 0.433617 model2 loss : 0.026320
[00:13:56.755] iteration 14716 : model1 loss : 0.436279 model2 loss : 0.025285
[00:13:56.932] iteration 14717 : model1 loss : 0.436468 model2 loss : 0.023804
[00:13:57.103] iteration 14718 : model1 loss : 0.436841 model2 loss : 0.021348
[00:13:57.279] iteration 14719 : model1 loss : 0.437896 model2 loss : 0.023281
[00:13:57.452] iteration 14720 : model1 loss : 0.438022 model2 loss : 0.021107
[00:13:57.632] iteration 14721 : model1 loss : 0.435326 model2 loss : 0.022064
[00:13:59.742] iteration 14722 : model1 loss : 0.441018 model2 loss : 0.029987
[00:13:59.913] iteration 14723 : model1 loss : 0.438812 model2 loss : 0.022531
[00:14:00.096] iteration 14724 : model1 loss : 0.438756 model2 loss : 0.021399
[00:14:00.270] iteration 14725 : model1 loss : 0.443638 model2 loss : 0.024939
[00:14:00.447] iteration 14726 : model1 loss : 0.438489 model2 loss : 0.022824
[00:14:00.626] iteration 14727 : model1 loss : 0.437285 model2 loss : 0.020998
[00:14:00.804] iteration 14728 : model1 loss : 0.439126 model2 loss : 0.025731
[00:14:00.976] iteration 14729 : model1 loss : 0.440468 model2 loss : 0.023402
[00:14:01.152] iteration 14730 : model1 loss : 0.440289 model2 loss : 0.021757
[00:14:01.327] iteration 14731 : model1 loss : 0.436535 model2 loss : 0.019842
[00:14:01.508] iteration 14732 : model1 loss : 0.432513 model2 loss : 0.020436
[00:14:01.677] iteration 14733 : model1 loss : 0.433257 model2 loss : 0.021816
[00:14:01.855] iteration 14734 : model1 loss : 0.437257 model2 loss : 0.023864
[00:14:02.027] iteration 14735 : model1 loss : 0.437172 model2 loss : 0.020084
[00:14:02.204] iteration 14736 : model1 loss : 0.435933 model2 loss : 0.024187
[00:14:02.377] iteration 14737 : model1 loss : 0.436750 model2 loss : 0.024121
[00:14:02.564] iteration 14738 : model1 loss : 0.434781 model2 loss : 0.023211
[00:14:02.737] iteration 14739 : model1 loss : 0.430099 model2 loss : 0.023444
[00:14:02.915] iteration 14740 : model1 loss : 0.434351 model2 loss : 0.021830
[00:14:03.085] iteration 14741 : model1 loss : 0.438789 model2 loss : 0.023747
[00:14:03.264] iteration 14742 : model1 loss : 0.437443 model2 loss : 0.023040
[00:14:05.435] iteration 14743 : model1 loss : 0.433012 model2 loss : 0.019667
[00:14:05.616] iteration 14744 : model1 loss : 0.440568 model2 loss : 0.023660
[00:14:05.796] iteration 14745 : model1 loss : 0.431904 model2 loss : 0.019944
[00:14:05.967] iteration 14746 : model1 loss : 0.437571 model2 loss : 0.020130
[00:14:06.144] iteration 14747 : model1 loss : 0.437856 model2 loss : 0.021121
[00:14:06.318] iteration 14748 : model1 loss : 0.436819 model2 loss : 0.021919
[00:14:06.498] iteration 14749 : model1 loss : 0.435864 model2 loss : 0.023434
[00:14:06.670] iteration 14750 : model1 loss : 0.433388 model2 loss : 0.019507
[00:14:06.848] iteration 14751 : model1 loss : 0.437952 model2 loss : 0.022718
[00:14:07.019] iteration 14752 : model1 loss : 0.437883 model2 loss : 0.021278
[00:14:07.196] iteration 14753 : model1 loss : 0.437298 model2 loss : 0.019202
[00:14:07.371] iteration 14754 : model1 loss : 0.438057 model2 loss : 0.022276
[00:14:07.551] iteration 14755 : model1 loss : 0.436540 model2 loss : 0.022892
[00:14:07.723] iteration 14756 : model1 loss : 0.439762 model2 loss : 0.019696
[00:14:07.901] iteration 14757 : model1 loss : 0.437790 model2 loss : 0.020920
[00:14:08.072] iteration 14758 : model1 loss : 0.436176 model2 loss : 0.020793
[00:14:08.250] iteration 14759 : model1 loss : 0.433206 model2 loss : 0.018956
[00:14:08.424] iteration 14760 : model1 loss : 0.437628 model2 loss : 0.024628
[00:14:08.605] iteration 14761 : model1 loss : 0.434876 model2 loss : 0.021394
[00:14:08.776] iteration 14762 : model1 loss : 0.442796 model2 loss : 0.024568
[00:14:08.952] iteration 14763 : model1 loss : 0.437166 model2 loss : 0.022112
[00:14:11.106] iteration 14764 : model1 loss : 0.439259 model2 loss : 0.021667
[00:14:11.282] iteration 14765 : model1 loss : 0.440430 model2 loss : 0.024380
[00:14:11.464] iteration 14766 : model1 loss : 0.435410 model2 loss : 0.018771
[00:14:11.638] iteration 14767 : model1 loss : 0.438816 model2 loss : 0.020709
[00:14:11.816] iteration 14768 : model1 loss : 0.436431 model2 loss : 0.020032
[00:14:11.988] iteration 14769 : model1 loss : 0.437645 model2 loss : 0.022533
[00:14:12.165] iteration 14770 : model1 loss : 0.433311 model2 loss : 0.020928
[00:14:12.338] iteration 14771 : model1 loss : 0.434830 model2 loss : 0.019899
[00:14:12.519] iteration 14772 : model1 loss : 0.434930 model2 loss : 0.020644
[00:14:12.691] iteration 14773 : model1 loss : 0.434936 model2 loss : 0.021652
[00:14:12.871] iteration 14774 : model1 loss : 0.440692 model2 loss : 0.026497
[00:14:13.042] iteration 14775 : model1 loss : 0.437129 model2 loss : 0.021718
[00:14:13.220] iteration 14776 : model1 loss : 0.436575 model2 loss : 0.023150
[00:14:13.395] iteration 14777 : model1 loss : 0.437506 model2 loss : 0.020635
[00:14:13.574] iteration 14778 : model1 loss : 0.439434 model2 loss : 0.024618
[00:14:13.745] iteration 14779 : model1 loss : 0.435408 model2 loss : 0.022053
[00:14:13.921] iteration 14780 : model1 loss : 0.441523 model2 loss : 0.026066
[00:14:14.095] iteration 14781 : model1 loss : 0.438400 model2 loss : 0.021169
[00:14:14.273] iteration 14782 : model1 loss : 0.433238 model2 loss : 0.020369
[00:14:14.442] iteration 14783 : model1 loss : 0.438382 model2 loss : 0.032162
[00:14:14.622] iteration 14784 : model1 loss : 0.436673 model2 loss : 0.024473
[00:14:16.801] iteration 14785 : model1 loss : 0.437194 model2 loss : 0.023970
[00:14:16.974] iteration 14786 : model1 loss : 0.440399 model2 loss : 0.026720
[00:14:17.154] iteration 14787 : model1 loss : 0.440383 model2 loss : 0.024175
[00:14:17.331] iteration 14788 : model1 loss : 0.436786 model2 loss : 0.022109
[00:14:17.514] iteration 14789 : model1 loss : 0.441435 model2 loss : 0.030067
[00:14:17.686] iteration 14790 : model1 loss : 0.435753 model2 loss : 0.028799
[00:14:17.863] iteration 14791 : model1 loss : 0.436734 model2 loss : 0.022287
[00:14:18.035] iteration 14792 : model1 loss : 0.435346 model2 loss : 0.021384
[00:14:18.213] iteration 14793 : model1 loss : 0.439469 model2 loss : 0.029457
[00:14:18.386] iteration 14794 : model1 loss : 0.439720 model2 loss : 0.023087
[00:14:18.562] iteration 14795 : model1 loss : 0.436198 model2 loss : 0.020932
[00:14:18.733] iteration 14796 : model1 loss : 0.437541 model2 loss : 0.023059
[00:14:18.911] iteration 14797 : model1 loss : 0.442688 model2 loss : 0.030649
[00:14:19.083] iteration 14798 : model1 loss : 0.434478 model2 loss : 0.025118
[00:14:19.263] iteration 14799 : model1 loss : 0.431972 model2 loss : 0.020406
[00:14:19.435] iteration 14800 : model1 loss : 0.437588 model2 loss : 0.026431
[00:14:19.617] iteration 14801 : model1 loss : 0.435514 model2 loss : 0.023084
[00:14:19.789] iteration 14802 : model1 loss : 0.438347 model2 loss : 0.024622
[00:14:19.970] iteration 14803 : model1 loss : 0.439107 model2 loss : 0.029111
[00:14:20.139] iteration 14804 : model1 loss : 0.433339 model2 loss : 0.019752
[00:14:20.316] iteration 14805 : model1 loss : 0.433879 model2 loss : 0.019761
[00:14:22.505] iteration 14806 : model1 loss : 0.437333 model2 loss : 0.025342
[00:14:22.680] iteration 14807 : model1 loss : 0.439609 model2 loss : 0.021580
[00:14:22.861] iteration 14808 : model1 loss : 0.437291 model2 loss : 0.023392
[00:14:23.035] iteration 14809 : model1 loss : 0.433802 model2 loss : 0.022624
[00:14:23.213] iteration 14810 : model1 loss : 0.438321 model2 loss : 0.024854
[00:14:23.385] iteration 14811 : model1 loss : 0.435989 model2 loss : 0.022013
[00:14:23.563] iteration 14812 : model1 loss : 0.437830 model2 loss : 0.023264
[00:14:23.737] iteration 14813 : model1 loss : 0.438971 model2 loss : 0.020726
[00:14:23.915] iteration 14814 : model1 loss : 0.437450 model2 loss : 0.022358
[00:14:24.085] iteration 14815 : model1 loss : 0.433564 model2 loss : 0.020346
[00:14:24.268] iteration 14816 : model1 loss : 0.435206 model2 loss : 0.023089
[00:14:24.437] iteration 14817 : model1 loss : 0.439678 model2 loss : 0.021178
[00:14:24.618] iteration 14818 : model1 loss : 0.438908 model2 loss : 0.021730
[00:14:24.790] iteration 14819 : model1 loss : 0.439584 model2 loss : 0.020163
[00:14:24.966] iteration 14820 : model1 loss : 0.433723 model2 loss : 0.021078
[00:14:25.139] iteration 14821 : model1 loss : 0.434471 model2 loss : 0.021560
[00:14:25.320] iteration 14822 : model1 loss : 0.439576 model2 loss : 0.021030
[00:14:25.493] iteration 14823 : model1 loss : 0.435382 model2 loss : 0.023698
[00:14:25.672] iteration 14824 : model1 loss : 0.437294 model2 loss : 0.020802
[00:14:25.843] iteration 14825 : model1 loss : 0.437638 model2 loss : 0.021389
[00:14:26.021] iteration 14826 : model1 loss : 0.438085 model2 loss : 0.021976
[00:14:28.171] iteration 14827 : model1 loss : 0.437433 model2 loss : 0.020381
[00:14:28.351] iteration 14828 : model1 loss : 0.434869 model2 loss : 0.022558
[00:14:28.527] iteration 14829 : model1 loss : 0.439103 model2 loss : 0.021702
[00:14:28.699] iteration 14830 : model1 loss : 0.435836 model2 loss : 0.019614
[00:14:28.875] iteration 14831 : model1 loss : 0.436688 model2 loss : 0.022454
[00:14:29.046] iteration 14832 : model1 loss : 0.439181 model2 loss : 0.024737
[00:14:29.230] iteration 14833 : model1 loss : 0.434867 model2 loss : 0.020859
[00:14:29.403] iteration 14834 : model1 loss : 0.437152 model2 loss : 0.019503
[00:14:29.582] iteration 14835 : model1 loss : 0.433590 model2 loss : 0.020173
[00:14:29.753] iteration 14836 : model1 loss : 0.437835 model2 loss : 0.021767
[00:14:29.933] iteration 14837 : model1 loss : 0.433225 model2 loss : 0.019752
[00:14:30.106] iteration 14838 : model1 loss : 0.440521 model2 loss : 0.023525
[00:14:30.284] iteration 14839 : model1 loss : 0.436817 model2 loss : 0.022063
[00:14:30.457] iteration 14840 : model1 loss : 0.438658 model2 loss : 0.021716
[00:14:30.637] iteration 14841 : model1 loss : 0.437262 model2 loss : 0.020182
[00:14:30.809] iteration 14842 : model1 loss : 0.435656 model2 loss : 0.018826
[00:14:30.988] iteration 14843 : model1 loss : 0.436261 model2 loss : 0.020653
[00:14:31.161] iteration 14844 : model1 loss : 0.436692 model2 loss : 0.023916
[00:14:31.342] iteration 14845 : model1 loss : 0.441486 model2 loss : 0.020551
[00:14:31.513] iteration 14846 : model1 loss : 0.436520 model2 loss : 0.021750
[00:14:31.688] iteration 14847 : model1 loss : 0.439086 model2 loss : 0.020711
[00:14:33.852] iteration 14848 : model1 loss : 0.434917 model2 loss : 0.021584
[00:14:34.028] iteration 14849 : model1 loss : 0.441300 model2 loss : 0.025846
[00:14:34.208] iteration 14850 : model1 loss : 0.434841 model2 loss : 0.020055
[00:14:34.380] iteration 14851 : model1 loss : 0.439694 model2 loss : 0.026087
[00:14:34.558] iteration 14852 : model1 loss : 0.444059 model2 loss : 0.024516
[00:14:34.728] iteration 14853 : model1 loss : 0.438012 model2 loss : 0.025064
[00:14:34.903] iteration 14854 : model1 loss : 0.434917 model2 loss : 0.020729
[00:14:35.077] iteration 14855 : model1 loss : 0.435343 model2 loss : 0.023231
[00:14:35.256] iteration 14856 : model1 loss : 0.437661 model2 loss : 0.019911
[00:14:35.426] iteration 14857 : model1 loss : 0.439997 model2 loss : 0.021553
[00:14:35.610] iteration 14858 : model1 loss : 0.434475 model2 loss : 0.023479
[00:14:35.782] iteration 14859 : model1 loss : 0.440227 model2 loss : 0.022419
[00:14:35.958] iteration 14860 : model1 loss : 0.434291 model2 loss : 0.020111
[00:14:36.131] iteration 14861 : model1 loss : 0.433004 model2 loss : 0.021612
[00:14:36.312] iteration 14862 : model1 loss : 0.440375 model2 loss : 0.026144
[00:14:36.482] iteration 14863 : model1 loss : 0.435944 model2 loss : 0.021857
[00:14:36.660] iteration 14864 : model1 loss : 0.437554 model2 loss : 0.021698
[00:14:36.833] iteration 14865 : model1 loss : 0.434951 model2 loss : 0.023444
[00:14:37.012] iteration 14866 : model1 loss : 0.438114 model2 loss : 0.021006
[00:14:37.183] iteration 14867 : model1 loss : 0.435685 model2 loss : 0.022528
[00:14:37.363] iteration 14868 : model1 loss : 0.437380 model2 loss : 0.022324
[00:14:39.530] iteration 14869 : model1 loss : 0.439459 model2 loss : 0.024293
[00:14:39.707] iteration 14870 : model1 loss : 0.438480 model2 loss : 0.024952
[00:14:39.885] iteration 14871 : model1 loss : 0.436178 model2 loss : 0.020290
[00:14:40.059] iteration 14872 : model1 loss : 0.435986 model2 loss : 0.020806
[00:14:40.237] iteration 14873 : model1 loss : 0.437216 model2 loss : 0.020362
[00:14:40.410] iteration 14874 : model1 loss : 0.434616 model2 loss : 0.022673
[00:14:40.587] iteration 14875 : model1 loss : 0.436195 model2 loss : 0.021106
[00:14:40.760] iteration 14876 : model1 loss : 0.439308 model2 loss : 0.020930
[00:14:40.938] iteration 14877 : model1 loss : 0.437516 model2 loss : 0.022617
[00:14:41.111] iteration 14878 : model1 loss : 0.435719 model2 loss : 0.020163
[00:14:41.288] iteration 14879 : model1 loss : 0.433925 model2 loss : 0.019873
[00:14:41.462] iteration 14880 : model1 loss : 0.434177 model2 loss : 0.021571
[00:14:41.641] iteration 14881 : model1 loss : 0.440061 model2 loss : 0.025133
[00:14:41.814] iteration 14882 : model1 loss : 0.435235 model2 loss : 0.021435
[00:14:41.993] iteration 14883 : model1 loss : 0.431001 model2 loss : 0.020487
[00:14:42.164] iteration 14884 : model1 loss : 0.440658 model2 loss : 0.021307
[00:14:42.343] iteration 14885 : model1 loss : 0.438831 model2 loss : 0.021235
[00:14:42.515] iteration 14886 : model1 loss : 0.439575 model2 loss : 0.022197
[00:14:42.695] iteration 14887 : model1 loss : 0.439806 model2 loss : 0.023887
[00:14:42.865] iteration 14888 : model1 loss : 0.434812 model2 loss : 0.022698
[00:14:43.041] iteration 14889 : model1 loss : 0.439405 model2 loss : 0.023853
[00:14:45.224] iteration 14890 : model1 loss : 0.434452 model2 loss : 0.021155
[00:14:45.399] iteration 14891 : model1 loss : 0.439834 model2 loss : 0.018143
[00:14:45.577] iteration 14892 : model1 loss : 0.429528 model2 loss : 0.018527
[00:14:45.750] iteration 14893 : model1 loss : 0.438598 model2 loss : 0.023753
[00:14:45.927] iteration 14894 : model1 loss : 0.434794 model2 loss : 0.020402
[00:14:46.102] iteration 14895 : model1 loss : 0.439661 model2 loss : 0.025071
[00:14:46.280] iteration 14896 : model1 loss : 0.441413 model2 loss : 0.024303
[00:14:46.452] iteration 14897 : model1 loss : 0.435354 model2 loss : 0.019459
[00:14:46.634] iteration 14898 : model1 loss : 0.436952 model2 loss : 0.021734
[00:14:46.805] iteration 14899 : model1 loss : 0.439725 model2 loss : 0.023118
[00:14:46.984] iteration 14900 : model1 loss : 0.435968 model2 loss : 0.021979
[00:14:47.155] iteration 14901 : model1 loss : 0.435468 model2 loss : 0.021686
[00:14:47.340] iteration 14902 : model1 loss : 0.433335 model2 loss : 0.020862
[00:14:47.516] iteration 14903 : model1 loss : 0.436636 model2 loss : 0.020556
[00:14:47.698] iteration 14904 : model1 loss : 0.437455 model2 loss : 0.020436
[00:14:47.873] iteration 14905 : model1 loss : 0.435464 model2 loss : 0.021006
[00:14:48.052] iteration 14906 : model1 loss : 0.440761 model2 loss : 0.023842
[00:14:48.223] iteration 14907 : model1 loss : 0.437048 model2 loss : 0.021191
[00:14:48.402] iteration 14908 : model1 loss : 0.437942 model2 loss : 0.020006
[00:14:48.574] iteration 14909 : model1 loss : 0.441623 model2 loss : 0.022796
[00:14:48.750] iteration 14910 : model1 loss : 0.438795 model2 loss : 0.019744
[00:14:50.881] iteration 14911 : model1 loss : 0.436620 model2 loss : 0.020739
[00:14:51.055] iteration 14912 : model1 loss : 0.436313 model2 loss : 0.019878
[00:14:51.237] iteration 14913 : model1 loss : 0.436903 model2 loss : 0.020430
[00:14:51.409] iteration 14914 : model1 loss : 0.439375 model2 loss : 0.025747
[00:14:51.587] iteration 14915 : model1 loss : 0.437853 model2 loss : 0.022017
[00:14:51.759] iteration 14916 : model1 loss : 0.434233 model2 loss : 0.022103
[00:14:51.938] iteration 14917 : model1 loss : 0.440529 model2 loss : 0.026429
[00:14:52.110] iteration 14918 : model1 loss : 0.442004 model2 loss : 0.018863
[00:14:52.287] iteration 14919 : model1 loss : 0.437497 model2 loss : 0.022988
[00:14:52.462] iteration 14920 : model1 loss : 0.435142 model2 loss : 0.028101
[00:14:52.640] iteration 14921 : model1 loss : 0.436464 model2 loss : 0.024338
[00:14:52.815] iteration 14922 : model1 loss : 0.436567 model2 loss : 0.020481
[00:14:52.992] iteration 14923 : model1 loss : 0.437216 model2 loss : 0.020562
[00:14:53.166] iteration 14924 : model1 loss : 0.440895 model2 loss : 0.022699
[00:14:53.349] iteration 14925 : model1 loss : 0.435141 model2 loss : 0.021087
[00:14:53.522] iteration 14926 : model1 loss : 0.432230 model2 loss : 0.020762
[00:14:53.702] iteration 14927 : model1 loss : 0.433527 model2 loss : 0.021150
[00:14:53.872] iteration 14928 : model1 loss : 0.435302 model2 loss : 0.027795
[00:14:54.049] iteration 14929 : model1 loss : 0.441029 model2 loss : 0.026660
[00:14:54.219] iteration 14930 : model1 loss : 0.435598 model2 loss : 0.019868
[00:14:54.395] iteration 14931 : model1 loss : 0.435647 model2 loss : 0.020205
[00:14:56.544] iteration 14932 : model1 loss : 0.437520 model2 loss : 0.021355
[00:14:56.719] iteration 14933 : model1 loss : 0.435245 model2 loss : 0.018971
[00:14:56.901] iteration 14934 : model1 loss : 0.435515 model2 loss : 0.024091
[00:14:57.072] iteration 14935 : model1 loss : 0.438408 model2 loss : 0.021574
[00:14:57.250] iteration 14936 : model1 loss : 0.437657 model2 loss : 0.018584
[00:14:57.425] iteration 14937 : model1 loss : 0.436251 model2 loss : 0.024035
[00:14:57.607] iteration 14938 : model1 loss : 0.435485 model2 loss : 0.021027
[00:14:57.778] iteration 14939 : model1 loss : 0.438829 model2 loss : 0.021963
[00:14:57.958] iteration 14940 : model1 loss : 0.434567 model2 loss : 0.020745
[00:14:58.131] iteration 14941 : model1 loss : 0.434157 model2 loss : 0.019379
[00:14:58.310] iteration 14942 : model1 loss : 0.437483 model2 loss : 0.023631
[00:14:58.479] iteration 14943 : model1 loss : 0.438111 model2 loss : 0.022074
[00:14:58.659] iteration 14944 : model1 loss : 0.435619 model2 loss : 0.019330
[00:14:58.831] iteration 14945 : model1 loss : 0.437566 model2 loss : 0.022836
[00:14:59.009] iteration 14946 : model1 loss : 0.437523 model2 loss : 0.022156
[00:14:59.180] iteration 14947 : model1 loss : 0.439501 model2 loss : 0.022436
[00:14:59.359] iteration 14948 : model1 loss : 0.441419 model2 loss : 0.025876
[00:14:59.532] iteration 14949 : model1 loss : 0.438427 model2 loss : 0.024577
[00:14:59.707] iteration 14950 : model1 loss : 0.437310 model2 loss : 0.020078
[00:14:59.879] iteration 14951 : model1 loss : 0.433894 model2 loss : 0.019779
[00:15:00.058] iteration 14952 : model1 loss : 0.439997 model2 loss : 0.024077
[00:15:02.198] iteration 14953 : model1 loss : 0.435684 model2 loss : 0.022615
[00:15:02.380] iteration 14954 : model1 loss : 0.435127 model2 loss : 0.022566
[00:15:02.560] iteration 14955 : model1 loss : 0.441236 model2 loss : 0.021686
[00:15:02.734] iteration 14956 : model1 loss : 0.438239 model2 loss : 0.021323
[00:15:02.909] iteration 14957 : model1 loss : 0.437999 model2 loss : 0.021273
[00:15:03.082] iteration 14958 : model1 loss : 0.433086 model2 loss : 0.019227
[00:15:03.260] iteration 14959 : model1 loss : 0.436994 model2 loss : 0.021377
[00:15:03.433] iteration 14960 : model1 loss : 0.439742 model2 loss : 0.021267
[00:15:03.613] iteration 14961 : model1 loss : 0.436241 model2 loss : 0.021908
[00:15:03.786] iteration 14962 : model1 loss : 0.433926 model2 loss : 0.021098
[00:15:03.965] iteration 14963 : model1 loss : 0.435303 model2 loss : 0.023790
[00:15:04.136] iteration 14964 : model1 loss : 0.436542 model2 loss : 0.020572
[00:15:04.315] iteration 14965 : model1 loss : 0.435758 model2 loss : 0.021324
[00:15:04.485] iteration 14966 : model1 loss : 0.440843 model2 loss : 0.023098
[00:15:04.665] iteration 14967 : model1 loss : 0.434575 model2 loss : 0.021663
[00:15:04.836] iteration 14968 : model1 loss : 0.439408 model2 loss : 0.024236
[00:15:05.013] iteration 14969 : model1 loss : 0.436764 model2 loss : 0.021678
[00:15:05.185] iteration 14970 : model1 loss : 0.442216 model2 loss : 0.023996
[00:15:05.365] iteration 14971 : model1 loss : 0.432515 model2 loss : 0.019112
[00:15:05.535] iteration 14972 : model1 loss : 0.437527 model2 loss : 0.019386
[00:15:05.710] iteration 14973 : model1 loss : 0.435733 model2 loss : 0.022008
[00:15:07.949] iteration 14974 : model1 loss : 0.440301 model2 loss : 0.021365
[00:15:08.123] iteration 14975 : model1 loss : 0.437149 model2 loss : 0.022014
[00:15:08.306] iteration 14976 : model1 loss : 0.436132 model2 loss : 0.025415
[00:15:08.479] iteration 14977 : model1 loss : 0.441446 model2 loss : 0.021386
[00:15:08.656] iteration 14978 : model1 loss : 0.438542 model2 loss : 0.023410
[00:15:08.828] iteration 14979 : model1 loss : 0.434599 model2 loss : 0.020735
[00:15:09.004] iteration 14980 : model1 loss : 0.441456 model2 loss : 0.027139
[00:15:09.177] iteration 14981 : model1 loss : 0.434323 model2 loss : 0.019660
[00:15:09.361] iteration 14982 : model1 loss : 0.438677 model2 loss : 0.022302
[00:15:09.533] iteration 14983 : model1 loss : 0.436314 model2 loss : 0.022111
[00:15:09.710] iteration 14984 : model1 loss : 0.437158 model2 loss : 0.020160
[00:15:09.882] iteration 14985 : model1 loss : 0.432023 model2 loss : 0.021737
[00:15:10.062] iteration 14986 : model1 loss : 0.437362 model2 loss : 0.023588
[00:15:10.236] iteration 14987 : model1 loss : 0.441588 model2 loss : 0.019641
[00:15:10.417] iteration 14988 : model1 loss : 0.433432 model2 loss : 0.017902
[00:15:10.590] iteration 14989 : model1 loss : 0.438038 model2 loss : 0.022104
[00:15:10.767] iteration 14990 : model1 loss : 0.438981 model2 loss : 0.021817
[00:15:10.938] iteration 14991 : model1 loss : 0.434439 model2 loss : 0.021436
[00:15:11.115] iteration 14992 : model1 loss : 0.435823 model2 loss : 0.021902
[00:15:11.285] iteration 14993 : model1 loss : 0.436964 model2 loss : 0.023869
[00:15:11.462] iteration 14994 : model1 loss : 0.436249 model2 loss : 0.021998
[00:15:13.671] iteration 14995 : model1 loss : 0.436613 model2 loss : 0.019831
[00:15:13.845] iteration 14996 : model1 loss : 0.432782 model2 loss : 0.021477
[00:15:14.027] iteration 14997 : model1 loss : 0.437817 model2 loss : 0.021104
[00:15:14.199] iteration 14998 : model1 loss : 0.435031 model2 loss : 0.023131
[00:15:14.386] iteration 14999 : model1 loss : 0.439268 model2 loss : 0.024446
[00:15:14.559] iteration 15000 : model1 loss : 0.438023 model2 loss : 0.024812
[00:15:23.773] iteration 15000 : model1_mean_dice : 0.838935 model1_mean_hd95 : 9.004601
[00:15:33.008] iteration 15000 : model2_mean_dice : 0.871019 model2_mean_hd95 : 9.213967
[00:15:33.038] save model1 to ../model/ACDC/EVILv1_kl0.5_tau0.25_14_1337/unet\model1_iter_15000.pth
[00:15:33.065] save model2 to ../model/ACDC/EVILv1_kl0.5_tau0.25_14_1337/unet\model2_iter_15000.pth
[00:15:33.254] iteration 15001 : model1 loss : 0.441491 model2 loss : 0.023480
[00:15:33.435] iteration 15002 : model1 loss : 0.436408 model2 loss : 0.021794
[00:15:33.618] iteration 15003 : model1 loss : 0.435418 model2 loss : 0.021413
[00:15:33.788] iteration 15004 : model1 loss : 0.435299 model2 loss : 0.021434
[00:15:33.964] iteration 15005 : model1 loss : 0.440047 model2 loss : 0.023321
[00:15:34.136] iteration 15006 : model1 loss : 0.434254 model2 loss : 0.020938
[00:15:34.314] iteration 15007 : model1 loss : 0.437297 model2 loss : 0.023405
[00:15:34.483] iteration 15008 : model1 loss : 0.436388 model2 loss : 0.020635
[00:15:34.662] iteration 15009 : model1 loss : 0.434981 model2 loss : 0.021719
[00:15:34.833] iteration 15010 : model1 loss : 0.437563 model2 loss : 0.022084
[00:15:35.009] iteration 15011 : model1 loss : 0.438833 model2 loss : 0.020457
[00:15:35.179] iteration 15012 : model1 loss : 0.437546 model2 loss : 0.021160
[00:15:35.357] iteration 15013 : model1 loss : 0.437276 model2 loss : 0.021538
[00:15:35.527] iteration 15014 : model1 loss : 0.443042 model2 loss : 0.025557
[00:15:35.704] iteration 15015 : model1 loss : 0.436055 model2 loss : 0.022537
[00:15:37.902] iteration 15016 : model1 loss : 0.434270 model2 loss : 0.020296
[00:15:38.073] iteration 15017 : model1 loss : 0.439501 model2 loss : 0.022466
[00:15:38.250] iteration 15018 : model1 loss : 0.436229 model2 loss : 0.026210
[00:15:38.425] iteration 15019 : model1 loss : 0.438494 model2 loss : 0.030061
[00:15:38.608] iteration 15020 : model1 loss : 0.440289 model2 loss : 0.021479
[00:15:38.777] iteration 15021 : model1 loss : 0.441826 model2 loss : 0.024737
[00:15:38.954] iteration 15022 : model1 loss : 0.435336 model2 loss : 0.021526
[00:15:39.125] iteration 15023 : model1 loss : 0.436724 model2 loss : 0.021278
[00:15:39.303] iteration 15024 : model1 loss : 0.440208 model2 loss : 0.030059
[00:15:39.473] iteration 15025 : model1 loss : 0.435672 model2 loss : 0.027927
[00:15:39.656] iteration 15026 : model1 loss : 0.441055 model2 loss : 0.024365
[00:15:39.828] iteration 15027 : model1 loss : 0.434326 model2 loss : 0.020572
[00:15:40.006] iteration 15028 : model1 loss : 0.439897 model2 loss : 0.026827
[00:15:40.177] iteration 15029 : model1 loss : 0.437571 model2 loss : 0.022085
[00:15:40.360] iteration 15030 : model1 loss : 0.440701 model2 loss : 0.026067
[00:15:40.532] iteration 15031 : model1 loss : 0.436749 model2 loss : 0.023633
[00:15:40.708] iteration 15032 : model1 loss : 0.436431 model2 loss : 0.026597
[00:15:40.878] iteration 15033 : model1 loss : 0.437753 model2 loss : 0.024165
[00:15:41.055] iteration 15034 : model1 loss : 0.443819 model2 loss : 0.024621
[00:15:41.226] iteration 15035 : model1 loss : 0.431791 model2 loss : 0.023396
[00:15:41.404] iteration 15036 : model1 loss : 0.434423 model2 loss : 0.021832
[00:15:43.611] iteration 15037 : model1 loss : 0.433956 model2 loss : 0.024413
[00:15:43.783] iteration 15038 : model1 loss : 0.439243 model2 loss : 0.021016
[00:15:43.962] iteration 15039 : model1 loss : 0.439064 model2 loss : 0.024228
[00:15:44.134] iteration 15040 : model1 loss : 0.433126 model2 loss : 0.022189
[00:15:44.314] iteration 15041 : model1 loss : 0.435371 model2 loss : 0.024295
[00:15:44.486] iteration 15042 : model1 loss : 0.436514 model2 loss : 0.021830
[00:15:44.665] iteration 15043 : model1 loss : 0.441151 model2 loss : 0.023382
[00:15:44.836] iteration 15044 : model1 loss : 0.439103 model2 loss : 0.023242
[00:15:45.014] iteration 15045 : model1 loss : 0.436615 model2 loss : 0.022930
[00:15:45.185] iteration 15046 : model1 loss : 0.434349 model2 loss : 0.021361
[00:15:45.366] iteration 15047 : model1 loss : 0.438240 model2 loss : 0.026187
[00:15:45.537] iteration 15048 : model1 loss : 0.435247 model2 loss : 0.022935
[00:15:45.714] iteration 15049 : model1 loss : 0.438873 model2 loss : 0.022554
[00:15:45.885] iteration 15050 : model1 loss : 0.439076 model2 loss : 0.020967
[00:15:46.061] iteration 15051 : model1 loss : 0.437227 model2 loss : 0.022821
[00:15:46.232] iteration 15052 : model1 loss : 0.437203 model2 loss : 0.023947
[00:15:46.414] iteration 15053 : model1 loss : 0.437320 model2 loss : 0.027173
[00:15:46.587] iteration 15054 : model1 loss : 0.437911 model2 loss : 0.030588
[00:15:46.762] iteration 15055 : model1 loss : 0.439223 model2 loss : 0.021608
[00:15:46.933] iteration 15056 : model1 loss : 0.436267 model2 loss : 0.022413
[00:15:47.109] iteration 15057 : model1 loss : 0.437452 model2 loss : 0.021560
[00:15:49.263] iteration 15058 : model1 loss : 0.439936 model2 loss : 0.028235
[00:15:49.437] iteration 15059 : model1 loss : 0.436895 model2 loss : 0.023523
[00:15:49.617] iteration 15060 : model1 loss : 0.438842 model2 loss : 0.024411
[00:15:49.791] iteration 15061 : model1 loss : 0.432931 model2 loss : 0.022077
[00:15:49.967] iteration 15062 : model1 loss : 0.436526 model2 loss : 0.023075
[00:15:50.139] iteration 15063 : model1 loss : 0.434142 model2 loss : 0.021541
[00:15:50.319] iteration 15064 : model1 loss : 0.443143 model2 loss : 0.024066
[00:15:50.491] iteration 15065 : model1 loss : 0.437520 model2 loss : 0.023562
[00:15:50.667] iteration 15066 : model1 loss : 0.434948 model2 loss : 0.020719
[00:15:50.838] iteration 15067 : model1 loss : 0.434128 model2 loss : 0.022133
[00:15:51.014] iteration 15068 : model1 loss : 0.440876 model2 loss : 0.023480
[00:15:51.186] iteration 15069 : model1 loss : 0.432732 model2 loss : 0.021150
[00:15:51.363] iteration 15070 : model1 loss : 0.436870 model2 loss : 0.022371
[00:15:51.535] iteration 15071 : model1 loss : 0.433379 model2 loss : 0.020504
[00:15:51.715] iteration 15072 : model1 loss : 0.433125 model2 loss : 0.021117
[00:15:51.885] iteration 15073 : model1 loss : 0.438106 model2 loss : 0.023450
[00:15:52.063] iteration 15074 : model1 loss : 0.439815 model2 loss : 0.021912
[00:15:52.234] iteration 15075 : model1 loss : 0.441418 model2 loss : 0.023321
[00:15:52.417] iteration 15076 : model1 loss : 0.440624 model2 loss : 0.022357
[00:15:52.589] iteration 15077 : model1 loss : 0.436580 model2 loss : 0.021916
[00:15:52.763] iteration 15078 : model1 loss : 0.440403 model2 loss : 0.022089
[00:15:54.933] iteration 15079 : model1 loss : 0.433763 model2 loss : 0.022267
[00:15:55.107] iteration 15080 : model1 loss : 0.438906 model2 loss : 0.021476
[00:15:55.284] iteration 15081 : model1 loss : 0.434289 model2 loss : 0.019753
[00:15:55.458] iteration 15082 : model1 loss : 0.439007 model2 loss : 0.020271
[00:15:55.636] iteration 15083 : model1 loss : 0.437790 model2 loss : 0.022484
[00:15:55.807] iteration 15084 : model1 loss : 0.436133 model2 loss : 0.020768
[00:15:55.984] iteration 15085 : model1 loss : 0.435620 model2 loss : 0.019716
[00:15:56.157] iteration 15086 : model1 loss : 0.436489 model2 loss : 0.020725
[00:15:56.338] iteration 15087 : model1 loss : 0.435742 model2 loss : 0.020017
[00:15:56.511] iteration 15088 : model1 loss : 0.440123 model2 loss : 0.023522
[00:15:56.690] iteration 15089 : model1 loss : 0.442018 model2 loss : 0.022536
[00:15:56.861] iteration 15090 : model1 loss : 0.443847 model2 loss : 0.024841
[00:15:57.038] iteration 15091 : model1 loss : 0.435517 model2 loss : 0.019252
[00:15:57.209] iteration 15092 : model1 loss : 0.435598 model2 loss : 0.022105
[00:15:57.387] iteration 15093 : model1 loss : 0.435591 model2 loss : 0.020924
[00:15:57.560] iteration 15094 : model1 loss : 0.438613 model2 loss : 0.024365
[00:15:57.737] iteration 15095 : model1 loss : 0.435627 model2 loss : 0.018535
[00:15:57.908] iteration 15096 : model1 loss : 0.439909 model2 loss : 0.021858
[00:15:58.088] iteration 15097 : model1 loss : 0.435514 model2 loss : 0.019445
[00:15:58.259] iteration 15098 : model1 loss : 0.436592 model2 loss : 0.019894
[00:15:58.437] iteration 15099 : model1 loss : 0.434216 model2 loss : 0.022114
[00:16:00.607] iteration 15100 : model1 loss : 0.434165 model2 loss : 0.020982
[00:16:00.778] iteration 15101 : model1 loss : 0.436807 model2 loss : 0.021388
[00:16:00.957] iteration 15102 : model1 loss : 0.438556 model2 loss : 0.021052
[00:16:01.129] iteration 15103 : model1 loss : 0.432340 model2 loss : 0.018463
[00:16:01.309] iteration 15104 : model1 loss : 0.437720 model2 loss : 0.023293
[00:16:01.482] iteration 15105 : model1 loss : 0.433269 model2 loss : 0.022798
[00:16:01.658] iteration 15106 : model1 loss : 0.435845 model2 loss : 0.023839
[00:16:01.830] iteration 15107 : model1 loss : 0.441604 model2 loss : 0.020587
[00:16:02.006] iteration 15108 : model1 loss : 0.438914 model2 loss : 0.023198
[00:16:02.180] iteration 15109 : model1 loss : 0.436754 model2 loss : 0.019488
[00:16:02.363] iteration 15110 : model1 loss : 0.440889 model2 loss : 0.021232
[00:16:02.541] iteration 15111 : model1 loss : 0.434020 model2 loss : 0.020009
[00:16:02.719] iteration 15112 : model1 loss : 0.441807 model2 loss : 0.024248
[00:16:02.890] iteration 15113 : model1 loss : 0.438024 model2 loss : 0.021702
[00:16:03.067] iteration 15114 : model1 loss : 0.439173 model2 loss : 0.019731
[00:16:03.238] iteration 15115 : model1 loss : 0.433968 model2 loss : 0.021313
[00:16:03.421] iteration 15116 : model1 loss : 0.433488 model2 loss : 0.018941
[00:16:03.596] iteration 15117 : model1 loss : 0.436168 model2 loss : 0.021771
[00:16:03.774] iteration 15118 : model1 loss : 0.437210 model2 loss : 0.022949
[00:16:03.942] iteration 15119 : model1 loss : 0.438160 model2 loss : 0.021186
[00:16:04.119] iteration 15120 : model1 loss : 0.442456 model2 loss : 0.028072
[00:16:06.281] iteration 15121 : model1 loss : 0.439452 model2 loss : 0.021549
[00:16:06.465] iteration 15122 : model1 loss : 0.434719 model2 loss : 0.022056
[00:16:06.644] iteration 15123 : model1 loss : 0.443367 model2 loss : 0.024785
[00:16:06.813] iteration 15124 : model1 loss : 0.438759 model2 loss : 0.022006
[00:16:06.995] iteration 15125 : model1 loss : 0.439853 model2 loss : 0.020658
[00:16:07.166] iteration 15126 : model1 loss : 0.434841 model2 loss : 0.020619
[00:16:07.345] iteration 15127 : model1 loss : 0.441303 model2 loss : 0.020538
[00:16:07.519] iteration 15128 : model1 loss : 0.434288 model2 loss : 0.021459
[00:16:07.700] iteration 15129 : model1 loss : 0.432117 model2 loss : 0.020197
[00:16:07.871] iteration 15130 : model1 loss : 0.437429 model2 loss : 0.022781
[00:16:08.049] iteration 15131 : model1 loss : 0.434417 model2 loss : 0.019156
[00:16:08.220] iteration 15132 : model1 loss : 0.436475 model2 loss : 0.021374
[00:16:08.400] iteration 15133 : model1 loss : 0.437001 model2 loss : 0.020207
[00:16:08.574] iteration 15134 : model1 loss : 0.438042 model2 loss : 0.020526
[00:16:08.749] iteration 15135 : model1 loss : 0.439266 model2 loss : 0.021070
[00:16:08.921] iteration 15136 : model1 loss : 0.436008 model2 loss : 0.023916
[00:16:09.097] iteration 15137 : model1 loss : 0.438953 model2 loss : 0.023050
[00:16:09.268] iteration 15138 : model1 loss : 0.436833 model2 loss : 0.021140
[00:16:09.446] iteration 15139 : model1 loss : 0.433441 model2 loss : 0.019593
[00:16:09.621] iteration 15140 : model1 loss : 0.434196 model2 loss : 0.016996
[00:16:09.797] iteration 15141 : model1 loss : 0.434410 model2 loss : 0.020294
[00:16:11.923] iteration 15142 : model1 loss : 0.440499 model2 loss : 0.023243
[00:16:12.095] iteration 15143 : model1 loss : 0.435205 model2 loss : 0.019728
[00:16:12.278] iteration 15144 : model1 loss : 0.435617 model2 loss : 0.020025
[00:16:12.453] iteration 15145 : model1 loss : 0.444039 model2 loss : 0.025145
[00:16:12.635] iteration 15146 : model1 loss : 0.436891 model2 loss : 0.018367
[00:16:12.804] iteration 15147 : model1 loss : 0.432660 model2 loss : 0.018930
[00:16:12.982] iteration 15148 : model1 loss : 0.440438 model2 loss : 0.021292
[00:16:13.153] iteration 15149 : model1 loss : 0.436604 model2 loss : 0.022109
[00:16:13.337] iteration 15150 : model1 loss : 0.433181 model2 loss : 0.020213
[00:16:13.509] iteration 15151 : model1 loss : 0.433210 model2 loss : 0.018845
[00:16:13.686] iteration 15152 : model1 loss : 0.438486 model2 loss : 0.019799
[00:16:13.858] iteration 15153 : model1 loss : 0.432778 model2 loss : 0.019811
[00:16:14.036] iteration 15154 : model1 loss : 0.441842 model2 loss : 0.022475
[00:16:14.208] iteration 15155 : model1 loss : 0.437996 model2 loss : 0.022397
[00:16:14.391] iteration 15156 : model1 loss : 0.438134 model2 loss : 0.024615
[00:16:14.564] iteration 15157 : model1 loss : 0.435692 model2 loss : 0.020120
[00:16:14.743] iteration 15158 : model1 loss : 0.435805 model2 loss : 0.022647
[00:16:14.915] iteration 15159 : model1 loss : 0.437230 model2 loss : 0.019370
[00:16:15.092] iteration 15160 : model1 loss : 0.439146 model2 loss : 0.020349
[00:16:15.264] iteration 15161 : model1 loss : 0.437970 model2 loss : 0.022052
[00:16:15.440] iteration 15162 : model1 loss : 0.435075 model2 loss : 0.021271
[00:16:17.653] iteration 15163 : model1 loss : 0.439179 model2 loss : 0.021457
[00:16:17.825] iteration 15164 : model1 loss : 0.434884 model2 loss : 0.020165
[00:16:18.007] iteration 15165 : model1 loss : 0.436360 model2 loss : 0.020899
[00:16:18.178] iteration 15166 : model1 loss : 0.441582 model2 loss : 0.021154
[00:16:18.358] iteration 15167 : model1 loss : 0.434793 model2 loss : 0.024156
[00:16:18.532] iteration 15168 : model1 loss : 0.440588 model2 loss : 0.023338
[00:16:18.710] iteration 15169 : model1 loss : 0.439500 model2 loss : 0.021858
[00:16:18.882] iteration 15170 : model1 loss : 0.434821 model2 loss : 0.020095
[00:16:19.058] iteration 15171 : model1 loss : 0.432139 model2 loss : 0.019511
[00:16:19.231] iteration 15172 : model1 loss : 0.433461 model2 loss : 0.021221
[00:16:19.416] iteration 15173 : model1 loss : 0.433433 model2 loss : 0.021119
[00:16:19.590] iteration 15174 : model1 loss : 0.438671 model2 loss : 0.019287
[00:16:19.766] iteration 15175 : model1 loss : 0.435282 model2 loss : 0.020282
[00:16:19.942] iteration 15176 : model1 loss : 0.436143 model2 loss : 0.019777
[00:16:20.122] iteration 15177 : model1 loss : 0.438519 model2 loss : 0.018724
[00:16:20.292] iteration 15178 : model1 loss : 0.433649 model2 loss : 0.022114
[00:16:20.471] iteration 15179 : model1 loss : 0.444751 model2 loss : 0.025530
[00:16:20.647] iteration 15180 : model1 loss : 0.436327 model2 loss : 0.017952
[00:16:20.826] iteration 15181 : model1 loss : 0.433166 model2 loss : 0.021612
[00:16:20.996] iteration 15182 : model1 loss : 0.437523 model2 loss : 0.022169
[00:16:21.172] iteration 15183 : model1 loss : 0.439260 model2 loss : 0.019087
[00:16:23.337] iteration 15184 : model1 loss : 0.439415 model2 loss : 0.020888
[00:16:23.514] iteration 15185 : model1 loss : 0.431409 model2 loss : 0.018797
[00:16:23.695] iteration 15186 : model1 loss : 0.436628 model2 loss : 0.022154
[00:16:23.866] iteration 15187 : model1 loss : 0.439982 model2 loss : 0.021548
[00:16:24.045] iteration 15188 : model1 loss : 0.438294 model2 loss : 0.021092
[00:16:24.215] iteration 15189 : model1 loss : 0.434400 model2 loss : 0.019238
[00:16:24.395] iteration 15190 : model1 loss : 0.440124 model2 loss : 0.022751
[00:16:24.571] iteration 15191 : model1 loss : 0.438148 model2 loss : 0.021870
[00:16:24.746] iteration 15192 : model1 loss : 0.439479 model2 loss : 0.021998
[00:16:24.919] iteration 15193 : model1 loss : 0.432900 model2 loss : 0.018968
[00:16:25.097] iteration 15194 : model1 loss : 0.432394 model2 loss : 0.018842
[00:16:25.269] iteration 15195 : model1 loss : 0.436077 model2 loss : 0.024308
[00:16:25.447] iteration 15196 : model1 loss : 0.438509 model2 loss : 0.027884
[00:16:25.621] iteration 15197 : model1 loss : 0.435899 model2 loss : 0.020317
[00:16:25.799] iteration 15198 : model1 loss : 0.437337 model2 loss : 0.023251
[00:16:25.971] iteration 15199 : model1 loss : 0.437927 model2 loss : 0.024111
[00:16:26.150] iteration 15200 : model1 loss : 0.440178 model2 loss : 0.024285
[00:16:26.329] iteration 15201 : model1 loss : 0.438508 model2 loss : 0.022519
[00:16:26.508] iteration 15202 : model1 loss : 0.440608 model2 loss : 0.027901
[00:16:26.678] iteration 15203 : model1 loss : 0.437324 model2 loss : 0.023667
[00:16:26.856] iteration 15204 : model1 loss : 0.438185 model2 loss : 0.022723
[00:16:29.030] iteration 15205 : model1 loss : 0.435949 model2 loss : 0.022937
[00:16:29.205] iteration 15206 : model1 loss : 0.438624 model2 loss : 0.023418
[00:16:29.385] iteration 15207 : model1 loss : 0.435857 model2 loss : 0.022028
[00:16:29.558] iteration 15208 : model1 loss : 0.438061 model2 loss : 0.016808
[00:16:29.737] iteration 15209 : model1 loss : 0.441474 model2 loss : 0.023986
[00:16:29.909] iteration 15210 : model1 loss : 0.436213 model2 loss : 0.021932
[00:16:30.086] iteration 15211 : model1 loss : 0.437672 model2 loss : 0.022161
[00:16:30.256] iteration 15212 : model1 loss : 0.434586 model2 loss : 0.020857
[00:16:30.436] iteration 15213 : model1 loss : 0.439142 model2 loss : 0.022329
[00:16:30.611] iteration 15214 : model1 loss : 0.442068 model2 loss : 0.022190
[00:16:30.791] iteration 15215 : model1 loss : 0.440081 model2 loss : 0.019975
[00:16:30.964] iteration 15216 : model1 loss : 0.438726 model2 loss : 0.020825
[00:16:31.140] iteration 15217 : model1 loss : 0.439998 model2 loss : 0.023873
[00:16:31.314] iteration 15218 : model1 loss : 0.440230 model2 loss : 0.023153
[00:16:31.495] iteration 15219 : model1 loss : 0.435826 model2 loss : 0.023361
[00:16:31.666] iteration 15220 : model1 loss : 0.434638 model2 loss : 0.021007
[00:16:31.846] iteration 15221 : model1 loss : 0.430516 model2 loss : 0.019541
[00:16:32.016] iteration 15222 : model1 loss : 0.434033 model2 loss : 0.025797
[00:16:32.197] iteration 15223 : model1 loss : 0.438983 model2 loss : 0.023266
[00:16:32.369] iteration 15224 : model1 loss : 0.435713 model2 loss : 0.019931
[00:16:32.546] iteration 15225 : model1 loss : 0.436332 model2 loss : 0.021458
[00:16:34.678] iteration 15226 : model1 loss : 0.437904 model2 loss : 0.020525
[00:16:34.848] iteration 15227 : model1 loss : 0.440744 model2 loss : 0.023413
[00:16:35.031] iteration 15228 : model1 loss : 0.438491 model2 loss : 0.020651
[00:16:35.202] iteration 15229 : model1 loss : 0.437203 model2 loss : 0.021443
[00:16:35.380] iteration 15230 : model1 loss : 0.437622 model2 loss : 0.017861
[00:16:35.554] iteration 15231 : model1 loss : 0.436491 model2 loss : 0.021137
[00:16:35.734] iteration 15232 : model1 loss : 0.436743 model2 loss : 0.020695
[00:16:35.904] iteration 15233 : model1 loss : 0.434271 model2 loss : 0.020192
[00:16:36.084] iteration 15234 : model1 loss : 0.435582 model2 loss : 0.021804
[00:16:36.257] iteration 15235 : model1 loss : 0.436990 model2 loss : 0.020583
[00:16:36.436] iteration 15236 : model1 loss : 0.434385 model2 loss : 0.019875
[00:16:36.611] iteration 15237 : model1 loss : 0.442323 model2 loss : 0.025936
[00:16:36.793] iteration 15238 : model1 loss : 0.435492 model2 loss : 0.018871
[00:16:36.965] iteration 15239 : model1 loss : 0.438174 model2 loss : 0.018092
[00:16:37.141] iteration 15240 : model1 loss : 0.434619 model2 loss : 0.021101
[00:16:37.316] iteration 15241 : model1 loss : 0.436961 model2 loss : 0.023742
[00:16:37.504] iteration 15242 : model1 loss : 0.434327 model2 loss : 0.017308
[00:16:37.673] iteration 15243 : model1 loss : 0.438749 model2 loss : 0.021032
[00:16:37.851] iteration 15244 : model1 loss : 0.437995 model2 loss : 0.020259
[00:16:38.023] iteration 15245 : model1 loss : 0.434582 model2 loss : 0.019193
[00:16:38.198] iteration 15246 : model1 loss : 0.438261 model2 loss : 0.022683
[00:16:40.355] iteration 15247 : model1 loss : 0.433083 model2 loss : 0.019221
[00:16:40.534] iteration 15248 : model1 loss : 0.438897 model2 loss : 0.021678
[00:16:40.713] iteration 15249 : model1 loss : 0.439294 model2 loss : 0.020241
[00:16:40.883] iteration 15250 : model1 loss : 0.437899 model2 loss : 0.018830
[00:16:41.058] iteration 15251 : model1 loss : 0.438940 model2 loss : 0.022468
[00:16:41.232] iteration 15252 : model1 loss : 0.441212 model2 loss : 0.019305
[00:16:41.411] iteration 15253 : model1 loss : 0.433904 model2 loss : 0.019487
[00:16:41.586] iteration 15254 : model1 loss : 0.436463 model2 loss : 0.019952
[00:16:41.766] iteration 15255 : model1 loss : 0.438226 model2 loss : 0.022903
[00:16:41.938] iteration 15256 : model1 loss : 0.439322 model2 loss : 0.020126
[00:16:42.115] iteration 15257 : model1 loss : 0.435970 model2 loss : 0.020251
[00:16:42.287] iteration 15258 : model1 loss : 0.437384 model2 loss : 0.017825
[00:16:42.468] iteration 15259 : model1 loss : 0.436401 model2 loss : 0.023011
[00:16:42.640] iteration 15260 : model1 loss : 0.437706 model2 loss : 0.022147
[00:16:42.816] iteration 15261 : model1 loss : 0.438379 model2 loss : 0.021544
[00:16:42.987] iteration 15262 : model1 loss : 0.435010 model2 loss : 0.019230
[00:16:43.164] iteration 15263 : model1 loss : 0.435337 model2 loss : 0.018421
[00:16:43.338] iteration 15264 : model1 loss : 0.435610 model2 loss : 0.020957
[00:16:43.517] iteration 15265 : model1 loss : 0.439547 model2 loss : 0.020126
[00:16:43.688] iteration 15266 : model1 loss : 0.435021 model2 loss : 0.022498
[00:16:43.865] iteration 15267 : model1 loss : 0.438573 model2 loss : 0.020581
[00:16:46.033] iteration 15268 : model1 loss : 0.440930 model2 loss : 0.023199
[00:16:46.206] iteration 15269 : model1 loss : 0.435535 model2 loss : 0.019826
[00:16:46.384] iteration 15270 : model1 loss : 0.438005 model2 loss : 0.016888
[00:16:46.556] iteration 15271 : model1 loss : 0.433691 model2 loss : 0.019727
[00:16:46.733] iteration 15272 : model1 loss : 0.441262 model2 loss : 0.021916
[00:16:46.905] iteration 15273 : model1 loss : 0.438134 model2 loss : 0.019235
[00:16:47.081] iteration 15274 : model1 loss : 0.437318 model2 loss : 0.025160
[00:16:47.253] iteration 15275 : model1 loss : 0.437441 model2 loss : 0.018913
[00:16:47.438] iteration 15276 : model1 loss : 0.435879 model2 loss : 0.022063
[00:16:47.613] iteration 15277 : model1 loss : 0.441342 model2 loss : 0.021304
[00:16:47.790] iteration 15278 : model1 loss : 0.436348 model2 loss : 0.020623
[00:16:47.962] iteration 15279 : model1 loss : 0.437568 model2 loss : 0.019057
[00:16:48.139] iteration 15280 : model1 loss : 0.439483 model2 loss : 0.021700
[00:16:48.313] iteration 15281 : model1 loss : 0.437738 model2 loss : 0.020169
[00:16:48.493] iteration 15282 : model1 loss : 0.440672 model2 loss : 0.025169
[00:16:48.667] iteration 15283 : model1 loss : 0.433888 model2 loss : 0.019099
[00:16:48.843] iteration 15284 : model1 loss : 0.435263 model2 loss : 0.020688
[00:16:49.013] iteration 15285 : model1 loss : 0.440511 model2 loss : 0.022843
[00:16:49.192] iteration 15286 : model1 loss : 0.433890 model2 loss : 0.021586
[00:16:49.364] iteration 15287 : model1 loss : 0.434428 model2 loss : 0.016593
[00:16:49.542] iteration 15288 : model1 loss : 0.435193 model2 loss : 0.019918
[00:16:51.671] iteration 15289 : model1 loss : 0.435606 model2 loss : 0.020187
[00:16:51.842] iteration 15290 : model1 loss : 0.434118 model2 loss : 0.020310
[00:16:52.023] iteration 15291 : model1 loss : 0.439264 model2 loss : 0.022027
[00:16:52.196] iteration 15292 : model1 loss : 0.438061 model2 loss : 0.020997
[00:16:52.375] iteration 15293 : model1 loss : 0.436227 model2 loss : 0.018853
[00:16:52.548] iteration 15294 : model1 loss : 0.436774 model2 loss : 0.021192
[00:16:52.726] iteration 15295 : model1 loss : 0.435520 model2 loss : 0.020362
[00:16:52.897] iteration 15296 : model1 loss : 0.436939 model2 loss : 0.021030
[00:16:53.074] iteration 15297 : model1 loss : 0.437100 model2 loss : 0.019332
[00:16:53.247] iteration 15298 : model1 loss : 0.439194 model2 loss : 0.021546
[00:16:53.429] iteration 15299 : model1 loss : 0.433783 model2 loss : 0.017790
[00:16:53.605] iteration 15300 : model1 loss : 0.438554 model2 loss : 0.022943
[00:16:53.784] iteration 15301 : model1 loss : 0.437618 model2 loss : 0.021186
[00:16:53.956] iteration 15302 : model1 loss : 0.437751 model2 loss : 0.019714
[00:16:54.138] iteration 15303 : model1 loss : 0.432603 model2 loss : 0.018439
[00:16:54.314] iteration 15304 : model1 loss : 0.439408 model2 loss : 0.020954
[00:16:54.493] iteration 15305 : model1 loss : 0.440905 model2 loss : 0.022925
[00:16:54.668] iteration 15306 : model1 loss : 0.435995 model2 loss : 0.021263
[00:16:54.845] iteration 15307 : model1 loss : 0.441789 model2 loss : 0.022899
[00:16:55.016] iteration 15308 : model1 loss : 0.438635 model2 loss : 0.020434
[00:16:55.189] iteration 15309 : model1 loss : 0.433026 model2 loss : 0.019379
[00:16:57.338] iteration 15310 : model1 loss : 0.437159 model2 loss : 0.019873
[00:16:57.520] iteration 15311 : model1 loss : 0.435384 model2 loss : 0.017670
[00:16:57.701] iteration 15312 : model1 loss : 0.432448 model2 loss : 0.020383
[00:16:57.875] iteration 15313 : model1 loss : 0.438786 model2 loss : 0.020818
[00:16:58.052] iteration 15314 : model1 loss : 0.438756 model2 loss : 0.021410
[00:16:58.224] iteration 15315 : model1 loss : 0.433284 model2 loss : 0.018152
[00:16:58.404] iteration 15316 : model1 loss : 0.438501 model2 loss : 0.021480
[00:16:58.575] iteration 15317 : model1 loss : 0.439635 model2 loss : 0.019630
[00:16:58.752] iteration 15318 : model1 loss : 0.437503 model2 loss : 0.021305
[00:16:58.923] iteration 15319 : model1 loss : 0.441425 model2 loss : 0.020959
[00:16:59.101] iteration 15320 : model1 loss : 0.439345 model2 loss : 0.021588
[00:16:59.274] iteration 15321 : model1 loss : 0.437970 model2 loss : 0.020128
[00:16:59.453] iteration 15322 : model1 loss : 0.438751 model2 loss : 0.019871
[00:16:59.628] iteration 15323 : model1 loss : 0.434899 model2 loss : 0.018092
[00:16:59.806] iteration 15324 : model1 loss : 0.433263 model2 loss : 0.020709
[00:16:59.978] iteration 15325 : model1 loss : 0.444745 model2 loss : 0.030606
[00:17:00.160] iteration 15326 : model1 loss : 0.435152 model2 loss : 0.020949
[00:17:00.339] iteration 15327 : model1 loss : 0.435851 model2 loss : 0.022195
[00:17:00.518] iteration 15328 : model1 loss : 0.438630 model2 loss : 0.020668
[00:17:00.687] iteration 15329 : model1 loss : 0.437176 model2 loss : 0.022963
[00:17:00.862] iteration 15330 : model1 loss : 0.431984 model2 loss : 0.020141
[00:17:03.014] iteration 15331 : model1 loss : 0.435490 model2 loss : 0.019985
[00:17:03.187] iteration 15332 : model1 loss : 0.435748 model2 loss : 0.020663
[00:17:03.367] iteration 15333 : model1 loss : 0.435217 model2 loss : 0.018872
[00:17:03.539] iteration 15334 : model1 loss : 0.430978 model2 loss : 0.020731
[00:17:03.718] iteration 15335 : model1 loss : 0.440782 model2 loss : 0.021066
[00:17:03.890] iteration 15336 : model1 loss : 0.437397 model2 loss : 0.022595
[00:17:04.067] iteration 15337 : model1 loss : 0.433082 model2 loss : 0.022254
[00:17:04.239] iteration 15338 : model1 loss : 0.435654 model2 loss : 0.021105
[00:17:04.420] iteration 15339 : model1 loss : 0.435670 model2 loss : 0.020901
[00:17:04.596] iteration 15340 : model1 loss : 0.433759 model2 loss : 0.018817
[00:17:04.772] iteration 15341 : model1 loss : 0.435614 model2 loss : 0.020764
[00:17:04.942] iteration 15342 : model1 loss : 0.436749 model2 loss : 0.020076
[00:17:05.118] iteration 15343 : model1 loss : 0.441144 model2 loss : 0.023191
[00:17:05.291] iteration 15344 : model1 loss : 0.435576 model2 loss : 0.019317
[00:17:05.471] iteration 15345 : model1 loss : 0.437518 model2 loss : 0.020362
[00:17:05.643] iteration 15346 : model1 loss : 0.440877 model2 loss : 0.023122
[00:17:05.819] iteration 15347 : model1 loss : 0.438970 model2 loss : 0.021526
[00:17:05.991] iteration 15348 : model1 loss : 0.437633 model2 loss : 0.022811
[00:17:06.168] iteration 15349 : model1 loss : 0.438693 model2 loss : 0.017960
[00:17:06.340] iteration 15350 : model1 loss : 0.439547 model2 loss : 0.019740
[00:17:06.517] iteration 15351 : model1 loss : 0.439680 model2 loss : 0.019070
[00:17:08.739] iteration 15352 : model1 loss : 0.438331 model2 loss : 0.019269
[00:17:08.912] iteration 15353 : model1 loss : 0.439654 model2 loss : 0.022510
[00:17:09.092] iteration 15354 : model1 loss : 0.436036 model2 loss : 0.020472
[00:17:09.266] iteration 15355 : model1 loss : 0.438538 model2 loss : 0.019514
[00:17:09.445] iteration 15356 : model1 loss : 0.438809 model2 loss : 0.021643
[00:17:09.620] iteration 15357 : model1 loss : 0.437239 model2 loss : 0.022190
[00:17:09.800] iteration 15358 : model1 loss : 0.434205 model2 loss : 0.018281
[00:17:09.971] iteration 15359 : model1 loss : 0.440629 model2 loss : 0.021945
[00:17:10.147] iteration 15360 : model1 loss : 0.436358 model2 loss : 0.021032
[00:17:10.323] iteration 15361 : model1 loss : 0.433498 model2 loss : 0.020791
[00:17:10.502] iteration 15362 : model1 loss : 0.436036 model2 loss : 0.020596
[00:17:10.675] iteration 15363 : model1 loss : 0.436015 model2 loss : 0.019014
[00:17:10.855] iteration 15364 : model1 loss : 0.438173 model2 loss : 0.021039
[00:17:11.028] iteration 15365 : model1 loss : 0.440710 model2 loss : 0.021381
[00:17:11.206] iteration 15366 : model1 loss : 0.436253 model2 loss : 0.020647
[00:17:11.378] iteration 15367 : model1 loss : 0.433921 model2 loss : 0.021156
[00:17:11.557] iteration 15368 : model1 loss : 0.434986 model2 loss : 0.020201
[00:17:11.730] iteration 15369 : model1 loss : 0.438918 model2 loss : 0.021566
[00:17:11.906] iteration 15370 : model1 loss : 0.435655 model2 loss : 0.019269
[00:17:12.077] iteration 15371 : model1 loss : 0.433507 model2 loss : 0.020595
[00:17:12.254] iteration 15372 : model1 loss : 0.438627 model2 loss : 0.023038
[00:17:14.448] iteration 15373 : model1 loss : 0.435586 model2 loss : 0.020387
[00:17:14.636] iteration 15374 : model1 loss : 0.440335 model2 loss : 0.020219
[00:17:14.812] iteration 15375 : model1 loss : 0.438008 model2 loss : 0.021315
[00:17:14.983] iteration 15376 : model1 loss : 0.439878 model2 loss : 0.024521
[00:17:15.158] iteration 15377 : model1 loss : 0.437432 model2 loss : 0.021217
[00:17:15.336] iteration 15378 : model1 loss : 0.432953 model2 loss : 0.018273
[00:17:15.512] iteration 15379 : model1 loss : 0.436210 model2 loss : 0.021734
[00:17:15.684] iteration 15380 : model1 loss : 0.436602 model2 loss : 0.019032
[00:17:15.864] iteration 15381 : model1 loss : 0.441865 model2 loss : 0.022483
[00:17:16.036] iteration 15382 : model1 loss : 0.437868 model2 loss : 0.021591
[00:17:16.216] iteration 15383 : model1 loss : 0.436339 model2 loss : 0.019708
[00:17:16.389] iteration 15384 : model1 loss : 0.438318 model2 loss : 0.021976
[00:17:16.569] iteration 15385 : model1 loss : 0.437413 model2 loss : 0.021842
[00:17:16.740] iteration 15386 : model1 loss : 0.437385 model2 loss : 0.020510
[00:17:16.919] iteration 15387 : model1 loss : 0.436187 model2 loss : 0.021038
[00:17:17.093] iteration 15388 : model1 loss : 0.439361 model2 loss : 0.018620
[00:17:17.270] iteration 15389 : model1 loss : 0.440923 model2 loss : 0.022099
[00:17:17.445] iteration 15390 : model1 loss : 0.435620 model2 loss : 0.019359
[00:17:17.629] iteration 15391 : model1 loss : 0.432432 model2 loss : 0.019810
[00:17:17.800] iteration 15392 : model1 loss : 0.433066 model2 loss : 0.019042
[00:17:17.975] iteration 15393 : model1 loss : 0.436424 model2 loss : 0.020021
[00:17:20.114] iteration 15394 : model1 loss : 0.436197 model2 loss : 0.020085
[00:17:20.288] iteration 15395 : model1 loss : 0.439860 model2 loss : 0.021738
[00:17:20.472] iteration 15396 : model1 loss : 0.437242 model2 loss : 0.022331
[00:17:20.647] iteration 15397 : model1 loss : 0.438073 model2 loss : 0.022177
[00:17:20.828] iteration 15398 : model1 loss : 0.435178 model2 loss : 0.021178
[00:17:21.000] iteration 15399 : model1 loss : 0.435654 model2 loss : 0.020592
[00:17:21.180] iteration 15400 : model1 loss : 0.438328 model2 loss : 0.020397
[00:17:21.353] iteration 15401 : model1 loss : 0.437578 model2 loss : 0.022606
[00:17:21.535] iteration 15402 : model1 loss : 0.439889 model2 loss : 0.018680
[00:17:21.706] iteration 15403 : model1 loss : 0.441451 model2 loss : 0.020695
[00:17:21.881] iteration 15404 : model1 loss : 0.434148 model2 loss : 0.019012
[00:17:22.054] iteration 15405 : model1 loss : 0.435055 model2 loss : 0.021727
[00:17:22.234] iteration 15406 : model1 loss : 0.432745 model2 loss : 0.019542
[00:17:22.414] iteration 15407 : model1 loss : 0.436909 model2 loss : 0.021948
[00:17:22.598] iteration 15408 : model1 loss : 0.435244 model2 loss : 0.019275
[00:17:22.771] iteration 15409 : model1 loss : 0.433803 model2 loss : 0.020888
[00:17:22.947] iteration 15410 : model1 loss : 0.440069 model2 loss : 0.019651
[00:17:23.118] iteration 15411 : model1 loss : 0.434464 model2 loss : 0.020844
[00:17:23.296] iteration 15412 : model1 loss : 0.438226 model2 loss : 0.022952
[00:17:23.470] iteration 15413 : model1 loss : 0.440545 model2 loss : 0.020919
[00:17:23.644] iteration 15414 : model1 loss : 0.438318 model2 loss : 0.021485
[00:17:25.815] iteration 15415 : model1 loss : 0.437590 model2 loss : 0.022258
[00:17:25.995] iteration 15416 : model1 loss : 0.434693 model2 loss : 0.019741
[00:17:26.174] iteration 15417 : model1 loss : 0.434113 model2 loss : 0.020112
[00:17:26.349] iteration 15418 : model1 loss : 0.439396 model2 loss : 0.019258
[00:17:26.527] iteration 15419 : model1 loss : 0.433985 model2 loss : 0.018583
[00:17:26.698] iteration 15420 : model1 loss : 0.437483 model2 loss : 0.020888
[00:17:26.877] iteration 15421 : model1 loss : 0.436926 model2 loss : 0.020410
[00:17:27.048] iteration 15422 : model1 loss : 0.434227 model2 loss : 0.018501
[00:17:27.225] iteration 15423 : model1 loss : 0.440470 model2 loss : 0.022504
[00:17:27.397] iteration 15424 : model1 loss : 0.436850 model2 loss : 0.019907
[00:17:27.578] iteration 15425 : model1 loss : 0.434580 model2 loss : 0.020855
[00:17:27.748] iteration 15426 : model1 loss : 0.438243 model2 loss : 0.019370
[00:17:27.922] iteration 15427 : model1 loss : 0.439230 model2 loss : 0.021807
[00:17:28.095] iteration 15428 : model1 loss : 0.435740 model2 loss : 0.018349
[00:17:28.274] iteration 15429 : model1 loss : 0.437961 model2 loss : 0.021332
[00:17:28.446] iteration 15430 : model1 loss : 0.440463 model2 loss : 0.023038
[00:17:28.629] iteration 15431 : model1 loss : 0.438322 model2 loss : 0.024144
[00:17:28.801] iteration 15432 : model1 loss : 0.438668 model2 loss : 0.022878
[00:17:28.979] iteration 15433 : model1 loss : 0.434514 model2 loss : 0.020356
[00:17:29.149] iteration 15434 : model1 loss : 0.441154 model2 loss : 0.019213
[00:17:29.327] iteration 15435 : model1 loss : 0.435015 model2 loss : 0.021921
[00:17:31.497] iteration 15436 : model1 loss : 0.435469 model2 loss : 0.021346
[00:17:31.673] iteration 15437 : model1 loss : 0.436647 model2 loss : 0.018941
[00:17:31.852] iteration 15438 : model1 loss : 0.436580 model2 loss : 0.020352
[00:17:32.025] iteration 15439 : model1 loss : 0.435538 model2 loss : 0.021007
[00:17:32.203] iteration 15440 : model1 loss : 0.437250 model2 loss : 0.022879
[00:17:32.376] iteration 15441 : model1 loss : 0.441358 model2 loss : 0.023180
[00:17:32.558] iteration 15442 : model1 loss : 0.439571 model2 loss : 0.021185
[00:17:32.730] iteration 15443 : model1 loss : 0.435769 model2 loss : 0.020025
[00:17:32.908] iteration 15444 : model1 loss : 0.442349 model2 loss : 0.021528
[00:17:33.078] iteration 15445 : model1 loss : 0.432868 model2 loss : 0.021123
[00:17:33.255] iteration 15446 : model1 loss : 0.436862 model2 loss : 0.020065
[00:17:33.426] iteration 15447 : model1 loss : 0.434591 model2 loss : 0.018664
[00:17:33.605] iteration 15448 : model1 loss : 0.436716 model2 loss : 0.018791
[00:17:33.777] iteration 15449 : model1 loss : 0.435975 model2 loss : 0.023572
[00:17:33.954] iteration 15450 : model1 loss : 0.436426 model2 loss : 0.021332
[00:17:34.126] iteration 15451 : model1 loss : 0.436605 model2 loss : 0.020499
[00:17:34.304] iteration 15452 : model1 loss : 0.443344 model2 loss : 0.020503
[00:17:34.477] iteration 15453 : model1 loss : 0.435694 model2 loss : 0.019299
[00:17:34.655] iteration 15454 : model1 loss : 0.438210 model2 loss : 0.025222
[00:17:34.825] iteration 15455 : model1 loss : 0.443260 model2 loss : 0.021676
[00:17:35.001] iteration 15456 : model1 loss : 0.437777 model2 loss : 0.021469
[00:17:37.161] iteration 15457 : model1 loss : 0.441005 model2 loss : 0.024886
[00:17:37.336] iteration 15458 : model1 loss : 0.435049 model2 loss : 0.019813
[00:17:37.520] iteration 15459 : model1 loss : 0.440228 model2 loss : 0.021161
[00:17:37.691] iteration 15460 : model1 loss : 0.437462 model2 loss : 0.021021
[00:17:37.870] iteration 15461 : model1 loss : 0.438274 model2 loss : 0.019402
[00:17:38.041] iteration 15462 : model1 loss : 0.438478 model2 loss : 0.020927
[00:17:38.220] iteration 15463 : model1 loss : 0.435667 model2 loss : 0.019724
[00:17:38.392] iteration 15464 : model1 loss : 0.441583 model2 loss : 0.019755
[00:17:38.572] iteration 15465 : model1 loss : 0.437164 model2 loss : 0.019926
[00:17:38.745] iteration 15466 : model1 loss : 0.437994 model2 loss : 0.019595
[00:17:38.922] iteration 15467 : model1 loss : 0.436505 model2 loss : 0.019819
[00:17:39.093] iteration 15468 : model1 loss : 0.435343 model2 loss : 0.018211
[00:17:39.271] iteration 15469 : model1 loss : 0.441712 model2 loss : 0.019772
[00:17:39.444] iteration 15470 : model1 loss : 0.434789 model2 loss : 0.019961
[00:17:39.624] iteration 15471 : model1 loss : 0.434890 model2 loss : 0.022411
[00:17:39.795] iteration 15472 : model1 loss : 0.442095 model2 loss : 0.022624
[00:17:39.971] iteration 15473 : model1 loss : 0.432345 model2 loss : 0.022401
[00:17:40.141] iteration 15474 : model1 loss : 0.433129 model2 loss : 0.020398
[00:17:40.323] iteration 15475 : model1 loss : 0.435354 model2 loss : 0.022335
[00:17:40.495] iteration 15476 : model1 loss : 0.436704 model2 loss : 0.021346
[00:17:40.673] iteration 15477 : model1 loss : 0.438653 model2 loss : 0.020092
[00:17:42.802] iteration 15478 : model1 loss : 0.433950 model2 loss : 0.019113
[00:17:42.978] iteration 15479 : model1 loss : 0.436648 model2 loss : 0.020872
[00:17:43.158] iteration 15480 : model1 loss : 0.440547 model2 loss : 0.023179
[00:17:43.336] iteration 15481 : model1 loss : 0.438902 model2 loss : 0.020522
[00:17:43.516] iteration 15482 : model1 loss : 0.437729 model2 loss : 0.020176
[00:17:43.687] iteration 15483 : model1 loss : 0.437053 model2 loss : 0.021781
[00:17:43.864] iteration 15484 : model1 loss : 0.437405 model2 loss : 0.018478
[00:17:44.035] iteration 15485 : model1 loss : 0.436929 model2 loss : 0.018659
[00:17:44.211] iteration 15486 : model1 loss : 0.438665 model2 loss : 0.020358
[00:17:44.385] iteration 15487 : model1 loss : 0.437801 model2 loss : 0.020990
[00:17:44.567] iteration 15488 : model1 loss : 0.436931 model2 loss : 0.024049
[00:17:44.738] iteration 15489 : model1 loss : 0.434865 model2 loss : 0.018178
[00:17:44.917] iteration 15490 : model1 loss : 0.438899 model2 loss : 0.019964
[00:17:45.089] iteration 15491 : model1 loss : 0.435053 model2 loss : 0.019519
[00:17:45.265] iteration 15492 : model1 loss : 0.440358 model2 loss : 0.020553
[00:17:45.438] iteration 15493 : model1 loss : 0.442227 model2 loss : 0.019796
[00:17:45.618] iteration 15494 : model1 loss : 0.435891 model2 loss : 0.021047
[00:17:45.791] iteration 15495 : model1 loss : 0.434127 model2 loss : 0.019511
[00:17:45.970] iteration 15496 : model1 loss : 0.432261 model2 loss : 0.019610
[00:17:46.141] iteration 15497 : model1 loss : 0.435870 model2 loss : 0.020944
[00:17:46.319] iteration 15498 : model1 loss : 0.438140 model2 loss : 0.022302
[00:17:48.524] iteration 15499 : model1 loss : 0.438626 model2 loss : 0.023176
[00:17:48.697] iteration 15500 : model1 loss : 0.437355 model2 loss : 0.019705
[00:17:48.876] iteration 15501 : model1 loss : 0.433679 model2 loss : 0.020533
[00:17:49.048] iteration 15502 : model1 loss : 0.433870 model2 loss : 0.018626
[00:17:49.229] iteration 15503 : model1 loss : 0.440517 model2 loss : 0.022744
[00:17:49.405] iteration 15504 : model1 loss : 0.435458 model2 loss : 0.019007
[00:17:49.586] iteration 15505 : model1 loss : 0.438828 model2 loss : 0.019371
[00:17:49.757] iteration 15506 : model1 loss : 0.436247 model2 loss : 0.018875
[00:17:49.939] iteration 15507 : model1 loss : 0.438481 model2 loss : 0.020008
[00:17:50.111] iteration 15508 : model1 loss : 0.436491 model2 loss : 0.021751
[00:17:50.289] iteration 15509 : model1 loss : 0.436207 model2 loss : 0.019920
[00:17:50.463] iteration 15510 : model1 loss : 0.437425 model2 loss : 0.021838
[00:17:50.646] iteration 15511 : model1 loss : 0.435485 model2 loss : 0.019867
[00:17:50.819] iteration 15512 : model1 loss : 0.437063 model2 loss : 0.019208
[00:17:50.995] iteration 15513 : model1 loss : 0.437198 model2 loss : 0.022570
[00:17:51.166] iteration 15514 : model1 loss : 0.438194 model2 loss : 0.019903
[00:17:51.346] iteration 15515 : model1 loss : 0.437428 model2 loss : 0.021507
[00:17:51.519] iteration 15516 : model1 loss : 0.434616 model2 loss : 0.019810
[00:17:51.695] iteration 15517 : model1 loss : 0.441219 model2 loss : 0.026638
[00:17:51.866] iteration 15518 : model1 loss : 0.440348 model2 loss : 0.023181
[00:17:52.043] iteration 15519 : model1 loss : 0.438006 model2 loss : 0.020748
[00:17:54.226] iteration 15520 : model1 loss : 0.435809 model2 loss : 0.018490
[00:17:54.400] iteration 15521 : model1 loss : 0.440469 model2 loss : 0.021387
[00:17:54.579] iteration 15522 : model1 loss : 0.436440 model2 loss : 0.020955
[00:17:54.750] iteration 15523 : model1 loss : 0.436081 model2 loss : 0.018841
[00:17:54.929] iteration 15524 : model1 loss : 0.435560 model2 loss : 0.018799
[00:17:55.101] iteration 15525 : model1 loss : 0.442027 model2 loss : 0.023296
[00:17:55.278] iteration 15526 : model1 loss : 0.440301 model2 loss : 0.020992
[00:17:55.450] iteration 15527 : model1 loss : 0.437933 model2 loss : 0.021734
[00:17:55.632] iteration 15528 : model1 loss : 0.432375 model2 loss : 0.021063
[00:17:55.803] iteration 15529 : model1 loss : 0.437828 model2 loss : 0.021417
[00:17:55.980] iteration 15530 : model1 loss : 0.438023 model2 loss : 0.020444
[00:17:56.152] iteration 15531 : model1 loss : 0.434731 model2 loss : 0.020452
[00:17:56.336] iteration 15532 : model1 loss : 0.439385 model2 loss : 0.024878
[00:17:56.510] iteration 15533 : model1 loss : 0.434230 model2 loss : 0.020467
[00:17:56.691] iteration 15534 : model1 loss : 0.433465 model2 loss : 0.018897
[00:17:56.863] iteration 15535 : model1 loss : 0.439094 model2 loss : 0.023127
[00:17:57.040] iteration 15536 : model1 loss : 0.433181 model2 loss : 0.020076
[00:17:57.221] iteration 15537 : model1 loss : 0.439840 model2 loss : 0.019788
[00:17:57.404] iteration 15538 : model1 loss : 0.438148 model2 loss : 0.021452
[00:17:57.574] iteration 15539 : model1 loss : 0.438932 model2 loss : 0.022002
[00:17:57.752] iteration 15540 : model1 loss : 0.435555 model2 loss : 0.018821
[00:17:59.873] iteration 15541 : model1 loss : 0.432672 model2 loss : 0.019071
[00:18:00.047] iteration 15542 : model1 loss : 0.434224 model2 loss : 0.018143
[00:18:00.231] iteration 15543 : model1 loss : 0.435772 model2 loss : 0.022029
[00:18:00.405] iteration 15544 : model1 loss : 0.442158 model2 loss : 0.023964
[00:18:00.584] iteration 15545 : model1 loss : 0.440983 model2 loss : 0.021480
[00:18:00.757] iteration 15546 : model1 loss : 0.438643 model2 loss : 0.019222
[00:18:00.934] iteration 15547 : model1 loss : 0.432879 model2 loss : 0.022163
[00:18:01.105] iteration 15548 : model1 loss : 0.435039 model2 loss : 0.017029
[00:18:01.282] iteration 15549 : model1 loss : 0.437577 model2 loss : 0.023053
[00:18:01.456] iteration 15550 : model1 loss : 0.434962 model2 loss : 0.021851
[00:18:01.636] iteration 15551 : model1 loss : 0.436720 model2 loss : 0.019015
[00:18:01.807] iteration 15552 : model1 loss : 0.442723 model2 loss : 0.025309
[00:18:01.984] iteration 15553 : model1 loss : 0.436083 model2 loss : 0.023391
[00:18:02.157] iteration 15554 : model1 loss : 0.442408 model2 loss : 0.022937
[00:18:02.342] iteration 15555 : model1 loss : 0.440996 model2 loss : 0.022072
[00:18:02.520] iteration 15556 : model1 loss : 0.437102 model2 loss : 0.020985
[00:18:02.701] iteration 15557 : model1 loss : 0.444582 model2 loss : 0.025006
[00:18:02.873] iteration 15558 : model1 loss : 0.439292 model2 loss : 0.020796
[00:18:03.050] iteration 15559 : model1 loss : 0.437029 model2 loss : 0.020218
[00:18:03.221] iteration 15560 : model1 loss : 0.435705 model2 loss : 0.021522
[00:18:03.398] iteration 15561 : model1 loss : 0.433930 model2 loss : 0.020532
[00:18:05.531] iteration 15562 : model1 loss : 0.441660 model2 loss : 0.022139
[00:18:05.709] iteration 15563 : model1 loss : 0.432848 model2 loss : 0.021201
[00:18:05.886] iteration 15564 : model1 loss : 0.436504 model2 loss : 0.019548
[00:18:06.061] iteration 15565 : model1 loss : 0.436025 model2 loss : 0.019974
[00:18:06.239] iteration 15566 : model1 loss : 0.435072 model2 loss : 0.019491
[00:18:06.413] iteration 15567 : model1 loss : 0.432848 model2 loss : 0.019224
[00:18:06.595] iteration 15568 : model1 loss : 0.438048 model2 loss : 0.018631
[00:18:06.767] iteration 15569 : model1 loss : 0.436064 model2 loss : 0.021759
[00:18:06.943] iteration 15570 : model1 loss : 0.439091 model2 loss : 0.022336
[00:18:07.114] iteration 15571 : model1 loss : 0.434967 model2 loss : 0.020301
[00:18:07.290] iteration 15572 : model1 loss : 0.440329 model2 loss : 0.023200
[00:18:07.466] iteration 15573 : model1 loss : 0.438166 model2 loss : 0.020742
[00:18:07.645] iteration 15574 : model1 loss : 0.434764 model2 loss : 0.020311
[00:18:07.816] iteration 15575 : model1 loss : 0.434126 model2 loss : 0.020036
[00:18:07.996] iteration 15576 : model1 loss : 0.437829 model2 loss : 0.019830
[00:18:08.168] iteration 15577 : model1 loss : 0.438840 model2 loss : 0.021123
[00:18:08.348] iteration 15578 : model1 loss : 0.437861 model2 loss : 0.021864
[00:18:08.521] iteration 15579 : model1 loss : 0.439620 model2 loss : 0.020401
[00:18:08.698] iteration 15580 : model1 loss : 0.435112 model2 loss : 0.021206
[00:18:08.867] iteration 15581 : model1 loss : 0.439549 model2 loss : 0.021547
[00:18:09.043] iteration 15582 : model1 loss : 0.439852 model2 loss : 0.021651
[00:18:11.195] iteration 15583 : model1 loss : 0.435704 model2 loss : 0.021640
[00:18:11.367] iteration 15584 : model1 loss : 0.436637 model2 loss : 0.018912
[00:18:11.544] iteration 15585 : model1 loss : 0.434422 model2 loss : 0.019889
[00:18:11.717] iteration 15586 : model1 loss : 0.434442 model2 loss : 0.019874
[00:18:11.895] iteration 15587 : model1 loss : 0.441033 model2 loss : 0.019957
[00:18:12.068] iteration 15588 : model1 loss : 0.439416 model2 loss : 0.020954
[00:18:12.244] iteration 15589 : model1 loss : 0.434491 model2 loss : 0.019325
[00:18:12.425] iteration 15590 : model1 loss : 0.429786 model2 loss : 0.019298
[00:18:12.608] iteration 15591 : model1 loss : 0.437965 model2 loss : 0.019394
[00:18:12.779] iteration 15592 : model1 loss : 0.437528 model2 loss : 0.020405
[00:18:12.955] iteration 15593 : model1 loss : 0.440263 model2 loss : 0.020040
[00:18:13.127] iteration 15594 : model1 loss : 0.436106 model2 loss : 0.020749
[00:18:13.306] iteration 15595 : model1 loss : 0.439116 model2 loss : 0.020288
[00:18:13.480] iteration 15596 : model1 loss : 0.437218 model2 loss : 0.019410
[00:18:13.660] iteration 15597 : model1 loss : 0.437683 model2 loss : 0.021898
[00:18:13.831] iteration 15598 : model1 loss : 0.436528 model2 loss : 0.020030
[00:18:14.010] iteration 15599 : model1 loss : 0.442018 model2 loss : 0.023404
[00:18:14.182] iteration 15600 : model1 loss : 0.439565 model2 loss : 0.021662
[00:18:14.364] iteration 15601 : model1 loss : 0.435764 model2 loss : 0.018884
[00:18:14.536] iteration 15602 : model1 loss : 0.437780 model2 loss : 0.019155
[00:18:14.709] iteration 15603 : model1 loss : 0.437803 model2 loss : 0.020707
[00:18:16.862] iteration 15604 : model1 loss : 0.434381 model2 loss : 0.020574
[00:18:17.038] iteration 15605 : model1 loss : 0.437903 model2 loss : 0.019901
[00:18:17.217] iteration 15606 : model1 loss : 0.435285 model2 loss : 0.019256
[00:18:17.392] iteration 15607 : model1 loss : 0.438444 model2 loss : 0.019783
[00:18:17.571] iteration 15608 : model1 loss : 0.438467 model2 loss : 0.021069
[00:18:17.743] iteration 15609 : model1 loss : 0.435739 model2 loss : 0.022299
[00:18:17.921] iteration 15610 : model1 loss : 0.441388 model2 loss : 0.023606
[00:18:18.093] iteration 15611 : model1 loss : 0.435626 model2 loss : 0.021415
[00:18:18.273] iteration 15612 : model1 loss : 0.441631 model2 loss : 0.020504
[00:18:18.447] iteration 15613 : model1 loss : 0.435961 model2 loss : 0.019870
[00:18:18.627] iteration 15614 : model1 loss : 0.438590 model2 loss : 0.021352
[00:18:18.799] iteration 15615 : model1 loss : 0.432415 model2 loss : 0.019501
[00:18:18.977] iteration 15616 : model1 loss : 0.436946 model2 loss : 0.021941
[00:18:19.148] iteration 15617 : model1 loss : 0.440231 model2 loss : 0.019501
[00:18:19.336] iteration 15618 : model1 loss : 0.435745 model2 loss : 0.019090
[00:18:19.510] iteration 15619 : model1 loss : 0.432294 model2 loss : 0.021514
[00:18:19.688] iteration 15620 : model1 loss : 0.439890 model2 loss : 0.022818
[00:18:19.860] iteration 15621 : model1 loss : 0.437678 model2 loss : 0.020981
[00:18:20.038] iteration 15622 : model1 loss : 0.441783 model2 loss : 0.020405
[00:18:20.207] iteration 15623 : model1 loss : 0.436426 model2 loss : 0.020746
[00:18:20.386] iteration 15624 : model1 loss : 0.434987 model2 loss : 0.022255
[00:18:22.608] iteration 15625 : model1 loss : 0.431149 model2 loss : 0.019082
[00:18:22.780] iteration 15626 : model1 loss : 0.437608 model2 loss : 0.019018
[00:18:22.961] iteration 15627 : model1 loss : 0.433950 model2 loss : 0.020049
[00:18:23.133] iteration 15628 : model1 loss : 0.441215 model2 loss : 0.024593
[00:18:23.311] iteration 15629 : model1 loss : 0.437425 model2 loss : 0.019642
[00:18:23.484] iteration 15630 : model1 loss : 0.435964 model2 loss : 0.019128
[00:18:23.663] iteration 15631 : model1 loss : 0.437802 model2 loss : 0.021244
[00:18:23.835] iteration 15632 : model1 loss : 0.442210 model2 loss : 0.019480
[00:18:24.014] iteration 15633 : model1 loss : 0.435433 model2 loss : 0.018341
[00:18:24.186] iteration 15634 : model1 loss : 0.437445 model2 loss : 0.021145
[00:18:24.369] iteration 15635 : model1 loss : 0.437178 model2 loss : 0.022498
[00:18:24.542] iteration 15636 : model1 loss : 0.435943 model2 loss : 0.018758
[00:18:24.719] iteration 15637 : model1 loss : 0.440352 model2 loss : 0.021642
[00:18:24.890] iteration 15638 : model1 loss : 0.438776 model2 loss : 0.020716
[00:18:25.067] iteration 15639 : model1 loss : 0.435628 model2 loss : 0.020017
[00:18:25.239] iteration 15640 : model1 loss : 0.434708 model2 loss : 0.018541
[00:18:25.418] iteration 15641 : model1 loss : 0.437973 model2 loss : 0.020537
[00:18:25.593] iteration 15642 : model1 loss : 0.433917 model2 loss : 0.020966
[00:18:25.776] iteration 15643 : model1 loss : 0.438342 model2 loss : 0.020880
[00:18:25.946] iteration 15644 : model1 loss : 0.436705 model2 loss : 0.022054
[00:18:26.126] iteration 15645 : model1 loss : 0.439311 model2 loss : 0.025765
[00:18:28.277] iteration 15646 : model1 loss : 0.434720 model2 loss : 0.020525
[00:18:28.453] iteration 15647 : model1 loss : 0.437367 model2 loss : 0.018629
[00:18:28.631] iteration 15648 : model1 loss : 0.433714 model2 loss : 0.020638
[00:18:28.802] iteration 15649 : model1 loss : 0.439488 model2 loss : 0.020669
[00:18:28.981] iteration 15650 : model1 loss : 0.436112 model2 loss : 0.022099
[00:18:29.152] iteration 15651 : model1 loss : 0.437178 model2 loss : 0.019070
[00:18:29.333] iteration 15652 : model1 loss : 0.439767 model2 loss : 0.020816
[00:18:29.505] iteration 15653 : model1 loss : 0.436419 model2 loss : 0.021470
[00:18:29.684] iteration 15654 : model1 loss : 0.439868 model2 loss : 0.022649
[00:18:29.859] iteration 15655 : model1 loss : 0.438291 model2 loss : 0.019377
[00:18:30.038] iteration 15656 : model1 loss : 0.437173 model2 loss : 0.020768
[00:18:30.209] iteration 15657 : model1 loss : 0.437469 model2 loss : 0.021903
[00:18:30.390] iteration 15658 : model1 loss : 0.436872 model2 loss : 0.019800
[00:18:30.563] iteration 15659 : model1 loss : 0.438947 model2 loss : 0.020813
[00:18:30.746] iteration 15660 : model1 loss : 0.433486 model2 loss : 0.017457
[00:18:30.917] iteration 15661 : model1 loss : 0.435183 model2 loss : 0.018873
[00:18:31.096] iteration 15662 : model1 loss : 0.432437 model2 loss : 0.018184
[00:18:31.268] iteration 15663 : model1 loss : 0.438087 model2 loss : 0.017040
[00:18:31.445] iteration 15664 : model1 loss : 0.435862 model2 loss : 0.017871
[00:18:31.617] iteration 15665 : model1 loss : 0.441729 model2 loss : 0.025128
[00:18:31.794] iteration 15666 : model1 loss : 0.438036 model2 loss : 0.022252
[00:18:33.919] iteration 15667 : model1 loss : 0.437331 model2 loss : 0.020800
[00:18:34.093] iteration 15668 : model1 loss : 0.436232 model2 loss : 0.019190
[00:18:34.276] iteration 15669 : model1 loss : 0.435372 model2 loss : 0.019484
[00:18:34.447] iteration 15670 : model1 loss : 0.433626 model2 loss : 0.020164
[00:18:34.629] iteration 15671 : model1 loss : 0.434867 model2 loss : 0.018434
[00:18:34.802] iteration 15672 : model1 loss : 0.440567 model2 loss : 0.025255
[00:18:34.981] iteration 15673 : model1 loss : 0.435994 model2 loss : 0.021167
[00:18:35.151] iteration 15674 : model1 loss : 0.436222 model2 loss : 0.017952
[00:18:35.333] iteration 15675 : model1 loss : 0.441108 model2 loss : 0.020895
[00:18:35.507] iteration 15676 : model1 loss : 0.440490 model2 loss : 0.022046
[00:18:35.684] iteration 15677 : model1 loss : 0.439600 model2 loss : 0.021013
[00:18:35.856] iteration 15678 : model1 loss : 0.432051 model2 loss : 0.019925
[00:18:36.035] iteration 15679 : model1 loss : 0.437459 model2 loss : 0.019490
[00:18:36.206] iteration 15680 : model1 loss : 0.436429 model2 loss : 0.017856
[00:18:36.386] iteration 15681 : model1 loss : 0.441115 model2 loss : 0.022229
[00:18:36.560] iteration 15682 : model1 loss : 0.437139 model2 loss : 0.019295
[00:18:36.737] iteration 15683 : model1 loss : 0.436099 model2 loss : 0.018527
[00:18:36.908] iteration 15684 : model1 loss : 0.440042 model2 loss : 0.021753
[00:18:37.087] iteration 15685 : model1 loss : 0.437681 model2 loss : 0.019753
[00:18:37.257] iteration 15686 : model1 loss : 0.436476 model2 loss : 0.020549
[00:18:37.436] iteration 15687 : model1 loss : 0.438033 model2 loss : 0.021873
[00:18:39.551] iteration 15688 : model1 loss : 0.438030 model2 loss : 0.018850
[00:18:39.725] iteration 15689 : model1 loss : 0.441163 model2 loss : 0.020057
[00:18:39.906] iteration 15690 : model1 loss : 0.436306 model2 loss : 0.017446
[00:18:40.077] iteration 15691 : model1 loss : 0.436485 model2 loss : 0.021081
[00:18:40.255] iteration 15692 : model1 loss : 0.442957 model2 loss : 0.023052
[00:18:40.427] iteration 15693 : model1 loss : 0.437437 model2 loss : 0.018812
[00:18:40.607] iteration 15694 : model1 loss : 0.434417 model2 loss : 0.018521
[00:18:40.776] iteration 15695 : model1 loss : 0.435636 model2 loss : 0.020063
[00:18:40.954] iteration 15696 : model1 loss : 0.442316 model2 loss : 0.026188
[00:18:41.124] iteration 15697 : model1 loss : 0.434810 model2 loss : 0.021063
[00:18:41.298] iteration 15698 : model1 loss : 0.434564 model2 loss : 0.020574
[00:18:41.471] iteration 15699 : model1 loss : 0.435698 model2 loss : 0.018235
[00:18:41.651] iteration 15700 : model1 loss : 0.444739 model2 loss : 0.024046
[00:18:41.822] iteration 15701 : model1 loss : 0.438985 model2 loss : 0.019680
[00:18:41.996] iteration 15702 : model1 loss : 0.436051 model2 loss : 0.019961
[00:18:42.171] iteration 15703 : model1 loss : 0.431220 model2 loss : 0.021235
[00:18:42.349] iteration 15704 : model1 loss : 0.438298 model2 loss : 0.022245
[00:18:42.523] iteration 15705 : model1 loss : 0.438010 model2 loss : 0.020454
[00:18:42.703] iteration 15706 : model1 loss : 0.437874 model2 loss : 0.020061
[00:18:42.874] iteration 15707 : model1 loss : 0.432508 model2 loss : 0.017600
[00:18:43.048] iteration 15708 : model1 loss : 0.434982 model2 loss : 0.019952
[00:18:45.179] iteration 15709 : model1 loss : 0.438850 model2 loss : 0.021857
[00:18:45.356] iteration 15710 : model1 loss : 0.436877 model2 loss : 0.020408
[00:18:45.537] iteration 15711 : model1 loss : 0.438181 model2 loss : 0.019424
[00:18:45.709] iteration 15712 : model1 loss : 0.434731 model2 loss : 0.019645
[00:18:45.886] iteration 15713 : model1 loss : 0.432184 model2 loss : 0.018823
[00:18:46.057] iteration 15714 : model1 loss : 0.430971 model2 loss : 0.018574
[00:18:46.233] iteration 15715 : model1 loss : 0.432878 model2 loss : 0.019283
[00:18:46.406] iteration 15716 : model1 loss : 0.440792 model2 loss : 0.021081
[00:18:46.586] iteration 15717 : model1 loss : 0.436064 model2 loss : 0.017407
[00:18:46.756] iteration 15718 : model1 loss : 0.435091 model2 loss : 0.021085
[00:18:46.931] iteration 15719 : model1 loss : 0.440322 model2 loss : 0.023177
[00:18:47.103] iteration 15720 : model1 loss : 0.436509 model2 loss : 0.019227
[00:18:47.279] iteration 15721 : model1 loss : 0.439403 model2 loss : 0.022494
[00:18:47.455] iteration 15722 : model1 loss : 0.437796 model2 loss : 0.019145
[00:18:47.633] iteration 15723 : model1 loss : 0.434855 model2 loss : 0.019692
[00:18:47.804] iteration 15724 : model1 loss : 0.447194 model2 loss : 0.025744
[00:18:47.982] iteration 15725 : model1 loss : 0.437003 model2 loss : 0.020395
[00:18:48.155] iteration 15726 : model1 loss : 0.439904 model2 loss : 0.019419
[00:18:48.336] iteration 15727 : model1 loss : 0.432676 model2 loss : 0.019199
[00:18:48.505] iteration 15728 : model1 loss : 0.442075 model2 loss : 0.022882
[00:18:48.680] iteration 15729 : model1 loss : 0.434055 model2 loss : 0.018365
[00:18:50.810] iteration 15730 : model1 loss : 0.438734 model2 loss : 0.021714
[00:18:50.984] iteration 15731 : model1 loss : 0.437475 model2 loss : 0.020461
[00:18:51.167] iteration 15732 : model1 loss : 0.438250 model2 loss : 0.019965
[00:18:51.341] iteration 15733 : model1 loss : 0.439874 model2 loss : 0.019835
[00:18:51.518] iteration 15734 : model1 loss : 0.437244 model2 loss : 0.018978
[00:18:51.691] iteration 15735 : model1 loss : 0.436040 model2 loss : 0.020620
[00:18:51.866] iteration 15736 : model1 loss : 0.437624 model2 loss : 0.021388
[00:18:52.038] iteration 15737 : model1 loss : 0.437308 model2 loss : 0.019920
[00:18:52.214] iteration 15738 : model1 loss : 0.437788 model2 loss : 0.020133
[00:18:52.386] iteration 15739 : model1 loss : 0.436421 model2 loss : 0.020729
[00:18:52.566] iteration 15740 : model1 loss : 0.441308 model2 loss : 0.023321
[00:18:52.736] iteration 15741 : model1 loss : 0.437065 model2 loss : 0.021241
[00:18:52.912] iteration 15742 : model1 loss : 0.436970 model2 loss : 0.020691
[00:18:53.082] iteration 15743 : model1 loss : 0.437045 model2 loss : 0.021497
[00:18:53.257] iteration 15744 : model1 loss : 0.436476 model2 loss : 0.020654
[00:18:53.429] iteration 15745 : model1 loss : 0.435623 model2 loss : 0.017594
[00:18:53.610] iteration 15746 : model1 loss : 0.436937 model2 loss : 0.020057
[00:18:53.782] iteration 15747 : model1 loss : 0.437210 model2 loss : 0.021482
[00:18:53.956] iteration 15748 : model1 loss : 0.431080 model2 loss : 0.018037
[00:18:54.127] iteration 15749 : model1 loss : 0.436716 model2 loss : 0.019474
[00:18:54.302] iteration 15750 : model1 loss : 0.434241 model2 loss : 0.019552
[00:18:56.452] iteration 15751 : model1 loss : 0.438760 model2 loss : 0.022163
[00:18:56.627] iteration 15752 : model1 loss : 0.437220 model2 loss : 0.019402
[00:18:56.808] iteration 15753 : model1 loss : 0.436582 model2 loss : 0.023813
[00:18:56.978] iteration 15754 : model1 loss : 0.441196 model2 loss : 0.021633
[00:18:57.155] iteration 15755 : model1 loss : 0.440785 model2 loss : 0.023082
[00:18:57.329] iteration 15756 : model1 loss : 0.440207 model2 loss : 0.023326
[00:18:57.507] iteration 15757 : model1 loss : 0.439206 model2 loss : 0.020090
[00:18:57.678] iteration 15758 : model1 loss : 0.434776 model2 loss : 0.019155
[00:18:57.852] iteration 15759 : model1 loss : 0.437416 model2 loss : 0.021768
[00:18:58.023] iteration 15760 : model1 loss : 0.435559 model2 loss : 0.020021
[00:18:58.197] iteration 15761 : model1 loss : 0.437480 model2 loss : 0.021642
[00:18:58.369] iteration 15762 : model1 loss : 0.435926 model2 loss : 0.019346
[00:18:58.543] iteration 15763 : model1 loss : 0.434769 model2 loss : 0.018057
[00:18:58.714] iteration 15764 : model1 loss : 0.437519 model2 loss : 0.019706
[00:18:58.889] iteration 15765 : model1 loss : 0.436195 model2 loss : 0.021773
[00:18:59.058] iteration 15766 : model1 loss : 0.436345 model2 loss : 0.022491
[00:18:59.235] iteration 15767 : model1 loss : 0.431657 model2 loss : 0.018763
[00:18:59.408] iteration 15768 : model1 loss : 0.438490 model2 loss : 0.022049
[00:18:59.586] iteration 15769 : model1 loss : 0.438881 model2 loss : 0.019530
[00:18:59.755] iteration 15770 : model1 loss : 0.435048 model2 loss : 0.018959
[00:18:59.929] iteration 15771 : model1 loss : 0.437433 model2 loss : 0.020780
[00:19:02.091] iteration 15772 : model1 loss : 0.434441 model2 loss : 0.019622
[00:19:02.270] iteration 15773 : model1 loss : 0.434705 model2 loss : 0.020664
[00:19:02.453] iteration 15774 : model1 loss : 0.438202 model2 loss : 0.022318
[00:19:02.626] iteration 15775 : model1 loss : 0.433980 model2 loss : 0.020139
[00:19:02.800] iteration 15776 : model1 loss : 0.438961 model2 loss : 0.021078
[00:19:02.973] iteration 15777 : model1 loss : 0.437386 model2 loss : 0.020149
[00:19:03.150] iteration 15778 : model1 loss : 0.437344 model2 loss : 0.022099
[00:19:03.324] iteration 15779 : model1 loss : 0.440360 model2 loss : 0.021847
[00:19:03.501] iteration 15780 : model1 loss : 0.432326 model2 loss : 0.019371
[00:19:03.673] iteration 15781 : model1 loss : 0.438549 model2 loss : 0.019902
[00:19:03.847] iteration 15782 : model1 loss : 0.438177 model2 loss : 0.019875
[00:19:04.017] iteration 15783 : model1 loss : 0.441751 model2 loss : 0.019312
[00:19:04.192] iteration 15784 : model1 loss : 0.434176 model2 loss : 0.018366
[00:19:04.364] iteration 15785 : model1 loss : 0.435838 model2 loss : 0.019158
[00:19:04.541] iteration 15786 : model1 loss : 0.439227 model2 loss : 0.020407
[00:19:04.713] iteration 15787 : model1 loss : 0.435763 model2 loss : 0.019279
[00:19:04.888] iteration 15788 : model1 loss : 0.438342 model2 loss : 0.020856
[00:19:05.060] iteration 15789 : model1 loss : 0.435838 model2 loss : 0.017886
[00:19:05.233] iteration 15790 : model1 loss : 0.438399 model2 loss : 0.020536
[00:19:05.403] iteration 15791 : model1 loss : 0.440030 model2 loss : 0.024173
[00:19:05.578] iteration 15792 : model1 loss : 0.435738 model2 loss : 0.018888
[00:19:07.725] iteration 15793 : model1 loss : 0.434326 model2 loss : 0.017918
[00:19:07.900] iteration 15794 : model1 loss : 0.436521 model2 loss : 0.020157
[00:19:08.079] iteration 15795 : model1 loss : 0.438322 model2 loss : 0.019952
[00:19:08.250] iteration 15796 : model1 loss : 0.436973 model2 loss : 0.019116
[00:19:08.431] iteration 15797 : model1 loss : 0.438227 model2 loss : 0.018682
[00:19:08.607] iteration 15798 : model1 loss : 0.436699 model2 loss : 0.019246
[00:19:08.783] iteration 15799 : model1 loss : 0.441825 model2 loss : 0.024582
[00:19:08.953] iteration 15800 : model1 loss : 0.432964 model2 loss : 0.019953
[00:19:09.128] iteration 15801 : model1 loss : 0.435983 model2 loss : 0.018228
[00:19:09.300] iteration 15802 : model1 loss : 0.439178 model2 loss : 0.019776
[00:19:09.474] iteration 15803 : model1 loss : 0.433846 model2 loss : 0.019002
[00:19:09.645] iteration 15804 : model1 loss : 0.437321 model2 loss : 0.020022
[00:19:09.822] iteration 15805 : model1 loss : 0.436253 model2 loss : 0.018908
[00:19:09.994] iteration 15806 : model1 loss : 0.437496 model2 loss : 0.020700
[00:19:10.170] iteration 15807 : model1 loss : 0.440120 model2 loss : 0.020790
[00:19:10.345] iteration 15808 : model1 loss : 0.438511 model2 loss : 0.020353
[00:19:10.523] iteration 15809 : model1 loss : 0.435724 model2 loss : 0.018734
[00:19:10.693] iteration 15810 : model1 loss : 0.432972 model2 loss : 0.019575
[00:19:10.873] iteration 15811 : model1 loss : 0.436600 model2 loss : 0.019052
[00:19:11.042] iteration 15812 : model1 loss : 0.436721 model2 loss : 0.020397
[00:19:11.216] iteration 15813 : model1 loss : 0.439986 model2 loss : 0.019823
[00:19:13.367] iteration 15814 : model1 loss : 0.436999 model2 loss : 0.019479
[00:19:13.539] iteration 15815 : model1 loss : 0.437712 model2 loss : 0.019458
[00:19:13.717] iteration 15816 : model1 loss : 0.436884 model2 loss : 0.021478
[00:19:13.889] iteration 15817 : model1 loss : 0.434453 model2 loss : 0.019085
[00:19:14.067] iteration 15818 : model1 loss : 0.436663 model2 loss : 0.018297
[00:19:14.237] iteration 15819 : model1 loss : 0.435354 model2 loss : 0.018585
[00:19:14.416] iteration 15820 : model1 loss : 0.441417 model2 loss : 0.019812
[00:19:14.590] iteration 15821 : model1 loss : 0.435438 model2 loss : 0.017493
[00:19:14.765] iteration 15822 : model1 loss : 0.437446 model2 loss : 0.021309
[00:19:14.937] iteration 15823 : model1 loss : 0.439056 model2 loss : 0.023059
[00:19:15.113] iteration 15824 : model1 loss : 0.435720 model2 loss : 0.019538
[00:19:15.284] iteration 15825 : model1 loss : 0.441479 model2 loss : 0.019327
[00:19:15.459] iteration 15826 : model1 loss : 0.434891 model2 loss : 0.020526
[00:19:15.633] iteration 15827 : model1 loss : 0.436903 model2 loss : 0.020244
[00:19:15.809] iteration 15828 : model1 loss : 0.436624 model2 loss : 0.019151
[00:19:15.981] iteration 15829 : model1 loss : 0.441731 model2 loss : 0.020729
[00:19:16.159] iteration 15830 : model1 loss : 0.432690 model2 loss : 0.022783
[00:19:16.332] iteration 15831 : model1 loss : 0.436890 model2 loss : 0.018848
[00:19:16.509] iteration 15832 : model1 loss : 0.436514 model2 loss : 0.020957
[00:19:16.678] iteration 15833 : model1 loss : 0.435709 model2 loss : 0.020123
[00:19:16.850] iteration 15834 : model1 loss : 0.436272 model2 loss : 0.021171
[00:19:18.982] iteration 15835 : model1 loss : 0.438955 model2 loss : 0.018742
[00:19:19.156] iteration 15836 : model1 loss : 0.439670 model2 loss : 0.017857
[00:19:19.342] iteration 15837 : model1 loss : 0.441756 model2 loss : 0.019332
[00:19:19.516] iteration 15838 : model1 loss : 0.433624 model2 loss : 0.019641
[00:19:19.693] iteration 15839 : model1 loss : 0.436876 model2 loss : 0.019665
[00:19:19.865] iteration 15840 : model1 loss : 0.434217 model2 loss : 0.017717
[00:19:20.040] iteration 15841 : model1 loss : 0.435973 model2 loss : 0.020345
[00:19:20.212] iteration 15842 : model1 loss : 0.437253 model2 loss : 0.020980
[00:19:20.392] iteration 15843 : model1 loss : 0.443086 model2 loss : 0.022586
[00:19:20.564] iteration 15844 : model1 loss : 0.437462 model2 loss : 0.020619
[00:19:20.740] iteration 15845 : model1 loss : 0.435887 model2 loss : 0.018042
[00:19:20.913] iteration 15846 : model1 loss : 0.435346 model2 loss : 0.021740
[00:19:21.091] iteration 15847 : model1 loss : 0.435945 model2 loss : 0.019662
[00:19:21.262] iteration 15848 : model1 loss : 0.432454 model2 loss : 0.018867
[00:19:21.439] iteration 15849 : model1 loss : 0.434638 model2 loss : 0.019100
[00:19:21.614] iteration 15850 : model1 loss : 0.441156 model2 loss : 0.020804
[00:19:21.789] iteration 15851 : model1 loss : 0.439350 model2 loss : 0.020920
[00:19:21.962] iteration 15852 : model1 loss : 0.441191 model2 loss : 0.020798
[00:19:22.138] iteration 15853 : model1 loss : 0.437561 model2 loss : 0.020058
[00:19:22.310] iteration 15854 : model1 loss : 0.436216 model2 loss : 0.020786
[00:19:22.490] iteration 15855 : model1 loss : 0.430894 model2 loss : 0.018255
[00:19:24.621] iteration 15856 : model1 loss : 0.431957 model2 loss : 0.019467
[00:19:24.797] iteration 15857 : model1 loss : 0.440352 model2 loss : 0.019481
[00:19:24.979] iteration 15858 : model1 loss : 0.436817 model2 loss : 0.020850
[00:19:25.151] iteration 15859 : model1 loss : 0.438202 model2 loss : 0.020084
[00:19:25.329] iteration 15860 : model1 loss : 0.441304 model2 loss : 0.021119
[00:19:25.502] iteration 15861 : model1 loss : 0.438366 model2 loss : 0.021035
[00:19:25.677] iteration 15862 : model1 loss : 0.435962 model2 loss : 0.020053
[00:19:25.848] iteration 15863 : model1 loss : 0.436505 model2 loss : 0.020284
[00:19:26.024] iteration 15864 : model1 loss : 0.437456 model2 loss : 0.019008
[00:19:26.195] iteration 15865 : model1 loss : 0.440569 model2 loss : 0.021792
[00:19:26.374] iteration 15866 : model1 loss : 0.436705 model2 loss : 0.020560
[00:19:26.547] iteration 15867 : model1 loss : 0.438125 model2 loss : 0.018861
[00:19:26.723] iteration 15868 : model1 loss : 0.439705 model2 loss : 0.020973
[00:19:26.895] iteration 15869 : model1 loss : 0.433914 model2 loss : 0.021441
[00:19:27.070] iteration 15870 : model1 loss : 0.435158 model2 loss : 0.019229
[00:19:27.241] iteration 15871 : model1 loss : 0.432329 model2 loss : 0.019803
[00:19:27.419] iteration 15872 : model1 loss : 0.435186 model2 loss : 0.018182
[00:19:27.592] iteration 15873 : model1 loss : 0.438393 model2 loss : 0.018366
[00:19:27.767] iteration 15874 : model1 loss : 0.438471 model2 loss : 0.020797
[00:19:27.936] iteration 15875 : model1 loss : 0.436848 model2 loss : 0.021353
[00:19:28.109] iteration 15876 : model1 loss : 0.441018 model2 loss : 0.020442
[00:19:30.222] iteration 15877 : model1 loss : 0.436427 model2 loss : 0.019957
[00:19:30.402] iteration 15878 : model1 loss : 0.436793 model2 loss : 0.021694
[00:19:30.581] iteration 15879 : model1 loss : 0.436806 model2 loss : 0.021911
[00:19:30.753] iteration 15880 : model1 loss : 0.438779 model2 loss : 0.022230
[00:19:30.927] iteration 15881 : model1 loss : 0.440532 model2 loss : 0.023261
[00:19:31.100] iteration 15882 : model1 loss : 0.437000 model2 loss : 0.019590
[00:19:31.274] iteration 15883 : model1 loss : 0.437193 model2 loss : 0.018597
[00:19:31.450] iteration 15884 : model1 loss : 0.437283 model2 loss : 0.020552
[00:19:31.630] iteration 15885 : model1 loss : 0.436117 model2 loss : 0.019596
[00:19:31.801] iteration 15886 : model1 loss : 0.438496 model2 loss : 0.019468
[00:19:31.974] iteration 15887 : model1 loss : 0.439890 model2 loss : 0.021370
[00:19:32.143] iteration 15888 : model1 loss : 0.434179 model2 loss : 0.018894
[00:19:32.321] iteration 15889 : model1 loss : 0.435257 model2 loss : 0.017696
[00:19:32.496] iteration 15890 : model1 loss : 0.437331 model2 loss : 0.019910
[00:19:32.676] iteration 15891 : model1 loss : 0.437139 model2 loss : 0.023985
[00:19:32.846] iteration 15892 : model1 loss : 0.433832 model2 loss : 0.020640
[00:19:33.023] iteration 15893 : model1 loss : 0.437156 model2 loss : 0.022815
[00:19:33.193] iteration 15894 : model1 loss : 0.437459 model2 loss : 0.021535
[00:19:33.368] iteration 15895 : model1 loss : 0.436129 model2 loss : 0.018678
[00:19:33.538] iteration 15896 : model1 loss : 0.436637 model2 loss : 0.020755
[00:19:33.716] iteration 15897 : model1 loss : 0.441166 model2 loss : 0.018340
[00:19:35.842] iteration 15898 : model1 loss : 0.439153 model2 loss : 0.022265
[00:19:36.017] iteration 15899 : model1 loss : 0.437382 model2 loss : 0.020934
[00:19:36.197] iteration 15900 : model1 loss : 0.439041 model2 loss : 0.020044
[00:19:36.371] iteration 15901 : model1 loss : 0.437328 model2 loss : 0.024246
[00:19:36.548] iteration 15902 : model1 loss : 0.437474 model2 loss : 0.020290
[00:19:36.719] iteration 15903 : model1 loss : 0.432043 model2 loss : 0.020550
[00:19:36.895] iteration 15904 : model1 loss : 0.432971 model2 loss : 0.021374
[00:19:37.067] iteration 15905 : model1 loss : 0.435122 model2 loss : 0.018058
[00:19:37.257] iteration 15906 : model1 loss : 0.439978 model2 loss : 0.020369
[00:19:37.434] iteration 15907 : model1 loss : 0.440058 model2 loss : 0.020366
[00:19:37.611] iteration 15908 : model1 loss : 0.433905 model2 loss : 0.018700
[00:19:37.782] iteration 15909 : model1 loss : 0.437112 model2 loss : 0.021231
[00:19:37.958] iteration 15910 : model1 loss : 0.441474 model2 loss : 0.021113
[00:19:38.132] iteration 15911 : model1 loss : 0.438319 model2 loss : 0.018868
[00:19:38.308] iteration 15912 : model1 loss : 0.438936 model2 loss : 0.021801
[00:19:38.482] iteration 15913 : model1 loss : 0.438694 model2 loss : 0.017249
[00:19:38.659] iteration 15914 : model1 loss : 0.439806 model2 loss : 0.019462
[00:19:38.833] iteration 15915 : model1 loss : 0.436472 model2 loss : 0.019552
[00:19:39.008] iteration 15916 : model1 loss : 0.434609 model2 loss : 0.020518
[00:19:39.176] iteration 15917 : model1 loss : 0.441182 model2 loss : 0.018434
[00:19:39.355] iteration 15918 : model1 loss : 0.433326 model2 loss : 0.018633
[00:19:41.489] iteration 15919 : model1 loss : 0.436997 model2 loss : 0.019193
[00:19:41.662] iteration 15920 : model1 loss : 0.434792 model2 loss : 0.018806
[00:19:41.839] iteration 15921 : model1 loss : 0.434492 model2 loss : 0.020885
[00:19:42.012] iteration 15922 : model1 loss : 0.439511 model2 loss : 0.021066
[00:19:42.187] iteration 15923 : model1 loss : 0.437599 model2 loss : 0.022872
[00:19:42.362] iteration 15924 : model1 loss : 0.436844 model2 loss : 0.019623
[00:19:42.539] iteration 15925 : model1 loss : 0.435147 model2 loss : 0.017785
[00:19:42.720] iteration 15926 : model1 loss : 0.436378 model2 loss : 0.019950
[00:19:42.898] iteration 15927 : model1 loss : 0.437860 model2 loss : 0.018917
[00:19:43.068] iteration 15928 : model1 loss : 0.439864 model2 loss : 0.022948
[00:19:43.242] iteration 15929 : model1 loss : 0.438064 model2 loss : 0.019772
[00:19:43.414] iteration 15930 : model1 loss : 0.436831 model2 loss : 0.019497
[00:19:43.590] iteration 15931 : model1 loss : 0.436468 model2 loss : 0.020275
[00:19:43.764] iteration 15932 : model1 loss : 0.437738 model2 loss : 0.018842
[00:19:43.939] iteration 15933 : model1 loss : 0.438201 model2 loss : 0.020373
[00:19:44.112] iteration 15934 : model1 loss : 0.435688 model2 loss : 0.018349
[00:19:44.290] iteration 15935 : model1 loss : 0.437426 model2 loss : 0.017610
[00:19:44.466] iteration 15936 : model1 loss : 0.438558 model2 loss : 0.019523
[00:19:44.645] iteration 15937 : model1 loss : 0.439137 model2 loss : 0.022732
[00:19:44.818] iteration 15938 : model1 loss : 0.434915 model2 loss : 0.019760
[00:19:44.996] iteration 15939 : model1 loss : 0.435805 model2 loss : 0.022529
[00:19:47.124] iteration 15940 : model1 loss : 0.433993 model2 loss : 0.020064
[00:19:47.298] iteration 15941 : model1 loss : 0.435856 model2 loss : 0.019743
[00:19:47.483] iteration 15942 : model1 loss : 0.434081 model2 loss : 0.018824
[00:19:47.655] iteration 15943 : model1 loss : 0.433091 model2 loss : 0.017496
[00:19:47.833] iteration 15944 : model1 loss : 0.437314 model2 loss : 0.019792
[00:19:48.004] iteration 15945 : model1 loss : 0.440501 model2 loss : 0.021702
[00:19:48.178] iteration 15946 : model1 loss : 0.432744 model2 loss : 0.017828
[00:19:48.349] iteration 15947 : model1 loss : 0.439026 model2 loss : 0.020181
[00:19:48.526] iteration 15948 : model1 loss : 0.437094 model2 loss : 0.019239
[00:19:48.697] iteration 15949 : model1 loss : 0.438917 model2 loss : 0.019687
[00:19:48.870] iteration 15950 : model1 loss : 0.432656 model2 loss : 0.018441
[00:19:49.041] iteration 15951 : model1 loss : 0.436116 model2 loss : 0.021172
[00:19:49.216] iteration 15952 : model1 loss : 0.438073 model2 loss : 0.020283
[00:19:49.388] iteration 15953 : model1 loss : 0.437201 model2 loss : 0.020566
[00:19:49.566] iteration 15954 : model1 loss : 0.439773 model2 loss : 0.019198
[00:19:49.737] iteration 15955 : model1 loss : 0.438844 model2 loss : 0.020456
[00:19:49.911] iteration 15956 : model1 loss : 0.440261 model2 loss : 0.022346
[00:19:50.082] iteration 15957 : model1 loss : 0.440619 model2 loss : 0.018837
[00:19:50.261] iteration 15958 : model1 loss : 0.435327 model2 loss : 0.020389
[00:19:50.434] iteration 15959 : model1 loss : 0.440408 model2 loss : 0.020609
[00:19:50.612] iteration 15960 : model1 loss : 0.436666 model2 loss : 0.020609
[00:19:52.764] iteration 15961 : model1 loss : 0.435966 model2 loss : 0.019218
[00:19:52.942] iteration 15962 : model1 loss : 0.437379 model2 loss : 0.021038
[00:19:53.121] iteration 15963 : model1 loss : 0.437561 model2 loss : 0.021539
[00:19:53.294] iteration 15964 : model1 loss : 0.433874 model2 loss : 0.020587
[00:19:53.470] iteration 15965 : model1 loss : 0.439012 model2 loss : 0.018020
[00:19:53.641] iteration 15966 : model1 loss : 0.434230 model2 loss : 0.017966
[00:19:53.815] iteration 15967 : model1 loss : 0.438855 model2 loss : 0.019528
[00:19:53.984] iteration 15968 : model1 loss : 0.437734 model2 loss : 0.018713
[00:19:54.159] iteration 15969 : model1 loss : 0.438637 model2 loss : 0.019424
[00:19:54.332] iteration 15970 : model1 loss : 0.436097 model2 loss : 0.021776
[00:19:54.512] iteration 15971 : model1 loss : 0.437957 model2 loss : 0.019728
[00:19:54.686] iteration 15972 : model1 loss : 0.435035 model2 loss : 0.018887
[00:19:54.865] iteration 15973 : model1 loss : 0.440795 model2 loss : 0.021668
[00:19:55.035] iteration 15974 : model1 loss : 0.439862 model2 loss : 0.019790
[00:19:55.211] iteration 15975 : model1 loss : 0.436172 model2 loss : 0.020815
[00:19:55.382] iteration 15976 : model1 loss : 0.437264 model2 loss : 0.021594
[00:19:55.558] iteration 15977 : model1 loss : 0.440814 model2 loss : 0.021875
[00:19:55.731] iteration 15978 : model1 loss : 0.434059 model2 loss : 0.018582
[00:19:55.907] iteration 15979 : model1 loss : 0.436689 model2 loss : 0.018600
[00:19:56.076] iteration 15980 : model1 loss : 0.439037 model2 loss : 0.019483
[00:19:56.250] iteration 15981 : model1 loss : 0.433679 model2 loss : 0.020506
[00:19:58.431] iteration 15982 : model1 loss : 0.438664 model2 loss : 0.024197
[00:19:58.606] iteration 15983 : model1 loss : 0.437075 model2 loss : 0.017737
[00:19:58.785] iteration 15984 : model1 loss : 0.434833 model2 loss : 0.019640
[00:19:58.956] iteration 15985 : model1 loss : 0.435953 model2 loss : 0.016082
[00:19:59.135] iteration 15986 : model1 loss : 0.435696 model2 loss : 0.020209
[00:19:59.308] iteration 15987 : model1 loss : 0.438069 model2 loss : 0.022563
[00:19:59.487] iteration 15988 : model1 loss : 0.436360 model2 loss : 0.020512
[00:19:59.660] iteration 15989 : model1 loss : 0.436219 model2 loss : 0.017911
[00:19:59.834] iteration 15990 : model1 loss : 0.436442 model2 loss : 0.019573
[00:20:00.006] iteration 15991 : model1 loss : 0.433757 model2 loss : 0.017882
[00:20:00.191] iteration 15992 : model1 loss : 0.436540 model2 loss : 0.021390
[00:20:00.366] iteration 15993 : model1 loss : 0.437284 model2 loss : 0.020841
[00:20:00.543] iteration 15994 : model1 loss : 0.440877 model2 loss : 0.022657
[00:20:00.714] iteration 15995 : model1 loss : 0.437292 model2 loss : 0.018915
[00:20:00.891] iteration 15996 : model1 loss : 0.441437 model2 loss : 0.022784
[00:20:01.062] iteration 15997 : model1 loss : 0.436022 model2 loss : 0.018374
[00:20:01.239] iteration 15998 : model1 loss : 0.437672 model2 loss : 0.016764
[00:20:01.413] iteration 15999 : model1 loss : 0.438735 model2 loss : 0.020630
[00:20:01.595] iteration 16000 : model1 loss : 0.437779 model2 loss : 0.021040
[00:20:10.839] iteration 16000 : model1_mean_dice : 0.859732 model1_mean_hd95 : 6.487018
[00:20:19.973] iteration 16000 : model2_mean_dice : 0.869007 model2_mean_hd95 : 7.384426
[00:20:20.152] iteration 16001 : model1 loss : 0.435844 model2 loss : 0.019287
[00:20:20.334] iteration 16002 : model1 loss : 0.440716 model2 loss : 0.020015
[00:20:22.545] iteration 16003 : model1 loss : 0.436848 model2 loss : 0.019960
[00:20:22.717] iteration 16004 : model1 loss : 0.434353 model2 loss : 0.018046
[00:20:22.895] iteration 16005 : model1 loss : 0.440233 model2 loss : 0.019527
[00:20:23.067] iteration 16006 : model1 loss : 0.434065 model2 loss : 0.021412
[00:20:23.240] iteration 16007 : model1 loss : 0.436156 model2 loss : 0.019178
[00:20:23.410] iteration 16008 : model1 loss : 0.437066 model2 loss : 0.021439
[00:20:23.590] iteration 16009 : model1 loss : 0.433789 model2 loss : 0.017415
[00:20:23.761] iteration 16010 : model1 loss : 0.440454 model2 loss : 0.019380
[00:20:23.934] iteration 16011 : model1 loss : 0.439045 model2 loss : 0.021842
[00:20:24.105] iteration 16012 : model1 loss : 0.434494 model2 loss : 0.018856
[00:20:24.282] iteration 16013 : model1 loss : 0.435725 model2 loss : 0.019325
[00:20:24.454] iteration 16014 : model1 loss : 0.439117 model2 loss : 0.018911
[00:20:24.634] iteration 16015 : model1 loss : 0.434202 model2 loss : 0.018747
[00:20:24.801] iteration 16016 : model1 loss : 0.438818 model2 loss : 0.021178
[00:20:24.977] iteration 16017 : model1 loss : 0.431749 model2 loss : 0.018654
[00:20:25.147] iteration 16018 : model1 loss : 0.441127 model2 loss : 0.021341
[00:20:25.325] iteration 16019 : model1 loss : 0.439618 model2 loss : 0.021735
[00:20:25.496] iteration 16020 : model1 loss : 0.436195 model2 loss : 0.020767
[00:20:25.670] iteration 16021 : model1 loss : 0.439853 model2 loss : 0.020380
[00:20:25.845] iteration 16022 : model1 loss : 0.439834 model2 loss : 0.020869
[00:20:26.023] iteration 16023 : model1 loss : 0.436840 model2 loss : 0.020547
[00:20:28.177] iteration 16024 : model1 loss : 0.435510 model2 loss : 0.016805
[00:20:28.350] iteration 16025 : model1 loss : 0.437387 model2 loss : 0.021267
[00:20:28.536] iteration 16026 : model1 loss : 0.436823 model2 loss : 0.020793
[00:20:28.708] iteration 16027 : model1 loss : 0.438263 model2 loss : 0.020033
[00:20:28.886] iteration 16028 : model1 loss : 0.438898 model2 loss : 0.018970
[00:20:29.054] iteration 16029 : model1 loss : 0.436578 model2 loss : 0.019577
[00:20:29.231] iteration 16030 : model1 loss : 0.437192 model2 loss : 0.020025
[00:20:29.400] iteration 16031 : model1 loss : 0.438512 model2 loss : 0.019852
[00:20:29.578] iteration 16032 : model1 loss : 0.438562 model2 loss : 0.020350
[00:20:29.747] iteration 16033 : model1 loss : 0.434889 model2 loss : 0.020100
[00:20:29.921] iteration 16034 : model1 loss : 0.435662 model2 loss : 0.021478
[00:20:30.091] iteration 16035 : model1 loss : 0.441030 model2 loss : 0.021255
[00:20:30.267] iteration 16036 : model1 loss : 0.435854 model2 loss : 0.019050
[00:20:30.438] iteration 16037 : model1 loss : 0.436171 model2 loss : 0.020196
[00:20:30.618] iteration 16038 : model1 loss : 0.435564 model2 loss : 0.018807
[00:20:30.791] iteration 16039 : model1 loss : 0.437788 model2 loss : 0.019367
[00:20:30.965] iteration 16040 : model1 loss : 0.439589 model2 loss : 0.019704
[00:20:31.137] iteration 16041 : model1 loss : 0.438184 model2 loss : 0.022846
[00:20:31.316] iteration 16042 : model1 loss : 0.439482 model2 loss : 0.023739
[00:20:31.487] iteration 16043 : model1 loss : 0.432377 model2 loss : 0.021259
[00:20:31.660] iteration 16044 : model1 loss : 0.437799 model2 loss : 0.021076
[00:20:33.782] iteration 16045 : model1 loss : 0.431429 model2 loss : 0.020293
[00:20:33.954] iteration 16046 : model1 loss : 0.434963 model2 loss : 0.021327
[00:20:34.135] iteration 16047 : model1 loss : 0.434498 model2 loss : 0.019480
[00:20:34.312] iteration 16048 : model1 loss : 0.433498 model2 loss : 0.019216
[00:20:34.490] iteration 16049 : model1 loss : 0.434966 model2 loss : 0.021076
[00:20:34.659] iteration 16050 : model1 loss : 0.438528 model2 loss : 0.021349
[00:20:34.834] iteration 16051 : model1 loss : 0.435739 model2 loss : 0.019332
[00:20:35.004] iteration 16052 : model1 loss : 0.436070 model2 loss : 0.018959
[00:20:35.182] iteration 16053 : model1 loss : 0.441186 model2 loss : 0.021466
[00:20:35.355] iteration 16054 : model1 loss : 0.438481 model2 loss : 0.019292
[00:20:35.530] iteration 16055 : model1 loss : 0.438301 model2 loss : 0.018045
[00:20:35.700] iteration 16056 : model1 loss : 0.443617 model2 loss : 0.022387
[00:20:35.878] iteration 16057 : model1 loss : 0.437407 model2 loss : 0.018892
[00:20:36.050] iteration 16058 : model1 loss : 0.440260 model2 loss : 0.020059
[00:20:36.225] iteration 16059 : model1 loss : 0.437515 model2 loss : 0.022692
[00:20:36.397] iteration 16060 : model1 loss : 0.434005 model2 loss : 0.018573
[00:20:36.574] iteration 16061 : model1 loss : 0.437631 model2 loss : 0.021839
[00:20:36.744] iteration 16062 : model1 loss : 0.440525 model2 loss : 0.021897
[00:20:36.920] iteration 16063 : model1 loss : 0.438222 model2 loss : 0.021635
[00:20:37.089] iteration 16064 : model1 loss : 0.435798 model2 loss : 0.020744
[00:20:37.264] iteration 16065 : model1 loss : 0.439575 model2 loss : 0.019744
[00:20:39.430] iteration 16066 : model1 loss : 0.438130 model2 loss : 0.020759
[00:20:39.608] iteration 16067 : model1 loss : 0.436886 model2 loss : 0.022403
[00:20:39.786] iteration 16068 : model1 loss : 0.440318 model2 loss : 0.019501
[00:20:39.960] iteration 16069 : model1 loss : 0.434089 model2 loss : 0.017940
[00:20:40.133] iteration 16070 : model1 loss : 0.440398 model2 loss : 0.020119
[00:20:40.305] iteration 16071 : model1 loss : 0.433471 model2 loss : 0.020706
[00:20:40.489] iteration 16072 : model1 loss : 0.434231 model2 loss : 0.019526
[00:20:40.658] iteration 16073 : model1 loss : 0.435932 model2 loss : 0.018074
[00:20:40.834] iteration 16074 : model1 loss : 0.439023 model2 loss : 0.020062
[00:20:41.005] iteration 16075 : model1 loss : 0.436174 model2 loss : 0.019682
[00:20:41.179] iteration 16076 : model1 loss : 0.438859 model2 loss : 0.019176
[00:20:41.352] iteration 16077 : model1 loss : 0.435987 model2 loss : 0.018761
[00:20:41.530] iteration 16078 : model1 loss : 0.431899 model2 loss : 0.018444
[00:20:41.701] iteration 16079 : model1 loss : 0.441306 model2 loss : 0.019731
[00:20:41.875] iteration 16080 : model1 loss : 0.437534 model2 loss : 0.020677
[00:20:42.046] iteration 16081 : model1 loss : 0.434794 model2 loss : 0.019841
[00:20:42.222] iteration 16082 : model1 loss : 0.435499 model2 loss : 0.021386
[00:20:42.393] iteration 16083 : model1 loss : 0.438115 model2 loss : 0.020531
[00:20:42.573] iteration 16084 : model1 loss : 0.439813 model2 loss : 0.022066
[00:20:42.741] iteration 16085 : model1 loss : 0.439018 model2 loss : 0.021513
[00:20:42.917] iteration 16086 : model1 loss : 0.437922 model2 loss : 0.019289
[00:20:45.036] iteration 16087 : model1 loss : 0.440883 model2 loss : 0.021913
[00:20:45.213] iteration 16088 : model1 loss : 0.434301 model2 loss : 0.020886
[00:20:45.392] iteration 16089 : model1 loss : 0.435528 model2 loss : 0.017484
[00:20:45.564] iteration 16090 : model1 loss : 0.435232 model2 loss : 0.019510
[00:20:45.738] iteration 16091 : model1 loss : 0.437902 model2 loss : 0.018192
[00:20:45.908] iteration 16092 : model1 loss : 0.439984 model2 loss : 0.024776
[00:20:46.084] iteration 16093 : model1 loss : 0.432946 model2 loss : 0.020838
[00:20:46.254] iteration 16094 : model1 loss : 0.436927 model2 loss : 0.021449
[00:20:46.428] iteration 16095 : model1 loss : 0.440529 model2 loss : 0.021712
[00:20:46.603] iteration 16096 : model1 loss : 0.437267 model2 loss : 0.023111
[00:20:46.779] iteration 16097 : model1 loss : 0.437457 model2 loss : 0.019610
[00:20:46.948] iteration 16098 : model1 loss : 0.436591 model2 loss : 0.020339
[00:20:47.125] iteration 16099 : model1 loss : 0.437753 model2 loss : 0.019870
[00:20:47.298] iteration 16100 : model1 loss : 0.439027 model2 loss : 0.019643
[00:20:47.476] iteration 16101 : model1 loss : 0.437354 model2 loss : 0.019010
[00:20:47.647] iteration 16102 : model1 loss : 0.436881 model2 loss : 0.019972
[00:20:47.823] iteration 16103 : model1 loss : 0.441346 model2 loss : 0.019473
[00:20:47.993] iteration 16104 : model1 loss : 0.436177 model2 loss : 0.019616
[00:20:48.168] iteration 16105 : model1 loss : 0.438162 model2 loss : 0.019484
[00:20:48.339] iteration 16106 : model1 loss : 0.436949 model2 loss : 0.019908
[00:20:48.512] iteration 16107 : model1 loss : 0.437721 model2 loss : 0.017805
[00:20:50.651] iteration 16108 : model1 loss : 0.435975 model2 loss : 0.018089
[00:20:50.823] iteration 16109 : model1 loss : 0.440451 model2 loss : 0.017473
[00:20:51.005] iteration 16110 : model1 loss : 0.439760 model2 loss : 0.018165
[00:20:51.176] iteration 16111 : model1 loss : 0.436263 model2 loss : 0.018173
[00:20:51.354] iteration 16112 : model1 loss : 0.433605 model2 loss : 0.018156
[00:20:51.526] iteration 16113 : model1 loss : 0.437340 model2 loss : 0.021403
[00:20:51.701] iteration 16114 : model1 loss : 0.441312 model2 loss : 0.020668
[00:20:51.874] iteration 16115 : model1 loss : 0.440958 model2 loss : 0.019237
[00:20:52.049] iteration 16116 : model1 loss : 0.436943 model2 loss : 0.021074
[00:20:52.221] iteration 16117 : model1 loss : 0.436885 model2 loss : 0.020660
[00:20:52.424] iteration 16118 : model1 loss : 0.438769 model2 loss : 0.021778
[00:20:52.600] iteration 16119 : model1 loss : 0.440084 model2 loss : 0.023210
[00:20:52.779] iteration 16120 : model1 loss : 0.435246 model2 loss : 0.019954
[00:20:52.948] iteration 16121 : model1 loss : 0.436996 model2 loss : 0.017448
[00:20:53.127] iteration 16122 : model1 loss : 0.436036 model2 loss : 0.020653
[00:20:53.302] iteration 16123 : model1 loss : 0.435273 model2 loss : 0.017982
[00:20:53.481] iteration 16124 : model1 loss : 0.435946 model2 loss : 0.020254
[00:20:53.651] iteration 16125 : model1 loss : 0.438822 model2 loss : 0.018447
[00:20:53.829] iteration 16126 : model1 loss : 0.436142 model2 loss : 0.021554
[00:20:53.998] iteration 16127 : model1 loss : 0.438897 model2 loss : 0.022554
[00:20:54.169] iteration 16128 : model1 loss : 0.432882 model2 loss : 0.019252
[00:20:56.330] iteration 16129 : model1 loss : 0.435275 model2 loss : 0.019800
[00:20:56.506] iteration 16130 : model1 loss : 0.434285 model2 loss : 0.019251
[00:20:56.685] iteration 16131 : model1 loss : 0.434370 model2 loss : 0.017813
[00:20:56.858] iteration 16132 : model1 loss : 0.435874 model2 loss : 0.019309
[00:20:57.034] iteration 16133 : model1 loss : 0.433245 model2 loss : 0.018333
[00:20:57.205] iteration 16134 : model1 loss : 0.436303 model2 loss : 0.017741
[00:20:57.382] iteration 16135 : model1 loss : 0.437684 model2 loss : 0.020775
[00:20:57.553] iteration 16136 : model1 loss : 0.437602 model2 loss : 0.022374
[00:20:57.728] iteration 16137 : model1 loss : 0.439260 model2 loss : 0.020938
[00:20:57.899] iteration 16138 : model1 loss : 0.436894 model2 loss : 0.018106
[00:20:58.076] iteration 16139 : model1 loss : 0.440659 model2 loss : 0.020752
[00:20:58.247] iteration 16140 : model1 loss : 0.436795 model2 loss : 0.020631
[00:20:58.423] iteration 16141 : model1 loss : 0.437155 model2 loss : 0.020540
[00:20:58.602] iteration 16142 : model1 loss : 0.439891 model2 loss : 0.019948
[00:20:58.778] iteration 16143 : model1 loss : 0.434806 model2 loss : 0.018807
[00:20:58.950] iteration 16144 : model1 loss : 0.436744 model2 loss : 0.019755
[00:20:59.128] iteration 16145 : model1 loss : 0.437943 model2 loss : 0.020443
[00:20:59.298] iteration 16146 : model1 loss : 0.440402 model2 loss : 0.020787
[00:20:59.476] iteration 16147 : model1 loss : 0.438499 model2 loss : 0.018915
[00:20:59.645] iteration 16148 : model1 loss : 0.438271 model2 loss : 0.020869
[00:20:59.821] iteration 16149 : model1 loss : 0.441615 model2 loss : 0.021421
[00:21:01.961] iteration 16150 : model1 loss : 0.432304 model2 loss : 0.018799
[00:21:02.137] iteration 16151 : model1 loss : 0.437523 model2 loss : 0.018605
[00:21:02.317] iteration 16152 : model1 loss : 0.432106 model2 loss : 0.019407
[00:21:02.494] iteration 16153 : model1 loss : 0.438737 model2 loss : 0.020426
[00:21:02.670] iteration 16154 : model1 loss : 0.443081 model2 loss : 0.023536
[00:21:02.842] iteration 16155 : model1 loss : 0.437918 model2 loss : 0.017056
[00:21:03.024] iteration 16156 : model1 loss : 0.434762 model2 loss : 0.019171
[00:21:03.195] iteration 16157 : model1 loss : 0.440567 model2 loss : 0.018604
[00:21:03.370] iteration 16158 : model1 loss : 0.438415 model2 loss : 0.021063
[00:21:03.539] iteration 16159 : model1 loss : 0.434094 model2 loss : 0.020871
[00:21:03.716] iteration 16160 : model1 loss : 0.438581 model2 loss : 0.019982
[00:21:03.888] iteration 16161 : model1 loss : 0.436531 model2 loss : 0.020062
[00:21:04.065] iteration 16162 : model1 loss : 0.437494 model2 loss : 0.021191
[00:21:04.236] iteration 16163 : model1 loss : 0.434720 model2 loss : 0.017638
[00:21:04.418] iteration 16164 : model1 loss : 0.438122 model2 loss : 0.020510
[00:21:04.590] iteration 16165 : model1 loss : 0.437754 model2 loss : 0.019953
[00:21:04.765] iteration 16166 : model1 loss : 0.436996 model2 loss : 0.020359
[00:21:04.936] iteration 16167 : model1 loss : 0.435455 model2 loss : 0.018599
[00:21:05.113] iteration 16168 : model1 loss : 0.441466 model2 loss : 0.019766
[00:21:05.282] iteration 16169 : model1 loss : 0.436561 model2 loss : 0.019567
[00:21:05.461] iteration 16170 : model1 loss : 0.435640 model2 loss : 0.019554
[00:21:07.617] iteration 16171 : model1 loss : 0.431515 model2 loss : 0.017245
[00:21:07.790] iteration 16172 : model1 loss : 0.438661 model2 loss : 0.020248
[00:21:07.971] iteration 16173 : model1 loss : 0.437773 model2 loss : 0.020264
[00:21:08.143] iteration 16174 : model1 loss : 0.435867 model2 loss : 0.017754
[00:21:08.321] iteration 16175 : model1 loss : 0.435114 model2 loss : 0.019229
[00:21:08.496] iteration 16176 : model1 loss : 0.438875 model2 loss : 0.018796
[00:21:08.674] iteration 16177 : model1 loss : 0.437478 model2 loss : 0.017819
[00:21:08.845] iteration 16178 : model1 loss : 0.440341 model2 loss : 0.021001
[00:21:09.023] iteration 16179 : model1 loss : 0.438721 model2 loss : 0.020078
[00:21:09.196] iteration 16180 : model1 loss : 0.437731 model2 loss : 0.021535
[00:21:09.371] iteration 16181 : model1 loss : 0.438930 model2 loss : 0.018198
[00:21:09.543] iteration 16182 : model1 loss : 0.436535 model2 loss : 0.019428
[00:21:09.717] iteration 16183 : model1 loss : 0.436688 model2 loss : 0.019795
[00:21:09.887] iteration 16184 : model1 loss : 0.434750 model2 loss : 0.018709
[00:21:10.061] iteration 16185 : model1 loss : 0.438243 model2 loss : 0.019956
[00:21:10.231] iteration 16186 : model1 loss : 0.434173 model2 loss : 0.017792
[00:21:10.409] iteration 16187 : model1 loss : 0.439682 model2 loss : 0.019675
[00:21:10.581] iteration 16188 : model1 loss : 0.438965 model2 loss : 0.022591
[00:21:10.756] iteration 16189 : model1 loss : 0.438191 model2 loss : 0.020722
[00:21:10.925] iteration 16190 : model1 loss : 0.437583 model2 loss : 0.018207
[00:21:11.099] iteration 16191 : model1 loss : 0.435819 model2 loss : 0.019945
[00:21:13.250] iteration 16192 : model1 loss : 0.433452 model2 loss : 0.019110
[00:21:13.422] iteration 16193 : model1 loss : 0.434907 model2 loss : 0.017438
[00:21:13.608] iteration 16194 : model1 loss : 0.435976 model2 loss : 0.018197
[00:21:13.779] iteration 16195 : model1 loss : 0.436976 model2 loss : 0.019384
[00:21:13.953] iteration 16196 : model1 loss : 0.437787 model2 loss : 0.020652
[00:21:14.128] iteration 16197 : model1 loss : 0.436668 model2 loss : 0.019850
[00:21:14.308] iteration 16198 : model1 loss : 0.439317 model2 loss : 0.020164
[00:21:14.481] iteration 16199 : model1 loss : 0.437740 model2 loss : 0.019700
[00:21:14.664] iteration 16200 : model1 loss : 0.436059 model2 loss : 0.020130
[00:21:14.835] iteration 16201 : model1 loss : 0.439750 model2 loss : 0.020344
[00:21:15.011] iteration 16202 : model1 loss : 0.435555 model2 loss : 0.020013
[00:21:15.181] iteration 16203 : model1 loss : 0.440026 model2 loss : 0.020544
[00:21:15.360] iteration 16204 : model1 loss : 0.435502 model2 loss : 0.023190
[00:21:15.530] iteration 16205 : model1 loss : 0.439635 model2 loss : 0.022064
[00:21:15.704] iteration 16206 : model1 loss : 0.438513 model2 loss : 0.019999
[00:21:15.874] iteration 16207 : model1 loss : 0.440329 model2 loss : 0.021974
[00:21:16.049] iteration 16208 : model1 loss : 0.437303 model2 loss : 0.020800
[00:21:16.220] iteration 16209 : model1 loss : 0.438831 model2 loss : 0.018442
[00:21:16.395] iteration 16210 : model1 loss : 0.435030 model2 loss : 0.020442
[00:21:16.565] iteration 16211 : model1 loss : 0.435280 model2 loss : 0.019949
[00:21:16.739] iteration 16212 : model1 loss : 0.435774 model2 loss : 0.019635
[00:21:18.886] iteration 16213 : model1 loss : 0.441923 model2 loss : 0.022563
[00:21:19.065] iteration 16214 : model1 loss : 0.436877 model2 loss : 0.020852
[00:21:19.244] iteration 16215 : model1 loss : 0.435855 model2 loss : 0.020184
[00:21:19.417] iteration 16216 : model1 loss : 0.434805 model2 loss : 0.019470
[00:21:19.592] iteration 16217 : model1 loss : 0.438916 model2 loss : 0.019647
[00:21:19.763] iteration 16218 : model1 loss : 0.434249 model2 loss : 0.019146
[00:21:19.937] iteration 16219 : model1 loss : 0.438303 model2 loss : 0.018233
[00:21:20.108] iteration 16220 : model1 loss : 0.435911 model2 loss : 0.020096
[00:21:20.284] iteration 16221 : model1 loss : 0.436131 model2 loss : 0.019883
[00:21:20.460] iteration 16222 : model1 loss : 0.438479 model2 loss : 0.021217
[00:21:20.637] iteration 16223 : model1 loss : 0.438247 model2 loss : 0.019267
[00:21:20.808] iteration 16224 : model1 loss : 0.438859 model2 loss : 0.019538
[00:21:20.983] iteration 16225 : model1 loss : 0.437708 model2 loss : 0.017846
[00:21:21.156] iteration 16226 : model1 loss : 0.441601 model2 loss : 0.021605
[00:21:21.334] iteration 16227 : model1 loss : 0.435529 model2 loss : 0.019876
[00:21:21.508] iteration 16228 : model1 loss : 0.437334 model2 loss : 0.020891
[00:21:21.686] iteration 16229 : model1 loss : 0.438020 model2 loss : 0.018409
[00:21:21.858] iteration 16230 : model1 loss : 0.441077 model2 loss : 0.020206
[00:21:22.032] iteration 16231 : model1 loss : 0.431630 model2 loss : 0.020294
[00:21:22.202] iteration 16232 : model1 loss : 0.435934 model2 loss : 0.020165
[00:21:22.377] iteration 16233 : model1 loss : 0.434112 model2 loss : 0.016935
[00:21:24.543] iteration 16234 : model1 loss : 0.438931 model2 loss : 0.018669
[00:21:24.718] iteration 16235 : model1 loss : 0.435731 model2 loss : 0.018012
[00:21:24.897] iteration 16236 : model1 loss : 0.438156 model2 loss : 0.020041
[00:21:25.069] iteration 16237 : model1 loss : 0.441733 model2 loss : 0.021683
[00:21:25.244] iteration 16238 : model1 loss : 0.435404 model2 loss : 0.018116
[00:21:25.417] iteration 16239 : model1 loss : 0.436239 model2 loss : 0.017382
[00:21:25.601] iteration 16240 : model1 loss : 0.440738 model2 loss : 0.022331
[00:21:25.774] iteration 16241 : model1 loss : 0.436810 model2 loss : 0.022421
[00:21:25.949] iteration 16242 : model1 loss : 0.432999 model2 loss : 0.018668
[00:21:26.120] iteration 16243 : model1 loss : 0.438497 model2 loss : 0.020832
[00:21:26.295] iteration 16244 : model1 loss : 0.436752 model2 loss : 0.021039
[00:21:26.470] iteration 16245 : model1 loss : 0.434255 model2 loss : 0.020643
[00:21:26.651] iteration 16246 : model1 loss : 0.436072 model2 loss : 0.019954
[00:21:26.823] iteration 16247 : model1 loss : 0.438369 model2 loss : 0.021770
[00:21:26.997] iteration 16248 : model1 loss : 0.437538 model2 loss : 0.019288
[00:21:27.170] iteration 16249 : model1 loss : 0.436216 model2 loss : 0.020153
[00:21:27.346] iteration 16250 : model1 loss : 0.438228 model2 loss : 0.020222
[00:21:27.520] iteration 16251 : model1 loss : 0.438935 model2 loss : 0.020987
[00:21:27.697] iteration 16252 : model1 loss : 0.438088 model2 loss : 0.022020
[00:21:27.866] iteration 16253 : model1 loss : 0.436314 model2 loss : 0.020354
[00:21:28.041] iteration 16254 : model1 loss : 0.438363 model2 loss : 0.018669
[00:21:30.159] iteration 16255 : model1 loss : 0.442546 model2 loss : 0.021195
[00:21:30.333] iteration 16256 : model1 loss : 0.440050 model2 loss : 0.020865
[00:21:30.515] iteration 16257 : model1 loss : 0.436097 model2 loss : 0.018431
[00:21:30.688] iteration 16258 : model1 loss : 0.434913 model2 loss : 0.019773
[00:21:30.866] iteration 16259 : model1 loss : 0.436756 model2 loss : 0.021394
[00:21:31.036] iteration 16260 : model1 loss : 0.436135 model2 loss : 0.020456
[00:21:31.212] iteration 16261 : model1 loss : 0.435737 model2 loss : 0.020122
[00:21:31.385] iteration 16262 : model1 loss : 0.441774 model2 loss : 0.022025
[00:21:31.562] iteration 16263 : model1 loss : 0.433599 model2 loss : 0.018835
[00:21:31.732] iteration 16264 : model1 loss : 0.437004 model2 loss : 0.020039
[00:21:31.907] iteration 16265 : model1 loss : 0.435413 model2 loss : 0.018970
[00:21:32.077] iteration 16266 : model1 loss : 0.439460 model2 loss : 0.023173
[00:21:32.253] iteration 16267 : model1 loss : 0.435409 model2 loss : 0.020190
[00:21:32.426] iteration 16268 : model1 loss : 0.434819 model2 loss : 0.022788
[00:21:32.605] iteration 16269 : model1 loss : 0.435716 model2 loss : 0.017555
[00:21:32.777] iteration 16270 : model1 loss : 0.437594 model2 loss : 0.019091
[00:21:32.954] iteration 16271 : model1 loss : 0.440278 model2 loss : 0.021318
[00:21:33.124] iteration 16272 : model1 loss : 0.435204 model2 loss : 0.018669
[00:21:33.302] iteration 16273 : model1 loss : 0.435580 model2 loss : 0.020954
[00:21:33.475] iteration 16274 : model1 loss : 0.443043 model2 loss : 0.021934
[00:21:33.649] iteration 16275 : model1 loss : 0.436843 model2 loss : 0.020413
[00:21:35.764] iteration 16276 : model1 loss : 0.440264 model2 loss : 0.020896
[00:21:35.934] iteration 16277 : model1 loss : 0.438910 model2 loss : 0.019733
[00:21:36.114] iteration 16278 : model1 loss : 0.439419 model2 loss : 0.021385
[00:21:36.286] iteration 16279 : model1 loss : 0.434202 model2 loss : 0.019250
[00:21:36.464] iteration 16280 : model1 loss : 0.433825 model2 loss : 0.020406
[00:21:36.636] iteration 16281 : model1 loss : 0.434316 model2 loss : 0.021164
[00:21:36.811] iteration 16282 : model1 loss : 0.435118 model2 loss : 0.022493
[00:21:36.983] iteration 16283 : model1 loss : 0.433905 model2 loss : 0.019128
[00:21:37.158] iteration 16284 : model1 loss : 0.439870 model2 loss : 0.020673
[00:21:37.334] iteration 16285 : model1 loss : 0.433461 model2 loss : 0.017807
[00:21:37.516] iteration 16286 : model1 loss : 0.438594 model2 loss : 0.020898
[00:21:37.685] iteration 16287 : model1 loss : 0.438922 model2 loss : 0.019429
[00:21:37.863] iteration 16288 : model1 loss : 0.441658 model2 loss : 0.018513
[00:21:38.033] iteration 16289 : model1 loss : 0.436966 model2 loss : 0.020684
[00:21:38.208] iteration 16290 : model1 loss : 0.435007 model2 loss : 0.018368
[00:21:38.382] iteration 16291 : model1 loss : 0.439105 model2 loss : 0.017869
[00:21:38.560] iteration 16292 : model1 loss : 0.437954 model2 loss : 0.021871
[00:21:38.731] iteration 16293 : model1 loss : 0.436941 model2 loss : 0.019816
[00:21:38.907] iteration 16294 : model1 loss : 0.435691 model2 loss : 0.021246
[00:21:39.077] iteration 16295 : model1 loss : 0.436684 model2 loss : 0.022135
[00:21:39.252] iteration 16296 : model1 loss : 0.438267 model2 loss : 0.019125
[00:21:41.394] iteration 16297 : model1 loss : 0.436591 model2 loss : 0.019102
[00:21:41.569] iteration 16298 : model1 loss : 0.438354 model2 loss : 0.022651
[00:21:41.748] iteration 16299 : model1 loss : 0.436850 model2 loss : 0.018569
[00:21:41.921] iteration 16300 : model1 loss : 0.436937 model2 loss : 0.017933
[00:21:42.098] iteration 16301 : model1 loss : 0.439434 model2 loss : 0.019329
[00:21:42.270] iteration 16302 : model1 loss : 0.436436 model2 loss : 0.021161
[00:21:42.451] iteration 16303 : model1 loss : 0.435521 model2 loss : 0.022556
[00:21:42.626] iteration 16304 : model1 loss : 0.436728 model2 loss : 0.022063
[00:21:42.803] iteration 16305 : model1 loss : 0.440729 model2 loss : 0.024635
[00:21:42.975] iteration 16306 : model1 loss : 0.444243 model2 loss : 0.032571
[00:21:43.150] iteration 16307 : model1 loss : 0.434039 model2 loss : 0.020286
[00:21:43.327] iteration 16308 : model1 loss : 0.435466 model2 loss : 0.021658
[00:21:43.505] iteration 16309 : model1 loss : 0.435460 model2 loss : 0.019224
[00:21:43.677] iteration 16310 : model1 loss : 0.433679 model2 loss : 0.021543
[00:21:43.850] iteration 16311 : model1 loss : 0.436820 model2 loss : 0.021064
[00:21:44.022] iteration 16312 : model1 loss : 0.437539 model2 loss : 0.022176
[00:21:44.197] iteration 16313 : model1 loss : 0.439298 model2 loss : 0.022343
[00:21:44.367] iteration 16314 : model1 loss : 0.432539 model2 loss : 0.019601
[00:21:44.546] iteration 16315 : model1 loss : 0.438996 model2 loss : 0.020087
[00:21:44.714] iteration 16316 : model1 loss : 0.438210 model2 loss : 0.021081
[00:21:44.888] iteration 16317 : model1 loss : 0.441800 model2 loss : 0.024779
[00:21:47.046] iteration 16318 : model1 loss : 0.441059 model2 loss : 0.020540
[00:21:47.228] iteration 16319 : model1 loss : 0.433263 model2 loss : 0.018600
[00:21:47.406] iteration 16320 : model1 loss : 0.438434 model2 loss : 0.023108
[00:21:47.577] iteration 16321 : model1 loss : 0.434676 model2 loss : 0.020169
[00:21:47.759] iteration 16322 : model1 loss : 0.433181 model2 loss : 0.019308
[00:21:47.935] iteration 16323 : model1 loss : 0.440017 model2 loss : 0.024143
[00:21:48.124] iteration 16324 : model1 loss : 0.443046 model2 loss : 0.023406
[00:21:48.293] iteration 16325 : model1 loss : 0.439870 model2 loss : 0.019334
[00:21:48.470] iteration 16326 : model1 loss : 0.438678 model2 loss : 0.022434
[00:21:48.641] iteration 16327 : model1 loss : 0.433488 model2 loss : 0.018568
[00:21:48.819] iteration 16328 : model1 loss : 0.435420 model2 loss : 0.022879
[00:21:48.989] iteration 16329 : model1 loss : 0.436729 model2 loss : 0.023361
[00:21:49.164] iteration 16330 : model1 loss : 0.440270 model2 loss : 0.021834
[00:21:49.336] iteration 16331 : model1 loss : 0.436892 model2 loss : 0.021540
[00:21:49.513] iteration 16332 : model1 loss : 0.435144 model2 loss : 0.021093
[00:21:49.683] iteration 16333 : model1 loss : 0.432155 model2 loss : 0.020635
[00:21:49.860] iteration 16334 : model1 loss : 0.438453 model2 loss : 0.022164
[00:21:50.030] iteration 16335 : model1 loss : 0.437102 model2 loss : 0.022298
[00:21:50.208] iteration 16336 : model1 loss : 0.436745 model2 loss : 0.021086
[00:21:50.378] iteration 16337 : model1 loss : 0.442686 model2 loss : 0.025785
[00:21:50.555] iteration 16338 : model1 loss : 0.442855 model2 loss : 0.024629
[00:21:52.719] iteration 16339 : model1 loss : 0.434838 model2 loss : 0.018804
[00:21:52.888] iteration 16340 : model1 loss : 0.432719 model2 loss : 0.019935
[00:21:53.070] iteration 16341 : model1 loss : 0.443325 model2 loss : 0.022559
[00:21:53.242] iteration 16342 : model1 loss : 0.434199 model2 loss : 0.019073
[00:21:53.421] iteration 16343 : model1 loss : 0.437200 model2 loss : 0.019468
[00:21:53.596] iteration 16344 : model1 loss : 0.433932 model2 loss : 0.018481
[00:21:53.771] iteration 16345 : model1 loss : 0.437498 model2 loss : 0.021814
[00:21:53.941] iteration 16346 : model1 loss : 0.433947 model2 loss : 0.022029
[00:21:54.120] iteration 16347 : model1 loss : 0.437357 model2 loss : 0.022189
[00:21:54.290] iteration 16348 : model1 loss : 0.440401 model2 loss : 0.021587
[00:21:54.466] iteration 16349 : model1 loss : 0.434355 model2 loss : 0.019769
[00:21:54.640] iteration 16350 : model1 loss : 0.435800 model2 loss : 0.021029
[00:21:54.814] iteration 16351 : model1 loss : 0.437415 model2 loss : 0.019468
[00:21:54.986] iteration 16352 : model1 loss : 0.438050 model2 loss : 0.021131
[00:21:55.161] iteration 16353 : model1 loss : 0.436287 model2 loss : 0.020350
[00:21:55.336] iteration 16354 : model1 loss : 0.440561 model2 loss : 0.022615
[00:21:55.513] iteration 16355 : model1 loss : 0.436440 model2 loss : 0.020613
[00:21:55.683] iteration 16356 : model1 loss : 0.437708 model2 loss : 0.022945
[00:21:55.859] iteration 16357 : model1 loss : 0.443975 model2 loss : 0.023498
[00:21:56.028] iteration 16358 : model1 loss : 0.442509 model2 loss : 0.022403
[00:21:56.199] iteration 16359 : model1 loss : 0.438331 model2 loss : 0.021612
[00:21:58.348] iteration 16360 : model1 loss : 0.441097 model2 loss : 0.023179
[00:21:58.522] iteration 16361 : model1 loss : 0.436868 model2 loss : 0.020041
[00:21:58.705] iteration 16362 : model1 loss : 0.432904 model2 loss : 0.018700
[00:21:58.875] iteration 16363 : model1 loss : 0.436889 model2 loss : 0.022197
[00:21:59.052] iteration 16364 : model1 loss : 0.437861 model2 loss : 0.021326
[00:21:59.224] iteration 16365 : model1 loss : 0.441786 model2 loss : 0.022068
[00:21:59.399] iteration 16366 : model1 loss : 0.440756 model2 loss : 0.021817
[00:21:59.572] iteration 16367 : model1 loss : 0.435755 model2 loss : 0.020280
[00:21:59.747] iteration 16368 : model1 loss : 0.433086 model2 loss : 0.020175
[00:21:59.916] iteration 16369 : model1 loss : 0.438639 model2 loss : 0.020284
[00:22:00.093] iteration 16370 : model1 loss : 0.438659 model2 loss : 0.022297
[00:22:00.266] iteration 16371 : model1 loss : 0.439157 model2 loss : 0.021857
[00:22:00.444] iteration 16372 : model1 loss : 0.439200 model2 loss : 0.020704
[00:22:00.619] iteration 16373 : model1 loss : 0.440681 model2 loss : 0.026186
[00:22:00.798] iteration 16374 : model1 loss : 0.433625 model2 loss : 0.018572
[00:22:00.969] iteration 16375 : model1 loss : 0.440785 model2 loss : 0.021778
[00:22:01.143] iteration 16376 : model1 loss : 0.436482 model2 loss : 0.018928
[00:22:01.317] iteration 16377 : model1 loss : 0.434977 model2 loss : 0.019188
[00:22:01.495] iteration 16378 : model1 loss : 0.439326 model2 loss : 0.020773
[00:22:01.664] iteration 16379 : model1 loss : 0.432116 model2 loss : 0.020333
[00:22:01.836] iteration 16380 : model1 loss : 0.438966 model2 loss : 0.020131
[00:22:03.978] iteration 16381 : model1 loss : 0.438828 model2 loss : 0.021794
[00:22:04.156] iteration 16382 : model1 loss : 0.439996 model2 loss : 0.024010
[00:22:04.338] iteration 16383 : model1 loss : 0.436414 model2 loss : 0.019326
[00:22:04.510] iteration 16384 : model1 loss : 0.438964 model2 loss : 0.019534
[00:22:04.685] iteration 16385 : model1 loss : 0.440953 model2 loss : 0.021901
[00:22:04.855] iteration 16386 : model1 loss : 0.438337 model2 loss : 0.019915
[00:22:05.029] iteration 16387 : model1 loss : 0.441359 model2 loss : 0.019541
[00:22:05.202] iteration 16388 : model1 loss : 0.435891 model2 loss : 0.018440
[00:22:05.378] iteration 16389 : model1 loss : 0.439273 model2 loss : 0.019790
[00:22:05.551] iteration 16390 : model1 loss : 0.434604 model2 loss : 0.019918
[00:22:05.725] iteration 16391 : model1 loss : 0.436266 model2 loss : 0.023980
[00:22:05.896] iteration 16392 : model1 loss : 0.436101 model2 loss : 0.020888
[00:22:06.074] iteration 16393 : model1 loss : 0.437082 model2 loss : 0.021983
[00:22:06.244] iteration 16394 : model1 loss : 0.437092 model2 loss : 0.020440
[00:22:06.423] iteration 16395 : model1 loss : 0.430683 model2 loss : 0.020228
[00:22:06.597] iteration 16396 : model1 loss : 0.437188 model2 loss : 0.021813
[00:22:06.783] iteration 16397 : model1 loss : 0.438343 model2 loss : 0.019968
[00:22:06.955] iteration 16398 : model1 loss : 0.435137 model2 loss : 0.017945
[00:22:07.133] iteration 16399 : model1 loss : 0.438176 model2 loss : 0.021749
[00:22:07.304] iteration 16400 : model1 loss : 0.436595 model2 loss : 0.020265
[00:22:07.487] iteration 16401 : model1 loss : 0.437972 model2 loss : 0.021170
[00:22:09.607] iteration 16402 : model1 loss : 0.439184 model2 loss : 0.019794
[00:22:09.780] iteration 16403 : model1 loss : 0.439173 model2 loss : 0.020195
[00:22:09.961] iteration 16404 : model1 loss : 0.438899 model2 loss : 0.017389
[00:22:10.134] iteration 16405 : model1 loss : 0.433488 model2 loss : 0.020585
[00:22:10.310] iteration 16406 : model1 loss : 0.437302 model2 loss : 0.018623
[00:22:10.482] iteration 16407 : model1 loss : 0.439495 model2 loss : 0.019086
[00:22:10.664] iteration 16408 : model1 loss : 0.440817 model2 loss : 0.021665
[00:22:10.835] iteration 16409 : model1 loss : 0.435448 model2 loss : 0.019632
[00:22:11.011] iteration 16410 : model1 loss : 0.437088 model2 loss : 0.018345
[00:22:11.181] iteration 16411 : model1 loss : 0.433070 model2 loss : 0.020954
[00:22:11.361] iteration 16412 : model1 loss : 0.434554 model2 loss : 0.018794
[00:22:11.532] iteration 16413 : model1 loss : 0.439928 model2 loss : 0.021199
[00:22:11.707] iteration 16414 : model1 loss : 0.436311 model2 loss : 0.019328
[00:22:11.880] iteration 16415 : model1 loss : 0.436315 model2 loss : 0.020405
[00:22:12.058] iteration 16416 : model1 loss : 0.441911 model2 loss : 0.021619
[00:22:12.230] iteration 16417 : model1 loss : 0.434572 model2 loss : 0.020612
[00:22:12.405] iteration 16418 : model1 loss : 0.438764 model2 loss : 0.022260
[00:22:12.576] iteration 16419 : model1 loss : 0.438969 model2 loss : 0.020346
[00:22:12.756] iteration 16420 : model1 loss : 0.435865 model2 loss : 0.018730
[00:22:12.926] iteration 16421 : model1 loss : 0.435599 model2 loss : 0.018428
[00:22:13.100] iteration 16422 : model1 loss : 0.435882 model2 loss : 0.018387
[00:22:15.215] iteration 16423 : model1 loss : 0.435655 model2 loss : 0.019760
[00:22:15.389] iteration 16424 : model1 loss : 0.440285 model2 loss : 0.021805
[00:22:15.570] iteration 16425 : model1 loss : 0.437460 model2 loss : 0.018851
[00:22:15.742] iteration 16426 : model1 loss : 0.437324 model2 loss : 0.021058
[00:22:15.919] iteration 16427 : model1 loss : 0.433654 model2 loss : 0.016555
[00:22:16.089] iteration 16428 : model1 loss : 0.440546 model2 loss : 0.021890
[00:22:16.264] iteration 16429 : model1 loss : 0.437985 model2 loss : 0.022137
[00:22:16.435] iteration 16430 : model1 loss : 0.438724 model2 loss : 0.018813
[00:22:16.614] iteration 16431 : model1 loss : 0.433741 model2 loss : 0.021151
[00:22:16.785] iteration 16432 : model1 loss : 0.440810 model2 loss : 0.021629
[00:22:16.962] iteration 16433 : model1 loss : 0.436096 model2 loss : 0.017910
[00:22:17.132] iteration 16434 : model1 loss : 0.433723 model2 loss : 0.017620
[00:22:17.313] iteration 16435 : model1 loss : 0.437112 model2 loss : 0.019309
[00:22:17.489] iteration 16436 : model1 loss : 0.436370 model2 loss : 0.021455
[00:22:17.666] iteration 16437 : model1 loss : 0.441370 model2 loss : 0.021878
[00:22:17.836] iteration 16438 : model1 loss : 0.438323 model2 loss : 0.020633
[00:22:18.009] iteration 16439 : model1 loss : 0.438059 model2 loss : 0.022690
[00:22:18.181] iteration 16440 : model1 loss : 0.439237 model2 loss : 0.017578
[00:22:18.359] iteration 16441 : model1 loss : 0.437428 model2 loss : 0.018961
[00:22:18.531] iteration 16442 : model1 loss : 0.434664 model2 loss : 0.018436
[00:22:18.704] iteration 16443 : model1 loss : 0.438934 model2 loss : 0.020586
[00:22:20.839] iteration 16444 : model1 loss : 0.435754 model2 loss : 0.021595
[00:22:21.010] iteration 16445 : model1 loss : 0.441235 model2 loss : 0.022583
[00:22:21.192] iteration 16446 : model1 loss : 0.437962 model2 loss : 0.019736
[00:22:21.369] iteration 16447 : model1 loss : 0.437747 model2 loss : 0.020106
[00:22:21.543] iteration 16448 : model1 loss : 0.437925 model2 loss : 0.021138
[00:22:21.712] iteration 16449 : model1 loss : 0.436389 model2 loss : 0.020731
[00:22:21.886] iteration 16450 : model1 loss : 0.439038 model2 loss : 0.018322
[00:22:22.056] iteration 16451 : model1 loss : 0.437004 model2 loss : 0.021021
[00:22:22.232] iteration 16452 : model1 loss : 0.437001 model2 loss : 0.019334
[00:22:22.404] iteration 16453 : model1 loss : 0.435503 model2 loss : 0.020268
[00:22:22.581] iteration 16454 : model1 loss : 0.439177 model2 loss : 0.022136
[00:22:22.751] iteration 16455 : model1 loss : 0.440493 model2 loss : 0.019410
[00:22:22.926] iteration 16456 : model1 loss : 0.434680 model2 loss : 0.020680
[00:22:23.097] iteration 16457 : model1 loss : 0.436868 model2 loss : 0.017986
[00:22:23.274] iteration 16458 : model1 loss : 0.437942 model2 loss : 0.022187
[00:22:23.446] iteration 16459 : model1 loss : 0.434800 model2 loss : 0.020429
[00:22:23.625] iteration 16460 : model1 loss : 0.435730 model2 loss : 0.019449
[00:22:23.798] iteration 16461 : model1 loss : 0.438162 model2 loss : 0.021008
[00:22:23.970] iteration 16462 : model1 loss : 0.435346 model2 loss : 0.019220
[00:22:24.140] iteration 16463 : model1 loss : 0.438466 model2 loss : 0.019155
[00:22:24.315] iteration 16464 : model1 loss : 0.439996 model2 loss : 0.018810
[00:22:26.415] iteration 16465 : model1 loss : 0.440962 model2 loss : 0.022858
[00:22:26.592] iteration 16466 : model1 loss : 0.437080 model2 loss : 0.020077
[00:22:26.774] iteration 16467 : model1 loss : 0.436645 model2 loss : 0.021419
[00:22:26.946] iteration 16468 : model1 loss : 0.438305 model2 loss : 0.020529
[00:22:27.123] iteration 16469 : model1 loss : 0.432872 model2 loss : 0.017555
[00:22:27.296] iteration 16470 : model1 loss : 0.440890 model2 loss : 0.021578
[00:22:27.476] iteration 16471 : model1 loss : 0.436925 model2 loss : 0.020186
[00:22:27.644] iteration 16472 : model1 loss : 0.433217 model2 loss : 0.018517
[00:22:27.819] iteration 16473 : model1 loss : 0.437721 model2 loss : 0.019590
[00:22:27.989] iteration 16474 : model1 loss : 0.439875 model2 loss : 0.020732
[00:22:28.166] iteration 16475 : model1 loss : 0.432224 model2 loss : 0.017196
[00:22:28.338] iteration 16476 : model1 loss : 0.436238 model2 loss : 0.018660
[00:22:28.513] iteration 16477 : model1 loss : 0.436188 model2 loss : 0.020665
[00:22:28.683] iteration 16478 : model1 loss : 0.435182 model2 loss : 0.020258
[00:22:28.866] iteration 16479 : model1 loss : 0.438405 model2 loss : 0.019819
[00:22:29.037] iteration 16480 : model1 loss : 0.438196 model2 loss : 0.022259
[00:22:29.212] iteration 16481 : model1 loss : 0.436691 model2 loss : 0.019622
[00:22:29.384] iteration 16482 : model1 loss : 0.438497 model2 loss : 0.020004
[00:22:29.560] iteration 16483 : model1 loss : 0.438362 model2 loss : 0.021784
[00:22:29.730] iteration 16484 : model1 loss : 0.439720 model2 loss : 0.020602
[00:22:29.902] iteration 16485 : model1 loss : 0.440855 model2 loss : 0.022441
[00:22:32.039] iteration 16486 : model1 loss : 0.435602 model2 loss : 0.018682
[00:22:32.213] iteration 16487 : model1 loss : 0.436049 model2 loss : 0.020857
[00:22:32.394] iteration 16488 : model1 loss : 0.439923 model2 loss : 0.020528
[00:22:32.566] iteration 16489 : model1 loss : 0.438930 model2 loss : 0.021343
[00:22:32.744] iteration 16490 : model1 loss : 0.443073 model2 loss : 0.023938
[00:22:32.915] iteration 16491 : model1 loss : 0.436710 model2 loss : 0.018200
[00:22:33.095] iteration 16492 : model1 loss : 0.435904 model2 loss : 0.019225
[00:22:33.267] iteration 16493 : model1 loss : 0.440471 model2 loss : 0.020792
[00:22:33.442] iteration 16494 : model1 loss : 0.433525 model2 loss : 0.021162
[00:22:33.616] iteration 16495 : model1 loss : 0.438004 model2 loss : 0.020392
[00:22:33.790] iteration 16496 : model1 loss : 0.434418 model2 loss : 0.020156
[00:22:33.961] iteration 16497 : model1 loss : 0.439077 model2 loss : 0.019317
[00:22:34.136] iteration 16498 : model1 loss : 0.436992 model2 loss : 0.024776
[00:22:34.309] iteration 16499 : model1 loss : 0.438153 model2 loss : 0.020883
[00:22:34.488] iteration 16500 : model1 loss : 0.440315 model2 loss : 0.018773
[00:22:34.662] iteration 16501 : model1 loss : 0.438356 model2 loss : 0.025676
[00:22:34.836] iteration 16502 : model1 loss : 0.437993 model2 loss : 0.022351
[00:22:35.007] iteration 16503 : model1 loss : 0.435039 model2 loss : 0.019092
[00:22:35.185] iteration 16504 : model1 loss : 0.436233 model2 loss : 0.019693
[00:22:35.354] iteration 16505 : model1 loss : 0.437362 model2 loss : 0.019120
[00:22:35.532] iteration 16506 : model1 loss : 0.433869 model2 loss : 0.018320
[00:22:37.701] iteration 16507 : model1 loss : 0.441305 model2 loss : 0.020690
[00:22:37.874] iteration 16508 : model1 loss : 0.436270 model2 loss : 0.018161
[00:22:38.053] iteration 16509 : model1 loss : 0.437122 model2 loss : 0.021821
[00:22:38.226] iteration 16510 : model1 loss : 0.440506 model2 loss : 0.022461
[00:22:38.406] iteration 16511 : model1 loss : 0.433080 model2 loss : 0.018300
[00:22:38.579] iteration 16512 : model1 loss : 0.435639 model2 loss : 0.019531
[00:22:38.755] iteration 16513 : model1 loss : 0.435394 model2 loss : 0.020009
[00:22:38.927] iteration 16514 : model1 loss : 0.438231 model2 loss : 0.018052
[00:22:39.103] iteration 16515 : model1 loss : 0.435294 model2 loss : 0.019642
[00:22:39.275] iteration 16516 : model1 loss : 0.434927 model2 loss : 0.022160
[00:22:39.460] iteration 16517 : model1 loss : 0.440859 model2 loss : 0.023996
[00:22:39.632] iteration 16518 : model1 loss : 0.439709 model2 loss : 0.023094
[00:22:39.808] iteration 16519 : model1 loss : 0.433967 model2 loss : 0.021679
[00:22:39.979] iteration 16520 : model1 loss : 0.440965 model2 loss : 0.020023
[00:22:40.157] iteration 16521 : model1 loss : 0.440933 model2 loss : 0.024025
[00:22:40.332] iteration 16522 : model1 loss : 0.436537 model2 loss : 0.016710
[00:22:40.509] iteration 16523 : model1 loss : 0.437435 model2 loss : 0.019048
[00:22:40.679] iteration 16524 : model1 loss : 0.438133 model2 loss : 0.018781
[00:22:40.856] iteration 16525 : model1 loss : 0.436840 model2 loss : 0.022330
[00:22:41.026] iteration 16526 : model1 loss : 0.436932 model2 loss : 0.021131
[00:22:41.202] iteration 16527 : model1 loss : 0.436437 model2 loss : 0.019161
[00:22:43.434] iteration 16528 : model1 loss : 0.437953 model2 loss : 0.021621
[00:22:43.616] iteration 16529 : model1 loss : 0.433167 model2 loss : 0.019387
[00:22:43.794] iteration 16530 : model1 loss : 0.434870 model2 loss : 0.019800
[00:22:43.967] iteration 16531 : model1 loss : 0.439359 model2 loss : 0.022659
[00:22:44.143] iteration 16532 : model1 loss : 0.441265 model2 loss : 0.024614
[00:22:44.315] iteration 16533 : model1 loss : 0.441058 model2 loss : 0.020177
[00:22:44.494] iteration 16534 : model1 loss : 0.434588 model2 loss : 0.019190
[00:22:44.665] iteration 16535 : model1 loss : 0.438546 model2 loss : 0.019755
[00:22:44.840] iteration 16536 : model1 loss : 0.440438 model2 loss : 0.021139
[00:22:45.010] iteration 16537 : model1 loss : 0.440348 model2 loss : 0.020017
[00:22:45.187] iteration 16538 : model1 loss : 0.435163 model2 loss : 0.018668
[00:22:45.358] iteration 16539 : model1 loss : 0.434487 model2 loss : 0.019126
[00:22:45.532] iteration 16540 : model1 loss : 0.437947 model2 loss : 0.020417
[00:22:45.703] iteration 16541 : model1 loss : 0.435390 model2 loss : 0.018883
[00:22:45.879] iteration 16542 : model1 loss : 0.441146 model2 loss : 0.023397
[00:22:46.049] iteration 16543 : model1 loss : 0.434985 model2 loss : 0.022298
[00:22:46.226] iteration 16544 : model1 loss : 0.440647 model2 loss : 0.020552
[00:22:46.397] iteration 16545 : model1 loss : 0.440926 model2 loss : 0.021357
[00:22:46.571] iteration 16546 : model1 loss : 0.433427 model2 loss : 0.018195
[00:22:46.740] iteration 16547 : model1 loss : 0.436983 model2 loss : 0.020592
[00:22:46.916] iteration 16548 : model1 loss : 0.437591 model2 loss : 0.021255
[00:22:49.083] iteration 16549 : model1 loss : 0.441498 model2 loss : 0.020129
[00:22:49.265] iteration 16550 : model1 loss : 0.436364 model2 loss : 0.023403
[00:22:49.444] iteration 16551 : model1 loss : 0.437448 model2 loss : 0.017985
[00:22:49.618] iteration 16552 : model1 loss : 0.433610 model2 loss : 0.018918
[00:22:49.797] iteration 16553 : model1 loss : 0.441681 model2 loss : 0.027846
[00:22:49.969] iteration 16554 : model1 loss : 0.442759 model2 loss : 0.025250
[00:22:50.146] iteration 16555 : model1 loss : 0.435385 model2 loss : 0.019470
[00:22:50.319] iteration 16556 : model1 loss : 0.434449 model2 loss : 0.017870
[00:22:50.498] iteration 16557 : model1 loss : 0.438179 model2 loss : 0.018533
[00:22:50.670] iteration 16558 : model1 loss : 0.439018 model2 loss : 0.017381
[00:22:50.845] iteration 16559 : model1 loss : 0.435813 model2 loss : 0.020511
[00:22:51.016] iteration 16560 : model1 loss : 0.438137 model2 loss : 0.019207
[00:22:51.192] iteration 16561 : model1 loss : 0.440155 model2 loss : 0.023003
[00:22:51.364] iteration 16562 : model1 loss : 0.433274 model2 loss : 0.018751
[00:22:51.541] iteration 16563 : model1 loss : 0.438800 model2 loss : 0.022112
[00:22:51.710] iteration 16564 : model1 loss : 0.439976 model2 loss : 0.025516
[00:22:51.889] iteration 16565 : model1 loss : 0.438723 model2 loss : 0.019848
[00:22:52.060] iteration 16566 : model1 loss : 0.437138 model2 loss : 0.018743
[00:22:52.237] iteration 16567 : model1 loss : 0.434237 model2 loss : 0.019314
[00:22:52.408] iteration 16568 : model1 loss : 0.437898 model2 loss : 0.020154
[00:22:52.581] iteration 16569 : model1 loss : 0.434041 model2 loss : 0.019299
[00:22:54.688] iteration 16570 : model1 loss : 0.439837 model2 loss : 0.018445
[00:22:54.861] iteration 16571 : model1 loss : 0.430554 model2 loss : 0.019037
[00:22:55.038] iteration 16572 : model1 loss : 0.438848 model2 loss : 0.016207
[00:22:55.211] iteration 16573 : model1 loss : 0.441981 model2 loss : 0.020368
[00:22:55.387] iteration 16574 : model1 loss : 0.435268 model2 loss : 0.020839
[00:22:55.559] iteration 16575 : model1 loss : 0.441843 model2 loss : 0.019640
[00:22:55.733] iteration 16576 : model1 loss : 0.436448 model2 loss : 0.018244
[00:22:55.904] iteration 16577 : model1 loss : 0.438569 model2 loss : 0.021402
[00:22:56.081] iteration 16578 : model1 loss : 0.441416 model2 loss : 0.020399
[00:22:56.252] iteration 16579 : model1 loss : 0.436492 model2 loss : 0.020773
[00:22:56.430] iteration 16580 : model1 loss : 0.438207 model2 loss : 0.018034
[00:22:56.603] iteration 16581 : model1 loss : 0.436916 model2 loss : 0.019090
[00:22:56.778] iteration 16582 : model1 loss : 0.435341 model2 loss : 0.021350
[00:22:56.950] iteration 16583 : model1 loss : 0.437681 model2 loss : 0.016535
[00:22:57.126] iteration 16584 : model1 loss : 0.438408 model2 loss : 0.019833
[00:22:57.301] iteration 16585 : model1 loss : 0.437639 model2 loss : 0.020859
[00:22:57.484] iteration 16586 : model1 loss : 0.437281 model2 loss : 0.022104
[00:22:57.655] iteration 16587 : model1 loss : 0.433294 model2 loss : 0.019873
[00:22:57.830] iteration 16588 : model1 loss : 0.435747 model2 loss : 0.019771
[00:22:58.002] iteration 16589 : model1 loss : 0.436942 model2 loss : 0.021975
[00:22:58.176] iteration 16590 : model1 loss : 0.438047 model2 loss : 0.018016
[00:23:00.301] iteration 16591 : model1 loss : 0.439106 model2 loss : 0.019272
[00:23:00.471] iteration 16592 : model1 loss : 0.437755 model2 loss : 0.022300
[00:23:00.649] iteration 16593 : model1 loss : 0.439600 model2 loss : 0.025124
[00:23:00.822] iteration 16594 : model1 loss : 0.435142 model2 loss : 0.019437
[00:23:00.999] iteration 16595 : model1 loss : 0.437844 model2 loss : 0.019123
[00:23:01.170] iteration 16596 : model1 loss : 0.441427 model2 loss : 0.020079
[00:23:01.346] iteration 16597 : model1 loss : 0.436760 model2 loss : 0.019903
[00:23:01.522] iteration 16598 : model1 loss : 0.437669 model2 loss : 0.019920
[00:23:01.699] iteration 16599 : model1 loss : 0.437788 model2 loss : 0.020072
[00:23:01.871] iteration 16600 : model1 loss : 0.435719 model2 loss : 0.019292
[00:23:02.046] iteration 16601 : model1 loss : 0.437200 model2 loss : 0.020765
[00:23:02.216] iteration 16602 : model1 loss : 0.433368 model2 loss : 0.018582
[00:23:02.394] iteration 16603 : model1 loss : 0.438064 model2 loss : 0.021735
[00:23:02.569] iteration 16604 : model1 loss : 0.439493 model2 loss : 0.020760
[00:23:02.746] iteration 16605 : model1 loss : 0.441837 model2 loss : 0.024082
[00:23:02.917] iteration 16606 : model1 loss : 0.435909 model2 loss : 0.018142
[00:23:03.092] iteration 16607 : model1 loss : 0.437200 model2 loss : 0.018538
[00:23:03.265] iteration 16608 : model1 loss : 0.434112 model2 loss : 0.020206
[00:23:03.442] iteration 16609 : model1 loss : 0.435581 model2 loss : 0.018918
[00:23:03.615] iteration 16610 : model1 loss : 0.440375 model2 loss : 0.021336
[00:23:03.792] iteration 16611 : model1 loss : 0.438518 model2 loss : 0.020341
[00:23:05.958] iteration 16612 : model1 loss : 0.437497 model2 loss : 0.019478
[00:23:06.137] iteration 16613 : model1 loss : 0.436690 model2 loss : 0.017736
[00:23:06.321] iteration 16614 : model1 loss : 0.437931 model2 loss : 0.018932
[00:23:06.493] iteration 16615 : model1 loss : 0.440391 model2 loss : 0.019535
[00:23:06.668] iteration 16616 : model1 loss : 0.438671 model2 loss : 0.019457
[00:23:06.838] iteration 16617 : model1 loss : 0.435636 model2 loss : 0.020069
[00:23:07.014] iteration 16618 : model1 loss : 0.437564 model2 loss : 0.020216
[00:23:07.184] iteration 16619 : model1 loss : 0.437927 model2 loss : 0.020202
[00:23:07.364] iteration 16620 : model1 loss : 0.436014 model2 loss : 0.019509
[00:23:07.540] iteration 16621 : model1 loss : 0.435777 model2 loss : 0.019093
[00:23:07.714] iteration 16622 : model1 loss : 0.439484 model2 loss : 0.019783
[00:23:07.884] iteration 16623 : model1 loss : 0.434596 model2 loss : 0.020020
[00:23:08.059] iteration 16624 : model1 loss : 0.437397 model2 loss : 0.020922
[00:23:08.229] iteration 16625 : model1 loss : 0.434439 model2 loss : 0.017361
[00:23:08.408] iteration 16626 : model1 loss : 0.438791 model2 loss : 0.019044
[00:23:08.580] iteration 16627 : model1 loss : 0.440112 model2 loss : 0.022837
[00:23:08.761] iteration 16628 : model1 loss : 0.438818 model2 loss : 0.018789
[00:23:08.933] iteration 16629 : model1 loss : 0.438074 model2 loss : 0.021179
[00:23:09.109] iteration 16630 : model1 loss : 0.437888 model2 loss : 0.020038
[00:23:09.277] iteration 16631 : model1 loss : 0.437967 model2 loss : 0.020934
[00:23:09.449] iteration 16632 : model1 loss : 0.435788 model2 loss : 0.019397
[00:23:11.583] iteration 16633 : model1 loss : 0.437146 model2 loss : 0.020474
[00:23:11.761] iteration 16634 : model1 loss : 0.437354 model2 loss : 0.018690
[00:23:11.940] iteration 16635 : model1 loss : 0.438384 model2 loss : 0.018626
[00:23:12.116] iteration 16636 : model1 loss : 0.436610 model2 loss : 0.021417
[00:23:12.293] iteration 16637 : model1 loss : 0.436432 model2 loss : 0.018406
[00:23:12.470] iteration 16638 : model1 loss : 0.439801 model2 loss : 0.020897
[00:23:12.646] iteration 16639 : model1 loss : 0.438556 model2 loss : 0.020295
[00:23:12.818] iteration 16640 : model1 loss : 0.434450 model2 loss : 0.019075
[00:23:12.994] iteration 16641 : model1 loss : 0.438470 model2 loss : 0.019919
[00:23:13.165] iteration 16642 : model1 loss : 0.432359 model2 loss : 0.018829
[00:23:13.341] iteration 16643 : model1 loss : 0.439157 model2 loss : 0.020939
[00:23:13.514] iteration 16644 : model1 loss : 0.436918 model2 loss : 0.018576
[00:23:13.691] iteration 16645 : model1 loss : 0.437526 model2 loss : 0.022688
[00:23:13.863] iteration 16646 : model1 loss : 0.438575 model2 loss : 0.019304
[00:23:14.035] iteration 16647 : model1 loss : 0.437580 model2 loss : 0.018775
[00:23:14.204] iteration 16648 : model1 loss : 0.436383 model2 loss : 0.020108
[00:23:14.383] iteration 16649 : model1 loss : 0.436678 model2 loss : 0.018294
[00:23:14.557] iteration 16650 : model1 loss : 0.433952 model2 loss : 0.020189
[00:23:14.731] iteration 16651 : model1 loss : 0.438653 model2 loss : 0.017715
[00:23:14.901] iteration 16652 : model1 loss : 0.436486 model2 loss : 0.020068
[00:23:15.076] iteration 16653 : model1 loss : 0.437414 model2 loss : 0.020293
[00:23:17.199] iteration 16654 : model1 loss : 0.438091 model2 loss : 0.021342
[00:23:17.372] iteration 16655 : model1 loss : 0.435907 model2 loss : 0.019177
[00:23:17.553] iteration 16656 : model1 loss : 0.432314 model2 loss : 0.018425
[00:23:17.725] iteration 16657 : model1 loss : 0.440202 model2 loss : 0.019452
[00:23:17.902] iteration 16658 : model1 loss : 0.440245 model2 loss : 0.019167
[00:23:18.072] iteration 16659 : model1 loss : 0.438609 model2 loss : 0.020705
[00:23:18.247] iteration 16660 : model1 loss : 0.434271 model2 loss : 0.018099
[00:23:18.419] iteration 16661 : model1 loss : 0.435542 model2 loss : 0.018099
[00:23:18.600] iteration 16662 : model1 loss : 0.439484 model2 loss : 0.019135
[00:23:18.771] iteration 16663 : model1 loss : 0.436045 model2 loss : 0.018448
[00:23:18.946] iteration 16664 : model1 loss : 0.434591 model2 loss : 0.019522
[00:23:19.118] iteration 16665 : model1 loss : 0.435687 model2 loss : 0.021640
[00:23:19.295] iteration 16666 : model1 loss : 0.438002 model2 loss : 0.017361
[00:23:19.465] iteration 16667 : model1 loss : 0.441624 model2 loss : 0.021309
[00:23:19.641] iteration 16668 : model1 loss : 0.435184 model2 loss : 0.020337
[00:23:19.811] iteration 16669 : model1 loss : 0.440342 model2 loss : 0.022805
[00:23:19.987] iteration 16670 : model1 loss : 0.438515 model2 loss : 0.019779
[00:23:20.160] iteration 16671 : model1 loss : 0.436604 model2 loss : 0.017997
[00:23:20.340] iteration 16672 : model1 loss : 0.437370 model2 loss : 0.020799
[00:23:20.514] iteration 16673 : model1 loss : 0.439944 model2 loss : 0.021790
[00:23:20.702] iteration 16674 : model1 loss : 0.436688 model2 loss : 0.021546
[00:23:22.913] iteration 16675 : model1 loss : 0.438280 model2 loss : 0.019515
[00:23:23.092] iteration 16676 : model1 loss : 0.438464 model2 loss : 0.019666
[00:23:23.271] iteration 16677 : model1 loss : 0.438704 model2 loss : 0.020023
[00:23:23.444] iteration 16678 : model1 loss : 0.436122 model2 loss : 0.020714
[00:23:23.621] iteration 16679 : model1 loss : 0.437382 model2 loss : 0.022564
[00:23:23.793] iteration 16680 : model1 loss : 0.440169 model2 loss : 0.021563
[00:23:23.969] iteration 16681 : model1 loss : 0.436504 model2 loss : 0.021325
[00:23:24.138] iteration 16682 : model1 loss : 0.440520 model2 loss : 0.020781
[00:23:24.318] iteration 16683 : model1 loss : 0.437053 model2 loss : 0.022188
[00:23:24.491] iteration 16684 : model1 loss : 0.434564 model2 loss : 0.019222
[00:23:24.669] iteration 16685 : model1 loss : 0.436069 model2 loss : 0.018918
[00:23:24.840] iteration 16686 : model1 loss : 0.440009 model2 loss : 0.020055
[00:23:25.017] iteration 16687 : model1 loss : 0.440414 model2 loss : 0.020822
[00:23:25.188] iteration 16688 : model1 loss : 0.439292 model2 loss : 0.020233
[00:23:25.363] iteration 16689 : model1 loss : 0.435540 model2 loss : 0.020472
[00:23:25.539] iteration 16690 : model1 loss : 0.434276 model2 loss : 0.020482
[00:23:25.714] iteration 16691 : model1 loss : 0.434732 model2 loss : 0.017719
[00:23:25.886] iteration 16692 : model1 loss : 0.436750 model2 loss : 0.017672
[00:23:26.066] iteration 16693 : model1 loss : 0.436653 model2 loss : 0.019053
[00:23:26.237] iteration 16694 : model1 loss : 0.435344 model2 loss : 0.020039
[00:23:26.411] iteration 16695 : model1 loss : 0.436664 model2 loss : 0.018800
[00:23:28.602] iteration 16696 : model1 loss : 0.434283 model2 loss : 0.019709
[00:23:28.776] iteration 16697 : model1 loss : 0.439908 model2 loss : 0.021670
[00:23:28.955] iteration 16698 : model1 loss : 0.433546 model2 loss : 0.018289
[00:23:29.127] iteration 16699 : model1 loss : 0.442251 model2 loss : 0.018149
[00:23:29.303] iteration 16700 : model1 loss : 0.435878 model2 loss : 0.019123
[00:23:29.476] iteration 16701 : model1 loss : 0.439143 model2 loss : 0.022239
[00:23:29.654] iteration 16702 : model1 loss : 0.437926 model2 loss : 0.021011
[00:23:29.825] iteration 16703 : model1 loss : 0.437404 model2 loss : 0.019339
[00:23:29.999] iteration 16704 : model1 loss : 0.441796 model2 loss : 0.021637
[00:23:30.170] iteration 16705 : model1 loss : 0.443476 model2 loss : 0.018578
[00:23:30.348] iteration 16706 : model1 loss : 0.438219 model2 loss : 0.021815
[00:23:30.522] iteration 16707 : model1 loss : 0.437516 model2 loss : 0.019553
[00:23:30.699] iteration 16708 : model1 loss : 0.434989 model2 loss : 0.018919
[00:23:30.871] iteration 16709 : model1 loss : 0.434387 model2 loss : 0.020126
[00:23:31.046] iteration 16710 : model1 loss : 0.436582 model2 loss : 0.018080
[00:23:31.218] iteration 16711 : model1 loss : 0.437290 model2 loss : 0.018628
[00:23:31.394] iteration 16712 : model1 loss : 0.438876 model2 loss : 0.022207
[00:23:31.567] iteration 16713 : model1 loss : 0.436609 model2 loss : 0.019661
[00:23:31.743] iteration 16714 : model1 loss : 0.437794 model2 loss : 0.019225
[00:23:31.913] iteration 16715 : model1 loss : 0.431472 model2 loss : 0.019002
[00:23:32.086] iteration 16716 : model1 loss : 0.439537 model2 loss : 0.016549
[00:23:34.225] iteration 16717 : model1 loss : 0.436886 model2 loss : 0.017416
[00:23:34.396] iteration 16718 : model1 loss : 0.438546 model2 loss : 0.021416
[00:23:34.576] iteration 16719 : model1 loss : 0.438874 model2 loss : 0.021231
[00:23:34.747] iteration 16720 : model1 loss : 0.435534 model2 loss : 0.018170
[00:23:34.926] iteration 16721 : model1 loss : 0.436267 model2 loss : 0.018976
[00:23:35.097] iteration 16722 : model1 loss : 0.432819 model2 loss : 0.019415
[00:23:35.276] iteration 16723 : model1 loss : 0.438201 model2 loss : 0.019942
[00:23:35.446] iteration 16724 : model1 loss : 0.440620 model2 loss : 0.021506
[00:23:35.625] iteration 16725 : model1 loss : 0.440166 model2 loss : 0.019467
[00:23:35.796] iteration 16726 : model1 loss : 0.435881 model2 loss : 0.018832
[00:23:35.970] iteration 16727 : model1 loss : 0.437808 model2 loss : 0.018610
[00:23:36.141] iteration 16728 : model1 loss : 0.435898 model2 loss : 0.020165
[00:23:36.320] iteration 16729 : model1 loss : 0.437690 model2 loss : 0.019835
[00:23:36.491] iteration 16730 : model1 loss : 0.440720 model2 loss : 0.021090
[00:23:36.666] iteration 16731 : model1 loss : 0.436184 model2 loss : 0.019651
[00:23:36.838] iteration 16732 : model1 loss : 0.438530 model2 loss : 0.020256
[00:23:37.015] iteration 16733 : model1 loss : 0.436320 model2 loss : 0.019504
[00:23:37.185] iteration 16734 : model1 loss : 0.438873 model2 loss : 0.019509
[00:23:37.362] iteration 16735 : model1 loss : 0.438067 model2 loss : 0.018429
[00:23:37.534] iteration 16736 : model1 loss : 0.437385 model2 loss : 0.019715
[00:23:37.707] iteration 16737 : model1 loss : 0.435778 model2 loss : 0.019382
[00:23:39.865] iteration 16738 : model1 loss : 0.436378 model2 loss : 0.019556
[00:23:40.041] iteration 16739 : model1 loss : 0.435257 model2 loss : 0.019744
[00:23:40.222] iteration 16740 : model1 loss : 0.437836 model2 loss : 0.020252
[00:23:40.395] iteration 16741 : model1 loss : 0.435013 model2 loss : 0.019551
[00:23:40.574] iteration 16742 : model1 loss : 0.432774 model2 loss : 0.020899
[00:23:40.745] iteration 16743 : model1 loss : 0.436694 model2 loss : 0.019459
[00:23:40.923] iteration 16744 : model1 loss : 0.438133 model2 loss : 0.018740
[00:23:41.094] iteration 16745 : model1 loss : 0.439316 model2 loss : 0.018902
[00:23:41.268] iteration 16746 : model1 loss : 0.435851 model2 loss : 0.018214
[00:23:41.438] iteration 16747 : model1 loss : 0.436848 model2 loss : 0.020392
[00:23:41.617] iteration 16748 : model1 loss : 0.439235 model2 loss : 0.021796
[00:23:41.787] iteration 16749 : model1 loss : 0.436505 model2 loss : 0.018063
[00:23:41.963] iteration 16750 : model1 loss : 0.435959 model2 loss : 0.018342
[00:23:42.134] iteration 16751 : model1 loss : 0.441664 model2 loss : 0.019271
[00:23:42.311] iteration 16752 : model1 loss : 0.436857 model2 loss : 0.018181
[00:23:42.487] iteration 16753 : model1 loss : 0.442220 model2 loss : 0.026148
[00:23:42.666] iteration 16754 : model1 loss : 0.438032 model2 loss : 0.019467
[00:23:42.837] iteration 16755 : model1 loss : 0.442231 model2 loss : 0.021851
[00:23:43.017] iteration 16756 : model1 loss : 0.437961 model2 loss : 0.018678
[00:23:43.184] iteration 16757 : model1 loss : 0.436988 model2 loss : 0.019708
[00:23:43.358] iteration 16758 : model1 loss : 0.435294 model2 loss : 0.019638
[00:23:45.471] iteration 16759 : model1 loss : 0.441828 model2 loss : 0.021778
[00:23:45.647] iteration 16760 : model1 loss : 0.435821 model2 loss : 0.018270
[00:23:45.824] iteration 16761 : model1 loss : 0.435685 model2 loss : 0.018882
[00:23:45.998] iteration 16762 : model1 loss : 0.438329 model2 loss : 0.019164
[00:23:46.174] iteration 16763 : model1 loss : 0.437527 model2 loss : 0.020821
[00:23:46.345] iteration 16764 : model1 loss : 0.431002 model2 loss : 0.018124
[00:23:46.528] iteration 16765 : model1 loss : 0.437624 model2 loss : 0.022775
[00:23:46.700] iteration 16766 : model1 loss : 0.438821 model2 loss : 0.019655
[00:23:46.874] iteration 16767 : model1 loss : 0.439377 model2 loss : 0.022765
[00:23:47.048] iteration 16768 : model1 loss : 0.438610 model2 loss : 0.021122
[00:23:47.238] iteration 16769 : model1 loss : 0.434614 model2 loss : 0.018583
[00:23:47.411] iteration 16770 : model1 loss : 0.439405 model2 loss : 0.020446
[00:23:47.590] iteration 16771 : model1 loss : 0.435361 model2 loss : 0.019249
[00:23:47.760] iteration 16772 : model1 loss : 0.437186 model2 loss : 0.021135
[00:23:47.935] iteration 16773 : model1 loss : 0.440302 model2 loss : 0.020956
[00:23:48.107] iteration 16774 : model1 loss : 0.440354 model2 loss : 0.020320
[00:23:48.285] iteration 16775 : model1 loss : 0.436673 model2 loss : 0.018178
[00:23:48.457] iteration 16776 : model1 loss : 0.436186 model2 loss : 0.019157
[00:23:48.637] iteration 16777 : model1 loss : 0.437912 model2 loss : 0.020973
[00:23:48.807] iteration 16778 : model1 loss : 0.439072 model2 loss : 0.018636
[00:23:48.981] iteration 16779 : model1 loss : 0.434644 model2 loss : 0.018939
[00:23:51.105] iteration 16780 : model1 loss : 0.443025 model2 loss : 0.022217
[00:23:51.281] iteration 16781 : model1 loss : 0.436991 model2 loss : 0.021436
[00:23:51.464] iteration 16782 : model1 loss : 0.436780 model2 loss : 0.019043
[00:23:51.636] iteration 16783 : model1 loss : 0.433155 model2 loss : 0.017782
[00:23:51.811] iteration 16784 : model1 loss : 0.437881 model2 loss : 0.019200
[00:23:51.983] iteration 16785 : model1 loss : 0.440890 model2 loss : 0.020347
[00:23:52.160] iteration 16786 : model1 loss : 0.439911 model2 loss : 0.020460
[00:23:52.334] iteration 16787 : model1 loss : 0.437536 model2 loss : 0.018640
[00:23:52.519] iteration 16788 : model1 loss : 0.438427 model2 loss : 0.019700
[00:23:52.690] iteration 16789 : model1 loss : 0.435081 model2 loss : 0.018841
[00:23:52.866] iteration 16790 : model1 loss : 0.436575 model2 loss : 0.020666
[00:23:53.036] iteration 16791 : model1 loss : 0.440602 model2 loss : 0.021489
[00:23:53.214] iteration 16792 : model1 loss : 0.438446 model2 loss : 0.024320
[00:23:53.385] iteration 16793 : model1 loss : 0.433816 model2 loss : 0.017067
[00:23:53.565] iteration 16794 : model1 loss : 0.438086 model2 loss : 0.019183
[00:23:53.737] iteration 16795 : model1 loss : 0.439915 model2 loss : 0.020604
[00:23:53.915] iteration 16796 : model1 loss : 0.433550 model2 loss : 0.017913
[00:23:54.086] iteration 16797 : model1 loss : 0.437184 model2 loss : 0.018354
[00:23:54.264] iteration 16798 : model1 loss : 0.434142 model2 loss : 0.018123
[00:23:54.435] iteration 16799 : model1 loss : 0.436911 model2 loss : 0.018197
[00:23:54.612] iteration 16800 : model1 loss : 0.441377 model2 loss : 0.019621
[00:23:56.725] iteration 16801 : model1 loss : 0.440804 model2 loss : 0.019297
[00:23:56.903] iteration 16802 : model1 loss : 0.433566 model2 loss : 0.020098
[00:23:57.083] iteration 16803 : model1 loss : 0.442299 model2 loss : 0.025079
[00:23:57.255] iteration 16804 : model1 loss : 0.435571 model2 loss : 0.019463
[00:23:57.435] iteration 16805 : model1 loss : 0.433086 model2 loss : 0.020994
[00:23:57.609] iteration 16806 : model1 loss : 0.438287 model2 loss : 0.018171
[00:23:57.785] iteration 16807 : model1 loss : 0.438232 model2 loss : 0.021869
[00:23:57.957] iteration 16808 : model1 loss : 0.438138 model2 loss : 0.020044
[00:23:58.133] iteration 16809 : model1 loss : 0.433017 model2 loss : 0.018562
[00:23:58.304] iteration 16810 : model1 loss : 0.439496 model2 loss : 0.022770
[00:23:58.481] iteration 16811 : model1 loss : 0.436482 model2 loss : 0.020128
[00:23:58.651] iteration 16812 : model1 loss : 0.436937 model2 loss : 0.018961
[00:23:58.829] iteration 16813 : model1 loss : 0.439714 model2 loss : 0.017813
[00:23:58.999] iteration 16814 : model1 loss : 0.438879 model2 loss : 0.019393
[00:23:59.173] iteration 16815 : model1 loss : 0.439685 model2 loss : 0.018706
[00:23:59.349] iteration 16816 : model1 loss : 0.441910 model2 loss : 0.020777
[00:23:59.530] iteration 16817 : model1 loss : 0.432892 model2 loss : 0.020049
[00:23:59.704] iteration 16818 : model1 loss : 0.442022 model2 loss : 0.019640
[00:23:59.878] iteration 16819 : model1 loss : 0.436344 model2 loss : 0.020759
[00:24:00.047] iteration 16820 : model1 loss : 0.439067 model2 loss : 0.018679
[00:24:00.227] iteration 16821 : model1 loss : 0.435261 model2 loss : 0.019608
[00:24:02.344] iteration 16822 : model1 loss : 0.436145 model2 loss : 0.018759
[00:24:02.520] iteration 16823 : model1 loss : 0.440202 model2 loss : 0.024197
[00:24:02.710] iteration 16824 : model1 loss : 0.441471 model2 loss : 0.022355
[00:24:02.880] iteration 16825 : model1 loss : 0.434269 model2 loss : 0.018903
[00:24:03.055] iteration 16826 : model1 loss : 0.430487 model2 loss : 0.019452
[00:24:03.226] iteration 16827 : model1 loss : 0.437584 model2 loss : 0.022263
[00:24:03.402] iteration 16828 : model1 loss : 0.439814 model2 loss : 0.021530
[00:24:03.573] iteration 16829 : model1 loss : 0.440649 model2 loss : 0.019877
[00:24:03.747] iteration 16830 : model1 loss : 0.436246 model2 loss : 0.019874
[00:24:03.917] iteration 16831 : model1 loss : 0.440549 model2 loss : 0.020519
[00:24:04.095] iteration 16832 : model1 loss : 0.437671 model2 loss : 0.020919
[00:24:04.266] iteration 16833 : model1 loss : 0.442438 model2 loss : 0.021162
[00:24:04.441] iteration 16834 : model1 loss : 0.438040 model2 loss : 0.021630
[00:24:04.615] iteration 16835 : model1 loss : 0.437272 model2 loss : 0.018110
[00:24:04.794] iteration 16836 : model1 loss : 0.437977 model2 loss : 0.022054
[00:24:04.964] iteration 16837 : model1 loss : 0.437793 model2 loss : 0.020296
[00:24:05.141] iteration 16838 : model1 loss : 0.437308 model2 loss : 0.019696
[00:24:05.314] iteration 16839 : model1 loss : 0.436888 model2 loss : 0.018254
[00:24:05.491] iteration 16840 : model1 loss : 0.434495 model2 loss : 0.017174
[00:24:05.661] iteration 16841 : model1 loss : 0.437367 model2 loss : 0.019228
[00:24:05.836] iteration 16842 : model1 loss : 0.435898 model2 loss : 0.018853
[00:24:08.002] iteration 16843 : model1 loss : 0.434001 model2 loss : 0.018276
[00:24:08.175] iteration 16844 : model1 loss : 0.436719 model2 loss : 0.020598
[00:24:08.358] iteration 16845 : model1 loss : 0.439429 model2 loss : 0.020398
[00:24:08.532] iteration 16846 : model1 loss : 0.434081 model2 loss : 0.019398
[00:24:08.709] iteration 16847 : model1 loss : 0.441727 model2 loss : 0.019220
[00:24:08.880] iteration 16848 : model1 loss : 0.437495 model2 loss : 0.022222
[00:24:09.056] iteration 16849 : model1 loss : 0.438036 model2 loss : 0.020237
[00:24:09.226] iteration 16850 : model1 loss : 0.433624 model2 loss : 0.018331
[00:24:09.401] iteration 16851 : model1 loss : 0.437696 model2 loss : 0.020501
[00:24:09.574] iteration 16852 : model1 loss : 0.436328 model2 loss : 0.019301
[00:24:09.751] iteration 16853 : model1 loss : 0.437270 model2 loss : 0.017276
[00:24:09.923] iteration 16854 : model1 loss : 0.439095 model2 loss : 0.019780
[00:24:10.098] iteration 16855 : model1 loss : 0.437655 model2 loss : 0.020650
[00:24:10.267] iteration 16856 : model1 loss : 0.435231 model2 loss : 0.026043
[00:24:10.446] iteration 16857 : model1 loss : 0.438500 model2 loss : 0.018520
[00:24:10.618] iteration 16858 : model1 loss : 0.441055 model2 loss : 0.019835
[00:24:10.799] iteration 16859 : model1 loss : 0.438677 model2 loss : 0.020562
[00:24:10.970] iteration 16860 : model1 loss : 0.436307 model2 loss : 0.017228
[00:24:11.148] iteration 16861 : model1 loss : 0.437914 model2 loss : 0.020370
[00:24:11.319] iteration 16862 : model1 loss : 0.439877 model2 loss : 0.021557
[00:24:11.496] iteration 16863 : model1 loss : 0.434736 model2 loss : 0.019330
[00:24:13.685] iteration 16864 : model1 loss : 0.437157 model2 loss : 0.019061
[00:24:13.859] iteration 16865 : model1 loss : 0.435965 model2 loss : 0.017672
[00:24:14.040] iteration 16866 : model1 loss : 0.438707 model2 loss : 0.021204
[00:24:14.212] iteration 16867 : model1 loss : 0.435541 model2 loss : 0.018347
[00:24:14.390] iteration 16868 : model1 loss : 0.440609 model2 loss : 0.018196
[00:24:14.565] iteration 16869 : model1 loss : 0.438141 model2 loss : 0.018728
[00:24:14.741] iteration 16870 : model1 loss : 0.441234 model2 loss : 0.022383
[00:24:14.912] iteration 16871 : model1 loss : 0.434113 model2 loss : 0.022179
[00:24:15.089] iteration 16872 : model1 loss : 0.434789 model2 loss : 0.022161
[00:24:15.260] iteration 16873 : model1 loss : 0.437809 model2 loss : 0.016734
[00:24:15.438] iteration 16874 : model1 loss : 0.437817 model2 loss : 0.021095
[00:24:15.613] iteration 16875 : model1 loss : 0.442690 model2 loss : 0.026179
[00:24:15.792] iteration 16876 : model1 loss : 0.439073 model2 loss : 0.020048
[00:24:15.964] iteration 16877 : model1 loss : 0.438873 model2 loss : 0.022086
[00:24:16.140] iteration 16878 : model1 loss : 0.434926 model2 loss : 0.020100
[00:24:16.313] iteration 16879 : model1 loss : 0.433645 model2 loss : 0.018167
[00:24:16.491] iteration 16880 : model1 loss : 0.438399 model2 loss : 0.020878
[00:24:16.664] iteration 16881 : model1 loss : 0.438459 model2 loss : 0.021131
[00:24:16.840] iteration 16882 : model1 loss : 0.436384 model2 loss : 0.021920
[00:24:17.010] iteration 16883 : model1 loss : 0.437147 model2 loss : 0.018620
[00:24:17.185] iteration 16884 : model1 loss : 0.435882 model2 loss : 0.019087
[00:24:19.384] iteration 16885 : model1 loss : 0.439034 model2 loss : 0.018797
[00:24:19.561] iteration 16886 : model1 loss : 0.431030 model2 loss : 0.018047
[00:24:19.739] iteration 16887 : model1 loss : 0.439115 model2 loss : 0.019609
[00:24:19.911] iteration 16888 : model1 loss : 0.436199 model2 loss : 0.019415
[00:24:20.087] iteration 16889 : model1 loss : 0.439780 model2 loss : 0.019494
[00:24:20.259] iteration 16890 : model1 loss : 0.437368 model2 loss : 0.021165
[00:24:20.435] iteration 16891 : model1 loss : 0.436083 model2 loss : 0.019235
[00:24:20.610] iteration 16892 : model1 loss : 0.437580 model2 loss : 0.021307
[00:24:20.785] iteration 16893 : model1 loss : 0.438200 model2 loss : 0.019199
[00:24:20.960] iteration 16894 : model1 loss : 0.435023 model2 loss : 0.020834
[00:24:21.135] iteration 16895 : model1 loss : 0.438517 model2 loss : 0.021103
[00:24:21.310] iteration 16896 : model1 loss : 0.442579 model2 loss : 0.021470
[00:24:21.488] iteration 16897 : model1 loss : 0.437763 model2 loss : 0.021255
[00:24:21.661] iteration 16898 : model1 loss : 0.436495 model2 loss : 0.018152
[00:24:21.851] iteration 16899 : model1 loss : 0.435886 model2 loss : 0.019577
[00:24:22.023] iteration 16900 : model1 loss : 0.437944 model2 loss : 0.019642
[00:24:22.197] iteration 16901 : model1 loss : 0.438470 model2 loss : 0.018461
[00:24:22.370] iteration 16902 : model1 loss : 0.435279 model2 loss : 0.019162
[00:24:22.547] iteration 16903 : model1 loss : 0.442357 model2 loss : 0.023155
[00:24:22.716] iteration 16904 : model1 loss : 0.433478 model2 loss : 0.020173
[00:24:22.890] iteration 16905 : model1 loss : 0.440338 model2 loss : 0.020808
[00:24:25.016] iteration 16906 : model1 loss : 0.437597 model2 loss : 0.018463
[00:24:25.188] iteration 16907 : model1 loss : 0.440554 model2 loss : 0.021675
[00:24:25.369] iteration 16908 : model1 loss : 0.434297 model2 loss : 0.020973
[00:24:25.542] iteration 16909 : model1 loss : 0.437401 model2 loss : 0.017891
[00:24:25.717] iteration 16910 : model1 loss : 0.441445 model2 loss : 0.021695
[00:24:25.892] iteration 16911 : model1 loss : 0.435053 model2 loss : 0.017944
[00:24:26.068] iteration 16912 : model1 loss : 0.436617 model2 loss : 0.021880
[00:24:26.242] iteration 16913 : model1 loss : 0.436151 model2 loss : 0.021776
[00:24:26.422] iteration 16914 : model1 loss : 0.437816 model2 loss : 0.020196
[00:24:26.601] iteration 16915 : model1 loss : 0.434768 model2 loss : 0.017387
[00:24:26.776] iteration 16916 : model1 loss : 0.434303 model2 loss : 0.019333
[00:24:26.950] iteration 16917 : model1 loss : 0.437233 model2 loss : 0.017956
[00:24:27.131] iteration 16918 : model1 loss : 0.436358 model2 loss : 0.019444
[00:24:27.307] iteration 16919 : model1 loss : 0.436872 model2 loss : 0.020906
[00:24:27.493] iteration 16920 : model1 loss : 0.435292 model2 loss : 0.018464
[00:24:27.670] iteration 16921 : model1 loss : 0.440518 model2 loss : 0.020437
[00:24:27.848] iteration 16922 : model1 loss : 0.438399 model2 loss : 0.018617
[00:24:28.019] iteration 16923 : model1 loss : 0.438776 model2 loss : 0.020067
[00:24:28.197] iteration 16924 : model1 loss : 0.438665 model2 loss : 0.018001
[00:24:28.368] iteration 16925 : model1 loss : 0.439340 model2 loss : 0.023122
[00:24:28.543] iteration 16926 : model1 loss : 0.437598 model2 loss : 0.019563
[00:24:30.838] iteration 16927 : model1 loss : 0.437609 model2 loss : 0.019865
[00:24:31.011] iteration 16928 : model1 loss : 0.439211 model2 loss : 0.019590
[00:24:31.195] iteration 16929 : model1 loss : 0.436246 model2 loss : 0.016703
[00:24:31.369] iteration 16930 : model1 loss : 0.439606 model2 loss : 0.020279
[00:24:31.551] iteration 16931 : model1 loss : 0.438790 model2 loss : 0.018056
[00:24:31.728] iteration 16932 : model1 loss : 0.434055 model2 loss : 0.017769
[00:24:31.905] iteration 16933 : model1 loss : 0.433895 model2 loss : 0.018424
[00:24:32.078] iteration 16934 : model1 loss : 0.439443 model2 loss : 0.022087
[00:24:32.262] iteration 16935 : model1 loss : 0.435499 model2 loss : 0.020173
[00:24:32.439] iteration 16936 : model1 loss : 0.438420 model2 loss : 0.021515
[00:24:32.615] iteration 16937 : model1 loss : 0.430681 model2 loss : 0.017724
[00:24:32.785] iteration 16938 : model1 loss : 0.437715 model2 loss : 0.020131
[00:24:32.966] iteration 16939 : model1 loss : 0.438727 model2 loss : 0.017979
[00:24:33.139] iteration 16940 : model1 loss : 0.439848 model2 loss : 0.019758
[00:24:33.320] iteration 16941 : model1 loss : 0.439632 model2 loss : 0.019530
[00:24:33.494] iteration 16942 : model1 loss : 0.437892 model2 loss : 0.020077
[00:24:33.670] iteration 16943 : model1 loss : 0.437813 model2 loss : 0.019360
[00:24:33.843] iteration 16944 : model1 loss : 0.437417 model2 loss : 0.020284
[00:24:34.022] iteration 16945 : model1 loss : 0.436743 model2 loss : 0.017917
[00:24:34.193] iteration 16946 : model1 loss : 0.439225 model2 loss : 0.018564
[00:24:34.367] iteration 16947 : model1 loss : 0.435201 model2 loss : 0.019748
[00:24:36.583] iteration 16948 : model1 loss : 0.434642 model2 loss : 0.018673
[00:24:36.755] iteration 16949 : model1 loss : 0.436355 model2 loss : 0.018688
[00:24:36.936] iteration 16950 : model1 loss : 0.431180 model2 loss : 0.017704
[00:24:37.115] iteration 16951 : model1 loss : 0.441909 model2 loss : 0.021252
[00:24:37.291] iteration 16952 : model1 loss : 0.433105 model2 loss : 0.018907
[00:24:37.469] iteration 16953 : model1 loss : 0.438478 model2 loss : 0.021061
[00:24:37.645] iteration 16954 : model1 loss : 0.435116 model2 loss : 0.019629
[00:24:37.818] iteration 16955 : model1 loss : 0.444017 model2 loss : 0.021726
[00:24:37.995] iteration 16956 : model1 loss : 0.434524 model2 loss : 0.017362
[00:24:38.167] iteration 16957 : model1 loss : 0.438167 model2 loss : 0.019160
[00:24:38.345] iteration 16958 : model1 loss : 0.436735 model2 loss : 0.018390
[00:24:38.519] iteration 16959 : model1 loss : 0.439071 model2 loss : 0.020148
[00:24:38.697] iteration 16960 : model1 loss : 0.438015 model2 loss : 0.018748
[00:24:38.868] iteration 16961 : model1 loss : 0.439471 model2 loss : 0.022662
[00:24:39.047] iteration 16962 : model1 loss : 0.439189 model2 loss : 0.023401
[00:24:39.223] iteration 16963 : model1 loss : 0.439606 model2 loss : 0.020009
[00:24:39.403] iteration 16964 : model1 loss : 0.439706 model2 loss : 0.017799
[00:24:39.577] iteration 16965 : model1 loss : 0.445164 model2 loss : 0.023706
[00:24:39.756] iteration 16966 : model1 loss : 0.438586 model2 loss : 0.020545
[00:24:39.924] iteration 16967 : model1 loss : 0.434122 model2 loss : 0.019758
[00:24:40.098] iteration 16968 : model1 loss : 0.431956 model2 loss : 0.020572
[00:24:42.222] iteration 16969 : model1 loss : 0.439487 model2 loss : 0.019263
[00:24:42.398] iteration 16970 : model1 loss : 0.432202 model2 loss : 0.017074
[00:24:42.580] iteration 16971 : model1 loss : 0.436349 model2 loss : 0.020071
[00:24:42.750] iteration 16972 : model1 loss : 0.435534 model2 loss : 0.020047
[00:24:42.928] iteration 16973 : model1 loss : 0.437069 model2 loss : 0.017476
[00:24:43.101] iteration 16974 : model1 loss : 0.437709 model2 loss : 0.019090
[00:24:43.277] iteration 16975 : model1 loss : 0.440001 model2 loss : 0.020294
[00:24:43.451] iteration 16976 : model1 loss : 0.433408 model2 loss : 0.019163
[00:24:43.627] iteration 16977 : model1 loss : 0.435997 model2 loss : 0.020771
[00:24:43.798] iteration 16978 : model1 loss : 0.438926 model2 loss : 0.021201
[00:24:43.976] iteration 16979 : model1 loss : 0.436992 model2 loss : 0.019307
[00:24:44.149] iteration 16980 : model1 loss : 0.436451 model2 loss : 0.021348
[00:24:44.332] iteration 16981 : model1 loss : 0.437121 model2 loss : 0.019474
[00:24:44.505] iteration 16982 : model1 loss : 0.438888 model2 loss : 0.020097
[00:24:44.680] iteration 16983 : model1 loss : 0.441671 model2 loss : 0.019054
[00:24:44.852] iteration 16984 : model1 loss : 0.440079 model2 loss : 0.019144
[00:24:45.029] iteration 16985 : model1 loss : 0.437808 model2 loss : 0.019096
[00:24:45.202] iteration 16986 : model1 loss : 0.434975 model2 loss : 0.017145
[00:24:45.381] iteration 16987 : model1 loss : 0.437339 model2 loss : 0.019173
[00:24:45.552] iteration 16988 : model1 loss : 0.436685 model2 loss : 0.021232
[00:24:45.724] iteration 16989 : model1 loss : 0.437919 model2 loss : 0.018867
[00:24:47.885] iteration 16990 : model1 loss : 0.438509 model2 loss : 0.020641
[00:24:48.059] iteration 16991 : model1 loss : 0.437221 model2 loss : 0.020347
[00:24:48.241] iteration 16992 : model1 loss : 0.437647 model2 loss : 0.018292
[00:24:48.416] iteration 16993 : model1 loss : 0.435595 model2 loss : 0.017320
[00:24:48.595] iteration 16994 : model1 loss : 0.434267 model2 loss : 0.018159
[00:24:48.766] iteration 16995 : model1 loss : 0.438554 model2 loss : 0.020730
[00:24:48.941] iteration 16996 : model1 loss : 0.438304 model2 loss : 0.021537
[00:24:49.115] iteration 16997 : model1 loss : 0.439515 model2 loss : 0.020157
[00:24:49.295] iteration 16998 : model1 loss : 0.437340 model2 loss : 0.019708
[00:24:49.469] iteration 16999 : model1 loss : 0.437291 model2 loss : 0.020443
[00:24:49.643] iteration 17000 : model1 loss : 0.432106 model2 loss : 0.018241
[00:24:58.846] iteration 17000 : model1_mean_dice : 0.866073 model1_mean_hd95 : 6.085710
[00:25:08.064] iteration 17000 : model2_mean_dice : 0.864437 model2_mean_hd95 : 6.495880
[00:25:08.243] iteration 17001 : model1 loss : 0.437032 model2 loss : 0.018688
[00:25:08.423] iteration 17002 : model1 loss : 0.433401 model2 loss : 0.019022
[00:25:08.597] iteration 17003 : model1 loss : 0.436729 model2 loss : 0.017911
[00:25:08.771] iteration 17004 : model1 loss : 0.440785 model2 loss : 0.021048
[00:25:08.941] iteration 17005 : model1 loss : 0.433638 model2 loss : 0.021161
[00:25:09.117] iteration 17006 : model1 loss : 0.437722 model2 loss : 0.018270
[00:25:09.287] iteration 17007 : model1 loss : 0.439030 model2 loss : 0.020190
[00:25:09.462] iteration 17008 : model1 loss : 0.437530 model2 loss : 0.019611
[00:25:09.632] iteration 17009 : model1 loss : 0.439884 model2 loss : 0.021053
[00:25:09.805] iteration 17010 : model1 loss : 0.443073 model2 loss : 0.020223
[00:25:12.005] iteration 17011 : model1 loss : 0.439918 model2 loss : 0.022021
[00:25:12.184] iteration 17012 : model1 loss : 0.436513 model2 loss : 0.017969
[00:25:12.364] iteration 17013 : model1 loss : 0.436878 model2 loss : 0.021754
[00:25:12.539] iteration 17014 : model1 loss : 0.437701 model2 loss : 0.021436
[00:25:12.715] iteration 17015 : model1 loss : 0.436295 model2 loss : 0.018852
[00:25:12.885] iteration 17016 : model1 loss : 0.436944 model2 loss : 0.016848
[00:25:13.059] iteration 17017 : model1 loss : 0.436916 model2 loss : 0.018520
[00:25:13.236] iteration 17018 : model1 loss : 0.436694 model2 loss : 0.020361
[00:25:13.411] iteration 17019 : model1 loss : 0.434969 model2 loss : 0.019277
[00:25:13.584] iteration 17020 : model1 loss : 0.444369 model2 loss : 0.022035
[00:25:13.765] iteration 17021 : model1 loss : 0.435923 model2 loss : 0.021578
[00:25:13.936] iteration 17022 : model1 loss : 0.441891 model2 loss : 0.022451
[00:25:14.110] iteration 17023 : model1 loss : 0.435688 model2 loss : 0.018252
[00:25:14.283] iteration 17024 : model1 loss : 0.437079 model2 loss : 0.020867
[00:25:14.461] iteration 17025 : model1 loss : 0.438034 model2 loss : 0.019429
[00:25:14.635] iteration 17026 : model1 loss : 0.436914 model2 loss : 0.020638
[00:25:14.809] iteration 17027 : model1 loss : 0.434998 model2 loss : 0.018422
[00:25:14.978] iteration 17028 : model1 loss : 0.436646 model2 loss : 0.017356
[00:25:15.156] iteration 17029 : model1 loss : 0.432190 model2 loss : 0.020900
[00:25:15.328] iteration 17030 : model1 loss : 0.440015 model2 loss : 0.019822
[00:25:15.501] iteration 17031 : model1 loss : 0.438090 model2 loss : 0.019099
[00:25:17.698] iteration 17032 : model1 loss : 0.435808 model2 loss : 0.017873
[00:25:17.870] iteration 17033 : model1 loss : 0.435299 model2 loss : 0.020177
[00:25:18.052] iteration 17034 : model1 loss : 0.439197 model2 loss : 0.020205
[00:25:18.226] iteration 17035 : model1 loss : 0.436504 model2 loss : 0.020176
[00:25:18.405] iteration 17036 : model1 loss : 0.436250 model2 loss : 0.018803
[00:25:18.576] iteration 17037 : model1 loss : 0.437815 model2 loss : 0.020596
[00:25:18.755] iteration 17038 : model1 loss : 0.435404 model2 loss : 0.017680
[00:25:18.925] iteration 17039 : model1 loss : 0.436911 model2 loss : 0.021101
[00:25:19.099] iteration 17040 : model1 loss : 0.436146 model2 loss : 0.020296
[00:25:19.270] iteration 17041 : model1 loss : 0.440389 model2 loss : 0.020006
[00:25:19.450] iteration 17042 : model1 loss : 0.439478 model2 loss : 0.020491
[00:25:19.626] iteration 17043 : model1 loss : 0.430336 model2 loss : 0.017409
[00:25:19.799] iteration 17044 : model1 loss : 0.440142 model2 loss : 0.020284
[00:25:19.970] iteration 17045 : model1 loss : 0.436451 model2 loss : 0.019757
[00:25:20.145] iteration 17046 : model1 loss : 0.440103 model2 loss : 0.019613
[00:25:20.316] iteration 17047 : model1 loss : 0.436500 model2 loss : 0.018452
[00:25:20.493] iteration 17048 : model1 loss : 0.438425 model2 loss : 0.019009
[00:25:20.666] iteration 17049 : model1 loss : 0.437030 model2 loss : 0.019500
[00:25:20.839] iteration 17050 : model1 loss : 0.439023 model2 loss : 0.023198
[00:25:21.008] iteration 17051 : model1 loss : 0.439203 model2 loss : 0.020049
[00:25:21.182] iteration 17052 : model1 loss : 0.440138 model2 loss : 0.021166
[00:25:23.367] iteration 17053 : model1 loss : 0.436762 model2 loss : 0.018031
[00:25:23.553] iteration 17054 : model1 loss : 0.434536 model2 loss : 0.020729
[00:25:23.730] iteration 17055 : model1 loss : 0.436706 model2 loss : 0.018886
[00:25:23.902] iteration 17056 : model1 loss : 0.440073 model2 loss : 0.020483
[00:25:24.076] iteration 17057 : model1 loss : 0.434507 model2 loss : 0.018975
[00:25:24.246] iteration 17058 : model1 loss : 0.438275 model2 loss : 0.018649
[00:25:24.423] iteration 17059 : model1 loss : 0.440174 model2 loss : 0.019424
[00:25:24.597] iteration 17060 : model1 loss : 0.440273 model2 loss : 0.019606
[00:25:24.770] iteration 17061 : model1 loss : 0.436273 model2 loss : 0.018911
[00:25:24.940] iteration 17062 : model1 loss : 0.442615 model2 loss : 0.021790
[00:25:25.118] iteration 17063 : model1 loss : 0.440722 model2 loss : 0.020854
[00:25:25.289] iteration 17064 : model1 loss : 0.436767 model2 loss : 0.018718
[00:25:25.465] iteration 17065 : model1 loss : 0.438893 model2 loss : 0.018161
[00:25:25.637] iteration 17066 : model1 loss : 0.433664 model2 loss : 0.018717
[00:25:25.813] iteration 17067 : model1 loss : 0.435049 model2 loss : 0.018867
[00:25:25.985] iteration 17068 : model1 loss : 0.434874 model2 loss : 0.019034
[00:25:26.161] iteration 17069 : model1 loss : 0.438346 model2 loss : 0.019494
[00:25:26.337] iteration 17070 : model1 loss : 0.435571 model2 loss : 0.019316
[00:25:26.517] iteration 17071 : model1 loss : 0.437720 model2 loss : 0.020474
[00:25:26.687] iteration 17072 : model1 loss : 0.438202 model2 loss : 0.018389
[00:25:26.861] iteration 17073 : model1 loss : 0.438315 model2 loss : 0.019239
[00:25:29.029] iteration 17074 : model1 loss : 0.439787 model2 loss : 0.020582
[00:25:29.202] iteration 17075 : model1 loss : 0.437893 model2 loss : 0.018458
[00:25:29.382] iteration 17076 : model1 loss : 0.433325 model2 loss : 0.018422
[00:25:29.554] iteration 17077 : model1 loss : 0.435625 model2 loss : 0.018394
[00:25:29.729] iteration 17078 : model1 loss : 0.439975 model2 loss : 0.020233
[00:25:29.899] iteration 17079 : model1 loss : 0.437418 model2 loss : 0.019015
[00:25:30.072] iteration 17080 : model1 loss : 0.436906 model2 loss : 0.019479
[00:25:30.243] iteration 17081 : model1 loss : 0.435097 model2 loss : 0.019714
[00:25:30.422] iteration 17082 : model1 loss : 0.439531 model2 loss : 0.018313
[00:25:30.594] iteration 17083 : model1 loss : 0.436922 model2 loss : 0.019411
[00:25:30.769] iteration 17084 : model1 loss : 0.437941 model2 loss : 0.017493
[00:25:30.938] iteration 17085 : model1 loss : 0.436886 model2 loss : 0.018261
[00:25:31.114] iteration 17086 : model1 loss : 0.438484 model2 loss : 0.020688
[00:25:31.284] iteration 17087 : model1 loss : 0.437724 model2 loss : 0.019983
[00:25:31.459] iteration 17088 : model1 loss : 0.435981 model2 loss : 0.018829
[00:25:31.633] iteration 17089 : model1 loss : 0.436194 model2 loss : 0.018667
[00:25:31.808] iteration 17090 : model1 loss : 0.437890 model2 loss : 0.018929
[00:25:31.979] iteration 17091 : model1 loss : 0.441267 model2 loss : 0.021023
[00:25:32.154] iteration 17092 : model1 loss : 0.434815 model2 loss : 0.020515
[00:25:32.326] iteration 17093 : model1 loss : 0.438584 model2 loss : 0.022702
[00:25:32.505] iteration 17094 : model1 loss : 0.436127 model2 loss : 0.018723
[00:25:34.640] iteration 17095 : model1 loss : 0.437765 model2 loss : 0.017617
[00:25:34.817] iteration 17096 : model1 loss : 0.436144 model2 loss : 0.019107
[00:25:34.994] iteration 17097 : model1 loss : 0.436498 model2 loss : 0.019254
[00:25:35.165] iteration 17098 : model1 loss : 0.432703 model2 loss : 0.018001
[00:25:35.341] iteration 17099 : model1 loss : 0.441831 model2 loss : 0.020681
[00:25:35.515] iteration 17100 : model1 loss : 0.435370 model2 loss : 0.019401
[00:25:35.695] iteration 17101 : model1 loss : 0.442194 model2 loss : 0.022524
[00:25:35.867] iteration 17102 : model1 loss : 0.434815 model2 loss : 0.017470
[00:25:36.044] iteration 17103 : model1 loss : 0.438663 model2 loss : 0.020136
[00:25:36.222] iteration 17104 : model1 loss : 0.439572 model2 loss : 0.021527
[00:25:36.401] iteration 17105 : model1 loss : 0.439795 model2 loss : 0.019800
[00:25:36.576] iteration 17106 : model1 loss : 0.433881 model2 loss : 0.018110
[00:25:36.752] iteration 17107 : model1 loss : 0.433835 model2 loss : 0.019485
[00:25:36.923] iteration 17108 : model1 loss : 0.436673 model2 loss : 0.020196
[00:25:37.097] iteration 17109 : model1 loss : 0.442406 model2 loss : 0.023229
[00:25:37.267] iteration 17110 : model1 loss : 0.438155 model2 loss : 0.021177
[00:25:37.446] iteration 17111 : model1 loss : 0.435965 model2 loss : 0.019525
[00:25:37.621] iteration 17112 : model1 loss : 0.438215 model2 loss : 0.017624
[00:25:37.798] iteration 17113 : model1 loss : 0.439312 model2 loss : 0.018128
[00:25:37.966] iteration 17114 : model1 loss : 0.438258 model2 loss : 0.020306
[00:25:38.140] iteration 17115 : model1 loss : 0.433572 model2 loss : 0.018766
[00:25:40.273] iteration 17116 : model1 loss : 0.430979 model2 loss : 0.017841
[00:25:40.448] iteration 17117 : model1 loss : 0.444010 model2 loss : 0.020186
[00:25:40.629] iteration 17118 : model1 loss : 0.437219 model2 loss : 0.017450
[00:25:40.801] iteration 17119 : model1 loss : 0.437932 model2 loss : 0.020751
[00:25:40.982] iteration 17120 : model1 loss : 0.433530 model2 loss : 0.017729
[00:25:41.152] iteration 17121 : model1 loss : 0.437603 model2 loss : 0.018545
[00:25:41.331] iteration 17122 : model1 loss : 0.433937 model2 loss : 0.018400
[00:25:41.502] iteration 17123 : model1 loss : 0.439104 model2 loss : 0.021066
[00:25:41.678] iteration 17124 : model1 loss : 0.443250 model2 loss : 0.022968
[00:25:41.849] iteration 17125 : model1 loss : 0.433796 model2 loss : 0.017750
[00:25:42.028] iteration 17126 : model1 loss : 0.435104 model2 loss : 0.019569
[00:25:42.200] iteration 17127 : model1 loss : 0.438222 model2 loss : 0.020788
[00:25:42.377] iteration 17128 : model1 loss : 0.435462 model2 loss : 0.019688
[00:25:42.552] iteration 17129 : model1 loss : 0.438637 model2 loss : 0.018221
[00:25:42.726] iteration 17130 : model1 loss : 0.434866 model2 loss : 0.016247
[00:25:42.896] iteration 17131 : model1 loss : 0.440465 model2 loss : 0.021021
[00:25:43.070] iteration 17132 : model1 loss : 0.434971 model2 loss : 0.020384
[00:25:43.240] iteration 17133 : model1 loss : 0.435135 model2 loss : 0.019213
[00:25:43.419] iteration 17134 : model1 loss : 0.438844 model2 loss : 0.020320
[00:25:43.590] iteration 17135 : model1 loss : 0.440153 model2 loss : 0.021598
[00:25:43.765] iteration 17136 : model1 loss : 0.441320 model2 loss : 0.018348
[00:25:45.913] iteration 17137 : model1 loss : 0.437513 model2 loss : 0.018475
[00:25:46.090] iteration 17138 : model1 loss : 0.440196 model2 loss : 0.020059
[00:25:46.269] iteration 17139 : model1 loss : 0.434266 model2 loss : 0.018763
[00:25:46.440] iteration 17140 : model1 loss : 0.433948 model2 loss : 0.017502
[00:25:46.616] iteration 17141 : model1 loss : 0.437310 model2 loss : 0.018020
[00:25:46.787] iteration 17142 : model1 loss : 0.437317 model2 loss : 0.020750
[00:25:46.964] iteration 17143 : model1 loss : 0.435414 model2 loss : 0.018349
[00:25:47.135] iteration 17144 : model1 loss : 0.443791 model2 loss : 0.023264
[00:25:47.314] iteration 17145 : model1 loss : 0.439400 model2 loss : 0.016889
[00:25:47.490] iteration 17146 : model1 loss : 0.439497 model2 loss : 0.022168
[00:25:47.666] iteration 17147 : model1 loss : 0.437088 model2 loss : 0.019671
[00:25:47.838] iteration 17148 : model1 loss : 0.440043 model2 loss : 0.020058
[00:25:48.013] iteration 17149 : model1 loss : 0.439147 model2 loss : 0.020592
[00:25:48.185] iteration 17150 : model1 loss : 0.435501 model2 loss : 0.019703
[00:25:48.363] iteration 17151 : model1 loss : 0.435647 model2 loss : 0.018626
[00:25:48.535] iteration 17152 : model1 loss : 0.438239 model2 loss : 0.019098
[00:25:48.708] iteration 17153 : model1 loss : 0.438875 model2 loss : 0.019447
[00:25:48.881] iteration 17154 : model1 loss : 0.438676 model2 loss : 0.020041
[00:25:49.058] iteration 17155 : model1 loss : 0.432636 model2 loss : 0.018249
[00:25:49.227] iteration 17156 : model1 loss : 0.437894 model2 loss : 0.019436
[00:25:49.399] iteration 17157 : model1 loss : 0.434818 model2 loss : 0.018702
[00:25:51.618] iteration 17158 : model1 loss : 0.437949 model2 loss : 0.019409
[00:25:51.787] iteration 17159 : model1 loss : 0.438152 model2 loss : 0.021221
[00:25:51.967] iteration 17160 : model1 loss : 0.437555 model2 loss : 0.019381
[00:25:52.138] iteration 17161 : model1 loss : 0.436750 model2 loss : 0.019114
[00:25:52.317] iteration 17162 : model1 loss : 0.434469 model2 loss : 0.019126
[00:25:52.492] iteration 17163 : model1 loss : 0.445469 model2 loss : 0.023987
[00:25:52.666] iteration 17164 : model1 loss : 0.434579 model2 loss : 0.018253
[00:25:52.835] iteration 17165 : model1 loss : 0.438533 model2 loss : 0.020779
[00:25:53.012] iteration 17166 : model1 loss : 0.434480 model2 loss : 0.020671
[00:25:53.182] iteration 17167 : model1 loss : 0.440142 model2 loss : 0.019498
[00:25:53.357] iteration 17168 : model1 loss : 0.436023 model2 loss : 0.020275
[00:25:53.527] iteration 17169 : model1 loss : 0.438607 model2 loss : 0.018537
[00:25:53.702] iteration 17170 : model1 loss : 0.438789 model2 loss : 0.019627
[00:25:53.876] iteration 17171 : model1 loss : 0.435269 model2 loss : 0.019258
[00:25:54.051] iteration 17172 : model1 loss : 0.439370 model2 loss : 0.018318
[00:25:54.223] iteration 17173 : model1 loss : 0.435584 model2 loss : 0.018553
[00:25:54.400] iteration 17174 : model1 loss : 0.436751 model2 loss : 0.019182
[00:25:54.572] iteration 17175 : model1 loss : 0.435993 model2 loss : 0.017591
[00:25:54.746] iteration 17176 : model1 loss : 0.437301 model2 loss : 0.020483
[00:25:54.915] iteration 17177 : model1 loss : 0.439630 model2 loss : 0.019561
[00:25:55.088] iteration 17178 : model1 loss : 0.438735 model2 loss : 0.019350
[00:25:57.223] iteration 17179 : model1 loss : 0.438100 model2 loss : 0.019477
[00:25:57.394] iteration 17180 : model1 loss : 0.436681 model2 loss : 0.019393
[00:25:57.574] iteration 17181 : model1 loss : 0.441686 model2 loss : 0.020567
[00:25:57.746] iteration 17182 : model1 loss : 0.438474 model2 loss : 0.020142
[00:25:57.923] iteration 17183 : model1 loss : 0.434832 model2 loss : 0.019359
[00:25:58.094] iteration 17184 : model1 loss : 0.434741 model2 loss : 0.017952
[00:25:58.270] iteration 17185 : model1 loss : 0.437615 model2 loss : 0.019399
[00:25:58.443] iteration 17186 : model1 loss : 0.438345 model2 loss : 0.018695
[00:25:58.623] iteration 17187 : model1 loss : 0.436306 model2 loss : 0.018572
[00:25:58.794] iteration 17188 : model1 loss : 0.430779 model2 loss : 0.016755
[00:25:58.969] iteration 17189 : model1 loss : 0.443285 model2 loss : 0.024165
[00:25:59.140] iteration 17190 : model1 loss : 0.437074 model2 loss : 0.018709
[00:25:59.321] iteration 17191 : model1 loss : 0.437338 model2 loss : 0.020197
[00:25:59.493] iteration 17192 : model1 loss : 0.444148 model2 loss : 0.022816
[00:25:59.668] iteration 17193 : model1 loss : 0.436551 model2 loss : 0.018926
[00:25:59.840] iteration 17194 : model1 loss : 0.439744 model2 loss : 0.020704
[00:26:00.016] iteration 17195 : model1 loss : 0.435140 model2 loss : 0.022170
[00:26:00.190] iteration 17196 : model1 loss : 0.439557 model2 loss : 0.022517
[00:26:00.368] iteration 17197 : model1 loss : 0.437855 model2 loss : 0.020252
[00:26:00.539] iteration 17198 : model1 loss : 0.435759 model2 loss : 0.018866
[00:26:00.713] iteration 17199 : model1 loss : 0.439547 model2 loss : 0.020477
[00:26:02.878] iteration 17200 : model1 loss : 0.436579 model2 loss : 0.019436
[00:26:03.056] iteration 17201 : model1 loss : 0.441515 model2 loss : 0.022435
[00:26:03.236] iteration 17202 : model1 loss : 0.435099 model2 loss : 0.021381
[00:26:03.408] iteration 17203 : model1 loss : 0.438693 model2 loss : 0.019827
[00:26:03.588] iteration 17204 : model1 loss : 0.439293 model2 loss : 0.020455
[00:26:03.759] iteration 17205 : model1 loss : 0.439731 model2 loss : 0.020571
[00:26:03.936] iteration 17206 : model1 loss : 0.441028 model2 loss : 0.018653
[00:26:04.108] iteration 17207 : model1 loss : 0.434964 model2 loss : 0.019576
[00:26:04.285] iteration 17208 : model1 loss : 0.435948 model2 loss : 0.018946
[00:26:04.455] iteration 17209 : model1 loss : 0.434289 model2 loss : 0.019581
[00:26:04.634] iteration 17210 : model1 loss : 0.438134 model2 loss : 0.021473
[00:26:04.807] iteration 17211 : model1 loss : 0.439627 model2 loss : 0.020063
[00:26:04.982] iteration 17212 : model1 loss : 0.437102 model2 loss : 0.023296
[00:26:05.153] iteration 17213 : model1 loss : 0.435310 model2 loss : 0.021498
[00:26:05.330] iteration 17214 : model1 loss : 0.431509 model2 loss : 0.017740
[00:26:05.502] iteration 17215 : model1 loss : 0.438349 model2 loss : 0.019963
[00:26:05.679] iteration 17216 : model1 loss : 0.445974 model2 loss : 0.021588
[00:26:05.849] iteration 17217 : model1 loss : 0.438578 model2 loss : 0.018010
[00:26:06.028] iteration 17218 : model1 loss : 0.439579 model2 loss : 0.020886
[00:26:06.199] iteration 17219 : model1 loss : 0.437293 model2 loss : 0.021519
[00:26:06.372] iteration 17220 : model1 loss : 0.437271 model2 loss : 0.021310
[00:26:08.554] iteration 17221 : model1 loss : 0.434789 model2 loss : 0.019522
[00:26:08.727] iteration 17222 : model1 loss : 0.436815 model2 loss : 0.017901
[00:26:08.908] iteration 17223 : model1 loss : 0.440220 model2 loss : 0.022257
[00:26:09.080] iteration 17224 : model1 loss : 0.437394 model2 loss : 0.017712
[00:26:09.257] iteration 17225 : model1 loss : 0.438816 model2 loss : 0.019014
[00:26:09.429] iteration 17226 : model1 loss : 0.438790 model2 loss : 0.017712
[00:26:09.612] iteration 17227 : model1 loss : 0.437796 model2 loss : 0.020002
[00:26:09.782] iteration 17228 : model1 loss : 0.436407 model2 loss : 0.020494
[00:26:09.958] iteration 17229 : model1 loss : 0.439222 model2 loss : 0.022388
[00:26:10.132] iteration 17230 : model1 loss : 0.431715 model2 loss : 0.019400
[00:26:10.309] iteration 17231 : model1 loss : 0.440549 model2 loss : 0.019730
[00:26:10.479] iteration 17232 : model1 loss : 0.437109 model2 loss : 0.018214
[00:26:10.657] iteration 17233 : model1 loss : 0.435201 model2 loss : 0.018419
[00:26:10.827] iteration 17234 : model1 loss : 0.438804 model2 loss : 0.018693
[00:26:11.001] iteration 17235 : model1 loss : 0.440967 model2 loss : 0.022039
[00:26:11.170] iteration 17236 : model1 loss : 0.437269 model2 loss : 0.019889
[00:26:11.349] iteration 17237 : model1 loss : 0.433603 model2 loss : 0.019605
[00:26:11.522] iteration 17238 : model1 loss : 0.436299 model2 loss : 0.017841
[00:26:11.698] iteration 17239 : model1 loss : 0.439416 model2 loss : 0.021232
[00:26:11.868] iteration 17240 : model1 loss : 0.436652 model2 loss : 0.020372
[00:26:12.042] iteration 17241 : model1 loss : 0.438031 model2 loss : 0.017959
[00:26:14.210] iteration 17242 : model1 loss : 0.437771 model2 loss : 0.019569
[00:26:14.388] iteration 17243 : model1 loss : 0.439102 model2 loss : 0.020766
[00:26:14.569] iteration 17244 : model1 loss : 0.439691 model2 loss : 0.019962
[00:26:14.742] iteration 17245 : model1 loss : 0.440462 model2 loss : 0.018951
[00:26:14.916] iteration 17246 : model1 loss : 0.433014 model2 loss : 0.020512
[00:26:15.086] iteration 17247 : model1 loss : 0.438163 model2 loss : 0.022686
[00:26:15.267] iteration 17248 : model1 loss : 0.436806 model2 loss : 0.019267
[00:26:15.439] iteration 17249 : model1 loss : 0.437560 model2 loss : 0.018363
[00:26:15.618] iteration 17250 : model1 loss : 0.438893 model2 loss : 0.019610
[00:26:15.789] iteration 17251 : model1 loss : 0.436090 model2 loss : 0.017732
[00:26:15.964] iteration 17252 : model1 loss : 0.438543 model2 loss : 0.019791
[00:26:16.136] iteration 17253 : model1 loss : 0.436263 model2 loss : 0.019888
[00:26:16.315] iteration 17254 : model1 loss : 0.436128 model2 loss : 0.019350
[00:26:16.486] iteration 17255 : model1 loss : 0.440042 model2 loss : 0.018684
[00:26:16.663] iteration 17256 : model1 loss : 0.437710 model2 loss : 0.018293
[00:26:16.834] iteration 17257 : model1 loss : 0.439612 model2 loss : 0.019534
[00:26:17.009] iteration 17258 : model1 loss : 0.433698 model2 loss : 0.017307
[00:26:17.178] iteration 17259 : model1 loss : 0.435607 model2 loss : 0.020413
[00:26:17.356] iteration 17260 : model1 loss : 0.435087 model2 loss : 0.018314
[00:26:17.531] iteration 17261 : model1 loss : 0.437958 model2 loss : 0.019866
[00:26:17.704] iteration 17262 : model1 loss : 0.438698 model2 loss : 0.020464
[00:26:19.872] iteration 17263 : model1 loss : 0.437039 model2 loss : 0.019302
[00:26:20.048] iteration 17264 : model1 loss : 0.438890 model2 loss : 0.017905
[00:26:20.227] iteration 17265 : model1 loss : 0.435602 model2 loss : 0.020420
[00:26:20.400] iteration 17266 : model1 loss : 0.438730 model2 loss : 0.020114
[00:26:20.579] iteration 17267 : model1 loss : 0.438200 model2 loss : 0.020043
[00:26:20.746] iteration 17268 : model1 loss : 0.442743 model2 loss : 0.021718
[00:26:20.925] iteration 17269 : model1 loss : 0.438421 model2 loss : 0.018756
[00:26:21.095] iteration 17270 : model1 loss : 0.439958 model2 loss : 0.022016
[00:26:21.271] iteration 17271 : model1 loss : 0.433363 model2 loss : 0.020148
[00:26:21.443] iteration 17272 : model1 loss : 0.437503 model2 loss : 0.018633
[00:26:21.623] iteration 17273 : model1 loss : 0.439288 model2 loss : 0.020160
[00:26:21.795] iteration 17274 : model1 loss : 0.434631 model2 loss : 0.020538
[00:26:21.970] iteration 17275 : model1 loss : 0.434058 model2 loss : 0.018574
[00:26:22.140] iteration 17276 : model1 loss : 0.436585 model2 loss : 0.018997
[00:26:22.321] iteration 17277 : model1 loss : 0.437655 model2 loss : 0.018402
[00:26:22.497] iteration 17278 : model1 loss : 0.437105 model2 loss : 0.019516
[00:26:22.675] iteration 17279 : model1 loss : 0.438819 model2 loss : 0.017713
[00:26:22.844] iteration 17280 : model1 loss : 0.437450 model2 loss : 0.022297
[00:26:23.021] iteration 17281 : model1 loss : 0.438001 model2 loss : 0.021122
[00:26:23.188] iteration 17282 : model1 loss : 0.438767 model2 loss : 0.020894
[00:26:23.360] iteration 17283 : model1 loss : 0.433879 model2 loss : 0.017625
[00:26:25.524] iteration 17284 : model1 loss : 0.435691 model2 loss : 0.019934
[00:26:25.699] iteration 17285 : model1 loss : 0.437938 model2 loss : 0.018389
[00:26:25.878] iteration 17286 : model1 loss : 0.435734 model2 loss : 0.019167
[00:26:26.050] iteration 17287 : model1 loss : 0.444188 model2 loss : 0.021203
[00:26:26.228] iteration 17288 : model1 loss : 0.438438 model2 loss : 0.020990
[00:26:26.398] iteration 17289 : model1 loss : 0.436770 model2 loss : 0.019868
[00:26:26.578] iteration 17290 : model1 loss : 0.440911 model2 loss : 0.019105
[00:26:26.748] iteration 17291 : model1 loss : 0.437545 model2 loss : 0.018755
[00:26:26.924] iteration 17292 : model1 loss : 0.437278 model2 loss : 0.018126
[00:26:27.095] iteration 17293 : model1 loss : 0.437378 model2 loss : 0.018960
[00:26:27.271] iteration 17294 : model1 loss : 0.434362 model2 loss : 0.017886
[00:26:27.445] iteration 17295 : model1 loss : 0.437389 model2 loss : 0.017265
[00:26:27.624] iteration 17296 : model1 loss : 0.434992 model2 loss : 0.018060
[00:26:27.795] iteration 17297 : model1 loss : 0.437405 model2 loss : 0.018727
[00:26:27.970] iteration 17298 : model1 loss : 0.439081 model2 loss : 0.021792
[00:26:28.140] iteration 17299 : model1 loss : 0.436210 model2 loss : 0.017315
[00:26:28.317] iteration 17300 : model1 loss : 0.437392 model2 loss : 0.020088
[00:26:28.489] iteration 17301 : model1 loss : 0.438646 model2 loss : 0.019825
[00:26:28.664] iteration 17302 : model1 loss : 0.439113 model2 loss : 0.018201
[00:26:28.833] iteration 17303 : model1 loss : 0.434658 model2 loss : 0.019613
[00:26:29.010] iteration 17304 : model1 loss : 0.433705 model2 loss : 0.019066
[00:26:31.185] iteration 17305 : model1 loss : 0.436511 model2 loss : 0.018492
[00:26:31.364] iteration 17306 : model1 loss : 0.435128 model2 loss : 0.020221
[00:26:31.545] iteration 17307 : model1 loss : 0.436544 model2 loss : 0.019292
[00:26:31.716] iteration 17308 : model1 loss : 0.434978 model2 loss : 0.018821
[00:26:31.891] iteration 17309 : model1 loss : 0.439924 model2 loss : 0.020638
[00:26:32.062] iteration 17310 : model1 loss : 0.436093 model2 loss : 0.017541
[00:26:32.239] iteration 17311 : model1 loss : 0.433594 model2 loss : 0.018720
[00:26:32.412] iteration 17312 : model1 loss : 0.441418 model2 loss : 0.021623
[00:26:32.589] iteration 17313 : model1 loss : 0.437251 model2 loss : 0.019329
[00:26:32.760] iteration 17314 : model1 loss : 0.438165 model2 loss : 0.019203
[00:26:32.935] iteration 17315 : model1 loss : 0.439396 model2 loss : 0.018282
[00:26:33.105] iteration 17316 : model1 loss : 0.436949 model2 loss : 0.017561
[00:26:33.279] iteration 17317 : model1 loss : 0.438881 model2 loss : 0.019895
[00:26:33.451] iteration 17318 : model1 loss : 0.434529 model2 loss : 0.019380
[00:26:33.628] iteration 17319 : model1 loss : 0.438260 model2 loss : 0.016986
[00:26:33.799] iteration 17320 : model1 loss : 0.435848 model2 loss : 0.019401
[00:26:33.975] iteration 17321 : model1 loss : 0.442183 model2 loss : 0.019550
[00:26:34.145] iteration 17322 : model1 loss : 0.435870 model2 loss : 0.017117
[00:26:34.324] iteration 17323 : model1 loss : 0.442652 model2 loss : 0.023936
[00:26:34.494] iteration 17324 : model1 loss : 0.438031 model2 loss : 0.019174
[00:26:34.667] iteration 17325 : model1 loss : 0.436013 model2 loss : 0.020106
[00:26:36.787] iteration 17326 : model1 loss : 0.438511 model2 loss : 0.019871
[00:26:36.962] iteration 17327 : model1 loss : 0.441283 model2 loss : 0.020131
[00:26:37.139] iteration 17328 : model1 loss : 0.441392 model2 loss : 0.020412
[00:26:37.314] iteration 17329 : model1 loss : 0.434521 model2 loss : 0.018499
[00:26:37.503] iteration 17330 : model1 loss : 0.435434 model2 loss : 0.016790
[00:26:37.674] iteration 17331 : model1 loss : 0.437750 model2 loss : 0.017418
[00:26:37.849] iteration 17332 : model1 loss : 0.439385 model2 loss : 0.020006
[00:26:38.020] iteration 17333 : model1 loss : 0.438664 model2 loss : 0.020091
[00:26:38.195] iteration 17334 : model1 loss : 0.433554 model2 loss : 0.018514
[00:26:38.366] iteration 17335 : model1 loss : 0.439446 model2 loss : 0.021600
[00:26:38.548] iteration 17336 : model1 loss : 0.437996 model2 loss : 0.020222
[00:26:38.718] iteration 17337 : model1 loss : 0.439477 model2 loss : 0.020911
[00:26:38.891] iteration 17338 : model1 loss : 0.438553 model2 loss : 0.022285
[00:26:39.066] iteration 17339 : model1 loss : 0.439871 model2 loss : 0.018829
[00:26:39.241] iteration 17340 : model1 loss : 0.438699 model2 loss : 0.020286
[00:26:39.415] iteration 17341 : model1 loss : 0.433173 model2 loss : 0.020744
[00:26:39.594] iteration 17342 : model1 loss : 0.433930 model2 loss : 0.018340
[00:26:39.765] iteration 17343 : model1 loss : 0.436268 model2 loss : 0.018121
[00:26:39.943] iteration 17344 : model1 loss : 0.436515 model2 loss : 0.019349
[00:26:40.113] iteration 17345 : model1 loss : 0.436431 model2 loss : 0.021189
[00:26:40.292] iteration 17346 : model1 loss : 0.437183 model2 loss : 0.019994
[00:26:42.450] iteration 17347 : model1 loss : 0.435249 model2 loss : 0.018204
[00:26:42.624] iteration 17348 : model1 loss : 0.437341 model2 loss : 0.017428
[00:26:42.807] iteration 17349 : model1 loss : 0.435529 model2 loss : 0.021989
[00:26:42.980] iteration 17350 : model1 loss : 0.438687 model2 loss : 0.020456
[00:26:43.159] iteration 17351 : model1 loss : 0.440050 model2 loss : 0.018903
[00:26:43.334] iteration 17352 : model1 loss : 0.434068 model2 loss : 0.016913
[00:26:43.513] iteration 17353 : model1 loss : 0.438011 model2 loss : 0.017755
[00:26:43.685] iteration 17354 : model1 loss : 0.437979 model2 loss : 0.020293
[00:26:43.863] iteration 17355 : model1 loss : 0.437473 model2 loss : 0.018719
[00:26:44.033] iteration 17356 : model1 loss : 0.438396 model2 loss : 0.018518
[00:26:44.209] iteration 17357 : model1 loss : 0.436397 model2 loss : 0.021120
[00:26:44.381] iteration 17358 : model1 loss : 0.437766 model2 loss : 0.017441
[00:26:44.559] iteration 17359 : model1 loss : 0.438435 model2 loss : 0.019737
[00:26:44.731] iteration 17360 : model1 loss : 0.437187 model2 loss : 0.019486
[00:26:44.906] iteration 17361 : model1 loss : 0.437539 model2 loss : 0.021137
[00:26:45.076] iteration 17362 : model1 loss : 0.432758 model2 loss : 0.018659
[00:26:45.252] iteration 17363 : model1 loss : 0.438334 model2 loss : 0.018107
[00:26:45.422] iteration 17364 : model1 loss : 0.436968 model2 loss : 0.020069
[00:26:45.602] iteration 17365 : model1 loss : 0.440886 model2 loss : 0.022586
[00:26:45.771] iteration 17366 : model1 loss : 0.436535 model2 loss : 0.020525
[00:26:45.944] iteration 17367 : model1 loss : 0.438478 model2 loss : 0.022549
[00:26:48.132] iteration 17368 : model1 loss : 0.435825 model2 loss : 0.019706
[00:26:48.309] iteration 17369 : model1 loss : 0.440308 model2 loss : 0.018628
[00:26:48.487] iteration 17370 : model1 loss : 0.435107 model2 loss : 0.019742
[00:26:48.662] iteration 17371 : model1 loss : 0.432256 model2 loss : 0.016419
[00:26:48.837] iteration 17372 : model1 loss : 0.439868 model2 loss : 0.019883
[00:26:49.009] iteration 17373 : model1 loss : 0.435679 model2 loss : 0.019834
[00:26:49.184] iteration 17374 : model1 loss : 0.438232 model2 loss : 0.021585
[00:26:49.357] iteration 17375 : model1 loss : 0.434620 model2 loss : 0.017625
[00:26:49.536] iteration 17376 : model1 loss : 0.434282 model2 loss : 0.017770
[00:26:49.706] iteration 17377 : model1 loss : 0.438236 model2 loss : 0.020692
[00:26:49.882] iteration 17378 : model1 loss : 0.438721 model2 loss : 0.021007
[00:26:50.052] iteration 17379 : model1 loss : 0.439284 model2 loss : 0.020027
[00:26:50.229] iteration 17380 : model1 loss : 0.433787 model2 loss : 0.020006
[00:26:50.400] iteration 17381 : model1 loss : 0.438167 model2 loss : 0.020092
[00:26:50.580] iteration 17382 : model1 loss : 0.435973 model2 loss : 0.019226
[00:26:50.751] iteration 17383 : model1 loss : 0.441245 model2 loss : 0.020406
[00:26:50.932] iteration 17384 : model1 loss : 0.440778 model2 loss : 0.017971
[00:26:51.104] iteration 17385 : model1 loss : 0.440634 model2 loss : 0.020761
[00:26:51.278] iteration 17386 : model1 loss : 0.438334 model2 loss : 0.018422
[00:26:51.448] iteration 17387 : model1 loss : 0.435638 model2 loss : 0.017971
[00:26:51.626] iteration 17388 : model1 loss : 0.439836 model2 loss : 0.019139
[00:26:53.809] iteration 17389 : model1 loss : 0.440243 model2 loss : 0.022349
[00:26:53.980] iteration 17390 : model1 loss : 0.436883 model2 loss : 0.018970
[00:26:54.160] iteration 17391 : model1 loss : 0.433420 model2 loss : 0.019931
[00:26:54.336] iteration 17392 : model1 loss : 0.436905 model2 loss : 0.019493
[00:26:54.516] iteration 17393 : model1 loss : 0.438328 model2 loss : 0.021248
[00:26:54.687] iteration 17394 : model1 loss : 0.443056 model2 loss : 0.022456
[00:26:54.865] iteration 17395 : model1 loss : 0.438982 model2 loss : 0.022208
[00:26:55.035] iteration 17396 : model1 loss : 0.442410 model2 loss : 0.019618
[00:26:55.210] iteration 17397 : model1 loss : 0.438316 model2 loss : 0.021540
[00:26:55.383] iteration 17398 : model1 loss : 0.438411 model2 loss : 0.020853
[00:26:55.561] iteration 17399 : model1 loss : 0.438853 model2 loss : 0.021440
[00:26:55.730] iteration 17400 : model1 loss : 0.435010 model2 loss : 0.018202
[00:26:55.905] iteration 17401 : model1 loss : 0.435367 model2 loss : 0.018926
[00:26:56.076] iteration 17402 : model1 loss : 0.441848 model2 loss : 0.021692
[00:26:56.252] iteration 17403 : model1 loss : 0.437613 model2 loss : 0.019839
[00:26:56.422] iteration 17404 : model1 loss : 0.437399 model2 loss : 0.019261
[00:26:56.600] iteration 17405 : model1 loss : 0.436699 model2 loss : 0.019789
[00:26:56.773] iteration 17406 : model1 loss : 0.436853 model2 loss : 0.018826
[00:26:56.950] iteration 17407 : model1 loss : 0.436984 model2 loss : 0.018474
[00:26:57.120] iteration 17408 : model1 loss : 0.439248 model2 loss : 0.020798
[00:26:57.294] iteration 17409 : model1 loss : 0.434584 model2 loss : 0.017805
[00:26:59.473] iteration 17410 : model1 loss : 0.435300 model2 loss : 0.019820
[00:26:59.651] iteration 17411 : model1 loss : 0.440834 model2 loss : 0.019169
[00:26:59.831] iteration 17412 : model1 loss : 0.440349 model2 loss : 0.019959
[00:27:00.003] iteration 17413 : model1 loss : 0.442419 model2 loss : 0.022207
[00:27:00.187] iteration 17414 : model1 loss : 0.440019 model2 loss : 0.019039
[00:27:00.359] iteration 17415 : model1 loss : 0.438321 model2 loss : 0.019011
[00:27:00.534] iteration 17416 : model1 loss : 0.438551 model2 loss : 0.019548
[00:27:00.703] iteration 17417 : model1 loss : 0.436327 model2 loss : 0.017809
[00:27:00.879] iteration 17418 : model1 loss : 0.434427 model2 loss : 0.019911
[00:27:01.050] iteration 17419 : model1 loss : 0.438279 model2 loss : 0.019744
[00:27:01.227] iteration 17420 : model1 loss : 0.434048 model2 loss : 0.017570
[00:27:01.400] iteration 17421 : model1 loss : 0.439683 model2 loss : 0.020436
[00:27:01.578] iteration 17422 : model1 loss : 0.434632 model2 loss : 0.019675
[00:27:01.749] iteration 17423 : model1 loss : 0.434724 model2 loss : 0.018839
[00:27:01.924] iteration 17424 : model1 loss : 0.441510 model2 loss : 0.022831
[00:27:02.096] iteration 17425 : model1 loss : 0.443485 model2 loss : 0.022484
[00:27:02.271] iteration 17426 : model1 loss : 0.437071 model2 loss : 0.020687
[00:27:02.447] iteration 17427 : model1 loss : 0.434534 model2 loss : 0.019967
[00:27:02.628] iteration 17428 : model1 loss : 0.435218 model2 loss : 0.020830
[00:27:02.798] iteration 17429 : model1 loss : 0.435107 model2 loss : 0.021911
[00:27:02.971] iteration 17430 : model1 loss : 0.436604 model2 loss : 0.018621
[00:27:05.121] iteration 17431 : model1 loss : 0.435735 model2 loss : 0.019888
[00:27:05.296] iteration 17432 : model1 loss : 0.434615 model2 loss : 0.020103
[00:27:05.479] iteration 17433 : model1 loss : 0.438380 model2 loss : 0.018817
[00:27:05.675] iteration 17434 : model1 loss : 0.434224 model2 loss : 0.019571
[00:27:05.852] iteration 17435 : model1 loss : 0.440935 model2 loss : 0.021718
[00:27:06.023] iteration 17436 : model1 loss : 0.440385 model2 loss : 0.019484
[00:27:06.202] iteration 17437 : model1 loss : 0.438727 model2 loss : 0.019431
[00:27:06.372] iteration 17438 : model1 loss : 0.436072 model2 loss : 0.019278
[00:27:06.550] iteration 17439 : model1 loss : 0.440637 model2 loss : 0.018675
[00:27:06.723] iteration 17440 : model1 loss : 0.439844 model2 loss : 0.020373
[00:27:06.898] iteration 17441 : model1 loss : 0.434925 model2 loss : 0.018089
[00:27:07.068] iteration 17442 : model1 loss : 0.439999 model2 loss : 0.020510
[00:27:07.243] iteration 17443 : model1 loss : 0.438955 model2 loss : 0.020746
[00:27:07.418] iteration 17444 : model1 loss : 0.437993 model2 loss : 0.021435
[00:27:07.600] iteration 17445 : model1 loss : 0.440281 model2 loss : 0.022551
[00:27:07.771] iteration 17446 : model1 loss : 0.435322 model2 loss : 0.017497
[00:27:07.946] iteration 17447 : model1 loss : 0.439371 model2 loss : 0.017790
[00:27:08.122] iteration 17448 : model1 loss : 0.438450 model2 loss : 0.020113
[00:27:08.302] iteration 17449 : model1 loss : 0.434562 model2 loss : 0.019542
[00:27:08.473] iteration 17450 : model1 loss : 0.437677 model2 loss : 0.019541
[00:27:08.648] iteration 17451 : model1 loss : 0.437503 model2 loss : 0.019517
[00:27:10.799] iteration 17452 : model1 loss : 0.435060 model2 loss : 0.019664
[00:27:10.969] iteration 17453 : model1 loss : 0.435677 model2 loss : 0.020485
[00:27:11.147] iteration 17454 : model1 loss : 0.441468 model2 loss : 0.019969
[00:27:11.322] iteration 17455 : model1 loss : 0.440662 model2 loss : 0.020374
[00:27:11.499] iteration 17456 : model1 loss : 0.438568 model2 loss : 0.018771
[00:27:11.681] iteration 17457 : model1 loss : 0.439437 model2 loss : 0.017849
[00:27:11.858] iteration 17458 : model1 loss : 0.435992 model2 loss : 0.020171
[00:27:12.031] iteration 17459 : model1 loss : 0.436324 model2 loss : 0.019705
[00:27:12.203] iteration 17460 : model1 loss : 0.437142 model2 loss : 0.020043
[00:27:12.378] iteration 17461 : model1 loss : 0.438589 model2 loss : 0.021331
[00:27:12.557] iteration 17462 : model1 loss : 0.438429 model2 loss : 0.018476
[00:27:12.731] iteration 17463 : model1 loss : 0.435338 model2 loss : 0.018388
[00:27:12.905] iteration 17464 : model1 loss : 0.434079 model2 loss : 0.016856
[00:27:13.075] iteration 17465 : model1 loss : 0.440544 model2 loss : 0.021364
[00:27:13.250] iteration 17466 : model1 loss : 0.439051 model2 loss : 0.019570
[00:27:13.424] iteration 17467 : model1 loss : 0.436193 model2 loss : 0.017265
[00:27:13.603] iteration 17468 : model1 loss : 0.435931 model2 loss : 0.019153
[00:27:13.774] iteration 17469 : model1 loss : 0.437698 model2 loss : 0.018295
[00:27:13.951] iteration 17470 : model1 loss : 0.437579 model2 loss : 0.021776
[00:27:14.122] iteration 17471 : model1 loss : 0.439628 model2 loss : 0.023644
[00:27:14.300] iteration 17472 : model1 loss : 0.439556 model2 loss : 0.019641
[00:27:16.459] iteration 17473 : model1 loss : 0.437234 model2 loss : 0.017947
[00:27:16.635] iteration 17474 : model1 loss : 0.433381 model2 loss : 0.018804
[00:27:16.814] iteration 17475 : model1 loss : 0.439430 model2 loss : 0.022243
[00:27:16.986] iteration 17476 : model1 loss : 0.434547 model2 loss : 0.018386
[00:27:17.165] iteration 17477 : model1 loss : 0.438038 model2 loss : 0.017561
[00:27:17.337] iteration 17478 : model1 loss : 0.440677 model2 loss : 0.021334
[00:27:17.523] iteration 17479 : model1 loss : 0.443889 model2 loss : 0.018726
[00:27:17.694] iteration 17480 : model1 loss : 0.435886 model2 loss : 0.020324
[00:27:17.868] iteration 17481 : model1 loss : 0.435989 model2 loss : 0.018014
[00:27:18.040] iteration 17482 : model1 loss : 0.435791 model2 loss : 0.019278
[00:27:18.215] iteration 17483 : model1 loss : 0.436895 model2 loss : 0.019814
[00:27:18.388] iteration 17484 : model1 loss : 0.436010 model2 loss : 0.019984
[00:27:18.567] iteration 17485 : model1 loss : 0.438090 model2 loss : 0.018100
[00:27:18.737] iteration 17486 : model1 loss : 0.437541 model2 loss : 0.019625
[00:27:18.911] iteration 17487 : model1 loss : 0.440976 model2 loss : 0.020567
[00:27:19.082] iteration 17488 : model1 loss : 0.435110 model2 loss : 0.019178
[00:27:19.258] iteration 17489 : model1 loss : 0.440285 model2 loss : 0.018264
[00:27:19.431] iteration 17490 : model1 loss : 0.436518 model2 loss : 0.021016
[00:27:19.612] iteration 17491 : model1 loss : 0.438086 model2 loss : 0.020368
[00:27:19.782] iteration 17492 : model1 loss : 0.437630 model2 loss : 0.019407
[00:27:19.956] iteration 17493 : model1 loss : 0.439166 model2 loss : 0.019826
[00:27:22.110] iteration 17494 : model1 loss : 0.436149 model2 loss : 0.017902
[00:27:22.287] iteration 17495 : model1 loss : 0.435863 model2 loss : 0.019445
[00:27:22.471] iteration 17496 : model1 loss : 0.436524 model2 loss : 0.019419
[00:27:22.642] iteration 17497 : model1 loss : 0.438765 model2 loss : 0.019148
[00:27:22.817] iteration 17498 : model1 loss : 0.437495 model2 loss : 0.017417
[00:27:22.989] iteration 17499 : model1 loss : 0.439252 model2 loss : 0.019972
[00:27:23.163] iteration 17500 : model1 loss : 0.437725 model2 loss : 0.018025
[00:27:23.336] iteration 17501 : model1 loss : 0.436769 model2 loss : 0.019926
[00:27:23.512] iteration 17502 : model1 loss : 0.440036 model2 loss : 0.019779
[00:27:23.687] iteration 17503 : model1 loss : 0.436754 model2 loss : 0.019762
[00:27:23.862] iteration 17504 : model1 loss : 0.434060 model2 loss : 0.018147
[00:27:24.032] iteration 17505 : model1 loss : 0.435778 model2 loss : 0.018798
[00:27:24.209] iteration 17506 : model1 loss : 0.434343 model2 loss : 0.017904
[00:27:24.380] iteration 17507 : model1 loss : 0.431881 model2 loss : 0.018842
[00:27:24.561] iteration 17508 : model1 loss : 0.437117 model2 loss : 0.019035
[00:27:24.733] iteration 17509 : model1 loss : 0.439573 model2 loss : 0.019649
[00:27:24.909] iteration 17510 : model1 loss : 0.442412 model2 loss : 0.023698
[00:27:25.079] iteration 17511 : model1 loss : 0.443803 model2 loss : 0.019188
[00:27:25.253] iteration 17512 : model1 loss : 0.436490 model2 loss : 0.019507
[00:27:25.427] iteration 17513 : model1 loss : 0.442444 model2 loss : 0.019991
[00:27:25.605] iteration 17514 : model1 loss : 0.439874 model2 loss : 0.019825
[00:27:27.772] iteration 17515 : model1 loss : 0.436104 model2 loss : 0.020130
[00:27:27.950] iteration 17516 : model1 loss : 0.435677 model2 loss : 0.020074
[00:27:28.132] iteration 17517 : model1 loss : 0.438459 model2 loss : 0.020353
[00:27:28.304] iteration 17518 : model1 loss : 0.435643 model2 loss : 0.020629
[00:27:28.484] iteration 17519 : model1 loss : 0.440735 model2 loss : 0.020276
[00:27:28.655] iteration 17520 : model1 loss : 0.434653 model2 loss : 0.019864
[00:27:28.832] iteration 17521 : model1 loss : 0.435966 model2 loss : 0.020053
[00:27:29.003] iteration 17522 : model1 loss : 0.438597 model2 loss : 0.020407
[00:27:29.182] iteration 17523 : model1 loss : 0.437030 model2 loss : 0.019250
[00:27:29.354] iteration 17524 : model1 loss : 0.436006 model2 loss : 0.017235
[00:27:29.531] iteration 17525 : model1 loss : 0.434636 model2 loss : 0.017043
[00:27:29.702] iteration 17526 : model1 loss : 0.433410 model2 loss : 0.017501
[00:27:29.877] iteration 17527 : model1 loss : 0.437421 model2 loss : 0.019014
[00:27:30.054] iteration 17528 : model1 loss : 0.440374 model2 loss : 0.020347
[00:27:30.231] iteration 17529 : model1 loss : 0.441602 model2 loss : 0.020182
[00:27:30.403] iteration 17530 : model1 loss : 0.443788 model2 loss : 0.020773
[00:27:30.581] iteration 17531 : model1 loss : 0.442331 model2 loss : 0.023940
[00:27:30.753] iteration 17532 : model1 loss : 0.436044 model2 loss : 0.018630
[00:27:30.931] iteration 17533 : model1 loss : 0.435800 model2 loss : 0.018588
[00:27:31.100] iteration 17534 : model1 loss : 0.439928 model2 loss : 0.018268
[00:27:31.273] iteration 17535 : model1 loss : 0.439762 model2 loss : 0.019527
[00:27:33.443] iteration 17536 : model1 loss : 0.438944 model2 loss : 0.021637
[00:27:33.622] iteration 17537 : model1 loss : 0.436995 model2 loss : 0.018157
[00:27:33.804] iteration 17538 : model1 loss : 0.437245 model2 loss : 0.017912
[00:27:33.979] iteration 17539 : model1 loss : 0.436206 model2 loss : 0.019735
[00:27:34.156] iteration 17540 : model1 loss : 0.440070 model2 loss : 0.020762
[00:27:34.331] iteration 17541 : model1 loss : 0.436998 model2 loss : 0.020540
[00:27:34.507] iteration 17542 : model1 loss : 0.435321 model2 loss : 0.016157
[00:27:34.676] iteration 17543 : model1 loss : 0.433142 model2 loss : 0.018069
[00:27:34.853] iteration 17544 : model1 loss : 0.441780 model2 loss : 0.019005
[00:27:35.023] iteration 17545 : model1 loss : 0.438707 model2 loss : 0.019065
[00:27:35.199] iteration 17546 : model1 loss : 0.438245 model2 loss : 0.018422
[00:27:35.370] iteration 17547 : model1 loss : 0.438872 model2 loss : 0.017799
[00:27:35.549] iteration 17548 : model1 loss : 0.436322 model2 loss : 0.019480
[00:27:35.721] iteration 17549 : model1 loss : 0.440186 model2 loss : 0.020605
[00:27:35.897] iteration 17550 : model1 loss : 0.435485 model2 loss : 0.018560
[00:27:36.068] iteration 17551 : model1 loss : 0.441237 model2 loss : 0.020734
[00:27:36.245] iteration 17552 : model1 loss : 0.434711 model2 loss : 0.021555
[00:27:36.417] iteration 17553 : model1 loss : 0.439433 model2 loss : 0.017274
[00:27:36.597] iteration 17554 : model1 loss : 0.435476 model2 loss : 0.017227
[00:27:36.765] iteration 17555 : model1 loss : 0.434963 model2 loss : 0.018463
[00:27:36.939] iteration 17556 : model1 loss : 0.439237 model2 loss : 0.021622
[00:27:39.084] iteration 17557 : model1 loss : 0.439561 model2 loss : 0.021441
[00:27:39.258] iteration 17558 : model1 loss : 0.436852 model2 loss : 0.017850
[00:27:39.439] iteration 17559 : model1 loss : 0.438292 model2 loss : 0.016199
[00:27:39.614] iteration 17560 : model1 loss : 0.440892 model2 loss : 0.019773
[00:27:39.794] iteration 17561 : model1 loss : 0.440873 model2 loss : 0.022763
[00:27:39.968] iteration 17562 : model1 loss : 0.438937 model2 loss : 0.018859
[00:27:40.147] iteration 17563 : model1 loss : 0.437976 model2 loss : 0.020130
[00:27:40.320] iteration 17564 : model1 loss : 0.435917 model2 loss : 0.017726
[00:27:40.499] iteration 17565 : model1 loss : 0.438435 model2 loss : 0.020115
[00:27:40.670] iteration 17566 : model1 loss : 0.438554 model2 loss : 0.020831
[00:27:40.847] iteration 17567 : model1 loss : 0.437277 model2 loss : 0.018467
[00:27:41.018] iteration 17568 : model1 loss : 0.437471 model2 loss : 0.017766
[00:27:41.195] iteration 17569 : model1 loss : 0.434345 model2 loss : 0.016460
[00:27:41.368] iteration 17570 : model1 loss : 0.437649 model2 loss : 0.020748
[00:27:41.547] iteration 17571 : model1 loss : 0.436761 model2 loss : 0.017991
[00:27:41.717] iteration 17572 : model1 loss : 0.435825 model2 loss : 0.017857
[00:27:41.896] iteration 17573 : model1 loss : 0.436985 model2 loss : 0.021866
[00:27:42.068] iteration 17574 : model1 loss : 0.436935 model2 loss : 0.019809
[00:27:42.244] iteration 17575 : model1 loss : 0.435891 model2 loss : 0.020413
[00:27:42.416] iteration 17576 : model1 loss : 0.436255 model2 loss : 0.019020
[00:27:42.594] iteration 17577 : model1 loss : 0.439261 model2 loss : 0.017222
[00:27:44.745] iteration 17578 : model1 loss : 0.439407 model2 loss : 0.019674
[00:27:44.921] iteration 17579 : model1 loss : 0.435171 model2 loss : 0.020214
[00:27:45.101] iteration 17580 : model1 loss : 0.433754 model2 loss : 0.018644
[00:27:45.272] iteration 17581 : model1 loss : 0.438531 model2 loss : 0.018174
[00:27:45.449] iteration 17582 : model1 loss : 0.438395 model2 loss : 0.020248
[00:27:45.624] iteration 17583 : model1 loss : 0.430751 model2 loss : 0.018063
[00:27:45.802] iteration 17584 : model1 loss : 0.436816 model2 loss : 0.019713
[00:27:45.973] iteration 17585 : model1 loss : 0.439488 model2 loss : 0.017971
[00:27:46.148] iteration 17586 : model1 loss : 0.437087 model2 loss : 0.018585
[00:27:46.321] iteration 17587 : model1 loss : 0.436726 model2 loss : 0.020798
[00:27:46.497] iteration 17588 : model1 loss : 0.433665 model2 loss : 0.018467
[00:27:46.667] iteration 17589 : model1 loss : 0.438594 model2 loss : 0.021836
[00:27:46.842] iteration 17590 : model1 loss : 0.440268 model2 loss : 0.020187
[00:27:47.012] iteration 17591 : model1 loss : 0.439198 model2 loss : 0.018467
[00:27:47.187] iteration 17592 : model1 loss : 0.442427 model2 loss : 0.020974
[00:27:47.360] iteration 17593 : model1 loss : 0.437613 model2 loss : 0.017993
[00:27:47.541] iteration 17594 : model1 loss : 0.439241 model2 loss : 0.021966
[00:27:47.712] iteration 17595 : model1 loss : 0.440918 model2 loss : 0.017839
[00:27:47.889] iteration 17596 : model1 loss : 0.442099 model2 loss : 0.021114
[00:27:48.060] iteration 17597 : model1 loss : 0.437706 model2 loss : 0.020370
[00:27:48.231] iteration 17598 : model1 loss : 0.435059 model2 loss : 0.019502
[00:27:50.377] iteration 17599 : model1 loss : 0.439937 model2 loss : 0.017838
[00:27:50.556] iteration 17600 : model1 loss : 0.440984 model2 loss : 0.019974
[00:27:50.735] iteration 17601 : model1 loss : 0.434925 model2 loss : 0.021114
[00:27:50.905] iteration 17602 : model1 loss : 0.441987 model2 loss : 0.022117
[00:27:51.087] iteration 17603 : model1 loss : 0.438660 model2 loss : 0.020490
[00:27:51.257] iteration 17604 : model1 loss : 0.440771 model2 loss : 0.017286
[00:27:51.433] iteration 17605 : model1 loss : 0.437997 model2 loss : 0.019337
[00:27:51.610] iteration 17606 : model1 loss : 0.439553 model2 loss : 0.021756
[00:27:51.787] iteration 17607 : model1 loss : 0.439128 model2 loss : 0.019859
[00:27:51.959] iteration 17608 : model1 loss : 0.434184 model2 loss : 0.021096
[00:27:52.136] iteration 17609 : model1 loss : 0.437015 model2 loss : 0.019650
[00:27:52.308] iteration 17610 : model1 loss : 0.437141 model2 loss : 0.020388
[00:27:52.488] iteration 17611 : model1 loss : 0.437368 model2 loss : 0.019706
[00:27:52.659] iteration 17612 : model1 loss : 0.438824 model2 loss : 0.018977
[00:27:52.835] iteration 17613 : model1 loss : 0.436218 model2 loss : 0.020215
[00:27:53.010] iteration 17614 : model1 loss : 0.433765 model2 loss : 0.018751
[00:27:53.188] iteration 17615 : model1 loss : 0.438403 model2 loss : 0.020613
[00:27:53.359] iteration 17616 : model1 loss : 0.439613 model2 loss : 0.019792
[00:27:53.538] iteration 17617 : model1 loss : 0.436399 model2 loss : 0.020677
[00:27:53.707] iteration 17618 : model1 loss : 0.438969 model2 loss : 0.019455
[00:27:53.882] iteration 17619 : model1 loss : 0.433329 model2 loss : 0.017191
[00:27:56.056] iteration 17620 : model1 loss : 0.440242 model2 loss : 0.019269
[00:27:56.228] iteration 17621 : model1 loss : 0.435279 model2 loss : 0.019375
[00:27:56.411] iteration 17622 : model1 loss : 0.441320 model2 loss : 0.018992
[00:27:56.585] iteration 17623 : model1 loss : 0.439140 model2 loss : 0.018286
[00:27:56.762] iteration 17624 : model1 loss : 0.440566 model2 loss : 0.021835
[00:27:56.933] iteration 17625 : model1 loss : 0.441151 model2 loss : 0.019747
[00:27:57.109] iteration 17626 : model1 loss : 0.431683 model2 loss : 0.018428
[00:27:57.281] iteration 17627 : model1 loss : 0.431344 model2 loss : 0.018043
[00:27:57.461] iteration 17628 : model1 loss : 0.437408 model2 loss : 0.018834
[00:27:57.633] iteration 17629 : model1 loss : 0.436391 model2 loss : 0.019582
[00:27:57.809] iteration 17630 : model1 loss : 0.436772 model2 loss : 0.019480
[00:27:57.980] iteration 17631 : model1 loss : 0.438590 model2 loss : 0.021800
[00:27:58.157] iteration 17632 : model1 loss : 0.436043 model2 loss : 0.021835
[00:27:58.330] iteration 17633 : model1 loss : 0.438499 model2 loss : 0.017450
[00:27:58.506] iteration 17634 : model1 loss : 0.438844 model2 loss : 0.019575
[00:27:58.677] iteration 17635 : model1 loss : 0.441688 model2 loss : 0.024907
[00:27:58.853] iteration 17636 : model1 loss : 0.434491 model2 loss : 0.018329
[00:27:59.024] iteration 17637 : model1 loss : 0.439687 model2 loss : 0.021697
[00:27:59.199] iteration 17638 : model1 loss : 0.435043 model2 loss : 0.019383
[00:27:59.368] iteration 17639 : model1 loss : 0.439600 model2 loss : 0.019907
[00:27:59.542] iteration 17640 : model1 loss : 0.441756 model2 loss : 0.020461
[00:28:01.688] iteration 17641 : model1 loss : 0.437592 model2 loss : 0.018715
[00:28:01.866] iteration 17642 : model1 loss : 0.434839 model2 loss : 0.017127
[00:28:02.045] iteration 17643 : model1 loss : 0.438404 model2 loss : 0.022503
[00:28:02.217] iteration 17644 : model1 loss : 0.435519 model2 loss : 0.017367
[00:28:02.396] iteration 17645 : model1 loss : 0.439061 model2 loss : 0.021121
[00:28:02.572] iteration 17646 : model1 loss : 0.437786 model2 loss : 0.018055
[00:28:02.748] iteration 17647 : model1 loss : 0.437590 model2 loss : 0.019339
[00:28:02.920] iteration 17648 : model1 loss : 0.437746 model2 loss : 0.020148
[00:28:03.097] iteration 17649 : model1 loss : 0.433634 model2 loss : 0.019335
[00:28:03.268] iteration 17650 : model1 loss : 0.438010 model2 loss : 0.020790
[00:28:03.441] iteration 17651 : model1 loss : 0.436933 model2 loss : 0.019959
[00:28:03.613] iteration 17652 : model1 loss : 0.435465 model2 loss : 0.018276
[00:28:03.792] iteration 17653 : model1 loss : 0.439508 model2 loss : 0.016567
[00:28:03.964] iteration 17654 : model1 loss : 0.435034 model2 loss : 0.019804
[00:28:04.139] iteration 17655 : model1 loss : 0.438591 model2 loss : 0.019413
[00:28:04.316] iteration 17656 : model1 loss : 0.436141 model2 loss : 0.019943
[00:28:04.493] iteration 17657 : model1 loss : 0.437474 model2 loss : 0.018323
[00:28:04.666] iteration 17658 : model1 loss : 0.440656 model2 loss : 0.023968
[00:28:04.842] iteration 17659 : model1 loss : 0.441996 model2 loss : 0.022585
[00:28:05.011] iteration 17660 : model1 loss : 0.436897 model2 loss : 0.020153
[00:28:05.187] iteration 17661 : model1 loss : 0.442127 model2 loss : 0.023897
[00:28:07.334] iteration 17662 : model1 loss : 0.433563 model2 loss : 0.016935
[00:28:07.513] iteration 17663 : model1 loss : 0.437244 model2 loss : 0.017905
[00:28:07.690] iteration 17664 : model1 loss : 0.438404 model2 loss : 0.020162
[00:28:07.863] iteration 17665 : model1 loss : 0.434496 model2 loss : 0.018006
[00:28:08.040] iteration 17666 : model1 loss : 0.439449 model2 loss : 0.022923
[00:28:08.214] iteration 17667 : model1 loss : 0.437715 model2 loss : 0.019144
[00:28:08.390] iteration 17668 : model1 loss : 0.440062 model2 loss : 0.022754
[00:28:08.565] iteration 17669 : model1 loss : 0.440187 model2 loss : 0.020678
[00:28:08.741] iteration 17670 : model1 loss : 0.436161 model2 loss : 0.020733
[00:28:08.913] iteration 17671 : model1 loss : 0.436574 model2 loss : 0.020470
[00:28:09.090] iteration 17672 : model1 loss : 0.439743 model2 loss : 0.019441
[00:28:09.260] iteration 17673 : model1 loss : 0.438480 model2 loss : 0.018928
[00:28:09.433] iteration 17674 : model1 loss : 0.436643 model2 loss : 0.019696
[00:28:09.608] iteration 17675 : model1 loss : 0.437183 model2 loss : 0.023457
[00:28:09.784] iteration 17676 : model1 loss : 0.429340 model2 loss : 0.019546
[00:28:09.954] iteration 17677 : model1 loss : 0.436983 model2 loss : 0.019004
[00:28:10.133] iteration 17678 : model1 loss : 0.440288 model2 loss : 0.019136
[00:28:10.304] iteration 17679 : model1 loss : 0.444869 model2 loss : 0.024812
[00:28:10.481] iteration 17680 : model1 loss : 0.440130 model2 loss : 0.018772
[00:28:10.650] iteration 17681 : model1 loss : 0.436430 model2 loss : 0.018812
[00:28:10.823] iteration 17682 : model1 loss : 0.438314 model2 loss : 0.019282
[00:28:12.970] iteration 17683 : model1 loss : 0.436561 model2 loss : 0.018067
[00:28:13.143] iteration 17684 : model1 loss : 0.436859 model2 loss : 0.018547
[00:28:13.327] iteration 17685 : model1 loss : 0.438315 model2 loss : 0.020764
[00:28:13.502] iteration 17686 : model1 loss : 0.439058 model2 loss : 0.019375
[00:28:13.676] iteration 17687 : model1 loss : 0.434684 model2 loss : 0.016988
[00:28:13.848] iteration 17688 : model1 loss : 0.435364 model2 loss : 0.018977
[00:28:14.024] iteration 17689 : model1 loss : 0.442571 model2 loss : 0.021387
[00:28:14.194] iteration 17690 : model1 loss : 0.441617 model2 loss : 0.021254
[00:28:14.371] iteration 17691 : model1 loss : 0.433518 model2 loss : 0.017350
[00:28:14.546] iteration 17692 : model1 loss : 0.438200 model2 loss : 0.018849
[00:28:14.723] iteration 17693 : model1 loss : 0.440051 model2 loss : 0.022481
[00:28:14.895] iteration 17694 : model1 loss : 0.438073 model2 loss : 0.018241
[00:28:15.070] iteration 17695 : model1 loss : 0.437785 model2 loss : 0.020587
[00:28:15.239] iteration 17696 : model1 loss : 0.435972 model2 loss : 0.020982
[00:28:15.416] iteration 17697 : model1 loss : 0.439524 model2 loss : 0.019317
[00:28:15.594] iteration 17698 : model1 loss : 0.436807 model2 loss : 0.019935
[00:28:15.772] iteration 17699 : model1 loss : 0.435762 model2 loss : 0.017711
[00:28:15.943] iteration 17700 : model1 loss : 0.437464 model2 loss : 0.020045
[00:28:16.126] iteration 17701 : model1 loss : 0.435777 model2 loss : 0.016767
[00:28:16.296] iteration 17702 : model1 loss : 0.435771 model2 loss : 0.019660
[00:28:16.472] iteration 17703 : model1 loss : 0.438000 model2 loss : 0.017997
[00:28:18.614] iteration 17704 : model1 loss : 0.438318 model2 loss : 0.017296
[00:28:18.792] iteration 17705 : model1 loss : 0.437411 model2 loss : 0.017959
[00:28:18.973] iteration 17706 : model1 loss : 0.440514 model2 loss : 0.019927
[00:28:19.145] iteration 17707 : model1 loss : 0.437689 model2 loss : 0.018852
[00:28:19.329] iteration 17708 : model1 loss : 0.436472 model2 loss : 0.017210
[00:28:19.502] iteration 17709 : model1 loss : 0.439235 model2 loss : 0.021758
[00:28:19.678] iteration 17710 : model1 loss : 0.436212 model2 loss : 0.019938
[00:28:19.849] iteration 17711 : model1 loss : 0.439459 model2 loss : 0.021422
[00:28:20.027] iteration 17712 : model1 loss : 0.435422 model2 loss : 0.019337
[00:28:20.199] iteration 17713 : model1 loss : 0.441055 model2 loss : 0.020915
[00:28:20.415] iteration 17714 : model1 loss : 0.439705 model2 loss : 0.020433
[00:28:20.588] iteration 17715 : model1 loss : 0.437101 model2 loss : 0.017522
[00:28:20.763] iteration 17716 : model1 loss : 0.438690 model2 loss : 0.019207
[00:28:20.935] iteration 17717 : model1 loss : 0.432844 model2 loss : 0.018644
[00:28:21.108] iteration 17718 : model1 loss : 0.438806 model2 loss : 0.020328
[00:28:21.280] iteration 17719 : model1 loss : 0.435244 model2 loss : 0.017077
[00:28:21.456] iteration 17720 : model1 loss : 0.434355 model2 loss : 0.018455
[00:28:21.630] iteration 17721 : model1 loss : 0.442193 model2 loss : 0.019622
[00:28:21.806] iteration 17722 : model1 loss : 0.436292 model2 loss : 0.020875
[00:28:21.976] iteration 17723 : model1 loss : 0.433709 model2 loss : 0.019753
[00:28:22.150] iteration 17724 : model1 loss : 0.439683 model2 loss : 0.018127
[00:28:24.305] iteration 17725 : model1 loss : 0.442329 model2 loss : 0.021281
[00:28:24.477] iteration 17726 : model1 loss : 0.440534 model2 loss : 0.021149
[00:28:24.654] iteration 17727 : model1 loss : 0.435347 model2 loss : 0.018850
[00:28:24.827] iteration 17728 : model1 loss : 0.438073 model2 loss : 0.020391
[00:28:25.005] iteration 17729 : model1 loss : 0.435631 model2 loss : 0.019600
[00:28:25.177] iteration 17730 : model1 loss : 0.434508 model2 loss : 0.018024
[00:28:25.353] iteration 17731 : model1 loss : 0.439738 model2 loss : 0.019675
[00:28:25.526] iteration 17732 : model1 loss : 0.434053 model2 loss : 0.018974
[00:28:25.700] iteration 17733 : model1 loss : 0.440425 model2 loss : 0.020106
[00:28:25.871] iteration 17734 : model1 loss : 0.435908 model2 loss : 0.019286
[00:28:26.048] iteration 17735 : model1 loss : 0.438932 model2 loss : 0.021578
[00:28:26.230] iteration 17736 : model1 loss : 0.436197 model2 loss : 0.018822
[00:28:26.407] iteration 17737 : model1 loss : 0.437350 model2 loss : 0.017865
[00:28:26.584] iteration 17738 : model1 loss : 0.434350 model2 loss : 0.019168
[00:28:26.762] iteration 17739 : model1 loss : 0.434816 model2 loss : 0.018523
[00:28:26.933] iteration 17740 : model1 loss : 0.438819 model2 loss : 0.019840
[00:28:27.107] iteration 17741 : model1 loss : 0.440188 model2 loss : 0.022322
[00:28:27.279] iteration 17742 : model1 loss : 0.436608 model2 loss : 0.020409
[00:28:27.458] iteration 17743 : model1 loss : 0.441114 model2 loss : 0.018555
[00:28:27.627] iteration 17744 : model1 loss : 0.438179 model2 loss : 0.018569
[00:28:27.801] iteration 17745 : model1 loss : 0.438217 model2 loss : 0.019486
[00:28:29.951] iteration 17746 : model1 loss : 0.436495 model2 loss : 0.018553
[00:28:30.123] iteration 17747 : model1 loss : 0.436572 model2 loss : 0.020165
[00:28:30.302] iteration 17748 : model1 loss : 0.438230 model2 loss : 0.017993
[00:28:30.475] iteration 17749 : model1 loss : 0.438647 model2 loss : 0.020705
[00:28:30.654] iteration 17750 : model1 loss : 0.434417 model2 loss : 0.019610
[00:28:30.825] iteration 17751 : model1 loss : 0.437407 model2 loss : 0.018955
[00:28:31.000] iteration 17752 : model1 loss : 0.440452 model2 loss : 0.024073
[00:28:31.172] iteration 17753 : model1 loss : 0.436671 model2 loss : 0.018196
[00:28:31.347] iteration 17754 : model1 loss : 0.435578 model2 loss : 0.018739
[00:28:31.521] iteration 17755 : model1 loss : 0.438742 model2 loss : 0.017684
[00:28:31.695] iteration 17756 : model1 loss : 0.439322 model2 loss : 0.020283
[00:28:31.868] iteration 17757 : model1 loss : 0.434871 model2 loss : 0.018638
[00:28:32.042] iteration 17758 : model1 loss : 0.435806 model2 loss : 0.019785
[00:28:32.213] iteration 17759 : model1 loss : 0.432714 model2 loss : 0.018145
[00:28:32.392] iteration 17760 : model1 loss : 0.437448 model2 loss : 0.019417
[00:28:32.565] iteration 17761 : model1 loss : 0.436656 model2 loss : 0.018890
[00:28:32.738] iteration 17762 : model1 loss : 0.438947 model2 loss : 0.019875
[00:28:32.910] iteration 17763 : model1 loss : 0.445762 model2 loss : 0.024202
[00:28:33.085] iteration 17764 : model1 loss : 0.435413 model2 loss : 0.016991
[00:28:33.255] iteration 17765 : model1 loss : 0.437866 model2 loss : 0.019426
[00:28:33.428] iteration 17766 : model1 loss : 0.442126 model2 loss : 0.019773
[00:28:35.554] iteration 17767 : model1 loss : 0.437900 model2 loss : 0.017334
[00:28:35.732] iteration 17768 : model1 loss : 0.438997 model2 loss : 0.020821
[00:28:35.910] iteration 17769 : model1 loss : 0.438921 model2 loss : 0.020762
[00:28:36.082] iteration 17770 : model1 loss : 0.434669 model2 loss : 0.018521
[00:28:36.255] iteration 17771 : model1 loss : 0.439848 model2 loss : 0.017800
[00:28:36.425] iteration 17772 : model1 loss : 0.439186 model2 loss : 0.019196
[00:28:36.605] iteration 17773 : model1 loss : 0.436275 model2 loss : 0.020196
[00:28:36.775] iteration 17774 : model1 loss : 0.437361 model2 loss : 0.019783
[00:28:36.950] iteration 17775 : model1 loss : 0.435333 model2 loss : 0.018370
[00:28:37.121] iteration 17776 : model1 loss : 0.433978 model2 loss : 0.019283
[00:28:37.296] iteration 17777 : model1 loss : 0.436579 model2 loss : 0.019473
[00:28:37.473] iteration 17778 : model1 loss : 0.441168 model2 loss : 0.018621
[00:28:37.650] iteration 17779 : model1 loss : 0.437757 model2 loss : 0.017835
[00:28:37.823] iteration 17780 : model1 loss : 0.433264 model2 loss : 0.016471
[00:28:38.008] iteration 17781 : model1 loss : 0.436458 model2 loss : 0.021480
[00:28:38.180] iteration 17782 : model1 loss : 0.435026 model2 loss : 0.018590
[00:28:38.361] iteration 17783 : model1 loss : 0.440904 model2 loss : 0.020738
[00:28:38.534] iteration 17784 : model1 loss : 0.436337 model2 loss : 0.019446
[00:28:38.710] iteration 17785 : model1 loss : 0.438297 model2 loss : 0.018103
[00:28:38.881] iteration 17786 : model1 loss : 0.440760 model2 loss : 0.020559
[00:28:39.055] iteration 17787 : model1 loss : 0.442189 model2 loss : 0.018763
[00:28:41.200] iteration 17788 : model1 loss : 0.436886 model2 loss : 0.019023
[00:28:41.377] iteration 17789 : model1 loss : 0.437774 model2 loss : 0.017448
[00:28:41.555] iteration 17790 : model1 loss : 0.435583 model2 loss : 0.015207
[00:28:41.727] iteration 17791 : model1 loss : 0.440502 model2 loss : 0.018601
[00:28:41.905] iteration 17792 : model1 loss : 0.436263 model2 loss : 0.019194
[00:28:42.081] iteration 17793 : model1 loss : 0.436310 model2 loss : 0.021978
[00:28:42.258] iteration 17794 : model1 loss : 0.442267 model2 loss : 0.021099
[00:28:42.431] iteration 17795 : model1 loss : 0.435464 model2 loss : 0.016456
[00:28:42.610] iteration 17796 : model1 loss : 0.433020 model2 loss : 0.017094
[00:28:42.780] iteration 17797 : model1 loss : 0.440976 model2 loss : 0.020955
[00:28:42.956] iteration 17798 : model1 loss : 0.442122 model2 loss : 0.021898
[00:28:43.126] iteration 17799 : model1 loss : 0.437592 model2 loss : 0.020251
[00:28:43.301] iteration 17800 : model1 loss : 0.433884 model2 loss : 0.018733
[00:28:43.473] iteration 17801 : model1 loss : 0.437766 model2 loss : 0.021483
[00:28:43.650] iteration 17802 : model1 loss : 0.432760 model2 loss : 0.017485
[00:28:43.823] iteration 17803 : model1 loss : 0.438882 model2 loss : 0.020473
[00:28:43.998] iteration 17804 : model1 loss : 0.437417 model2 loss : 0.017721
[00:28:44.169] iteration 17805 : model1 loss : 0.438925 model2 loss : 0.020337
[00:28:44.346] iteration 17806 : model1 loss : 0.434002 model2 loss : 0.018543
[00:28:44.517] iteration 17807 : model1 loss : 0.438215 model2 loss : 0.018513
[00:28:44.693] iteration 17808 : model1 loss : 0.442622 model2 loss : 0.019592
[00:28:46.854] iteration 17809 : model1 loss : 0.436899 model2 loss : 0.020396
[00:28:47.026] iteration 17810 : model1 loss : 0.436738 model2 loss : 0.020449
[00:28:47.207] iteration 17811 : model1 loss : 0.439605 model2 loss : 0.018801
[00:28:47.378] iteration 17812 : model1 loss : 0.435851 model2 loss : 0.017976
[00:28:47.557] iteration 17813 : model1 loss : 0.434380 model2 loss : 0.018411
[00:28:47.726] iteration 17814 : model1 loss : 0.438188 model2 loss : 0.018770
[00:28:47.900] iteration 17815 : model1 loss : 0.441471 model2 loss : 0.019981
[00:28:48.071] iteration 17816 : model1 loss : 0.439448 model2 loss : 0.017627
[00:28:48.248] iteration 17817 : model1 loss : 0.437419 model2 loss : 0.020946
[00:28:48.419] iteration 17818 : model1 loss : 0.433998 model2 loss : 0.018965
[00:28:48.599] iteration 17819 : model1 loss : 0.441661 model2 loss : 0.019323
[00:28:48.771] iteration 17820 : model1 loss : 0.437037 model2 loss : 0.018967
[00:28:48.947] iteration 17821 : model1 loss : 0.440887 model2 loss : 0.022611
[00:28:49.117] iteration 17822 : model1 loss : 0.440383 model2 loss : 0.017853
[00:28:49.291] iteration 17823 : model1 loss : 0.436080 model2 loss : 0.021848
[00:28:49.462] iteration 17824 : model1 loss : 0.439396 model2 loss : 0.019025
[00:28:49.638] iteration 17825 : model1 loss : 0.439960 model2 loss : 0.021455
[00:28:49.811] iteration 17826 : model1 loss : 0.434556 model2 loss : 0.018461
[00:28:49.988] iteration 17827 : model1 loss : 0.440432 model2 loss : 0.022416
[00:28:50.158] iteration 17828 : model1 loss : 0.438638 model2 loss : 0.023557
[00:28:50.334] iteration 17829 : model1 loss : 0.435872 model2 loss : 0.019857
[00:28:52.486] iteration 17830 : model1 loss : 0.439163 model2 loss : 0.019999
[00:28:52.657] iteration 17831 : model1 loss : 0.440920 model2 loss : 0.020639
[00:28:52.833] iteration 17832 : model1 loss : 0.438550 model2 loss : 0.019690
[00:28:53.007] iteration 17833 : model1 loss : 0.438798 model2 loss : 0.018993
[00:28:53.181] iteration 17834 : model1 loss : 0.438612 model2 loss : 0.020411
[00:28:53.355] iteration 17835 : model1 loss : 0.442701 model2 loss : 0.019890
[00:28:53.534] iteration 17836 : model1 loss : 0.435019 model2 loss : 0.017865
[00:28:53.704] iteration 17837 : model1 loss : 0.440229 model2 loss : 0.020229
[00:28:53.879] iteration 17838 : model1 loss : 0.440777 model2 loss : 0.018844
[00:28:54.051] iteration 17839 : model1 loss : 0.436345 model2 loss : 0.020288
[00:28:54.227] iteration 17840 : model1 loss : 0.440971 model2 loss : 0.021558
[00:28:54.398] iteration 17841 : model1 loss : 0.436461 model2 loss : 0.018107
[00:28:54.577] iteration 17842 : model1 loss : 0.437456 model2 loss : 0.018182
[00:28:54.747] iteration 17843 : model1 loss : 0.432091 model2 loss : 0.021287
[00:28:54.924] iteration 17844 : model1 loss : 0.437319 model2 loss : 0.021420
[00:28:55.095] iteration 17845 : model1 loss : 0.433409 model2 loss : 0.020488
[00:28:55.272] iteration 17846 : model1 loss : 0.435129 model2 loss : 0.018947
[00:28:55.442] iteration 17847 : model1 loss : 0.439541 model2 loss : 0.022046
[00:28:55.623] iteration 17848 : model1 loss : 0.435005 model2 loss : 0.019804
[00:28:55.792] iteration 17849 : model1 loss : 0.434284 model2 loss : 0.016759
[00:28:55.965] iteration 17850 : model1 loss : 0.439598 model2 loss : 0.020115
[00:28:58.120] iteration 17851 : model1 loss : 0.439960 model2 loss : 0.019154
[00:28:58.294] iteration 17852 : model1 loss : 0.438973 model2 loss : 0.020094
[00:28:58.473] iteration 17853 : model1 loss : 0.440884 model2 loss : 0.018231
[00:28:58.647] iteration 17854 : model1 loss : 0.436584 model2 loss : 0.017671
[00:28:58.824] iteration 17855 : model1 loss : 0.437433 model2 loss : 0.019998
[00:28:58.996] iteration 17856 : model1 loss : 0.435224 model2 loss : 0.020853
[00:28:59.170] iteration 17857 : model1 loss : 0.439036 model2 loss : 0.018868
[00:28:59.347] iteration 17858 : model1 loss : 0.440847 model2 loss : 0.021236
[00:28:59.527] iteration 17859 : model1 loss : 0.436019 model2 loss : 0.017974
[00:28:59.699] iteration 17860 : model1 loss : 0.438825 model2 loss : 0.022037
[00:28:59.873] iteration 17861 : model1 loss : 0.438757 model2 loss : 0.018431
[00:29:00.042] iteration 17862 : model1 loss : 0.439295 model2 loss : 0.019839
[00:29:00.221] iteration 17863 : model1 loss : 0.436059 model2 loss : 0.020066
[00:29:00.392] iteration 17864 : model1 loss : 0.442040 model2 loss : 0.020004
[00:29:00.570] iteration 17865 : model1 loss : 0.433809 model2 loss : 0.017160
[00:29:00.740] iteration 17866 : model1 loss : 0.436835 model2 loss : 0.018684
[00:29:00.917] iteration 17867 : model1 loss : 0.438883 model2 loss : 0.021685
[00:29:01.088] iteration 17868 : model1 loss : 0.436416 model2 loss : 0.019543
[00:29:01.265] iteration 17869 : model1 loss : 0.432912 model2 loss : 0.017642
[00:29:01.435] iteration 17870 : model1 loss : 0.438432 model2 loss : 0.019547
[00:29:01.613] iteration 17871 : model1 loss : 0.442690 model2 loss : 0.018124
[00:29:03.735] iteration 17872 : model1 loss : 0.439661 model2 loss : 0.020677
[00:29:03.912] iteration 17873 : model1 loss : 0.435171 model2 loss : 0.020130
[00:29:04.090] iteration 17874 : model1 loss : 0.436300 model2 loss : 0.019230
[00:29:04.264] iteration 17875 : model1 loss : 0.438318 model2 loss : 0.017942
[00:29:04.439] iteration 17876 : model1 loss : 0.439780 model2 loss : 0.019866
[00:29:04.613] iteration 17877 : model1 loss : 0.439767 model2 loss : 0.025488
[00:29:04.789] iteration 17878 : model1 loss : 0.435191 model2 loss : 0.020843
[00:29:04.959] iteration 17879 : model1 loss : 0.440037 model2 loss : 0.019685
[00:29:05.134] iteration 17880 : model1 loss : 0.434919 model2 loss : 0.019430
[00:29:05.306] iteration 17881 : model1 loss : 0.437551 model2 loss : 0.019419
[00:29:05.483] iteration 17882 : model1 loss : 0.437876 model2 loss : 0.020751
[00:29:05.660] iteration 17883 : model1 loss : 0.438281 model2 loss : 0.020404
[00:29:05.836] iteration 17884 : model1 loss : 0.441099 model2 loss : 0.021680
[00:29:06.007] iteration 17885 : model1 loss : 0.436165 model2 loss : 0.018675
[00:29:06.183] iteration 17886 : model1 loss : 0.434533 model2 loss : 0.018317
[00:29:06.354] iteration 17887 : model1 loss : 0.432665 model2 loss : 0.019074
[00:29:06.532] iteration 17888 : model1 loss : 0.438189 model2 loss : 0.017573
[00:29:06.702] iteration 17889 : model1 loss : 0.442841 model2 loss : 0.018924
[00:29:06.880] iteration 17890 : model1 loss : 0.442716 model2 loss : 0.022252
[00:29:07.049] iteration 17891 : model1 loss : 0.433223 model2 loss : 0.016880
[00:29:07.226] iteration 17892 : model1 loss : 0.439510 model2 loss : 0.019118
[00:29:09.374] iteration 17893 : model1 loss : 0.437051 model2 loss : 0.018772
[00:29:09.546] iteration 17894 : model1 loss : 0.439820 model2 loss : 0.020316
[00:29:09.725] iteration 17895 : model1 loss : 0.440993 model2 loss : 0.020717
[00:29:09.900] iteration 17896 : model1 loss : 0.438678 model2 loss : 0.022254
[00:29:10.073] iteration 17897 : model1 loss : 0.433134 model2 loss : 0.019463
[00:29:10.243] iteration 17898 : model1 loss : 0.433574 model2 loss : 0.019614
[00:29:10.420] iteration 17899 : model1 loss : 0.437757 model2 loss : 0.022421
[00:29:10.594] iteration 17900 : model1 loss : 0.443567 model2 loss : 0.023843
[00:29:10.768] iteration 17901 : model1 loss : 0.443420 model2 loss : 0.020550
[00:29:10.939] iteration 17902 : model1 loss : 0.440459 model2 loss : 0.019370
[00:29:11.114] iteration 17903 : model1 loss : 0.442608 model2 loss : 0.020212
[00:29:11.284] iteration 17904 : model1 loss : 0.439219 model2 loss : 0.019603
[00:29:11.458] iteration 17905 : model1 loss : 0.436819 model2 loss : 0.019521
[00:29:11.633] iteration 17906 : model1 loss : 0.435487 model2 loss : 0.021458
[00:29:11.811] iteration 17907 : model1 loss : 0.436540 model2 loss : 0.018339
[00:29:11.982] iteration 17908 : model1 loss : 0.437074 model2 loss : 0.018900
[00:29:12.161] iteration 17909 : model1 loss : 0.437566 model2 loss : 0.020182
[00:29:12.334] iteration 17910 : model1 loss : 0.436768 model2 loss : 0.018772
[00:29:12.518] iteration 17911 : model1 loss : 0.437451 model2 loss : 0.017915
[00:29:12.686] iteration 17912 : model1 loss : 0.434794 model2 loss : 0.019797
[00:29:12.860] iteration 17913 : model1 loss : 0.438156 model2 loss : 0.019120
[00:29:14.978] iteration 17914 : model1 loss : 0.441839 model2 loss : 0.020290
[00:29:15.151] iteration 17915 : model1 loss : 0.439458 model2 loss : 0.018652
[00:29:15.333] iteration 17916 : model1 loss : 0.441291 model2 loss : 0.019054
[00:29:15.506] iteration 17917 : model1 loss : 0.434714 model2 loss : 0.018098
[00:29:15.684] iteration 17918 : model1 loss : 0.436213 model2 loss : 0.018788
[00:29:15.857] iteration 17919 : model1 loss : 0.438149 model2 loss : 0.019304
[00:29:16.030] iteration 17920 : model1 loss : 0.436124 model2 loss : 0.022209
[00:29:16.203] iteration 17921 : model1 loss : 0.438592 model2 loss : 0.018355
[00:29:16.380] iteration 17922 : model1 loss : 0.437735 model2 loss : 0.017822
[00:29:16.559] iteration 17923 : model1 loss : 0.436735 model2 loss : 0.020389
[00:29:16.732] iteration 17924 : model1 loss : 0.439643 model2 loss : 0.019191
[00:29:16.902] iteration 17925 : model1 loss : 0.444910 model2 loss : 0.024031
[00:29:17.079] iteration 17926 : model1 loss : 0.432369 model2 loss : 0.017004
[00:29:17.250] iteration 17927 : model1 loss : 0.438145 model2 loss : 0.019890
[00:29:17.431] iteration 17928 : model1 loss : 0.434941 model2 loss : 0.019807
[00:29:17.607] iteration 17929 : model1 loss : 0.439147 model2 loss : 0.021311
[00:29:17.783] iteration 17930 : model1 loss : 0.434693 model2 loss : 0.018949
[00:29:17.953] iteration 17931 : model1 loss : 0.437300 model2 loss : 0.021005
[00:29:18.129] iteration 17932 : model1 loss : 0.437097 model2 loss : 0.019829
[00:29:18.300] iteration 17933 : model1 loss : 0.435675 model2 loss : 0.018496
[00:29:18.479] iteration 17934 : model1 loss : 0.435285 model2 loss : 0.018899
[00:29:20.589] iteration 17935 : model1 loss : 0.440163 model2 loss : 0.018814
[00:29:20.759] iteration 17936 : model1 loss : 0.437337 model2 loss : 0.019849
[00:29:20.935] iteration 17937 : model1 loss : 0.443090 model2 loss : 0.022949
[00:29:21.109] iteration 17938 : model1 loss : 0.438207 model2 loss : 0.018773
[00:29:21.286] iteration 17939 : model1 loss : 0.439924 model2 loss : 0.020378
[00:29:21.461] iteration 17940 : model1 loss : 0.438367 model2 loss : 0.021270
[00:29:21.638] iteration 17941 : model1 loss : 0.435887 model2 loss : 0.017617
[00:29:21.809] iteration 17942 : model1 loss : 0.438689 model2 loss : 0.019862
[00:29:21.985] iteration 17943 : model1 loss : 0.438919 model2 loss : 0.020903
[00:29:22.156] iteration 17944 : model1 loss : 0.435295 model2 loss : 0.019715
[00:29:22.336] iteration 17945 : model1 loss : 0.437199 model2 loss : 0.016092
[00:29:22.515] iteration 17946 : model1 loss : 0.436209 model2 loss : 0.018763
[00:29:22.692] iteration 17947 : model1 loss : 0.430343 model2 loss : 0.017835
[00:29:22.862] iteration 17948 : model1 loss : 0.437988 model2 loss : 0.019039
[00:29:23.037] iteration 17949 : model1 loss : 0.442620 model2 loss : 0.022762
[00:29:23.207] iteration 17950 : model1 loss : 0.437279 model2 loss : 0.020468
[00:29:23.385] iteration 17951 : model1 loss : 0.436788 model2 loss : 0.018324
[00:29:23.557] iteration 17952 : model1 loss : 0.440349 model2 loss : 0.019507
[00:29:23.735] iteration 17953 : model1 loss : 0.437444 model2 loss : 0.022147
[00:29:23.904] iteration 17954 : model1 loss : 0.439833 model2 loss : 0.022009
[00:29:24.079] iteration 17955 : model1 loss : 0.436723 model2 loss : 0.019703
[00:29:26.200] iteration 17956 : model1 loss : 0.436561 model2 loss : 0.019357
[00:29:26.382] iteration 17957 : model1 loss : 0.438800 model2 loss : 0.023184
[00:29:26.562] iteration 17958 : model1 loss : 0.436763 model2 loss : 0.017932
[00:29:26.735] iteration 17959 : model1 loss : 0.443213 model2 loss : 0.022226
[00:29:26.911] iteration 17960 : model1 loss : 0.434375 model2 loss : 0.017524
[00:29:27.084] iteration 17961 : model1 loss : 0.439653 model2 loss : 0.019206
[00:29:27.260] iteration 17962 : model1 loss : 0.430974 model2 loss : 0.020065
[00:29:27.435] iteration 17963 : model1 loss : 0.442407 model2 loss : 0.020653
[00:29:27.613] iteration 17964 : model1 loss : 0.438488 model2 loss : 0.022204
[00:29:27.782] iteration 17965 : model1 loss : 0.435848 model2 loss : 0.022455
[00:29:27.961] iteration 17966 : model1 loss : 0.436869 model2 loss : 0.021188
[00:29:28.129] iteration 17967 : model1 loss : 0.437148 model2 loss : 0.019179
[00:29:28.307] iteration 17968 : model1 loss : 0.438717 model2 loss : 0.019860
[00:29:28.478] iteration 17969 : model1 loss : 0.438596 model2 loss : 0.017832
[00:29:28.655] iteration 17970 : model1 loss : 0.436608 model2 loss : 0.020370
[00:29:28.826] iteration 17971 : model1 loss : 0.440171 model2 loss : 0.019078
[00:29:29.003] iteration 17972 : model1 loss : 0.433507 model2 loss : 0.018526
[00:29:29.173] iteration 17973 : model1 loss : 0.437874 model2 loss : 0.020609
[00:29:29.350] iteration 17974 : model1 loss : 0.437061 model2 loss : 0.018568
[00:29:29.521] iteration 17975 : model1 loss : 0.443538 model2 loss : 0.021252
[00:29:29.695] iteration 17976 : model1 loss : 0.436326 model2 loss : 0.017952
[00:29:31.810] iteration 17977 : model1 loss : 0.439277 model2 loss : 0.019894
[00:29:31.992] iteration 17978 : model1 loss : 0.432339 model2 loss : 0.019493
[00:29:32.170] iteration 17979 : model1 loss : 0.438945 model2 loss : 0.020415
[00:29:32.347] iteration 17980 : model1 loss : 0.440177 model2 loss : 0.019062
[00:29:32.530] iteration 17981 : model1 loss : 0.434974 model2 loss : 0.018622
[00:29:32.701] iteration 17982 : model1 loss : 0.436708 model2 loss : 0.021993
[00:29:32.876] iteration 17983 : model1 loss : 0.437556 model2 loss : 0.019919
[00:29:33.047] iteration 17984 : model1 loss : 0.435902 model2 loss : 0.016376
[00:29:33.224] iteration 17985 : model1 loss : 0.436032 model2 loss : 0.019486
[00:29:33.394] iteration 17986 : model1 loss : 0.436579 model2 loss : 0.017134
[00:29:33.572] iteration 17987 : model1 loss : 0.435493 model2 loss : 0.019939
[00:29:33.743] iteration 17988 : model1 loss : 0.438786 model2 loss : 0.023556
[00:29:33.919] iteration 17989 : model1 loss : 0.439917 model2 loss : 0.021410
[00:29:34.090] iteration 17990 : model1 loss : 0.443860 model2 loss : 0.019065
[00:29:34.265] iteration 17991 : model1 loss : 0.441835 model2 loss : 0.021069
[00:29:34.437] iteration 17992 : model1 loss : 0.438458 model2 loss : 0.021455
[00:29:34.621] iteration 17993 : model1 loss : 0.434340 model2 loss : 0.018958
[00:29:34.791] iteration 17994 : model1 loss : 0.439151 model2 loss : 0.018919
[00:29:34.968] iteration 17995 : model1 loss : 0.436654 model2 loss : 0.018103
[00:29:35.138] iteration 17996 : model1 loss : 0.439358 model2 loss : 0.016917
[00:29:35.322] iteration 17997 : model1 loss : 0.440243 model2 loss : 0.018770
[00:29:37.456] iteration 17998 : model1 loss : 0.435461 model2 loss : 0.016451
[00:29:37.630] iteration 17999 : model1 loss : 0.438861 model2 loss : 0.018296
[00:29:37.811] iteration 18000 : model1 loss : 0.436431 model2 loss : 0.018298
[00:29:46.989] iteration 18000 : model1_mean_dice : 0.867776 model1_mean_hd95 : 4.335130
[00:29:56.141] iteration 18000 : model2_mean_dice : 0.875966 model2_mean_hd95 : 3.849604
[00:29:56.169] save model1 to ../model/ACDC/EVILv1_kl0.5_tau0.25_14_1337/unet\model1_iter_18000.pth
[00:29:56.217] save model2 to ../model/ACDC/EVILv1_kl0.5_tau0.25_14_1337/unet\model2_iter_18000.pth
[00:29:56.406] iteration 18001 : model1 loss : 0.438766 model2 loss : 0.020399
[00:29:56.586] iteration 18002 : model1 loss : 0.429518 model2 loss : 0.017954
[00:29:56.762] iteration 18003 : model1 loss : 0.438783 model2 loss : 0.021135
[00:29:56.932] iteration 18004 : model1 loss : 0.440297 model2 loss : 0.018650
[00:29:57.104] iteration 18005 : model1 loss : 0.442237 model2 loss : 0.019887
[00:29:57.275] iteration 18006 : model1 loss : 0.438060 model2 loss : 0.017937
[00:29:57.450] iteration 18007 : model1 loss : 0.433835 model2 loss : 0.018591
[00:29:57.624] iteration 18008 : model1 loss : 0.438261 model2 loss : 0.018494
[00:29:57.799] iteration 18009 : model1 loss : 0.436313 model2 loss : 0.017145
[00:29:57.968] iteration 18010 : model1 loss : 0.441224 model2 loss : 0.018943
[00:29:58.144] iteration 18011 : model1 loss : 0.436344 model2 loss : 0.020095
[00:29:58.317] iteration 18012 : model1 loss : 0.439209 model2 loss : 0.018927
[00:29:58.495] iteration 18013 : model1 loss : 0.433213 model2 loss : 0.019326
[00:29:58.668] iteration 18014 : model1 loss : 0.437892 model2 loss : 0.020511
[00:29:58.841] iteration 18015 : model1 loss : 0.443560 model2 loss : 0.024520
[00:29:59.011] iteration 18016 : model1 loss : 0.434375 model2 loss : 0.018259
[00:29:59.185] iteration 18017 : model1 loss : 0.436462 model2 loss : 0.019425
[00:29:59.354] iteration 18018 : model1 loss : 0.439931 model2 loss : 0.021142
[00:30:01.523] iteration 18019 : model1 loss : 0.434491 model2 loss : 0.017700
[00:30:01.702] iteration 18020 : model1 loss : 0.439907 model2 loss : 0.021063
[00:30:01.878] iteration 18021 : model1 loss : 0.433763 model2 loss : 0.019918
[00:30:02.048] iteration 18022 : model1 loss : 0.438680 model2 loss : 0.020482
[00:30:02.225] iteration 18023 : model1 loss : 0.437488 model2 loss : 0.018979
[00:30:02.397] iteration 18024 : model1 loss : 0.437083 model2 loss : 0.018892
[00:30:02.573] iteration 18025 : model1 loss : 0.434055 model2 loss : 0.018674
[00:30:02.743] iteration 18026 : model1 loss : 0.435395 model2 loss : 0.018872
[00:30:02.917] iteration 18027 : model1 loss : 0.436059 model2 loss : 0.020712
[00:30:03.088] iteration 18028 : model1 loss : 0.439747 model2 loss : 0.021716
[00:30:03.263] iteration 18029 : model1 loss : 0.440576 model2 loss : 0.021402
[00:30:03.435] iteration 18030 : model1 loss : 0.438125 model2 loss : 0.020621
[00:30:03.612] iteration 18031 : model1 loss : 0.440665 model2 loss : 0.018260
[00:30:03.781] iteration 18032 : model1 loss : 0.436224 model2 loss : 0.018698
[00:30:03.959] iteration 18033 : model1 loss : 0.438340 model2 loss : 0.018220
[00:30:04.131] iteration 18034 : model1 loss : 0.438634 model2 loss : 0.018058
[00:30:04.303] iteration 18035 : model1 loss : 0.438007 model2 loss : 0.017775
[00:30:04.473] iteration 18036 : model1 loss : 0.439300 model2 loss : 0.020633
[00:30:04.650] iteration 18037 : model1 loss : 0.440148 model2 loss : 0.016681
[00:30:04.819] iteration 18038 : model1 loss : 0.439879 model2 loss : 0.020050
[00:30:04.991] iteration 18039 : model1 loss : 0.435960 model2 loss : 0.018960
[00:30:07.118] iteration 18040 : model1 loss : 0.440987 model2 loss : 0.019174
[00:30:07.291] iteration 18041 : model1 loss : 0.438586 model2 loss : 0.018465
[00:30:07.478] iteration 18042 : model1 loss : 0.440797 model2 loss : 0.020601
[00:30:07.647] iteration 18043 : model1 loss : 0.437796 model2 loss : 0.019963
[00:30:07.823] iteration 18044 : model1 loss : 0.434846 model2 loss : 0.018486
[00:30:07.993] iteration 18045 : model1 loss : 0.434170 model2 loss : 0.020570
[00:30:08.167] iteration 18046 : model1 loss : 0.435871 model2 loss : 0.017778
[00:30:08.340] iteration 18047 : model1 loss : 0.440149 model2 loss : 0.021824
[00:30:08.517] iteration 18048 : model1 loss : 0.439939 model2 loss : 0.019683
[00:30:08.687] iteration 18049 : model1 loss : 0.444881 model2 loss : 0.022323
[00:30:08.862] iteration 18050 : model1 loss : 0.439126 model2 loss : 0.020296
[00:30:09.031] iteration 18051 : model1 loss : 0.436460 model2 loss : 0.017311
[00:30:09.207] iteration 18052 : model1 loss : 0.438295 model2 loss : 0.019767
[00:30:09.378] iteration 18053 : model1 loss : 0.435223 model2 loss : 0.019694
[00:30:09.553] iteration 18054 : model1 loss : 0.440380 model2 loss : 0.021242
[00:30:09.725] iteration 18055 : model1 loss : 0.437041 model2 loss : 0.017984
[00:30:09.905] iteration 18056 : model1 loss : 0.437720 model2 loss : 0.018629
[00:30:10.076] iteration 18057 : model1 loss : 0.437580 model2 loss : 0.019451
[00:30:10.253] iteration 18058 : model1 loss : 0.433734 model2 loss : 0.018561
[00:30:10.422] iteration 18059 : model1 loss : 0.432590 model2 loss : 0.018822
[00:30:10.600] iteration 18060 : model1 loss : 0.436335 model2 loss : 0.018489
[00:30:12.739] iteration 18061 : model1 loss : 0.440317 model2 loss : 0.018481
[00:30:12.911] iteration 18062 : model1 loss : 0.432794 model2 loss : 0.018769
[00:30:13.093] iteration 18063 : model1 loss : 0.437928 model2 loss : 0.019450
[00:30:13.264] iteration 18064 : model1 loss : 0.435675 model2 loss : 0.016853
[00:30:13.439] iteration 18065 : model1 loss : 0.437733 model2 loss : 0.018386
[00:30:13.614] iteration 18066 : model1 loss : 0.438578 model2 loss : 0.019551
[00:30:13.789] iteration 18067 : model1 loss : 0.436321 model2 loss : 0.020058
[00:30:13.959] iteration 18068 : model1 loss : 0.441939 model2 loss : 0.021468
[00:30:14.135] iteration 18069 : model1 loss : 0.440560 model2 loss : 0.020481
[00:30:14.308] iteration 18070 : model1 loss : 0.436912 model2 loss : 0.020817
[00:30:14.483] iteration 18071 : model1 loss : 0.441165 model2 loss : 0.022365
[00:30:14.656] iteration 18072 : model1 loss : 0.438933 model2 loss : 0.020673
[00:30:14.833] iteration 18073 : model1 loss : 0.437257 model2 loss : 0.020080
[00:30:15.002] iteration 18074 : model1 loss : 0.439371 model2 loss : 0.019729
[00:30:15.176] iteration 18075 : model1 loss : 0.437043 model2 loss : 0.020943
[00:30:15.349] iteration 18076 : model1 loss : 0.436223 model2 loss : 0.017699
[00:30:15.525] iteration 18077 : model1 loss : 0.437221 model2 loss : 0.018958
[00:30:15.696] iteration 18078 : model1 loss : 0.436250 model2 loss : 0.020492
[00:30:15.870] iteration 18079 : model1 loss : 0.436677 model2 loss : 0.019329
[00:30:16.040] iteration 18080 : model1 loss : 0.434628 model2 loss : 0.017963
[00:30:16.213] iteration 18081 : model1 loss : 0.436312 model2 loss : 0.019593
[00:30:18.357] iteration 18082 : model1 loss : 0.437734 model2 loss : 0.018439
[00:30:18.533] iteration 18083 : model1 loss : 0.436974 model2 loss : 0.017025
[00:30:18.712] iteration 18084 : model1 loss : 0.439256 model2 loss : 0.019809
[00:30:18.883] iteration 18085 : model1 loss : 0.438073 model2 loss : 0.018692
[00:30:19.059] iteration 18086 : model1 loss : 0.437468 model2 loss : 0.017851
[00:30:19.234] iteration 18087 : model1 loss : 0.436890 model2 loss : 0.017319
[00:30:19.411] iteration 18088 : model1 loss : 0.432981 model2 loss : 0.019570
[00:30:19.583] iteration 18089 : model1 loss : 0.436798 model2 loss : 0.017405
[00:30:19.761] iteration 18090 : model1 loss : 0.433416 model2 loss : 0.016917
[00:30:19.931] iteration 18091 : model1 loss : 0.443963 model2 loss : 0.024503
[00:30:20.107] iteration 18092 : model1 loss : 0.435669 model2 loss : 0.017912
[00:30:20.277] iteration 18093 : model1 loss : 0.441437 model2 loss : 0.019551
[00:30:20.452] iteration 18094 : model1 loss : 0.439523 model2 loss : 0.018714
[00:30:20.627] iteration 18095 : model1 loss : 0.435800 model2 loss : 0.022528
[00:30:20.803] iteration 18096 : model1 loss : 0.435728 model2 loss : 0.019001
[00:30:20.975] iteration 18097 : model1 loss : 0.437000 model2 loss : 0.019919
[00:30:21.150] iteration 18098 : model1 loss : 0.438212 model2 loss : 0.019853
[00:30:21.324] iteration 18099 : model1 loss : 0.436696 model2 loss : 0.018964
[00:30:21.499] iteration 18100 : model1 loss : 0.435033 model2 loss : 0.018913
[00:30:21.669] iteration 18101 : model1 loss : 0.441133 model2 loss : 0.019340
[00:30:21.841] iteration 18102 : model1 loss : 0.441112 model2 loss : 0.019668
[00:30:23.978] iteration 18103 : model1 loss : 0.434641 model2 loss : 0.018215
[00:30:24.150] iteration 18104 : model1 loss : 0.437934 model2 loss : 0.019129
[00:30:24.337] iteration 18105 : model1 loss : 0.442713 model2 loss : 0.020510
[00:30:24.509] iteration 18106 : model1 loss : 0.439735 model2 loss : 0.019187
[00:30:24.686] iteration 18107 : model1 loss : 0.436955 model2 loss : 0.020439
[00:30:24.856] iteration 18108 : model1 loss : 0.432342 model2 loss : 0.019434
[00:30:25.030] iteration 18109 : model1 loss : 0.435756 model2 loss : 0.020157
[00:30:25.200] iteration 18110 : model1 loss : 0.441345 model2 loss : 0.020333
[00:30:25.375] iteration 18111 : model1 loss : 0.438956 model2 loss : 0.019096
[00:30:25.548] iteration 18112 : model1 loss : 0.437564 model2 loss : 0.017524
[00:30:25.726] iteration 18113 : model1 loss : 0.437211 model2 loss : 0.020720
[00:30:25.896] iteration 18114 : model1 loss : 0.436655 model2 loss : 0.019554
[00:30:26.075] iteration 18115 : model1 loss : 0.442135 model2 loss : 0.020669
[00:30:26.246] iteration 18116 : model1 loss : 0.441014 model2 loss : 0.018577
[00:30:26.425] iteration 18117 : model1 loss : 0.437023 model2 loss : 0.017408
[00:30:26.602] iteration 18118 : model1 loss : 0.436020 model2 loss : 0.020458
[00:30:26.777] iteration 18119 : model1 loss : 0.434609 model2 loss : 0.017390
[00:30:26.946] iteration 18120 : model1 loss : 0.436214 model2 loss : 0.017257
[00:30:27.123] iteration 18121 : model1 loss : 0.437220 model2 loss : 0.019624
[00:30:27.293] iteration 18122 : model1 loss : 0.437858 model2 loss : 0.019645
[00:30:27.471] iteration 18123 : model1 loss : 0.432939 model2 loss : 0.018498
[00:30:29.616] iteration 18124 : model1 loss : 0.434638 model2 loss : 0.019377
[00:30:29.794] iteration 18125 : model1 loss : 0.437898 model2 loss : 0.019642
[00:30:29.971] iteration 18126 : model1 loss : 0.434204 model2 loss : 0.020012
[00:30:30.141] iteration 18127 : model1 loss : 0.436917 model2 loss : 0.020328
[00:30:30.319] iteration 18128 : model1 loss : 0.440063 model2 loss : 0.020797
[00:30:30.490] iteration 18129 : model1 loss : 0.440164 model2 loss : 0.019663
[00:30:30.668] iteration 18130 : model1 loss : 0.436052 model2 loss : 0.018288
[00:30:30.839] iteration 18131 : model1 loss : 0.436162 model2 loss : 0.019175
[00:30:31.015] iteration 18132 : model1 loss : 0.441057 model2 loss : 0.019260
[00:30:31.184] iteration 18133 : model1 loss : 0.439123 model2 loss : 0.019279
[00:30:31.361] iteration 18134 : model1 loss : 0.438725 model2 loss : 0.018933
[00:30:31.531] iteration 18135 : model1 loss : 0.435308 model2 loss : 0.018723
[00:30:31.710] iteration 18136 : model1 loss : 0.439050 model2 loss : 0.018542
[00:30:31.881] iteration 18137 : model1 loss : 0.435563 model2 loss : 0.019086
[00:30:32.057] iteration 18138 : model1 loss : 0.442055 model2 loss : 0.019396
[00:30:32.229] iteration 18139 : model1 loss : 0.440413 model2 loss : 0.019646
[00:30:32.403] iteration 18140 : model1 loss : 0.436026 model2 loss : 0.019509
[00:30:32.574] iteration 18141 : model1 loss : 0.437743 model2 loss : 0.021056
[00:30:32.748] iteration 18142 : model1 loss : 0.436861 model2 loss : 0.017741
[00:30:32.915] iteration 18143 : model1 loss : 0.438415 model2 loss : 0.019731
[00:30:33.090] iteration 18144 : model1 loss : 0.434600 model2 loss : 0.017132
[00:30:35.233] iteration 18145 : model1 loss : 0.438585 model2 loss : 0.020413
[00:30:35.411] iteration 18146 : model1 loss : 0.433906 model2 loss : 0.019326
[00:30:35.589] iteration 18147 : model1 loss : 0.435509 model2 loss : 0.019203
[00:30:35.762] iteration 18148 : model1 loss : 0.440723 model2 loss : 0.019303
[00:30:35.936] iteration 18149 : model1 loss : 0.442114 model2 loss : 0.020941
[00:30:36.109] iteration 18150 : model1 loss : 0.437167 model2 loss : 0.018068
[00:30:36.287] iteration 18151 : model1 loss : 0.436461 model2 loss : 0.019604
[00:30:36.462] iteration 18152 : model1 loss : 0.439731 model2 loss : 0.019805
[00:30:36.643] iteration 18153 : model1 loss : 0.439527 model2 loss : 0.021136
[00:30:36.812] iteration 18154 : model1 loss : 0.435501 model2 loss : 0.020024
[00:30:36.989] iteration 18155 : model1 loss : 0.438063 model2 loss : 0.019719
[00:30:37.159] iteration 18156 : model1 loss : 0.436343 model2 loss : 0.019142
[00:30:37.340] iteration 18157 : model1 loss : 0.439914 model2 loss : 0.019946
[00:30:37.514] iteration 18158 : model1 loss : 0.439837 model2 loss : 0.020838
[00:30:37.691] iteration 18159 : model1 loss : 0.434987 model2 loss : 0.020396
[00:30:37.861] iteration 18160 : model1 loss : 0.437791 model2 loss : 0.021827
[00:30:38.037] iteration 18161 : model1 loss : 0.440607 model2 loss : 0.020465
[00:30:38.207] iteration 18162 : model1 loss : 0.437193 model2 loss : 0.019974
[00:30:38.381] iteration 18163 : model1 loss : 0.435775 model2 loss : 0.017759
[00:30:38.550] iteration 18164 : model1 loss : 0.436566 model2 loss : 0.018237
[00:30:38.726] iteration 18165 : model1 loss : 0.434686 model2 loss : 0.019883
[00:30:40.882] iteration 18166 : model1 loss : 0.438257 model2 loss : 0.021932
[00:30:41.056] iteration 18167 : model1 loss : 0.440881 model2 loss : 0.021650
[00:30:41.239] iteration 18168 : model1 loss : 0.440497 model2 loss : 0.019711
[00:30:41.412] iteration 18169 : model1 loss : 0.438396 model2 loss : 0.019128
[00:30:41.591] iteration 18170 : model1 loss : 0.440120 model2 loss : 0.018580
[00:30:41.759] iteration 18171 : model1 loss : 0.441173 model2 loss : 0.020469
[00:30:41.934] iteration 18172 : model1 loss : 0.433137 model2 loss : 0.017150
[00:30:42.104] iteration 18173 : model1 loss : 0.436376 model2 loss : 0.016865
[00:30:42.281] iteration 18174 : model1 loss : 0.439724 model2 loss : 0.020051
[00:30:42.453] iteration 18175 : model1 loss : 0.433284 model2 loss : 0.019351
[00:30:42.633] iteration 18176 : model1 loss : 0.433671 model2 loss : 0.019354
[00:30:42.812] iteration 18177 : model1 loss : 0.438085 model2 loss : 0.019872
[00:30:42.990] iteration 18178 : model1 loss : 0.436982 model2 loss : 0.020892
[00:30:43.158] iteration 18179 : model1 loss : 0.436810 model2 loss : 0.017966
[00:30:43.335] iteration 18180 : model1 loss : 0.441307 model2 loss : 0.017620
[00:30:43.505] iteration 18181 : model1 loss : 0.435692 model2 loss : 0.020278
[00:30:43.681] iteration 18182 : model1 loss : 0.437122 model2 loss : 0.017813
[00:30:43.851] iteration 18183 : model1 loss : 0.437118 model2 loss : 0.017902
[00:30:44.028] iteration 18184 : model1 loss : 0.438069 model2 loss : 0.018122
[00:30:44.197] iteration 18185 : model1 loss : 0.436512 model2 loss : 0.018424
[00:30:44.369] iteration 18186 : model1 loss : 0.438065 model2 loss : 0.020035
[00:30:46.535] iteration 18187 : model1 loss : 0.435315 model2 loss : 0.019450
[00:30:46.710] iteration 18188 : model1 loss : 0.437613 model2 loss : 0.021134
[00:30:46.886] iteration 18189 : model1 loss : 0.442414 model2 loss : 0.018438
[00:30:47.057] iteration 18190 : model1 loss : 0.437984 model2 loss : 0.019657
[00:30:47.231] iteration 18191 : model1 loss : 0.436086 model2 loss : 0.017659
[00:30:47.403] iteration 18192 : model1 loss : 0.435121 model2 loss : 0.017588
[00:30:47.578] iteration 18193 : model1 loss : 0.433664 model2 loss : 0.018539
[00:30:47.748] iteration 18194 : model1 loss : 0.440751 model2 loss : 0.019450
[00:30:47.923] iteration 18195 : model1 loss : 0.438354 model2 loss : 0.022684
[00:30:48.093] iteration 18196 : model1 loss : 0.437888 model2 loss : 0.020664
[00:30:48.270] iteration 18197 : model1 loss : 0.435644 model2 loss : 0.018641
[00:30:48.443] iteration 18198 : model1 loss : 0.436023 model2 loss : 0.019092
[00:30:48.624] iteration 18199 : model1 loss : 0.439086 model2 loss : 0.019364
[00:30:48.793] iteration 18200 : model1 loss : 0.442340 model2 loss : 0.018410
[00:30:48.968] iteration 18201 : model1 loss : 0.439254 model2 loss : 0.021740
[00:30:49.138] iteration 18202 : model1 loss : 0.440339 model2 loss : 0.019177
[00:30:49.317] iteration 18203 : model1 loss : 0.437479 model2 loss : 0.018435
[00:30:49.488] iteration 18204 : model1 loss : 0.437243 model2 loss : 0.019071
[00:30:49.668] iteration 18205 : model1 loss : 0.433461 model2 loss : 0.021351
[00:30:49.837] iteration 18206 : model1 loss : 0.439961 model2 loss : 0.019357
[00:30:50.012] iteration 18207 : model1 loss : 0.437906 model2 loss : 0.020250
[00:30:52.142] iteration 18208 : model1 loss : 0.440724 model2 loss : 0.020919
[00:30:52.323] iteration 18209 : model1 loss : 0.435820 model2 loss : 0.017338
[00:30:52.508] iteration 18210 : model1 loss : 0.435099 model2 loss : 0.018179
[00:30:52.680] iteration 18211 : model1 loss : 0.437150 model2 loss : 0.020966
[00:30:52.853] iteration 18212 : model1 loss : 0.439249 model2 loss : 0.018558
[00:30:53.025] iteration 18213 : model1 loss : 0.437398 model2 loss : 0.018023
[00:30:53.200] iteration 18214 : model1 loss : 0.439138 model2 loss : 0.017696
[00:30:53.371] iteration 18215 : model1 loss : 0.435558 model2 loss : 0.018244
[00:30:53.546] iteration 18216 : model1 loss : 0.439512 model2 loss : 0.019117
[00:30:53.716] iteration 18217 : model1 loss : 0.440946 model2 loss : 0.021465
[00:30:53.896] iteration 18218 : model1 loss : 0.442912 model2 loss : 0.020898
[00:30:54.070] iteration 18219 : model1 loss : 0.439229 model2 loss : 0.019326
[00:30:54.245] iteration 18220 : model1 loss : 0.436916 model2 loss : 0.015884
[00:30:54.418] iteration 18221 : model1 loss : 0.434678 model2 loss : 0.018064
[00:30:54.598] iteration 18222 : model1 loss : 0.435834 model2 loss : 0.017012
[00:30:54.768] iteration 18223 : model1 loss : 0.430334 model2 loss : 0.016967
[00:30:54.944] iteration 18224 : model1 loss : 0.441429 model2 loss : 0.018570
[00:30:55.113] iteration 18225 : model1 loss : 0.434862 model2 loss : 0.018418
[00:30:55.289] iteration 18226 : model1 loss : 0.435742 model2 loss : 0.020707
[00:30:55.458] iteration 18227 : model1 loss : 0.440269 model2 loss : 0.019463
[00:30:55.633] iteration 18228 : model1 loss : 0.441282 model2 loss : 0.020181
[00:30:57.751] iteration 18229 : model1 loss : 0.434368 model2 loss : 0.017509
[00:30:57.927] iteration 18230 : model1 loss : 0.433527 model2 loss : 0.018236
[00:30:58.108] iteration 18231 : model1 loss : 0.436037 model2 loss : 0.018501
[00:30:58.278] iteration 18232 : model1 loss : 0.440569 model2 loss : 0.019173
[00:30:58.455] iteration 18233 : model1 loss : 0.442713 model2 loss : 0.022190
[00:30:58.628] iteration 18234 : model1 loss : 0.439425 model2 loss : 0.018046
[00:30:58.802] iteration 18235 : model1 loss : 0.436895 model2 loss : 0.018362
[00:30:58.973] iteration 18236 : model1 loss : 0.437959 model2 loss : 0.019420
[00:30:59.148] iteration 18237 : model1 loss : 0.440634 model2 loss : 0.018907
[00:30:59.323] iteration 18238 : model1 loss : 0.435055 model2 loss : 0.020804
[00:30:59.504] iteration 18239 : model1 loss : 0.440370 model2 loss : 0.019441
[00:30:59.675] iteration 18240 : model1 loss : 0.436506 model2 loss : 0.019434
[00:30:59.849] iteration 18241 : model1 loss : 0.436092 model2 loss : 0.021291
[00:31:00.020] iteration 18242 : model1 loss : 0.435652 model2 loss : 0.019066
[00:31:00.201] iteration 18243 : model1 loss : 0.436323 model2 loss : 0.020883
[00:31:00.372] iteration 18244 : model1 loss : 0.435615 model2 loss : 0.018054
[00:31:00.549] iteration 18245 : model1 loss : 0.438303 model2 loss : 0.019338
[00:31:00.720] iteration 18246 : model1 loss : 0.438785 model2 loss : 0.019513
[00:31:00.894] iteration 18247 : model1 loss : 0.438390 model2 loss : 0.018541
[00:31:01.064] iteration 18248 : model1 loss : 0.438129 model2 loss : 0.018712
[00:31:01.238] iteration 18249 : model1 loss : 0.439649 model2 loss : 0.018551
[00:31:03.377] iteration 18250 : model1 loss : 0.440127 model2 loss : 0.018414
[00:31:03.551] iteration 18251 : model1 loss : 0.436640 model2 loss : 0.020475
[00:31:03.732] iteration 18252 : model1 loss : 0.436793 model2 loss : 0.019361
[00:31:03.901] iteration 18253 : model1 loss : 0.436208 model2 loss : 0.018384
[00:31:04.077] iteration 18254 : model1 loss : 0.435613 model2 loss : 0.018601
[00:31:04.248] iteration 18255 : model1 loss : 0.436260 model2 loss : 0.017931
[00:31:04.425] iteration 18256 : model1 loss : 0.438506 model2 loss : 0.019626
[00:31:04.601] iteration 18257 : model1 loss : 0.440125 model2 loss : 0.017823
[00:31:04.778] iteration 18258 : model1 loss : 0.442681 model2 loss : 0.021258
[00:31:04.949] iteration 18259 : model1 loss : 0.438187 model2 loss : 0.020737
[00:31:05.127] iteration 18260 : model1 loss : 0.436755 model2 loss : 0.018302
[00:31:05.301] iteration 18261 : model1 loss : 0.436534 model2 loss : 0.018407
[00:31:05.476] iteration 18262 : model1 loss : 0.440765 model2 loss : 0.020190
[00:31:05.648] iteration 18263 : model1 loss : 0.437868 model2 loss : 0.018525
[00:31:05.823] iteration 18264 : model1 loss : 0.436535 model2 loss : 0.017738
[00:31:05.993] iteration 18265 : model1 loss : 0.438993 model2 loss : 0.018857
[00:31:06.168] iteration 18266 : model1 loss : 0.434733 model2 loss : 0.019282
[00:31:06.341] iteration 18267 : model1 loss : 0.434636 model2 loss : 0.018060
[00:31:06.517] iteration 18268 : model1 loss : 0.435991 model2 loss : 0.017746
[00:31:06.686] iteration 18269 : model1 loss : 0.438278 model2 loss : 0.019597
[00:31:06.859] iteration 18270 : model1 loss : 0.440649 model2 loss : 0.019989
[00:31:09.093] iteration 18271 : model1 loss : 0.441955 model2 loss : 0.021588
[00:31:09.270] iteration 18272 : model1 loss : 0.440614 model2 loss : 0.020930
[00:31:09.449] iteration 18273 : model1 loss : 0.438589 model2 loss : 0.018378
[00:31:09.621] iteration 18274 : model1 loss : 0.435065 model2 loss : 0.019155
[00:31:09.798] iteration 18275 : model1 loss : 0.436581 model2 loss : 0.019784
[00:31:09.968] iteration 18276 : model1 loss : 0.433378 model2 loss : 0.020327
[00:31:10.145] iteration 18277 : model1 loss : 0.436758 model2 loss : 0.017497
[00:31:10.321] iteration 18278 : model1 loss : 0.436940 model2 loss : 0.018420
[00:31:10.498] iteration 18279 : model1 loss : 0.437975 model2 loss : 0.020927
[00:31:10.671] iteration 18280 : model1 loss : 0.441427 model2 loss : 0.019127
[00:31:10.853] iteration 18281 : model1 loss : 0.438451 model2 loss : 0.023064
[00:31:11.031] iteration 18282 : model1 loss : 0.439216 model2 loss : 0.020661
[00:31:11.209] iteration 18283 : model1 loss : 0.437602 model2 loss : 0.019266
[00:31:11.384] iteration 18284 : model1 loss : 0.443130 model2 loss : 0.019520
[00:31:11.565] iteration 18285 : model1 loss : 0.440723 model2 loss : 0.022396
[00:31:11.738] iteration 18286 : model1 loss : 0.438985 model2 loss : 0.019302
[00:31:11.915] iteration 18287 : model1 loss : 0.435850 model2 loss : 0.018313
[00:31:12.086] iteration 18288 : model1 loss : 0.431711 model2 loss : 0.018987
[00:31:12.270] iteration 18289 : model1 loss : 0.439746 model2 loss : 0.018944
[00:31:12.441] iteration 18290 : model1 loss : 0.438219 model2 loss : 0.018131
[00:31:12.619] iteration 18291 : model1 loss : 0.435667 model2 loss : 0.018754
[00:31:16.042] iteration 18292 : model1 loss : 0.437597 model2 loss : 0.017574
[00:31:16.211] iteration 18293 : model1 loss : 0.436434 model2 loss : 0.018793
[00:31:16.382] iteration 18294 : model1 loss : 0.435168 model2 loss : 0.014845
[00:31:16.553] iteration 18295 : model1 loss : 0.437711 model2 loss : 0.021527
[00:31:16.721] iteration 18296 : model1 loss : 0.445282 model2 loss : 0.022151
[00:31:16.888] iteration 18297 : model1 loss : 0.439376 model2 loss : 0.018111
[00:31:17.056] iteration 18298 : model1 loss : 0.430528 model2 loss : 0.019234
[00:31:17.224] iteration 18299 : model1 loss : 0.442269 model2 loss : 0.019494
[00:31:17.395] iteration 18300 : model1 loss : 0.437276 model2 loss : 0.018704
[00:31:17.572] iteration 18301 : model1 loss : 0.441569 model2 loss : 0.023412
[00:31:17.738] iteration 18302 : model1 loss : 0.437921 model2 loss : 0.017378
[00:31:17.906] iteration 18303 : model1 loss : 0.435456 model2 loss : 0.021686
[00:31:18.074] iteration 18304 : model1 loss : 0.431512 model2 loss : 0.017319
[00:31:18.247] iteration 18305 : model1 loss : 0.438696 model2 loss : 0.020242
[00:31:18.418] iteration 18306 : model1 loss : 0.436575 model2 loss : 0.018236
[00:31:18.589] iteration 18307 : model1 loss : 0.435557 model2 loss : 0.017265
[00:31:18.754] iteration 18308 : model1 loss : 0.439267 model2 loss : 0.019489
[00:31:18.926] iteration 18309 : model1 loss : 0.444224 model2 loss : 0.021762
[00:31:19.093] iteration 18310 : model1 loss : 0.436069 model2 loss : 0.020421
[00:31:19.259] iteration 18311 : model1 loss : 0.436047 model2 loss : 0.022074
[00:31:19.431] iteration 18312 : model1 loss : 0.438842 model2 loss : 0.017447
[00:31:21.499] iteration 18313 : model1 loss : 0.435726 model2 loss : 0.018554
[00:31:21.670] iteration 18314 : model1 loss : 0.435341 model2 loss : 0.018421
[00:31:21.840] iteration 18315 : model1 loss : 0.436372 model2 loss : 0.020458
[00:31:22.007] iteration 18316 : model1 loss : 0.438618 model2 loss : 0.019563
[00:31:22.177] iteration 18317 : model1 loss : 0.435192 model2 loss : 0.017984
[00:31:22.347] iteration 18318 : model1 loss : 0.440500 model2 loss : 0.020728
[00:31:22.517] iteration 18319 : model1 loss : 0.436959 model2 loss : 0.019634
[00:31:22.684] iteration 18320 : model1 loss : 0.436835 model2 loss : 0.017259
[00:31:22.855] iteration 18321 : model1 loss : 0.441554 model2 loss : 0.021495
[00:31:23.023] iteration 18322 : model1 loss : 0.438576 model2 loss : 0.018329
[00:31:23.193] iteration 18323 : model1 loss : 0.435224 model2 loss : 0.020156
[00:31:23.361] iteration 18324 : model1 loss : 0.436020 model2 loss : 0.019814
[00:31:23.530] iteration 18325 : model1 loss : 0.438347 model2 loss : 0.018714
[00:31:23.699] iteration 18326 : model1 loss : 0.444698 model2 loss : 0.022084
[00:31:23.869] iteration 18327 : model1 loss : 0.435057 model2 loss : 0.019991
[00:31:24.035] iteration 18328 : model1 loss : 0.438424 model2 loss : 0.021836
[00:31:24.205] iteration 18329 : model1 loss : 0.441002 model2 loss : 0.020600
[00:31:24.372] iteration 18330 : model1 loss : 0.442221 model2 loss : 0.020414
[00:31:24.541] iteration 18331 : model1 loss : 0.437829 model2 loss : 0.020186
[00:31:24.708] iteration 18332 : model1 loss : 0.436285 model2 loss : 0.018915
[00:31:24.874] iteration 18333 : model1 loss : 0.434577 model2 loss : 0.020114
[00:31:26.880] iteration 18334 : model1 loss : 0.438480 model2 loss : 0.021579
[00:31:27.051] iteration 18335 : model1 loss : 0.440479 model2 loss : 0.018485
[00:31:27.222] iteration 18336 : model1 loss : 0.436993 model2 loss : 0.019269
[00:31:27.389] iteration 18337 : model1 loss : 0.437231 model2 loss : 0.019069
[00:31:27.558] iteration 18338 : model1 loss : 0.437591 model2 loss : 0.018058
[00:31:27.723] iteration 18339 : model1 loss : 0.440117 model2 loss : 0.020163
[00:31:27.894] iteration 18340 : model1 loss : 0.434932 model2 loss : 0.019623
[00:31:28.059] iteration 18341 : model1 loss : 0.435534 model2 loss : 0.018280
[00:31:28.227] iteration 18342 : model1 loss : 0.439471 model2 loss : 0.022669
[00:31:28.396] iteration 18343 : model1 loss : 0.436512 model2 loss : 0.020125
[00:31:28.567] iteration 18344 : model1 loss : 0.438243 model2 loss : 0.019659
[00:31:28.733] iteration 18345 : model1 loss : 0.438052 model2 loss : 0.019122
[00:31:28.901] iteration 18346 : model1 loss : 0.437767 model2 loss : 0.018148
[00:31:29.068] iteration 18347 : model1 loss : 0.438744 model2 loss : 0.019562
[00:31:29.237] iteration 18348 : model1 loss : 0.439206 model2 loss : 0.018299
[00:31:29.405] iteration 18349 : model1 loss : 0.439781 model2 loss : 0.020245
[00:31:29.577] iteration 18350 : model1 loss : 0.435568 model2 loss : 0.018862
[00:31:29.742] iteration 18351 : model1 loss : 0.437350 model2 loss : 0.019038
[00:31:29.911] iteration 18352 : model1 loss : 0.439069 model2 loss : 0.021512
[00:31:30.075] iteration 18353 : model1 loss : 0.434613 model2 loss : 0.018440
[00:31:30.243] iteration 18354 : model1 loss : 0.437315 model2 loss : 0.019178
[00:31:32.260] iteration 18355 : model1 loss : 0.437981 model2 loss : 0.018648
[00:31:32.437] iteration 18356 : model1 loss : 0.438214 model2 loss : 0.020217
[00:31:32.609] iteration 18357 : model1 loss : 0.435630 model2 loss : 0.018042
[00:31:32.775] iteration 18358 : model1 loss : 0.437929 model2 loss : 0.018882
[00:31:32.945] iteration 18359 : model1 loss : 0.435793 model2 loss : 0.019503
[00:31:33.111] iteration 18360 : model1 loss : 0.435792 model2 loss : 0.018132
[00:31:33.279] iteration 18361 : model1 loss : 0.436527 model2 loss : 0.022463
[00:31:33.445] iteration 18362 : model1 loss : 0.442616 model2 loss : 0.021249
[00:31:33.618] iteration 18363 : model1 loss : 0.436378 model2 loss : 0.017255
[00:31:33.783] iteration 18364 : model1 loss : 0.439492 model2 loss : 0.017913
[00:31:33.954] iteration 18365 : model1 loss : 0.442576 model2 loss : 0.020247
[00:31:34.122] iteration 18366 : model1 loss : 0.437309 model2 loss : 0.018885
[00:31:34.290] iteration 18367 : model1 loss : 0.438357 model2 loss : 0.020882
[00:31:34.456] iteration 18368 : model1 loss : 0.434476 model2 loss : 0.018020
[00:31:34.629] iteration 18369 : model1 loss : 0.442317 model2 loss : 0.022013
[00:31:34.796] iteration 18370 : model1 loss : 0.439829 model2 loss : 0.019937
[00:31:34.964] iteration 18371 : model1 loss : 0.435646 model2 loss : 0.018924
[00:31:35.132] iteration 18372 : model1 loss : 0.435956 model2 loss : 0.018115
[00:31:35.302] iteration 18373 : model1 loss : 0.439746 model2 loss : 0.017066
[00:31:35.469] iteration 18374 : model1 loss : 0.439139 model2 loss : 0.018032
[00:31:35.635] iteration 18375 : model1 loss : 0.431174 model2 loss : 0.018548
[00:31:37.693] iteration 18376 : model1 loss : 0.437617 model2 loss : 0.020077
[00:31:37.862] iteration 18377 : model1 loss : 0.434751 model2 loss : 0.019296
[00:31:38.031] iteration 18378 : model1 loss : 0.435153 model2 loss : 0.019557
[00:31:38.197] iteration 18379 : model1 loss : 0.437719 model2 loss : 0.018255
[00:31:38.368] iteration 18380 : model1 loss : 0.438223 model2 loss : 0.019884
[00:31:38.536] iteration 18381 : model1 loss : 0.438125 model2 loss : 0.019198
[00:31:38.706] iteration 18382 : model1 loss : 0.439768 model2 loss : 0.020174
[00:31:38.874] iteration 18383 : model1 loss : 0.439130 model2 loss : 0.020738
[00:31:39.042] iteration 18384 : model1 loss : 0.438100 model2 loss : 0.019915
[00:31:39.208] iteration 18385 : model1 loss : 0.435300 model2 loss : 0.017505
[00:31:39.375] iteration 18386 : model1 loss : 0.432709 model2 loss : 0.017914
[00:31:39.542] iteration 18387 : model1 loss : 0.440178 model2 loss : 0.017849
[00:31:39.709] iteration 18388 : model1 loss : 0.439791 model2 loss : 0.019796
[00:31:39.876] iteration 18389 : model1 loss : 0.438248 model2 loss : 0.020782
[00:31:40.043] iteration 18390 : model1 loss : 0.438189 model2 loss : 0.018417
[00:31:40.211] iteration 18391 : model1 loss : 0.443480 model2 loss : 0.021638
[00:31:40.381] iteration 18392 : model1 loss : 0.434718 model2 loss : 0.018973
[00:31:40.548] iteration 18393 : model1 loss : 0.436885 model2 loss : 0.019899
[00:31:40.716] iteration 18394 : model1 loss : 0.437419 model2 loss : 0.019828
[00:31:40.882] iteration 18395 : model1 loss : 0.440761 model2 loss : 0.019452
[00:31:41.051] iteration 18396 : model1 loss : 0.437090 model2 loss : 0.018856
[00:31:43.085] iteration 18397 : model1 loss : 0.439025 model2 loss : 0.018443
[00:31:43.253] iteration 18398 : model1 loss : 0.440096 model2 loss : 0.019942
[00:31:43.423] iteration 18399 : model1 loss : 0.441328 model2 loss : 0.022549
[00:31:43.592] iteration 18400 : model1 loss : 0.438313 model2 loss : 0.019942
[00:31:43.760] iteration 18401 : model1 loss : 0.441014 model2 loss : 0.022474
[00:31:43.926] iteration 18402 : model1 loss : 0.432663 model2 loss : 0.017244
[00:31:44.094] iteration 18403 : model1 loss : 0.433887 model2 loss : 0.018566
[00:31:44.261] iteration 18404 : model1 loss : 0.436984 model2 loss : 0.016508
[00:31:44.433] iteration 18405 : model1 loss : 0.437880 model2 loss : 0.020380
[00:31:44.603] iteration 18406 : model1 loss : 0.441992 model2 loss : 0.018311
[00:31:44.771] iteration 18407 : model1 loss : 0.439800 model2 loss : 0.021809
[00:31:44.938] iteration 18408 : model1 loss : 0.439820 model2 loss : 0.017020
[00:31:45.108] iteration 18409 : model1 loss : 0.437584 model2 loss : 0.018711
[00:31:45.276] iteration 18410 : model1 loss : 0.437815 model2 loss : 0.020609
[00:31:45.445] iteration 18411 : model1 loss : 0.434045 model2 loss : 0.019461
[00:31:45.615] iteration 18412 : model1 loss : 0.437956 model2 loss : 0.018651
[00:31:45.785] iteration 18413 : model1 loss : 0.436224 model2 loss : 0.019913
[00:31:45.952] iteration 18414 : model1 loss : 0.433570 model2 loss : 0.017198
[00:31:46.122] iteration 18415 : model1 loss : 0.443456 model2 loss : 0.019724
[00:31:46.289] iteration 18416 : model1 loss : 0.436164 model2 loss : 0.018066
[00:31:46.456] iteration 18417 : model1 loss : 0.436375 model2 loss : 0.018962
[00:31:48.513] iteration 18418 : model1 loss : 0.441388 model2 loss : 0.020594
[00:31:48.680] iteration 18419 : model1 loss : 0.438007 model2 loss : 0.023958
[00:31:48.851] iteration 18420 : model1 loss : 0.439464 model2 loss : 0.020381
[00:31:49.016] iteration 18421 : model1 loss : 0.438655 model2 loss : 0.020169
[00:31:49.188] iteration 18422 : model1 loss : 0.440968 model2 loss : 0.019287
[00:31:49.355] iteration 18423 : model1 loss : 0.437672 model2 loss : 0.018242
[00:31:49.523] iteration 18424 : model1 loss : 0.439612 model2 loss : 0.020323
[00:31:49.689] iteration 18425 : model1 loss : 0.435526 model2 loss : 0.018546
[00:31:49.857] iteration 18426 : model1 loss : 0.434223 model2 loss : 0.018290
[00:31:50.023] iteration 18427 : model1 loss : 0.436923 model2 loss : 0.018969
[00:31:50.194] iteration 18428 : model1 loss : 0.442660 model2 loss : 0.019206
[00:31:50.367] iteration 18429 : model1 loss : 0.441294 model2 loss : 0.021279
[00:31:50.537] iteration 18430 : model1 loss : 0.435742 model2 loss : 0.020429
[00:31:50.704] iteration 18431 : model1 loss : 0.439129 model2 loss : 0.018716
[00:31:50.873] iteration 18432 : model1 loss : 0.434763 model2 loss : 0.018501
[00:31:51.038] iteration 18433 : model1 loss : 0.436751 model2 loss : 0.018856
[00:31:51.207] iteration 18434 : model1 loss : 0.438095 model2 loss : 0.019209
[00:31:51.376] iteration 18435 : model1 loss : 0.435379 model2 loss : 0.018381
[00:31:51.547] iteration 18436 : model1 loss : 0.440955 model2 loss : 0.022052
[00:31:51.711] iteration 18437 : model1 loss : 0.434553 model2 loss : 0.018688
[00:31:51.879] iteration 18438 : model1 loss : 0.436576 model2 loss : 0.019228
[00:31:53.888] iteration 18439 : model1 loss : 0.441796 model2 loss : 0.026532
[00:31:54.054] iteration 18440 : model1 loss : 0.441359 model2 loss : 0.018978
[00:31:54.223] iteration 18441 : model1 loss : 0.437279 model2 loss : 0.018193
[00:31:54.389] iteration 18442 : model1 loss : 0.439285 model2 loss : 0.018778
[00:31:54.567] iteration 18443 : model1 loss : 0.437609 model2 loss : 0.018602
[00:31:54.733] iteration 18444 : model1 loss : 0.433746 model2 loss : 0.018149
[00:31:54.902] iteration 18445 : model1 loss : 0.439717 model2 loss : 0.021166
[00:31:55.071] iteration 18446 : model1 loss : 0.430361 model2 loss : 0.018189
[00:31:55.240] iteration 18447 : model1 loss : 0.439255 model2 loss : 0.017553
[00:31:55.407] iteration 18448 : model1 loss : 0.441727 model2 loss : 0.020552
[00:31:55.578] iteration 18449 : model1 loss : 0.438643 model2 loss : 0.021277
[00:31:55.743] iteration 18450 : model1 loss : 0.439683 model2 loss : 0.020098
[00:31:55.913] iteration 18451 : model1 loss : 0.436089 model2 loss : 0.018718
[00:31:56.081] iteration 18452 : model1 loss : 0.440297 model2 loss : 0.021426
[00:31:56.248] iteration 18453 : model1 loss : 0.440997 model2 loss : 0.023709
[00:31:56.416] iteration 18454 : model1 loss : 0.443441 model2 loss : 0.022590
[00:31:56.585] iteration 18455 : model1 loss : 0.434762 model2 loss : 0.019927
[00:31:56.755] iteration 18456 : model1 loss : 0.435403 model2 loss : 0.018883
[00:31:56.922] iteration 18457 : model1 loss : 0.435530 model2 loss : 0.019053
[00:31:57.087] iteration 18458 : model1 loss : 0.437380 model2 loss : 0.017473
[00:31:57.254] iteration 18459 : model1 loss : 0.432235 model2 loss : 0.019054
[00:31:59.266] iteration 18460 : model1 loss : 0.438596 model2 loss : 0.019630
[00:31:59.434] iteration 18461 : model1 loss : 0.434840 model2 loss : 0.019350
[00:31:59.603] iteration 18462 : model1 loss : 0.440558 model2 loss : 0.022238
[00:31:59.769] iteration 18463 : model1 loss : 0.434658 model2 loss : 0.020257
[00:31:59.938] iteration 18464 : model1 loss : 0.440725 model2 loss : 0.020139
[00:32:00.104] iteration 18465 : model1 loss : 0.437715 model2 loss : 0.021245
[00:32:00.275] iteration 18466 : model1 loss : 0.436322 model2 loss : 0.018920
[00:32:00.443] iteration 18467 : model1 loss : 0.438298 model2 loss : 0.019107
[00:32:00.616] iteration 18468 : model1 loss : 0.441428 model2 loss : 0.020897
[00:32:00.783] iteration 18469 : model1 loss : 0.437335 model2 loss : 0.019178
[00:32:00.952] iteration 18470 : model1 loss : 0.444065 model2 loss : 0.023458
[00:32:01.120] iteration 18471 : model1 loss : 0.437483 model2 loss : 0.020575
[00:32:01.292] iteration 18472 : model1 loss : 0.437977 model2 loss : 0.019698
[00:32:01.458] iteration 18473 : model1 loss : 0.439461 model2 loss : 0.018765
[00:32:01.631] iteration 18474 : model1 loss : 0.440735 model2 loss : 0.021648
[00:32:01.797] iteration 18475 : model1 loss : 0.441667 model2 loss : 0.021122
[00:32:01.963] iteration 18476 : model1 loss : 0.432952 model2 loss : 0.018471
[00:32:02.129] iteration 18477 : model1 loss : 0.439231 model2 loss : 0.018421
[00:32:02.299] iteration 18478 : model1 loss : 0.434991 model2 loss : 0.019249
[00:32:02.470] iteration 18479 : model1 loss : 0.440881 model2 loss : 0.018363
[00:32:02.639] iteration 18480 : model1 loss : 0.431577 model2 loss : 0.019516
[00:32:04.641] iteration 18481 : model1 loss : 0.434725 model2 loss : 0.020196
[00:32:04.812] iteration 18482 : model1 loss : 0.436858 model2 loss : 0.019752
[00:32:04.980] iteration 18483 : model1 loss : 0.438045 model2 loss : 0.018901
[00:32:05.146] iteration 18484 : model1 loss : 0.435976 model2 loss : 0.020420
[00:32:05.316] iteration 18485 : model1 loss : 0.431845 model2 loss : 0.016456
[00:32:05.485] iteration 18486 : model1 loss : 0.438464 model2 loss : 0.019240
[00:32:05.655] iteration 18487 : model1 loss : 0.437500 model2 loss : 0.018571
[00:32:05.821] iteration 18488 : model1 loss : 0.437361 model2 loss : 0.018849
[00:32:05.991] iteration 18489 : model1 loss : 0.435742 model2 loss : 0.017056
[00:32:06.157] iteration 18490 : model1 loss : 0.439797 model2 loss : 0.017432
[00:32:06.327] iteration 18491 : model1 loss : 0.436009 model2 loss : 0.020238
[00:32:06.493] iteration 18492 : model1 loss : 0.435446 model2 loss : 0.018040
[00:32:06.664] iteration 18493 : model1 loss : 0.433510 model2 loss : 0.017270
[00:32:06.829] iteration 18494 : model1 loss : 0.444942 model2 loss : 0.021980
[00:32:06.998] iteration 18495 : model1 loss : 0.440774 model2 loss : 0.018402
[00:32:07.168] iteration 18496 : model1 loss : 0.436321 model2 loss : 0.018216
[00:32:07.339] iteration 18497 : model1 loss : 0.438013 model2 loss : 0.021694
[00:32:07.510] iteration 18498 : model1 loss : 0.441287 model2 loss : 0.021873
[00:32:07.677] iteration 18499 : model1 loss : 0.437952 model2 loss : 0.018752
[00:32:07.843] iteration 18500 : model1 loss : 0.442243 model2 loss : 0.022778
[00:32:08.012] iteration 18501 : model1 loss : 0.436816 model2 loss : 0.019281
[00:32:10.051] iteration 18502 : model1 loss : 0.438521 model2 loss : 0.018358
[00:32:10.224] iteration 18503 : model1 loss : 0.435011 model2 loss : 0.018493
[00:32:10.396] iteration 18504 : model1 loss : 0.440507 model2 loss : 0.022125
[00:32:10.561] iteration 18505 : model1 loss : 0.443216 model2 loss : 0.024134
[00:32:10.728] iteration 18506 : model1 loss : 0.441841 model2 loss : 0.018643
[00:32:10.911] iteration 18507 : model1 loss : 0.436132 model2 loss : 0.017519
[00:32:11.079] iteration 18508 : model1 loss : 0.441657 model2 loss : 0.019906
[00:32:11.244] iteration 18509 : model1 loss : 0.436829 model2 loss : 0.017622
[00:32:11.413] iteration 18510 : model1 loss : 0.439417 model2 loss : 0.019299
[00:32:11.582] iteration 18511 : model1 loss : 0.431302 model2 loss : 0.019106
[00:32:11.753] iteration 18512 : model1 loss : 0.437826 model2 loss : 0.017389
[00:32:11.918] iteration 18513 : model1 loss : 0.442013 model2 loss : 0.021484
[00:32:12.094] iteration 18514 : model1 loss : 0.435576 model2 loss : 0.019176
[00:32:12.261] iteration 18515 : model1 loss : 0.434580 model2 loss : 0.019898
[00:32:12.434] iteration 18516 : model1 loss : 0.435830 model2 loss : 0.018677
[00:32:12.604] iteration 18517 : model1 loss : 0.436748 model2 loss : 0.019790
[00:32:12.772] iteration 18518 : model1 loss : 0.437089 model2 loss : 0.019317
[00:32:12.939] iteration 18519 : model1 loss : 0.440515 model2 loss : 0.020075
[00:32:13.106] iteration 18520 : model1 loss : 0.438721 model2 loss : 0.019173
[00:32:13.271] iteration 18521 : model1 loss : 0.436381 model2 loss : 0.017444
[00:32:13.449] iteration 18522 : model1 loss : 0.436567 model2 loss : 0.017992
[00:32:15.459] iteration 18523 : model1 loss : 0.440364 model2 loss : 0.020488
[00:32:15.631] iteration 18524 : model1 loss : 0.436583 model2 loss : 0.017716
[00:32:15.805] iteration 18525 : model1 loss : 0.438426 model2 loss : 0.019435
[00:32:15.974] iteration 18526 : model1 loss : 0.437593 model2 loss : 0.018522
[00:32:16.142] iteration 18527 : model1 loss : 0.434590 model2 loss : 0.017767
[00:32:16.311] iteration 18528 : model1 loss : 0.438177 model2 loss : 0.019390
[00:32:16.481] iteration 18529 : model1 loss : 0.437590 model2 loss : 0.017951
[00:32:16.653] iteration 18530 : model1 loss : 0.440350 model2 loss : 0.019409
[00:32:16.821] iteration 18531 : model1 loss : 0.434433 model2 loss : 0.019255
[00:32:16.988] iteration 18532 : model1 loss : 0.433697 model2 loss : 0.019265
[00:32:17.159] iteration 18533 : model1 loss : 0.437263 model2 loss : 0.019441
[00:32:17.326] iteration 18534 : model1 loss : 0.437193 model2 loss : 0.018964
[00:32:17.502] iteration 18535 : model1 loss : 0.439899 model2 loss : 0.020237
[00:32:17.668] iteration 18536 : model1 loss : 0.435916 model2 loss : 0.018529
[00:32:17.837] iteration 18537 : model1 loss : 0.438580 model2 loss : 0.017280
[00:32:18.004] iteration 18538 : model1 loss : 0.436988 model2 loss : 0.018033
[00:32:18.174] iteration 18539 : model1 loss : 0.440756 model2 loss : 0.017771
[00:32:18.341] iteration 18540 : model1 loss : 0.437755 model2 loss : 0.019296
[00:32:18.513] iteration 18541 : model1 loss : 0.440455 model2 loss : 0.020456
[00:32:18.677] iteration 18542 : model1 loss : 0.435959 model2 loss : 0.017907
[00:32:18.844] iteration 18543 : model1 loss : 0.441729 model2 loss : 0.020712
[00:32:20.834] iteration 18544 : model1 loss : 0.441598 model2 loss : 0.019358
[00:32:21.006] iteration 18545 : model1 loss : 0.438545 model2 loss : 0.016471
[00:32:21.176] iteration 18546 : model1 loss : 0.440062 model2 loss : 0.020404
[00:32:21.349] iteration 18547 : model1 loss : 0.437831 model2 loss : 0.018158
[00:32:21.519] iteration 18548 : model1 loss : 0.435446 model2 loss : 0.016605
[00:32:21.684] iteration 18549 : model1 loss : 0.437094 model2 loss : 0.018438
[00:32:21.856] iteration 18550 : model1 loss : 0.441633 model2 loss : 0.017350
[00:32:22.022] iteration 18551 : model1 loss : 0.440019 model2 loss : 0.021635
[00:32:22.190] iteration 18552 : model1 loss : 0.436402 model2 loss : 0.017752
[00:32:22.357] iteration 18553 : model1 loss : 0.436045 model2 loss : 0.017248
[00:32:22.528] iteration 18554 : model1 loss : 0.436981 model2 loss : 0.022788
[00:32:22.695] iteration 18555 : model1 loss : 0.438614 model2 loss : 0.021280
[00:32:22.865] iteration 18556 : model1 loss : 0.444381 model2 loss : 0.021961
[00:32:23.032] iteration 18557 : model1 loss : 0.437345 model2 loss : 0.017260
[00:32:23.201] iteration 18558 : model1 loss : 0.435082 model2 loss : 0.017835
[00:32:23.373] iteration 18559 : model1 loss : 0.435602 model2 loss : 0.020754
[00:32:23.543] iteration 18560 : model1 loss : 0.438001 model2 loss : 0.019495
[00:32:23.710] iteration 18561 : model1 loss : 0.440804 model2 loss : 0.021258
[00:32:23.880] iteration 18562 : model1 loss : 0.438706 model2 loss : 0.021004
[00:32:24.044] iteration 18563 : model1 loss : 0.431712 model2 loss : 0.017079
[00:32:24.212] iteration 18564 : model1 loss : 0.433891 model2 loss : 0.017618
[00:32:26.222] iteration 18565 : model1 loss : 0.437085 model2 loss : 0.018779
[00:32:26.389] iteration 18566 : model1 loss : 0.440598 model2 loss : 0.020374
[00:32:26.559] iteration 18567 : model1 loss : 0.435084 model2 loss : 0.017068
[00:32:26.726] iteration 18568 : model1 loss : 0.436136 model2 loss : 0.019547
[00:32:26.896] iteration 18569 : model1 loss : 0.434340 model2 loss : 0.019310
[00:32:27.063] iteration 18570 : model1 loss : 0.433750 model2 loss : 0.017654
[00:32:27.231] iteration 18571 : model1 loss : 0.437445 model2 loss : 0.019765
[00:32:27.399] iteration 18572 : model1 loss : 0.436573 model2 loss : 0.018871
[00:32:27.568] iteration 18573 : model1 loss : 0.443953 model2 loss : 0.018391
[00:32:27.735] iteration 18574 : model1 loss : 0.440543 model2 loss : 0.024192
[00:32:27.907] iteration 18575 : model1 loss : 0.439028 model2 loss : 0.020834
[00:32:28.074] iteration 18576 : model1 loss : 0.436227 model2 loss : 0.019162
[00:32:28.243] iteration 18577 : model1 loss : 0.439687 model2 loss : 0.020877
[00:32:28.412] iteration 18578 : model1 loss : 0.436801 model2 loss : 0.018888
[00:32:28.582] iteration 18579 : model1 loss : 0.438014 model2 loss : 0.017150
[00:32:28.748] iteration 18580 : model1 loss : 0.438641 model2 loss : 0.018782
[00:32:28.919] iteration 18581 : model1 loss : 0.440022 model2 loss : 0.018486
[00:32:29.085] iteration 18582 : model1 loss : 0.440246 model2 loss : 0.021242
[00:32:29.256] iteration 18583 : model1 loss : 0.437578 model2 loss : 0.017884
[00:32:29.423] iteration 18584 : model1 loss : 0.441137 model2 loss : 0.020713
[00:32:29.591] iteration 18585 : model1 loss : 0.439898 model2 loss : 0.019517
[00:32:31.598] iteration 18586 : model1 loss : 0.438890 model2 loss : 0.019011
[00:32:31.767] iteration 18587 : model1 loss : 0.439438 model2 loss : 0.018816
[00:32:31.937] iteration 18588 : model1 loss : 0.438598 model2 loss : 0.019653
[00:32:32.105] iteration 18589 : model1 loss : 0.433976 model2 loss : 0.016819
[00:32:32.273] iteration 18590 : model1 loss : 0.438034 model2 loss : 0.019210
[00:32:32.447] iteration 18591 : model1 loss : 0.433221 model2 loss : 0.018821
[00:32:32.616] iteration 18592 : model1 loss : 0.437628 model2 loss : 0.018671
[00:32:32.781] iteration 18593 : model1 loss : 0.440645 model2 loss : 0.018972
[00:32:32.949] iteration 18594 : model1 loss : 0.439827 model2 loss : 0.019073
[00:32:33.115] iteration 18595 : model1 loss : 0.437405 model2 loss : 0.020941
[00:32:33.283] iteration 18596 : model1 loss : 0.438321 model2 loss : 0.020756
[00:32:33.450] iteration 18597 : model1 loss : 0.439481 model2 loss : 0.016441
[00:32:33.621] iteration 18598 : model1 loss : 0.433790 model2 loss : 0.019764
[00:32:33.789] iteration 18599 : model1 loss : 0.437522 model2 loss : 0.018701
[00:32:33.957] iteration 18600 : model1 loss : 0.439360 model2 loss : 0.018340
[00:32:34.126] iteration 18601 : model1 loss : 0.436668 model2 loss : 0.021261
[00:32:34.298] iteration 18602 : model1 loss : 0.437829 model2 loss : 0.016619
[00:32:34.465] iteration 18603 : model1 loss : 0.440526 model2 loss : 0.018814
[00:32:34.639] iteration 18604 : model1 loss : 0.437812 model2 loss : 0.016797
[00:32:34.803] iteration 18605 : model1 loss : 0.439063 model2 loss : 0.018378
[00:32:34.989] iteration 18606 : model1 loss : 0.437117 model2 loss : 0.020362
[00:32:37.011] iteration 18607 : model1 loss : 0.438154 model2 loss : 0.017076
[00:32:37.179] iteration 18608 : model1 loss : 0.435842 model2 loss : 0.020720
[00:32:37.350] iteration 18609 : model1 loss : 0.439728 model2 loss : 0.018785
[00:32:37.518] iteration 18610 : model1 loss : 0.436418 model2 loss : 0.018637
[00:32:37.686] iteration 18611 : model1 loss : 0.435120 model2 loss : 0.016879
[00:32:37.855] iteration 18612 : model1 loss : 0.434577 model2 loss : 0.018507
[00:32:38.022] iteration 18613 : model1 loss : 0.438871 model2 loss : 0.019791
[00:32:38.189] iteration 18614 : model1 loss : 0.439504 model2 loss : 0.018649
[00:32:38.360] iteration 18615 : model1 loss : 0.436454 model2 loss : 0.017975
[00:32:38.528] iteration 18616 : model1 loss : 0.439969 model2 loss : 0.019856
[00:32:38.696] iteration 18617 : model1 loss : 0.437954 model2 loss : 0.019598
[00:32:38.863] iteration 18618 : model1 loss : 0.435505 model2 loss : 0.019633
[00:32:39.030] iteration 18619 : model1 loss : 0.445741 model2 loss : 0.021298
[00:32:39.198] iteration 18620 : model1 loss : 0.441908 model2 loss : 0.020541
[00:32:39.368] iteration 18621 : model1 loss : 0.435356 model2 loss : 0.018166
[00:32:39.535] iteration 18622 : model1 loss : 0.435020 model2 loss : 0.019141
[00:32:39.712] iteration 18623 : model1 loss : 0.436988 model2 loss : 0.019475
[00:32:39.880] iteration 18624 : model1 loss : 0.437089 model2 loss : 0.019610
[00:32:40.046] iteration 18625 : model1 loss : 0.441178 model2 loss : 0.018013
[00:32:40.213] iteration 18626 : model1 loss : 0.435539 model2 loss : 0.017392
[00:32:40.380] iteration 18627 : model1 loss : 0.438417 model2 loss : 0.015706
[00:32:42.390] iteration 18628 : model1 loss : 0.438449 model2 loss : 0.018120
[00:32:42.562] iteration 18629 : model1 loss : 0.436357 model2 loss : 0.015974
[00:32:42.735] iteration 18630 : model1 loss : 0.437991 model2 loss : 0.018867
[00:32:42.900] iteration 18631 : model1 loss : 0.436717 model2 loss : 0.017282
[00:32:43.070] iteration 18632 : model1 loss : 0.440865 model2 loss : 0.022044
[00:32:43.238] iteration 18633 : model1 loss : 0.439741 model2 loss : 0.019826
[00:32:43.408] iteration 18634 : model1 loss : 0.437699 model2 loss : 0.016486
[00:32:43.578] iteration 18635 : model1 loss : 0.438143 model2 loss : 0.020700
[00:32:43.762] iteration 18636 : model1 loss : 0.436090 model2 loss : 0.016801
[00:32:43.927] iteration 18637 : model1 loss : 0.437995 model2 loss : 0.021167
[00:32:44.099] iteration 18638 : model1 loss : 0.434125 model2 loss : 0.020870
[00:32:44.266] iteration 18639 : model1 loss : 0.435998 model2 loss : 0.017619
[00:32:44.436] iteration 18640 : model1 loss : 0.438542 model2 loss : 0.018552
[00:32:44.603] iteration 18641 : model1 loss : 0.436846 model2 loss : 0.018125
[00:32:44.772] iteration 18642 : model1 loss : 0.439070 model2 loss : 0.019495
[00:32:44.940] iteration 18643 : model1 loss : 0.436507 model2 loss : 0.017481
[00:32:45.107] iteration 18644 : model1 loss : 0.433836 model2 loss : 0.017381
[00:32:45.273] iteration 18645 : model1 loss : 0.438184 model2 loss : 0.022899
[00:32:45.443] iteration 18646 : model1 loss : 0.442758 model2 loss : 0.020790
[00:32:45.610] iteration 18647 : model1 loss : 0.435156 model2 loss : 0.019052
[00:32:45.777] iteration 18648 : model1 loss : 0.442633 model2 loss : 0.022780
[00:32:47.803] iteration 18649 : model1 loss : 0.439752 model2 loss : 0.018713
[00:32:47.971] iteration 18650 : model1 loss : 0.435956 model2 loss : 0.017764
[00:32:48.142] iteration 18651 : model1 loss : 0.435292 model2 loss : 0.018231
[00:32:48.310] iteration 18652 : model1 loss : 0.444120 model2 loss : 0.019494
[00:32:48.479] iteration 18653 : model1 loss : 0.436319 model2 loss : 0.017471
[00:32:48.651] iteration 18654 : model1 loss : 0.443582 model2 loss : 0.023866
[00:32:48.821] iteration 18655 : model1 loss : 0.444329 model2 loss : 0.023546
[00:32:48.989] iteration 18656 : model1 loss : 0.437163 model2 loss : 0.019441
[00:32:49.158] iteration 18657 : model1 loss : 0.434636 model2 loss : 0.018635
[00:32:49.330] iteration 18658 : model1 loss : 0.432889 model2 loss : 0.020144
[00:32:49.497] iteration 18659 : model1 loss : 0.438987 model2 loss : 0.021270
[00:32:49.665] iteration 18660 : model1 loss : 0.436487 model2 loss : 0.018161
[00:32:49.835] iteration 18661 : model1 loss : 0.438741 model2 loss : 0.020926
[00:32:50.003] iteration 18662 : model1 loss : 0.438598 model2 loss : 0.021287
[00:32:50.173] iteration 18663 : model1 loss : 0.438856 model2 loss : 0.018126
[00:32:50.343] iteration 18664 : model1 loss : 0.438054 model2 loss : 0.019704
[00:32:50.513] iteration 18665 : model1 loss : 0.434476 model2 loss : 0.018345
[00:32:50.681] iteration 18666 : model1 loss : 0.437224 model2 loss : 0.019270
[00:32:50.850] iteration 18667 : model1 loss : 0.436083 model2 loss : 0.021301
[00:32:51.015] iteration 18668 : model1 loss : 0.439497 model2 loss : 0.018884
[00:32:51.184] iteration 18669 : model1 loss : 0.440376 model2 loss : 0.020048
[00:32:53.220] iteration 18670 : model1 loss : 0.436671 model2 loss : 0.018073
[00:32:53.388] iteration 18671 : model1 loss : 0.435071 model2 loss : 0.017581
[00:32:53.560] iteration 18672 : model1 loss : 0.435652 model2 loss : 0.018364
[00:32:53.729] iteration 18673 : model1 loss : 0.438122 model2 loss : 0.019938
[00:32:53.899] iteration 18674 : model1 loss : 0.436483 model2 loss : 0.019507
[00:32:54.068] iteration 18675 : model1 loss : 0.443391 model2 loss : 0.019128
[00:32:54.235] iteration 18676 : model1 loss : 0.434098 model2 loss : 0.018327
[00:32:54.405] iteration 18677 : model1 loss : 0.437652 model2 loss : 0.018978
[00:32:54.578] iteration 18678 : model1 loss : 0.437143 model2 loss : 0.019864
[00:32:54.746] iteration 18679 : model1 loss : 0.434112 model2 loss : 0.019308
[00:32:54.916] iteration 18680 : model1 loss : 0.442849 model2 loss : 0.019925
[00:32:55.084] iteration 18681 : model1 loss : 0.440191 model2 loss : 0.020548
[00:32:55.251] iteration 18682 : model1 loss : 0.436570 model2 loss : 0.019433
[00:32:55.421] iteration 18683 : model1 loss : 0.438859 model2 loss : 0.019208
[00:32:55.591] iteration 18684 : model1 loss : 0.437909 model2 loss : 0.019123
[00:32:55.759] iteration 18685 : model1 loss : 0.441913 model2 loss : 0.019058
[00:32:55.927] iteration 18686 : model1 loss : 0.437200 model2 loss : 0.020086
[00:32:56.092] iteration 18687 : model1 loss : 0.438630 model2 loss : 0.018078
[00:32:56.260] iteration 18688 : model1 loss : 0.441228 model2 loss : 0.020951
[00:32:56.425] iteration 18689 : model1 loss : 0.441079 model2 loss : 0.019620
[00:32:56.592] iteration 18690 : model1 loss : 0.434229 model2 loss : 0.018223
[00:32:58.633] iteration 18691 : model1 loss : 0.437450 model2 loss : 0.017777
[00:32:58.804] iteration 18692 : model1 loss : 0.439385 model2 loss : 0.017981
[00:32:58.973] iteration 18693 : model1 loss : 0.436465 model2 loss : 0.018110
[00:32:59.150] iteration 18694 : model1 loss : 0.434872 model2 loss : 0.016702
[00:32:59.320] iteration 18695 : model1 loss : 0.434839 model2 loss : 0.017823
[00:32:59.488] iteration 18696 : model1 loss : 0.434934 model2 loss : 0.019741
[00:32:59.658] iteration 18697 : model1 loss : 0.440211 model2 loss : 0.019019
[00:32:59.825] iteration 18698 : model1 loss : 0.440478 model2 loss : 0.019716
[00:32:59.994] iteration 18699 : model1 loss : 0.438691 model2 loss : 0.018962
[00:33:00.164] iteration 18700 : model1 loss : 0.433928 model2 loss : 0.016665
[00:33:00.334] iteration 18701 : model1 loss : 0.438333 model2 loss : 0.018763
[00:33:00.503] iteration 18702 : model1 loss : 0.437316 model2 loss : 0.018418
[00:33:00.675] iteration 18703 : model1 loss : 0.439730 model2 loss : 0.020376
[00:33:00.842] iteration 18704 : model1 loss : 0.437653 model2 loss : 0.017700
[00:33:01.012] iteration 18705 : model1 loss : 0.435542 model2 loss : 0.017650
[00:33:01.178] iteration 18706 : model1 loss : 0.436845 model2 loss : 0.020906
[00:33:01.348] iteration 18707 : model1 loss : 0.439718 model2 loss : 0.019900
[00:33:01.515] iteration 18708 : model1 loss : 0.438049 model2 loss : 0.019679
[00:33:01.690] iteration 18709 : model1 loss : 0.437850 model2 loss : 0.020780
[00:33:01.855] iteration 18710 : model1 loss : 0.443453 model2 loss : 0.020717
[00:33:02.025] iteration 18711 : model1 loss : 0.439224 model2 loss : 0.019021
[00:33:04.038] iteration 18712 : model1 loss : 0.437973 model2 loss : 0.018899
[00:33:04.209] iteration 18713 : model1 loss : 0.436127 model2 loss : 0.020025
[00:33:04.380] iteration 18714 : model1 loss : 0.435896 model2 loss : 0.018690
[00:33:04.547] iteration 18715 : model1 loss : 0.439300 model2 loss : 0.019411
[00:33:04.716] iteration 18716 : model1 loss : 0.437634 model2 loss : 0.017380
[00:33:04.882] iteration 18717 : model1 loss : 0.438271 model2 loss : 0.017905
[00:33:05.051] iteration 18718 : model1 loss : 0.434714 model2 loss : 0.020046
[00:33:05.218] iteration 18719 : model1 loss : 0.440130 model2 loss : 0.020870
[00:33:05.386] iteration 18720 : model1 loss : 0.437715 model2 loss : 0.021251
[00:33:05.553] iteration 18721 : model1 loss : 0.437993 model2 loss : 0.018902
[00:33:05.724] iteration 18722 : model1 loss : 0.434328 model2 loss : 0.017427
[00:33:05.889] iteration 18723 : model1 loss : 0.437092 model2 loss : 0.018064
[00:33:06.059] iteration 18724 : model1 loss : 0.437432 model2 loss : 0.020022
[00:33:06.225] iteration 18725 : model1 loss : 0.440090 model2 loss : 0.020282
[00:33:06.394] iteration 18726 : model1 loss : 0.440694 model2 loss : 0.020366
[00:33:06.563] iteration 18727 : model1 loss : 0.437223 model2 loss : 0.018842
[00:33:06.731] iteration 18728 : model1 loss : 0.435480 model2 loss : 0.018043
[00:33:06.900] iteration 18729 : model1 loss : 0.439217 model2 loss : 0.019681
[00:33:07.068] iteration 18730 : model1 loss : 0.441446 model2 loss : 0.022039
[00:33:07.234] iteration 18731 : model1 loss : 0.438305 model2 loss : 0.018374
[00:33:07.404] iteration 18732 : model1 loss : 0.438301 model2 loss : 0.019386
[00:33:09.459] iteration 18733 : model1 loss : 0.436404 model2 loss : 0.019046
[00:33:09.628] iteration 18734 : model1 loss : 0.437879 model2 loss : 0.017747
[00:33:09.797] iteration 18735 : model1 loss : 0.441310 model2 loss : 0.018393
[00:33:09.964] iteration 18736 : model1 loss : 0.437221 model2 loss : 0.017676
[00:33:10.133] iteration 18737 : model1 loss : 0.433157 model2 loss : 0.018767
[00:33:10.302] iteration 18738 : model1 loss : 0.432864 model2 loss : 0.018910
[00:33:10.471] iteration 18739 : model1 loss : 0.439461 model2 loss : 0.018833
[00:33:10.641] iteration 18740 : model1 loss : 0.437694 model2 loss : 0.018176
[00:33:10.811] iteration 18741 : model1 loss : 0.435230 model2 loss : 0.016997
[00:33:10.978] iteration 18742 : model1 loss : 0.438716 model2 loss : 0.020092
[00:33:11.145] iteration 18743 : model1 loss : 0.436151 model2 loss : 0.020215
[00:33:11.312] iteration 18744 : model1 loss : 0.441395 model2 loss : 0.018794
[00:33:11.486] iteration 18745 : model1 loss : 0.433119 model2 loss : 0.019143
[00:33:11.655] iteration 18746 : model1 loss : 0.439013 model2 loss : 0.019589
[00:33:11.826] iteration 18747 : model1 loss : 0.441270 model2 loss : 0.016850
[00:33:11.991] iteration 18748 : model1 loss : 0.441159 model2 loss : 0.020088
[00:33:12.160] iteration 18749 : model1 loss : 0.442142 model2 loss : 0.018180
[00:33:12.330] iteration 18750 : model1 loss : 0.434703 model2 loss : 0.019434
[00:33:12.507] iteration 18751 : model1 loss : 0.437243 model2 loss : 0.018404
[00:33:12.673] iteration 18752 : model1 loss : 0.440571 model2 loss : 0.018045
[00:33:12.840] iteration 18753 : model1 loss : 0.441786 model2 loss : 0.020810
[00:33:14.870] iteration 18754 : model1 loss : 0.434858 model2 loss : 0.019215
[00:33:15.041] iteration 18755 : model1 loss : 0.438367 model2 loss : 0.019114
[00:33:15.212] iteration 18756 : model1 loss : 0.433301 model2 loss : 0.016731
[00:33:15.379] iteration 18757 : model1 loss : 0.438395 model2 loss : 0.018254
[00:33:15.547] iteration 18758 : model1 loss : 0.435025 model2 loss : 0.018933
[00:33:15.716] iteration 18759 : model1 loss : 0.437218 model2 loss : 0.019853
[00:33:15.884] iteration 18760 : model1 loss : 0.438324 model2 loss : 0.020022
[00:33:16.052] iteration 18761 : model1 loss : 0.439511 model2 loss : 0.021700
[00:33:16.221] iteration 18762 : model1 loss : 0.434744 model2 loss : 0.017492
[00:33:16.390] iteration 18763 : model1 loss : 0.440940 model2 loss : 0.020719
[00:33:16.562] iteration 18764 : model1 loss : 0.439241 model2 loss : 0.019067
[00:33:16.729] iteration 18765 : model1 loss : 0.438392 model2 loss : 0.018164
[00:33:16.901] iteration 18766 : model1 loss : 0.436963 model2 loss : 0.020318
[00:33:17.066] iteration 18767 : model1 loss : 0.438265 model2 loss : 0.018943
[00:33:17.236] iteration 18768 : model1 loss : 0.438183 model2 loss : 0.018643
[00:33:17.405] iteration 18769 : model1 loss : 0.437373 model2 loss : 0.017832
[00:33:17.575] iteration 18770 : model1 loss : 0.436497 model2 loss : 0.017895
[00:33:17.742] iteration 18771 : model1 loss : 0.439988 model2 loss : 0.018574
[00:33:17.913] iteration 18772 : model1 loss : 0.440708 model2 loss : 0.021760
[00:33:18.078] iteration 18773 : model1 loss : 0.438699 model2 loss : 0.020664
[00:33:18.245] iteration 18774 : model1 loss : 0.442660 model2 loss : 0.017712
[00:33:20.252] iteration 18775 : model1 loss : 0.438717 model2 loss : 0.018228
[00:33:20.420] iteration 18776 : model1 loss : 0.436327 model2 loss : 0.019859
[00:33:20.590] iteration 18777 : model1 loss : 0.432502 model2 loss : 0.018541
[00:33:20.758] iteration 18778 : model1 loss : 0.437306 model2 loss : 0.018432
[00:33:20.926] iteration 18779 : model1 loss : 0.436937 model2 loss : 0.017600
[00:33:21.093] iteration 18780 : model1 loss : 0.436836 model2 loss : 0.017617
[00:33:21.262] iteration 18781 : model1 loss : 0.437204 model2 loss : 0.019596
[00:33:21.431] iteration 18782 : model1 loss : 0.435100 model2 loss : 0.020353
[00:33:21.598] iteration 18783 : model1 loss : 0.438821 model2 loss : 0.019094
[00:33:21.764] iteration 18784 : model1 loss : 0.440534 model2 loss : 0.019746
[00:33:21.933] iteration 18785 : model1 loss : 0.438151 model2 loss : 0.017569
[00:33:22.098] iteration 18786 : model1 loss : 0.442527 model2 loss : 0.022461
[00:33:22.266] iteration 18787 : model1 loss : 0.440216 model2 loss : 0.019258
[00:33:22.435] iteration 18788 : model1 loss : 0.440672 model2 loss : 0.021137
[00:33:22.603] iteration 18789 : model1 loss : 0.435330 model2 loss : 0.019523
[00:33:22.769] iteration 18790 : model1 loss : 0.440218 model2 loss : 0.018657
[00:33:22.938] iteration 18791 : model1 loss : 0.436392 model2 loss : 0.018324
[00:33:23.104] iteration 18792 : model1 loss : 0.438429 model2 loss : 0.019164
[00:33:23.274] iteration 18793 : model1 loss : 0.440353 model2 loss : 0.019446
[00:33:23.438] iteration 18794 : model1 loss : 0.432840 model2 loss : 0.015838
[00:33:23.607] iteration 18795 : model1 loss : 0.438971 model2 loss : 0.019752
[00:33:25.672] iteration 18796 : model1 loss : 0.434505 model2 loss : 0.019360
[00:33:25.839] iteration 18797 : model1 loss : 0.434030 model2 loss : 0.017534
[00:33:26.008] iteration 18798 : model1 loss : 0.434441 model2 loss : 0.018842
[00:33:26.177] iteration 18799 : model1 loss : 0.438156 model2 loss : 0.017762
[00:33:26.348] iteration 18800 : model1 loss : 0.436539 model2 loss : 0.017958
[00:33:26.516] iteration 18801 : model1 loss : 0.432787 model2 loss : 0.018257
[00:33:26.689] iteration 18802 : model1 loss : 0.438985 model2 loss : 0.019417
[00:33:26.855] iteration 18803 : model1 loss : 0.440329 model2 loss : 0.019320
[00:33:27.023] iteration 18804 : model1 loss : 0.438755 model2 loss : 0.019535
[00:33:27.190] iteration 18805 : model1 loss : 0.443030 model2 loss : 0.021938
[00:33:27.359] iteration 18806 : model1 loss : 0.441912 model2 loss : 0.018452
[00:33:27.526] iteration 18807 : model1 loss : 0.439435 model2 loss : 0.022556
[00:33:27.698] iteration 18808 : model1 loss : 0.439715 model2 loss : 0.018027
[00:33:27.866] iteration 18809 : model1 loss : 0.435572 model2 loss : 0.020640
[00:33:28.035] iteration 18810 : model1 loss : 0.440405 model2 loss : 0.019101
[00:33:28.201] iteration 18811 : model1 loss : 0.440181 model2 loss : 0.018807
[00:33:28.370] iteration 18812 : model1 loss : 0.435973 model2 loss : 0.018562
[00:33:28.535] iteration 18813 : model1 loss : 0.444961 model2 loss : 0.023186
[00:33:28.707] iteration 18814 : model1 loss : 0.438520 model2 loss : 0.019826
[00:33:28.873] iteration 18815 : model1 loss : 0.440687 model2 loss : 0.020411
[00:33:29.040] iteration 18816 : model1 loss : 0.435286 model2 loss : 0.018703
[00:33:31.065] iteration 18817 : model1 loss : 0.437396 model2 loss : 0.019085
[00:33:31.237] iteration 18818 : model1 loss : 0.438853 model2 loss : 0.019409
[00:33:31.408] iteration 18819 : model1 loss : 0.439158 model2 loss : 0.018440
[00:33:31.578] iteration 18820 : model1 loss : 0.440552 model2 loss : 0.018638
[00:33:31.746] iteration 18821 : model1 loss : 0.438717 model2 loss : 0.021409
[00:33:31.912] iteration 18822 : model1 loss : 0.436925 model2 loss : 0.018598
[00:33:32.082] iteration 18823 : model1 loss : 0.438897 model2 loss : 0.020045
[00:33:32.248] iteration 18824 : model1 loss : 0.439516 model2 loss : 0.018925
[00:33:32.423] iteration 18825 : model1 loss : 0.442713 model2 loss : 0.020512
[00:33:32.590] iteration 18826 : model1 loss : 0.438223 model2 loss : 0.017913
[00:33:32.759] iteration 18827 : model1 loss : 0.438993 model2 loss : 0.018801
[00:33:32.926] iteration 18828 : model1 loss : 0.435480 model2 loss : 0.019284
[00:33:33.093] iteration 18829 : model1 loss : 0.436535 model2 loss : 0.017507
[00:33:33.258] iteration 18830 : model1 loss : 0.439895 model2 loss : 0.020018
[00:33:33.429] iteration 18831 : model1 loss : 0.436072 model2 loss : 0.019301
[00:33:33.594] iteration 18832 : model1 loss : 0.434532 model2 loss : 0.019275
[00:33:33.764] iteration 18833 : model1 loss : 0.434103 model2 loss : 0.019381
[00:33:33.933] iteration 18834 : model1 loss : 0.440067 model2 loss : 0.017376
[00:33:34.101] iteration 18835 : model1 loss : 0.440410 model2 loss : 0.019614
[00:33:34.266] iteration 18836 : model1 loss : 0.436647 model2 loss : 0.020538
[00:33:34.432] iteration 18837 : model1 loss : 0.438952 model2 loss : 0.020238
[00:33:36.428] iteration 18838 : model1 loss : 0.438963 model2 loss : 0.021220
[00:33:36.597] iteration 18839 : model1 loss : 0.437804 model2 loss : 0.019224
[00:33:36.771] iteration 18840 : model1 loss : 0.437287 model2 loss : 0.015976
[00:33:36.937] iteration 18841 : model1 loss : 0.439700 model2 loss : 0.019397
[00:33:37.110] iteration 18842 : model1 loss : 0.437118 model2 loss : 0.018764
[00:33:37.276] iteration 18843 : model1 loss : 0.436119 model2 loss : 0.016935
[00:33:37.449] iteration 18844 : model1 loss : 0.437305 model2 loss : 0.017964
[00:33:37.616] iteration 18845 : model1 loss : 0.435928 model2 loss : 0.017634
[00:33:37.784] iteration 18846 : model1 loss : 0.434427 model2 loss : 0.016677
[00:33:37.959] iteration 18847 : model1 loss : 0.437999 model2 loss : 0.017811
[00:33:38.131] iteration 18848 : model1 loss : 0.442490 model2 loss : 0.022141
[00:33:38.302] iteration 18849 : model1 loss : 0.435818 model2 loss : 0.018406
[00:33:38.474] iteration 18850 : model1 loss : 0.437741 model2 loss : 0.019014
[00:33:38.641] iteration 18851 : model1 loss : 0.440571 model2 loss : 0.016985
[00:33:38.810] iteration 18852 : model1 loss : 0.434548 model2 loss : 0.020053
[00:33:38.979] iteration 18853 : model1 loss : 0.438996 model2 loss : 0.019342
[00:33:39.149] iteration 18854 : model1 loss : 0.440238 model2 loss : 0.018122
[00:33:39.325] iteration 18855 : model1 loss : 0.434424 model2 loss : 0.017137
[00:33:39.494] iteration 18856 : model1 loss : 0.440989 model2 loss : 0.019606
[00:33:39.661] iteration 18857 : model1 loss : 0.436729 model2 loss : 0.020280
[00:33:39.828] iteration 18858 : model1 loss : 0.438275 model2 loss : 0.016283
[00:33:41.852] iteration 18859 : model1 loss : 0.438765 model2 loss : 0.018302
[00:33:42.022] iteration 18860 : model1 loss : 0.436334 model2 loss : 0.018269
[00:33:42.196] iteration 18861 : model1 loss : 0.439446 model2 loss : 0.020365
[00:33:42.365] iteration 18862 : model1 loss : 0.436974 model2 loss : 0.018925
[00:33:42.535] iteration 18863 : model1 loss : 0.436034 model2 loss : 0.017404
[00:33:42.705] iteration 18864 : model1 loss : 0.434576 model2 loss : 0.020120
[00:33:42.872] iteration 18865 : model1 loss : 0.438255 model2 loss : 0.021714
[00:33:43.038] iteration 18866 : model1 loss : 0.438262 model2 loss : 0.019942
[00:33:43.209] iteration 18867 : model1 loss : 0.435839 model2 loss : 0.018317
[00:33:43.377] iteration 18868 : model1 loss : 0.443998 model2 loss : 0.021849
[00:33:43.545] iteration 18869 : model1 loss : 0.441679 model2 loss : 0.020010
[00:33:43.715] iteration 18870 : model1 loss : 0.440004 model2 loss : 0.018515
[00:33:43.883] iteration 18871 : model1 loss : 0.439841 model2 loss : 0.021428
[00:33:44.050] iteration 18872 : model1 loss : 0.437413 model2 loss : 0.017626
[00:33:44.218] iteration 18873 : model1 loss : 0.439440 model2 loss : 0.016616
[00:33:44.383] iteration 18874 : model1 loss : 0.439584 model2 loss : 0.020210
[00:33:44.552] iteration 18875 : model1 loss : 0.436977 model2 loss : 0.019008
[00:33:44.722] iteration 18876 : model1 loss : 0.436172 model2 loss : 0.018955
[00:33:44.896] iteration 18877 : model1 loss : 0.435223 model2 loss : 0.019377
[00:33:45.061] iteration 18878 : model1 loss : 0.441531 model2 loss : 0.018815
[00:33:45.228] iteration 18879 : model1 loss : 0.434013 model2 loss : 0.017915
[00:33:47.234] iteration 18880 : model1 loss : 0.439674 model2 loss : 0.018194
[00:33:47.404] iteration 18881 : model1 loss : 0.438136 model2 loss : 0.019403
[00:33:47.573] iteration 18882 : model1 loss : 0.434993 model2 loss : 0.017733
[00:33:47.740] iteration 18883 : model1 loss : 0.441038 model2 loss : 0.020896
[00:33:47.909] iteration 18884 : model1 loss : 0.436486 model2 loss : 0.020368
[00:33:48.075] iteration 18885 : model1 loss : 0.437643 model2 loss : 0.018014
[00:33:48.245] iteration 18886 : model1 loss : 0.434797 model2 loss : 0.019087
[00:33:48.411] iteration 18887 : model1 loss : 0.438699 model2 loss : 0.017702
[00:33:48.583] iteration 18888 : model1 loss : 0.434832 model2 loss : 0.018368
[00:33:48.750] iteration 18889 : model1 loss : 0.435614 model2 loss : 0.016431
[00:33:48.919] iteration 18890 : model1 loss : 0.441410 model2 loss : 0.017062
[00:33:49.084] iteration 18891 : model1 loss : 0.437663 model2 loss : 0.021745
[00:33:49.251] iteration 18892 : model1 loss : 0.440342 model2 loss : 0.019412
[00:33:49.421] iteration 18893 : model1 loss : 0.434864 model2 loss : 0.016961
[00:33:49.592] iteration 18894 : model1 loss : 0.441111 model2 loss : 0.021041
[00:33:49.760] iteration 18895 : model1 loss : 0.437340 model2 loss : 0.017796
[00:33:49.930] iteration 18896 : model1 loss : 0.439756 model2 loss : 0.017219
[00:33:50.096] iteration 18897 : model1 loss : 0.439985 model2 loss : 0.018832
[00:33:50.265] iteration 18898 : model1 loss : 0.437619 model2 loss : 0.018057
[00:33:50.435] iteration 18899 : model1 loss : 0.432680 model2 loss : 0.019641
[00:33:50.603] iteration 18900 : model1 loss : 0.439176 model2 loss : 0.019692
[00:33:52.672] iteration 18901 : model1 loss : 0.438110 model2 loss : 0.020503
[00:33:52.837] iteration 18902 : model1 loss : 0.435608 model2 loss : 0.019326
[00:33:53.006] iteration 18903 : model1 loss : 0.438207 model2 loss : 0.019900
[00:33:53.171] iteration 18904 : model1 loss : 0.436737 model2 loss : 0.018224
[00:33:53.344] iteration 18905 : model1 loss : 0.440108 model2 loss : 0.018349
[00:33:53.510] iteration 18906 : model1 loss : 0.431470 model2 loss : 0.017900
[00:33:53.678] iteration 18907 : model1 loss : 0.435751 model2 loss : 0.019216
[00:33:53.844] iteration 18908 : model1 loss : 0.437541 model2 loss : 0.020127
[00:33:54.012] iteration 18909 : model1 loss : 0.439932 model2 loss : 0.022349
[00:33:54.178] iteration 18910 : model1 loss : 0.440800 model2 loss : 0.019165
[00:33:54.348] iteration 18911 : model1 loss : 0.439451 model2 loss : 0.018971
[00:33:54.517] iteration 18912 : model1 loss : 0.438462 model2 loss : 0.017609
[00:33:54.687] iteration 18913 : model1 loss : 0.438460 model2 loss : 0.020782
[00:33:54.853] iteration 18914 : model1 loss : 0.440399 model2 loss : 0.020554
[00:33:55.020] iteration 18915 : model1 loss : 0.437061 model2 loss : 0.022256
[00:33:55.188] iteration 18916 : model1 loss : 0.439598 model2 loss : 0.019816
[00:33:55.357] iteration 18917 : model1 loss : 0.433849 model2 loss : 0.017561
[00:33:55.528] iteration 18918 : model1 loss : 0.436897 model2 loss : 0.017881
[00:33:55.701] iteration 18919 : model1 loss : 0.439677 model2 loss : 0.019631
[00:33:55.866] iteration 18920 : model1 loss : 0.436633 model2 loss : 0.022000
[00:33:56.031] iteration 18921 : model1 loss : 0.443395 model2 loss : 0.021135
[00:33:58.072] iteration 18922 : model1 loss : 0.437373 model2 loss : 0.019450
[00:33:58.242] iteration 18923 : model1 loss : 0.439992 model2 loss : 0.021308
[00:33:58.414] iteration 18924 : model1 loss : 0.436724 model2 loss : 0.020851
[00:33:58.581] iteration 18925 : model1 loss : 0.439640 model2 loss : 0.020059
[00:33:58.750] iteration 18926 : model1 loss : 0.438071 model2 loss : 0.022075
[00:33:58.916] iteration 18927 : model1 loss : 0.437413 model2 loss : 0.017656
[00:33:59.085] iteration 18928 : model1 loss : 0.437147 model2 loss : 0.020433
[00:33:59.250] iteration 18929 : model1 loss : 0.440098 model2 loss : 0.020255
[00:33:59.420] iteration 18930 : model1 loss : 0.434053 model2 loss : 0.017277
[00:33:59.588] iteration 18931 : model1 loss : 0.438775 model2 loss : 0.017232
[00:33:59.758] iteration 18932 : model1 loss : 0.438123 model2 loss : 0.018557
[00:33:59.924] iteration 18933 : model1 loss : 0.435070 model2 loss : 0.016959
[00:34:00.099] iteration 18934 : model1 loss : 0.437707 model2 loss : 0.019029
[00:34:00.267] iteration 18935 : model1 loss : 0.440721 model2 loss : 0.017834
[00:34:00.435] iteration 18936 : model1 loss : 0.436417 model2 loss : 0.016927
[00:34:00.603] iteration 18937 : model1 loss : 0.435012 model2 loss : 0.017580
[00:34:00.773] iteration 18938 : model1 loss : 0.440029 model2 loss : 0.018638
[00:34:00.940] iteration 18939 : model1 loss : 0.437595 model2 loss : 0.018757
[00:34:01.110] iteration 18940 : model1 loss : 0.439547 model2 loss : 0.019711
[00:34:01.275] iteration 18941 : model1 loss : 0.438267 model2 loss : 0.019573
[00:34:01.450] iteration 18942 : model1 loss : 0.440478 model2 loss : 0.018709
[00:34:03.504] iteration 18943 : model1 loss : 0.442268 model2 loss : 0.018859
[00:34:03.674] iteration 18944 : model1 loss : 0.434137 model2 loss : 0.020316
[00:34:03.843] iteration 18945 : model1 loss : 0.438520 model2 loss : 0.017837
[00:34:04.009] iteration 18946 : model1 loss : 0.436249 model2 loss : 0.020560
[00:34:04.175] iteration 18947 : model1 loss : 0.439194 model2 loss : 0.019183
[00:34:04.341] iteration 18948 : model1 loss : 0.439108 model2 loss : 0.019825
[00:34:04.509] iteration 18949 : model1 loss : 0.436898 model2 loss : 0.018853
[00:34:04.679] iteration 18950 : model1 loss : 0.437945 model2 loss : 0.018135
[00:34:04.849] iteration 18951 : model1 loss : 0.436972 model2 loss : 0.019191
[00:34:05.016] iteration 18952 : model1 loss : 0.439548 model2 loss : 0.017051
[00:34:05.185] iteration 18953 : model1 loss : 0.438541 model2 loss : 0.018560
[00:34:05.353] iteration 18954 : model1 loss : 0.438249 model2 loss : 0.016329
[00:34:05.523] iteration 18955 : model1 loss : 0.435414 model2 loss : 0.019214
[00:34:05.691] iteration 18956 : model1 loss : 0.435477 model2 loss : 0.017281
[00:34:05.859] iteration 18957 : model1 loss : 0.439307 model2 loss : 0.019573
[00:34:06.039] iteration 18958 : model1 loss : 0.437744 model2 loss : 0.019091
[00:34:06.208] iteration 18959 : model1 loss : 0.434271 model2 loss : 0.017267
[00:34:06.376] iteration 18960 : model1 loss : 0.438379 model2 loss : 0.018297
[00:34:06.545] iteration 18961 : model1 loss : 0.437176 model2 loss : 0.017804
[00:34:06.712] iteration 18962 : model1 loss : 0.438745 model2 loss : 0.019626
[00:34:06.879] iteration 18963 : model1 loss : 0.442913 model2 loss : 0.020637
[00:34:08.912] iteration 18964 : model1 loss : 0.438688 model2 loss : 0.018357
[00:34:09.086] iteration 18965 : model1 loss : 0.436068 model2 loss : 0.018288
[00:34:09.258] iteration 18966 : model1 loss : 0.436817 model2 loss : 0.017888
[00:34:09.423] iteration 18967 : model1 loss : 0.438548 model2 loss : 0.019384
[00:34:09.591] iteration 18968 : model1 loss : 0.437314 model2 loss : 0.018363
[00:34:09.758] iteration 18969 : model1 loss : 0.436734 model2 loss : 0.020199
[00:34:09.927] iteration 18970 : model1 loss : 0.438870 model2 loss : 0.017746
[00:34:10.094] iteration 18971 : model1 loss : 0.438241 model2 loss : 0.020061
[00:34:10.261] iteration 18972 : model1 loss : 0.436870 model2 loss : 0.017573
[00:34:10.431] iteration 18973 : model1 loss : 0.435124 model2 loss : 0.019375
[00:34:10.600] iteration 18974 : model1 loss : 0.435425 model2 loss : 0.017382
[00:34:10.767] iteration 18975 : model1 loss : 0.440899 model2 loss : 0.019180
[00:34:10.935] iteration 18976 : model1 loss : 0.435460 model2 loss : 0.018238
[00:34:11.101] iteration 18977 : model1 loss : 0.443326 model2 loss : 0.020662
[00:34:11.271] iteration 18978 : model1 loss : 0.441204 model2 loss : 0.019370
[00:34:11.438] iteration 18979 : model1 loss : 0.439478 model2 loss : 0.020229
[00:34:11.608] iteration 18980 : model1 loss : 0.437799 model2 loss : 0.020396
[00:34:11.778] iteration 18981 : model1 loss : 0.437367 model2 loss : 0.021621
[00:34:11.946] iteration 18982 : model1 loss : 0.439204 model2 loss : 0.021199
[00:34:12.111] iteration 18983 : model1 loss : 0.435685 model2 loss : 0.018810
[00:34:12.282] iteration 18984 : model1 loss : 0.439932 model2 loss : 0.017740
[00:34:14.347] iteration 18985 : model1 loss : 0.440453 model2 loss : 0.022175
[00:34:14.516] iteration 18986 : model1 loss : 0.442276 model2 loss : 0.021160
[00:34:14.688] iteration 18987 : model1 loss : 0.442925 model2 loss : 0.018640
[00:34:14.853] iteration 18988 : model1 loss : 0.434338 model2 loss : 0.019137
[00:34:15.024] iteration 18989 : model1 loss : 0.440759 model2 loss : 0.016503
[00:34:15.191] iteration 18990 : model1 loss : 0.438512 model2 loss : 0.018281
[00:34:15.360] iteration 18991 : model1 loss : 0.435977 model2 loss : 0.018787
[00:34:15.527] iteration 18992 : model1 loss : 0.433392 model2 loss : 0.018687
[00:34:15.701] iteration 18993 : model1 loss : 0.438283 model2 loss : 0.018782
[00:34:15.868] iteration 18994 : model1 loss : 0.439611 model2 loss : 0.018104
[00:34:16.037] iteration 18995 : model1 loss : 0.434724 model2 loss : 0.018483
[00:34:16.205] iteration 18996 : model1 loss : 0.441792 model2 loss : 0.022678
[00:34:16.376] iteration 18997 : model1 loss : 0.434536 model2 loss : 0.018869
[00:34:16.545] iteration 18998 : model1 loss : 0.436453 model2 loss : 0.018789
[00:34:16.718] iteration 18999 : model1 loss : 0.434313 model2 loss : 0.017717
[00:34:16.884] iteration 19000 : model1 loss : 0.441006 model2 loss : 0.020566
[00:34:25.644] iteration 19000 : model1_mean_dice : 0.865313 model1_mean_hd95 : 5.042375
[00:34:34.435] iteration 19000 : model2_mean_dice : 0.878130 model2_mean_hd95 : 3.870783
[00:34:34.613] iteration 19001 : model1 loss : 0.435464 model2 loss : 0.017461
[00:34:34.782] iteration 19002 : model1 loss : 0.439644 model2 loss : 0.018846
[00:34:34.947] iteration 19003 : model1 loss : 0.436908 model2 loss : 0.019243
[00:34:35.113] iteration 19004 : model1 loss : 0.437459 model2 loss : 0.020799
[00:34:35.277] iteration 19005 : model1 loss : 0.440092 model2 loss : 0.020105
[00:34:37.314] iteration 19006 : model1 loss : 0.436104 model2 loss : 0.018586
[00:34:37.486] iteration 19007 : model1 loss : 0.437636 model2 loss : 0.017592
[00:34:37.656] iteration 19008 : model1 loss : 0.435252 model2 loss : 0.019010
[00:34:37.821] iteration 19009 : model1 loss : 0.438574 model2 loss : 0.017836
[00:34:37.989] iteration 19010 : model1 loss : 0.435054 model2 loss : 0.018599
[00:34:38.155] iteration 19011 : model1 loss : 0.441560 model2 loss : 0.021425
[00:34:38.327] iteration 19012 : model1 loss : 0.440764 model2 loss : 0.019355
[00:34:38.494] iteration 19013 : model1 loss : 0.436290 model2 loss : 0.019750
[00:34:38.664] iteration 19014 : model1 loss : 0.442501 model2 loss : 0.019879
[00:34:38.830] iteration 19015 : model1 loss : 0.438209 model2 loss : 0.017455
[00:34:38.998] iteration 19016 : model1 loss : 0.438901 model2 loss : 0.018125
[00:34:39.166] iteration 19017 : model1 loss : 0.439391 model2 loss : 0.018487
[00:34:39.335] iteration 19018 : model1 loss : 0.438895 model2 loss : 0.018429
[00:34:39.501] iteration 19019 : model1 loss : 0.433505 model2 loss : 0.018346
[00:34:39.671] iteration 19020 : model1 loss : 0.433725 model2 loss : 0.017593
[00:34:39.839] iteration 19021 : model1 loss : 0.437682 model2 loss : 0.018524
[00:34:40.009] iteration 19022 : model1 loss : 0.442129 model2 loss : 0.017988
[00:34:40.176] iteration 19023 : model1 loss : 0.439861 model2 loss : 0.019520
[00:34:40.343] iteration 19024 : model1 loss : 0.445167 model2 loss : 0.022570
[00:34:40.508] iteration 19025 : model1 loss : 0.436574 model2 loss : 0.017753
[00:34:40.675] iteration 19026 : model1 loss : 0.432285 model2 loss : 0.018134
[00:34:42.709] iteration 19027 : model1 loss : 0.438961 model2 loss : 0.020464
[00:34:42.874] iteration 19028 : model1 loss : 0.431728 model2 loss : 0.018119
[00:34:43.043] iteration 19029 : model1 loss : 0.437593 model2 loss : 0.017838
[00:34:43.211] iteration 19030 : model1 loss : 0.434065 model2 loss : 0.018044
[00:34:43.378] iteration 19031 : model1 loss : 0.437876 model2 loss : 0.017678
[00:34:43.545] iteration 19032 : model1 loss : 0.435926 model2 loss : 0.017613
[00:34:43.719] iteration 19033 : model1 loss : 0.436009 model2 loss : 0.019883
[00:34:43.886] iteration 19034 : model1 loss : 0.435098 model2 loss : 0.019343
[00:34:44.055] iteration 19035 : model1 loss : 0.443314 model2 loss : 0.019092
[00:34:44.220] iteration 19036 : model1 loss : 0.437700 model2 loss : 0.019178
[00:34:44.390] iteration 19037 : model1 loss : 0.435870 model2 loss : 0.017181
[00:34:44.556] iteration 19038 : model1 loss : 0.437331 model2 loss : 0.017013
[00:34:44.731] iteration 19039 : model1 loss : 0.440380 model2 loss : 0.021196
[00:34:44.899] iteration 19040 : model1 loss : 0.438806 model2 loss : 0.019230
[00:34:45.068] iteration 19041 : model1 loss : 0.439960 model2 loss : 0.017711
[00:34:45.235] iteration 19042 : model1 loss : 0.435744 model2 loss : 0.015602
[00:34:45.404] iteration 19043 : model1 loss : 0.435755 model2 loss : 0.017309
[00:34:45.572] iteration 19044 : model1 loss : 0.439059 model2 loss : 0.019411
[00:34:45.745] iteration 19045 : model1 loss : 0.438234 model2 loss : 0.019099
[00:34:45.909] iteration 19046 : model1 loss : 0.439193 model2 loss : 0.018657
[00:34:46.075] iteration 19047 : model1 loss : 0.443086 model2 loss : 0.021200
[00:34:48.117] iteration 19048 : model1 loss : 0.438521 model2 loss : 0.019220
[00:34:48.292] iteration 19049 : model1 loss : 0.434539 model2 loss : 0.020669
[00:34:48.461] iteration 19050 : model1 loss : 0.436973 model2 loss : 0.019601
[00:34:48.626] iteration 19051 : model1 loss : 0.437600 model2 loss : 0.019602
[00:34:48.794] iteration 19052 : model1 loss : 0.439411 model2 loss : 0.018494
[00:34:48.960] iteration 19053 : model1 loss : 0.436262 model2 loss : 0.018570
[00:34:49.129] iteration 19054 : model1 loss : 0.444001 model2 loss : 0.018406
[00:34:49.296] iteration 19055 : model1 loss : 0.438049 model2 loss : 0.019267
[00:34:49.463] iteration 19056 : model1 loss : 0.435482 model2 loss : 0.019994
[00:34:49.630] iteration 19057 : model1 loss : 0.434565 model2 loss : 0.018497
[00:34:49.798] iteration 19058 : model1 loss : 0.440953 model2 loss : 0.018842
[00:34:49.967] iteration 19059 : model1 loss : 0.437360 model2 loss : 0.020444
[00:34:50.137] iteration 19060 : model1 loss : 0.436819 model2 loss : 0.018848
[00:34:50.307] iteration 19061 : model1 loss : 0.437195 model2 loss : 0.018571
[00:34:50.476] iteration 19062 : model1 loss : 0.437228 model2 loss : 0.016462
[00:34:50.645] iteration 19063 : model1 loss : 0.439400 model2 loss : 0.018892
[00:34:50.814] iteration 19064 : model1 loss : 0.435199 model2 loss : 0.018406
[00:34:50.981] iteration 19065 : model1 loss : 0.441946 model2 loss : 0.020755
[00:34:51.150] iteration 19066 : model1 loss : 0.439303 model2 loss : 0.015967
[00:34:51.318] iteration 19067 : model1 loss : 0.435193 model2 loss : 0.016419
[00:34:51.485] iteration 19068 : model1 loss : 0.440865 model2 loss : 0.019426
[00:34:53.528] iteration 19069 : model1 loss : 0.437313 model2 loss : 0.020060
[00:34:53.700] iteration 19070 : model1 loss : 0.436980 model2 loss : 0.019817
[00:34:53.869] iteration 19071 : model1 loss : 0.435446 model2 loss : 0.019022
[00:34:54.035] iteration 19072 : model1 loss : 0.443035 model2 loss : 0.019783
[00:34:54.204] iteration 19073 : model1 loss : 0.437419 model2 loss : 0.019515
[00:34:54.372] iteration 19074 : model1 loss : 0.439846 model2 loss : 0.019033
[00:34:54.541] iteration 19075 : model1 loss : 0.436373 model2 loss : 0.017135
[00:34:54.710] iteration 19076 : model1 loss : 0.435425 model2 loss : 0.017843
[00:34:54.880] iteration 19077 : model1 loss : 0.435903 model2 loss : 0.017904
[00:34:55.047] iteration 19078 : model1 loss : 0.435921 model2 loss : 0.018463
[00:34:55.219] iteration 19079 : model1 loss : 0.438425 model2 loss : 0.019588
[00:34:55.385] iteration 19080 : model1 loss : 0.437284 model2 loss : 0.017818
[00:34:55.555] iteration 19081 : model1 loss : 0.444047 model2 loss : 0.022331
[00:34:55.724] iteration 19082 : model1 loss : 0.439908 model2 loss : 0.020974
[00:34:55.893] iteration 19083 : model1 loss : 0.434551 model2 loss : 0.018672
[00:34:56.060] iteration 19084 : model1 loss : 0.434571 model2 loss : 0.020917
[00:34:56.229] iteration 19085 : model1 loss : 0.437828 model2 loss : 0.019535
[00:34:56.397] iteration 19086 : model1 loss : 0.438798 model2 loss : 0.017827
[00:34:56.568] iteration 19087 : model1 loss : 0.440956 model2 loss : 0.020065
[00:34:56.736] iteration 19088 : model1 loss : 0.440486 model2 loss : 0.019396
[00:34:56.903] iteration 19089 : model1 loss : 0.438509 model2 loss : 0.019303
[00:34:58.965] iteration 19090 : model1 loss : 0.439307 model2 loss : 0.017198
[00:34:59.132] iteration 19091 : model1 loss : 0.435590 model2 loss : 0.019633
[00:34:59.305] iteration 19092 : model1 loss : 0.435953 model2 loss : 0.017685
[00:34:59.471] iteration 19093 : model1 loss : 0.436330 model2 loss : 0.019528
[00:34:59.639] iteration 19094 : model1 loss : 0.434990 model2 loss : 0.019634
[00:34:59.805] iteration 19095 : model1 loss : 0.436114 model2 loss : 0.017796
[00:34:59.975] iteration 19096 : model1 loss : 0.435564 model2 loss : 0.017872
[00:35:00.142] iteration 19097 : model1 loss : 0.438038 model2 loss : 0.018588
[00:35:00.312] iteration 19098 : model1 loss : 0.440020 model2 loss : 0.018941
[00:35:00.481] iteration 19099 : model1 loss : 0.439991 model2 loss : 0.019354
[00:35:00.651] iteration 19100 : model1 loss : 0.441335 model2 loss : 0.019046
[00:35:00.820] iteration 19101 : model1 loss : 0.438178 model2 loss : 0.019783
[00:35:00.989] iteration 19102 : model1 loss : 0.438920 model2 loss : 0.019119
[00:35:01.155] iteration 19103 : model1 loss : 0.441394 model2 loss : 0.020208
[00:35:01.326] iteration 19104 : model1 loss : 0.438042 model2 loss : 0.019021
[00:35:01.492] iteration 19105 : model1 loss : 0.440317 model2 loss : 0.018944
[00:35:01.662] iteration 19106 : model1 loss : 0.437548 model2 loss : 0.017572
[00:35:01.829] iteration 19107 : model1 loss : 0.435608 model2 loss : 0.019057
[00:35:01.996] iteration 19108 : model1 loss : 0.434788 model2 loss : 0.019032
[00:35:02.162] iteration 19109 : model1 loss : 0.441185 model2 loss : 0.018690
[00:35:02.330] iteration 19110 : model1 loss : 0.442263 model2 loss : 0.019393
[00:35:04.385] iteration 19111 : model1 loss : 0.437025 model2 loss : 0.017926
[00:35:04.555] iteration 19112 : model1 loss : 0.434819 model2 loss : 0.017694
[00:35:04.728] iteration 19113 : model1 loss : 0.434319 model2 loss : 0.016976
[00:35:04.896] iteration 19114 : model1 loss : 0.440028 model2 loss : 0.019066
[00:35:05.063] iteration 19115 : model1 loss : 0.440323 model2 loss : 0.020701
[00:35:05.233] iteration 19116 : model1 loss : 0.440052 model2 loss : 0.020529
[00:35:05.403] iteration 19117 : model1 loss : 0.437740 model2 loss : 0.018531
[00:35:05.570] iteration 19118 : model1 loss : 0.434832 model2 loss : 0.021219
[00:35:05.742] iteration 19119 : model1 loss : 0.438190 model2 loss : 0.019408
[00:35:05.908] iteration 19120 : model1 loss : 0.437846 model2 loss : 0.018462
[00:35:06.077] iteration 19121 : model1 loss : 0.441923 model2 loss : 0.020240
[00:35:06.243] iteration 19122 : model1 loss : 0.436052 model2 loss : 0.019309
[00:35:06.412] iteration 19123 : model1 loss : 0.441120 model2 loss : 0.019488
[00:35:06.579] iteration 19124 : model1 loss : 0.434424 model2 loss : 0.018513
[00:35:06.751] iteration 19125 : model1 loss : 0.433853 model2 loss : 0.018791
[00:35:06.919] iteration 19126 : model1 loss : 0.438197 model2 loss : 0.017032
[00:35:07.088] iteration 19127 : model1 loss : 0.439466 model2 loss : 0.020346
[00:35:07.254] iteration 19128 : model1 loss : 0.441060 model2 loss : 0.019792
[00:35:07.428] iteration 19129 : model1 loss : 0.438360 model2 loss : 0.018608
[00:35:07.594] iteration 19130 : model1 loss : 0.437914 model2 loss : 0.018285
[00:35:07.762] iteration 19131 : model1 loss : 0.441751 model2 loss : 0.017895
[00:35:09.797] iteration 19132 : model1 loss : 0.437746 model2 loss : 0.018785
[00:35:09.964] iteration 19133 : model1 loss : 0.441559 model2 loss : 0.019317
[00:35:10.136] iteration 19134 : model1 loss : 0.436992 model2 loss : 0.019194
[00:35:10.304] iteration 19135 : model1 loss : 0.435118 model2 loss : 0.017819
[00:35:10.474] iteration 19136 : model1 loss : 0.436833 model2 loss : 0.017122
[00:35:10.642] iteration 19137 : model1 loss : 0.439506 model2 loss : 0.018645
[00:35:10.813] iteration 19138 : model1 loss : 0.437433 model2 loss : 0.019592
[00:35:10.979] iteration 19139 : model1 loss : 0.434251 model2 loss : 0.017705
[00:35:11.148] iteration 19140 : model1 loss : 0.440307 model2 loss : 0.019149
[00:35:11.326] iteration 19141 : model1 loss : 0.440756 model2 loss : 0.017874
[00:35:11.495] iteration 19142 : model1 loss : 0.438293 model2 loss : 0.020343
[00:35:11.661] iteration 19143 : model1 loss : 0.435074 model2 loss : 0.017366
[00:35:11.830] iteration 19144 : model1 loss : 0.433495 model2 loss : 0.018034
[00:35:11.997] iteration 19145 : model1 loss : 0.436793 model2 loss : 0.020264
[00:35:12.168] iteration 19146 : model1 loss : 0.440838 model2 loss : 0.020120
[00:35:12.339] iteration 19147 : model1 loss : 0.441712 model2 loss : 0.019648
[00:35:12.509] iteration 19148 : model1 loss : 0.441658 model2 loss : 0.019841
[00:35:12.680] iteration 19149 : model1 loss : 0.439212 model2 loss : 0.019201
[00:35:12.850] iteration 19150 : model1 loss : 0.435495 model2 loss : 0.016985
[00:35:13.017] iteration 19151 : model1 loss : 0.436243 model2 loss : 0.017601
[00:35:13.185] iteration 19152 : model1 loss : 0.438201 model2 loss : 0.017485
[00:35:15.286] iteration 19153 : model1 loss : 0.438469 model2 loss : 0.019250
[00:35:15.457] iteration 19154 : model1 loss : 0.439979 model2 loss : 0.018922
[00:35:15.625] iteration 19155 : model1 loss : 0.438026 model2 loss : 0.020221
[00:35:15.792] iteration 19156 : model1 loss : 0.440577 model2 loss : 0.018387
[00:35:15.961] iteration 19157 : model1 loss : 0.439385 model2 loss : 0.019444
[00:35:16.127] iteration 19158 : model1 loss : 0.434557 model2 loss : 0.016798
[00:35:16.301] iteration 19159 : model1 loss : 0.439948 model2 loss : 0.021077
[00:35:16.471] iteration 19160 : model1 loss : 0.435601 model2 loss : 0.017748
[00:35:16.641] iteration 19161 : model1 loss : 0.432781 model2 loss : 0.018284
[00:35:16.806] iteration 19162 : model1 loss : 0.440454 model2 loss : 0.019991
[00:35:16.975] iteration 19163 : model1 loss : 0.438465 model2 loss : 0.017865
[00:35:17.142] iteration 19164 : model1 loss : 0.436624 model2 loss : 0.018609
[00:35:17.317] iteration 19165 : model1 loss : 0.441302 model2 loss : 0.018436
[00:35:17.488] iteration 19166 : model1 loss : 0.438026 model2 loss : 0.018897
[00:35:17.657] iteration 19167 : model1 loss : 0.436582 model2 loss : 0.019633
[00:35:17.825] iteration 19168 : model1 loss : 0.442480 model2 loss : 0.021666
[00:35:17.992] iteration 19169 : model1 loss : 0.434861 model2 loss : 0.017953
[00:35:18.160] iteration 19170 : model1 loss : 0.435514 model2 loss : 0.017897
[00:35:18.330] iteration 19171 : model1 loss : 0.437835 model2 loss : 0.018991
[00:35:18.496] iteration 19172 : model1 loss : 0.436916 model2 loss : 0.017293
[00:35:18.663] iteration 19173 : model1 loss : 0.438520 model2 loss : 0.021409
[00:35:20.714] iteration 19174 : model1 loss : 0.436930 model2 loss : 0.020274
[00:35:20.881] iteration 19175 : model1 loss : 0.439644 model2 loss : 0.017635
[00:35:21.050] iteration 19176 : model1 loss : 0.433196 model2 loss : 0.016836
[00:35:21.216] iteration 19177 : model1 loss : 0.441736 model2 loss : 0.020708
[00:35:21.386] iteration 19178 : model1 loss : 0.438462 model2 loss : 0.018312
[00:35:21.552] iteration 19179 : model1 loss : 0.438667 model2 loss : 0.018922
[00:35:21.725] iteration 19180 : model1 loss : 0.439141 model2 loss : 0.021085
[00:35:21.905] iteration 19181 : model1 loss : 0.439816 model2 loss : 0.018194
[00:35:22.074] iteration 19182 : model1 loss : 0.437311 model2 loss : 0.020452
[00:35:22.242] iteration 19183 : model1 loss : 0.436630 model2 loss : 0.019637
[00:35:22.414] iteration 19184 : model1 loss : 0.440900 model2 loss : 0.021925
[00:35:22.582] iteration 19185 : model1 loss : 0.435448 model2 loss : 0.019150
[00:35:22.751] iteration 19186 : model1 loss : 0.434081 model2 loss : 0.018546
[00:35:22.918] iteration 19187 : model1 loss : 0.441461 model2 loss : 0.022316
[00:35:23.088] iteration 19188 : model1 loss : 0.438456 model2 loss : 0.019158
[00:35:23.253] iteration 19189 : model1 loss : 0.440352 model2 loss : 0.021964
[00:35:23.423] iteration 19190 : model1 loss : 0.436192 model2 loss : 0.018412
[00:35:23.590] iteration 19191 : model1 loss : 0.437160 model2 loss : 0.020783
[00:35:23.759] iteration 19192 : model1 loss : 0.435222 model2 loss : 0.019005
[00:35:23.926] iteration 19193 : model1 loss : 0.441377 model2 loss : 0.018346
[00:35:24.094] iteration 19194 : model1 loss : 0.438185 model2 loss : 0.018684
[00:35:26.122] iteration 19195 : model1 loss : 0.441544 model2 loss : 0.019839
[00:35:26.287] iteration 19196 : model1 loss : 0.434644 model2 loss : 0.018691
[00:35:26.456] iteration 19197 : model1 loss : 0.439528 model2 loss : 0.019218
[00:35:26.624] iteration 19198 : model1 loss : 0.440173 model2 loss : 0.020985
[00:35:26.793] iteration 19199 : model1 loss : 0.439376 model2 loss : 0.018011
[00:35:26.959] iteration 19200 : model1 loss : 0.437582 model2 loss : 0.019693
[00:35:27.128] iteration 19201 : model1 loss : 0.436636 model2 loss : 0.018386
[00:35:27.295] iteration 19202 : model1 loss : 0.436413 model2 loss : 0.019302
[00:35:27.465] iteration 19203 : model1 loss : 0.438231 model2 loss : 0.018691
[00:35:27.631] iteration 19204 : model1 loss : 0.438669 model2 loss : 0.020411
[00:35:27.799] iteration 19205 : model1 loss : 0.443795 model2 loss : 0.019964
[00:35:27.965] iteration 19206 : model1 loss : 0.441300 model2 loss : 0.018344
[00:35:28.135] iteration 19207 : model1 loss : 0.435962 model2 loss : 0.016425
[00:35:28.304] iteration 19208 : model1 loss : 0.435965 model2 loss : 0.018062
[00:35:28.473] iteration 19209 : model1 loss : 0.440761 model2 loss : 0.019629
[00:35:28.644] iteration 19210 : model1 loss : 0.434049 model2 loss : 0.019808
[00:35:28.812] iteration 19211 : model1 loss : 0.435144 model2 loss : 0.018223
[00:35:28.980] iteration 19212 : model1 loss : 0.435346 model2 loss : 0.018652
[00:35:29.149] iteration 19213 : model1 loss : 0.436629 model2 loss : 0.018740
[00:35:29.317] iteration 19214 : model1 loss : 0.437101 model2 loss : 0.018978
[00:35:29.485] iteration 19215 : model1 loss : 0.438717 model2 loss : 0.016953
[00:35:31.537] iteration 19216 : model1 loss : 0.438535 model2 loss : 0.018291
[00:35:31.708] iteration 19217 : model1 loss : 0.442288 model2 loss : 0.019311
[00:35:31.879] iteration 19218 : model1 loss : 0.436076 model2 loss : 0.017578
[00:35:32.045] iteration 19219 : model1 loss : 0.440909 model2 loss : 0.021936
[00:35:32.213] iteration 19220 : model1 loss : 0.439980 model2 loss : 0.019039
[00:35:32.379] iteration 19221 : model1 loss : 0.437689 model2 loss : 0.017434
[00:35:32.552] iteration 19222 : model1 loss : 0.436563 model2 loss : 0.020482
[00:35:32.721] iteration 19223 : model1 loss : 0.436389 model2 loss : 0.016795
[00:35:32.913] iteration 19224 : model1 loss : 0.438983 model2 loss : 0.021920
[00:35:33.080] iteration 19225 : model1 loss : 0.435991 model2 loss : 0.018442
[00:35:33.248] iteration 19226 : model1 loss : 0.442801 model2 loss : 0.021933
[00:35:33.418] iteration 19227 : model1 loss : 0.439425 model2 loss : 0.017021
[00:35:33.587] iteration 19228 : model1 loss : 0.440328 model2 loss : 0.018284
[00:35:33.757] iteration 19229 : model1 loss : 0.436037 model2 loss : 0.020153
[00:35:33.926] iteration 19230 : model1 loss : 0.437945 model2 loss : 0.020524
[00:35:34.094] iteration 19231 : model1 loss : 0.437067 model2 loss : 0.019062
[00:35:34.263] iteration 19232 : model1 loss : 0.438006 model2 loss : 0.017943
[00:35:34.428] iteration 19233 : model1 loss : 0.436779 model2 loss : 0.017657
[00:35:34.597] iteration 19234 : model1 loss : 0.431094 model2 loss : 0.017569
[00:35:34.763] iteration 19235 : model1 loss : 0.441635 model2 loss : 0.019268
[00:35:34.932] iteration 19236 : model1 loss : 0.435102 model2 loss : 0.018172
[00:35:36.993] iteration 19237 : model1 loss : 0.434094 model2 loss : 0.018974
[00:35:37.161] iteration 19238 : model1 loss : 0.436327 model2 loss : 0.019576
[00:35:37.336] iteration 19239 : model1 loss : 0.439336 model2 loss : 0.019813
[00:35:37.508] iteration 19240 : model1 loss : 0.438274 model2 loss : 0.018978
[00:35:37.677] iteration 19241 : model1 loss : 0.436894 model2 loss : 0.016893
[00:35:37.843] iteration 19242 : model1 loss : 0.438403 model2 loss : 0.018493
[00:35:38.010] iteration 19243 : model1 loss : 0.436638 model2 loss : 0.017827
[00:35:38.178] iteration 19244 : model1 loss : 0.437562 model2 loss : 0.018090
[00:35:38.349] iteration 19245 : model1 loss : 0.432813 model2 loss : 0.015977
[00:35:38.513] iteration 19246 : model1 loss : 0.439109 model2 loss : 0.019481
[00:35:38.683] iteration 19247 : model1 loss : 0.439927 model2 loss : 0.019451
[00:35:38.851] iteration 19248 : model1 loss : 0.438736 model2 loss : 0.019086
[00:35:39.022] iteration 19249 : model1 loss : 0.435426 model2 loss : 0.019648
[00:35:39.187] iteration 19250 : model1 loss : 0.440998 model2 loss : 0.020755
[00:35:39.357] iteration 19251 : model1 loss : 0.440029 model2 loss : 0.018909
[00:35:39.522] iteration 19252 : model1 loss : 0.435990 model2 loss : 0.019829
[00:35:39.690] iteration 19253 : model1 loss : 0.445128 model2 loss : 0.020265
[00:35:39.857] iteration 19254 : model1 loss : 0.437345 model2 loss : 0.019055
[00:35:40.027] iteration 19255 : model1 loss : 0.442512 model2 loss : 0.023060
[00:35:40.192] iteration 19256 : model1 loss : 0.435783 model2 loss : 0.019168
[00:35:40.360] iteration 19257 : model1 loss : 0.438287 model2 loss : 0.019401
[00:35:42.383] iteration 19258 : model1 loss : 0.439892 model2 loss : 0.017215
[00:35:42.552] iteration 19259 : model1 loss : 0.440662 model2 loss : 0.018810
[00:35:42.724] iteration 19260 : model1 loss : 0.439058 model2 loss : 0.017428
[00:35:42.891] iteration 19261 : model1 loss : 0.438699 model2 loss : 0.017754
[00:35:43.061] iteration 19262 : model1 loss : 0.438612 model2 loss : 0.018646
[00:35:43.227] iteration 19263 : model1 loss : 0.437099 model2 loss : 0.017849
[00:35:43.397] iteration 19264 : model1 loss : 0.441709 model2 loss : 0.019111
[00:35:43.564] iteration 19265 : model1 loss : 0.432801 model2 loss : 0.016608
[00:35:43.737] iteration 19266 : model1 loss : 0.434314 model2 loss : 0.019154
[00:35:43.903] iteration 19267 : model1 loss : 0.438245 model2 loss : 0.021516
[00:35:44.072] iteration 19268 : model1 loss : 0.441447 model2 loss : 0.020810
[00:35:44.238] iteration 19269 : model1 loss : 0.438230 model2 loss : 0.017360
[00:35:44.409] iteration 19270 : model1 loss : 0.438237 model2 loss : 0.019904
[00:35:44.585] iteration 19271 : model1 loss : 0.438163 model2 loss : 0.019823
[00:35:44.757] iteration 19272 : model1 loss : 0.441522 model2 loss : 0.023124
[00:35:44.922] iteration 19273 : model1 loss : 0.437899 model2 loss : 0.019129
[00:35:45.092] iteration 19274 : model1 loss : 0.439263 model2 loss : 0.020819
[00:35:45.260] iteration 19275 : model1 loss : 0.438315 model2 loss : 0.020199
[00:35:45.428] iteration 19276 : model1 loss : 0.431782 model2 loss : 0.019169
[00:35:45.599] iteration 19277 : model1 loss : 0.436358 model2 loss : 0.017989
[00:35:45.767] iteration 19278 : model1 loss : 0.439363 model2 loss : 0.018812
[00:35:47.806] iteration 19279 : model1 loss : 0.440564 model2 loss : 0.019657
[00:35:47.972] iteration 19280 : model1 loss : 0.437609 model2 loss : 0.020403
[00:35:48.144] iteration 19281 : model1 loss : 0.439567 model2 loss : 0.018490
[00:35:48.313] iteration 19282 : model1 loss : 0.443484 model2 loss : 0.022330
[00:35:48.484] iteration 19283 : model1 loss : 0.434029 model2 loss : 0.019258
[00:35:48.653] iteration 19284 : model1 loss : 0.434282 model2 loss : 0.018607
[00:35:48.820] iteration 19285 : model1 loss : 0.439671 model2 loss : 0.021113
[00:35:48.988] iteration 19286 : model1 loss : 0.437946 model2 loss : 0.019032
[00:35:49.157] iteration 19287 : model1 loss : 0.438467 model2 loss : 0.017768
[00:35:49.331] iteration 19288 : model1 loss : 0.441495 model2 loss : 0.020048
[00:35:49.500] iteration 19289 : model1 loss : 0.439172 model2 loss : 0.018501
[00:35:49.668] iteration 19290 : model1 loss : 0.433338 model2 loss : 0.020164
[00:35:49.836] iteration 19291 : model1 loss : 0.442733 model2 loss : 0.023726
[00:35:50.004] iteration 19292 : model1 loss : 0.438291 model2 loss : 0.017815
[00:35:50.175] iteration 19293 : model1 loss : 0.437295 model2 loss : 0.017852
[00:35:50.343] iteration 19294 : model1 loss : 0.437183 model2 loss : 0.018770
[00:35:50.512] iteration 19295 : model1 loss : 0.438360 model2 loss : 0.018640
[00:35:50.680] iteration 19296 : model1 loss : 0.434573 model2 loss : 0.015540
[00:35:50.850] iteration 19297 : model1 loss : 0.440742 model2 loss : 0.019573
[00:35:51.015] iteration 19298 : model1 loss : 0.436067 model2 loss : 0.018398
[00:35:51.184] iteration 19299 : model1 loss : 0.437044 model2 loss : 0.020336
[00:35:53.223] iteration 19300 : model1 loss : 0.439041 model2 loss : 0.019544
[00:35:53.396] iteration 19301 : model1 loss : 0.431144 model2 loss : 0.018264
[00:35:53.566] iteration 19302 : model1 loss : 0.439444 model2 loss : 0.017714
[00:35:53.734] iteration 19303 : model1 loss : 0.437365 model2 loss : 0.017921
[00:35:53.903] iteration 19304 : model1 loss : 0.438737 model2 loss : 0.018722
[00:35:54.071] iteration 19305 : model1 loss : 0.437493 model2 loss : 0.017305
[00:35:54.240] iteration 19306 : model1 loss : 0.442551 model2 loss : 0.020950
[00:35:54.409] iteration 19307 : model1 loss : 0.439768 model2 loss : 0.018804
[00:35:54.579] iteration 19308 : model1 loss : 0.437203 model2 loss : 0.018803
[00:35:54.747] iteration 19309 : model1 loss : 0.436578 model2 loss : 0.017951
[00:35:54.916] iteration 19310 : model1 loss : 0.434078 model2 loss : 0.019114
[00:35:55.083] iteration 19311 : model1 loss : 0.438621 model2 loss : 0.018664
[00:35:55.249] iteration 19312 : model1 loss : 0.441267 model2 loss : 0.018171
[00:35:55.417] iteration 19313 : model1 loss : 0.440824 model2 loss : 0.019318
[00:35:55.585] iteration 19314 : model1 loss : 0.437560 model2 loss : 0.021256
[00:35:55.757] iteration 19315 : model1 loss : 0.439356 model2 loss : 0.019177
[00:35:55.924] iteration 19316 : model1 loss : 0.438173 model2 loss : 0.018619
[00:35:56.092] iteration 19317 : model1 loss : 0.439835 model2 loss : 0.019367
[00:35:56.272] iteration 19318 : model1 loss : 0.434113 model2 loss : 0.018880
[00:35:56.437] iteration 19319 : model1 loss : 0.438228 model2 loss : 0.020150
[00:35:56.605] iteration 19320 : model1 loss : 0.439574 model2 loss : 0.019892
[00:35:58.712] iteration 19321 : model1 loss : 0.430431 model2 loss : 0.017338
[00:35:58.880] iteration 19322 : model1 loss : 0.440608 model2 loss : 0.018793
[00:35:59.049] iteration 19323 : model1 loss : 0.439781 model2 loss : 0.018665
[00:35:59.215] iteration 19324 : model1 loss : 0.439442 model2 loss : 0.018391
[00:35:59.386] iteration 19325 : model1 loss : 0.436450 model2 loss : 0.020649
[00:35:59.554] iteration 19326 : model1 loss : 0.436499 model2 loss : 0.018103
[00:35:59.725] iteration 19327 : model1 loss : 0.435016 model2 loss : 0.017809
[00:35:59.891] iteration 19328 : model1 loss : 0.436042 model2 loss : 0.020105
[00:36:00.062] iteration 19329 : model1 loss : 0.441174 model2 loss : 0.019803
[00:36:00.230] iteration 19330 : model1 loss : 0.439460 model2 loss : 0.018169
[00:36:00.397] iteration 19331 : model1 loss : 0.437837 model2 loss : 0.018159
[00:36:00.564] iteration 19332 : model1 loss : 0.440341 model2 loss : 0.022060
[00:36:00.735] iteration 19333 : model1 loss : 0.440419 model2 loss : 0.021061
[00:36:00.907] iteration 19334 : model1 loss : 0.435216 model2 loss : 0.019571
[00:36:01.076] iteration 19335 : model1 loss : 0.439158 model2 loss : 0.017956
[00:36:01.241] iteration 19336 : model1 loss : 0.438167 model2 loss : 0.017337
[00:36:01.410] iteration 19337 : model1 loss : 0.440342 model2 loss : 0.017084
[00:36:01.575] iteration 19338 : model1 loss : 0.435949 model2 loss : 0.019718
[00:36:01.746] iteration 19339 : model1 loss : 0.435983 model2 loss : 0.017341
[00:36:01.911] iteration 19340 : model1 loss : 0.437714 model2 loss : 0.019846
[00:36:02.080] iteration 19341 : model1 loss : 0.441471 model2 loss : 0.021003
[00:36:04.135] iteration 19342 : model1 loss : 0.443575 model2 loss : 0.022035
[00:36:04.302] iteration 19343 : model1 loss : 0.433319 model2 loss : 0.016335
[00:36:04.470] iteration 19344 : model1 loss : 0.435175 model2 loss : 0.018186
[00:36:04.636] iteration 19345 : model1 loss : 0.440887 model2 loss : 0.019248
[00:36:04.806] iteration 19346 : model1 loss : 0.430801 model2 loss : 0.017945
[00:36:04.973] iteration 19347 : model1 loss : 0.441768 model2 loss : 0.020335
[00:36:05.142] iteration 19348 : model1 loss : 0.436391 model2 loss : 0.018358
[00:36:05.313] iteration 19349 : model1 loss : 0.434389 model2 loss : 0.020019
[00:36:05.480] iteration 19350 : model1 loss : 0.441881 model2 loss : 0.019726
[00:36:05.646] iteration 19351 : model1 loss : 0.443023 model2 loss : 0.020232
[00:36:05.816] iteration 19352 : model1 loss : 0.439688 model2 loss : 0.018060
[00:36:05.983] iteration 19353 : model1 loss : 0.437007 model2 loss : 0.018654
[00:36:06.153] iteration 19354 : model1 loss : 0.439799 model2 loss : 0.021232
[00:36:06.323] iteration 19355 : model1 loss : 0.439431 model2 loss : 0.018994
[00:36:06.492] iteration 19356 : model1 loss : 0.437128 model2 loss : 0.019396
[00:36:06.660] iteration 19357 : model1 loss : 0.433131 model2 loss : 0.016446
[00:36:06.829] iteration 19358 : model1 loss : 0.437491 model2 loss : 0.020472
[00:36:06.995] iteration 19359 : model1 loss : 0.437893 model2 loss : 0.018771
[00:36:07.164] iteration 19360 : model1 loss : 0.438508 model2 loss : 0.018432
[00:36:07.333] iteration 19361 : model1 loss : 0.439103 model2 loss : 0.019638
[00:36:07.505] iteration 19362 : model1 loss : 0.440634 model2 loss : 0.017488
[00:36:09.544] iteration 19363 : model1 loss : 0.437707 model2 loss : 0.019181
[00:36:09.711] iteration 19364 : model1 loss : 0.437582 model2 loss : 0.019250
[00:36:09.880] iteration 19365 : model1 loss : 0.435930 model2 loss : 0.017876
[00:36:10.052] iteration 19366 : model1 loss : 0.440785 model2 loss : 0.019856
[00:36:10.222] iteration 19367 : model1 loss : 0.439745 model2 loss : 0.018502
[00:36:10.399] iteration 19368 : model1 loss : 0.443301 model2 loss : 0.019642
[00:36:10.567] iteration 19369 : model1 loss : 0.438528 model2 loss : 0.019495
[00:36:10.736] iteration 19370 : model1 loss : 0.438178 model2 loss : 0.018578
[00:36:10.904] iteration 19371 : model1 loss : 0.437116 model2 loss : 0.016909
[00:36:11.072] iteration 19372 : model1 loss : 0.436419 model2 loss : 0.018971
[00:36:11.242] iteration 19373 : model1 loss : 0.433309 model2 loss : 0.018580
[00:36:11.410] iteration 19374 : model1 loss : 0.439932 model2 loss : 0.021422
[00:36:11.578] iteration 19375 : model1 loss : 0.439431 model2 loss : 0.018190
[00:36:11.750] iteration 19376 : model1 loss : 0.438228 model2 loss : 0.018802
[00:36:11.917] iteration 19377 : model1 loss : 0.437876 model2 loss : 0.018159
[00:36:12.086] iteration 19378 : model1 loss : 0.437706 model2 loss : 0.018916
[00:36:12.254] iteration 19379 : model1 loss : 0.438443 model2 loss : 0.018251
[00:36:12.424] iteration 19380 : model1 loss : 0.440478 model2 loss : 0.017896
[00:36:12.594] iteration 19381 : model1 loss : 0.436507 model2 loss : 0.020791
[00:36:12.765] iteration 19382 : model1 loss : 0.440196 model2 loss : 0.017920
[00:36:12.932] iteration 19383 : model1 loss : 0.437975 model2 loss : 0.019332
[00:36:15.011] iteration 19384 : model1 loss : 0.435567 model2 loss : 0.016967
[00:36:15.180] iteration 19385 : model1 loss : 0.441220 model2 loss : 0.019348
[00:36:15.350] iteration 19386 : model1 loss : 0.436343 model2 loss : 0.020456
[00:36:15.518] iteration 19387 : model1 loss : 0.443264 model2 loss : 0.019856
[00:36:15.686] iteration 19388 : model1 loss : 0.436320 model2 loss : 0.019183
[00:36:15.854] iteration 19389 : model1 loss : 0.443421 model2 loss : 0.020566
[00:36:16.022] iteration 19390 : model1 loss : 0.437616 model2 loss : 0.019909
[00:36:16.192] iteration 19391 : model1 loss : 0.439568 model2 loss : 0.018706
[00:36:16.361] iteration 19392 : model1 loss : 0.437482 model2 loss : 0.020282
[00:36:16.528] iteration 19393 : model1 loss : 0.439969 model2 loss : 0.018731
[00:36:16.695] iteration 19394 : model1 loss : 0.439366 model2 loss : 0.017739
[00:36:16.864] iteration 19395 : model1 loss : 0.440702 model2 loss : 0.016643
[00:36:17.034] iteration 19396 : model1 loss : 0.440388 model2 loss : 0.018170
[00:36:17.200] iteration 19397 : model1 loss : 0.434694 model2 loss : 0.018012
[00:36:17.369] iteration 19398 : model1 loss : 0.435265 model2 loss : 0.018477
[00:36:17.536] iteration 19399 : model1 loss : 0.441035 model2 loss : 0.020925
[00:36:17.706] iteration 19400 : model1 loss : 0.434833 model2 loss : 0.016113
[00:36:17.874] iteration 19401 : model1 loss : 0.437528 model2 loss : 0.018016
[00:36:18.043] iteration 19402 : model1 loss : 0.438613 model2 loss : 0.018628
[00:36:18.207] iteration 19403 : model1 loss : 0.435628 model2 loss : 0.020257
[00:36:18.376] iteration 19404 : model1 loss : 0.435702 model2 loss : 0.018073
[00:36:20.384] iteration 19405 : model1 loss : 0.433442 model2 loss : 0.018590
[00:36:20.552] iteration 19406 : model1 loss : 0.439141 model2 loss : 0.018415
[00:36:20.720] iteration 19407 : model1 loss : 0.440964 model2 loss : 0.018283
[00:36:20.888] iteration 19408 : model1 loss : 0.436362 model2 loss : 0.018148
[00:36:21.056] iteration 19409 : model1 loss : 0.439478 model2 loss : 0.017248
[00:36:21.222] iteration 19410 : model1 loss : 0.439017 model2 loss : 0.018252
[00:36:21.392] iteration 19411 : model1 loss : 0.437293 model2 loss : 0.017588
[00:36:21.558] iteration 19412 : model1 loss : 0.439064 model2 loss : 0.018351
[00:36:21.727] iteration 19413 : model1 loss : 0.440047 model2 loss : 0.018130
[00:36:21.895] iteration 19414 : model1 loss : 0.437698 model2 loss : 0.018375
[00:36:22.063] iteration 19415 : model1 loss : 0.436369 model2 loss : 0.020269
[00:36:22.229] iteration 19416 : model1 loss : 0.441457 model2 loss : 0.020676
[00:36:22.399] iteration 19417 : model1 loss : 0.436204 model2 loss : 0.020161
[00:36:22.564] iteration 19418 : model1 loss : 0.441630 model2 loss : 0.019595
[00:36:22.736] iteration 19419 : model1 loss : 0.433843 model2 loss : 0.017260
[00:36:22.901] iteration 19420 : model1 loss : 0.438307 model2 loss : 0.017386
[00:36:23.070] iteration 19421 : model1 loss : 0.439124 model2 loss : 0.017516
[00:36:23.237] iteration 19422 : model1 loss : 0.438564 model2 loss : 0.019502
[00:36:23.407] iteration 19423 : model1 loss : 0.436842 model2 loss : 0.018924
[00:36:23.573] iteration 19424 : model1 loss : 0.436850 model2 loss : 0.017669
[00:36:23.743] iteration 19425 : model1 loss : 0.439644 model2 loss : 0.017139
[00:36:25.783] iteration 19426 : model1 loss : 0.437289 model2 loss : 0.016622
[00:36:25.954] iteration 19427 : model1 loss : 0.434924 model2 loss : 0.017322
[00:36:26.128] iteration 19428 : model1 loss : 0.435983 model2 loss : 0.017078
[00:36:26.295] iteration 19429 : model1 loss : 0.439191 model2 loss : 0.020078
[00:36:26.463] iteration 19430 : model1 loss : 0.438930 model2 loss : 0.021076
[00:36:26.632] iteration 19431 : model1 loss : 0.440130 model2 loss : 0.019568
[00:36:26.802] iteration 19432 : model1 loss : 0.438637 model2 loss : 0.017121
[00:36:26.969] iteration 19433 : model1 loss : 0.438689 model2 loss : 0.017158
[00:36:27.137] iteration 19434 : model1 loss : 0.434755 model2 loss : 0.017090
[00:36:27.306] iteration 19435 : model1 loss : 0.439219 model2 loss : 0.017822
[00:36:27.478] iteration 19436 : model1 loss : 0.438242 model2 loss : 0.018755
[00:36:27.644] iteration 19437 : model1 loss : 0.440074 model2 loss : 0.018321
[00:36:27.813] iteration 19438 : model1 loss : 0.436530 model2 loss : 0.018812
[00:36:27.981] iteration 19439 : model1 loss : 0.439019 model2 loss : 0.018768
[00:36:28.150] iteration 19440 : model1 loss : 0.434082 model2 loss : 0.018193
[00:36:28.318] iteration 19441 : model1 loss : 0.436141 model2 loss : 0.017624
[00:36:28.488] iteration 19442 : model1 loss : 0.439971 model2 loss : 0.019108
[00:36:28.655] iteration 19443 : model1 loss : 0.439706 model2 loss : 0.017856
[00:36:28.827] iteration 19444 : model1 loss : 0.438265 model2 loss : 0.018539
[00:36:28.992] iteration 19445 : model1 loss : 0.446083 model2 loss : 0.021120
[00:36:29.162] iteration 19446 : model1 loss : 0.433630 model2 loss : 0.017590
[00:36:31.193] iteration 19447 : model1 loss : 0.441056 model2 loss : 0.020611
[00:36:31.362] iteration 19448 : model1 loss : 0.439093 model2 loss : 0.019907
[00:36:31.533] iteration 19449 : model1 loss : 0.435144 model2 loss : 0.017988
[00:36:31.699] iteration 19450 : model1 loss : 0.436911 model2 loss : 0.018570
[00:36:31.870] iteration 19451 : model1 loss : 0.436783 model2 loss : 0.016499
[00:36:32.037] iteration 19452 : model1 loss : 0.441553 model2 loss : 0.019790
[00:36:32.209] iteration 19453 : model1 loss : 0.440543 model2 loss : 0.020003
[00:36:32.376] iteration 19454 : model1 loss : 0.435594 model2 loss : 0.017924
[00:36:32.545] iteration 19455 : model1 loss : 0.438046 model2 loss : 0.018192
[00:36:32.715] iteration 19456 : model1 loss : 0.440235 model2 loss : 0.021014
[00:36:32.884] iteration 19457 : model1 loss : 0.438920 model2 loss : 0.019097
[00:36:33.051] iteration 19458 : model1 loss : 0.439138 model2 loss : 0.019968
[00:36:33.220] iteration 19459 : model1 loss : 0.438157 model2 loss : 0.020260
[00:36:33.384] iteration 19460 : model1 loss : 0.440548 model2 loss : 0.019658
[00:36:33.554] iteration 19461 : model1 loss : 0.435594 model2 loss : 0.019850
[00:36:33.719] iteration 19462 : model1 loss : 0.439389 model2 loss : 0.020124
[00:36:33.887] iteration 19463 : model1 loss : 0.437198 model2 loss : 0.018691
[00:36:34.054] iteration 19464 : model1 loss : 0.437163 model2 loss : 0.018478
[00:36:34.222] iteration 19465 : model1 loss : 0.440955 model2 loss : 0.017557
[00:36:34.387] iteration 19466 : model1 loss : 0.435206 model2 loss : 0.018209
[00:36:34.556] iteration 19467 : model1 loss : 0.437079 model2 loss : 0.018873
[00:36:36.583] iteration 19468 : model1 loss : 0.436729 model2 loss : 0.017680
[00:36:36.754] iteration 19469 : model1 loss : 0.440164 model2 loss : 0.020056
[00:36:36.923] iteration 19470 : model1 loss : 0.437679 model2 loss : 0.023477
[00:36:37.088] iteration 19471 : model1 loss : 0.440524 model2 loss : 0.018022
[00:36:37.257] iteration 19472 : model1 loss : 0.438513 model2 loss : 0.017075
[00:36:37.427] iteration 19473 : model1 loss : 0.434707 model2 loss : 0.017318
[00:36:37.596] iteration 19474 : model1 loss : 0.436146 model2 loss : 0.018115
[00:36:37.765] iteration 19475 : model1 loss : 0.436648 model2 loss : 0.019286
[00:36:37.938] iteration 19476 : model1 loss : 0.438089 model2 loss : 0.018900
[00:36:38.103] iteration 19477 : model1 loss : 0.439867 model2 loss : 0.017098
[00:36:38.275] iteration 19478 : model1 loss : 0.439293 model2 loss : 0.019697
[00:36:38.441] iteration 19479 : model1 loss : 0.437520 model2 loss : 0.018890
[00:36:38.611] iteration 19480 : model1 loss : 0.439504 model2 loss : 0.020416
[00:36:38.781] iteration 19481 : model1 loss : 0.434612 model2 loss : 0.019290
[00:36:38.950] iteration 19482 : model1 loss : 0.440887 model2 loss : 0.016941
[00:36:39.119] iteration 19483 : model1 loss : 0.436731 model2 loss : 0.019751
[00:36:39.287] iteration 19484 : model1 loss : 0.437331 model2 loss : 0.017942
[00:36:39.454] iteration 19485 : model1 loss : 0.441705 model2 loss : 0.020855
[00:36:39.623] iteration 19486 : model1 loss : 0.436508 model2 loss : 0.017736
[00:36:39.788] iteration 19487 : model1 loss : 0.439451 model2 loss : 0.019216
[00:36:39.955] iteration 19488 : model1 loss : 0.438227 model2 loss : 0.020072
[00:36:41.957] iteration 19489 : model1 loss : 0.441138 model2 loss : 0.020965
[00:36:42.126] iteration 19490 : model1 loss : 0.440577 model2 loss : 0.019637
[00:36:42.296] iteration 19491 : model1 loss : 0.440917 model2 loss : 0.020019
[00:36:42.464] iteration 19492 : model1 loss : 0.440878 model2 loss : 0.019254
[00:36:42.634] iteration 19493 : model1 loss : 0.434987 model2 loss : 0.019228
[00:36:42.804] iteration 19494 : model1 loss : 0.436439 model2 loss : 0.018946
[00:36:42.972] iteration 19495 : model1 loss : 0.433314 model2 loss : 0.020285
[00:36:43.139] iteration 19496 : model1 loss : 0.437022 model2 loss : 0.018952
[00:36:43.309] iteration 19497 : model1 loss : 0.439362 model2 loss : 0.018086
[00:36:43.477] iteration 19498 : model1 loss : 0.436116 model2 loss : 0.016821
[00:36:43.649] iteration 19499 : model1 loss : 0.439150 model2 loss : 0.020117
[00:36:43.817] iteration 19500 : model1 loss : 0.442062 model2 loss : 0.018983
[00:36:43.987] iteration 19501 : model1 loss : 0.441461 model2 loss : 0.022370
[00:36:44.154] iteration 19502 : model1 loss : 0.437507 model2 loss : 0.018585
[00:36:44.324] iteration 19503 : model1 loss : 0.435272 model2 loss : 0.018565
[00:36:44.490] iteration 19504 : model1 loss : 0.440398 model2 loss : 0.019962
[00:36:44.660] iteration 19505 : model1 loss : 0.438742 model2 loss : 0.019009
[00:36:44.827] iteration 19506 : model1 loss : 0.434345 model2 loss : 0.017524
[00:36:44.995] iteration 19507 : model1 loss : 0.437082 model2 loss : 0.018400
[00:36:45.161] iteration 19508 : model1 loss : 0.439425 model2 loss : 0.019567
[00:36:45.330] iteration 19509 : model1 loss : 0.442376 model2 loss : 0.019456
[00:36:47.373] iteration 19510 : model1 loss : 0.439119 model2 loss : 0.020132
[00:36:47.543] iteration 19511 : model1 loss : 0.433405 model2 loss : 0.017273
[00:36:47.721] iteration 19512 : model1 loss : 0.440316 model2 loss : 0.020231
[00:36:47.888] iteration 19513 : model1 loss : 0.437827 model2 loss : 0.019419
[00:36:48.055] iteration 19514 : model1 loss : 0.443331 model2 loss : 0.020443
[00:36:48.222] iteration 19515 : model1 loss : 0.437522 model2 loss : 0.018335
[00:36:48.390] iteration 19516 : model1 loss : 0.439661 model2 loss : 0.022111
[00:36:48.558] iteration 19517 : model1 loss : 0.435865 model2 loss : 0.020722
[00:36:48.729] iteration 19518 : model1 loss : 0.439921 model2 loss : 0.018911
[00:36:48.896] iteration 19519 : model1 loss : 0.438309 model2 loss : 0.017256
[00:36:49.064] iteration 19520 : model1 loss : 0.441917 model2 loss : 0.020911
[00:36:49.231] iteration 19521 : model1 loss : 0.439952 model2 loss : 0.017117
[00:36:49.400] iteration 19522 : model1 loss : 0.436926 model2 loss : 0.018914
[00:36:49.568] iteration 19523 : model1 loss : 0.436304 model2 loss : 0.015522
[00:36:49.738] iteration 19524 : model1 loss : 0.443072 model2 loss : 0.022374
[00:36:49.904] iteration 19525 : model1 loss : 0.437376 model2 loss : 0.017885
[00:36:50.073] iteration 19526 : model1 loss : 0.433437 model2 loss : 0.016210
[00:36:50.240] iteration 19527 : model1 loss : 0.438538 model2 loss : 0.019354
[00:36:50.408] iteration 19528 : model1 loss : 0.437550 model2 loss : 0.019005
[00:36:50.573] iteration 19529 : model1 loss : 0.436102 model2 loss : 0.018470
[00:36:50.742] iteration 19530 : model1 loss : 0.436941 model2 loss : 0.017294
[00:36:52.795] iteration 19531 : model1 loss : 0.436137 model2 loss : 0.019882
[00:36:52.964] iteration 19532 : model1 loss : 0.438747 model2 loss : 0.020913
[00:36:53.134] iteration 19533 : model1 loss : 0.436300 model2 loss : 0.019630
[00:36:53.303] iteration 19534 : model1 loss : 0.436084 model2 loss : 0.019145
[00:36:53.472] iteration 19535 : model1 loss : 0.436312 model2 loss : 0.018298
[00:36:53.639] iteration 19536 : model1 loss : 0.439518 model2 loss : 0.018773
[00:36:53.808] iteration 19537 : model1 loss : 0.437201 model2 loss : 0.018400
[00:36:53.976] iteration 19538 : model1 loss : 0.440466 model2 loss : 0.018637
[00:36:54.147] iteration 19539 : model1 loss : 0.438250 model2 loss : 0.019117
[00:36:54.314] iteration 19540 : model1 loss : 0.441577 model2 loss : 0.017843
[00:36:54.483] iteration 19541 : model1 loss : 0.436606 model2 loss : 0.017180
[00:36:54.650] iteration 19542 : model1 loss : 0.439185 model2 loss : 0.018730
[00:36:54.818] iteration 19543 : model1 loss : 0.441898 model2 loss : 0.019524
[00:36:54.984] iteration 19544 : model1 loss : 0.437320 model2 loss : 0.017233
[00:36:55.154] iteration 19545 : model1 loss : 0.438825 model2 loss : 0.017335
[00:36:55.322] iteration 19546 : model1 loss : 0.441516 model2 loss : 0.019114
[00:36:55.492] iteration 19547 : model1 loss : 0.437259 model2 loss : 0.016436
[00:36:55.660] iteration 19548 : model1 loss : 0.440434 model2 loss : 0.019973
[00:36:55.829] iteration 19549 : model1 loss : 0.440783 model2 loss : 0.019284
[00:36:55.993] iteration 19550 : model1 loss : 0.431938 model2 loss : 0.018704
[00:36:56.161] iteration 19551 : model1 loss : 0.436478 model2 loss : 0.017887
[00:36:58.200] iteration 19552 : model1 loss : 0.435320 model2 loss : 0.018324
[00:36:58.369] iteration 19553 : model1 loss : 0.439022 model2 loss : 0.018048
[00:36:58.538] iteration 19554 : model1 loss : 0.437111 model2 loss : 0.017928
[00:36:58.705] iteration 19555 : model1 loss : 0.435327 model2 loss : 0.017608
[00:36:58.873] iteration 19556 : model1 loss : 0.440433 model2 loss : 0.017257
[00:36:59.039] iteration 19557 : model1 loss : 0.433966 model2 loss : 0.018427
[00:36:59.209] iteration 19558 : model1 loss : 0.440349 model2 loss : 0.016760
[00:36:59.376] iteration 19559 : model1 loss : 0.438100 model2 loss : 0.018548
[00:36:59.544] iteration 19560 : model1 loss : 0.439500 model2 loss : 0.017095
[00:36:59.712] iteration 19561 : model1 loss : 0.441186 model2 loss : 0.019964
[00:36:59.881] iteration 19562 : model1 loss : 0.438145 model2 loss : 0.018853
[00:37:00.048] iteration 19563 : model1 loss : 0.438464 model2 loss : 0.016994
[00:37:00.219] iteration 19564 : model1 loss : 0.439963 model2 loss : 0.019356
[00:37:00.385] iteration 19565 : model1 loss : 0.438271 model2 loss : 0.018146
[00:37:00.554] iteration 19566 : model1 loss : 0.436948 model2 loss : 0.019779
[00:37:00.722] iteration 19567 : model1 loss : 0.436362 model2 loss : 0.018486
[00:37:00.891] iteration 19568 : model1 loss : 0.437580 model2 loss : 0.017692
[00:37:01.056] iteration 19569 : model1 loss : 0.442685 model2 loss : 0.017268
[00:37:01.225] iteration 19570 : model1 loss : 0.438653 model2 loss : 0.020110
[00:37:01.391] iteration 19571 : model1 loss : 0.437471 model2 loss : 0.018840
[00:37:01.560] iteration 19572 : model1 loss : 0.432130 model2 loss : 0.017623
[00:37:03.635] iteration 19573 : model1 loss : 0.436754 model2 loss : 0.017370
[00:37:03.803] iteration 19574 : model1 loss : 0.441446 model2 loss : 0.019462
[00:37:03.973] iteration 19575 : model1 loss : 0.434760 model2 loss : 0.017749
[00:37:04.138] iteration 19576 : model1 loss : 0.431515 model2 loss : 0.017557
[00:37:04.310] iteration 19577 : model1 loss : 0.437089 model2 loss : 0.019558
[00:37:04.477] iteration 19578 : model1 loss : 0.436664 model2 loss : 0.017685
[00:37:04.649] iteration 19579 : model1 loss : 0.440033 model2 loss : 0.018288
[00:37:04.816] iteration 19580 : model1 loss : 0.435383 model2 loss : 0.017768
[00:37:04.984] iteration 19581 : model1 loss : 0.437114 model2 loss : 0.019305
[00:37:05.151] iteration 19582 : model1 loss : 0.441501 model2 loss : 0.024253
[00:37:05.321] iteration 19583 : model1 loss : 0.440648 model2 loss : 0.021150
[00:37:05.487] iteration 19584 : model1 loss : 0.437365 model2 loss : 0.019460
[00:37:05.655] iteration 19585 : model1 loss : 0.443619 model2 loss : 0.021965
[00:37:05.823] iteration 19586 : model1 loss : 0.437256 model2 loss : 0.019028
[00:37:05.993] iteration 19587 : model1 loss : 0.441754 model2 loss : 0.021670
[00:37:06.161] iteration 19588 : model1 loss : 0.436469 model2 loss : 0.019970
[00:37:06.331] iteration 19589 : model1 loss : 0.435471 model2 loss : 0.017208
[00:37:06.498] iteration 19590 : model1 loss : 0.438861 model2 loss : 0.018513
[00:37:06.666] iteration 19591 : model1 loss : 0.441543 model2 loss : 0.020183
[00:37:06.832] iteration 19592 : model1 loss : 0.438040 model2 loss : 0.017565
[00:37:06.999] iteration 19593 : model1 loss : 0.438807 model2 loss : 0.021593
[00:37:09.037] iteration 19594 : model1 loss : 0.440820 model2 loss : 0.017808
[00:37:09.204] iteration 19595 : model1 loss : 0.436736 model2 loss : 0.018081
[00:37:09.373] iteration 19596 : model1 loss : 0.436018 model2 loss : 0.020564
[00:37:09.540] iteration 19597 : model1 loss : 0.436784 model2 loss : 0.018638
[00:37:09.708] iteration 19598 : model1 loss : 0.436280 model2 loss : 0.017540
[00:37:09.875] iteration 19599 : model1 loss : 0.438167 model2 loss : 0.018906
[00:37:10.044] iteration 19600 : model1 loss : 0.437969 model2 loss : 0.018824
[00:37:10.211] iteration 19601 : model1 loss : 0.438941 model2 loss : 0.020016
[00:37:10.380] iteration 19602 : model1 loss : 0.438307 model2 loss : 0.017560
[00:37:10.549] iteration 19603 : model1 loss : 0.439395 model2 loss : 0.021110
[00:37:10.717] iteration 19604 : model1 loss : 0.440484 model2 loss : 0.020058
[00:37:10.883] iteration 19605 : model1 loss : 0.438422 model2 loss : 0.017775
[00:37:11.052] iteration 19606 : model1 loss : 0.437583 model2 loss : 0.018267
[00:37:11.221] iteration 19607 : model1 loss : 0.435475 model2 loss : 0.018729
[00:37:11.389] iteration 19608 : model1 loss : 0.438433 model2 loss : 0.018422
[00:37:11.555] iteration 19609 : model1 loss : 0.440212 model2 loss : 0.019778
[00:37:11.723] iteration 19610 : model1 loss : 0.437298 model2 loss : 0.017628
[00:37:11.889] iteration 19611 : model1 loss : 0.439432 model2 loss : 0.018487
[00:37:12.058] iteration 19612 : model1 loss : 0.435377 model2 loss : 0.017466
[00:37:12.222] iteration 19613 : model1 loss : 0.440688 model2 loss : 0.019726
[00:37:12.389] iteration 19614 : model1 loss : 0.435581 model2 loss : 0.017876
[00:37:14.385] iteration 19615 : model1 loss : 0.435040 model2 loss : 0.017622
[00:37:14.553] iteration 19616 : model1 loss : 0.441851 model2 loss : 0.017736
[00:37:14.722] iteration 19617 : model1 loss : 0.436389 model2 loss : 0.018197
[00:37:14.890] iteration 19618 : model1 loss : 0.440510 model2 loss : 0.021031
[00:37:15.059] iteration 19619 : model1 loss : 0.437439 model2 loss : 0.018593
[00:37:15.225] iteration 19620 : model1 loss : 0.439252 model2 loss : 0.019109
[00:37:15.395] iteration 19621 : model1 loss : 0.437330 model2 loss : 0.018493
[00:37:15.563] iteration 19622 : model1 loss : 0.433664 model2 loss : 0.018911
[00:37:15.733] iteration 19623 : model1 loss : 0.436978 model2 loss : 0.019072
[00:37:15.901] iteration 19624 : model1 loss : 0.440156 model2 loss : 0.019017
[00:37:16.069] iteration 19625 : model1 loss : 0.438326 model2 loss : 0.017915
[00:37:16.235] iteration 19626 : model1 loss : 0.438790 model2 loss : 0.020749
[00:37:16.406] iteration 19627 : model1 loss : 0.436254 model2 loss : 0.016607
[00:37:16.576] iteration 19628 : model1 loss : 0.438827 model2 loss : 0.019456
[00:37:16.746] iteration 19629 : model1 loss : 0.437293 model2 loss : 0.018940
[00:37:16.912] iteration 19630 : model1 loss : 0.441620 model2 loss : 0.021190
[00:37:17.080] iteration 19631 : model1 loss : 0.440387 model2 loss : 0.020301
[00:37:17.248] iteration 19632 : model1 loss : 0.436943 model2 loss : 0.018651
[00:37:17.419] iteration 19633 : model1 loss : 0.440615 model2 loss : 0.017859
[00:37:17.586] iteration 19634 : model1 loss : 0.436970 model2 loss : 0.018708
[00:37:17.755] iteration 19635 : model1 loss : 0.440011 model2 loss : 0.017646
[00:37:19.792] iteration 19636 : model1 loss : 0.435717 model2 loss : 0.017178
[00:37:19.959] iteration 19637 : model1 loss : 0.436413 model2 loss : 0.020461
[00:37:20.129] iteration 19638 : model1 loss : 0.444374 model2 loss : 0.020222
[00:37:20.297] iteration 19639 : model1 loss : 0.438289 model2 loss : 0.019368
[00:37:20.465] iteration 19640 : model1 loss : 0.440550 model2 loss : 0.017837
[00:37:20.632] iteration 19641 : model1 loss : 0.439071 model2 loss : 0.015767
[00:37:20.807] iteration 19642 : model1 loss : 0.435197 model2 loss : 0.016859
[00:37:20.973] iteration 19643 : model1 loss : 0.441599 model2 loss : 0.018986
[00:37:21.143] iteration 19644 : model1 loss : 0.441702 model2 loss : 0.020265
[00:37:21.310] iteration 19645 : model1 loss : 0.441433 model2 loss : 0.020786
[00:37:21.478] iteration 19646 : model1 loss : 0.434403 model2 loss : 0.017895
[00:37:21.645] iteration 19647 : model1 loss : 0.441416 model2 loss : 0.020900
[00:37:21.816] iteration 19648 : model1 loss : 0.433587 model2 loss : 0.019715
[00:37:21.983] iteration 19649 : model1 loss : 0.435818 model2 loss : 0.018234
[00:37:22.151] iteration 19650 : model1 loss : 0.437168 model2 loss : 0.018770
[00:37:22.327] iteration 19651 : model1 loss : 0.437337 model2 loss : 0.020904
[00:37:22.500] iteration 19652 : model1 loss : 0.435603 model2 loss : 0.016428
[00:37:22.665] iteration 19653 : model1 loss : 0.439162 model2 loss : 0.020148
[00:37:22.838] iteration 19654 : model1 loss : 0.436986 model2 loss : 0.019313
[00:37:23.003] iteration 19655 : model1 loss : 0.440149 model2 loss : 0.018576
[00:37:23.172] iteration 19656 : model1 loss : 0.439366 model2 loss : 0.019244
[00:37:25.158] iteration 19657 : model1 loss : 0.439773 model2 loss : 0.019855
[00:37:25.331] iteration 19658 : model1 loss : 0.439270 model2 loss : 0.017572
[00:37:25.500] iteration 19659 : model1 loss : 0.443737 model2 loss : 0.021969
[00:37:25.667] iteration 19660 : model1 loss : 0.437196 model2 loss : 0.016657
[00:37:25.849] iteration 19661 : model1 loss : 0.439707 model2 loss : 0.018591
[00:37:26.017] iteration 19662 : model1 loss : 0.435258 model2 loss : 0.017350
[00:37:26.186] iteration 19663 : model1 loss : 0.440385 model2 loss : 0.021446
[00:37:26.353] iteration 19664 : model1 loss : 0.438150 model2 loss : 0.018171
[00:37:26.521] iteration 19665 : model1 loss : 0.434252 model2 loss : 0.017525
[00:37:26.688] iteration 19666 : model1 loss : 0.438973 model2 loss : 0.018471
[00:37:26.854] iteration 19667 : model1 loss : 0.436245 model2 loss : 0.017622
[00:37:27.020] iteration 19668 : model1 loss : 0.440667 model2 loss : 0.018417
[00:37:27.189] iteration 19669 : model1 loss : 0.435610 model2 loss : 0.020379
[00:37:27.358] iteration 19670 : model1 loss : 0.436332 model2 loss : 0.018694
[00:37:27.528] iteration 19671 : model1 loss : 0.437035 model2 loss : 0.017178
[00:37:27.695] iteration 19672 : model1 loss : 0.438983 model2 loss : 0.017916
[00:37:27.867] iteration 19673 : model1 loss : 0.437516 model2 loss : 0.017186
[00:37:28.034] iteration 19674 : model1 loss : 0.436486 model2 loss : 0.018934
[00:37:28.204] iteration 19675 : model1 loss : 0.442558 model2 loss : 0.019291
[00:37:28.372] iteration 19676 : model1 loss : 0.436318 model2 loss : 0.017208
[00:37:28.539] iteration 19677 : model1 loss : 0.435942 model2 loss : 0.017997
[00:37:30.546] iteration 19678 : model1 loss : 0.435524 model2 loss : 0.017205
[00:37:30.713] iteration 19679 : model1 loss : 0.438429 model2 loss : 0.021180
[00:37:30.882] iteration 19680 : model1 loss : 0.439255 model2 loss : 0.020849
[00:37:31.049] iteration 19681 : model1 loss : 0.439023 model2 loss : 0.017582
[00:37:31.217] iteration 19682 : model1 loss : 0.438805 model2 loss : 0.017567
[00:37:31.383] iteration 19683 : model1 loss : 0.439296 model2 loss : 0.018157
[00:37:31.552] iteration 19684 : model1 loss : 0.441617 model2 loss : 0.017233
[00:37:31.722] iteration 19685 : model1 loss : 0.434974 model2 loss : 0.017213
[00:37:31.891] iteration 19686 : model1 loss : 0.435733 model2 loss : 0.018918
[00:37:32.058] iteration 19687 : model1 loss : 0.435704 model2 loss : 0.019455
[00:37:32.227] iteration 19688 : model1 loss : 0.437984 model2 loss : 0.017775
[00:37:32.395] iteration 19689 : model1 loss : 0.438425 model2 loss : 0.017896
[00:37:32.565] iteration 19690 : model1 loss : 0.436475 model2 loss : 0.017668
[00:37:32.735] iteration 19691 : model1 loss : 0.436818 model2 loss : 0.018180
[00:37:32.904] iteration 19692 : model1 loss : 0.435027 model2 loss : 0.017358
[00:37:33.070] iteration 19693 : model1 loss : 0.444111 model2 loss : 0.021528
[00:37:33.239] iteration 19694 : model1 loss : 0.440158 model2 loss : 0.016886
[00:37:33.408] iteration 19695 : model1 loss : 0.437350 model2 loss : 0.019376
[00:37:33.577] iteration 19696 : model1 loss : 0.440194 model2 loss : 0.019228
[00:37:33.743] iteration 19697 : model1 loss : 0.436617 model2 loss : 0.015788
[00:37:33.911] iteration 19698 : model1 loss : 0.443450 model2 loss : 0.019294
[00:37:35.919] iteration 19699 : model1 loss : 0.438847 model2 loss : 0.019581
[00:37:36.087] iteration 19700 : model1 loss : 0.435473 model2 loss : 0.016623
[00:37:36.255] iteration 19701 : model1 loss : 0.437662 model2 loss : 0.017917
[00:37:36.421] iteration 19702 : model1 loss : 0.437992 model2 loss : 0.017522
[00:37:36.590] iteration 19703 : model1 loss : 0.440656 model2 loss : 0.018357
[00:37:36.757] iteration 19704 : model1 loss : 0.437044 model2 loss : 0.017874
[00:37:36.928] iteration 19705 : model1 loss : 0.439064 model2 loss : 0.019186
[00:37:37.094] iteration 19706 : model1 loss : 0.439933 model2 loss : 0.019314
[00:37:37.262] iteration 19707 : model1 loss : 0.435799 model2 loss : 0.018290
[00:37:37.432] iteration 19708 : model1 loss : 0.437433 model2 loss : 0.019043
[00:37:37.602] iteration 19709 : model1 loss : 0.435982 model2 loss : 0.019157
[00:37:37.769] iteration 19710 : model1 loss : 0.437546 model2 loss : 0.018165
[00:37:37.936] iteration 19711 : model1 loss : 0.438148 model2 loss : 0.016029
[00:37:38.103] iteration 19712 : model1 loss : 0.438192 model2 loss : 0.020402
[00:37:38.273] iteration 19713 : model1 loss : 0.438637 model2 loss : 0.020412
[00:37:38.442] iteration 19714 : model1 loss : 0.438604 model2 loss : 0.018753
[00:37:38.611] iteration 19715 : model1 loss : 0.437498 model2 loss : 0.016503
[00:37:38.781] iteration 19716 : model1 loss : 0.444549 model2 loss : 0.020599
[00:37:38.950] iteration 19717 : model1 loss : 0.442794 model2 loss : 0.020734
[00:37:39.115] iteration 19718 : model1 loss : 0.435567 model2 loss : 0.018383
[00:37:39.282] iteration 19719 : model1 loss : 0.438323 model2 loss : 0.018625
[00:37:41.274] iteration 19720 : model1 loss : 0.439330 model2 loss : 0.016931
[00:37:41.440] iteration 19721 : model1 loss : 0.441127 model2 loss : 0.017731
[00:37:41.609] iteration 19722 : model1 loss : 0.437710 model2 loss : 0.020824
[00:37:41.777] iteration 19723 : model1 loss : 0.436982 model2 loss : 0.019082
[00:37:41.946] iteration 19724 : model1 loss : 0.438263 model2 loss : 0.017580
[00:37:42.116] iteration 19725 : model1 loss : 0.433420 model2 loss : 0.019267
[00:37:42.283] iteration 19726 : model1 loss : 0.439503 model2 loss : 0.019626
[00:37:42.450] iteration 19727 : model1 loss : 0.434164 model2 loss : 0.018416
[00:37:42.619] iteration 19728 : model1 loss : 0.439804 model2 loss : 0.020809
[00:37:42.789] iteration 19729 : model1 loss : 0.440798 model2 loss : 0.021104
[00:37:42.957] iteration 19730 : model1 loss : 0.439263 model2 loss : 0.019563
[00:37:43.123] iteration 19731 : model1 loss : 0.441409 model2 loss : 0.017544
[00:37:43.290] iteration 19732 : model1 loss : 0.434382 model2 loss : 0.018686
[00:37:43.457] iteration 19733 : model1 loss : 0.439760 model2 loss : 0.019904
[00:37:43.626] iteration 19734 : model1 loss : 0.438372 model2 loss : 0.019607
[00:37:43.804] iteration 19735 : model1 loss : 0.439424 model2 loss : 0.019391
[00:37:43.972] iteration 19736 : model1 loss : 0.438139 model2 loss : 0.017398
[00:37:44.138] iteration 19737 : model1 loss : 0.434363 model2 loss : 0.018706
[00:37:44.311] iteration 19738 : model1 loss : 0.439303 model2 loss : 0.017641
[00:37:44.478] iteration 19739 : model1 loss : 0.435663 model2 loss : 0.016750
[00:37:44.644] iteration 19740 : model1 loss : 0.440335 model2 loss : 0.018336
[00:37:46.689] iteration 19741 : model1 loss : 0.436349 model2 loss : 0.017590
[00:37:46.859] iteration 19742 : model1 loss : 0.435560 model2 loss : 0.017858
[00:37:47.027] iteration 19743 : model1 loss : 0.435325 model2 loss : 0.017748
[00:37:47.196] iteration 19744 : model1 loss : 0.440631 model2 loss : 0.018163
[00:37:47.366] iteration 19745 : model1 loss : 0.435906 model2 loss : 0.018679
[00:37:47.533] iteration 19746 : model1 loss : 0.435330 model2 loss : 0.018873
[00:37:47.709] iteration 19747 : model1 loss : 0.442405 model2 loss : 0.019277
[00:37:47.875] iteration 19748 : model1 loss : 0.435308 model2 loss : 0.018092
[00:37:48.045] iteration 19749 : model1 loss : 0.437154 model2 loss : 0.018026
[00:37:48.213] iteration 19750 : model1 loss : 0.437064 model2 loss : 0.017875
[00:37:48.381] iteration 19751 : model1 loss : 0.437851 model2 loss : 0.017453
[00:37:48.548] iteration 19752 : model1 loss : 0.441488 model2 loss : 0.019127
[00:37:48.716] iteration 19753 : model1 loss : 0.440852 model2 loss : 0.017863
[00:37:48.884] iteration 19754 : model1 loss : 0.437849 model2 loss : 0.019311
[00:37:49.052] iteration 19755 : model1 loss : 0.439175 model2 loss : 0.020351
[00:37:49.221] iteration 19756 : model1 loss : 0.443281 model2 loss : 0.022477
[00:37:49.391] iteration 19757 : model1 loss : 0.437951 model2 loss : 0.019953
[00:37:49.559] iteration 19758 : model1 loss : 0.436774 model2 loss : 0.016110
[00:37:49.731] iteration 19759 : model1 loss : 0.442703 model2 loss : 0.021840
[00:37:49.896] iteration 19760 : model1 loss : 0.439319 model2 loss : 0.019186
[00:37:50.064] iteration 19761 : model1 loss : 0.437733 model2 loss : 0.020081
[00:37:52.096] iteration 19762 : model1 loss : 0.436726 model2 loss : 0.017128
[00:37:52.266] iteration 19763 : model1 loss : 0.435262 model2 loss : 0.020507
[00:37:52.440] iteration 19764 : model1 loss : 0.434375 model2 loss : 0.018690
[00:37:52.605] iteration 19765 : model1 loss : 0.439621 model2 loss : 0.017076
[00:37:52.773] iteration 19766 : model1 loss : 0.442569 model2 loss : 0.021335
[00:37:52.942] iteration 19767 : model1 loss : 0.436544 model2 loss : 0.018725
[00:37:53.110] iteration 19768 : model1 loss : 0.438946 model2 loss : 0.018870
[00:37:53.278] iteration 19769 : model1 loss : 0.438777 model2 loss : 0.020546
[00:37:53.447] iteration 19770 : model1 loss : 0.438841 model2 loss : 0.020251
[00:37:53.613] iteration 19771 : model1 loss : 0.437936 model2 loss : 0.017447
[00:37:53.781] iteration 19772 : model1 loss : 0.437025 model2 loss : 0.017822
[00:37:53.949] iteration 19773 : model1 loss : 0.442557 model2 loss : 0.019540
[00:37:54.119] iteration 19774 : model1 loss : 0.440651 model2 loss : 0.019623
[00:37:54.285] iteration 19775 : model1 loss : 0.440259 model2 loss : 0.020408
[00:37:54.456] iteration 19776 : model1 loss : 0.442833 model2 loss : 0.022184
[00:37:54.621] iteration 19777 : model1 loss : 0.432022 model2 loss : 0.017049
[00:37:54.794] iteration 19778 : model1 loss : 0.435592 model2 loss : 0.018572
[00:37:54.969] iteration 19779 : model1 loss : 0.443188 model2 loss : 0.015928
[00:37:55.136] iteration 19780 : model1 loss : 0.435372 model2 loss : 0.018917
[00:37:55.302] iteration 19781 : model1 loss : 0.437097 model2 loss : 0.017556
[00:37:55.468] iteration 19782 : model1 loss : 0.438568 model2 loss : 0.018090
[00:37:57.551] iteration 19783 : model1 loss : 0.437053 model2 loss : 0.016005
[00:37:57.719] iteration 19784 : model1 loss : 0.440145 model2 loss : 0.020272
[00:37:57.889] iteration 19785 : model1 loss : 0.439531 model2 loss : 0.018209
[00:37:58.055] iteration 19786 : model1 loss : 0.433929 model2 loss : 0.018367
[00:37:58.223] iteration 19787 : model1 loss : 0.435803 model2 loss : 0.016677
[00:37:58.390] iteration 19788 : model1 loss : 0.436523 model2 loss : 0.018704
[00:37:58.558] iteration 19789 : model1 loss : 0.439126 model2 loss : 0.018741
[00:37:58.723] iteration 19790 : model1 loss : 0.443209 model2 loss : 0.018603
[00:37:58.892] iteration 19791 : model1 loss : 0.435969 model2 loss : 0.019122
[00:37:59.061] iteration 19792 : model1 loss : 0.438655 model2 loss : 0.017180
[00:37:59.231] iteration 19793 : model1 loss : 0.439318 model2 loss : 0.018077
[00:37:59.399] iteration 19794 : model1 loss : 0.438019 model2 loss : 0.020278
[00:37:59.568] iteration 19795 : model1 loss : 0.437975 model2 loss : 0.017803
[00:37:59.734] iteration 19796 : model1 loss : 0.438473 model2 loss : 0.017746
[00:37:59.901] iteration 19797 : model1 loss : 0.435258 model2 loss : 0.019598
[00:38:00.066] iteration 19798 : model1 loss : 0.440086 model2 loss : 0.019316
[00:38:00.236] iteration 19799 : model1 loss : 0.440648 model2 loss : 0.018193
[00:38:00.403] iteration 19800 : model1 loss : 0.439017 model2 loss : 0.020445
[00:38:00.573] iteration 19801 : model1 loss : 0.437482 model2 loss : 0.019254
[00:38:00.740] iteration 19802 : model1 loss : 0.437885 model2 loss : 0.018358
[00:38:00.906] iteration 19803 : model1 loss : 0.438558 model2 loss : 0.018965
[00:38:02.957] iteration 19804 : model1 loss : 0.446702 model2 loss : 0.018719
[00:38:03.123] iteration 19805 : model1 loss : 0.438187 model2 loss : 0.017469
[00:38:03.295] iteration 19806 : model1 loss : 0.431468 model2 loss : 0.019091
[00:38:03.463] iteration 19807 : model1 loss : 0.443344 model2 loss : 0.018310
[00:38:03.630] iteration 19808 : model1 loss : 0.438345 model2 loss : 0.019439
[00:38:03.798] iteration 19809 : model1 loss : 0.437709 model2 loss : 0.018828
[00:38:03.966] iteration 19810 : model1 loss : 0.438417 model2 loss : 0.017208
[00:38:04.132] iteration 19811 : model1 loss : 0.437555 model2 loss : 0.019939
[00:38:04.302] iteration 19812 : model1 loss : 0.437882 model2 loss : 0.016432
[00:38:04.466] iteration 19813 : model1 loss : 0.436988 model2 loss : 0.020870
[00:38:04.635] iteration 19814 : model1 loss : 0.437970 model2 loss : 0.019603
[00:38:04.802] iteration 19815 : model1 loss : 0.436776 model2 loss : 0.020125
[00:38:04.972] iteration 19816 : model1 loss : 0.441388 model2 loss : 0.018854
[00:38:05.141] iteration 19817 : model1 loss : 0.434484 model2 loss : 0.016869
[00:38:05.310] iteration 19818 : model1 loss : 0.439551 model2 loss : 0.018916
[00:38:05.477] iteration 19819 : model1 loss : 0.434111 model2 loss : 0.017651
[00:38:05.643] iteration 19820 : model1 loss : 0.438824 model2 loss : 0.016864
[00:38:05.811] iteration 19821 : model1 loss : 0.436288 model2 loss : 0.019801
[00:38:05.981] iteration 19822 : model1 loss : 0.437297 model2 loss : 0.018800
[00:38:06.145] iteration 19823 : model1 loss : 0.439127 model2 loss : 0.018912
[00:38:06.320] iteration 19824 : model1 loss : 0.443632 model2 loss : 0.019991
[00:38:08.376] iteration 19825 : model1 loss : 0.435541 model2 loss : 0.018717
[00:38:08.545] iteration 19826 : model1 loss : 0.436699 model2 loss : 0.018900
[00:38:08.716] iteration 19827 : model1 loss : 0.439989 model2 loss : 0.018617
[00:38:08.882] iteration 19828 : model1 loss : 0.439290 model2 loss : 0.019640
[00:38:09.057] iteration 19829 : model1 loss : 0.436201 model2 loss : 0.017741
[00:38:09.226] iteration 19830 : model1 loss : 0.439646 model2 loss : 0.019686
[00:38:09.395] iteration 19831 : model1 loss : 0.440637 model2 loss : 0.019783
[00:38:09.562] iteration 19832 : model1 loss : 0.436207 model2 loss : 0.020178
[00:38:09.733] iteration 19833 : model1 loss : 0.441687 model2 loss : 0.020365
[00:38:09.898] iteration 19834 : model1 loss : 0.438776 model2 loss : 0.017985
[00:38:10.067] iteration 19835 : model1 loss : 0.438917 model2 loss : 0.019805
[00:38:10.232] iteration 19836 : model1 loss : 0.442599 model2 loss : 0.020571
[00:38:10.400] iteration 19837 : model1 loss : 0.440092 model2 loss : 0.020643
[00:38:10.569] iteration 19838 : model1 loss : 0.434938 model2 loss : 0.019530
[00:38:10.739] iteration 19839 : model1 loss : 0.440775 model2 loss : 0.019042
[00:38:10.905] iteration 19840 : model1 loss : 0.438177 model2 loss : 0.020346
[00:38:11.074] iteration 19841 : model1 loss : 0.437280 model2 loss : 0.016959
[00:38:11.240] iteration 19842 : model1 loss : 0.441187 model2 loss : 0.018027
[00:38:11.410] iteration 19843 : model1 loss : 0.436979 model2 loss : 0.019432
[00:38:11.575] iteration 19844 : model1 loss : 0.436409 model2 loss : 0.018229
[00:38:11.744] iteration 19845 : model1 loss : 0.434695 model2 loss : 0.017663
[00:38:13.792] iteration 19846 : model1 loss : 0.441784 model2 loss : 0.018557
[00:38:13.967] iteration 19847 : model1 loss : 0.435683 model2 loss : 0.018583
[00:38:14.138] iteration 19848 : model1 loss : 0.440312 model2 loss : 0.019499
[00:38:14.307] iteration 19849 : model1 loss : 0.437650 model2 loss : 0.016924
[00:38:14.478] iteration 19850 : model1 loss : 0.436813 model2 loss : 0.017798
[00:38:14.645] iteration 19851 : model1 loss : 0.439471 model2 loss : 0.016118
[00:38:14.820] iteration 19852 : model1 loss : 0.436496 model2 loss : 0.018728
[00:38:14.986] iteration 19853 : model1 loss : 0.439588 model2 loss : 0.018693
[00:38:15.155] iteration 19854 : model1 loss : 0.441741 model2 loss : 0.019489
[00:38:15.324] iteration 19855 : model1 loss : 0.441585 model2 loss : 0.019253
[00:38:15.490] iteration 19856 : model1 loss : 0.440237 model2 loss : 0.018203
[00:38:15.657] iteration 19857 : model1 loss : 0.441187 model2 loss : 0.020766
[00:38:15.826] iteration 19858 : model1 loss : 0.436918 model2 loss : 0.019698
[00:38:15.995] iteration 19859 : model1 loss : 0.436156 model2 loss : 0.016462
[00:38:16.163] iteration 19860 : model1 loss : 0.436372 model2 loss : 0.017476
[00:38:16.331] iteration 19861 : model1 loss : 0.441879 model2 loss : 0.019555
[00:38:16.499] iteration 19862 : model1 loss : 0.436171 model2 loss : 0.017493
[00:38:16.666] iteration 19863 : model1 loss : 0.435504 model2 loss : 0.017889
[00:38:16.837] iteration 19864 : model1 loss : 0.436241 model2 loss : 0.017965
[00:38:17.003] iteration 19865 : model1 loss : 0.435097 model2 loss : 0.017709
[00:38:17.170] iteration 19866 : model1 loss : 0.436641 model2 loss : 0.019118
[00:38:19.201] iteration 19867 : model1 loss : 0.439459 model2 loss : 0.018070
[00:38:19.372] iteration 19868 : model1 loss : 0.439883 model2 loss : 0.018469
[00:38:19.542] iteration 19869 : model1 loss : 0.437545 model2 loss : 0.018071
[00:38:19.711] iteration 19870 : model1 loss : 0.434856 model2 loss : 0.016076
[00:38:19.891] iteration 19871 : model1 loss : 0.437840 model2 loss : 0.017315
[00:38:20.057] iteration 19872 : model1 loss : 0.440978 model2 loss : 0.019438
[00:38:20.228] iteration 19873 : model1 loss : 0.441140 model2 loss : 0.018796
[00:38:20.394] iteration 19874 : model1 loss : 0.436122 model2 loss : 0.018992
[00:38:20.562] iteration 19875 : model1 loss : 0.437331 model2 loss : 0.018654
[00:38:20.730] iteration 19876 : model1 loss : 0.440889 model2 loss : 0.018298
[00:38:20.897] iteration 19877 : model1 loss : 0.433083 model2 loss : 0.016835
[00:38:21.064] iteration 19878 : model1 loss : 0.439179 model2 loss : 0.019685
[00:38:21.232] iteration 19879 : model1 loss : 0.439303 model2 loss : 0.018156
[00:38:21.400] iteration 19880 : model1 loss : 0.442095 model2 loss : 0.020564
[00:38:21.568] iteration 19881 : model1 loss : 0.437650 model2 loss : 0.017560
[00:38:21.737] iteration 19882 : model1 loss : 0.441352 model2 loss : 0.020287
[00:38:21.905] iteration 19883 : model1 loss : 0.440947 model2 loss : 0.016944
[00:38:22.073] iteration 19884 : model1 loss : 0.438188 model2 loss : 0.019685
[00:38:22.242] iteration 19885 : model1 loss : 0.436713 model2 loss : 0.018482
[00:38:22.410] iteration 19886 : model1 loss : 0.435413 model2 loss : 0.019857
[00:38:22.577] iteration 19887 : model1 loss : 0.436933 model2 loss : 0.018006
[00:38:24.615] iteration 19888 : model1 loss : 0.435809 model2 loss : 0.017115
[00:38:24.784] iteration 19889 : model1 loss : 0.438054 model2 loss : 0.019694
[00:38:24.954] iteration 19890 : model1 loss : 0.436678 model2 loss : 0.018973
[00:38:25.117] iteration 19891 : model1 loss : 0.437908 model2 loss : 0.015848
[00:38:25.286] iteration 19892 : model1 loss : 0.438931 model2 loss : 0.019063
[00:38:25.452] iteration 19893 : model1 loss : 0.442893 model2 loss : 0.020823
[00:38:25.621] iteration 19894 : model1 loss : 0.439265 model2 loss : 0.018864
[00:38:25.789] iteration 19895 : model1 loss : 0.439470 model2 loss : 0.017360
[00:38:25.958] iteration 19896 : model1 loss : 0.436785 model2 loss : 0.019300
[00:38:26.126] iteration 19897 : model1 loss : 0.438979 model2 loss : 0.021569
[00:38:26.296] iteration 19898 : model1 loss : 0.442383 model2 loss : 0.020660
[00:38:26.462] iteration 19899 : model1 loss : 0.433290 model2 loss : 0.016067
[00:38:26.633] iteration 19900 : model1 loss : 0.439586 model2 loss : 0.019739
[00:38:26.800] iteration 19901 : model1 loss : 0.439990 model2 loss : 0.019382
[00:38:26.969] iteration 19902 : model1 loss : 0.441441 model2 loss : 0.020412
[00:38:27.135] iteration 19903 : model1 loss : 0.436896 model2 loss : 0.019652
[00:38:27.306] iteration 19904 : model1 loss : 0.434846 model2 loss : 0.019179
[00:38:27.475] iteration 19905 : model1 loss : 0.434775 model2 loss : 0.018650
[00:38:27.644] iteration 19906 : model1 loss : 0.440287 model2 loss : 0.017628
[00:38:27.811] iteration 19907 : model1 loss : 0.435151 model2 loss : 0.018854
[00:38:27.980] iteration 19908 : model1 loss : 0.439132 model2 loss : 0.018376
[00:38:30.027] iteration 19909 : model1 loss : 0.437428 model2 loss : 0.017805
[00:38:30.193] iteration 19910 : model1 loss : 0.441189 model2 loss : 0.020089
[00:38:30.362] iteration 19911 : model1 loss : 0.440531 model2 loss : 0.018553
[00:38:30.530] iteration 19912 : model1 loss : 0.438415 model2 loss : 0.021541
[00:38:30.700] iteration 19913 : model1 loss : 0.437220 model2 loss : 0.018917
[00:38:30.868] iteration 19914 : model1 loss : 0.431000 model2 loss : 0.015821
[00:38:31.034] iteration 19915 : model1 loss : 0.438421 model2 loss : 0.019495
[00:38:31.202] iteration 19916 : model1 loss : 0.434191 model2 loss : 0.019219
[00:38:31.372] iteration 19917 : model1 loss : 0.436239 model2 loss : 0.017764
[00:38:31.540] iteration 19918 : model1 loss : 0.435593 model2 loss : 0.020340
[00:38:31.709] iteration 19919 : model1 loss : 0.440261 model2 loss : 0.018307
[00:38:31.875] iteration 19920 : model1 loss : 0.437709 model2 loss : 0.017484
[00:38:32.044] iteration 19921 : model1 loss : 0.436533 model2 loss : 0.017014
[00:38:32.215] iteration 19922 : model1 loss : 0.441641 model2 loss : 0.019843
[00:38:32.384] iteration 19923 : model1 loss : 0.439474 model2 loss : 0.015739
[00:38:32.550] iteration 19924 : model1 loss : 0.437987 model2 loss : 0.019771
[00:38:32.719] iteration 19925 : model1 loss : 0.440036 model2 loss : 0.019280
[00:38:32.885] iteration 19926 : model1 loss : 0.441172 model2 loss : 0.020561
[00:38:33.054] iteration 19927 : model1 loss : 0.439510 model2 loss : 0.021550
[00:38:33.220] iteration 19928 : model1 loss : 0.438904 model2 loss : 0.016161
[00:38:33.387] iteration 19929 : model1 loss : 0.439910 model2 loss : 0.016917
[00:38:35.384] iteration 19930 : model1 loss : 0.441370 model2 loss : 0.021236
[00:38:35.551] iteration 19931 : model1 loss : 0.444522 model2 loss : 0.022272
[00:38:35.720] iteration 19932 : model1 loss : 0.434400 model2 loss : 0.017481
[00:38:35.886] iteration 19933 : model1 loss : 0.436996 model2 loss : 0.020142
[00:38:36.056] iteration 19934 : model1 loss : 0.437396 model2 loss : 0.018830
[00:38:36.223] iteration 19935 : model1 loss : 0.435299 model2 loss : 0.017406
[00:38:36.394] iteration 19936 : model1 loss : 0.437482 model2 loss : 0.016617
[00:38:36.561] iteration 19937 : model1 loss : 0.440886 model2 loss : 0.018456
[00:38:36.728] iteration 19938 : model1 loss : 0.437869 model2 loss : 0.019913
[00:38:36.895] iteration 19939 : model1 loss : 0.435176 model2 loss : 0.017242
[00:38:37.065] iteration 19940 : model1 loss : 0.431728 model2 loss : 0.017836
[00:38:37.230] iteration 19941 : model1 loss : 0.442459 model2 loss : 0.019760
[00:38:37.404] iteration 19942 : model1 loss : 0.440219 model2 loss : 0.021497
[00:38:37.572] iteration 19943 : model1 loss : 0.444693 model2 loss : 0.019470
[00:38:37.740] iteration 19944 : model1 loss : 0.441969 model2 loss : 0.019598
[00:38:37.906] iteration 19945 : model1 loss : 0.435535 model2 loss : 0.017565
[00:38:38.077] iteration 19946 : model1 loss : 0.438277 model2 loss : 0.019188
[00:38:38.242] iteration 19947 : model1 loss : 0.438247 model2 loss : 0.020744
[00:38:38.413] iteration 19948 : model1 loss : 0.438137 model2 loss : 0.018544
[00:38:38.580] iteration 19949 : model1 loss : 0.435170 model2 loss : 0.017971
[00:38:38.749] iteration 19950 : model1 loss : 0.441309 model2 loss : 0.018939
[00:38:40.776] iteration 19951 : model1 loss : 0.439120 model2 loss : 0.020649
[00:38:40.943] iteration 19952 : model1 loss : 0.438221 model2 loss : 0.018487
[00:38:41.111] iteration 19953 : model1 loss : 0.438629 model2 loss : 0.019879
[00:38:41.280] iteration 19954 : model1 loss : 0.433557 model2 loss : 0.017200
[00:38:41.447] iteration 19955 : model1 loss : 0.443662 model2 loss : 0.015323
[00:38:41.615] iteration 19956 : model1 loss : 0.440092 model2 loss : 0.019516
[00:38:41.787] iteration 19957 : model1 loss : 0.439299 model2 loss : 0.017021
[00:38:41.954] iteration 19958 : model1 loss : 0.434677 model2 loss : 0.018506
[00:38:42.125] iteration 19959 : model1 loss : 0.439379 model2 loss : 0.019830
[00:38:42.292] iteration 19960 : model1 loss : 0.434249 model2 loss : 0.018064
[00:38:42.465] iteration 19961 : model1 loss : 0.437919 model2 loss : 0.017602
[00:38:42.632] iteration 19962 : model1 loss : 0.438723 model2 loss : 0.017540
[00:38:42.802] iteration 19963 : model1 loss : 0.442390 model2 loss : 0.020514
[00:38:42.971] iteration 19964 : model1 loss : 0.433059 model2 loss : 0.016487
[00:38:43.137] iteration 19965 : model1 loss : 0.438571 model2 loss : 0.017951
[00:38:43.306] iteration 19966 : model1 loss : 0.436511 model2 loss : 0.018181
[00:38:43.476] iteration 19967 : model1 loss : 0.440675 model2 loss : 0.018965
[00:38:43.643] iteration 19968 : model1 loss : 0.436319 model2 loss : 0.019124
[00:38:43.812] iteration 19969 : model1 loss : 0.434267 model2 loss : 0.018548
[00:38:43.981] iteration 19970 : model1 loss : 0.442045 model2 loss : 0.020568
[00:38:44.148] iteration 19971 : model1 loss : 0.441212 model2 loss : 0.019029
[00:38:46.182] iteration 19972 : model1 loss : 0.437706 model2 loss : 0.018669
[00:38:46.354] iteration 19973 : model1 loss : 0.442269 model2 loss : 0.019583
[00:38:46.525] iteration 19974 : model1 loss : 0.433860 model2 loss : 0.018196
[00:38:46.691] iteration 19975 : model1 loss : 0.436653 model2 loss : 0.019509
[00:38:46.862] iteration 19976 : model1 loss : 0.433769 model2 loss : 0.017524
[00:38:47.027] iteration 19977 : model1 loss : 0.439038 model2 loss : 0.018792
[00:38:47.200] iteration 19978 : model1 loss : 0.444629 model2 loss : 0.019334
[00:38:47.367] iteration 19979 : model1 loss : 0.437196 model2 loss : 0.017579
[00:38:47.535] iteration 19980 : model1 loss : 0.436811 model2 loss : 0.019614
[00:38:47.703] iteration 19981 : model1 loss : 0.434435 model2 loss : 0.018808
[00:38:47.871] iteration 19982 : model1 loss : 0.440167 model2 loss : 0.018908
[00:38:48.036] iteration 19983 : model1 loss : 0.436590 model2 loss : 0.017861
[00:38:48.204] iteration 19984 : model1 loss : 0.438431 model2 loss : 0.017449
[00:38:48.370] iteration 19985 : model1 loss : 0.436779 model2 loss : 0.018886
[00:38:48.537] iteration 19986 : model1 loss : 0.444744 model2 loss : 0.024743
[00:38:48.705] iteration 19987 : model1 loss : 0.436296 model2 loss : 0.018548
[00:38:48.876] iteration 19988 : model1 loss : 0.438448 model2 loss : 0.020301
[00:38:49.043] iteration 19989 : model1 loss : 0.441964 model2 loss : 0.020770
[00:38:49.213] iteration 19990 : model1 loss : 0.439429 model2 loss : 0.020552
[00:38:49.379] iteration 19991 : model1 loss : 0.438327 model2 loss : 0.018781
[00:38:49.548] iteration 19992 : model1 loss : 0.440999 model2 loss : 0.020621
[00:38:51.568] iteration 19993 : model1 loss : 0.436062 model2 loss : 0.019524
[00:38:51.734] iteration 19994 : model1 loss : 0.439987 model2 loss : 0.018129
[00:38:51.903] iteration 19995 : model1 loss : 0.437732 model2 loss : 0.018493
[00:38:52.069] iteration 19996 : model1 loss : 0.438216 model2 loss : 0.019496
[00:38:52.238] iteration 19997 : model1 loss : 0.439271 model2 loss : 0.020649
[00:38:52.404] iteration 19998 : model1 loss : 0.437120 model2 loss : 0.016960
[00:38:52.573] iteration 19999 : model1 loss : 0.439182 model2 loss : 0.019199
[00:38:52.739] iteration 20000 : model1 loss : 0.437722 model2 loss : 0.019217
[00:39:01.307] iteration 20000 : model1_mean_dice : 0.877235 model1_mean_hd95 : 3.138922
[00:39:09.964] iteration 20000 : model2_mean_dice : 0.879645 model2_mean_hd95 : 3.559940
[00:39:10.137] iteration 20001 : model1 loss : 0.439146 model2 loss : 0.020324
[00:39:10.306] iteration 20002 : model1 loss : 0.441724 model2 loss : 0.020837
[00:39:10.473] iteration 20003 : model1 loss : 0.437941 model2 loss : 0.018300
[00:39:10.643] iteration 20004 : model1 loss : 0.440803 model2 loss : 0.019171
[00:39:10.812] iteration 20005 : model1 loss : 0.438699 model2 loss : 0.019922
[00:39:10.979] iteration 20006 : model1 loss : 0.435329 model2 loss : 0.019906
[00:39:11.146] iteration 20007 : model1 loss : 0.437465 model2 loss : 0.019659
[00:39:11.319] iteration 20008 : model1 loss : 0.436442 model2 loss : 0.019784
[00:39:11.508] iteration 20009 : model1 loss : 0.434481 model2 loss : 0.017918
[00:39:11.676] iteration 20010 : model1 loss : 0.440503 model2 loss : 0.017854
[00:39:11.845] iteration 20011 : model1 loss : 0.443189 model2 loss : 0.020384
[00:39:12.012] iteration 20012 : model1 loss : 0.436426 model2 loss : 0.017721
[00:39:12.177] iteration 20013 : model1 loss : 0.436635 model2 loss : 0.020761
[00:39:14.236] iteration 20014 : model1 loss : 0.438296 model2 loss : 0.018660
[00:39:14.403] iteration 20015 : model1 loss : 0.440694 model2 loss : 0.016568
[00:39:14.575] iteration 20016 : model1 loss : 0.446323 model2 loss : 0.020120
[00:39:14.742] iteration 20017 : model1 loss : 0.437172 model2 loss : 0.020066
[00:39:14.909] iteration 20018 : model1 loss : 0.440011 model2 loss : 0.021142
[00:39:15.076] iteration 20019 : model1 loss : 0.437021 model2 loss : 0.018178
[00:39:15.243] iteration 20020 : model1 loss : 0.433451 model2 loss : 0.017410
[00:39:15.414] iteration 20021 : model1 loss : 0.434277 model2 loss : 0.017880
[00:39:15.582] iteration 20022 : model1 loss : 0.437441 model2 loss : 0.018021
[00:39:15.751] iteration 20023 : model1 loss : 0.436374 model2 loss : 0.020200
[00:39:15.920] iteration 20024 : model1 loss : 0.437112 model2 loss : 0.020010
[00:39:16.086] iteration 20025 : model1 loss : 0.438957 model2 loss : 0.017018
[00:39:16.255] iteration 20026 : model1 loss : 0.439862 model2 loss : 0.021494
[00:39:16.420] iteration 20027 : model1 loss : 0.441506 model2 loss : 0.018569
[00:39:16.590] iteration 20028 : model1 loss : 0.434373 model2 loss : 0.021037
[00:39:16.759] iteration 20029 : model1 loss : 0.442925 model2 loss : 0.019158
[00:39:16.926] iteration 20030 : model1 loss : 0.445910 model2 loss : 0.021785
[00:39:17.091] iteration 20031 : model1 loss : 0.436295 model2 loss : 0.018370
[00:39:17.261] iteration 20032 : model1 loss : 0.439174 model2 loss : 0.020588
[00:39:17.429] iteration 20033 : model1 loss : 0.432770 model2 loss : 0.017639
[00:39:17.598] iteration 20034 : model1 loss : 0.437033 model2 loss : 0.019211
[00:39:19.634] iteration 20035 : model1 loss : 0.436592 model2 loss : 0.018640
[00:39:19.800] iteration 20036 : model1 loss : 0.440919 model2 loss : 0.021669
[00:39:19.973] iteration 20037 : model1 loss : 0.438517 model2 loss : 0.016766
[00:39:20.139] iteration 20038 : model1 loss : 0.435106 model2 loss : 0.018587
[00:39:20.307] iteration 20039 : model1 loss : 0.438748 model2 loss : 0.018557
[00:39:20.473] iteration 20040 : model1 loss : 0.440316 model2 loss : 0.019313
[00:39:20.643] iteration 20041 : model1 loss : 0.435223 model2 loss : 0.019068
[00:39:20.811] iteration 20042 : model1 loss : 0.436402 model2 loss : 0.018547
[00:39:20.979] iteration 20043 : model1 loss : 0.440376 model2 loss : 0.019494
[00:39:21.145] iteration 20044 : model1 loss : 0.438739 model2 loss : 0.019987
[00:39:21.315] iteration 20045 : model1 loss : 0.438385 model2 loss : 0.020167
[00:39:21.481] iteration 20046 : model1 loss : 0.439566 model2 loss : 0.017021
[00:39:21.652] iteration 20047 : model1 loss : 0.440893 model2 loss : 0.020000
[00:39:21.819] iteration 20048 : model1 loss : 0.434611 model2 loss : 0.017841
[00:39:21.986] iteration 20049 : model1 loss : 0.440057 model2 loss : 0.021397
[00:39:22.153] iteration 20050 : model1 loss : 0.438679 model2 loss : 0.019123
[00:39:22.325] iteration 20051 : model1 loss : 0.438623 model2 loss : 0.019202
[00:39:22.497] iteration 20052 : model1 loss : 0.437726 model2 loss : 0.018159
[00:39:22.665] iteration 20053 : model1 loss : 0.437319 model2 loss : 0.019152
[00:39:22.831] iteration 20054 : model1 loss : 0.443461 model2 loss : 0.019633
[00:39:22.998] iteration 20055 : model1 loss : 0.438789 model2 loss : 0.018383
[00:39:24.995] iteration 20056 : model1 loss : 0.440026 model2 loss : 0.020454
[00:39:25.164] iteration 20057 : model1 loss : 0.441131 model2 loss : 0.019757
[00:39:25.335] iteration 20058 : model1 loss : 0.437699 model2 loss : 0.017944
[00:39:25.502] iteration 20059 : model1 loss : 0.442873 model2 loss : 0.018814
[00:39:25.673] iteration 20060 : model1 loss : 0.439722 model2 loss : 0.019095
[00:39:25.843] iteration 20061 : model1 loss : 0.438239 model2 loss : 0.017755
[00:39:26.010] iteration 20062 : model1 loss : 0.434650 model2 loss : 0.018152
[00:39:26.177] iteration 20063 : model1 loss : 0.436462 model2 loss : 0.018546
[00:39:26.347] iteration 20064 : model1 loss : 0.439341 model2 loss : 0.018700
[00:39:26.517] iteration 20065 : model1 loss : 0.435491 model2 loss : 0.016436
[00:39:26.687] iteration 20066 : model1 loss : 0.438500 model2 loss : 0.018292
[00:39:26.857] iteration 20067 : model1 loss : 0.441415 model2 loss : 0.020161
[00:39:27.025] iteration 20068 : model1 loss : 0.436476 model2 loss : 0.018303
[00:39:27.192] iteration 20069 : model1 loss : 0.436760 model2 loss : 0.018032
[00:39:27.363] iteration 20070 : model1 loss : 0.437805 model2 loss : 0.019528
[00:39:27.530] iteration 20071 : model1 loss : 0.436272 model2 loss : 0.017087
[00:39:27.700] iteration 20072 : model1 loss : 0.441276 model2 loss : 0.019597
[00:39:27.869] iteration 20073 : model1 loss : 0.437817 model2 loss : 0.019752
[00:39:28.036] iteration 20074 : model1 loss : 0.438738 model2 loss : 0.018085
[00:39:28.202] iteration 20075 : model1 loss : 0.433287 model2 loss : 0.018784
[00:39:28.368] iteration 20076 : model1 loss : 0.435838 model2 loss : 0.016224
[00:39:30.367] iteration 20077 : model1 loss : 0.437562 model2 loss : 0.018104
[00:39:30.533] iteration 20078 : model1 loss : 0.435054 model2 loss : 0.016853
[00:39:30.705] iteration 20079 : model1 loss : 0.434018 model2 loss : 0.017029
[00:39:30.872] iteration 20080 : model1 loss : 0.438435 model2 loss : 0.019712
[00:39:31.039] iteration 20081 : model1 loss : 0.435908 model2 loss : 0.017819
[00:39:31.205] iteration 20082 : model1 loss : 0.435343 model2 loss : 0.018581
[00:39:31.375] iteration 20083 : model1 loss : 0.441295 model2 loss : 0.019335
[00:39:31.543] iteration 20084 : model1 loss : 0.441422 model2 loss : 0.018504
[00:39:31.713] iteration 20085 : model1 loss : 0.437072 model2 loss : 0.020282
[00:39:31.879] iteration 20086 : model1 loss : 0.439176 model2 loss : 0.019368
[00:39:32.047] iteration 20087 : model1 loss : 0.439017 model2 loss : 0.017208
[00:39:32.216] iteration 20088 : model1 loss : 0.437334 model2 loss : 0.020686
[00:39:32.403] iteration 20089 : model1 loss : 0.437564 model2 loss : 0.020492
[00:39:32.568] iteration 20090 : model1 loss : 0.440330 model2 loss : 0.016454
[00:39:32.739] iteration 20091 : model1 loss : 0.440624 model2 loss : 0.018712
[00:39:32.904] iteration 20092 : model1 loss : 0.439562 model2 loss : 0.019441
[00:39:33.073] iteration 20093 : model1 loss : 0.440937 model2 loss : 0.018744
[00:39:33.239] iteration 20094 : model1 loss : 0.439894 model2 loss : 0.017733
[00:39:33.410] iteration 20095 : model1 loss : 0.439073 model2 loss : 0.019401
[00:39:33.576] iteration 20096 : model1 loss : 0.438447 model2 loss : 0.019848
[00:39:33.745] iteration 20097 : model1 loss : 0.436483 model2 loss : 0.017228
[00:39:35.753] iteration 20098 : model1 loss : 0.437499 model2 loss : 0.017615
[00:39:35.919] iteration 20099 : model1 loss : 0.439231 model2 loss : 0.019049
[00:39:36.089] iteration 20100 : model1 loss : 0.438927 model2 loss : 0.018233
[00:39:36.257] iteration 20101 : model1 loss : 0.436825 model2 loss : 0.018897
[00:39:36.428] iteration 20102 : model1 loss : 0.439317 model2 loss : 0.018700
[00:39:36.596] iteration 20103 : model1 loss : 0.433560 model2 loss : 0.016398
[00:39:36.767] iteration 20104 : model1 loss : 0.439071 model2 loss : 0.021591
[00:39:36.936] iteration 20105 : model1 loss : 0.438912 model2 loss : 0.019941
[00:39:37.105] iteration 20106 : model1 loss : 0.442304 model2 loss : 0.020761
[00:39:37.273] iteration 20107 : model1 loss : 0.435725 model2 loss : 0.017898
[00:39:37.447] iteration 20108 : model1 loss : 0.438581 model2 loss : 0.018301
[00:39:37.616] iteration 20109 : model1 loss : 0.439071 model2 loss : 0.015701
[00:39:37.786] iteration 20110 : model1 loss : 0.438333 model2 loss : 0.020990
[00:39:37.951] iteration 20111 : model1 loss : 0.438714 model2 loss : 0.019490
[00:39:38.125] iteration 20112 : model1 loss : 0.439443 model2 loss : 0.018798
[00:39:38.295] iteration 20113 : model1 loss : 0.439110 model2 loss : 0.016990
[00:39:38.464] iteration 20114 : model1 loss : 0.438905 model2 loss : 0.018777
[00:39:38.632] iteration 20115 : model1 loss : 0.439101 model2 loss : 0.020637
[00:39:38.802] iteration 20116 : model1 loss : 0.437655 model2 loss : 0.018643
[00:39:38.967] iteration 20117 : model1 loss : 0.439115 model2 loss : 0.019964
[00:39:39.135] iteration 20118 : model1 loss : 0.436909 model2 loss : 0.020677
[00:39:41.166] iteration 20119 : model1 loss : 0.441445 model2 loss : 0.020531
[00:39:41.343] iteration 20120 : model1 loss : 0.438169 model2 loss : 0.021188
[00:39:41.515] iteration 20121 : model1 loss : 0.436671 model2 loss : 0.017678
[00:39:41.683] iteration 20122 : model1 loss : 0.438472 model2 loss : 0.019315
[00:39:41.855] iteration 20123 : model1 loss : 0.440191 model2 loss : 0.018451
[00:39:42.021] iteration 20124 : model1 loss : 0.437480 model2 loss : 0.018695
[00:39:42.188] iteration 20125 : model1 loss : 0.439919 model2 loss : 0.016426
[00:39:42.356] iteration 20126 : model1 loss : 0.441118 model2 loss : 0.022375
[00:39:42.523] iteration 20127 : model1 loss : 0.433389 model2 loss : 0.015847
[00:39:42.690] iteration 20128 : model1 loss : 0.435336 model2 loss : 0.019000
[00:39:42.863] iteration 20129 : model1 loss : 0.437322 model2 loss : 0.018324
[00:39:43.029] iteration 20130 : model1 loss : 0.439419 model2 loss : 0.020300
[00:39:43.198] iteration 20131 : model1 loss : 0.433869 model2 loss : 0.018040
[00:39:43.364] iteration 20132 : model1 loss : 0.445252 model2 loss : 0.023130
[00:39:43.534] iteration 20133 : model1 loss : 0.442512 model2 loss : 0.020928
[00:39:43.701] iteration 20134 : model1 loss : 0.440170 model2 loss : 0.019574
[00:39:43.873] iteration 20135 : model1 loss : 0.436210 model2 loss : 0.017519
[00:39:44.040] iteration 20136 : model1 loss : 0.438883 model2 loss : 0.018448
[00:39:44.209] iteration 20137 : model1 loss : 0.438709 model2 loss : 0.018745
[00:39:44.373] iteration 20138 : model1 loss : 0.436869 model2 loss : 0.017625
[00:39:44.541] iteration 20139 : model1 loss : 0.438149 model2 loss : 0.018679
[00:39:46.577] iteration 20140 : model1 loss : 0.434559 model2 loss : 0.017141
[00:39:46.747] iteration 20141 : model1 loss : 0.438475 model2 loss : 0.016947
[00:39:46.918] iteration 20142 : model1 loss : 0.441184 model2 loss : 0.020128
[00:39:47.085] iteration 20143 : model1 loss : 0.438506 model2 loss : 0.019808
[00:39:47.254] iteration 20144 : model1 loss : 0.437785 model2 loss : 0.019356
[00:39:47.422] iteration 20145 : model1 loss : 0.436184 model2 loss : 0.018231
[00:39:47.593] iteration 20146 : model1 loss : 0.442119 model2 loss : 0.019262
[00:39:47.760] iteration 20147 : model1 loss : 0.437154 model2 loss : 0.017807
[00:39:47.928] iteration 20148 : model1 loss : 0.438730 model2 loss : 0.020259
[00:39:48.095] iteration 20149 : model1 loss : 0.442196 model2 loss : 0.021025
[00:39:48.264] iteration 20150 : model1 loss : 0.435816 model2 loss : 0.020061
[00:39:48.430] iteration 20151 : model1 loss : 0.439957 model2 loss : 0.018883
[00:39:48.599] iteration 20152 : model1 loss : 0.438578 model2 loss : 0.020760
[00:39:48.766] iteration 20153 : model1 loss : 0.436500 model2 loss : 0.018237
[00:39:48.935] iteration 20154 : model1 loss : 0.434482 model2 loss : 0.019172
[00:39:49.102] iteration 20155 : model1 loss : 0.435519 model2 loss : 0.019414
[00:39:49.273] iteration 20156 : model1 loss : 0.439487 model2 loss : 0.018626
[00:39:49.439] iteration 20157 : model1 loss : 0.437949 model2 loss : 0.018027
[00:39:49.608] iteration 20158 : model1 loss : 0.442190 model2 loss : 0.018099
[00:39:49.775] iteration 20159 : model1 loss : 0.439130 model2 loss : 0.019504
[00:39:49.941] iteration 20160 : model1 loss : 0.444283 model2 loss : 0.019622
[00:39:51.961] iteration 20161 : model1 loss : 0.441433 model2 loss : 0.019015
[00:39:52.130] iteration 20162 : model1 loss : 0.437300 model2 loss : 0.019741
[00:39:52.300] iteration 20163 : model1 loss : 0.437514 model2 loss : 0.017700
[00:39:52.469] iteration 20164 : model1 loss : 0.436451 model2 loss : 0.020676
[00:39:52.638] iteration 20165 : model1 loss : 0.433525 model2 loss : 0.017202
[00:39:52.806] iteration 20166 : model1 loss : 0.432365 model2 loss : 0.017608
[00:39:52.975] iteration 20167 : model1 loss : 0.442223 model2 loss : 0.018085
[00:39:53.141] iteration 20168 : model1 loss : 0.440953 model2 loss : 0.018992
[00:39:53.313] iteration 20169 : model1 loss : 0.435776 model2 loss : 0.019168
[00:39:53.479] iteration 20170 : model1 loss : 0.447254 model2 loss : 0.019497
[00:39:53.649] iteration 20171 : model1 loss : 0.443517 model2 loss : 0.019477
[00:39:53.829] iteration 20172 : model1 loss : 0.443137 model2 loss : 0.020149
[00:39:53.996] iteration 20173 : model1 loss : 0.436550 model2 loss : 0.017186
[00:39:54.162] iteration 20174 : model1 loss : 0.439458 model2 loss : 0.020188
[00:39:54.332] iteration 20175 : model1 loss : 0.442294 model2 loss : 0.020583
[00:39:54.499] iteration 20176 : model1 loss : 0.437965 model2 loss : 0.017230
[00:39:54.669] iteration 20177 : model1 loss : 0.436607 model2 loss : 0.018923
[00:39:54.836] iteration 20178 : model1 loss : 0.441902 model2 loss : 0.022238
[00:39:55.006] iteration 20179 : model1 loss : 0.436637 model2 loss : 0.017080
[00:39:55.170] iteration 20180 : model1 loss : 0.439799 model2 loss : 0.018640
[00:39:55.342] iteration 20181 : model1 loss : 0.435008 model2 loss : 0.018384
[00:39:57.333] iteration 20182 : model1 loss : 0.440305 model2 loss : 0.019087
[00:39:57.507] iteration 20183 : model1 loss : 0.439915 model2 loss : 0.019951
[00:39:57.679] iteration 20184 : model1 loss : 0.438278 model2 loss : 0.018609
[00:39:57.850] iteration 20185 : model1 loss : 0.437278 model2 loss : 0.017575
[00:39:58.035] iteration 20186 : model1 loss : 0.440654 model2 loss : 0.019590
[00:39:58.203] iteration 20187 : model1 loss : 0.438738 model2 loss : 0.019055
[00:39:58.371] iteration 20188 : model1 loss : 0.439648 model2 loss : 0.017124
[00:39:58.537] iteration 20189 : model1 loss : 0.436585 model2 loss : 0.017456
[00:39:58.705] iteration 20190 : model1 loss : 0.439381 model2 loss : 0.020141
[00:39:58.873] iteration 20191 : model1 loss : 0.438198 model2 loss : 0.018012
[00:39:59.040] iteration 20192 : model1 loss : 0.439236 model2 loss : 0.017495
[00:39:59.207] iteration 20193 : model1 loss : 0.435943 model2 loss : 0.021002
[00:39:59.377] iteration 20194 : model1 loss : 0.437181 model2 loss : 0.018499
[00:39:59.544] iteration 20195 : model1 loss : 0.439651 model2 loss : 0.019735
[00:39:59.714] iteration 20196 : model1 loss : 0.442786 model2 loss : 0.018947
[00:39:59.880] iteration 20197 : model1 loss : 0.438678 model2 loss : 0.019440
[00:40:00.049] iteration 20198 : model1 loss : 0.434713 model2 loss : 0.017408
[00:40:00.217] iteration 20199 : model1 loss : 0.438125 model2 loss : 0.020027
[00:40:00.390] iteration 20200 : model1 loss : 0.437108 model2 loss : 0.018666
[00:40:00.556] iteration 20201 : model1 loss : 0.437549 model2 loss : 0.019731
[00:40:00.725] iteration 20202 : model1 loss : 0.441374 model2 loss : 0.018957
[00:40:02.733] iteration 20203 : model1 loss : 0.443136 model2 loss : 0.019932
[00:40:02.902] iteration 20204 : model1 loss : 0.441350 model2 loss : 0.017645
[00:40:03.072] iteration 20205 : model1 loss : 0.439354 model2 loss : 0.021242
[00:40:03.237] iteration 20206 : model1 loss : 0.436201 model2 loss : 0.018216
[00:40:03.405] iteration 20207 : model1 loss : 0.434389 model2 loss : 0.019694
[00:40:03.571] iteration 20208 : model1 loss : 0.437738 model2 loss : 0.019788
[00:40:03.740] iteration 20209 : model1 loss : 0.438282 model2 loss : 0.018777
[00:40:03.906] iteration 20210 : model1 loss : 0.436925 model2 loss : 0.019109
[00:40:04.074] iteration 20211 : model1 loss : 0.438726 model2 loss : 0.019164
[00:40:04.239] iteration 20212 : model1 loss : 0.440476 model2 loss : 0.020061
[00:40:04.410] iteration 20213 : model1 loss : 0.439266 model2 loss : 0.018815
[00:40:04.576] iteration 20214 : model1 loss : 0.442730 model2 loss : 0.020524
[00:40:04.746] iteration 20215 : model1 loss : 0.435842 model2 loss : 0.018761
[00:40:04.914] iteration 20216 : model1 loss : 0.435219 model2 loss : 0.016354
[00:40:05.081] iteration 20217 : model1 loss : 0.440598 model2 loss : 0.020702
[00:40:05.249] iteration 20218 : model1 loss : 0.434460 model2 loss : 0.018384
[00:40:05.419] iteration 20219 : model1 loss : 0.443158 model2 loss : 0.021846
[00:40:05.584] iteration 20220 : model1 loss : 0.434664 model2 loss : 0.018905
[00:40:05.753] iteration 20221 : model1 loss : 0.440450 model2 loss : 0.018656
[00:40:05.917] iteration 20222 : model1 loss : 0.441061 model2 loss : 0.017410
[00:40:06.085] iteration 20223 : model1 loss : 0.439634 model2 loss : 0.020078
[00:40:08.134] iteration 20224 : model1 loss : 0.432730 model2 loss : 0.016732
[00:40:08.307] iteration 20225 : model1 loss : 0.440895 model2 loss : 0.017850
[00:40:08.481] iteration 20226 : model1 loss : 0.436391 model2 loss : 0.020157
[00:40:08.648] iteration 20227 : model1 loss : 0.438802 model2 loss : 0.022807
[00:40:08.818] iteration 20228 : model1 loss : 0.438265 model2 loss : 0.018549
[00:40:08.987] iteration 20229 : model1 loss : 0.435283 model2 loss : 0.018260
[00:40:09.163] iteration 20230 : model1 loss : 0.436539 model2 loss : 0.017814
[00:40:09.334] iteration 20231 : model1 loss : 0.440940 model2 loss : 0.018781
[00:40:09.505] iteration 20232 : model1 loss : 0.441561 model2 loss : 0.019007
[00:40:09.671] iteration 20233 : model1 loss : 0.442422 model2 loss : 0.019718
[00:40:09.840] iteration 20234 : model1 loss : 0.436874 model2 loss : 0.017372
[00:40:10.009] iteration 20235 : model1 loss : 0.438646 model2 loss : 0.019690
[00:40:10.178] iteration 20236 : model1 loss : 0.434434 model2 loss : 0.019167
[00:40:10.346] iteration 20237 : model1 loss : 0.440594 model2 loss : 0.019274
[00:40:10.514] iteration 20238 : model1 loss : 0.441619 model2 loss : 0.020393
[00:40:10.682] iteration 20239 : model1 loss : 0.441339 model2 loss : 0.019262
[00:40:10.853] iteration 20240 : model1 loss : 0.435935 model2 loss : 0.017017
[00:40:11.020] iteration 20241 : model1 loss : 0.439232 model2 loss : 0.018932
[00:40:11.188] iteration 20242 : model1 loss : 0.438463 model2 loss : 0.017560
[00:40:11.352] iteration 20243 : model1 loss : 0.440201 model2 loss : 0.018413
[00:40:11.519] iteration 20244 : model1 loss : 0.437696 model2 loss : 0.017529
[00:40:13.579] iteration 20245 : model1 loss : 0.440896 model2 loss : 0.019679
[00:40:13.746] iteration 20246 : model1 loss : 0.441057 model2 loss : 0.017348
[00:40:13.915] iteration 20247 : model1 loss : 0.438253 model2 loss : 0.018487
[00:40:14.084] iteration 20248 : model1 loss : 0.442087 model2 loss : 0.019229
[00:40:14.252] iteration 20249 : model1 loss : 0.440299 model2 loss : 0.019313
[00:40:14.421] iteration 20250 : model1 loss : 0.438221 model2 loss : 0.018815
[00:40:14.592] iteration 20251 : model1 loss : 0.440001 model2 loss : 0.017874
[00:40:14.759] iteration 20252 : model1 loss : 0.435771 model2 loss : 0.017505
[00:40:14.928] iteration 20253 : model1 loss : 0.436649 model2 loss : 0.019909
[00:40:15.095] iteration 20254 : model1 loss : 0.440648 model2 loss : 0.019108
[00:40:15.266] iteration 20255 : model1 loss : 0.441751 model2 loss : 0.019182
[00:40:15.436] iteration 20256 : model1 loss : 0.437688 model2 loss : 0.016769
[00:40:15.605] iteration 20257 : model1 loss : 0.435532 model2 loss : 0.018993
[00:40:15.773] iteration 20258 : model1 loss : 0.438896 model2 loss : 0.020931
[00:40:15.942] iteration 20259 : model1 loss : 0.439566 model2 loss : 0.019413
[00:40:16.110] iteration 20260 : model1 loss : 0.440494 model2 loss : 0.022126
[00:40:16.277] iteration 20261 : model1 loss : 0.438017 model2 loss : 0.018501
[00:40:16.443] iteration 20262 : model1 loss : 0.442452 model2 loss : 0.017876
[00:40:16.617] iteration 20263 : model1 loss : 0.433295 model2 loss : 0.016951
[00:40:16.789] iteration 20264 : model1 loss : 0.434711 model2 loss : 0.017029
[00:40:16.955] iteration 20265 : model1 loss : 0.435151 model2 loss : 0.018524
[00:40:18.996] iteration 20266 : model1 loss : 0.436904 model2 loss : 0.019528
[00:40:19.167] iteration 20267 : model1 loss : 0.438844 model2 loss : 0.019546
[00:40:19.341] iteration 20268 : model1 loss : 0.434018 model2 loss : 0.016770
[00:40:19.508] iteration 20269 : model1 loss : 0.442256 model2 loss : 0.018678
[00:40:19.677] iteration 20270 : model1 loss : 0.439068 model2 loss : 0.017068
[00:40:19.846] iteration 20271 : model1 loss : 0.442855 model2 loss : 0.021341
[00:40:20.014] iteration 20272 : model1 loss : 0.437406 model2 loss : 0.018266
[00:40:20.182] iteration 20273 : model1 loss : 0.437798 model2 loss : 0.017909
[00:40:20.352] iteration 20274 : model1 loss : 0.439580 model2 loss : 0.018363
[00:40:20.519] iteration 20275 : model1 loss : 0.436660 model2 loss : 0.017031
[00:40:20.690] iteration 20276 : model1 loss : 0.437345 model2 loss : 0.016725
[00:40:20.860] iteration 20277 : model1 loss : 0.438764 model2 loss : 0.017758
[00:40:21.027] iteration 20278 : model1 loss : 0.439662 model2 loss : 0.015188
[00:40:21.194] iteration 20279 : model1 loss : 0.440826 model2 loss : 0.019970
[00:40:21.364] iteration 20280 : model1 loss : 0.436874 model2 loss : 0.019829
[00:40:21.532] iteration 20281 : model1 loss : 0.436388 model2 loss : 0.018946
[00:40:21.701] iteration 20282 : model1 loss : 0.439250 model2 loss : 0.017901
[00:40:21.872] iteration 20283 : model1 loss : 0.434749 model2 loss : 0.017519
[00:40:22.053] iteration 20284 : model1 loss : 0.437459 model2 loss : 0.018571
[00:40:22.217] iteration 20285 : model1 loss : 0.439014 model2 loss : 0.017162
[00:40:22.385] iteration 20286 : model1 loss : 0.440961 model2 loss : 0.018718
[00:40:24.402] iteration 20287 : model1 loss : 0.436700 model2 loss : 0.018388
[00:40:24.572] iteration 20288 : model1 loss : 0.436140 model2 loss : 0.017552
[00:40:24.741] iteration 20289 : model1 loss : 0.438161 model2 loss : 0.017928
[00:40:24.907] iteration 20290 : model1 loss : 0.441271 model2 loss : 0.018244
[00:40:25.076] iteration 20291 : model1 loss : 0.435049 model2 loss : 0.018007
[00:40:25.243] iteration 20292 : model1 loss : 0.440002 model2 loss : 0.017915
[00:40:25.423] iteration 20293 : model1 loss : 0.439684 model2 loss : 0.019275
[00:40:25.592] iteration 20294 : model1 loss : 0.433496 model2 loss : 0.019522
[00:40:25.761] iteration 20295 : model1 loss : 0.439924 model2 loss : 0.020741
[00:40:25.929] iteration 20296 : model1 loss : 0.438492 model2 loss : 0.018731
[00:40:26.099] iteration 20297 : model1 loss : 0.440288 model2 loss : 0.019814
[00:40:26.264] iteration 20298 : model1 loss : 0.440590 model2 loss : 0.017892
[00:40:26.433] iteration 20299 : model1 loss : 0.441219 model2 loss : 0.017645
[00:40:26.603] iteration 20300 : model1 loss : 0.438895 model2 loss : 0.018430
[00:40:26.773] iteration 20301 : model1 loss : 0.435675 model2 loss : 0.017819
[00:40:26.940] iteration 20302 : model1 loss : 0.438666 model2 loss : 0.018425
[00:40:27.110] iteration 20303 : model1 loss : 0.436976 model2 loss : 0.019814
[00:40:27.277] iteration 20304 : model1 loss : 0.439292 model2 loss : 0.019841
[00:40:27.448] iteration 20305 : model1 loss : 0.438768 model2 loss : 0.017618
[00:40:27.613] iteration 20306 : model1 loss : 0.439582 model2 loss : 0.018927
[00:40:27.780] iteration 20307 : model1 loss : 0.437131 model2 loss : 0.016630
[00:40:29.784] iteration 20308 : model1 loss : 0.438155 model2 loss : 0.019681
[00:40:29.953] iteration 20309 : model1 loss : 0.441735 model2 loss : 0.018164
[00:40:30.124] iteration 20310 : model1 loss : 0.441133 model2 loss : 0.016855
[00:40:30.294] iteration 20311 : model1 loss : 0.434591 model2 loss : 0.019740
[00:40:30.465] iteration 20312 : model1 loss : 0.441425 model2 loss : 0.020673
[00:40:30.632] iteration 20313 : model1 loss : 0.438370 model2 loss : 0.017563
[00:40:30.809] iteration 20314 : model1 loss : 0.441195 model2 loss : 0.020786
[00:40:30.975] iteration 20315 : model1 loss : 0.440503 model2 loss : 0.021022
[00:40:31.145] iteration 20316 : model1 loss : 0.439703 model2 loss : 0.018012
[00:40:31.311] iteration 20317 : model1 loss : 0.440429 model2 loss : 0.016878
[00:40:31.480] iteration 20318 : model1 loss : 0.437209 model2 loss : 0.017666
[00:40:31.648] iteration 20319 : model1 loss : 0.435531 model2 loss : 0.017291
[00:40:31.818] iteration 20320 : model1 loss : 0.441320 model2 loss : 0.021334
[00:40:31.985] iteration 20321 : model1 loss : 0.441178 model2 loss : 0.018473
[00:40:32.157] iteration 20322 : model1 loss : 0.438566 model2 loss : 0.020862
[00:40:32.325] iteration 20323 : model1 loss : 0.440867 model2 loss : 0.020223
[00:40:32.502] iteration 20324 : model1 loss : 0.435260 model2 loss : 0.018949
[00:40:32.669] iteration 20325 : model1 loss : 0.440108 model2 loss : 0.019707
[00:40:32.838] iteration 20326 : model1 loss : 0.436140 model2 loss : 0.018451
[00:40:33.004] iteration 20327 : model1 loss : 0.434987 model2 loss : 0.017270
[00:40:33.173] iteration 20328 : model1 loss : 0.435097 model2 loss : 0.016766
[00:40:35.205] iteration 20329 : model1 loss : 0.433465 model2 loss : 0.017230
[00:40:35.373] iteration 20330 : model1 loss : 0.438295 model2 loss : 0.015815
[00:40:35.543] iteration 20331 : model1 loss : 0.440145 model2 loss : 0.019210
[00:40:35.709] iteration 20332 : model1 loss : 0.438583 model2 loss : 0.019697
[00:40:35.879] iteration 20333 : model1 loss : 0.442572 model2 loss : 0.020067
[00:40:36.048] iteration 20334 : model1 loss : 0.441340 model2 loss : 0.019271
[00:40:36.216] iteration 20335 : model1 loss : 0.440606 model2 loss : 0.018163
[00:40:36.383] iteration 20336 : model1 loss : 0.434450 model2 loss : 0.018793
[00:40:36.552] iteration 20337 : model1 loss : 0.438808 model2 loss : 0.018076
[00:40:36.721] iteration 20338 : model1 loss : 0.438023 model2 loss : 0.017359
[00:40:36.892] iteration 20339 : model1 loss : 0.435892 model2 loss : 0.018650
[00:40:37.058] iteration 20340 : model1 loss : 0.440509 model2 loss : 0.020364
[00:40:37.228] iteration 20341 : model1 loss : 0.436872 model2 loss : 0.018740
[00:40:37.393] iteration 20342 : model1 loss : 0.434243 model2 loss : 0.018389
[00:40:37.562] iteration 20343 : model1 loss : 0.438560 model2 loss : 0.017514
[00:40:37.731] iteration 20344 : model1 loss : 0.442750 model2 loss : 0.023387
[00:40:37.904] iteration 20345 : model1 loss : 0.438414 model2 loss : 0.017575
[00:40:38.070] iteration 20346 : model1 loss : 0.438995 model2 loss : 0.018064
[00:40:38.238] iteration 20347 : model1 loss : 0.436368 model2 loss : 0.022282
[00:40:38.402] iteration 20348 : model1 loss : 0.439785 model2 loss : 0.018981
[00:40:38.570] iteration 20349 : model1 loss : 0.438457 model2 loss : 0.019977
[00:40:40.596] iteration 20350 : model1 loss : 0.440893 model2 loss : 0.019069
[00:40:40.772] iteration 20351 : model1 loss : 0.438191 model2 loss : 0.019155
[00:40:40.941] iteration 20352 : model1 loss : 0.437500 model2 loss : 0.020721
[00:40:41.106] iteration 20353 : model1 loss : 0.441132 model2 loss : 0.018391
[00:40:41.279] iteration 20354 : model1 loss : 0.438539 model2 loss : 0.019535
[00:40:41.445] iteration 20355 : model1 loss : 0.437083 model2 loss : 0.018728
[00:40:41.615] iteration 20356 : model1 loss : 0.437375 model2 loss : 0.019943
[00:40:41.783] iteration 20357 : model1 loss : 0.440418 model2 loss : 0.020090
[00:40:41.951] iteration 20358 : model1 loss : 0.436306 model2 loss : 0.019276
[00:40:42.121] iteration 20359 : model1 loss : 0.435451 model2 loss : 0.019117
[00:40:42.290] iteration 20360 : model1 loss : 0.439318 model2 loss : 0.018197
[00:40:42.459] iteration 20361 : model1 loss : 0.438713 model2 loss : 0.020419
[00:40:42.629] iteration 20362 : model1 loss : 0.437935 model2 loss : 0.017793
[00:40:42.797] iteration 20363 : model1 loss : 0.439330 model2 loss : 0.018273
[00:40:42.967] iteration 20364 : model1 loss : 0.442515 model2 loss : 0.019659
[00:40:43.132] iteration 20365 : model1 loss : 0.440642 model2 loss : 0.020864
[00:40:43.302] iteration 20366 : model1 loss : 0.434035 model2 loss : 0.018043
[00:40:43.468] iteration 20367 : model1 loss : 0.440159 model2 loss : 0.021768
[00:40:43.639] iteration 20368 : model1 loss : 0.440711 model2 loss : 0.021614
[00:40:43.806] iteration 20369 : model1 loss : 0.441192 model2 loss : 0.017671
[00:40:43.973] iteration 20370 : model1 loss : 0.435672 model2 loss : 0.016265
[00:40:45.985] iteration 20371 : model1 loss : 0.440779 model2 loss : 0.018953
[00:40:46.150] iteration 20372 : model1 loss : 0.435228 model2 loss : 0.017710
[00:40:46.322] iteration 20373 : model1 loss : 0.443447 model2 loss : 0.021608
[00:40:46.490] iteration 20374 : model1 loss : 0.438384 model2 loss : 0.018612
[00:40:46.660] iteration 20375 : model1 loss : 0.438272 model2 loss : 0.017894
[00:40:46.828] iteration 20376 : model1 loss : 0.433962 model2 loss : 0.016295
[00:40:46.997] iteration 20377 : model1 loss : 0.438845 model2 loss : 0.019827
[00:40:47.162] iteration 20378 : model1 loss : 0.437139 model2 loss : 0.018176
[00:40:47.334] iteration 20379 : model1 loss : 0.438862 model2 loss : 0.017376
[00:40:47.501] iteration 20380 : model1 loss : 0.438062 model2 loss : 0.019837
[00:40:47.669] iteration 20381 : model1 loss : 0.440441 model2 loss : 0.020163
[00:40:47.837] iteration 20382 : model1 loss : 0.438514 model2 loss : 0.017077
[00:40:48.008] iteration 20383 : model1 loss : 0.440409 model2 loss : 0.019397
[00:40:48.175] iteration 20384 : model1 loss : 0.439136 model2 loss : 0.018652
[00:40:48.344] iteration 20385 : model1 loss : 0.435632 model2 loss : 0.018812
[00:40:48.509] iteration 20386 : model1 loss : 0.436283 model2 loss : 0.016577
[00:40:48.677] iteration 20387 : model1 loss : 0.437691 model2 loss : 0.018779
[00:40:48.846] iteration 20388 : model1 loss : 0.441284 model2 loss : 0.018893
[00:40:49.014] iteration 20389 : model1 loss : 0.440748 model2 loss : 0.018631
[00:40:49.179] iteration 20390 : model1 loss : 0.437405 model2 loss : 0.022046
[00:40:49.348] iteration 20391 : model1 loss : 0.440559 model2 loss : 0.022772
[00:40:51.354] iteration 20392 : model1 loss : 0.432893 model2 loss : 0.017205
[00:40:51.523] iteration 20393 : model1 loss : 0.436250 model2 loss : 0.016877
[00:40:51.694] iteration 20394 : model1 loss : 0.436010 model2 loss : 0.019833
[00:40:51.860] iteration 20395 : model1 loss : 0.436526 model2 loss : 0.018229
[00:40:52.029] iteration 20396 : model1 loss : 0.435714 model2 loss : 0.017137
[00:40:52.195] iteration 20397 : model1 loss : 0.440185 model2 loss : 0.019420
[00:40:52.364] iteration 20398 : model1 loss : 0.436442 model2 loss : 0.018936
[00:40:52.532] iteration 20399 : model1 loss : 0.439711 model2 loss : 0.019107
[00:40:52.701] iteration 20400 : model1 loss : 0.440235 model2 loss : 0.017813
[00:40:52.869] iteration 20401 : model1 loss : 0.441556 model2 loss : 0.017584
[00:40:53.039] iteration 20402 : model1 loss : 0.444154 model2 loss : 0.022344
[00:40:53.206] iteration 20403 : model1 loss : 0.440692 model2 loss : 0.017566
[00:40:53.377] iteration 20404 : model1 loss : 0.436110 model2 loss : 0.016814
[00:40:53.542] iteration 20405 : model1 loss : 0.439394 model2 loss : 0.018400
[00:40:53.710] iteration 20406 : model1 loss : 0.437049 model2 loss : 0.021091
[00:40:53.878] iteration 20407 : model1 loss : 0.437289 model2 loss : 0.019474
[00:40:54.046] iteration 20408 : model1 loss : 0.439635 model2 loss : 0.019843
[00:40:54.213] iteration 20409 : model1 loss : 0.440104 model2 loss : 0.022544
[00:40:54.381] iteration 20410 : model1 loss : 0.435210 model2 loss : 0.018472
[00:40:54.546] iteration 20411 : model1 loss : 0.439461 model2 loss : 0.017155
[00:40:54.714] iteration 20412 : model1 loss : 0.442842 model2 loss : 0.020023
[00:40:56.715] iteration 20413 : model1 loss : 0.441464 model2 loss : 0.019866
[00:40:56.883] iteration 20414 : model1 loss : 0.440982 model2 loss : 0.019944
[00:40:57.050] iteration 20415 : model1 loss : 0.441375 model2 loss : 0.020546
[00:40:57.216] iteration 20416 : model1 loss : 0.438655 model2 loss : 0.021274
[00:40:57.389] iteration 20417 : model1 loss : 0.437941 model2 loss : 0.019270
[00:40:57.555] iteration 20418 : model1 loss : 0.437680 model2 loss : 0.018623
[00:40:57.726] iteration 20419 : model1 loss : 0.437186 model2 loss : 0.018949
[00:40:57.893] iteration 20420 : model1 loss : 0.436431 model2 loss : 0.018799
[00:40:58.062] iteration 20421 : model1 loss : 0.436156 model2 loss : 0.017512
[00:40:58.228] iteration 20422 : model1 loss : 0.443489 model2 loss : 0.018257
[00:40:58.399] iteration 20423 : model1 loss : 0.440553 model2 loss : 0.018713
[00:40:58.564] iteration 20424 : model1 loss : 0.437862 model2 loss : 0.019912
[00:40:58.733] iteration 20425 : model1 loss : 0.438861 model2 loss : 0.019769
[00:40:58.906] iteration 20426 : model1 loss : 0.435621 model2 loss : 0.016333
[00:40:59.074] iteration 20427 : model1 loss : 0.436936 model2 loss : 0.018149
[00:40:59.241] iteration 20428 : model1 loss : 0.439124 model2 loss : 0.019069
[00:40:59.411] iteration 20429 : model1 loss : 0.437337 model2 loss : 0.017651
[00:40:59.580] iteration 20430 : model1 loss : 0.438458 model2 loss : 0.017139
[00:40:59.749] iteration 20431 : model1 loss : 0.433076 model2 loss : 0.017065
[00:40:59.919] iteration 20432 : model1 loss : 0.438326 model2 loss : 0.019995
[00:41:00.084] iteration 20433 : model1 loss : 0.442234 model2 loss : 0.019900
[00:41:02.113] iteration 20434 : model1 loss : 0.438131 model2 loss : 0.019851
[00:41:02.281] iteration 20435 : model1 loss : 0.439674 model2 loss : 0.017417
[00:41:02.453] iteration 20436 : model1 loss : 0.439881 model2 loss : 0.016764
[00:41:02.619] iteration 20437 : model1 loss : 0.438438 model2 loss : 0.019471
[00:41:02.800] iteration 20438 : model1 loss : 0.436561 model2 loss : 0.018087
[00:41:02.967] iteration 20439 : model1 loss : 0.435300 model2 loss : 0.018638
[00:41:03.134] iteration 20440 : model1 loss : 0.436343 model2 loss : 0.017564
[00:41:03.305] iteration 20441 : model1 loss : 0.440112 model2 loss : 0.019309
[00:41:03.472] iteration 20442 : model1 loss : 0.437603 model2 loss : 0.016115
[00:41:03.639] iteration 20443 : model1 loss : 0.439448 model2 loss : 0.020248
[00:41:03.807] iteration 20444 : model1 loss : 0.437257 model2 loss : 0.017356
[00:41:03.973] iteration 20445 : model1 loss : 0.438996 model2 loss : 0.020729
[00:41:04.142] iteration 20446 : model1 loss : 0.441079 model2 loss : 0.019551
[00:41:04.310] iteration 20447 : model1 loss : 0.436801 model2 loss : 0.019453
[00:41:04.479] iteration 20448 : model1 loss : 0.437058 model2 loss : 0.019333
[00:41:04.646] iteration 20449 : model1 loss : 0.443866 model2 loss : 0.018935
[00:41:04.814] iteration 20450 : model1 loss : 0.440681 model2 loss : 0.019754
[00:41:04.981] iteration 20451 : model1 loss : 0.438100 model2 loss : 0.022370
[00:41:05.150] iteration 20452 : model1 loss : 0.442227 model2 loss : 0.019854
[00:41:05.328] iteration 20453 : model1 loss : 0.436659 model2 loss : 0.018628
[00:41:05.495] iteration 20454 : model1 loss : 0.438772 model2 loss : 0.021155
[00:41:07.509] iteration 20455 : model1 loss : 0.435028 model2 loss : 0.016613
[00:41:07.677] iteration 20456 : model1 loss : 0.435772 model2 loss : 0.017256
[00:41:07.847] iteration 20457 : model1 loss : 0.440855 model2 loss : 0.019501
[00:41:08.014] iteration 20458 : model1 loss : 0.442368 model2 loss : 0.019901
[00:41:08.180] iteration 20459 : model1 loss : 0.436287 model2 loss : 0.017467
[00:41:08.348] iteration 20460 : model1 loss : 0.439823 model2 loss : 0.017992
[00:41:08.516] iteration 20461 : model1 loss : 0.437913 model2 loss : 0.021954
[00:41:08.701] iteration 20462 : model1 loss : 0.433555 model2 loss : 0.019639
[00:41:08.869] iteration 20463 : model1 loss : 0.439383 model2 loss : 0.018698
[00:41:09.034] iteration 20464 : model1 loss : 0.438513 model2 loss : 0.016829
[00:41:09.203] iteration 20465 : model1 loss : 0.437325 model2 loss : 0.017149
[00:41:09.372] iteration 20466 : model1 loss : 0.442244 model2 loss : 0.017718
[00:41:09.541] iteration 20467 : model1 loss : 0.442590 model2 loss : 0.020475
[00:41:09.707] iteration 20468 : model1 loss : 0.440206 model2 loss : 0.019830
[00:41:09.878] iteration 20469 : model1 loss : 0.441447 model2 loss : 0.017850
[00:41:10.045] iteration 20470 : model1 loss : 0.436363 model2 loss : 0.017462
[00:41:10.214] iteration 20471 : model1 loss : 0.438173 model2 loss : 0.018037
[00:41:10.381] iteration 20472 : model1 loss : 0.433639 model2 loss : 0.019543
[00:41:10.549] iteration 20473 : model1 loss : 0.435433 model2 loss : 0.017792
[00:41:10.713] iteration 20474 : model1 loss : 0.439165 model2 loss : 0.018047
[00:41:10.889] iteration 20475 : model1 loss : 0.440589 model2 loss : 0.022186
[00:41:12.911] iteration 20476 : model1 loss : 0.439342 model2 loss : 0.020257
[00:41:13.080] iteration 20477 : model1 loss : 0.441577 model2 loss : 0.019803
[00:41:13.247] iteration 20478 : model1 loss : 0.438391 model2 loss : 0.019109
[00:41:13.415] iteration 20479 : model1 loss : 0.439665 model2 loss : 0.018193
[00:41:13.583] iteration 20480 : model1 loss : 0.439358 model2 loss : 0.016874
[00:41:13.750] iteration 20481 : model1 loss : 0.433037 model2 loss : 0.016758
[00:41:13.924] iteration 20482 : model1 loss : 0.442415 model2 loss : 0.016534
[00:41:14.091] iteration 20483 : model1 loss : 0.435849 model2 loss : 0.016942
[00:41:14.260] iteration 20484 : model1 loss : 0.438066 model2 loss : 0.020266
[00:41:14.426] iteration 20485 : model1 loss : 0.438980 model2 loss : 0.017128
[00:41:14.594] iteration 20486 : model1 loss : 0.438345 model2 loss : 0.018033
[00:41:14.763] iteration 20487 : model1 loss : 0.441939 model2 loss : 0.020900
[00:41:14.933] iteration 20488 : model1 loss : 0.436257 model2 loss : 0.017809
[00:41:15.101] iteration 20489 : model1 loss : 0.435738 model2 loss : 0.017259
[00:41:15.270] iteration 20490 : model1 loss : 0.439505 model2 loss : 0.016045
[00:41:15.436] iteration 20491 : model1 loss : 0.442027 model2 loss : 0.018814
[00:41:15.605] iteration 20492 : model1 loss : 0.436232 model2 loss : 0.018291
[00:41:15.770] iteration 20493 : model1 loss : 0.435034 model2 loss : 0.019138
[00:41:15.942] iteration 20494 : model1 loss : 0.433366 model2 loss : 0.016792
[00:41:16.108] iteration 20495 : model1 loss : 0.439478 model2 loss : 0.018058
[00:41:16.275] iteration 20496 : model1 loss : 0.440332 model2 loss : 0.017649
[00:41:18.291] iteration 20497 : model1 loss : 0.437955 model2 loss : 0.018628
[00:41:18.461] iteration 20498 : model1 loss : 0.437713 model2 loss : 0.017219
[00:41:18.631] iteration 20499 : model1 loss : 0.437564 model2 loss : 0.017195
[00:41:18.798] iteration 20500 : model1 loss : 0.436403 model2 loss : 0.018247
[00:41:18.967] iteration 20501 : model1 loss : 0.440433 model2 loss : 0.018663
[00:41:19.133] iteration 20502 : model1 loss : 0.439475 model2 loss : 0.020242
[00:41:19.302] iteration 20503 : model1 loss : 0.433439 model2 loss : 0.017989
[00:41:19.468] iteration 20504 : model1 loss : 0.437668 model2 loss : 0.018730
[00:41:19.641] iteration 20505 : model1 loss : 0.439009 model2 loss : 0.019478
[00:41:19.808] iteration 20506 : model1 loss : 0.439704 model2 loss : 0.019708
[00:41:19.979] iteration 20507 : model1 loss : 0.435095 model2 loss : 0.019251
[00:41:20.146] iteration 20508 : model1 loss : 0.443012 model2 loss : 0.020736
[00:41:20.318] iteration 20509 : model1 loss : 0.435851 model2 loss : 0.016608
[00:41:20.485] iteration 20510 : model1 loss : 0.443008 model2 loss : 0.021530
[00:41:20.655] iteration 20511 : model1 loss : 0.437965 model2 loss : 0.019791
[00:41:20.824] iteration 20512 : model1 loss : 0.442059 model2 loss : 0.020778
[00:41:20.992] iteration 20513 : model1 loss : 0.436188 model2 loss : 0.018238
[00:41:21.160] iteration 20514 : model1 loss : 0.436765 model2 loss : 0.016512
[00:41:21.331] iteration 20515 : model1 loss : 0.443554 model2 loss : 0.018738
[00:41:21.496] iteration 20516 : model1 loss : 0.436539 model2 loss : 0.016831
[00:41:21.663] iteration 20517 : model1 loss : 0.438312 model2 loss : 0.018315
[00:41:23.689] iteration 20518 : model1 loss : 0.440382 model2 loss : 0.020055
[00:41:23.867] iteration 20519 : model1 loss : 0.437873 model2 loss : 0.019802
[00:41:24.035] iteration 20520 : model1 loss : 0.442207 model2 loss : 0.019504
[00:41:24.203] iteration 20521 : model1 loss : 0.440624 model2 loss : 0.017916
[00:41:24.372] iteration 20522 : model1 loss : 0.433737 model2 loss : 0.018316
[00:41:24.538] iteration 20523 : model1 loss : 0.438472 model2 loss : 0.018126
[00:41:24.709] iteration 20524 : model1 loss : 0.442390 model2 loss : 0.019108
[00:41:24.875] iteration 20525 : model1 loss : 0.434346 model2 loss : 0.018620
[00:41:25.044] iteration 20526 : model1 loss : 0.437025 model2 loss : 0.017885
[00:41:25.211] iteration 20527 : model1 loss : 0.435854 model2 loss : 0.017881
[00:41:25.381] iteration 20528 : model1 loss : 0.438971 model2 loss : 0.016867
[00:41:25.547] iteration 20529 : model1 loss : 0.437914 model2 loss : 0.018726
[00:41:25.715] iteration 20530 : model1 loss : 0.443343 model2 loss : 0.017415
[00:41:25.885] iteration 20531 : model1 loss : 0.439700 model2 loss : 0.020518
[00:41:26.051] iteration 20532 : model1 loss : 0.436895 model2 loss : 0.016714
[00:41:26.218] iteration 20533 : model1 loss : 0.437155 model2 loss : 0.015865
[00:41:26.388] iteration 20534 : model1 loss : 0.436131 model2 loss : 0.017781
[00:41:26.554] iteration 20535 : model1 loss : 0.440911 model2 loss : 0.020043
[00:41:26.725] iteration 20536 : model1 loss : 0.438915 model2 loss : 0.018680
[00:41:26.892] iteration 20537 : model1 loss : 0.436781 model2 loss : 0.018523
[00:41:27.060] iteration 20538 : model1 loss : 0.438245 model2 loss : 0.019712
[00:41:29.100] iteration 20539 : model1 loss : 0.437717 model2 loss : 0.019854
[00:41:29.269] iteration 20540 : model1 loss : 0.437957 model2 loss : 0.019693
[00:41:29.439] iteration 20541 : model1 loss : 0.440322 model2 loss : 0.018252
[00:41:29.606] iteration 20542 : model1 loss : 0.440748 model2 loss : 0.022037
[00:41:29.776] iteration 20543 : model1 loss : 0.439575 model2 loss : 0.018290
[00:41:29.943] iteration 20544 : model1 loss : 0.435857 model2 loss : 0.016867
[00:41:30.114] iteration 20545 : model1 loss : 0.441479 model2 loss : 0.018522
[00:41:30.282] iteration 20546 : model1 loss : 0.437146 model2 loss : 0.016599
[00:41:30.452] iteration 20547 : model1 loss : 0.437089 model2 loss : 0.020402
[00:41:30.618] iteration 20548 : model1 loss : 0.440868 model2 loss : 0.017542
[00:41:30.786] iteration 20549 : model1 loss : 0.440701 model2 loss : 0.018451
[00:41:30.952] iteration 20550 : model1 loss : 0.439551 model2 loss : 0.018290
[00:41:31.122] iteration 20551 : model1 loss : 0.436320 model2 loss : 0.020249
[00:41:31.287] iteration 20552 : model1 loss : 0.438356 model2 loss : 0.017626
[00:41:31.457] iteration 20553 : model1 loss : 0.437075 model2 loss : 0.019123
[00:41:31.622] iteration 20554 : model1 loss : 0.437705 model2 loss : 0.019651
[00:41:31.791] iteration 20555 : model1 loss : 0.438693 model2 loss : 0.019088
[00:41:31.959] iteration 20556 : model1 loss : 0.433452 model2 loss : 0.018255
[00:41:32.130] iteration 20557 : model1 loss : 0.440195 model2 loss : 0.018953
[00:41:32.295] iteration 20558 : model1 loss : 0.436796 model2 loss : 0.016590
[00:41:32.466] iteration 20559 : model1 loss : 0.438884 model2 loss : 0.016279
[00:41:34.458] iteration 20560 : model1 loss : 0.439973 model2 loss : 0.020207
[00:41:34.630] iteration 20561 : model1 loss : 0.434648 model2 loss : 0.018390
[00:41:34.801] iteration 20562 : model1 loss : 0.438739 model2 loss : 0.018224
[00:41:34.968] iteration 20563 : model1 loss : 0.438757 model2 loss : 0.018022
[00:41:35.137] iteration 20564 : model1 loss : 0.440100 model2 loss : 0.017495
[00:41:35.304] iteration 20565 : model1 loss : 0.434694 model2 loss : 0.018239
[00:41:35.473] iteration 20566 : model1 loss : 0.437033 model2 loss : 0.019038
[00:41:35.640] iteration 20567 : model1 loss : 0.433678 model2 loss : 0.016809
[00:41:35.808] iteration 20568 : model1 loss : 0.437443 model2 loss : 0.018563
[00:41:35.976] iteration 20569 : model1 loss : 0.439655 model2 loss : 0.016943
[00:41:36.144] iteration 20570 : model1 loss : 0.437685 model2 loss : 0.018595
[00:41:36.314] iteration 20571 : model1 loss : 0.439774 model2 loss : 0.017705
[00:41:36.492] iteration 20572 : model1 loss : 0.443525 model2 loss : 0.018902
[00:41:36.659] iteration 20573 : model1 loss : 0.442571 model2 loss : 0.020885
[00:41:36.829] iteration 20574 : model1 loss : 0.439848 model2 loss : 0.019551
[00:41:36.996] iteration 20575 : model1 loss : 0.437603 model2 loss : 0.016489
[00:41:37.165] iteration 20576 : model1 loss : 0.437353 model2 loss : 0.017715
[00:41:37.335] iteration 20577 : model1 loss : 0.439898 model2 loss : 0.018447
[00:41:37.506] iteration 20578 : model1 loss : 0.440715 model2 loss : 0.018186
[00:41:37.671] iteration 20579 : model1 loss : 0.438418 model2 loss : 0.018387
[00:41:37.839] iteration 20580 : model1 loss : 0.439150 model2 loss : 0.020462
[00:41:39.845] iteration 20581 : model1 loss : 0.438518 model2 loss : 0.016483
[00:41:40.013] iteration 20582 : model1 loss : 0.435274 model2 loss : 0.016608
[00:41:40.180] iteration 20583 : model1 loss : 0.444087 model2 loss : 0.019444
[00:41:40.348] iteration 20584 : model1 loss : 0.440938 model2 loss : 0.020711
[00:41:40.515] iteration 20585 : model1 loss : 0.438366 model2 loss : 0.020876
[00:41:40.681] iteration 20586 : model1 loss : 0.435833 model2 loss : 0.020115
[00:41:40.853] iteration 20587 : model1 loss : 0.438540 model2 loss : 0.017436
[00:41:41.020] iteration 20588 : model1 loss : 0.435564 model2 loss : 0.020688
[00:41:41.188] iteration 20589 : model1 loss : 0.440632 model2 loss : 0.021563
[00:41:41.353] iteration 20590 : model1 loss : 0.434328 model2 loss : 0.018817
[00:41:41.520] iteration 20591 : model1 loss : 0.440536 model2 loss : 0.017990
[00:41:41.688] iteration 20592 : model1 loss : 0.437495 model2 loss : 0.018614
[00:41:41.856] iteration 20593 : model1 loss : 0.440066 model2 loss : 0.020669
[00:41:42.023] iteration 20594 : model1 loss : 0.435351 model2 loss : 0.017919
[00:41:42.192] iteration 20595 : model1 loss : 0.439607 model2 loss : 0.019322
[00:41:42.358] iteration 20596 : model1 loss : 0.436993 model2 loss : 0.018592
[00:41:42.528] iteration 20597 : model1 loss : 0.441400 model2 loss : 0.016872
[00:41:42.695] iteration 20598 : model1 loss : 0.439415 model2 loss : 0.016540
[00:41:42.864] iteration 20599 : model1 loss : 0.438553 model2 loss : 0.017168
[00:41:43.029] iteration 20600 : model1 loss : 0.440645 model2 loss : 0.019080
[00:41:43.198] iteration 20601 : model1 loss : 0.437945 model2 loss : 0.016401
[00:41:45.189] iteration 20602 : model1 loss : 0.435932 model2 loss : 0.018237
[00:41:45.361] iteration 20603 : model1 loss : 0.438905 model2 loss : 0.018771
[00:41:45.531] iteration 20604 : model1 loss : 0.444651 model2 loss : 0.020010
[00:41:45.710] iteration 20605 : model1 loss : 0.436450 model2 loss : 0.020433
[00:41:45.879] iteration 20606 : model1 loss : 0.441177 model2 loss : 0.020837
[00:41:46.045] iteration 20607 : model1 loss : 0.436988 model2 loss : 0.018702
[00:41:46.216] iteration 20608 : model1 loss : 0.438052 model2 loss : 0.017338
[00:41:46.382] iteration 20609 : model1 loss : 0.436060 model2 loss : 0.018152
[00:41:46.550] iteration 20610 : model1 loss : 0.441030 model2 loss : 0.018802
[00:41:46.716] iteration 20611 : model1 loss : 0.434607 model2 loss : 0.017589
[00:41:46.889] iteration 20612 : model1 loss : 0.441340 model2 loss : 0.021360
[00:41:47.055] iteration 20613 : model1 loss : 0.438474 model2 loss : 0.021422
[00:41:47.224] iteration 20614 : model1 loss : 0.438646 model2 loss : 0.016893
[00:41:47.391] iteration 20615 : model1 loss : 0.445005 model2 loss : 0.019381
[00:41:47.561] iteration 20616 : model1 loss : 0.437205 model2 loss : 0.019566
[00:41:47.729] iteration 20617 : model1 loss : 0.441099 model2 loss : 0.020358
[00:41:47.899] iteration 20618 : model1 loss : 0.435957 model2 loss : 0.017046
[00:41:48.064] iteration 20619 : model1 loss : 0.435433 model2 loss : 0.018405
[00:41:48.241] iteration 20620 : model1 loss : 0.435980 model2 loss : 0.018101
[00:41:48.406] iteration 20621 : model1 loss : 0.437904 model2 loss : 0.019456
[00:41:48.575] iteration 20622 : model1 loss : 0.440501 model2 loss : 0.019591
[00:41:50.595] iteration 20623 : model1 loss : 0.436832 model2 loss : 0.017737
[00:41:50.765] iteration 20624 : model1 loss : 0.433755 model2 loss : 0.017432
[00:41:50.938] iteration 20625 : model1 loss : 0.438591 model2 loss : 0.019298
[00:41:51.105] iteration 20626 : model1 loss : 0.441791 model2 loss : 0.015656
[00:41:51.280] iteration 20627 : model1 loss : 0.441019 model2 loss : 0.018336
[00:41:51.452] iteration 20628 : model1 loss : 0.440212 model2 loss : 0.017559
[00:41:51.620] iteration 20629 : model1 loss : 0.436585 model2 loss : 0.018868
[00:41:51.787] iteration 20630 : model1 loss : 0.441414 model2 loss : 0.018830
[00:41:51.959] iteration 20631 : model1 loss : 0.436923 model2 loss : 0.016943
[00:41:52.124] iteration 20632 : model1 loss : 0.436452 model2 loss : 0.019565
[00:41:52.294] iteration 20633 : model1 loss : 0.440717 model2 loss : 0.020744
[00:41:52.464] iteration 20634 : model1 loss : 0.434961 model2 loss : 0.020490
[00:41:52.632] iteration 20635 : model1 loss : 0.438408 model2 loss : 0.019961
[00:41:52.800] iteration 20636 : model1 loss : 0.439169 model2 loss : 0.018166
[00:41:52.968] iteration 20637 : model1 loss : 0.436889 model2 loss : 0.017675
[00:41:53.135] iteration 20638 : model1 loss : 0.444688 model2 loss : 0.021459
[00:41:53.305] iteration 20639 : model1 loss : 0.438652 model2 loss : 0.018087
[00:41:53.473] iteration 20640 : model1 loss : 0.441092 model2 loss : 0.018371
[00:41:53.642] iteration 20641 : model1 loss : 0.437727 model2 loss : 0.018359
[00:41:53.808] iteration 20642 : model1 loss : 0.436769 model2 loss : 0.017278
[00:41:53.975] iteration 20643 : model1 loss : 0.440205 model2 loss : 0.018250
[00:41:56.002] iteration 20644 : model1 loss : 0.439656 model2 loss : 0.019568
[00:41:56.169] iteration 20645 : model1 loss : 0.432720 model2 loss : 0.017700
[00:41:56.341] iteration 20646 : model1 loss : 0.443387 model2 loss : 0.021368
[00:41:56.508] iteration 20647 : model1 loss : 0.436015 model2 loss : 0.019149
[00:41:56.676] iteration 20648 : model1 loss : 0.437268 model2 loss : 0.019459
[00:41:56.845] iteration 20649 : model1 loss : 0.440334 model2 loss : 0.018568
[00:41:57.013] iteration 20650 : model1 loss : 0.435978 model2 loss : 0.016818
[00:41:57.179] iteration 20651 : model1 loss : 0.438823 model2 loss : 0.018660
[00:41:57.349] iteration 20652 : model1 loss : 0.438424 model2 loss : 0.016816
[00:41:57.516] iteration 20653 : model1 loss : 0.437073 model2 loss : 0.016301
[00:41:57.684] iteration 20654 : model1 loss : 0.444790 model2 loss : 0.020032
[00:41:57.853] iteration 20655 : model1 loss : 0.438191 model2 loss : 0.019974
[00:41:58.021] iteration 20656 : model1 loss : 0.436104 model2 loss : 0.019471
[00:41:58.188] iteration 20657 : model1 loss : 0.438656 model2 loss : 0.021575
[00:41:58.356] iteration 20658 : model1 loss : 0.441476 model2 loss : 0.019688
[00:41:58.524] iteration 20659 : model1 loss : 0.439128 model2 loss : 0.019209
[00:41:58.694] iteration 20660 : model1 loss : 0.437557 model2 loss : 0.018325
[00:41:58.861] iteration 20661 : model1 loss : 0.439676 model2 loss : 0.018199
[00:41:59.032] iteration 20662 : model1 loss : 0.438167 model2 loss : 0.019938
[00:41:59.197] iteration 20663 : model1 loss : 0.440825 model2 loss : 0.019324
[00:41:59.365] iteration 20664 : model1 loss : 0.437505 model2 loss : 0.019081
[00:42:01.373] iteration 20665 : model1 loss : 0.441056 model2 loss : 0.021702
[00:42:01.539] iteration 20666 : model1 loss : 0.440334 model2 loss : 0.018903
[00:42:01.706] iteration 20667 : model1 loss : 0.438403 model2 loss : 0.017575
[00:42:01.874] iteration 20668 : model1 loss : 0.442518 model2 loss : 0.018256
[00:42:02.045] iteration 20669 : model1 loss : 0.440605 model2 loss : 0.021075
[00:42:02.213] iteration 20670 : model1 loss : 0.439322 model2 loss : 0.017454
[00:42:02.381] iteration 20671 : model1 loss : 0.438287 model2 loss : 0.019709
[00:42:02.549] iteration 20672 : model1 loss : 0.436360 model2 loss : 0.016295
[00:42:02.717] iteration 20673 : model1 loss : 0.436488 model2 loss : 0.019586
[00:42:02.885] iteration 20674 : model1 loss : 0.436379 model2 loss : 0.016670
[00:42:03.053] iteration 20675 : model1 loss : 0.432577 model2 loss : 0.019560
[00:42:03.219] iteration 20676 : model1 loss : 0.441682 model2 loss : 0.018609
[00:42:03.389] iteration 20677 : model1 loss : 0.439554 model2 loss : 0.018033
[00:42:03.556] iteration 20678 : model1 loss : 0.439135 model2 loss : 0.019281
[00:42:03.726] iteration 20679 : model1 loss : 0.436411 model2 loss : 0.020074
[00:42:03.892] iteration 20680 : model1 loss : 0.442818 model2 loss : 0.019828
[00:42:04.061] iteration 20681 : model1 loss : 0.443267 model2 loss : 0.021987
[00:42:04.229] iteration 20682 : model1 loss : 0.435854 model2 loss : 0.018176
[00:42:04.397] iteration 20683 : model1 loss : 0.436163 model2 loss : 0.019043
[00:42:04.565] iteration 20684 : model1 loss : 0.438383 model2 loss : 0.017030
[00:42:04.730] iteration 20685 : model1 loss : 0.431576 model2 loss : 0.016920
[00:42:06.718] iteration 20686 : model1 loss : 0.439923 model2 loss : 0.020258
[00:42:06.886] iteration 20687 : model1 loss : 0.440483 model2 loss : 0.020175
[00:42:07.056] iteration 20688 : model1 loss : 0.434635 model2 loss : 0.017651
[00:42:07.223] iteration 20689 : model1 loss : 0.436686 model2 loss : 0.018762
[00:42:07.392] iteration 20690 : model1 loss : 0.440022 model2 loss : 0.019921
[00:42:07.560] iteration 20691 : model1 loss : 0.437432 model2 loss : 0.017801
[00:42:07.728] iteration 20692 : model1 loss : 0.441048 model2 loss : 0.017749
[00:42:07.896] iteration 20693 : model1 loss : 0.440206 model2 loss : 0.020071
[00:42:08.064] iteration 20694 : model1 loss : 0.437158 model2 loss : 0.017570
[00:42:08.232] iteration 20695 : model1 loss : 0.434403 model2 loss : 0.017144
[00:42:08.402] iteration 20696 : model1 loss : 0.441411 model2 loss : 0.017897
[00:42:08.568] iteration 20697 : model1 loss : 0.440334 model2 loss : 0.018255
[00:42:08.737] iteration 20698 : model1 loss : 0.441457 model2 loss : 0.021504
[00:42:08.905] iteration 20699 : model1 loss : 0.436884 model2 loss : 0.018947
[00:42:09.071] iteration 20700 : model1 loss : 0.439600 model2 loss : 0.019515
[00:42:09.240] iteration 20701 : model1 loss : 0.433689 model2 loss : 0.016911
[00:42:09.409] iteration 20702 : model1 loss : 0.435273 model2 loss : 0.016616
[00:42:09.577] iteration 20703 : model1 loss : 0.439234 model2 loss : 0.017521
[00:42:09.744] iteration 20704 : model1 loss : 0.436525 model2 loss : 0.018172
[00:42:09.912] iteration 20705 : model1 loss : 0.438077 model2 loss : 0.019656
[00:42:10.082] iteration 20706 : model1 loss : 0.440225 model2 loss : 0.019684
[00:42:12.103] iteration 20707 : model1 loss : 0.441496 model2 loss : 0.016075
[00:42:12.279] iteration 20708 : model1 loss : 0.435930 model2 loss : 0.019959
[00:42:12.451] iteration 20709 : model1 loss : 0.438278 model2 loss : 0.020383
[00:42:12.618] iteration 20710 : model1 loss : 0.436759 model2 loss : 0.018114
[00:42:12.789] iteration 20711 : model1 loss : 0.437816 model2 loss : 0.017861
[00:42:12.960] iteration 20712 : model1 loss : 0.445454 model2 loss : 0.023086
[00:42:13.127] iteration 20713 : model1 loss : 0.438336 model2 loss : 0.018484
[00:42:13.296] iteration 20714 : model1 loss : 0.440193 model2 loss : 0.018629
[00:42:13.464] iteration 20715 : model1 loss : 0.439612 model2 loss : 0.017737
[00:42:13.631] iteration 20716 : model1 loss : 0.440545 model2 loss : 0.018070
[00:42:13.801] iteration 20717 : model1 loss : 0.440839 model2 loss : 0.017989
[00:42:13.969] iteration 20718 : model1 loss : 0.437374 model2 loss : 0.017898
[00:42:14.137] iteration 20719 : model1 loss : 0.434178 model2 loss : 0.018373
[00:42:14.306] iteration 20720 : model1 loss : 0.438192 model2 loss : 0.020842
[00:42:14.474] iteration 20721 : model1 loss : 0.437139 model2 loss : 0.016487
[00:42:14.642] iteration 20722 : model1 loss : 0.432347 model2 loss : 0.019149
[00:42:14.813] iteration 20723 : model1 loss : 0.439807 model2 loss : 0.018095
[00:42:14.980] iteration 20724 : model1 loss : 0.439966 model2 loss : 0.018966
[00:42:15.150] iteration 20725 : model1 loss : 0.440254 model2 loss : 0.017770
[00:42:15.318] iteration 20726 : model1 loss : 0.440507 model2 loss : 0.019229
[00:42:15.487] iteration 20727 : model1 loss : 0.436320 model2 loss : 0.018585
[00:42:17.580] iteration 20728 : model1 loss : 0.440218 model2 loss : 0.016863
[00:42:17.747] iteration 20729 : model1 loss : 0.439874 model2 loss : 0.017168
[00:42:17.917] iteration 20730 : model1 loss : 0.437019 model2 loss : 0.019801
[00:42:18.084] iteration 20731 : model1 loss : 0.436426 model2 loss : 0.017779
[00:42:18.254] iteration 20732 : model1 loss : 0.439063 model2 loss : 0.020455
[00:42:18.421] iteration 20733 : model1 loss : 0.440085 model2 loss : 0.019404
[00:42:18.593] iteration 20734 : model1 loss : 0.437587 model2 loss : 0.016290
[00:42:18.759] iteration 20735 : model1 loss : 0.436174 model2 loss : 0.017896
[00:42:18.928] iteration 20736 : model1 loss : 0.445091 model2 loss : 0.021179
[00:42:19.094] iteration 20737 : model1 loss : 0.439057 model2 loss : 0.015162
[00:42:19.265] iteration 20738 : model1 loss : 0.436228 model2 loss : 0.018841
[00:42:19.432] iteration 20739 : model1 loss : 0.437194 model2 loss : 0.018071
[00:42:19.599] iteration 20740 : model1 loss : 0.438330 model2 loss : 0.019523
[00:42:19.768] iteration 20741 : model1 loss : 0.440140 model2 loss : 0.018375
[00:42:19.939] iteration 20742 : model1 loss : 0.442126 model2 loss : 0.020568
[00:42:20.105] iteration 20743 : model1 loss : 0.437563 model2 loss : 0.019544
[00:42:20.274] iteration 20744 : model1 loss : 0.440011 model2 loss : 0.018477
[00:42:20.442] iteration 20745 : model1 loss : 0.438087 model2 loss : 0.018459
[00:42:20.612] iteration 20746 : model1 loss : 0.438043 model2 loss : 0.020995
[00:42:20.776] iteration 20747 : model1 loss : 0.435132 model2 loss : 0.016281
[00:42:20.946] iteration 20748 : model1 loss : 0.434133 model2 loss : 0.017734
[00:42:22.979] iteration 20749 : model1 loss : 0.436967 model2 loss : 0.017303
[00:42:23.152] iteration 20750 : model1 loss : 0.440960 model2 loss : 0.017334
[00:42:23.325] iteration 20751 : model1 loss : 0.437419 model2 loss : 0.017756
[00:42:23.495] iteration 20752 : model1 loss : 0.434605 model2 loss : 0.017957
[00:42:23.665] iteration 20753 : model1 loss : 0.437964 model2 loss : 0.018672
[00:42:23.835] iteration 20754 : model1 loss : 0.439693 model2 loss : 0.017923
[00:42:24.003] iteration 20755 : model1 loss : 0.439012 model2 loss : 0.018422
[00:42:24.170] iteration 20756 : model1 loss : 0.440129 model2 loss : 0.018315
[00:42:24.340] iteration 20757 : model1 loss : 0.442241 model2 loss : 0.019789
[00:42:24.507] iteration 20758 : model1 loss : 0.440107 model2 loss : 0.017240
[00:42:24.676] iteration 20759 : model1 loss : 0.437966 model2 loss : 0.020791
[00:42:24.843] iteration 20760 : model1 loss : 0.440175 model2 loss : 0.018881
[00:42:25.021] iteration 20761 : model1 loss : 0.440002 model2 loss : 0.019109
[00:42:25.188] iteration 20762 : model1 loss : 0.438349 model2 loss : 0.018345
[00:42:25.356] iteration 20763 : model1 loss : 0.436759 model2 loss : 0.018188
[00:42:25.523] iteration 20764 : model1 loss : 0.442169 model2 loss : 0.019712
[00:42:25.692] iteration 20765 : model1 loss : 0.434836 model2 loss : 0.018392
[00:42:25.861] iteration 20766 : model1 loss : 0.438270 model2 loss : 0.018680
[00:42:26.029] iteration 20767 : model1 loss : 0.440840 model2 loss : 0.017753
[00:42:26.195] iteration 20768 : model1 loss : 0.435515 model2 loss : 0.017856
[00:42:26.363] iteration 20769 : model1 loss : 0.440384 model2 loss : 0.018531
[00:42:28.405] iteration 20770 : model1 loss : 0.437426 model2 loss : 0.019530
[00:42:28.574] iteration 20771 : model1 loss : 0.439166 model2 loss : 0.019291
[00:42:28.743] iteration 20772 : model1 loss : 0.437825 model2 loss : 0.016353
[00:42:28.914] iteration 20773 : model1 loss : 0.435505 model2 loss : 0.018302
[00:42:29.083] iteration 20774 : model1 loss : 0.437098 model2 loss : 0.017920
[00:42:29.250] iteration 20775 : model1 loss : 0.440850 model2 loss : 0.018485
[00:42:29.427] iteration 20776 : model1 loss : 0.435289 model2 loss : 0.015891
[00:42:29.597] iteration 20777 : model1 loss : 0.437212 model2 loss : 0.018732
[00:42:29.768] iteration 20778 : model1 loss : 0.438895 model2 loss : 0.019175
[00:42:29.936] iteration 20779 : model1 loss : 0.441688 model2 loss : 0.019483
[00:42:30.115] iteration 20780 : model1 loss : 0.437256 model2 loss : 0.018817
[00:42:30.283] iteration 20781 : model1 loss : 0.438858 model2 loss : 0.017281
[00:42:30.454] iteration 20782 : model1 loss : 0.440880 model2 loss : 0.018540
[00:42:30.624] iteration 20783 : model1 loss : 0.440328 model2 loss : 0.019056
[00:42:30.795] iteration 20784 : model1 loss : 0.441275 model2 loss : 0.018733
[00:42:30.966] iteration 20785 : model1 loss : 0.435645 model2 loss : 0.019714
[00:42:31.133] iteration 20786 : model1 loss : 0.437034 model2 loss : 0.016731
[00:42:31.301] iteration 20787 : model1 loss : 0.438700 model2 loss : 0.017598
[00:42:31.470] iteration 20788 : model1 loss : 0.435752 model2 loss : 0.016378
[00:42:31.635] iteration 20789 : model1 loss : 0.440358 model2 loss : 0.018353
[00:42:31.801] iteration 20790 : model1 loss : 0.442036 model2 loss : 0.020321
[00:42:33.813] iteration 20791 : model1 loss : 0.435728 model2 loss : 0.018770
[00:42:33.984] iteration 20792 : model1 loss : 0.438099 model2 loss : 0.017814
[00:42:34.156] iteration 20793 : model1 loss : 0.440557 model2 loss : 0.017320
[00:42:34.325] iteration 20794 : model1 loss : 0.436720 model2 loss : 0.015780
[00:42:34.493] iteration 20795 : model1 loss : 0.439580 model2 loss : 0.019012
[00:42:34.661] iteration 20796 : model1 loss : 0.438130 model2 loss : 0.020871
[00:42:34.832] iteration 20797 : model1 loss : 0.434613 model2 loss : 0.018144
[00:42:34.999] iteration 20798 : model1 loss : 0.437071 model2 loss : 0.017084
[00:42:35.168] iteration 20799 : model1 loss : 0.442028 model2 loss : 0.018101
[00:42:35.334] iteration 20800 : model1 loss : 0.440247 model2 loss : 0.019014
[00:42:35.504] iteration 20801 : model1 loss : 0.442597 model2 loss : 0.018022
[00:42:35.672] iteration 20802 : model1 loss : 0.437967 model2 loss : 0.018333
[00:42:35.842] iteration 20803 : model1 loss : 0.439438 model2 loss : 0.017672
[00:42:36.009] iteration 20804 : model1 loss : 0.437887 model2 loss : 0.018884
[00:42:36.179] iteration 20805 : model1 loss : 0.438327 model2 loss : 0.020555
[00:42:36.347] iteration 20806 : model1 loss : 0.439162 model2 loss : 0.018305
[00:42:36.516] iteration 20807 : model1 loss : 0.437480 model2 loss : 0.016767
[00:42:36.685] iteration 20808 : model1 loss : 0.441657 model2 loss : 0.020278
[00:42:36.856] iteration 20809 : model1 loss : 0.434736 model2 loss : 0.017952
[00:42:37.021] iteration 20810 : model1 loss : 0.438858 model2 loss : 0.019586
[00:42:37.189] iteration 20811 : model1 loss : 0.440694 model2 loss : 0.017998
[00:42:39.197] iteration 20812 : model1 loss : 0.437370 model2 loss : 0.018173
[00:42:39.366] iteration 20813 : model1 loss : 0.435910 model2 loss : 0.016049
[00:42:39.538] iteration 20814 : model1 loss : 0.438562 model2 loss : 0.019176
[00:42:39.705] iteration 20815 : model1 loss : 0.434869 model2 loss : 0.017595
[00:42:39.872] iteration 20816 : model1 loss : 0.440913 model2 loss : 0.019573
[00:42:40.039] iteration 20817 : model1 loss : 0.437725 model2 loss : 0.018838
[00:42:40.206] iteration 20818 : model1 loss : 0.438577 model2 loss : 0.018588
[00:42:40.373] iteration 20819 : model1 loss : 0.438709 model2 loss : 0.017125
[00:42:40.540] iteration 20820 : model1 loss : 0.440453 model2 loss : 0.018303
[00:42:40.707] iteration 20821 : model1 loss : 0.442436 model2 loss : 0.018844
[00:42:40.881] iteration 20822 : model1 loss : 0.437128 model2 loss : 0.019449
[00:42:41.049] iteration 20823 : model1 loss : 0.439155 model2 loss : 0.019795
[00:42:41.217] iteration 20824 : model1 loss : 0.438792 model2 loss : 0.018081
[00:42:41.385] iteration 20825 : model1 loss : 0.440716 model2 loss : 0.016886
[00:42:41.554] iteration 20826 : model1 loss : 0.437353 model2 loss : 0.018570
[00:42:41.721] iteration 20827 : model1 loss : 0.435680 model2 loss : 0.018581
[00:42:41.890] iteration 20828 : model1 loss : 0.437813 model2 loss : 0.016776
[00:42:42.060] iteration 20829 : model1 loss : 0.438222 model2 loss : 0.017889
[00:42:42.228] iteration 20830 : model1 loss : 0.439799 model2 loss : 0.020352
[00:42:42.393] iteration 20831 : model1 loss : 0.439775 model2 loss : 0.018948
[00:42:42.560] iteration 20832 : model1 loss : 0.442108 model2 loss : 0.021066
[00:42:44.557] iteration 20833 : model1 loss : 0.440205 model2 loss : 0.017406
[00:42:44.727] iteration 20834 : model1 loss : 0.435512 model2 loss : 0.018436
[00:42:44.897] iteration 20835 : model1 loss : 0.442631 model2 loss : 0.018241
[00:42:45.064] iteration 20836 : model1 loss : 0.439895 model2 loss : 0.016906
[00:42:45.235] iteration 20837 : model1 loss : 0.440478 model2 loss : 0.018175
[00:42:45.400] iteration 20838 : model1 loss : 0.441803 model2 loss : 0.018751
[00:42:45.568] iteration 20839 : model1 loss : 0.439282 model2 loss : 0.016614
[00:42:45.747] iteration 20840 : model1 loss : 0.440542 model2 loss : 0.019885
[00:42:45.917] iteration 20841 : model1 loss : 0.438381 model2 loss : 0.020420
[00:42:46.082] iteration 20842 : model1 loss : 0.437255 model2 loss : 0.017577
[00:42:46.252] iteration 20843 : model1 loss : 0.432659 model2 loss : 0.018542
[00:42:46.419] iteration 20844 : model1 loss : 0.438736 model2 loss : 0.019111
[00:42:46.589] iteration 20845 : model1 loss : 0.443227 model2 loss : 0.020664
[00:42:46.758] iteration 20846 : model1 loss : 0.436476 model2 loss : 0.021561
[00:42:46.927] iteration 20847 : model1 loss : 0.436771 model2 loss : 0.018911
[00:42:47.094] iteration 20848 : model1 loss : 0.439971 model2 loss : 0.018217
[00:42:47.263] iteration 20849 : model1 loss : 0.437814 model2 loss : 0.020366
[00:42:47.431] iteration 20850 : model1 loss : 0.439521 model2 loss : 0.019047
[00:42:47.601] iteration 20851 : model1 loss : 0.436709 model2 loss : 0.019380
[00:42:47.770] iteration 20852 : model1 loss : 0.439493 model2 loss : 0.021901
[00:42:47.937] iteration 20853 : model1 loss : 0.441211 model2 loss : 0.020362
[00:42:49.951] iteration 20854 : model1 loss : 0.434513 model2 loss : 0.015816
[00:42:50.123] iteration 20855 : model1 loss : 0.440309 model2 loss : 0.018349
[00:42:50.294] iteration 20856 : model1 loss : 0.436028 model2 loss : 0.020421
[00:42:50.460] iteration 20857 : model1 loss : 0.438302 model2 loss : 0.018362
[00:42:50.629] iteration 20858 : model1 loss : 0.440329 model2 loss : 0.018447
[00:42:50.796] iteration 20859 : model1 loss : 0.440336 model2 loss : 0.020805
[00:42:50.965] iteration 20860 : model1 loss : 0.436674 model2 loss : 0.018177
[00:42:51.133] iteration 20861 : model1 loss : 0.442217 model2 loss : 0.022077
[00:42:51.302] iteration 20862 : model1 loss : 0.438218 model2 loss : 0.018963
[00:42:51.469] iteration 20863 : model1 loss : 0.447227 model2 loss : 0.018389
[00:42:51.637] iteration 20864 : model1 loss : 0.441781 model2 loss : 0.019299
[00:42:51.803] iteration 20865 : model1 loss : 0.438390 model2 loss : 0.019229
[00:42:51.973] iteration 20866 : model1 loss : 0.439164 model2 loss : 0.019621
[00:42:52.139] iteration 20867 : model1 loss : 0.437581 model2 loss : 0.019228
[00:42:52.308] iteration 20868 : model1 loss : 0.439390 model2 loss : 0.019730
[00:42:52.478] iteration 20869 : model1 loss : 0.436829 model2 loss : 0.018766
[00:42:52.647] iteration 20870 : model1 loss : 0.439414 model2 loss : 0.016154
[00:42:52.815] iteration 20871 : model1 loss : 0.436595 model2 loss : 0.019789
[00:42:52.988] iteration 20872 : model1 loss : 0.436532 model2 loss : 0.020234
[00:42:53.153] iteration 20873 : model1 loss : 0.438440 model2 loss : 0.019401
[00:42:53.325] iteration 20874 : model1 loss : 0.438454 model2 loss : 0.018793
[00:42:55.307] iteration 20875 : model1 loss : 0.436127 model2 loss : 0.018698
[00:42:55.474] iteration 20876 : model1 loss : 0.439723 model2 loss : 0.017480
[00:42:55.642] iteration 20877 : model1 loss : 0.442794 model2 loss : 0.019245
[00:42:55.809] iteration 20878 : model1 loss : 0.438515 model2 loss : 0.019959
[00:42:55.980] iteration 20879 : model1 loss : 0.442561 model2 loss : 0.018968
[00:42:56.147] iteration 20880 : model1 loss : 0.433885 model2 loss : 0.018070
[00:42:56.316] iteration 20881 : model1 loss : 0.437311 model2 loss : 0.018529
[00:42:56.485] iteration 20882 : model1 loss : 0.432857 model2 loss : 0.019043
[00:42:56.653] iteration 20883 : model1 loss : 0.441422 model2 loss : 0.019639
[00:42:56.819] iteration 20884 : model1 loss : 0.440871 model2 loss : 0.019294
[00:42:56.992] iteration 20885 : model1 loss : 0.438349 model2 loss : 0.020598
[00:42:57.158] iteration 20886 : model1 loss : 0.440793 model2 loss : 0.017530
[00:42:57.328] iteration 20887 : model1 loss : 0.437412 model2 loss : 0.018639
[00:42:57.499] iteration 20888 : model1 loss : 0.442994 model2 loss : 0.020430
[00:42:57.670] iteration 20889 : model1 loss : 0.438344 model2 loss : 0.017234
[00:42:57.836] iteration 20890 : model1 loss : 0.435095 model2 loss : 0.018281
[00:42:58.010] iteration 20891 : model1 loss : 0.442196 model2 loss : 0.019604
[00:42:58.178] iteration 20892 : model1 loss : 0.437282 model2 loss : 0.017381
[00:42:58.348] iteration 20893 : model1 loss : 0.440105 model2 loss : 0.017992
[00:42:58.515] iteration 20894 : model1 loss : 0.434444 model2 loss : 0.016964
[00:42:58.683] iteration 20895 : model1 loss : 0.439312 model2 loss : 0.016361
[00:43:00.694] iteration 20896 : model1 loss : 0.438516 model2 loss : 0.020548
[00:43:00.864] iteration 20897 : model1 loss : 0.438347 model2 loss : 0.019809
[00:43:01.032] iteration 20898 : model1 loss : 0.431185 model2 loss : 0.018264
[00:43:01.199] iteration 20899 : model1 loss : 0.438956 model2 loss : 0.019015
[00:43:01.367] iteration 20900 : model1 loss : 0.439242 model2 loss : 0.020857
[00:43:01.534] iteration 20901 : model1 loss : 0.439888 model2 loss : 0.017257
[00:43:01.704] iteration 20902 : model1 loss : 0.438316 model2 loss : 0.019324
[00:43:01.871] iteration 20903 : model1 loss : 0.441993 model2 loss : 0.020262
[00:43:02.038] iteration 20904 : model1 loss : 0.438781 model2 loss : 0.017660
[00:43:02.203] iteration 20905 : model1 loss : 0.434692 model2 loss : 0.018632
[00:43:02.374] iteration 20906 : model1 loss : 0.435140 model2 loss : 0.018291
[00:43:02.540] iteration 20907 : model1 loss : 0.443433 model2 loss : 0.019962
[00:43:02.709] iteration 20908 : model1 loss : 0.442220 model2 loss : 0.020590
[00:43:02.888] iteration 20909 : model1 loss : 0.439542 model2 loss : 0.018243
[00:43:03.058] iteration 20910 : model1 loss : 0.440971 model2 loss : 0.017387
[00:43:03.224] iteration 20911 : model1 loss : 0.438830 model2 loss : 0.018814
[00:43:03.395] iteration 20912 : model1 loss : 0.439024 model2 loss : 0.015752
[00:43:03.562] iteration 20913 : model1 loss : 0.442032 model2 loss : 0.021512
[00:43:03.730] iteration 20914 : model1 loss : 0.441410 model2 loss : 0.017502
[00:43:03.897] iteration 20915 : model1 loss : 0.435960 model2 loss : 0.020349
[00:43:04.065] iteration 20916 : model1 loss : 0.436560 model2 loss : 0.018800
[00:43:06.079] iteration 20917 : model1 loss : 0.435045 model2 loss : 0.018589
[00:43:06.246] iteration 20918 : model1 loss : 0.444755 model2 loss : 0.023186
[00:43:06.418] iteration 20919 : model1 loss : 0.444470 model2 loss : 0.019410
[00:43:06.584] iteration 20920 : model1 loss : 0.435956 model2 loss : 0.017943
[00:43:06.755] iteration 20921 : model1 loss : 0.438622 model2 loss : 0.020523
[00:43:06.924] iteration 20922 : model1 loss : 0.436440 model2 loss : 0.019166
[00:43:07.094] iteration 20923 : model1 loss : 0.433745 model2 loss : 0.017181
[00:43:07.260] iteration 20924 : model1 loss : 0.440215 model2 loss : 0.017471
[00:43:07.429] iteration 20925 : model1 loss : 0.437324 model2 loss : 0.018163
[00:43:07.595] iteration 20926 : model1 loss : 0.437583 model2 loss : 0.018656
[00:43:07.769] iteration 20927 : model1 loss : 0.438461 model2 loss : 0.018346
[00:43:07.938] iteration 20928 : model1 loss : 0.442386 model2 loss : 0.019874
[00:43:08.108] iteration 20929 : model1 loss : 0.436221 model2 loss : 0.016676
[00:43:08.274] iteration 20930 : model1 loss : 0.440002 model2 loss : 0.021099
[00:43:08.443] iteration 20931 : model1 loss : 0.436933 model2 loss : 0.016092
[00:43:08.625] iteration 20932 : model1 loss : 0.435208 model2 loss : 0.017267
[00:43:08.795] iteration 20933 : model1 loss : 0.439552 model2 loss : 0.018968
[00:43:08.963] iteration 20934 : model1 loss : 0.439029 model2 loss : 0.018593
[00:43:09.132] iteration 20935 : model1 loss : 0.436734 model2 loss : 0.016232
[00:43:09.300] iteration 20936 : model1 loss : 0.441450 model2 loss : 0.016646
[00:43:09.466] iteration 20937 : model1 loss : 0.440001 model2 loss : 0.018741
[00:43:11.500] iteration 20938 : model1 loss : 0.436201 model2 loss : 0.017358
[00:43:11.666] iteration 20939 : model1 loss : 0.440464 model2 loss : 0.017800
[00:43:11.838] iteration 20940 : model1 loss : 0.437241 model2 loss : 0.017674
[00:43:12.007] iteration 20941 : model1 loss : 0.444596 model2 loss : 0.018900
[00:43:12.177] iteration 20942 : model1 loss : 0.441288 model2 loss : 0.021384
[00:43:12.344] iteration 20943 : model1 loss : 0.438642 model2 loss : 0.016737
[00:43:12.513] iteration 20944 : model1 loss : 0.443196 model2 loss : 0.021323
[00:43:12.678] iteration 20945 : model1 loss : 0.438961 model2 loss : 0.019744
[00:43:12.848] iteration 20946 : model1 loss : 0.436818 model2 loss : 0.019051
[00:43:13.018] iteration 20947 : model1 loss : 0.440337 model2 loss : 0.020484
[00:43:13.187] iteration 20948 : model1 loss : 0.436326 model2 loss : 0.017076
[00:43:13.357] iteration 20949 : model1 loss : 0.436911 model2 loss : 0.019170
[00:43:13.525] iteration 20950 : model1 loss : 0.435853 model2 loss : 0.016590
[00:43:13.691] iteration 20951 : model1 loss : 0.440375 model2 loss : 0.020330
[00:43:13.860] iteration 20952 : model1 loss : 0.435151 model2 loss : 0.016948
[00:43:14.029] iteration 20953 : model1 loss : 0.435301 model2 loss : 0.018096
[00:43:14.197] iteration 20954 : model1 loss : 0.436523 model2 loss : 0.018840
[00:43:14.373] iteration 20955 : model1 loss : 0.441933 model2 loss : 0.019924
[00:43:14.540] iteration 20956 : model1 loss : 0.438780 model2 loss : 0.018304
[00:43:14.705] iteration 20957 : model1 loss : 0.439679 model2 loss : 0.018823
[00:43:14.871] iteration 20958 : model1 loss : 0.438502 model2 loss : 0.018812
[00:43:16.877] iteration 20959 : model1 loss : 0.441672 model2 loss : 0.020565
[00:43:17.045] iteration 20960 : model1 loss : 0.436842 model2 loss : 0.018672
[00:43:17.211] iteration 20961 : model1 loss : 0.435940 model2 loss : 0.018533
[00:43:17.380] iteration 20962 : model1 loss : 0.443642 model2 loss : 0.020108
[00:43:17.549] iteration 20963 : model1 loss : 0.442069 model2 loss : 0.018281
[00:43:17.718] iteration 20964 : model1 loss : 0.435536 model2 loss : 0.019775
[00:43:17.886] iteration 20965 : model1 loss : 0.434710 model2 loss : 0.018365
[00:43:18.051] iteration 20966 : model1 loss : 0.434189 model2 loss : 0.019395
[00:43:18.219] iteration 20967 : model1 loss : 0.438553 model2 loss : 0.019276
[00:43:18.385] iteration 20968 : model1 loss : 0.438673 model2 loss : 0.017043
[00:43:18.552] iteration 20969 : model1 loss : 0.437693 model2 loss : 0.018351
[00:43:18.718] iteration 20970 : model1 loss : 0.440225 model2 loss : 0.019168
[00:43:18.888] iteration 20971 : model1 loss : 0.437845 model2 loss : 0.020857
[00:43:19.053] iteration 20972 : model1 loss : 0.437452 model2 loss : 0.017874
[00:43:19.222] iteration 20973 : model1 loss : 0.434780 model2 loss : 0.018633
[00:43:19.389] iteration 20974 : model1 loss : 0.440431 model2 loss : 0.018149
[00:43:19.557] iteration 20975 : model1 loss : 0.437769 model2 loss : 0.017055
[00:43:19.726] iteration 20976 : model1 loss : 0.440450 model2 loss : 0.019071
[00:43:19.896] iteration 20977 : model1 loss : 0.445153 model2 loss : 0.021089
[00:43:20.061] iteration 20978 : model1 loss : 0.437720 model2 loss : 0.018307
[00:43:20.227] iteration 20979 : model1 loss : 0.441704 model2 loss : 0.018432
[00:43:22.252] iteration 20980 : model1 loss : 0.434794 model2 loss : 0.017941
[00:43:22.421] iteration 20981 : model1 loss : 0.442696 model2 loss : 0.018912
[00:43:22.591] iteration 20982 : model1 loss : 0.444075 model2 loss : 0.019164
[00:43:22.757] iteration 20983 : model1 loss : 0.437183 model2 loss : 0.020692
[00:43:22.926] iteration 20984 : model1 loss : 0.438651 model2 loss : 0.018829
[00:43:23.093] iteration 20985 : model1 loss : 0.435762 model2 loss : 0.019451
[00:43:23.262] iteration 20986 : model1 loss : 0.438107 model2 loss : 0.021129
[00:43:23.426] iteration 20987 : model1 loss : 0.437171 model2 loss : 0.018608
[00:43:23.596] iteration 20988 : model1 loss : 0.442629 model2 loss : 0.020305
[00:43:23.770] iteration 20989 : model1 loss : 0.440797 model2 loss : 0.019671
[00:43:23.940] iteration 20990 : model1 loss : 0.438181 model2 loss : 0.017960
[00:43:24.108] iteration 20991 : model1 loss : 0.435474 model2 loss : 0.017427
[00:43:24.277] iteration 20992 : model1 loss : 0.434935 model2 loss : 0.018255
[00:43:24.441] iteration 20993 : model1 loss : 0.441871 model2 loss : 0.022008
[00:43:24.610] iteration 20994 : model1 loss : 0.438110 model2 loss : 0.017831
[00:43:24.782] iteration 20995 : model1 loss : 0.437166 model2 loss : 0.018138
[00:43:24.952] iteration 20996 : model1 loss : 0.439287 model2 loss : 0.018520
[00:43:25.122] iteration 20997 : model1 loss : 0.438766 model2 loss : 0.016019
[00:43:25.293] iteration 20998 : model1 loss : 0.440627 model2 loss : 0.020273
[00:43:25.457] iteration 20999 : model1 loss : 0.438827 model2 loss : 0.017742
[00:43:25.624] iteration 21000 : model1 loss : 0.441977 model2 loss : 0.021229
[00:43:34.222] iteration 21000 : model1_mean_dice : 0.873052 model1_mean_hd95 : 3.445049
[00:43:42.883] iteration 21000 : model2_mean_dice : 0.880180 model2_mean_hd95 : 5.144316
[00:43:42.912] save model1 to ../model/ACDC/EVILv1_kl0.5_tau0.25_14_1337/unet\model1_iter_21000.pth
[00:43:42.940] save model2 to ../model/ACDC/EVILv1_kl0.5_tau0.25_14_1337/unet\model2_iter_21000.pth
[00:43:44.953] iteration 21001 : model1 loss : 0.443110 model2 loss : 0.018128
[00:43:45.120] iteration 21002 : model1 loss : 0.443157 model2 loss : 0.017970
[00:43:45.291] iteration 21003 : model1 loss : 0.440740 model2 loss : 0.018008
[00:43:45.457] iteration 21004 : model1 loss : 0.437736 model2 loss : 0.020516
[00:43:45.627] iteration 21005 : model1 loss : 0.441537 model2 loss : 0.019330
[00:43:45.794] iteration 21006 : model1 loss : 0.437084 model2 loss : 0.018005
[00:43:45.962] iteration 21007 : model1 loss : 0.441678 model2 loss : 0.019223
[00:43:46.126] iteration 21008 : model1 loss : 0.439924 model2 loss : 0.019250
[00:43:46.293] iteration 21009 : model1 loss : 0.441107 model2 loss : 0.018141
[00:43:46.457] iteration 21010 : model1 loss : 0.440127 model2 loss : 0.017031
[00:43:46.630] iteration 21011 : model1 loss : 0.441664 model2 loss : 0.019684
[00:43:46.795] iteration 21012 : model1 loss : 0.433804 model2 loss : 0.018067
[00:43:46.965] iteration 21013 : model1 loss : 0.436652 model2 loss : 0.019056
[00:43:47.131] iteration 21014 : model1 loss : 0.439793 model2 loss : 0.018596
[00:43:47.300] iteration 21015 : model1 loss : 0.435919 model2 loss : 0.018689
[00:43:47.469] iteration 21016 : model1 loss : 0.438613 model2 loss : 0.018867
[00:43:47.638] iteration 21017 : model1 loss : 0.433420 model2 loss : 0.016897
[00:43:47.806] iteration 21018 : model1 loss : 0.434329 model2 loss : 0.017236
[00:43:47.976] iteration 21019 : model1 loss : 0.436023 model2 loss : 0.019107
[00:43:48.141] iteration 21020 : model1 loss : 0.440660 model2 loss : 0.018895
[00:43:48.311] iteration 21021 : model1 loss : 0.436160 model2 loss : 0.016584
[00:43:50.320] iteration 21022 : model1 loss : 0.436649 model2 loss : 0.019870
[00:43:50.485] iteration 21023 : model1 loss : 0.441019 model2 loss : 0.018191
[00:43:50.652] iteration 21024 : model1 loss : 0.437037 model2 loss : 0.015574
[00:43:50.819] iteration 21025 : model1 loss : 0.439091 model2 loss : 0.018865
[00:43:50.991] iteration 21026 : model1 loss : 0.441852 model2 loss : 0.018923
[00:43:51.156] iteration 21027 : model1 loss : 0.437792 model2 loss : 0.019084
[00:43:51.328] iteration 21028 : model1 loss : 0.438336 model2 loss : 0.018456
[00:43:51.493] iteration 21029 : model1 loss : 0.437934 model2 loss : 0.017165
[00:43:51.661] iteration 21030 : model1 loss : 0.435982 model2 loss : 0.018924
[00:43:51.827] iteration 21031 : model1 loss : 0.437887 model2 loss : 0.021185
[00:43:51.996] iteration 21032 : model1 loss : 0.439304 model2 loss : 0.017921
[00:43:52.161] iteration 21033 : model1 loss : 0.442398 model2 loss : 0.021326
[00:43:52.330] iteration 21034 : model1 loss : 0.439782 model2 loss : 0.016878
[00:43:52.499] iteration 21035 : model1 loss : 0.434862 model2 loss : 0.018427
[00:43:52.666] iteration 21036 : model1 loss : 0.442293 model2 loss : 0.020868
[00:43:52.832] iteration 21037 : model1 loss : 0.437358 model2 loss : 0.017652
[00:43:53.001] iteration 21038 : model1 loss : 0.436976 model2 loss : 0.016342
[00:43:53.166] iteration 21039 : model1 loss : 0.440220 model2 loss : 0.022705
[00:43:53.335] iteration 21040 : model1 loss : 0.436044 model2 loss : 0.016922
[00:43:53.498] iteration 21041 : model1 loss : 0.438323 model2 loss : 0.017491
[00:43:53.665] iteration 21042 : model1 loss : 0.443679 model2 loss : 0.021548
[00:43:55.685] iteration 21043 : model1 loss : 0.436633 model2 loss : 0.020467
[00:43:55.853] iteration 21044 : model1 loss : 0.438135 model2 loss : 0.019056
[00:43:56.026] iteration 21045 : model1 loss : 0.440421 model2 loss : 0.018709
[00:43:56.192] iteration 21046 : model1 loss : 0.435354 model2 loss : 0.018480
[00:43:56.363] iteration 21047 : model1 loss : 0.442940 model2 loss : 0.019701
[00:43:56.530] iteration 21048 : model1 loss : 0.439680 model2 loss : 0.020289
[00:43:56.699] iteration 21049 : model1 loss : 0.441059 model2 loss : 0.018354
[00:43:56.865] iteration 21050 : model1 loss : 0.439162 model2 loss : 0.018863
[00:43:57.035] iteration 21051 : model1 loss : 0.439803 model2 loss : 0.018989
[00:43:57.201] iteration 21052 : model1 loss : 0.437808 model2 loss : 0.018126
[00:43:57.371] iteration 21053 : model1 loss : 0.437493 model2 loss : 0.019378
[00:43:57.537] iteration 21054 : model1 loss : 0.437028 model2 loss : 0.019007
[00:43:57.709] iteration 21055 : model1 loss : 0.439462 model2 loss : 0.017969
[00:43:57.875] iteration 21056 : model1 loss : 0.440461 model2 loss : 0.017756
[00:43:58.045] iteration 21057 : model1 loss : 0.438308 model2 loss : 0.020112
[00:43:58.211] iteration 21058 : model1 loss : 0.438881 model2 loss : 0.019756
[00:43:58.378] iteration 21059 : model1 loss : 0.442155 model2 loss : 0.021336
[00:43:58.543] iteration 21060 : model1 loss : 0.443331 model2 loss : 0.023009
[00:43:58.710] iteration 21061 : model1 loss : 0.434770 model2 loss : 0.019571
[00:43:58.876] iteration 21062 : model1 loss : 0.435983 model2 loss : 0.019052
[00:43:59.044] iteration 21063 : model1 loss : 0.439268 model2 loss : 0.018979
[00:44:01.116] iteration 21064 : model1 loss : 0.440837 model2 loss : 0.019583
[00:44:01.289] iteration 21065 : model1 loss : 0.439564 model2 loss : 0.018271
[00:44:01.457] iteration 21066 : model1 loss : 0.437405 model2 loss : 0.018569
[00:44:01.624] iteration 21067 : model1 loss : 0.440259 model2 loss : 0.020699
[00:44:01.795] iteration 21068 : model1 loss : 0.436433 model2 loss : 0.019379
[00:44:01.963] iteration 21069 : model1 loss : 0.437040 model2 loss : 0.019709
[00:44:02.133] iteration 21070 : model1 loss : 0.437864 model2 loss : 0.020137
[00:44:02.300] iteration 21071 : model1 loss : 0.439806 model2 loss : 0.020880
[00:44:02.469] iteration 21072 : model1 loss : 0.439323 model2 loss : 0.021999
[00:44:02.636] iteration 21073 : model1 loss : 0.437493 model2 loss : 0.020833
[00:44:02.805] iteration 21074 : model1 loss : 0.439111 model2 loss : 0.018756
[00:44:02.973] iteration 21075 : model1 loss : 0.439572 model2 loss : 0.018716
[00:44:03.142] iteration 21076 : model1 loss : 0.436197 model2 loss : 0.018248
[00:44:03.310] iteration 21077 : model1 loss : 0.441871 model2 loss : 0.017594
[00:44:03.480] iteration 21078 : model1 loss : 0.438987 model2 loss : 0.019074
[00:44:03.645] iteration 21079 : model1 loss : 0.440003 model2 loss : 0.017482
[00:44:03.815] iteration 21080 : model1 loss : 0.436260 model2 loss : 0.015887
[00:44:03.982] iteration 21081 : model1 loss : 0.437286 model2 loss : 0.019590
[00:44:04.151] iteration 21082 : model1 loss : 0.434991 model2 loss : 0.018396
[00:44:04.316] iteration 21083 : model1 loss : 0.442793 model2 loss : 0.019068
[00:44:04.485] iteration 21084 : model1 loss : 0.439986 model2 loss : 0.019997
[00:44:06.507] iteration 21085 : model1 loss : 0.437836 model2 loss : 0.018013
[00:44:06.680] iteration 21086 : model1 loss : 0.442019 model2 loss : 0.017598
[00:44:06.849] iteration 21087 : model1 loss : 0.437811 model2 loss : 0.017656
[00:44:07.019] iteration 21088 : model1 loss : 0.439209 model2 loss : 0.018014
[00:44:07.190] iteration 21089 : model1 loss : 0.439790 model2 loss : 0.017298
[00:44:07.359] iteration 21090 : model1 loss : 0.441469 model2 loss : 0.017707
[00:44:07.528] iteration 21091 : model1 loss : 0.438739 model2 loss : 0.017736
[00:44:07.696] iteration 21092 : model1 loss : 0.438613 model2 loss : 0.017822
[00:44:07.866] iteration 21093 : model1 loss : 0.440810 model2 loss : 0.019642
[00:44:08.039] iteration 21094 : model1 loss : 0.438327 model2 loss : 0.017364
[00:44:08.210] iteration 21095 : model1 loss : 0.441649 model2 loss : 0.019087
[00:44:08.375] iteration 21096 : model1 loss : 0.435695 model2 loss : 0.018240
[00:44:08.545] iteration 21097 : model1 loss : 0.435397 model2 loss : 0.018598
[00:44:08.715] iteration 21098 : model1 loss : 0.438062 model2 loss : 0.017339
[00:44:08.891] iteration 21099 : model1 loss : 0.434655 model2 loss : 0.019077
[00:44:09.060] iteration 21100 : model1 loss : 0.438164 model2 loss : 0.017831
[00:44:09.227] iteration 21101 : model1 loss : 0.438707 model2 loss : 0.018378
[00:44:09.405] iteration 21102 : model1 loss : 0.440318 model2 loss : 0.019392
[00:44:09.574] iteration 21103 : model1 loss : 0.437807 model2 loss : 0.018121
[00:44:09.740] iteration 21104 : model1 loss : 0.436117 model2 loss : 0.017461
[00:44:09.906] iteration 21105 : model1 loss : 0.441536 model2 loss : 0.018024
[00:44:12.009] iteration 21106 : model1 loss : 0.436206 model2 loss : 0.017895
[00:44:12.179] iteration 21107 : model1 loss : 0.440687 model2 loss : 0.018281
[00:44:12.350] iteration 21108 : model1 loss : 0.438344 model2 loss : 0.018124
[00:44:12.516] iteration 21109 : model1 loss : 0.436699 model2 loss : 0.018782
[00:44:12.683] iteration 21110 : model1 loss : 0.439247 model2 loss : 0.018160
[00:44:12.852] iteration 21111 : model1 loss : 0.437582 model2 loss : 0.017788
[00:44:13.024] iteration 21112 : model1 loss : 0.437140 model2 loss : 0.019843
[00:44:13.190] iteration 21113 : model1 loss : 0.441230 model2 loss : 0.018490
[00:44:13.359] iteration 21114 : model1 loss : 0.441227 model2 loss : 0.019691
[00:44:13.524] iteration 21115 : model1 loss : 0.438000 model2 loss : 0.019543
[00:44:13.694] iteration 21116 : model1 loss : 0.439204 model2 loss : 0.017247
[00:44:13.862] iteration 21117 : model1 loss : 0.435715 model2 loss : 0.015842
[00:44:14.034] iteration 21118 : model1 loss : 0.436879 model2 loss : 0.018636
[00:44:14.200] iteration 21119 : model1 loss : 0.438573 model2 loss : 0.018603
[00:44:14.371] iteration 21120 : model1 loss : 0.436163 model2 loss : 0.020748
[00:44:14.535] iteration 21121 : model1 loss : 0.444999 model2 loss : 0.024104
[00:44:14.704] iteration 21122 : model1 loss : 0.434563 model2 loss : 0.019496
[00:44:14.873] iteration 21123 : model1 loss : 0.443144 model2 loss : 0.019720
[00:44:15.044] iteration 21124 : model1 loss : 0.438002 model2 loss : 0.019546
[00:44:15.210] iteration 21125 : model1 loss : 0.437131 model2 loss : 0.017822
[00:44:15.377] iteration 21126 : model1 loss : 0.441968 model2 loss : 0.017589
[00:44:17.380] iteration 21127 : model1 loss : 0.437698 model2 loss : 0.018429
[00:44:17.544] iteration 21128 : model1 loss : 0.439988 model2 loss : 0.018482
[00:44:17.719] iteration 21129 : model1 loss : 0.439415 model2 loss : 0.019336
[00:44:17.898] iteration 21130 : model1 loss : 0.440932 model2 loss : 0.020933
[00:44:18.066] iteration 21131 : model1 loss : 0.441053 model2 loss : 0.016525
[00:44:18.233] iteration 21132 : model1 loss : 0.439563 model2 loss : 0.020118
[00:44:18.402] iteration 21133 : model1 loss : 0.433102 model2 loss : 0.016124
[00:44:18.570] iteration 21134 : model1 loss : 0.439713 model2 loss : 0.019936
[00:44:18.737] iteration 21135 : model1 loss : 0.442107 model2 loss : 0.019629
[00:44:18.906] iteration 21136 : model1 loss : 0.440093 model2 loss : 0.019411
[00:44:19.075] iteration 21137 : model1 loss : 0.439293 model2 loss : 0.018433
[00:44:19.242] iteration 21138 : model1 loss : 0.441082 model2 loss : 0.020283
[00:44:19.413] iteration 21139 : model1 loss : 0.437993 model2 loss : 0.017690
[00:44:19.580] iteration 21140 : model1 loss : 0.437705 model2 loss : 0.017110
[00:44:19.749] iteration 21141 : model1 loss : 0.435510 model2 loss : 0.016974
[00:44:19.918] iteration 21142 : model1 loss : 0.440275 model2 loss : 0.019677
[00:44:20.087] iteration 21143 : model1 loss : 0.438091 model2 loss : 0.018078
[00:44:20.254] iteration 21144 : model1 loss : 0.439929 model2 loss : 0.017353
[00:44:20.425] iteration 21145 : model1 loss : 0.438365 model2 loss : 0.019161
[00:44:20.590] iteration 21146 : model1 loss : 0.439193 model2 loss : 0.018347
[00:44:20.762] iteration 21147 : model1 loss : 0.435088 model2 loss : 0.017427
[00:44:22.819] iteration 21148 : model1 loss : 0.439306 model2 loss : 0.017544
[00:44:22.990] iteration 21149 : model1 loss : 0.435618 model2 loss : 0.016415
[00:44:23.159] iteration 21150 : model1 loss : 0.439566 model2 loss : 0.018100
[00:44:23.328] iteration 21151 : model1 loss : 0.438495 model2 loss : 0.017049
[00:44:23.496] iteration 21152 : model1 loss : 0.435549 model2 loss : 0.018374
[00:44:23.663] iteration 21153 : model1 loss : 0.438880 model2 loss : 0.021475
[00:44:23.835] iteration 21154 : model1 loss : 0.443243 model2 loss : 0.021070
[00:44:24.004] iteration 21155 : model1 loss : 0.437145 model2 loss : 0.022095
[00:44:24.172] iteration 21156 : model1 loss : 0.436877 model2 loss : 0.017447
[00:44:24.341] iteration 21157 : model1 loss : 0.438993 model2 loss : 0.019999
[00:44:24.509] iteration 21158 : model1 loss : 0.440361 model2 loss : 0.018663
[00:44:24.675] iteration 21159 : model1 loss : 0.442061 model2 loss : 0.021168
[00:44:24.845] iteration 21160 : model1 loss : 0.438895 model2 loss : 0.022104
[00:44:25.016] iteration 21161 : model1 loss : 0.437790 model2 loss : 0.021867
[00:44:25.184] iteration 21162 : model1 loss : 0.438296 model2 loss : 0.020040
[00:44:25.349] iteration 21163 : model1 loss : 0.441183 model2 loss : 0.021463
[00:44:25.517] iteration 21164 : model1 loss : 0.438412 model2 loss : 0.021786
[00:44:25.682] iteration 21165 : model1 loss : 0.438105 model2 loss : 0.023684
[00:44:25.851] iteration 21166 : model1 loss : 0.440581 model2 loss : 0.024716
[00:44:26.022] iteration 21167 : model1 loss : 0.443266 model2 loss : 0.021800
[00:44:26.189] iteration 21168 : model1 loss : 0.439938 model2 loss : 0.024018
[00:44:28.244] iteration 21169 : model1 loss : 0.442166 model2 loss : 0.019426
[00:44:28.415] iteration 21170 : model1 loss : 0.442312 model2 loss : 0.020654
[00:44:28.586] iteration 21171 : model1 loss : 0.444049 model2 loss : 0.027279
[00:44:28.754] iteration 21172 : model1 loss : 0.433369 model2 loss : 0.019821
[00:44:28.938] iteration 21173 : model1 loss : 0.437481 model2 loss : 0.023588
[00:44:29.105] iteration 21174 : model1 loss : 0.434568 model2 loss : 0.020939
[00:44:29.273] iteration 21175 : model1 loss : 0.438761 model2 loss : 0.023511
[00:44:29.439] iteration 21176 : model1 loss : 0.440072 model2 loss : 0.018872
[00:44:29.606] iteration 21177 : model1 loss : 0.439198 model2 loss : 0.019688
[00:44:29.775] iteration 21178 : model1 loss : 0.440930 model2 loss : 0.028740
[00:44:29.945] iteration 21179 : model1 loss : 0.445690 model2 loss : 0.024968
[00:44:30.113] iteration 21180 : model1 loss : 0.440224 model2 loss : 0.018004
[00:44:30.283] iteration 21181 : model1 loss : 0.438438 model2 loss : 0.017876
[00:44:30.451] iteration 21182 : model1 loss : 0.434831 model2 loss : 0.021931
[00:44:30.620] iteration 21183 : model1 loss : 0.440933 model2 loss : 0.017271
[00:44:30.786] iteration 21184 : model1 loss : 0.437929 model2 loss : 0.022385
[00:44:30.957] iteration 21185 : model1 loss : 0.439029 model2 loss : 0.020821
[00:44:31.122] iteration 21186 : model1 loss : 0.436557 model2 loss : 0.021237
[00:44:31.292] iteration 21187 : model1 loss : 0.441409 model2 loss : 0.018413
[00:44:31.457] iteration 21188 : model1 loss : 0.439342 model2 loss : 0.020609
[00:44:31.625] iteration 21189 : model1 loss : 0.436808 model2 loss : 0.021930
[00:44:33.692] iteration 21190 : model1 loss : 0.438906 model2 loss : 0.022631
[00:44:33.859] iteration 21191 : model1 loss : 0.437669 model2 loss : 0.019370
[00:44:34.031] iteration 21192 : model1 loss : 0.438290 model2 loss : 0.019045
[00:44:34.198] iteration 21193 : model1 loss : 0.437430 model2 loss : 0.019946
[00:44:34.367] iteration 21194 : model1 loss : 0.440700 model2 loss : 0.021557
[00:44:34.532] iteration 21195 : model1 loss : 0.439686 model2 loss : 0.019019
[00:44:34.700] iteration 21196 : model1 loss : 0.437270 model2 loss : 0.019122
[00:44:34.870] iteration 21197 : model1 loss : 0.439204 model2 loss : 0.019569
[00:44:35.041] iteration 21198 : model1 loss : 0.439553 model2 loss : 0.018233
[00:44:35.208] iteration 21199 : model1 loss : 0.438537 model2 loss : 0.017991
[00:44:35.377] iteration 21200 : model1 loss : 0.435807 model2 loss : 0.021458
[00:44:35.543] iteration 21201 : model1 loss : 0.437963 model2 loss : 0.019685
[00:44:35.723] iteration 21202 : model1 loss : 0.438045 model2 loss : 0.018590
[00:44:35.890] iteration 21203 : model1 loss : 0.444294 model2 loss : 0.018942
[00:44:36.059] iteration 21204 : model1 loss : 0.441656 model2 loss : 0.022858
[00:44:36.225] iteration 21205 : model1 loss : 0.437682 model2 loss : 0.018916
[00:44:36.392] iteration 21206 : model1 loss : 0.437544 model2 loss : 0.017616
[00:44:36.559] iteration 21207 : model1 loss : 0.437556 model2 loss : 0.017797
[00:44:36.728] iteration 21208 : model1 loss : 0.441087 model2 loss : 0.019913
[00:44:36.896] iteration 21209 : model1 loss : 0.440274 model2 loss : 0.019888
[00:44:37.066] iteration 21210 : model1 loss : 0.441661 model2 loss : 0.021922
[00:44:39.096] iteration 21211 : model1 loss : 0.432460 model2 loss : 0.016959
[00:44:39.265] iteration 21212 : model1 loss : 0.435442 model2 loss : 0.017521
[00:44:39.438] iteration 21213 : model1 loss : 0.438032 model2 loss : 0.018527
[00:44:39.606] iteration 21214 : model1 loss : 0.438984 model2 loss : 0.018220
[00:44:39.774] iteration 21215 : model1 loss : 0.433657 model2 loss : 0.020566
[00:44:39.942] iteration 21216 : model1 loss : 0.438980 model2 loss : 0.018437
[00:44:40.110] iteration 21217 : model1 loss : 0.442910 model2 loss : 0.021584
[00:44:40.277] iteration 21218 : model1 loss : 0.438281 model2 loss : 0.020951
[00:44:40.445] iteration 21219 : model1 loss : 0.436292 model2 loss : 0.018450
[00:44:40.611] iteration 21220 : model1 loss : 0.438965 model2 loss : 0.019670
[00:44:40.779] iteration 21221 : model1 loss : 0.443896 model2 loss : 0.019676
[00:44:40.945] iteration 21222 : model1 loss : 0.438868 model2 loss : 0.018285
[00:44:41.114] iteration 21223 : model1 loss : 0.440461 model2 loss : 0.019992
[00:44:41.282] iteration 21224 : model1 loss : 0.440301 model2 loss : 0.019895
[00:44:41.450] iteration 21225 : model1 loss : 0.441343 model2 loss : 0.019227
[00:44:41.617] iteration 21226 : model1 loss : 0.440756 model2 loss : 0.021903
[00:44:41.786] iteration 21227 : model1 loss : 0.440851 model2 loss : 0.018673
[00:44:41.954] iteration 21228 : model1 loss : 0.435391 model2 loss : 0.017398
[00:44:42.125] iteration 21229 : model1 loss : 0.438192 model2 loss : 0.019947
[00:44:42.291] iteration 21230 : model1 loss : 0.440340 model2 loss : 0.021661
[00:44:42.467] iteration 21231 : model1 loss : 0.441711 model2 loss : 0.022061
[00:44:44.526] iteration 21232 : model1 loss : 0.438254 model2 loss : 0.019302
[00:44:44.699] iteration 21233 : model1 loss : 0.438399 model2 loss : 0.021520
[00:44:44.870] iteration 21234 : model1 loss : 0.444404 model2 loss : 0.021533
[00:44:45.040] iteration 21235 : model1 loss : 0.441676 model2 loss : 0.017113
[00:44:45.208] iteration 21236 : model1 loss : 0.437059 model2 loss : 0.020456
[00:44:45.376] iteration 21237 : model1 loss : 0.442243 model2 loss : 0.019697
[00:44:45.542] iteration 21238 : model1 loss : 0.438330 model2 loss : 0.020827
[00:44:45.709] iteration 21239 : model1 loss : 0.439958 model2 loss : 0.020291
[00:44:45.876] iteration 21240 : model1 loss : 0.435013 model2 loss : 0.017107
[00:44:46.045] iteration 21241 : model1 loss : 0.441754 model2 loss : 0.018026
[00:44:46.214] iteration 21242 : model1 loss : 0.444031 model2 loss : 0.019445
[00:44:46.382] iteration 21243 : model1 loss : 0.440029 model2 loss : 0.019566
[00:44:46.550] iteration 21244 : model1 loss : 0.439465 model2 loss : 0.016931
[00:44:46.717] iteration 21245 : model1 loss : 0.439099 model2 loss : 0.018861
[00:44:46.885] iteration 21246 : model1 loss : 0.434664 model2 loss : 0.018698
[00:44:47.052] iteration 21247 : model1 loss : 0.439193 model2 loss : 0.020725
[00:44:47.219] iteration 21248 : model1 loss : 0.440080 model2 loss : 0.017141
[00:44:47.385] iteration 21249 : model1 loss : 0.434508 model2 loss : 0.019099
[00:44:47.555] iteration 21250 : model1 loss : 0.436736 model2 loss : 0.018999
[00:44:47.720] iteration 21251 : model1 loss : 0.438695 model2 loss : 0.018822
[00:44:47.887] iteration 21252 : model1 loss : 0.433616 model2 loss : 0.016807
[00:44:49.899] iteration 21253 : model1 loss : 0.437682 model2 loss : 0.017510
[00:44:50.070] iteration 21254 : model1 loss : 0.439170 model2 loss : 0.018926
[00:44:50.242] iteration 21255 : model1 loss : 0.442733 model2 loss : 0.022357
[00:44:50.412] iteration 21256 : model1 loss : 0.442389 model2 loss : 0.018853
[00:44:50.580] iteration 21257 : model1 loss : 0.438133 model2 loss : 0.018765
[00:44:50.750] iteration 21258 : model1 loss : 0.442534 model2 loss : 0.021308
[00:44:50.918] iteration 21259 : model1 loss : 0.437964 model2 loss : 0.017487
[00:44:51.085] iteration 21260 : model1 loss : 0.441683 model2 loss : 0.021406
[00:44:51.254] iteration 21261 : model1 loss : 0.437609 model2 loss : 0.018046
[00:44:51.421] iteration 21262 : model1 loss : 0.436813 model2 loss : 0.017864
[00:44:51.590] iteration 21263 : model1 loss : 0.441684 model2 loss : 0.019574
[00:44:51.755] iteration 21264 : model1 loss : 0.441045 model2 loss : 0.019058
[00:44:51.925] iteration 21265 : model1 loss : 0.436909 model2 loss : 0.018425
[00:44:52.091] iteration 21266 : model1 loss : 0.437072 model2 loss : 0.017502
[00:44:52.263] iteration 21267 : model1 loss : 0.439445 model2 loss : 0.020905
[00:44:52.431] iteration 21268 : model1 loss : 0.435161 model2 loss : 0.019231
[00:44:52.601] iteration 21269 : model1 loss : 0.435966 model2 loss : 0.017632
[00:44:52.768] iteration 21270 : model1 loss : 0.437843 model2 loss : 0.019315
[00:44:52.938] iteration 21271 : model1 loss : 0.438985 model2 loss : 0.020753
[00:44:53.116] iteration 21272 : model1 loss : 0.436551 model2 loss : 0.017996
[00:44:53.287] iteration 21273 : model1 loss : 0.436002 model2 loss : 0.020324
[00:44:55.317] iteration 21274 : model1 loss : 0.440034 model2 loss : 0.018704
[00:44:55.489] iteration 21275 : model1 loss : 0.438767 model2 loss : 0.017788
[00:44:55.658] iteration 21276 : model1 loss : 0.439261 model2 loss : 0.018885
[00:44:55.827] iteration 21277 : model1 loss : 0.436499 model2 loss : 0.018637
[00:44:55.995] iteration 21278 : model1 loss : 0.441065 model2 loss : 0.024794
[00:44:56.162] iteration 21279 : model1 loss : 0.437476 model2 loss : 0.019040
[00:44:56.334] iteration 21280 : model1 loss : 0.437566 model2 loss : 0.018000
[00:44:56.502] iteration 21281 : model1 loss : 0.441847 model2 loss : 0.021565
[00:44:56.671] iteration 21282 : model1 loss : 0.437359 model2 loss : 0.018638
[00:44:56.840] iteration 21283 : model1 loss : 0.438162 model2 loss : 0.019042
[00:44:57.011] iteration 21284 : model1 loss : 0.435211 model2 loss : 0.016731
[00:44:57.176] iteration 21285 : model1 loss : 0.442754 model2 loss : 0.020894
[00:44:57.350] iteration 21286 : model1 loss : 0.439635 model2 loss : 0.020725
[00:44:57.518] iteration 21287 : model1 loss : 0.443118 model2 loss : 0.021570
[00:44:57.687] iteration 21288 : model1 loss : 0.439855 model2 loss : 0.016638
[00:44:57.853] iteration 21289 : model1 loss : 0.439703 model2 loss : 0.021889
[00:44:58.026] iteration 21290 : model1 loss : 0.436392 model2 loss : 0.018430
[00:44:58.191] iteration 21291 : model1 loss : 0.438823 model2 loss : 0.018722
[00:44:58.363] iteration 21292 : model1 loss : 0.436969 model2 loss : 0.019133
[00:44:58.527] iteration 21293 : model1 loss : 0.437160 model2 loss : 0.017331
[00:44:58.695] iteration 21294 : model1 loss : 0.440909 model2 loss : 0.020770
[00:45:00.718] iteration 21295 : model1 loss : 0.433467 model2 loss : 0.016176
[00:45:00.889] iteration 21296 : model1 loss : 0.436631 model2 loss : 0.018278
[00:45:01.059] iteration 21297 : model1 loss : 0.442916 model2 loss : 0.019222
[00:45:01.225] iteration 21298 : model1 loss : 0.439442 model2 loss : 0.017407
[00:45:01.395] iteration 21299 : model1 loss : 0.441388 model2 loss : 0.021210
[00:45:01.563] iteration 21300 : model1 loss : 0.438415 model2 loss : 0.018598
[00:45:01.748] iteration 21301 : model1 loss : 0.441721 model2 loss : 0.018455
[00:45:01.918] iteration 21302 : model1 loss : 0.440188 model2 loss : 0.018039
[00:45:02.087] iteration 21303 : model1 loss : 0.438648 model2 loss : 0.017183
[00:45:02.253] iteration 21304 : model1 loss : 0.438529 model2 loss : 0.018040
[00:45:02.427] iteration 21305 : model1 loss : 0.438948 model2 loss : 0.018603
[00:45:02.595] iteration 21306 : model1 loss : 0.437540 model2 loss : 0.018223
[00:45:02.765] iteration 21307 : model1 loss : 0.438150 model2 loss : 0.018070
[00:45:02.934] iteration 21308 : model1 loss : 0.437217 model2 loss : 0.020951
[00:45:03.105] iteration 21309 : model1 loss : 0.440828 model2 loss : 0.019135
[00:45:03.270] iteration 21310 : model1 loss : 0.437316 model2 loss : 0.020119
[00:45:03.439] iteration 21311 : model1 loss : 0.440336 model2 loss : 0.018896
[00:45:03.603] iteration 21312 : model1 loss : 0.436828 model2 loss : 0.018164
[00:45:03.772] iteration 21313 : model1 loss : 0.438450 model2 loss : 0.017222
[00:45:03.936] iteration 21314 : model1 loss : 0.439187 model2 loss : 0.021351
[00:45:04.105] iteration 21315 : model1 loss : 0.437348 model2 loss : 0.018635
[00:45:06.125] iteration 21316 : model1 loss : 0.440342 model2 loss : 0.021159
[00:45:06.293] iteration 21317 : model1 loss : 0.441394 model2 loss : 0.020155
[00:45:06.463] iteration 21318 : model1 loss : 0.442353 model2 loss : 0.022008
[00:45:06.631] iteration 21319 : model1 loss : 0.438052 model2 loss : 0.017630
[00:45:06.803] iteration 21320 : model1 loss : 0.441794 model2 loss : 0.019859
[00:45:06.972] iteration 21321 : model1 loss : 0.437432 model2 loss : 0.016241
[00:45:07.142] iteration 21322 : model1 loss : 0.437551 model2 loss : 0.016710
[00:45:07.312] iteration 21323 : model1 loss : 0.439662 model2 loss : 0.020373
[00:45:07.485] iteration 21324 : model1 loss : 0.432071 model2 loss : 0.017638
[00:45:07.652] iteration 21325 : model1 loss : 0.440807 model2 loss : 0.020543
[00:45:07.822] iteration 21326 : model1 loss : 0.440131 model2 loss : 0.018202
[00:45:07.991] iteration 21327 : model1 loss : 0.438637 model2 loss : 0.019553
[00:45:08.160] iteration 21328 : model1 loss : 0.442216 model2 loss : 0.018739
[00:45:08.329] iteration 21329 : model1 loss : 0.437140 model2 loss : 0.019087
[00:45:08.497] iteration 21330 : model1 loss : 0.432361 model2 loss : 0.016951
[00:45:08.663] iteration 21331 : model1 loss : 0.441797 model2 loss : 0.018605
[00:45:08.834] iteration 21332 : model1 loss : 0.438170 model2 loss : 0.017405
[00:45:09.003] iteration 21333 : model1 loss : 0.440790 model2 loss : 0.019920
[00:45:09.168] iteration 21334 : model1 loss : 0.438711 model2 loss : 0.018247
[00:45:09.337] iteration 21335 : model1 loss : 0.437813 model2 loss : 0.017486
[00:45:09.505] iteration 21336 : model1 loss : 0.438416 model2 loss : 0.016914
[00:45:11.545] iteration 21337 : model1 loss : 0.442943 model2 loss : 0.017716
[00:45:11.711] iteration 21338 : model1 loss : 0.439108 model2 loss : 0.017965
[00:45:11.880] iteration 21339 : model1 loss : 0.437040 model2 loss : 0.019710
[00:45:12.049] iteration 21340 : model1 loss : 0.439560 model2 loss : 0.018721
[00:45:12.215] iteration 21341 : model1 loss : 0.433624 model2 loss : 0.018617
[00:45:12.384] iteration 21342 : model1 loss : 0.436153 model2 loss : 0.018884
[00:45:12.552] iteration 21343 : model1 loss : 0.435392 model2 loss : 0.017645
[00:45:12.735] iteration 21344 : model1 loss : 0.438984 model2 loss : 0.016418
[00:45:12.904] iteration 21345 : model1 loss : 0.437253 model2 loss : 0.017067
[00:45:13.070] iteration 21346 : model1 loss : 0.437121 model2 loss : 0.019473
[00:45:13.238] iteration 21347 : model1 loss : 0.440148 model2 loss : 0.018710
[00:45:13.404] iteration 21348 : model1 loss : 0.443188 model2 loss : 0.018995
[00:45:13.571] iteration 21349 : model1 loss : 0.442471 model2 loss : 0.017788
[00:45:13.738] iteration 21350 : model1 loss : 0.441745 model2 loss : 0.021031
[00:45:13.909] iteration 21351 : model1 loss : 0.438246 model2 loss : 0.019410
[00:45:14.075] iteration 21352 : model1 loss : 0.438615 model2 loss : 0.017608
[00:45:14.244] iteration 21353 : model1 loss : 0.440165 model2 loss : 0.019310
[00:45:14.411] iteration 21354 : model1 loss : 0.435419 model2 loss : 0.018701
[00:45:14.582] iteration 21355 : model1 loss : 0.440221 model2 loss : 0.019274
[00:45:14.749] iteration 21356 : model1 loss : 0.439741 model2 loss : 0.019346
[00:45:14.918] iteration 21357 : model1 loss : 0.435803 model2 loss : 0.017003
[00:45:16.955] iteration 21358 : model1 loss : 0.435480 model2 loss : 0.016136
[00:45:17.128] iteration 21359 : model1 loss : 0.439386 model2 loss : 0.020864
[00:45:17.302] iteration 21360 : model1 loss : 0.435873 model2 loss : 0.017461
[00:45:17.474] iteration 21361 : model1 loss : 0.438715 model2 loss : 0.016696
[00:45:17.646] iteration 21362 : model1 loss : 0.441962 model2 loss : 0.020395
[00:45:17.814] iteration 21363 : model1 loss : 0.438370 model2 loss : 0.018193
[00:45:17.983] iteration 21364 : model1 loss : 0.439357 model2 loss : 0.019682
[00:45:18.149] iteration 21365 : model1 loss : 0.438225 model2 loss : 0.018193
[00:45:18.321] iteration 21366 : model1 loss : 0.437691 model2 loss : 0.016024
[00:45:18.486] iteration 21367 : model1 loss : 0.439046 model2 loss : 0.017814
[00:45:18.655] iteration 21368 : model1 loss : 0.441396 model2 loss : 0.018149
[00:45:18.821] iteration 21369 : model1 loss : 0.439402 model2 loss : 0.019388
[00:45:18.990] iteration 21370 : model1 loss : 0.440122 model2 loss : 0.018684
[00:45:19.155] iteration 21371 : model1 loss : 0.438617 model2 loss : 0.019619
[00:45:19.330] iteration 21372 : model1 loss : 0.441842 model2 loss : 0.017797
[00:45:19.496] iteration 21373 : model1 loss : 0.438874 model2 loss : 0.017962
[00:45:19.664] iteration 21374 : model1 loss : 0.441989 model2 loss : 0.017485
[00:45:19.832] iteration 21375 : model1 loss : 0.439257 model2 loss : 0.020578
[00:45:20.002] iteration 21376 : model1 loss : 0.433935 model2 loss : 0.018025
[00:45:20.177] iteration 21377 : model1 loss : 0.435230 model2 loss : 0.018091
[00:45:20.345] iteration 21378 : model1 loss : 0.438056 model2 loss : 0.015902
[00:45:22.358] iteration 21379 : model1 loss : 0.443044 model2 loss : 0.020489
[00:45:22.531] iteration 21380 : model1 loss : 0.437584 model2 loss : 0.017648
[00:45:22.702] iteration 21381 : model1 loss : 0.437185 model2 loss : 0.017029
[00:45:22.869] iteration 21382 : model1 loss : 0.435805 model2 loss : 0.017115
[00:45:23.040] iteration 21383 : model1 loss : 0.438538 model2 loss : 0.018243
[00:45:23.208] iteration 21384 : model1 loss : 0.436843 model2 loss : 0.019418
[00:45:23.377] iteration 21385 : model1 loss : 0.441521 model2 loss : 0.021659
[00:45:23.543] iteration 21386 : model1 loss : 0.440499 model2 loss : 0.019576
[00:45:23.712] iteration 21387 : model1 loss : 0.436576 model2 loss : 0.018564
[00:45:23.879] iteration 21388 : model1 loss : 0.438328 model2 loss : 0.017841
[00:45:24.051] iteration 21389 : model1 loss : 0.441948 model2 loss : 0.017508
[00:45:24.218] iteration 21390 : model1 loss : 0.439657 model2 loss : 0.018953
[00:45:24.388] iteration 21391 : model1 loss : 0.439473 model2 loss : 0.017223
[00:45:24.555] iteration 21392 : model1 loss : 0.438744 model2 loss : 0.019376
[00:45:24.724] iteration 21393 : model1 loss : 0.440189 model2 loss : 0.020737
[00:45:24.893] iteration 21394 : model1 loss : 0.434457 model2 loss : 0.018790
[00:45:25.064] iteration 21395 : model1 loss : 0.440273 model2 loss : 0.017957
[00:45:25.231] iteration 21396 : model1 loss : 0.441823 model2 loss : 0.019381
[00:45:25.401] iteration 21397 : model1 loss : 0.433629 model2 loss : 0.020827
[00:45:25.567] iteration 21398 : model1 loss : 0.442614 model2 loss : 0.022032
[00:45:25.733] iteration 21399 : model1 loss : 0.437706 model2 loss : 0.021035
[00:45:27.758] iteration 21400 : model1 loss : 0.440796 model2 loss : 0.018968
[00:45:27.927] iteration 21401 : model1 loss : 0.433888 model2 loss : 0.018095
[00:45:28.098] iteration 21402 : model1 loss : 0.441230 model2 loss : 0.019249
[00:45:28.264] iteration 21403 : model1 loss : 0.437228 model2 loss : 0.016392
[00:45:28.443] iteration 21404 : model1 loss : 0.440952 model2 loss : 0.020173
[00:45:28.609] iteration 21405 : model1 loss : 0.439763 model2 loss : 0.019917
[00:45:28.779] iteration 21406 : model1 loss : 0.440427 model2 loss : 0.017869
[00:45:28.947] iteration 21407 : model1 loss : 0.438880 model2 loss : 0.019701
[00:45:29.117] iteration 21408 : model1 loss : 0.440707 model2 loss : 0.018414
[00:45:29.282] iteration 21409 : model1 loss : 0.436380 model2 loss : 0.019190
[00:45:29.451] iteration 21410 : model1 loss : 0.435454 model2 loss : 0.017600
[00:45:29.619] iteration 21411 : model1 loss : 0.439123 model2 loss : 0.019350
[00:45:29.788] iteration 21412 : model1 loss : 0.441023 model2 loss : 0.020304
[00:45:29.957] iteration 21413 : model1 loss : 0.439307 model2 loss : 0.018250
[00:45:30.127] iteration 21414 : model1 loss : 0.438173 model2 loss : 0.019505
[00:45:30.293] iteration 21415 : model1 loss : 0.434691 model2 loss : 0.017874
[00:45:30.462] iteration 21416 : model1 loss : 0.441532 model2 loss : 0.018763
[00:45:30.629] iteration 21417 : model1 loss : 0.435139 model2 loss : 0.020241
[00:45:30.797] iteration 21418 : model1 loss : 0.442133 model2 loss : 0.018466
[00:45:30.964] iteration 21419 : model1 loss : 0.440179 model2 loss : 0.017610
[00:45:31.132] iteration 21420 : model1 loss : 0.441766 model2 loss : 0.022175
[00:45:33.166] iteration 21421 : model1 loss : 0.442703 model2 loss : 0.022642
[00:45:33.334] iteration 21422 : model1 loss : 0.436736 model2 loss : 0.020280
[00:45:33.506] iteration 21423 : model1 loss : 0.436097 model2 loss : 0.018527
[00:45:33.672] iteration 21424 : model1 loss : 0.440510 model2 loss : 0.019791
[00:45:33.842] iteration 21425 : model1 loss : 0.437615 model2 loss : 0.017556
[00:45:34.011] iteration 21426 : model1 loss : 0.439004 model2 loss : 0.018686
[00:45:34.183] iteration 21427 : model1 loss : 0.441307 model2 loss : 0.019606
[00:45:34.350] iteration 21428 : model1 loss : 0.438432 model2 loss : 0.018138
[00:45:34.520] iteration 21429 : model1 loss : 0.440092 model2 loss : 0.019792
[00:45:34.686] iteration 21430 : model1 loss : 0.441366 model2 loss : 0.020731
[00:45:34.855] iteration 21431 : model1 loss : 0.440960 model2 loss : 0.015556
[00:45:35.026] iteration 21432 : model1 loss : 0.437599 model2 loss : 0.020824
[00:45:35.194] iteration 21433 : model1 loss : 0.435146 model2 loss : 0.018823
[00:45:35.362] iteration 21434 : model1 loss : 0.439063 model2 loss : 0.018619
[00:45:35.532] iteration 21435 : model1 loss : 0.441430 model2 loss : 0.022925
[00:45:35.698] iteration 21436 : model1 loss : 0.441957 model2 loss : 0.021020
[00:45:35.867] iteration 21437 : model1 loss : 0.435477 model2 loss : 0.018145
[00:45:36.046] iteration 21438 : model1 loss : 0.436613 model2 loss : 0.019053
[00:45:36.219] iteration 21439 : model1 loss : 0.438691 model2 loss : 0.020747
[00:45:36.388] iteration 21440 : model1 loss : 0.440407 model2 loss : 0.021965
[00:45:36.555] iteration 21441 : model1 loss : 0.441160 model2 loss : 0.020184
[00:45:38.615] iteration 21442 : model1 loss : 0.436943 model2 loss : 0.018752
[00:45:38.779] iteration 21443 : model1 loss : 0.439552 model2 loss : 0.019294
[00:45:38.950] iteration 21444 : model1 loss : 0.439473 model2 loss : 0.019905
[00:45:39.117] iteration 21445 : model1 loss : 0.440500 model2 loss : 0.020568
[00:45:39.284] iteration 21446 : model1 loss : 0.440876 model2 loss : 0.018991
[00:45:39.452] iteration 21447 : model1 loss : 0.440559 model2 loss : 0.019166
[00:45:39.623] iteration 21448 : model1 loss : 0.440523 model2 loss : 0.018999
[00:45:39.790] iteration 21449 : model1 loss : 0.442080 model2 loss : 0.019951
[00:45:39.958] iteration 21450 : model1 loss : 0.437141 model2 loss : 0.017466
[00:45:40.128] iteration 21451 : model1 loss : 0.438269 model2 loss : 0.018860
[00:45:40.298] iteration 21452 : model1 loss : 0.437943 model2 loss : 0.020531
[00:45:40.467] iteration 21453 : model1 loss : 0.443893 model2 loss : 0.021228
[00:45:40.636] iteration 21454 : model1 loss : 0.440316 model2 loss : 0.017106
[00:45:40.802] iteration 21455 : model1 loss : 0.437293 model2 loss : 0.018332
[00:45:40.969] iteration 21456 : model1 loss : 0.441832 model2 loss : 0.017202
[00:45:41.137] iteration 21457 : model1 loss : 0.440839 model2 loss : 0.019914
[00:45:41.307] iteration 21458 : model1 loss : 0.440034 model2 loss : 0.020640
[00:45:41.474] iteration 21459 : model1 loss : 0.435910 model2 loss : 0.015214
[00:45:41.644] iteration 21460 : model1 loss : 0.434941 model2 loss : 0.018052
[00:45:41.808] iteration 21461 : model1 loss : 0.437968 model2 loss : 0.017422
[00:45:41.976] iteration 21462 : model1 loss : 0.434941 model2 loss : 0.018742
[00:45:44.033] iteration 21463 : model1 loss : 0.439066 model2 loss : 0.018759
[00:45:44.206] iteration 21464 : model1 loss : 0.437835 model2 loss : 0.016865
[00:45:44.376] iteration 21465 : model1 loss : 0.439605 model2 loss : 0.018551
[00:45:44.541] iteration 21466 : model1 loss : 0.438179 model2 loss : 0.019105
[00:45:44.712] iteration 21467 : model1 loss : 0.440860 model2 loss : 0.019173
[00:45:44.880] iteration 21468 : model1 loss : 0.437120 model2 loss : 0.017838
[00:45:45.052] iteration 21469 : model1 loss : 0.441346 model2 loss : 0.016842
[00:45:45.220] iteration 21470 : model1 loss : 0.436699 model2 loss : 0.019252
[00:45:45.387] iteration 21471 : model1 loss : 0.437041 model2 loss : 0.018881
[00:45:45.555] iteration 21472 : model1 loss : 0.442114 model2 loss : 0.018424
[00:45:45.723] iteration 21473 : model1 loss : 0.432392 model2 loss : 0.016077
[00:45:45.888] iteration 21474 : model1 loss : 0.435490 model2 loss : 0.017532
[00:45:46.057] iteration 21475 : model1 loss : 0.439979 model2 loss : 0.016076
[00:45:46.223] iteration 21476 : model1 loss : 0.439130 model2 loss : 0.018545
[00:45:46.391] iteration 21477 : model1 loss : 0.438063 model2 loss : 0.017642
[00:45:46.557] iteration 21478 : model1 loss : 0.440892 model2 loss : 0.017659
[00:45:46.726] iteration 21479 : model1 loss : 0.440950 model2 loss : 0.018208
[00:45:46.896] iteration 21480 : model1 loss : 0.439037 model2 loss : 0.017403
[00:45:47.067] iteration 21481 : model1 loss : 0.437482 model2 loss : 0.017042
[00:45:47.233] iteration 21482 : model1 loss : 0.437833 model2 loss : 0.019866
[00:45:47.402] iteration 21483 : model1 loss : 0.442363 model2 loss : 0.018248
[00:45:49.414] iteration 21484 : model1 loss : 0.437898 model2 loss : 0.018273
[00:45:49.585] iteration 21485 : model1 loss : 0.439577 model2 loss : 0.016674
[00:45:49.755] iteration 21486 : model1 loss : 0.436550 model2 loss : 0.017905
[00:45:49.924] iteration 21487 : model1 loss : 0.439562 model2 loss : 0.019552
[00:45:50.096] iteration 21488 : model1 loss : 0.435041 model2 loss : 0.016524
[00:45:50.262] iteration 21489 : model1 loss : 0.442883 model2 loss : 0.019718
[00:45:50.431] iteration 21490 : model1 loss : 0.440764 model2 loss : 0.019676
[00:45:50.597] iteration 21491 : model1 loss : 0.437329 model2 loss : 0.018902
[00:45:50.767] iteration 21492 : model1 loss : 0.439442 model2 loss : 0.020917
[00:45:50.937] iteration 21493 : model1 loss : 0.439298 model2 loss : 0.019245
[00:45:51.109] iteration 21494 : model1 loss : 0.441904 model2 loss : 0.021353
[00:45:51.275] iteration 21495 : model1 loss : 0.434019 model2 loss : 0.017343
[00:45:51.446] iteration 21496 : model1 loss : 0.440946 model2 loss : 0.018307
[00:45:51.612] iteration 21497 : model1 loss : 0.439309 model2 loss : 0.018665
[00:45:51.780] iteration 21498 : model1 loss : 0.439942 model2 loss : 0.018697
[00:45:51.945] iteration 21499 : model1 loss : 0.437981 model2 loss : 0.018573
[00:45:52.116] iteration 21500 : model1 loss : 0.439618 model2 loss : 0.017231
[00:45:52.283] iteration 21501 : model1 loss : 0.438243 model2 loss : 0.018646
[00:45:52.454] iteration 21502 : model1 loss : 0.438596 model2 loss : 0.020584
[00:45:52.620] iteration 21503 : model1 loss : 0.436385 model2 loss : 0.016926
[00:45:52.787] iteration 21504 : model1 loss : 0.441263 model2 loss : 0.018235
[00:45:54.830] iteration 21505 : model1 loss : 0.440206 model2 loss : 0.018752
[00:45:55.000] iteration 21506 : model1 loss : 0.439260 model2 loss : 0.016955
[00:45:55.170] iteration 21507 : model1 loss : 0.433738 model2 loss : 0.016333
[00:45:55.336] iteration 21508 : model1 loss : 0.439498 model2 loss : 0.018006
[00:45:55.505] iteration 21509 : model1 loss : 0.438236 model2 loss : 0.017237
[00:45:55.675] iteration 21510 : model1 loss : 0.436676 model2 loss : 0.016531
[00:45:55.846] iteration 21511 : model1 loss : 0.441743 model2 loss : 0.020739
[00:45:56.014] iteration 21512 : model1 loss : 0.442697 model2 loss : 0.015366
[00:45:56.182] iteration 21513 : model1 loss : 0.439362 model2 loss : 0.019522
[00:45:56.351] iteration 21514 : model1 loss : 0.438635 model2 loss : 0.020071
[00:45:56.522] iteration 21515 : model1 loss : 0.437798 model2 loss : 0.018780
[00:45:56.690] iteration 21516 : model1 loss : 0.440697 model2 loss : 0.016684
[00:45:56.861] iteration 21517 : model1 loss : 0.432739 model2 loss : 0.016846
[00:45:57.028] iteration 21518 : model1 loss : 0.439558 model2 loss : 0.017955
[00:45:57.198] iteration 21519 : model1 loss : 0.441433 model2 loss : 0.019721
[00:45:57.365] iteration 21520 : model1 loss : 0.441252 model2 loss : 0.017221
[00:45:57.533] iteration 21521 : model1 loss : 0.440093 model2 loss : 0.018287
[00:45:57.699] iteration 21522 : model1 loss : 0.435890 model2 loss : 0.019055
[00:45:57.869] iteration 21523 : model1 loss : 0.436410 model2 loss : 0.017782
[00:45:58.036] iteration 21524 : model1 loss : 0.441778 model2 loss : 0.019638
[00:45:58.202] iteration 21525 : model1 loss : 0.434758 model2 loss : 0.019103
[00:46:00.271] iteration 21526 : model1 loss : 0.437231 model2 loss : 0.018131
[00:46:00.439] iteration 21527 : model1 loss : 0.441853 model2 loss : 0.018358
[00:46:00.610] iteration 21528 : model1 loss : 0.442105 model2 loss : 0.019355
[00:46:00.777] iteration 21529 : model1 loss : 0.434402 model2 loss : 0.016774
[00:46:00.947] iteration 21530 : model1 loss : 0.440377 model2 loss : 0.018050
[00:46:01.116] iteration 21531 : model1 loss : 0.437935 model2 loss : 0.017762
[00:46:01.285] iteration 21532 : model1 loss : 0.441821 model2 loss : 0.019993
[00:46:01.453] iteration 21533 : model1 loss : 0.439995 model2 loss : 0.019674
[00:46:01.621] iteration 21534 : model1 loss : 0.438704 model2 loss : 0.017476
[00:46:01.789] iteration 21535 : model1 loss : 0.436516 model2 loss : 0.018357
[00:46:01.963] iteration 21536 : model1 loss : 0.433277 model2 loss : 0.016867
[00:46:02.132] iteration 21537 : model1 loss : 0.435383 model2 loss : 0.016535
[00:46:02.302] iteration 21538 : model1 loss : 0.444615 model2 loss : 0.020897
[00:46:02.472] iteration 21539 : model1 loss : 0.441419 model2 loss : 0.020811
[00:46:02.641] iteration 21540 : model1 loss : 0.437269 model2 loss : 0.017518
[00:46:02.809] iteration 21541 : model1 loss : 0.438662 model2 loss : 0.018719
[00:46:02.980] iteration 21542 : model1 loss : 0.440289 model2 loss : 0.017228
[00:46:03.147] iteration 21543 : model1 loss : 0.437222 model2 loss : 0.018843
[00:46:03.317] iteration 21544 : model1 loss : 0.441232 model2 loss : 0.019770
[00:46:03.482] iteration 21545 : model1 loss : 0.437371 model2 loss : 0.021184
[00:46:03.651] iteration 21546 : model1 loss : 0.436947 model2 loss : 0.016672
[00:46:05.674] iteration 21547 : model1 loss : 0.437467 model2 loss : 0.018792
[00:46:05.840] iteration 21548 : model1 loss : 0.440114 model2 loss : 0.020153
[00:46:06.010] iteration 21549 : model1 loss : 0.437302 model2 loss : 0.017418
[00:46:06.177] iteration 21550 : model1 loss : 0.436051 model2 loss : 0.018432
[00:46:06.352] iteration 21551 : model1 loss : 0.441701 model2 loss : 0.020491
[00:46:06.517] iteration 21552 : model1 loss : 0.438438 model2 loss : 0.019147
[00:46:06.686] iteration 21553 : model1 loss : 0.436738 model2 loss : 0.019692
[00:46:06.853] iteration 21554 : model1 loss : 0.440828 model2 loss : 0.020008
[00:46:07.025] iteration 21555 : model1 loss : 0.440226 model2 loss : 0.018525
[00:46:07.192] iteration 21556 : model1 loss : 0.440743 model2 loss : 0.019481
[00:46:07.365] iteration 21557 : model1 loss : 0.444399 model2 loss : 0.019632
[00:46:07.534] iteration 21558 : model1 loss : 0.438405 model2 loss : 0.017284
[00:46:07.701] iteration 21559 : model1 loss : 0.437350 model2 loss : 0.019966
[00:46:07.868] iteration 21560 : model1 loss : 0.439335 model2 loss : 0.019687
[00:46:08.039] iteration 21561 : model1 loss : 0.437472 model2 loss : 0.015860
[00:46:08.208] iteration 21562 : model1 loss : 0.437945 model2 loss : 0.019678
[00:46:08.377] iteration 21563 : model1 loss : 0.440102 model2 loss : 0.019526
[00:46:08.543] iteration 21564 : model1 loss : 0.440336 model2 loss : 0.020179
[00:46:08.712] iteration 21565 : model1 loss : 0.437132 model2 loss : 0.017946
[00:46:08.878] iteration 21566 : model1 loss : 0.438467 model2 loss : 0.019077
[00:46:09.046] iteration 21567 : model1 loss : 0.436481 model2 loss : 0.016121
[00:46:11.072] iteration 21568 : model1 loss : 0.436659 model2 loss : 0.018723
[00:46:11.236] iteration 21569 : model1 loss : 0.438103 model2 loss : 0.018204
[00:46:11.408] iteration 21570 : model1 loss : 0.443182 model2 loss : 0.020078
[00:46:11.574] iteration 21571 : model1 loss : 0.444000 model2 loss : 0.019721
[00:46:11.742] iteration 21572 : model1 loss : 0.445761 model2 loss : 0.021368
[00:46:11.911] iteration 21573 : model1 loss : 0.443821 model2 loss : 0.021465
[00:46:12.083] iteration 21574 : model1 loss : 0.438317 model2 loss : 0.017102
[00:46:12.250] iteration 21575 : model1 loss : 0.436805 model2 loss : 0.019787
[00:46:12.420] iteration 21576 : model1 loss : 0.437342 model2 loss : 0.020118
[00:46:12.588] iteration 21577 : model1 loss : 0.439722 model2 loss : 0.018856
[00:46:12.760] iteration 21578 : model1 loss : 0.438349 model2 loss : 0.019244
[00:46:12.927] iteration 21579 : model1 loss : 0.436788 model2 loss : 0.017594
[00:46:13.098] iteration 21580 : model1 loss : 0.438598 model2 loss : 0.018827
[00:46:13.265] iteration 21581 : model1 loss : 0.436385 model2 loss : 0.019764
[00:46:13.432] iteration 21582 : model1 loss : 0.435041 model2 loss : 0.017448
[00:46:13.600] iteration 21583 : model1 loss : 0.437073 model2 loss : 0.018202
[00:46:13.770] iteration 21584 : model1 loss : 0.440550 model2 loss : 0.019883
[00:46:13.937] iteration 21585 : model1 loss : 0.437911 model2 loss : 0.018312
[00:46:14.116] iteration 21586 : model1 loss : 0.438292 model2 loss : 0.018837
[00:46:14.279] iteration 21587 : model1 loss : 0.442082 model2 loss : 0.018471
[00:46:14.448] iteration 21588 : model1 loss : 0.435173 model2 loss : 0.018568
[00:46:16.459] iteration 21589 : model1 loss : 0.436496 model2 loss : 0.016583
[00:46:16.628] iteration 21590 : model1 loss : 0.441103 model2 loss : 0.018035
[00:46:16.800] iteration 21591 : model1 loss : 0.437419 model2 loss : 0.016422
[00:46:16.965] iteration 21592 : model1 loss : 0.441876 model2 loss : 0.018509
[00:46:17.134] iteration 21593 : model1 loss : 0.442428 model2 loss : 0.021337
[00:46:17.301] iteration 21594 : model1 loss : 0.439415 model2 loss : 0.017136
[00:46:17.472] iteration 21595 : model1 loss : 0.441334 model2 loss : 0.018570
[00:46:17.640] iteration 21596 : model1 loss : 0.443535 model2 loss : 0.018919
[00:46:17.809] iteration 21597 : model1 loss : 0.439764 model2 loss : 0.019498
[00:46:17.978] iteration 21598 : model1 loss : 0.439656 model2 loss : 0.020285
[00:46:18.146] iteration 21599 : model1 loss : 0.436085 model2 loss : 0.018280
[00:46:18.315] iteration 21600 : model1 loss : 0.441001 model2 loss : 0.018715
[00:46:18.483] iteration 21601 : model1 loss : 0.435143 model2 loss : 0.016875
[00:46:18.648] iteration 21602 : model1 loss : 0.434209 model2 loss : 0.018126
[00:46:18.819] iteration 21603 : model1 loss : 0.440389 model2 loss : 0.019487
[00:46:18.990] iteration 21604 : model1 loss : 0.435364 model2 loss : 0.018924
[00:46:19.157] iteration 21605 : model1 loss : 0.436378 model2 loss : 0.016305
[00:46:19.326] iteration 21606 : model1 loss : 0.440519 model2 loss : 0.018049
[00:46:19.496] iteration 21607 : model1 loss : 0.437276 model2 loss : 0.017984
[00:46:19.663] iteration 21608 : model1 loss : 0.437555 model2 loss : 0.018775
[00:46:19.830] iteration 21609 : model1 loss : 0.439090 model2 loss : 0.018238
[00:46:21.857] iteration 21610 : model1 loss : 0.439034 model2 loss : 0.017456
[00:46:22.032] iteration 21611 : model1 loss : 0.441551 model2 loss : 0.018640
[00:46:22.203] iteration 21612 : model1 loss : 0.436516 model2 loss : 0.018269
[00:46:22.370] iteration 21613 : model1 loss : 0.439562 model2 loss : 0.019602
[00:46:22.539] iteration 21614 : model1 loss : 0.436496 model2 loss : 0.017595
[00:46:22.707] iteration 21615 : model1 loss : 0.439062 model2 loss : 0.017435
[00:46:22.879] iteration 21616 : model1 loss : 0.436682 model2 loss : 0.016582
[00:46:23.046] iteration 21617 : model1 loss : 0.439100 model2 loss : 0.019074
[00:46:23.215] iteration 21618 : model1 loss : 0.437556 model2 loss : 0.017486
[00:46:23.383] iteration 21619 : model1 loss : 0.437340 model2 loss : 0.017014
[00:46:23.551] iteration 21620 : model1 loss : 0.440642 model2 loss : 0.020198
[00:46:23.717] iteration 21621 : model1 loss : 0.439529 model2 loss : 0.016440
[00:46:23.887] iteration 21622 : model1 loss : 0.436586 model2 loss : 0.015179
[00:46:24.054] iteration 21623 : model1 loss : 0.438899 model2 loss : 0.018424
[00:46:24.225] iteration 21624 : model1 loss : 0.439104 model2 loss : 0.018199
[00:46:24.391] iteration 21625 : model1 loss : 0.438596 model2 loss : 0.018689
[00:46:24.560] iteration 21626 : model1 loss : 0.440876 model2 loss : 0.019611
[00:46:24.727] iteration 21627 : model1 loss : 0.442660 model2 loss : 0.016465
[00:46:24.897] iteration 21628 : model1 loss : 0.436621 model2 loss : 0.020824
[00:46:25.063] iteration 21629 : model1 loss : 0.442329 model2 loss : 0.020856
[00:46:25.230] iteration 21630 : model1 loss : 0.438945 model2 loss : 0.020124
[00:46:27.299] iteration 21631 : model1 loss : 0.438938 model2 loss : 0.016753
[00:46:27.471] iteration 21632 : model1 loss : 0.443336 model2 loss : 0.019355
[00:46:27.638] iteration 21633 : model1 loss : 0.439713 model2 loss : 0.017094
[00:46:27.803] iteration 21634 : model1 loss : 0.435907 model2 loss : 0.016822
[00:46:27.974] iteration 21635 : model1 loss : 0.438098 model2 loss : 0.017701
[00:46:28.142] iteration 21636 : model1 loss : 0.443729 model2 loss : 0.020281
[00:46:28.315] iteration 21637 : model1 loss : 0.443893 model2 loss : 0.017997
[00:46:28.482] iteration 21638 : model1 loss : 0.435459 model2 loss : 0.019034
[00:46:28.651] iteration 21639 : model1 loss : 0.438628 model2 loss : 0.019438
[00:46:28.819] iteration 21640 : model1 loss : 0.442356 model2 loss : 0.017198
[00:46:28.990] iteration 21641 : model1 loss : 0.433633 model2 loss : 0.017081
[00:46:29.169] iteration 21642 : model1 loss : 0.438521 model2 loss : 0.019370
[00:46:29.338] iteration 21643 : model1 loss : 0.437160 model2 loss : 0.018456
[00:46:29.506] iteration 21644 : model1 loss : 0.436264 model2 loss : 0.019074
[00:46:29.673] iteration 21645 : model1 loss : 0.440684 model2 loss : 0.018630
[00:46:29.843] iteration 21646 : model1 loss : 0.438956 model2 loss : 0.017071
[00:46:30.013] iteration 21647 : model1 loss : 0.438499 model2 loss : 0.018522
[00:46:30.181] iteration 21648 : model1 loss : 0.435265 model2 loss : 0.017580
[00:46:30.350] iteration 21649 : model1 loss : 0.442835 model2 loss : 0.018894
[00:46:30.515] iteration 21650 : model1 loss : 0.440265 model2 loss : 0.018569
[00:46:30.682] iteration 21651 : model1 loss : 0.436359 model2 loss : 0.019462
[00:46:32.741] iteration 21652 : model1 loss : 0.438896 model2 loss : 0.019305
[00:46:32.907] iteration 21653 : model1 loss : 0.440900 model2 loss : 0.017513
[00:46:33.077] iteration 21654 : model1 loss : 0.439362 model2 loss : 0.018084
[00:46:33.247] iteration 21655 : model1 loss : 0.438239 model2 loss : 0.017898
[00:46:33.416] iteration 21656 : model1 loss : 0.437318 model2 loss : 0.019597
[00:46:33.581] iteration 21657 : model1 loss : 0.435373 model2 loss : 0.018184
[00:46:33.752] iteration 21658 : model1 loss : 0.437948 model2 loss : 0.019843
[00:46:33.918] iteration 21659 : model1 loss : 0.434801 model2 loss : 0.017241
[00:46:34.090] iteration 21660 : model1 loss : 0.436192 model2 loss : 0.019141
[00:46:34.257] iteration 21661 : model1 loss : 0.440354 model2 loss : 0.019075
[00:46:34.424] iteration 21662 : model1 loss : 0.443995 model2 loss : 0.019851
[00:46:34.592] iteration 21663 : model1 loss : 0.438992 model2 loss : 0.017601
[00:46:34.761] iteration 21664 : model1 loss : 0.441855 model2 loss : 0.019211
[00:46:34.927] iteration 21665 : model1 loss : 0.438889 model2 loss : 0.017172
[00:46:35.101] iteration 21666 : model1 loss : 0.439194 model2 loss : 0.017378
[00:46:35.269] iteration 21667 : model1 loss : 0.442165 model2 loss : 0.017550
[00:46:35.440] iteration 21668 : model1 loss : 0.443970 model2 loss : 0.018918
[00:46:35.610] iteration 21669 : model1 loss : 0.441206 model2 loss : 0.019477
[00:46:35.776] iteration 21670 : model1 loss : 0.435490 model2 loss : 0.018085
[00:46:35.941] iteration 21671 : model1 loss : 0.435843 model2 loss : 0.018035
[00:46:36.116] iteration 21672 : model1 loss : 0.438219 model2 loss : 0.018522
[00:46:38.189] iteration 21673 : model1 loss : 0.439804 model2 loss : 0.019637
[00:46:38.363] iteration 21674 : model1 loss : 0.440674 model2 loss : 0.019109
[00:46:38.534] iteration 21675 : model1 loss : 0.436056 model2 loss : 0.019324
[00:46:38.706] iteration 21676 : model1 loss : 0.440256 model2 loss : 0.018098
[00:46:38.878] iteration 21677 : model1 loss : 0.435440 model2 loss : 0.018264
[00:46:39.044] iteration 21678 : model1 loss : 0.440675 model2 loss : 0.019371
[00:46:39.215] iteration 21679 : model1 loss : 0.441270 model2 loss : 0.019950
[00:46:39.382] iteration 21680 : model1 loss : 0.441464 model2 loss : 0.018831
[00:46:39.550] iteration 21681 : model1 loss : 0.439878 model2 loss : 0.018148
[00:46:39.720] iteration 21682 : model1 loss : 0.440817 model2 loss : 0.018441
[00:46:39.890] iteration 21683 : model1 loss : 0.439423 model2 loss : 0.017295
[00:46:40.058] iteration 21684 : model1 loss : 0.435135 model2 loss : 0.016885
[00:46:40.226] iteration 21685 : model1 loss : 0.436882 model2 loss : 0.017747
[00:46:40.393] iteration 21686 : model1 loss : 0.440569 model2 loss : 0.018758
[00:46:40.562] iteration 21687 : model1 loss : 0.444020 model2 loss : 0.018113
[00:46:40.729] iteration 21688 : model1 loss : 0.435099 model2 loss : 0.016622
[00:46:40.898] iteration 21689 : model1 loss : 0.439326 model2 loss : 0.020277
[00:46:41.069] iteration 21690 : model1 loss : 0.433990 model2 loss : 0.017986
[00:46:41.239] iteration 21691 : model1 loss : 0.439498 model2 loss : 0.015936
[00:46:41.404] iteration 21692 : model1 loss : 0.438937 model2 loss : 0.019448
[00:46:41.572] iteration 21693 : model1 loss : 0.437532 model2 loss : 0.017808
[00:46:43.618] iteration 21694 : model1 loss : 0.438288 model2 loss : 0.015798
[00:46:43.787] iteration 21695 : model1 loss : 0.436556 model2 loss : 0.017166
[00:46:43.957] iteration 21696 : model1 loss : 0.439934 model2 loss : 0.016759
[00:46:44.126] iteration 21697 : model1 loss : 0.434500 model2 loss : 0.018794
[00:46:44.296] iteration 21698 : model1 loss : 0.440674 model2 loss : 0.016602
[00:46:44.463] iteration 21699 : model1 loss : 0.433644 model2 loss : 0.018162
[00:46:44.634] iteration 21700 : model1 loss : 0.433215 model2 loss : 0.017817
[00:46:44.802] iteration 21701 : model1 loss : 0.437723 model2 loss : 0.018363
[00:46:44.973] iteration 21702 : model1 loss : 0.441411 model2 loss : 0.017703
[00:46:45.140] iteration 21703 : model1 loss : 0.436261 model2 loss : 0.016843
[00:46:45.313] iteration 21704 : model1 loss : 0.444715 model2 loss : 0.021575
[00:46:45.480] iteration 21705 : model1 loss : 0.438685 model2 loss : 0.019637
[00:46:45.648] iteration 21706 : model1 loss : 0.439880 model2 loss : 0.019412
[00:46:45.816] iteration 21707 : model1 loss : 0.434705 model2 loss : 0.017596
[00:46:45.984] iteration 21708 : model1 loss : 0.444358 model2 loss : 0.021690
[00:46:46.152] iteration 21709 : model1 loss : 0.440949 model2 loss : 0.018989
[00:46:46.323] iteration 21710 : model1 loss : 0.438132 model2 loss : 0.018225
[00:46:46.491] iteration 21711 : model1 loss : 0.440585 model2 loss : 0.017317
[00:46:46.659] iteration 21712 : model1 loss : 0.441375 model2 loss : 0.019192
[00:46:46.827] iteration 21713 : model1 loss : 0.440676 model2 loss : 0.018959
[00:46:46.996] iteration 21714 : model1 loss : 0.440743 model2 loss : 0.018684
[00:46:49.034] iteration 21715 : model1 loss : 0.435631 model2 loss : 0.018733
[00:46:49.202] iteration 21716 : model1 loss : 0.438053 model2 loss : 0.019055
[00:46:49.371] iteration 21717 : model1 loss : 0.441481 model2 loss : 0.018567
[00:46:49.538] iteration 21718 : model1 loss : 0.442270 model2 loss : 0.018597
[00:46:49.708] iteration 21719 : model1 loss : 0.441263 model2 loss : 0.020917
[00:46:49.876] iteration 21720 : model1 loss : 0.438390 model2 loss : 0.017080
[00:46:50.045] iteration 21721 : model1 loss : 0.436660 model2 loss : 0.018924
[00:46:50.212] iteration 21722 : model1 loss : 0.442835 model2 loss : 0.020209
[00:46:50.382] iteration 21723 : model1 loss : 0.434449 model2 loss : 0.019162
[00:46:50.550] iteration 21724 : model1 loss : 0.439293 model2 loss : 0.018086
[00:46:50.719] iteration 21725 : model1 loss : 0.435122 model2 loss : 0.018422
[00:46:50.886] iteration 21726 : model1 loss : 0.440621 model2 loss : 0.017577
[00:46:51.056] iteration 21727 : model1 loss : 0.441014 model2 loss : 0.017508
[00:46:51.225] iteration 21728 : model1 loss : 0.441095 model2 loss : 0.018686
[00:46:51.410] iteration 21729 : model1 loss : 0.436749 model2 loss : 0.018503
[00:46:51.577] iteration 21730 : model1 loss : 0.440295 model2 loss : 0.019537
[00:46:51.748] iteration 21731 : model1 loss : 0.436078 model2 loss : 0.016490
[00:46:51.917] iteration 21732 : model1 loss : 0.441121 model2 loss : 0.017154
[00:46:52.088] iteration 21733 : model1 loss : 0.436357 model2 loss : 0.018059
[00:46:52.253] iteration 21734 : model1 loss : 0.440458 model2 loss : 0.018292
[00:46:52.425] iteration 21735 : model1 loss : 0.440025 model2 loss : 0.019242
[00:46:54.449] iteration 21736 : model1 loss : 0.436300 model2 loss : 0.017393
[00:46:54.616] iteration 21737 : model1 loss : 0.439541 model2 loss : 0.017081
[00:46:54.786] iteration 21738 : model1 loss : 0.436389 model2 loss : 0.015624
[00:46:54.953] iteration 21739 : model1 loss : 0.442185 model2 loss : 0.018867
[00:46:55.137] iteration 21740 : model1 loss : 0.435739 model2 loss : 0.017536
[00:46:55.304] iteration 21741 : model1 loss : 0.441974 model2 loss : 0.020292
[00:46:55.473] iteration 21742 : model1 loss : 0.440752 model2 loss : 0.017768
[00:46:55.641] iteration 21743 : model1 loss : 0.438183 model2 loss : 0.020811
[00:46:55.810] iteration 21744 : model1 loss : 0.439469 model2 loss : 0.019510
[00:46:55.978] iteration 21745 : model1 loss : 0.442030 model2 loss : 0.016718
[00:46:56.147] iteration 21746 : model1 loss : 0.439422 model2 loss : 0.018628
[00:46:56.316] iteration 21747 : model1 loss : 0.436920 model2 loss : 0.017115
[00:46:56.483] iteration 21748 : model1 loss : 0.437768 model2 loss : 0.019430
[00:46:56.653] iteration 21749 : model1 loss : 0.438816 model2 loss : 0.017315
[00:46:56.835] iteration 21750 : model1 loss : 0.440510 model2 loss : 0.019575
[00:46:57.002] iteration 21751 : model1 loss : 0.437401 model2 loss : 0.018684
[00:46:57.172] iteration 21752 : model1 loss : 0.442638 model2 loss : 0.020571
[00:46:57.340] iteration 21753 : model1 loss : 0.436838 model2 loss : 0.017882
[00:46:57.511] iteration 21754 : model1 loss : 0.441229 model2 loss : 0.018533
[00:46:57.676] iteration 21755 : model1 loss : 0.433802 model2 loss : 0.021363
[00:46:57.848] iteration 21756 : model1 loss : 0.442606 model2 loss : 0.018946
[00:46:59.854] iteration 21757 : model1 loss : 0.437201 model2 loss : 0.016912
[00:47:00.022] iteration 21758 : model1 loss : 0.438288 model2 loss : 0.018157
[00:47:00.196] iteration 21759 : model1 loss : 0.441743 model2 loss : 0.018861
[00:47:00.367] iteration 21760 : model1 loss : 0.438268 model2 loss : 0.020283
[00:47:00.538] iteration 21761 : model1 loss : 0.437523 model2 loss : 0.016499
[00:47:00.706] iteration 21762 : model1 loss : 0.441080 model2 loss : 0.019511
[00:47:00.878] iteration 21763 : model1 loss : 0.439678 model2 loss : 0.019380
[00:47:01.047] iteration 21764 : model1 loss : 0.439519 model2 loss : 0.017022
[00:47:01.217] iteration 21765 : model1 loss : 0.439692 model2 loss : 0.017562
[00:47:01.385] iteration 21766 : model1 loss : 0.436421 model2 loss : 0.018190
[00:47:01.553] iteration 21767 : model1 loss : 0.440225 model2 loss : 0.021492
[00:47:01.721] iteration 21768 : model1 loss : 0.439942 model2 loss : 0.017547
[00:47:01.892] iteration 21769 : model1 loss : 0.444142 model2 loss : 0.019314
[00:47:02.060] iteration 21770 : model1 loss : 0.438694 model2 loss : 0.017694
[00:47:02.230] iteration 21771 : model1 loss : 0.437437 model2 loss : 0.021038
[00:47:02.396] iteration 21772 : model1 loss : 0.437732 model2 loss : 0.018184
[00:47:02.568] iteration 21773 : model1 loss : 0.439776 model2 loss : 0.019814
[00:47:02.737] iteration 21774 : model1 loss : 0.435856 model2 loss : 0.018852
[00:47:02.910] iteration 21775 : model1 loss : 0.440161 model2 loss : 0.018450
[00:47:03.079] iteration 21776 : model1 loss : 0.440526 model2 loss : 0.021540
[00:47:03.246] iteration 21777 : model1 loss : 0.439202 model2 loss : 0.017950
[00:47:05.311] iteration 21778 : model1 loss : 0.437251 model2 loss : 0.019637
[00:47:05.481] iteration 21779 : model1 loss : 0.440553 model2 loss : 0.019433
[00:47:05.652] iteration 21780 : model1 loss : 0.437899 model2 loss : 0.017883
[00:47:05.820] iteration 21781 : model1 loss : 0.441461 model2 loss : 0.018159
[00:47:05.989] iteration 21782 : model1 loss : 0.438988 model2 loss : 0.017362
[00:47:06.156] iteration 21783 : model1 loss : 0.440919 model2 loss : 0.022948
[00:47:06.331] iteration 21784 : model1 loss : 0.438909 model2 loss : 0.016396
[00:47:06.499] iteration 21785 : model1 loss : 0.437041 model2 loss : 0.016830
[00:47:06.670] iteration 21786 : model1 loss : 0.438380 model2 loss : 0.016641
[00:47:06.837] iteration 21787 : model1 loss : 0.440029 model2 loss : 0.018170
[00:47:07.010] iteration 21788 : model1 loss : 0.436122 model2 loss : 0.016947
[00:47:07.176] iteration 21789 : model1 loss : 0.436381 model2 loss : 0.018362
[00:47:07.348] iteration 21790 : model1 loss : 0.442278 model2 loss : 0.020622
[00:47:07.516] iteration 21791 : model1 loss : 0.439517 model2 loss : 0.019439
[00:47:07.686] iteration 21792 : model1 loss : 0.440282 model2 loss : 0.017453
[00:47:07.854] iteration 21793 : model1 loss : 0.438849 model2 loss : 0.017315
[00:47:08.025] iteration 21794 : model1 loss : 0.444112 model2 loss : 0.018453
[00:47:08.195] iteration 21795 : model1 loss : 0.434083 model2 loss : 0.019385
[00:47:08.364] iteration 21796 : model1 loss : 0.439495 model2 loss : 0.018572
[00:47:08.530] iteration 21797 : model1 loss : 0.438885 model2 loss : 0.016637
[00:47:08.699] iteration 21798 : model1 loss : 0.438785 model2 loss : 0.017823
[00:47:10.735] iteration 21799 : model1 loss : 0.434075 model2 loss : 0.017110
[00:47:10.903] iteration 21800 : model1 loss : 0.440281 model2 loss : 0.019226
[00:47:11.075] iteration 21801 : model1 loss : 0.436818 model2 loss : 0.018541
[00:47:11.240] iteration 21802 : model1 loss : 0.433801 model2 loss : 0.017483
[00:47:11.411] iteration 21803 : model1 loss : 0.442597 model2 loss : 0.022581
[00:47:11.578] iteration 21804 : model1 loss : 0.436291 model2 loss : 0.016906
[00:47:11.750] iteration 21805 : model1 loss : 0.444936 model2 loss : 0.022370
[00:47:11.920] iteration 21806 : model1 loss : 0.442399 model2 loss : 0.020363
[00:47:12.091] iteration 21807 : model1 loss : 0.443004 model2 loss : 0.019650
[00:47:12.260] iteration 21808 : model1 loss : 0.436804 model2 loss : 0.016680
[00:47:12.432] iteration 21809 : model1 loss : 0.438260 model2 loss : 0.017542
[00:47:12.600] iteration 21810 : model1 loss : 0.437810 model2 loss : 0.019860
[00:47:12.771] iteration 21811 : model1 loss : 0.438213 model2 loss : 0.019136
[00:47:12.940] iteration 21812 : model1 loss : 0.433020 model2 loss : 0.018535
[00:47:13.111] iteration 21813 : model1 loss : 0.437836 model2 loss : 0.016172
[00:47:13.278] iteration 21814 : model1 loss : 0.442281 model2 loss : 0.019767
[00:47:13.449] iteration 21815 : model1 loss : 0.442200 model2 loss : 0.019109
[00:47:13.618] iteration 21816 : model1 loss : 0.440703 model2 loss : 0.018648
[00:47:13.788] iteration 21817 : model1 loss : 0.440266 model2 loss : 0.018298
[00:47:13.953] iteration 21818 : model1 loss : 0.436547 model2 loss : 0.016956
[00:47:14.123] iteration 21819 : model1 loss : 0.442854 model2 loss : 0.019914
[00:47:16.168] iteration 21820 : model1 loss : 0.436765 model2 loss : 0.016755
[00:47:16.343] iteration 21821 : model1 loss : 0.438148 model2 loss : 0.018305
[00:47:16.515] iteration 21822 : model1 loss : 0.438245 model2 loss : 0.018215
[00:47:16.683] iteration 21823 : model1 loss : 0.437646 model2 loss : 0.018660
[00:47:16.854] iteration 21824 : model1 loss : 0.442783 model2 loss : 0.020517
[00:47:17.023] iteration 21825 : model1 loss : 0.439522 model2 loss : 0.016781
[00:47:17.191] iteration 21826 : model1 loss : 0.438100 model2 loss : 0.017658
[00:47:17.359] iteration 21827 : model1 loss : 0.435901 model2 loss : 0.019011
[00:47:17.527] iteration 21828 : model1 loss : 0.431568 model2 loss : 0.017811
[00:47:17.695] iteration 21829 : model1 loss : 0.438381 model2 loss : 0.018364
[00:47:17.865] iteration 21830 : model1 loss : 0.440208 model2 loss : 0.017917
[00:47:18.032] iteration 21831 : model1 loss : 0.440211 model2 loss : 0.016600
[00:47:18.201] iteration 21832 : model1 loss : 0.446378 model2 loss : 0.021492
[00:47:18.370] iteration 21833 : model1 loss : 0.438550 model2 loss : 0.018042
[00:47:18.539] iteration 21834 : model1 loss : 0.441879 model2 loss : 0.020261
[00:47:18.706] iteration 21835 : model1 loss : 0.437316 model2 loss : 0.018565
[00:47:18.877] iteration 21836 : model1 loss : 0.440456 model2 loss : 0.022942
[00:47:19.045] iteration 21837 : model1 loss : 0.439752 model2 loss : 0.019375
[00:47:19.214] iteration 21838 : model1 loss : 0.440674 model2 loss : 0.020213
[00:47:19.379] iteration 21839 : model1 loss : 0.438995 model2 loss : 0.019403
[00:47:19.546] iteration 21840 : model1 loss : 0.439914 model2 loss : 0.019786
[00:47:21.566] iteration 21841 : model1 loss : 0.444540 model2 loss : 0.021495
[00:47:21.734] iteration 21842 : model1 loss : 0.441101 model2 loss : 0.018209
[00:47:21.905] iteration 21843 : model1 loss : 0.441887 model2 loss : 0.016040
[00:47:22.074] iteration 21844 : model1 loss : 0.438266 model2 loss : 0.019528
[00:47:22.245] iteration 21845 : model1 loss : 0.437776 model2 loss : 0.017580
[00:47:22.414] iteration 21846 : model1 loss : 0.436896 model2 loss : 0.019069
[00:47:22.583] iteration 21847 : model1 loss : 0.437505 model2 loss : 0.018895
[00:47:22.749] iteration 21848 : model1 loss : 0.434799 model2 loss : 0.018828
[00:47:22.919] iteration 21849 : model1 loss : 0.433928 model2 loss : 0.019009
[00:47:23.090] iteration 21850 : model1 loss : 0.438237 model2 loss : 0.018136
[00:47:23.258] iteration 21851 : model1 loss : 0.440725 model2 loss : 0.018492
[00:47:23.425] iteration 21852 : model1 loss : 0.439800 model2 loss : 0.019531
[00:47:23.596] iteration 21853 : model1 loss : 0.439901 model2 loss : 0.021372
[00:47:23.767] iteration 21854 : model1 loss : 0.440941 model2 loss : 0.018957
[00:47:23.938] iteration 21855 : model1 loss : 0.444869 model2 loss : 0.019822
[00:47:24.112] iteration 21856 : model1 loss : 0.438938 model2 loss : 0.018039
[00:47:24.284] iteration 21857 : model1 loss : 0.441359 model2 loss : 0.020412
[00:47:24.450] iteration 21858 : model1 loss : 0.438907 model2 loss : 0.016123
[00:47:24.621] iteration 21859 : model1 loss : 0.441280 model2 loss : 0.019732
[00:47:24.788] iteration 21860 : model1 loss : 0.434726 model2 loss : 0.016549
[00:47:24.956] iteration 21861 : model1 loss : 0.437276 model2 loss : 0.019280
[00:47:26.971] iteration 21862 : model1 loss : 0.437337 model2 loss : 0.017567
[00:47:27.143] iteration 21863 : model1 loss : 0.436285 model2 loss : 0.017250
[00:47:27.315] iteration 21864 : model1 loss : 0.441221 model2 loss : 0.018848
[00:47:27.487] iteration 21865 : model1 loss : 0.435457 model2 loss : 0.017185
[00:47:27.654] iteration 21866 : model1 loss : 0.439265 model2 loss : 0.019767
[00:47:27.822] iteration 21867 : model1 loss : 0.436585 model2 loss : 0.017981
[00:47:27.994] iteration 21868 : model1 loss : 0.439660 model2 loss : 0.020340
[00:47:28.161] iteration 21869 : model1 loss : 0.441642 model2 loss : 0.019505
[00:47:28.332] iteration 21870 : model1 loss : 0.439963 model2 loss : 0.017175
[00:47:28.499] iteration 21871 : model1 loss : 0.437808 model2 loss : 0.016977
[00:47:28.667] iteration 21872 : model1 loss : 0.440597 model2 loss : 0.018761
[00:47:28.834] iteration 21873 : model1 loss : 0.440807 model2 loss : 0.019406
[00:47:29.005] iteration 21874 : model1 loss : 0.443487 model2 loss : 0.018968
[00:47:29.174] iteration 21875 : model1 loss : 0.436190 model2 loss : 0.017601
[00:47:29.343] iteration 21876 : model1 loss : 0.440034 model2 loss : 0.019396
[00:47:29.508] iteration 21877 : model1 loss : 0.441411 model2 loss : 0.020076
[00:47:29.678] iteration 21878 : model1 loss : 0.434697 model2 loss : 0.016902
[00:47:29.847] iteration 21879 : model1 loss : 0.442018 model2 loss : 0.020278
[00:47:30.018] iteration 21880 : model1 loss : 0.442826 model2 loss : 0.018668
[00:47:30.188] iteration 21881 : model1 loss : 0.436858 model2 loss : 0.018388
[00:47:30.356] iteration 21882 : model1 loss : 0.435303 model2 loss : 0.018654
[00:47:32.390] iteration 21883 : model1 loss : 0.436239 model2 loss : 0.018759
[00:47:32.564] iteration 21884 : model1 loss : 0.438447 model2 loss : 0.018869
[00:47:32.736] iteration 21885 : model1 loss : 0.434542 model2 loss : 0.016758
[00:47:32.905] iteration 21886 : model1 loss : 0.436682 model2 loss : 0.018070
[00:47:33.075] iteration 21887 : model1 loss : 0.443359 model2 loss : 0.019898
[00:47:33.240] iteration 21888 : model1 loss : 0.438917 model2 loss : 0.018591
[00:47:33.410] iteration 21889 : model1 loss : 0.438695 model2 loss : 0.018120
[00:47:33.578] iteration 21890 : model1 loss : 0.441901 model2 loss : 0.018489
[00:47:33.746] iteration 21891 : model1 loss : 0.435715 model2 loss : 0.021179
[00:47:33.915] iteration 21892 : model1 loss : 0.438404 model2 loss : 0.018428
[00:47:34.087] iteration 21893 : model1 loss : 0.439590 model2 loss : 0.018475
[00:47:34.255] iteration 21894 : model1 loss : 0.445311 model2 loss : 0.021095
[00:47:34.423] iteration 21895 : model1 loss : 0.443380 model2 loss : 0.019740
[00:47:34.592] iteration 21896 : model1 loss : 0.435007 model2 loss : 0.018502
[00:47:34.762] iteration 21897 : model1 loss : 0.440606 model2 loss : 0.018422
[00:47:34.931] iteration 21898 : model1 loss : 0.440169 model2 loss : 0.018564
[00:47:35.104] iteration 21899 : model1 loss : 0.435661 model2 loss : 0.016322
[00:47:35.271] iteration 21900 : model1 loss : 0.441377 model2 loss : 0.018577
[00:47:35.440] iteration 21901 : model1 loss : 0.435715 model2 loss : 0.015741
[00:47:35.607] iteration 21902 : model1 loss : 0.438331 model2 loss : 0.017949
[00:47:35.776] iteration 21903 : model1 loss : 0.442297 model2 loss : 0.021824
[00:47:37.819] iteration 21904 : model1 loss : 0.438449 model2 loss : 0.017295
[00:47:37.987] iteration 21905 : model1 loss : 0.441427 model2 loss : 0.019864
[00:47:38.156] iteration 21906 : model1 loss : 0.439495 model2 loss : 0.019699
[00:47:38.330] iteration 21907 : model1 loss : 0.443527 model2 loss : 0.021791
[00:47:38.499] iteration 21908 : model1 loss : 0.443902 model2 loss : 0.021475
[00:47:38.669] iteration 21909 : model1 loss : 0.434620 model2 loss : 0.017863
[00:47:38.839] iteration 21910 : model1 loss : 0.435671 model2 loss : 0.016739
[00:47:39.008] iteration 21911 : model1 loss : 0.441651 model2 loss : 0.020104
[00:47:39.178] iteration 21912 : model1 loss : 0.439140 model2 loss : 0.017789
[00:47:39.346] iteration 21913 : model1 loss : 0.438044 model2 loss : 0.017220
[00:47:39.513] iteration 21914 : model1 loss : 0.443504 model2 loss : 0.021383
[00:47:39.682] iteration 21915 : model1 loss : 0.440541 model2 loss : 0.017805
[00:47:39.852] iteration 21916 : model1 loss : 0.442753 model2 loss : 0.019770
[00:47:40.019] iteration 21917 : model1 loss : 0.435306 model2 loss : 0.016772
[00:47:40.187] iteration 21918 : model1 loss : 0.436267 model2 loss : 0.017936
[00:47:40.355] iteration 21919 : model1 loss : 0.436045 model2 loss : 0.018343
[00:47:40.526] iteration 21920 : model1 loss : 0.436722 model2 loss : 0.016962
[00:47:40.693] iteration 21921 : model1 loss : 0.439456 model2 loss : 0.018663
[00:47:40.862] iteration 21922 : model1 loss : 0.435306 model2 loss : 0.019435
[00:47:41.028] iteration 21923 : model1 loss : 0.440269 model2 loss : 0.017859
[00:47:41.195] iteration 21924 : model1 loss : 0.439609 model2 loss : 0.016411
[00:47:43.203] iteration 21925 : model1 loss : 0.440012 model2 loss : 0.021039
[00:47:43.371] iteration 21926 : model1 loss : 0.438787 model2 loss : 0.019296
[00:47:43.543] iteration 21927 : model1 loss : 0.437851 model2 loss : 0.016768
[00:47:43.713] iteration 21928 : model1 loss : 0.441444 model2 loss : 0.016713
[00:47:43.883] iteration 21929 : model1 loss : 0.439558 model2 loss : 0.018599
[00:47:44.052] iteration 21930 : model1 loss : 0.441514 model2 loss : 0.017318
[00:47:44.221] iteration 21931 : model1 loss : 0.441018 model2 loss : 0.018996
[00:47:44.389] iteration 21932 : model1 loss : 0.438117 model2 loss : 0.020389
[00:47:44.558] iteration 21933 : model1 loss : 0.441940 model2 loss : 0.018402
[00:47:44.727] iteration 21934 : model1 loss : 0.441582 model2 loss : 0.018809
[00:47:44.898] iteration 21935 : model1 loss : 0.435300 model2 loss : 0.017555
[00:47:45.065] iteration 21936 : model1 loss : 0.441091 model2 loss : 0.016483
[00:47:45.233] iteration 21937 : model1 loss : 0.439499 model2 loss : 0.016208
[00:47:45.400] iteration 21938 : model1 loss : 0.435483 model2 loss : 0.018554
[00:47:45.569] iteration 21939 : model1 loss : 0.437349 model2 loss : 0.016382
[00:47:45.736] iteration 21940 : model1 loss : 0.442276 model2 loss : 0.017386
[00:47:45.907] iteration 21941 : model1 loss : 0.438934 model2 loss : 0.016760
[00:47:46.074] iteration 21942 : model1 loss : 0.440153 model2 loss : 0.018363
[00:47:46.242] iteration 21943 : model1 loss : 0.432382 model2 loss : 0.018757
[00:47:46.407] iteration 21944 : model1 loss : 0.437041 model2 loss : 0.017630
[00:47:46.575] iteration 21945 : model1 loss : 0.438319 model2 loss : 0.019070
[00:47:48.609] iteration 21946 : model1 loss : 0.435453 model2 loss : 0.018233
[00:47:48.775] iteration 21947 : model1 loss : 0.442099 model2 loss : 0.018289
[00:47:48.947] iteration 21948 : model1 loss : 0.434749 model2 loss : 0.016763
[00:47:49.117] iteration 21949 : model1 loss : 0.438039 model2 loss : 0.015459
[00:47:49.297] iteration 21950 : model1 loss : 0.443918 model2 loss : 0.022873
[00:47:49.463] iteration 21951 : model1 loss : 0.436429 model2 loss : 0.019331
[00:47:49.633] iteration 21952 : model1 loss : 0.437893 model2 loss : 0.019302
[00:47:49.801] iteration 21953 : model1 loss : 0.437388 model2 loss : 0.017351
[00:47:49.971] iteration 21954 : model1 loss : 0.441655 model2 loss : 0.018705
[00:47:50.138] iteration 21955 : model1 loss : 0.441789 model2 loss : 0.018248
[00:47:50.307] iteration 21956 : model1 loss : 0.436955 model2 loss : 0.018689
[00:47:50.474] iteration 21957 : model1 loss : 0.435112 model2 loss : 0.018240
[00:47:50.643] iteration 21958 : model1 loss : 0.440688 model2 loss : 0.019163
[00:47:50.812] iteration 21959 : model1 loss : 0.435067 model2 loss : 0.018715
[00:47:50.983] iteration 21960 : model1 loss : 0.441007 model2 loss : 0.020279
[00:47:51.148] iteration 21961 : model1 loss : 0.438093 model2 loss : 0.020371
[00:47:51.318] iteration 21962 : model1 loss : 0.439828 model2 loss : 0.018012
[00:47:51.485] iteration 21963 : model1 loss : 0.439860 model2 loss : 0.018400
[00:47:51.657] iteration 21964 : model1 loss : 0.443030 model2 loss : 0.017920
[00:47:51.824] iteration 21965 : model1 loss : 0.440519 model2 loss : 0.016200
[00:47:51.993] iteration 21966 : model1 loss : 0.439823 model2 loss : 0.019113
[00:47:54.013] iteration 21967 : model1 loss : 0.440319 model2 loss : 0.018499
[00:47:54.182] iteration 21968 : model1 loss : 0.438591 model2 loss : 0.018090
[00:47:54.354] iteration 21969 : model1 loss : 0.437735 model2 loss : 0.017106
[00:47:54.523] iteration 21970 : model1 loss : 0.434655 model2 loss : 0.017828
[00:47:54.699] iteration 21971 : model1 loss : 0.437022 model2 loss : 0.017999
[00:47:54.870] iteration 21972 : model1 loss : 0.436033 model2 loss : 0.017223
[00:47:55.041] iteration 21973 : model1 loss : 0.434920 model2 loss : 0.017220
[00:47:55.210] iteration 21974 : model1 loss : 0.441967 model2 loss : 0.019663
[00:47:55.378] iteration 21975 : model1 loss : 0.438864 model2 loss : 0.019775
[00:47:55.546] iteration 21976 : model1 loss : 0.436240 model2 loss : 0.018036
[00:47:55.715] iteration 21977 : model1 loss : 0.437329 model2 loss : 0.016235
[00:47:55.883] iteration 21978 : model1 loss : 0.436887 model2 loss : 0.016784
[00:47:56.056] iteration 21979 : model1 loss : 0.440923 model2 loss : 0.018582
[00:47:56.222] iteration 21980 : model1 loss : 0.439589 model2 loss : 0.018874
[00:47:56.392] iteration 21981 : model1 loss : 0.440247 model2 loss : 0.019817
[00:47:56.560] iteration 21982 : model1 loss : 0.439197 model2 loss : 0.018186
[00:47:56.729] iteration 21983 : model1 loss : 0.436773 model2 loss : 0.017578
[00:47:56.899] iteration 21984 : model1 loss : 0.439707 model2 loss : 0.018301
[00:47:57.073] iteration 21985 : model1 loss : 0.439531 model2 loss : 0.016404
[00:47:57.239] iteration 21986 : model1 loss : 0.442292 model2 loss : 0.019313
[00:47:57.405] iteration 21987 : model1 loss : 0.447551 model2 loss : 0.023619
[00:47:59.428] iteration 21988 : model1 loss : 0.439404 model2 loss : 0.016246
[00:47:59.601] iteration 21989 : model1 loss : 0.435843 model2 loss : 0.016726
[00:47:59.769] iteration 21990 : model1 loss : 0.438484 model2 loss : 0.015356
[00:47:59.938] iteration 21991 : model1 loss : 0.439523 model2 loss : 0.019298
[00:48:00.112] iteration 21992 : model1 loss : 0.434026 model2 loss : 0.018297
[00:48:00.284] iteration 21993 : model1 loss : 0.438991 model2 loss : 0.019076
[00:48:00.451] iteration 21994 : model1 loss : 0.442781 model2 loss : 0.020355
[00:48:00.619] iteration 21995 : model1 loss : 0.437735 model2 loss : 0.018201
[00:48:00.790] iteration 21996 : model1 loss : 0.438250 model2 loss : 0.018360
[00:48:00.959] iteration 21997 : model1 loss : 0.436748 model2 loss : 0.017491
[00:48:01.128] iteration 21998 : model1 loss : 0.437422 model2 loss : 0.017296
[00:48:01.297] iteration 21999 : model1 loss : 0.436836 model2 loss : 0.019271
[00:48:01.464] iteration 22000 : model1 loss : 0.440746 model2 loss : 0.019146
[00:48:10.140] iteration 22000 : model1_mean_dice : 0.880637 model1_mean_hd95 : 3.851819
[00:48:18.903] iteration 22000 : model2_mean_dice : 0.880989 model2_mean_hd95 : 4.203978
[00:48:19.079] iteration 22001 : model1 loss : 0.439679 model2 loss : 0.019693
[00:48:19.249] iteration 22002 : model1 loss : 0.441274 model2 loss : 0.017469
[00:48:19.416] iteration 22003 : model1 loss : 0.437246 model2 loss : 0.017910
[00:48:19.584] iteration 22004 : model1 loss : 0.436253 model2 loss : 0.018402
[00:48:19.749] iteration 22005 : model1 loss : 0.440036 model2 loss : 0.019254
[00:48:19.919] iteration 22006 : model1 loss : 0.438683 model2 loss : 0.018392
[00:48:20.085] iteration 22007 : model1 loss : 0.444221 model2 loss : 0.020691
[00:48:20.252] iteration 22008 : model1 loss : 0.447148 model2 loss : 0.026237
[00:48:22.280] iteration 22009 : model1 loss : 0.437863 model2 loss : 0.018006
[00:48:22.447] iteration 22010 : model1 loss : 0.440639 model2 loss : 0.018131
[00:48:22.613] iteration 22011 : model1 loss : 0.438100 model2 loss : 0.017274
[00:48:22.779] iteration 22012 : model1 loss : 0.434394 model2 loss : 0.016616
[00:48:22.948] iteration 22013 : model1 loss : 0.445848 model2 loss : 0.021726
[00:48:23.120] iteration 22014 : model1 loss : 0.434466 model2 loss : 0.016272
[00:48:23.286] iteration 22015 : model1 loss : 0.438110 model2 loss : 0.021157
[00:48:23.451] iteration 22016 : model1 loss : 0.441611 model2 loss : 0.021272
[00:48:23.619] iteration 22017 : model1 loss : 0.441319 model2 loss : 0.019350
[00:48:23.784] iteration 22018 : model1 loss : 0.441116 model2 loss : 0.019402
[00:48:23.953] iteration 22019 : model1 loss : 0.437586 model2 loss : 0.018876
[00:48:24.126] iteration 22020 : model1 loss : 0.437224 model2 loss : 0.020002
[00:48:24.295] iteration 22021 : model1 loss : 0.435203 model2 loss : 0.016826
[00:48:24.460] iteration 22022 : model1 loss : 0.436800 model2 loss : 0.018004
[00:48:24.628] iteration 22023 : model1 loss : 0.440259 model2 loss : 0.017738
[00:48:24.795] iteration 22024 : model1 loss : 0.438662 model2 loss : 0.016787
[00:48:24.962] iteration 22025 : model1 loss : 0.445121 model2 loss : 0.019998
[00:48:25.132] iteration 22026 : model1 loss : 0.439929 model2 loss : 0.019768
[00:48:25.302] iteration 22027 : model1 loss : 0.438376 model2 loss : 0.019502
[00:48:25.467] iteration 22028 : model1 loss : 0.435992 model2 loss : 0.018501
[00:48:25.636] iteration 22029 : model1 loss : 0.441058 model2 loss : 0.017405
[00:48:27.653] iteration 22030 : model1 loss : 0.439512 model2 loss : 0.016898
[00:48:27.820] iteration 22031 : model1 loss : 0.437920 model2 loss : 0.018139
[00:48:27.987] iteration 22032 : model1 loss : 0.436943 model2 loss : 0.016660
[00:48:28.153] iteration 22033 : model1 loss : 0.438485 model2 loss : 0.018947
[00:48:28.325] iteration 22034 : model1 loss : 0.435030 model2 loss : 0.018957
[00:48:28.491] iteration 22035 : model1 loss : 0.441812 model2 loss : 0.019379
[00:48:28.658] iteration 22036 : model1 loss : 0.439967 model2 loss : 0.017823
[00:48:28.822] iteration 22037 : model1 loss : 0.437346 model2 loss : 0.016403
[00:48:28.992] iteration 22038 : model1 loss : 0.436744 model2 loss : 0.017402
[00:48:29.158] iteration 22039 : model1 loss : 0.436222 model2 loss : 0.017771
[00:48:29.329] iteration 22040 : model1 loss : 0.443083 model2 loss : 0.018742
[00:48:29.496] iteration 22041 : model1 loss : 0.439476 model2 loss : 0.018077
[00:48:29.665] iteration 22042 : model1 loss : 0.439258 model2 loss : 0.019685
[00:48:29.830] iteration 22043 : model1 loss : 0.444170 model2 loss : 0.018468
[00:48:29.999] iteration 22044 : model1 loss : 0.438696 model2 loss : 0.016843
[00:48:30.166] iteration 22045 : model1 loss : 0.441406 model2 loss : 0.017069
[00:48:30.337] iteration 22046 : model1 loss : 0.436807 model2 loss : 0.017894
[00:48:30.504] iteration 22047 : model1 loss : 0.437116 model2 loss : 0.017700
[00:48:30.671] iteration 22048 : model1 loss : 0.440420 model2 loss : 0.019718
[00:48:30.835] iteration 22049 : model1 loss : 0.440039 model2 loss : 0.018251
[00:48:31.004] iteration 22050 : model1 loss : 0.436198 model2 loss : 0.020129
[00:48:33.064] iteration 22051 : model1 loss : 0.439198 model2 loss : 0.020307
[00:48:33.236] iteration 22052 : model1 loss : 0.437944 model2 loss : 0.016031
[00:48:33.406] iteration 22053 : model1 loss : 0.436462 model2 loss : 0.017866
[00:48:33.572] iteration 22054 : model1 loss : 0.441635 model2 loss : 0.019581
[00:48:33.740] iteration 22055 : model1 loss : 0.444047 model2 loss : 0.019350
[00:48:33.904] iteration 22056 : model1 loss : 0.434714 model2 loss : 0.016540
[00:48:34.076] iteration 22057 : model1 loss : 0.436155 model2 loss : 0.018891
[00:48:34.240] iteration 22058 : model1 loss : 0.438321 model2 loss : 0.017594
[00:48:34.408] iteration 22059 : model1 loss : 0.441749 model2 loss : 0.018588
[00:48:34.572] iteration 22060 : model1 loss : 0.442232 model2 loss : 0.017625
[00:48:34.741] iteration 22061 : model1 loss : 0.438165 model2 loss : 0.016045
[00:48:34.909] iteration 22062 : model1 loss : 0.440046 model2 loss : 0.020796
[00:48:35.077] iteration 22063 : model1 loss : 0.441114 model2 loss : 0.019989
[00:48:35.244] iteration 22064 : model1 loss : 0.438071 model2 loss : 0.017944
[00:48:35.414] iteration 22065 : model1 loss : 0.435129 model2 loss : 0.018129
[00:48:35.581] iteration 22066 : model1 loss : 0.441248 model2 loss : 0.019089
[00:48:35.750] iteration 22067 : model1 loss : 0.443252 model2 loss : 0.019779
[00:48:35.917] iteration 22068 : model1 loss : 0.434772 model2 loss : 0.017254
[00:48:36.086] iteration 22069 : model1 loss : 0.438212 model2 loss : 0.018151
[00:48:36.249] iteration 22070 : model1 loss : 0.440138 model2 loss : 0.019943
[00:48:36.416] iteration 22071 : model1 loss : 0.438076 model2 loss : 0.018650
[00:48:38.458] iteration 22072 : model1 loss : 0.434862 model2 loss : 0.017407
[00:48:38.629] iteration 22073 : model1 loss : 0.440260 model2 loss : 0.018179
[00:48:38.798] iteration 22074 : model1 loss : 0.437765 model2 loss : 0.015701
[00:48:38.965] iteration 22075 : model1 loss : 0.439253 model2 loss : 0.017042
[00:48:39.133] iteration 22076 : model1 loss : 0.439189 model2 loss : 0.018548
[00:48:39.301] iteration 22077 : model1 loss : 0.434045 model2 loss : 0.018852
[00:48:39.467] iteration 22078 : model1 loss : 0.440616 model2 loss : 0.017235
[00:48:39.634] iteration 22079 : model1 loss : 0.438904 model2 loss : 0.017877
[00:48:39.801] iteration 22080 : model1 loss : 0.434648 model2 loss : 0.017200
[00:48:39.966] iteration 22081 : model1 loss : 0.442913 model2 loss : 0.022078
[00:48:40.138] iteration 22082 : model1 loss : 0.441254 model2 loss : 0.017192
[00:48:40.307] iteration 22083 : model1 loss : 0.438323 model2 loss : 0.017455
[00:48:40.476] iteration 22084 : model1 loss : 0.439699 model2 loss : 0.016587
[00:48:40.644] iteration 22085 : model1 loss : 0.435135 model2 loss : 0.017035
[00:48:40.813] iteration 22086 : model1 loss : 0.437151 model2 loss : 0.019159
[00:48:40.980] iteration 22087 : model1 loss : 0.441009 model2 loss : 0.018824
[00:48:41.148] iteration 22088 : model1 loss : 0.439414 model2 loss : 0.017339
[00:48:41.317] iteration 22089 : model1 loss : 0.439534 model2 loss : 0.018084
[00:48:41.485] iteration 22090 : model1 loss : 0.442597 model2 loss : 0.018812
[00:48:41.649] iteration 22091 : model1 loss : 0.440295 model2 loss : 0.018685
[00:48:41.816] iteration 22092 : model1 loss : 0.441800 model2 loss : 0.019473
[00:48:43.828] iteration 22093 : model1 loss : 0.440341 model2 loss : 0.018687
[00:48:43.998] iteration 22094 : model1 loss : 0.441934 model2 loss : 0.017288
[00:48:44.170] iteration 22095 : model1 loss : 0.439785 model2 loss : 0.018455
[00:48:44.338] iteration 22096 : model1 loss : 0.440954 model2 loss : 0.017114
[00:48:44.507] iteration 22097 : model1 loss : 0.438792 model2 loss : 0.020458
[00:48:44.674] iteration 22098 : model1 loss : 0.439301 model2 loss : 0.018429
[00:48:44.844] iteration 22099 : model1 loss : 0.447239 model2 loss : 0.020955
[00:48:45.011] iteration 22100 : model1 loss : 0.437272 model2 loss : 0.017055
[00:48:45.179] iteration 22101 : model1 loss : 0.437892 model2 loss : 0.018442
[00:48:45.344] iteration 22102 : model1 loss : 0.437997 model2 loss : 0.021461
[00:48:45.512] iteration 22103 : model1 loss : 0.438907 model2 loss : 0.019793
[00:48:45.681] iteration 22104 : model1 loss : 0.435322 model2 loss : 0.017027
[00:48:45.850] iteration 22105 : model1 loss : 0.437352 model2 loss : 0.018520
[00:48:46.018] iteration 22106 : model1 loss : 0.439650 model2 loss : 0.019453
[00:48:46.186] iteration 22107 : model1 loss : 0.440706 model2 loss : 0.018972
[00:48:46.352] iteration 22108 : model1 loss : 0.441770 model2 loss : 0.021726
[00:48:46.519] iteration 22109 : model1 loss : 0.437786 model2 loss : 0.020667
[00:48:46.685] iteration 22110 : model1 loss : 0.440994 model2 loss : 0.020277
[00:48:46.856] iteration 22111 : model1 loss : 0.443928 model2 loss : 0.016473
[00:48:47.021] iteration 22112 : model1 loss : 0.437819 model2 loss : 0.017274
[00:48:47.190] iteration 22113 : model1 loss : 0.432235 model2 loss : 0.016901
[00:48:49.202] iteration 22114 : model1 loss : 0.439570 model2 loss : 0.017116
[00:48:49.372] iteration 22115 : model1 loss : 0.443793 model2 loss : 0.019436
[00:48:49.544] iteration 22116 : model1 loss : 0.434774 model2 loss : 0.019667
[00:48:49.711] iteration 22117 : model1 loss : 0.439552 model2 loss : 0.017174
[00:48:49.882] iteration 22118 : model1 loss : 0.444022 model2 loss : 0.021373
[00:48:50.050] iteration 22119 : model1 loss : 0.436400 model2 loss : 0.016890
[00:48:50.219] iteration 22120 : model1 loss : 0.444628 model2 loss : 0.022482
[00:48:50.385] iteration 22121 : model1 loss : 0.439629 model2 loss : 0.018213
[00:48:50.553] iteration 22122 : model1 loss : 0.434932 model2 loss : 0.017636
[00:48:50.721] iteration 22123 : model1 loss : 0.439086 model2 loss : 0.015640
[00:48:50.892] iteration 22124 : model1 loss : 0.439148 model2 loss : 0.020303
[00:48:51.060] iteration 22125 : model1 loss : 0.441905 model2 loss : 0.018953
[00:48:51.231] iteration 22126 : model1 loss : 0.441657 model2 loss : 0.018019
[00:48:51.396] iteration 22127 : model1 loss : 0.435623 model2 loss : 0.018416
[00:48:51.565] iteration 22128 : model1 loss : 0.443585 model2 loss : 0.019979
[00:48:51.730] iteration 22129 : model1 loss : 0.435929 model2 loss : 0.016458
[00:48:51.900] iteration 22130 : model1 loss : 0.435043 model2 loss : 0.017355
[00:48:52.068] iteration 22131 : model1 loss : 0.438121 model2 loss : 0.016169
[00:48:52.236] iteration 22132 : model1 loss : 0.439468 model2 loss : 0.017611
[00:48:52.404] iteration 22133 : model1 loss : 0.440945 model2 loss : 0.019922
[00:48:52.571] iteration 22134 : model1 loss : 0.435445 model2 loss : 0.015825
[00:48:54.567] iteration 22135 : model1 loss : 0.434045 model2 loss : 0.016187
[00:48:54.738] iteration 22136 : model1 loss : 0.445328 model2 loss : 0.021166
[00:48:54.909] iteration 22137 : model1 loss : 0.436082 model2 loss : 0.017708
[00:48:55.075] iteration 22138 : model1 loss : 0.440392 model2 loss : 0.018082
[00:48:55.245] iteration 22139 : model1 loss : 0.436955 model2 loss : 0.017958
[00:48:55.411] iteration 22140 : model1 loss : 0.435056 model2 loss : 0.017891
[00:48:55.581] iteration 22141 : model1 loss : 0.435134 model2 loss : 0.016690
[00:48:55.748] iteration 22142 : model1 loss : 0.439723 model2 loss : 0.016363
[00:48:55.916] iteration 22143 : model1 loss : 0.443401 model2 loss : 0.019624
[00:48:56.084] iteration 22144 : model1 loss : 0.438722 model2 loss : 0.017639
[00:48:56.252] iteration 22145 : model1 loss : 0.439733 model2 loss : 0.018213
[00:48:56.420] iteration 22146 : model1 loss : 0.442375 model2 loss : 0.020061
[00:48:56.588] iteration 22147 : model1 loss : 0.440736 model2 loss : 0.019238
[00:48:56.755] iteration 22148 : model1 loss : 0.439431 model2 loss : 0.017376
[00:48:56.935] iteration 22149 : model1 loss : 0.442144 model2 loss : 0.018769
[00:48:57.103] iteration 22150 : model1 loss : 0.436166 model2 loss : 0.018384
[00:48:57.269] iteration 22151 : model1 loss : 0.439430 model2 loss : 0.020710
[00:48:57.437] iteration 22152 : model1 loss : 0.437734 model2 loss : 0.017882
[00:48:57.606] iteration 22153 : model1 loss : 0.436065 model2 loss : 0.016768
[00:48:57.771] iteration 22154 : model1 loss : 0.440673 model2 loss : 0.021796
[00:48:57.939] iteration 22155 : model1 loss : 0.439492 model2 loss : 0.017506
[00:48:59.955] iteration 22156 : model1 loss : 0.435181 model2 loss : 0.017252
[00:49:00.133] iteration 22157 : model1 loss : 0.440358 model2 loss : 0.018461
[00:49:00.308] iteration 22158 : model1 loss : 0.439188 model2 loss : 0.019222
[00:49:00.475] iteration 22159 : model1 loss : 0.440511 model2 loss : 0.018226
[00:49:00.645] iteration 22160 : model1 loss : 0.439291 model2 loss : 0.018346
[00:49:00.812] iteration 22161 : model1 loss : 0.436552 model2 loss : 0.018602
[00:49:00.980] iteration 22162 : model1 loss : 0.440382 model2 loss : 0.017984
[00:49:01.147] iteration 22163 : model1 loss : 0.439358 model2 loss : 0.020851
[00:49:01.319] iteration 22164 : model1 loss : 0.439919 model2 loss : 0.019225
[00:49:01.487] iteration 22165 : model1 loss : 0.439965 model2 loss : 0.018140
[00:49:01.655] iteration 22166 : model1 loss : 0.439967 model2 loss : 0.019471
[00:49:01.821] iteration 22167 : model1 loss : 0.437262 model2 loss : 0.016781
[00:49:01.992] iteration 22168 : model1 loss : 0.442585 model2 loss : 0.019236
[00:49:02.160] iteration 22169 : model1 loss : 0.435333 model2 loss : 0.017805
[00:49:02.330] iteration 22170 : model1 loss : 0.440291 model2 loss : 0.017431
[00:49:02.498] iteration 22171 : model1 loss : 0.440884 model2 loss : 0.016361
[00:49:02.665] iteration 22172 : model1 loss : 0.440234 model2 loss : 0.017992
[00:49:02.834] iteration 22173 : model1 loss : 0.439878 model2 loss : 0.016456
[00:49:03.003] iteration 22174 : model1 loss : 0.434115 model2 loss : 0.017301
[00:49:03.167] iteration 22175 : model1 loss : 0.438449 model2 loss : 0.016423
[00:49:03.338] iteration 22176 : model1 loss : 0.439564 model2 loss : 0.019184
[00:49:05.338] iteration 22177 : model1 loss : 0.437324 model2 loss : 0.017914
[00:49:05.507] iteration 22178 : model1 loss : 0.441241 model2 loss : 0.018977
[00:49:05.675] iteration 22179 : model1 loss : 0.439243 model2 loss : 0.018863
[00:49:05.839] iteration 22180 : model1 loss : 0.442024 model2 loss : 0.018238
[00:49:06.006] iteration 22181 : model1 loss : 0.435179 model2 loss : 0.018561
[00:49:06.175] iteration 22182 : model1 loss : 0.440178 model2 loss : 0.015115
[00:49:06.344] iteration 22183 : model1 loss : 0.438770 model2 loss : 0.018396
[00:49:06.511] iteration 22184 : model1 loss : 0.439407 model2 loss : 0.018456
[00:49:06.676] iteration 22185 : model1 loss : 0.441049 model2 loss : 0.018978
[00:49:06.860] iteration 22186 : model1 loss : 0.438757 model2 loss : 0.017237
[00:49:07.028] iteration 22187 : model1 loss : 0.437600 model2 loss : 0.017527
[00:49:07.198] iteration 22188 : model1 loss : 0.437505 model2 loss : 0.015333
[00:49:07.369] iteration 22189 : model1 loss : 0.438464 model2 loss : 0.017792
[00:49:07.536] iteration 22190 : model1 loss : 0.434692 model2 loss : 0.016926
[00:49:07.703] iteration 22191 : model1 loss : 0.442131 model2 loss : 0.019653
[00:49:07.872] iteration 22192 : model1 loss : 0.437749 model2 loss : 0.016550
[00:49:08.043] iteration 22193 : model1 loss : 0.439300 model2 loss : 0.016530
[00:49:08.212] iteration 22194 : model1 loss : 0.439148 model2 loss : 0.017459
[00:49:08.379] iteration 22195 : model1 loss : 0.440789 model2 loss : 0.021928
[00:49:08.544] iteration 22196 : model1 loss : 0.436204 model2 loss : 0.017785
[00:49:08.711] iteration 22197 : model1 loss : 0.442452 model2 loss : 0.020776
[00:49:10.702] iteration 22198 : model1 loss : 0.442387 model2 loss : 0.017975
[00:49:10.872] iteration 22199 : model1 loss : 0.442275 model2 loss : 0.023312
[00:49:11.041] iteration 22200 : model1 loss : 0.441889 model2 loss : 0.021066
[00:49:11.206] iteration 22201 : model1 loss : 0.434410 model2 loss : 0.014007
[00:49:11.374] iteration 22202 : model1 loss : 0.444157 model2 loss : 0.019447
[00:49:11.541] iteration 22203 : model1 loss : 0.438161 model2 loss : 0.018588
[00:49:11.712] iteration 22204 : model1 loss : 0.439723 model2 loss : 0.018051
[00:49:11.877] iteration 22205 : model1 loss : 0.436751 model2 loss : 0.016040
[00:49:12.062] iteration 22206 : model1 loss : 0.436782 model2 loss : 0.017260
[00:49:12.229] iteration 22207 : model1 loss : 0.440462 model2 loss : 0.018808
[00:49:12.400] iteration 22208 : model1 loss : 0.441729 model2 loss : 0.017356
[00:49:12.568] iteration 22209 : model1 loss : 0.438542 model2 loss : 0.019068
[00:49:12.736] iteration 22210 : model1 loss : 0.433583 model2 loss : 0.017893
[00:49:12.901] iteration 22211 : model1 loss : 0.438460 model2 loss : 0.017100
[00:49:13.070] iteration 22212 : model1 loss : 0.437796 model2 loss : 0.019291
[00:49:13.234] iteration 22213 : model1 loss : 0.437180 model2 loss : 0.019254
[00:49:13.409] iteration 22214 : model1 loss : 0.442242 model2 loss : 0.019755
[00:49:13.580] iteration 22215 : model1 loss : 0.437376 model2 loss : 0.018223
[00:49:13.751] iteration 22216 : model1 loss : 0.438685 model2 loss : 0.017481
[00:49:13.915] iteration 22217 : model1 loss : 0.437218 model2 loss : 0.016031
[00:49:14.083] iteration 22218 : model1 loss : 0.437031 model2 loss : 0.017949
[00:49:16.101] iteration 22219 : model1 loss : 0.433624 model2 loss : 0.016528
[00:49:16.268] iteration 22220 : model1 loss : 0.438581 model2 loss : 0.017072
[00:49:16.437] iteration 22221 : model1 loss : 0.441429 model2 loss : 0.021899
[00:49:16.604] iteration 22222 : model1 loss : 0.439674 model2 loss : 0.019679
[00:49:16.801] iteration 22223 : model1 loss : 0.442345 model2 loss : 0.018559
[00:49:17.028] iteration 22224 : model1 loss : 0.440548 model2 loss : 0.020640
[00:49:17.233] iteration 22225 : model1 loss : 0.440829 model2 loss : 0.016642
[00:49:17.461] iteration 22226 : model1 loss : 0.437346 model2 loss : 0.016928
[00:49:17.649] iteration 22227 : model1 loss : 0.439851 model2 loss : 0.021164
[00:49:17.827] iteration 22228 : model1 loss : 0.437111 model2 loss : 0.017571
[00:49:18.005] iteration 22229 : model1 loss : 0.438450 model2 loss : 0.018279
[00:49:18.183] iteration 22230 : model1 loss : 0.436909 model2 loss : 0.019538
[00:49:18.357] iteration 22231 : model1 loss : 0.435682 model2 loss : 0.017604
[00:49:18.533] iteration 22232 : model1 loss : 0.439647 model2 loss : 0.017490
[00:49:18.710] iteration 22233 : model1 loss : 0.437864 model2 loss : 0.019762
[00:49:18.889] iteration 22234 : model1 loss : 0.438975 model2 loss : 0.016888
[00:49:19.065] iteration 22235 : model1 loss : 0.438474 model2 loss : 0.017827
[00:49:19.242] iteration 22236 : model1 loss : 0.439637 model2 loss : 0.017546
[00:49:19.419] iteration 22237 : model1 loss : 0.438847 model2 loss : 0.018999
[00:49:19.596] iteration 22238 : model1 loss : 0.441630 model2 loss : 0.017974
[00:49:19.775] iteration 22239 : model1 loss : 0.440412 model2 loss : 0.017329
[00:49:21.891] iteration 22240 : model1 loss : 0.441620 model2 loss : 0.016882
[00:49:22.069] iteration 22241 : model1 loss : 0.438730 model2 loss : 0.018153
[00:49:22.247] iteration 22242 : model1 loss : 0.437039 model2 loss : 0.018561
[00:49:22.426] iteration 22243 : model1 loss : 0.435914 model2 loss : 0.018325
[00:49:22.603] iteration 22244 : model1 loss : 0.438239 model2 loss : 0.014473
[00:49:22.779] iteration 22245 : model1 loss : 0.439938 model2 loss : 0.019263
[00:49:22.959] iteration 22246 : model1 loss : 0.441776 model2 loss : 0.018224
[00:49:23.138] iteration 22247 : model1 loss : 0.437086 model2 loss : 0.017581
[00:49:23.319] iteration 22248 : model1 loss : 0.434229 model2 loss : 0.018270
[00:49:23.495] iteration 22249 : model1 loss : 0.439885 model2 loss : 0.020301
[00:49:23.673] iteration 22250 : model1 loss : 0.441729 model2 loss : 0.018398
[00:49:23.850] iteration 22251 : model1 loss : 0.437416 model2 loss : 0.017369
[00:49:24.027] iteration 22252 : model1 loss : 0.444648 model2 loss : 0.021333
[00:49:24.206] iteration 22253 : model1 loss : 0.440177 model2 loss : 0.018212
[00:49:24.383] iteration 22254 : model1 loss : 0.437720 model2 loss : 0.016680
[00:49:24.560] iteration 22255 : model1 loss : 0.439291 model2 loss : 0.018110
[00:49:24.738] iteration 22256 : model1 loss : 0.437039 model2 loss : 0.018129
[00:49:24.916] iteration 22257 : model1 loss : 0.441628 model2 loss : 0.021498
[00:49:25.105] iteration 22258 : model1 loss : 0.437751 model2 loss : 0.018089
[00:49:25.278] iteration 22259 : model1 loss : 0.437486 model2 loss : 0.017383
[00:49:25.453] iteration 22260 : model1 loss : 0.441164 model2 loss : 0.017871
[00:49:27.577] iteration 22261 : model1 loss : 0.439185 model2 loss : 0.020370
[00:49:27.754] iteration 22262 : model1 loss : 0.444474 model2 loss : 0.019914
[00:49:27.933] iteration 22263 : model1 loss : 0.441323 model2 loss : 0.020268
[00:49:28.112] iteration 22264 : model1 loss : 0.439977 model2 loss : 0.019281
[00:49:28.291] iteration 22265 : model1 loss : 0.438221 model2 loss : 0.019469
[00:49:28.467] iteration 22266 : model1 loss : 0.442185 model2 loss : 0.017028
[00:49:28.651] iteration 22267 : model1 loss : 0.439705 model2 loss : 0.019083
[00:49:28.825] iteration 22268 : model1 loss : 0.437683 model2 loss : 0.016387
[00:49:29.004] iteration 22269 : model1 loss : 0.435374 model2 loss : 0.018626
[00:49:29.180] iteration 22270 : model1 loss : 0.437248 model2 loss : 0.016439
[00:49:29.357] iteration 22271 : model1 loss : 0.438923 model2 loss : 0.019528
[00:49:29.532] iteration 22272 : model1 loss : 0.438034 model2 loss : 0.016884
[00:49:29.709] iteration 22273 : model1 loss : 0.442500 model2 loss : 0.019163
[00:49:29.887] iteration 22274 : model1 loss : 0.445217 model2 loss : 0.021313
[00:49:30.066] iteration 22275 : model1 loss : 0.433363 model2 loss : 0.017728
[00:49:30.254] iteration 22276 : model1 loss : 0.437432 model2 loss : 0.014596
[00:49:30.430] iteration 22277 : model1 loss : 0.437465 model2 loss : 0.016493
[00:49:30.609] iteration 22278 : model1 loss : 0.437770 model2 loss : 0.018313
[00:49:30.789] iteration 22279 : model1 loss : 0.438621 model2 loss : 0.018460
[00:49:30.967] iteration 22280 : model1 loss : 0.442377 model2 loss : 0.019055
[00:49:31.141] iteration 22281 : model1 loss : 0.435106 model2 loss : 0.015385
[00:49:33.226] iteration 22282 : model1 loss : 0.438205 model2 loss : 0.017862
[00:49:33.399] iteration 22283 : model1 loss : 0.439291 model2 loss : 0.016396
[00:49:33.585] iteration 22284 : model1 loss : 0.442357 model2 loss : 0.018498
[00:49:33.757] iteration 22285 : model1 loss : 0.439249 model2 loss : 0.017825
[00:49:33.928] iteration 22286 : model1 loss : 0.436795 model2 loss : 0.017698
[00:49:34.097] iteration 22287 : model1 loss : 0.441098 model2 loss : 0.017669
[00:49:34.268] iteration 22288 : model1 loss : 0.437412 model2 loss : 0.017982
[00:49:34.437] iteration 22289 : model1 loss : 0.439660 model2 loss : 0.016825
[00:49:34.609] iteration 22290 : model1 loss : 0.440879 model2 loss : 0.017052
[00:49:34.780] iteration 22291 : model1 loss : 0.438044 model2 loss : 0.020077
[00:49:34.953] iteration 22292 : model1 loss : 0.436789 model2 loss : 0.017545
[00:49:35.124] iteration 22293 : model1 loss : 0.437114 model2 loss : 0.018608
[00:49:35.296] iteration 22294 : model1 loss : 0.442368 model2 loss : 0.017454
[00:49:35.465] iteration 22295 : model1 loss : 0.435145 model2 loss : 0.017154
[00:49:35.636] iteration 22296 : model1 loss : 0.440252 model2 loss : 0.018352
[00:49:35.806] iteration 22297 : model1 loss : 0.435873 model2 loss : 0.016753
[00:49:35.982] iteration 22298 : model1 loss : 0.441765 model2 loss : 0.019847
[00:49:36.149] iteration 22299 : model1 loss : 0.439157 model2 loss : 0.019905
[00:49:36.321] iteration 22300 : model1 loss : 0.440306 model2 loss : 0.018125
[00:49:36.487] iteration 22301 : model1 loss : 0.437023 model2 loss : 0.016643
[00:49:36.655] iteration 22302 : model1 loss : 0.442244 model2 loss : 0.016987
[00:49:38.736] iteration 22303 : model1 loss : 0.438272 model2 loss : 0.018537
[00:49:38.910] iteration 22304 : model1 loss : 0.439069 model2 loss : 0.018725
[00:49:39.085] iteration 22305 : model1 loss : 0.441109 model2 loss : 0.015845
[00:49:39.251] iteration 22306 : model1 loss : 0.438142 model2 loss : 0.018220
[00:49:39.422] iteration 22307 : model1 loss : 0.441185 model2 loss : 0.016906
[00:49:39.589] iteration 22308 : model1 loss : 0.441287 model2 loss : 0.017034
[00:49:39.760] iteration 22309 : model1 loss : 0.443350 model2 loss : 0.021848
[00:49:39.931] iteration 22310 : model1 loss : 0.441941 model2 loss : 0.018160
[00:49:40.102] iteration 22311 : model1 loss : 0.434139 model2 loss : 0.017320
[00:49:40.271] iteration 22312 : model1 loss : 0.438469 model2 loss : 0.019900
[00:49:40.441] iteration 22313 : model1 loss : 0.434974 model2 loss : 0.019207
[00:49:40.609] iteration 22314 : model1 loss : 0.440386 model2 loss : 0.017493
[00:49:40.781] iteration 22315 : model1 loss : 0.436277 model2 loss : 0.016304
[00:49:40.951] iteration 22316 : model1 loss : 0.437661 model2 loss : 0.017257
[00:49:41.125] iteration 22317 : model1 loss : 0.439303 model2 loss : 0.020062
[00:49:41.293] iteration 22318 : model1 loss : 0.437305 model2 loss : 0.018593
[00:49:41.462] iteration 22319 : model1 loss : 0.441497 model2 loss : 0.018856
[00:49:41.631] iteration 22320 : model1 loss : 0.442487 model2 loss : 0.019146
[00:49:41.803] iteration 22321 : model1 loss : 0.441500 model2 loss : 0.020195
[00:49:41.974] iteration 22322 : model1 loss : 0.440867 model2 loss : 0.018417
[00:49:42.145] iteration 22323 : model1 loss : 0.434348 model2 loss : 0.018531
[00:49:44.217] iteration 22324 : model1 loss : 0.444946 model2 loss : 0.020088
[00:49:44.392] iteration 22325 : model1 loss : 0.443481 model2 loss : 0.017235
[00:49:44.566] iteration 22326 : model1 loss : 0.441466 model2 loss : 0.019679
[00:49:44.735] iteration 22327 : model1 loss : 0.435995 model2 loss : 0.017155
[00:49:44.909] iteration 22328 : model1 loss : 0.437891 model2 loss : 0.017417
[00:49:45.080] iteration 22329 : model1 loss : 0.441714 model2 loss : 0.019493
[00:49:45.250] iteration 22330 : model1 loss : 0.431969 model2 loss : 0.015556
[00:49:45.418] iteration 22331 : model1 loss : 0.437395 model2 loss : 0.018462
[00:49:45.589] iteration 22332 : model1 loss : 0.439676 model2 loss : 0.016918
[00:49:45.757] iteration 22333 : model1 loss : 0.437208 model2 loss : 0.015651
[00:49:45.930] iteration 22334 : model1 loss : 0.436402 model2 loss : 0.017524
[00:49:46.099] iteration 22335 : model1 loss : 0.438232 model2 loss : 0.018142
[00:49:46.269] iteration 22336 : model1 loss : 0.439350 model2 loss : 0.018449
[00:49:46.438] iteration 22337 : model1 loss : 0.438819 model2 loss : 0.016931
[00:49:46.608] iteration 22338 : model1 loss : 0.434137 model2 loss : 0.016967
[00:49:46.776] iteration 22339 : model1 loss : 0.439038 model2 loss : 0.015586
[00:49:46.948] iteration 22340 : model1 loss : 0.437686 model2 loss : 0.018928
[00:49:47.120] iteration 22341 : model1 loss : 0.441374 model2 loss : 0.019305
[00:49:47.291] iteration 22342 : model1 loss : 0.440715 model2 loss : 0.019124
[00:49:47.463] iteration 22343 : model1 loss : 0.442963 model2 loss : 0.019583
[00:49:47.631] iteration 22344 : model1 loss : 0.441308 model2 loss : 0.018419
[00:49:49.684] iteration 22345 : model1 loss : 0.435827 model2 loss : 0.018933
[00:49:49.855] iteration 22346 : model1 loss : 0.436763 model2 loss : 0.016564
[00:49:50.029] iteration 22347 : model1 loss : 0.434984 model2 loss : 0.018922
[00:49:50.197] iteration 22348 : model1 loss : 0.438851 model2 loss : 0.018209
[00:49:50.370] iteration 22349 : model1 loss : 0.442700 model2 loss : 0.016952
[00:49:50.541] iteration 22350 : model1 loss : 0.439799 model2 loss : 0.018597
[00:49:50.714] iteration 22351 : model1 loss : 0.441132 model2 loss : 0.018414
[00:49:50.885] iteration 22352 : model1 loss : 0.438088 model2 loss : 0.017724
[00:49:51.057] iteration 22353 : model1 loss : 0.439598 model2 loss : 0.016519
[00:49:51.225] iteration 22354 : model1 loss : 0.437198 model2 loss : 0.017282
[00:49:51.396] iteration 22355 : model1 loss : 0.440719 model2 loss : 0.018534
[00:49:51.563] iteration 22356 : model1 loss : 0.434298 model2 loss : 0.017258
[00:49:51.735] iteration 22357 : model1 loss : 0.437779 model2 loss : 0.018074
[00:49:51.905] iteration 22358 : model1 loss : 0.438329 model2 loss : 0.016539
[00:49:52.079] iteration 22359 : model1 loss : 0.440061 model2 loss : 0.018933
[00:49:52.246] iteration 22360 : model1 loss : 0.445431 model2 loss : 0.021866
[00:49:52.419] iteration 22361 : model1 loss : 0.439142 model2 loss : 0.019029
[00:49:52.587] iteration 22362 : model1 loss : 0.440237 model2 loss : 0.020257
[00:49:52.758] iteration 22363 : model1 loss : 0.440843 model2 loss : 0.019169
[00:49:52.929] iteration 22364 : model1 loss : 0.436055 model2 loss : 0.018940
[00:49:53.101] iteration 22365 : model1 loss : 0.442281 model2 loss : 0.018726
[00:49:55.124] iteration 22366 : model1 loss : 0.437940 model2 loss : 0.018238
[00:49:55.297] iteration 22367 : model1 loss : 0.440539 model2 loss : 0.015871
[00:49:55.469] iteration 22368 : model1 loss : 0.443320 model2 loss : 0.019642
[00:49:55.638] iteration 22369 : model1 loss : 0.440939 model2 loss : 0.017662
[00:49:55.811] iteration 22370 : model1 loss : 0.441024 model2 loss : 0.018040
[00:49:55.980] iteration 22371 : model1 loss : 0.437475 model2 loss : 0.018733
[00:49:56.151] iteration 22372 : model1 loss : 0.438951 model2 loss : 0.018605
[00:49:56.323] iteration 22373 : model1 loss : 0.434959 model2 loss : 0.016304
[00:49:56.493] iteration 22374 : model1 loss : 0.441733 model2 loss : 0.019366
[00:49:56.662] iteration 22375 : model1 loss : 0.436773 model2 loss : 0.018680
[00:49:56.835] iteration 22376 : model1 loss : 0.441616 model2 loss : 0.019165
[00:49:57.004] iteration 22377 : model1 loss : 0.438714 model2 loss : 0.017763
[00:49:57.174] iteration 22378 : model1 loss : 0.437287 model2 loss : 0.016146
[00:49:57.346] iteration 22379 : model1 loss : 0.440732 model2 loss : 0.020812
[00:49:57.520] iteration 22380 : model1 loss : 0.435082 model2 loss : 0.017162
[00:49:57.691] iteration 22381 : model1 loss : 0.437826 model2 loss : 0.017000
[00:49:57.863] iteration 22382 : model1 loss : 0.437664 model2 loss : 0.018072
[00:49:58.033] iteration 22383 : model1 loss : 0.443162 model2 loss : 0.018960
[00:49:58.203] iteration 22384 : model1 loss : 0.438403 model2 loss : 0.018868
[00:49:58.372] iteration 22385 : model1 loss : 0.439962 model2 loss : 0.019351
[00:49:58.542] iteration 22386 : model1 loss : 0.438083 model2 loss : 0.016918
[00:50:00.604] iteration 22387 : model1 loss : 0.438306 model2 loss : 0.015936
[00:50:00.775] iteration 22388 : model1 loss : 0.442946 model2 loss : 0.020942
[00:50:00.951] iteration 22389 : model1 loss : 0.440099 model2 loss : 0.018578
[00:50:01.122] iteration 22390 : model1 loss : 0.441289 model2 loss : 0.016799
[00:50:01.293] iteration 22391 : model1 loss : 0.439599 model2 loss : 0.018594
[00:50:01.463] iteration 22392 : model1 loss : 0.438367 model2 loss : 0.019074
[00:50:01.632] iteration 22393 : model1 loss : 0.435789 model2 loss : 0.018175
[00:50:01.803] iteration 22394 : model1 loss : 0.436765 model2 loss : 0.018820
[00:50:01.978] iteration 22395 : model1 loss : 0.438363 model2 loss : 0.017906
[00:50:02.148] iteration 22396 : model1 loss : 0.437014 model2 loss : 0.018412
[00:50:02.322] iteration 22397 : model1 loss : 0.440403 model2 loss : 0.016632
[00:50:02.498] iteration 22398 : model1 loss : 0.442735 model2 loss : 0.017816
[00:50:02.671] iteration 22399 : model1 loss : 0.441332 model2 loss : 0.017763
[00:50:02.841] iteration 22400 : model1 loss : 0.441145 model2 loss : 0.017780
[00:50:03.015] iteration 22401 : model1 loss : 0.441215 model2 loss : 0.018546
[00:50:03.182] iteration 22402 : model1 loss : 0.437821 model2 loss : 0.016215
[00:50:03.352] iteration 22403 : model1 loss : 0.438553 model2 loss : 0.017989
[00:50:03.522] iteration 22404 : model1 loss : 0.441014 model2 loss : 0.017484
[00:50:03.693] iteration 22405 : model1 loss : 0.435495 model2 loss : 0.018041
[00:50:03.861] iteration 22406 : model1 loss : 0.435789 model2 loss : 0.019128
[00:50:04.032] iteration 22407 : model1 loss : 0.440649 model2 loss : 0.015973
[00:50:06.064] iteration 22408 : model1 loss : 0.439471 model2 loss : 0.019339
[00:50:06.236] iteration 22409 : model1 loss : 0.441053 model2 loss : 0.018334
[00:50:06.411] iteration 22410 : model1 loss : 0.436796 model2 loss : 0.017017
[00:50:06.580] iteration 22411 : model1 loss : 0.440390 model2 loss : 0.018679
[00:50:06.751] iteration 22412 : model1 loss : 0.438512 model2 loss : 0.017703
[00:50:06.922] iteration 22413 : model1 loss : 0.435098 model2 loss : 0.017696
[00:50:07.096] iteration 22414 : model1 loss : 0.441078 model2 loss : 0.017223
[00:50:07.265] iteration 22415 : model1 loss : 0.438962 model2 loss : 0.017000
[00:50:07.439] iteration 22416 : model1 loss : 0.433161 model2 loss : 0.018498
[00:50:07.611] iteration 22417 : model1 loss : 0.441851 model2 loss : 0.019471
[00:50:07.783] iteration 22418 : model1 loss : 0.437094 model2 loss : 0.016700
[00:50:07.954] iteration 22419 : model1 loss : 0.442648 model2 loss : 0.018603
[00:50:08.128] iteration 22420 : model1 loss : 0.439375 model2 loss : 0.019076
[00:50:08.302] iteration 22421 : model1 loss : 0.441163 model2 loss : 0.015990
[00:50:08.472] iteration 22422 : model1 loss : 0.437981 model2 loss : 0.018296
[00:50:08.644] iteration 22423 : model1 loss : 0.440953 model2 loss : 0.015212
[00:50:08.816] iteration 22424 : model1 loss : 0.435907 model2 loss : 0.016378
[00:50:08.987] iteration 22425 : model1 loss : 0.437117 model2 loss : 0.019810
[00:50:09.157] iteration 22426 : model1 loss : 0.442883 model2 loss : 0.017944
[00:50:09.326] iteration 22427 : model1 loss : 0.438720 model2 loss : 0.018191
[00:50:09.496] iteration 22428 : model1 loss : 0.440396 model2 loss : 0.016539
[00:50:11.651] iteration 22429 : model1 loss : 0.435186 model2 loss : 0.016949
[00:50:11.823] iteration 22430 : model1 loss : 0.438783 model2 loss : 0.018822
[00:50:11.997] iteration 22431 : model1 loss : 0.434893 model2 loss : 0.019489
[00:50:12.165] iteration 22432 : model1 loss : 0.436701 model2 loss : 0.017616
[00:50:12.335] iteration 22433 : model1 loss : 0.438817 model2 loss : 0.017737
[00:50:12.506] iteration 22434 : model1 loss : 0.440217 model2 loss : 0.018383
[00:50:12.677] iteration 22435 : model1 loss : 0.444113 model2 loss : 0.019122
[00:50:12.847] iteration 22436 : model1 loss : 0.438638 model2 loss : 0.017369
[00:50:13.019] iteration 22437 : model1 loss : 0.437006 model2 loss : 0.018348
[00:50:13.187] iteration 22438 : model1 loss : 0.439472 model2 loss : 0.017825
[00:50:13.358] iteration 22439 : model1 loss : 0.440761 model2 loss : 0.018977
[00:50:13.527] iteration 22440 : model1 loss : 0.439072 model2 loss : 0.017952
[00:50:13.701] iteration 22441 : model1 loss : 0.440597 model2 loss : 0.018172
[00:50:13.871] iteration 22442 : model1 loss : 0.435479 model2 loss : 0.018252
[00:50:14.044] iteration 22443 : model1 loss : 0.440499 model2 loss : 0.017219
[00:50:14.212] iteration 22444 : model1 loss : 0.439807 model2 loss : 0.017431
[00:50:14.385] iteration 22445 : model1 loss : 0.441614 model2 loss : 0.015833
[00:50:14.556] iteration 22446 : model1 loss : 0.439579 model2 loss : 0.017719
[00:50:14.728] iteration 22447 : model1 loss : 0.437508 model2 loss : 0.019034
[00:50:14.899] iteration 22448 : model1 loss : 0.439915 model2 loss : 0.019072
[00:50:15.070] iteration 22449 : model1 loss : 0.443388 model2 loss : 0.018536
[00:50:17.112] iteration 22450 : model1 loss : 0.436245 model2 loss : 0.017071
[00:50:17.281] iteration 22451 : model1 loss : 0.438307 model2 loss : 0.018945
[00:50:17.457] iteration 22452 : model1 loss : 0.444136 model2 loss : 0.018789
[00:50:17.626] iteration 22453 : model1 loss : 0.436768 model2 loss : 0.018107
[00:50:17.798] iteration 22454 : model1 loss : 0.441914 model2 loss : 0.021168
[00:50:17.968] iteration 22455 : model1 loss : 0.440773 model2 loss : 0.016806
[00:50:18.142] iteration 22456 : model1 loss : 0.436292 model2 loss : 0.018364
[00:50:18.312] iteration 22457 : model1 loss : 0.435679 model2 loss : 0.018139
[00:50:18.483] iteration 22458 : model1 loss : 0.437530 model2 loss : 0.018275
[00:50:18.652] iteration 22459 : model1 loss : 0.434093 model2 loss : 0.016918
[00:50:18.823] iteration 22460 : model1 loss : 0.434545 model2 loss : 0.015741
[00:50:18.994] iteration 22461 : model1 loss : 0.442592 model2 loss : 0.015518
[00:50:19.164] iteration 22462 : model1 loss : 0.441148 model2 loss : 0.020639
[00:50:19.335] iteration 22463 : model1 loss : 0.443243 model2 loss : 0.018288
[00:50:19.508] iteration 22464 : model1 loss : 0.441075 model2 loss : 0.017620
[00:50:19.677] iteration 22465 : model1 loss : 0.438566 model2 loss : 0.016495
[00:50:19.849] iteration 22466 : model1 loss : 0.443386 model2 loss : 0.017752
[00:50:20.021] iteration 22467 : model1 loss : 0.438640 model2 loss : 0.016725
[00:50:20.192] iteration 22468 : model1 loss : 0.435819 model2 loss : 0.017875
[00:50:20.360] iteration 22469 : model1 loss : 0.438027 model2 loss : 0.017998
[00:50:20.529] iteration 22470 : model1 loss : 0.442841 model2 loss : 0.019215
[00:50:22.598] iteration 22471 : model1 loss : 0.443102 model2 loss : 0.017980
[00:50:22.782] iteration 22472 : model1 loss : 0.437674 model2 loss : 0.019227
[00:50:22.956] iteration 22473 : model1 loss : 0.436095 model2 loss : 0.019460
[00:50:23.128] iteration 22474 : model1 loss : 0.440696 model2 loss : 0.015851
[00:50:23.301] iteration 22475 : model1 loss : 0.437336 model2 loss : 0.019105
[00:50:23.468] iteration 22476 : model1 loss : 0.441493 model2 loss : 0.017534
[00:50:23.640] iteration 22477 : model1 loss : 0.442115 model2 loss : 0.019122
[00:50:23.809] iteration 22478 : model1 loss : 0.442678 model2 loss : 0.019922
[00:50:23.982] iteration 22479 : model1 loss : 0.436155 model2 loss : 0.020067
[00:50:24.150] iteration 22480 : model1 loss : 0.437514 model2 loss : 0.017985
[00:50:24.324] iteration 22481 : model1 loss : 0.440117 model2 loss : 0.017456
[00:50:24.496] iteration 22482 : model1 loss : 0.441122 model2 loss : 0.019104
[00:50:24.666] iteration 22483 : model1 loss : 0.439874 model2 loss : 0.016605
[00:50:24.838] iteration 22484 : model1 loss : 0.441258 model2 loss : 0.019508
[00:50:25.010] iteration 22485 : model1 loss : 0.440491 model2 loss : 0.017715
[00:50:25.179] iteration 22486 : model1 loss : 0.431193 model2 loss : 0.016481
[00:50:25.349] iteration 22487 : model1 loss : 0.437626 model2 loss : 0.017604
[00:50:25.518] iteration 22488 : model1 loss : 0.439247 model2 loss : 0.017438
[00:50:25.692] iteration 22489 : model1 loss : 0.444886 model2 loss : 0.019270
[00:50:25.859] iteration 22490 : model1 loss : 0.435470 model2 loss : 0.015899
[00:50:26.031] iteration 22491 : model1 loss : 0.438191 model2 loss : 0.020017
[00:50:28.096] iteration 22492 : model1 loss : 0.440589 model2 loss : 0.020198
[00:50:28.263] iteration 22493 : model1 loss : 0.437536 model2 loss : 0.018475
[00:50:28.436] iteration 22494 : model1 loss : 0.441478 model2 loss : 0.018335
[00:50:28.603] iteration 22495 : model1 loss : 0.437351 model2 loss : 0.016730
[00:50:28.775] iteration 22496 : model1 loss : 0.440485 model2 loss : 0.019929
[00:50:28.946] iteration 22497 : model1 loss : 0.445462 model2 loss : 0.019457
[00:50:29.120] iteration 22498 : model1 loss : 0.439509 model2 loss : 0.017139
[00:50:29.288] iteration 22499 : model1 loss : 0.439370 model2 loss : 0.017293
[00:50:29.458] iteration 22500 : model1 loss : 0.436228 model2 loss : 0.018774
[00:50:29.629] iteration 22501 : model1 loss : 0.442453 model2 loss : 0.018516
[00:50:29.800] iteration 22502 : model1 loss : 0.443914 model2 loss : 0.021306
[00:50:29.972] iteration 22503 : model1 loss : 0.442690 model2 loss : 0.018817
[00:50:30.146] iteration 22504 : model1 loss : 0.434490 model2 loss : 0.019857
[00:50:30.317] iteration 22505 : model1 loss : 0.436408 model2 loss : 0.018338
[00:50:30.487] iteration 22506 : model1 loss : 0.440507 model2 loss : 0.018462
[00:50:30.659] iteration 22507 : model1 loss : 0.440708 model2 loss : 0.018912
[00:50:30.831] iteration 22508 : model1 loss : 0.437697 model2 loss : 0.016258
[00:50:31.002] iteration 22509 : model1 loss : 0.438983 model2 loss : 0.015979
[00:50:31.172] iteration 22510 : model1 loss : 0.437751 model2 loss : 0.016858
[00:50:31.339] iteration 22511 : model1 loss : 0.434242 model2 loss : 0.018868
[00:50:31.509] iteration 22512 : model1 loss : 0.439455 model2 loss : 0.017347
[00:50:33.573] iteration 22513 : model1 loss : 0.439685 model2 loss : 0.017641
[00:50:33.747] iteration 22514 : model1 loss : 0.439470 model2 loss : 0.017723
[00:50:33.922] iteration 22515 : model1 loss : 0.437178 model2 loss : 0.016793
[00:50:34.092] iteration 22516 : model1 loss : 0.443128 model2 loss : 0.017181
[00:50:34.262] iteration 22517 : model1 loss : 0.435028 model2 loss : 0.017473
[00:50:34.430] iteration 22518 : model1 loss : 0.440304 model2 loss : 0.019602
[00:50:34.603] iteration 22519 : model1 loss : 0.436714 model2 loss : 0.016416
[00:50:34.774] iteration 22520 : model1 loss : 0.441864 model2 loss : 0.019619
[00:50:34.947] iteration 22521 : model1 loss : 0.435950 model2 loss : 0.018758
[00:50:35.119] iteration 22522 : model1 loss : 0.438650 model2 loss : 0.018688
[00:50:35.289] iteration 22523 : model1 loss : 0.436770 model2 loss : 0.018065
[00:50:35.457] iteration 22524 : model1 loss : 0.440503 model2 loss : 0.019610
[00:50:35.628] iteration 22525 : model1 loss : 0.442378 model2 loss : 0.019091
[00:50:35.797] iteration 22526 : model1 loss : 0.442118 model2 loss : 0.017481
[00:50:35.971] iteration 22527 : model1 loss : 0.437342 model2 loss : 0.017936
[00:50:36.142] iteration 22528 : model1 loss : 0.439199 model2 loss : 0.016876
[00:50:36.315] iteration 22529 : model1 loss : 0.443206 model2 loss : 0.018298
[00:50:36.482] iteration 22530 : model1 loss : 0.434395 model2 loss : 0.020091
[00:50:36.653] iteration 22531 : model1 loss : 0.439775 model2 loss : 0.017871
[00:50:36.821] iteration 22532 : model1 loss : 0.438718 model2 loss : 0.016348
[00:50:37.000] iteration 22533 : model1 loss : 0.438579 model2 loss : 0.016904
[00:50:39.070] iteration 22534 : model1 loss : 0.438588 model2 loss : 0.019093
[00:50:39.239] iteration 22535 : model1 loss : 0.437201 model2 loss : 0.018192
[00:50:39.413] iteration 22536 : model1 loss : 0.438271 model2 loss : 0.017905
[00:50:39.582] iteration 22537 : model1 loss : 0.441877 model2 loss : 0.019665
[00:50:39.755] iteration 22538 : model1 loss : 0.439442 model2 loss : 0.016178
[00:50:39.926] iteration 22539 : model1 loss : 0.442055 model2 loss : 0.017982
[00:50:40.098] iteration 22540 : model1 loss : 0.439996 model2 loss : 0.016761
[00:50:40.264] iteration 22541 : model1 loss : 0.441522 model2 loss : 0.018890
[00:50:40.435] iteration 22542 : model1 loss : 0.440744 model2 loss : 0.019666
[00:50:40.604] iteration 22543 : model1 loss : 0.443738 model2 loss : 0.021482
[00:50:40.776] iteration 22544 : model1 loss : 0.436875 model2 loss : 0.019852
[00:50:40.947] iteration 22545 : model1 loss : 0.437550 model2 loss : 0.017728
[00:50:41.121] iteration 22546 : model1 loss : 0.438459 model2 loss : 0.018442
[00:50:41.289] iteration 22547 : model1 loss : 0.435191 model2 loss : 0.017779
[00:50:41.463] iteration 22548 : model1 loss : 0.439275 model2 loss : 0.017590
[00:50:41.634] iteration 22549 : model1 loss : 0.439249 model2 loss : 0.017018
[00:50:41.805] iteration 22550 : model1 loss : 0.435601 model2 loss : 0.016131
[00:50:41.980] iteration 22551 : model1 loss : 0.438794 model2 loss : 0.018562
[00:50:42.150] iteration 22552 : model1 loss : 0.439471 model2 loss : 0.016151
[00:50:42.319] iteration 22553 : model1 loss : 0.435672 model2 loss : 0.018788
[00:50:42.494] iteration 22554 : model1 loss : 0.441679 model2 loss : 0.016967
[00:50:44.524] iteration 22555 : model1 loss : 0.436122 model2 loss : 0.017647
[00:50:44.699] iteration 22556 : model1 loss : 0.440194 model2 loss : 0.016230
[00:50:44.874] iteration 22557 : model1 loss : 0.437303 model2 loss : 0.015113
[00:50:45.044] iteration 22558 : model1 loss : 0.436895 model2 loss : 0.018199
[00:50:45.216] iteration 22559 : model1 loss : 0.442470 model2 loss : 0.019195
[00:50:45.385] iteration 22560 : model1 loss : 0.437236 model2 loss : 0.018157
[00:50:45.555] iteration 22561 : model1 loss : 0.442115 model2 loss : 0.020482
[00:50:45.726] iteration 22562 : model1 loss : 0.441185 model2 loss : 0.017599
[00:50:45.898] iteration 22563 : model1 loss : 0.439056 model2 loss : 0.019428
[00:50:46.067] iteration 22564 : model1 loss : 0.437217 model2 loss : 0.017482
[00:50:46.236] iteration 22565 : model1 loss : 0.439153 model2 loss : 0.018865
[00:50:46.403] iteration 22566 : model1 loss : 0.439897 model2 loss : 0.018358
[00:50:46.574] iteration 22567 : model1 loss : 0.436634 model2 loss : 0.019184
[00:50:46.744] iteration 22568 : model1 loss : 0.435623 model2 loss : 0.017918
[00:50:46.917] iteration 22569 : model1 loss : 0.440751 model2 loss : 0.016939
[00:50:47.086] iteration 22570 : model1 loss : 0.441427 model2 loss : 0.018323
[00:50:47.257] iteration 22571 : model1 loss : 0.440405 model2 loss : 0.019735
[00:50:47.429] iteration 22572 : model1 loss : 0.440049 model2 loss : 0.017120
[00:50:47.604] iteration 22573 : model1 loss : 0.440575 model2 loss : 0.017741
[00:50:47.772] iteration 22574 : model1 loss : 0.438299 model2 loss : 0.016587
[00:50:47.944] iteration 22575 : model1 loss : 0.442650 model2 loss : 0.018021
[00:50:50.008] iteration 22576 : model1 loss : 0.432799 model2 loss : 0.015740
[00:50:50.179] iteration 22577 : model1 loss : 0.438588 model2 loss : 0.015916
[00:50:50.351] iteration 22578 : model1 loss : 0.434801 model2 loss : 0.017205
[00:50:50.522] iteration 22579 : model1 loss : 0.440798 model2 loss : 0.019401
[00:50:50.696] iteration 22580 : model1 loss : 0.441530 model2 loss : 0.019953
[00:50:50.865] iteration 22581 : model1 loss : 0.441394 model2 loss : 0.017356
[00:50:51.038] iteration 22582 : model1 loss : 0.436497 model2 loss : 0.019549
[00:50:51.208] iteration 22583 : model1 loss : 0.437947 model2 loss : 0.017736
[00:50:51.378] iteration 22584 : model1 loss : 0.440786 model2 loss : 0.019850
[00:50:51.545] iteration 22585 : model1 loss : 0.440071 model2 loss : 0.018701
[00:50:51.720] iteration 22586 : model1 loss : 0.435872 model2 loss : 0.016937
[00:50:51.890] iteration 22587 : model1 loss : 0.440058 model2 loss : 0.016884
[00:50:52.062] iteration 22588 : model1 loss : 0.446191 model2 loss : 0.023115
[00:50:52.230] iteration 22589 : model1 loss : 0.439537 model2 loss : 0.016669
[00:50:52.400] iteration 22590 : model1 loss : 0.440249 model2 loss : 0.018893
[00:50:52.570] iteration 22591 : model1 loss : 0.437368 model2 loss : 0.017373
[00:50:52.743] iteration 22592 : model1 loss : 0.436166 model2 loss : 0.017667
[00:50:52.912] iteration 22593 : model1 loss : 0.441791 model2 loss : 0.019968
[00:50:53.085] iteration 22594 : model1 loss : 0.438620 model2 loss : 0.018138
[00:50:53.252] iteration 22595 : model1 loss : 0.441202 model2 loss : 0.018643
[00:50:53.421] iteration 22596 : model1 loss : 0.442630 model2 loss : 0.020341
[00:50:55.564] iteration 22597 : model1 loss : 0.435976 model2 loss : 0.017824
[00:50:55.735] iteration 22598 : model1 loss : 0.440459 model2 loss : 0.017691
[00:50:55.912] iteration 22599 : model1 loss : 0.438590 model2 loss : 0.016748
[00:50:56.084] iteration 22600 : model1 loss : 0.440692 model2 loss : 0.018527
[00:50:56.258] iteration 22601 : model1 loss : 0.434591 model2 loss : 0.018807
[00:50:56.429] iteration 22602 : model1 loss : 0.442702 model2 loss : 0.017832
[00:50:56.609] iteration 22603 : model1 loss : 0.441064 model2 loss : 0.016758
[00:50:56.778] iteration 22604 : model1 loss : 0.434191 model2 loss : 0.018602
[00:50:56.952] iteration 22605 : model1 loss : 0.439937 model2 loss : 0.017429
[00:50:57.122] iteration 22606 : model1 loss : 0.438477 model2 loss : 0.019600
[00:50:57.298] iteration 22607 : model1 loss : 0.438888 model2 loss : 0.019444
[00:50:57.475] iteration 22608 : model1 loss : 0.439556 model2 loss : 0.016918
[00:50:57.652] iteration 22609 : model1 loss : 0.442376 model2 loss : 0.020567
[00:50:57.824] iteration 22610 : model1 loss : 0.439298 model2 loss : 0.017469
[00:50:58.011] iteration 22611 : model1 loss : 0.439355 model2 loss : 0.019615
[00:50:58.181] iteration 22612 : model1 loss : 0.438713 model2 loss : 0.019343
[00:50:58.362] iteration 22613 : model1 loss : 0.446267 model2 loss : 0.018820
[00:50:58.531] iteration 22614 : model1 loss : 0.436206 model2 loss : 0.018512
[00:50:58.709] iteration 22615 : model1 loss : 0.440056 model2 loss : 0.017233
[00:50:58.883] iteration 22616 : model1 loss : 0.439181 model2 loss : 0.016414
[00:50:59.058] iteration 22617 : model1 loss : 0.438430 model2 loss : 0.018287
[00:51:01.115] iteration 22618 : model1 loss : 0.441586 model2 loss : 0.015774
[00:51:01.287] iteration 22619 : model1 loss : 0.437970 model2 loss : 0.016571
[00:51:01.469] iteration 22620 : model1 loss : 0.438579 model2 loss : 0.018371
[00:51:01.640] iteration 22621 : model1 loss : 0.436711 model2 loss : 0.017553
[00:51:01.815] iteration 22622 : model1 loss : 0.435934 model2 loss : 0.017099
[00:51:01.991] iteration 22623 : model1 loss : 0.442110 model2 loss : 0.018211
[00:51:02.165] iteration 22624 : model1 loss : 0.435376 model2 loss : 0.018288
[00:51:02.338] iteration 22625 : model1 loss : 0.440564 model2 loss : 0.019655
[00:51:02.519] iteration 22626 : model1 loss : 0.440002 model2 loss : 0.019511
[00:51:02.692] iteration 22627 : model1 loss : 0.437989 model2 loss : 0.019699
[00:51:02.873] iteration 22628 : model1 loss : 0.437503 model2 loss : 0.017091
[00:51:03.047] iteration 22629 : model1 loss : 0.442755 model2 loss : 0.018522
[00:51:03.252] iteration 22630 : model1 loss : 0.441999 model2 loss : 0.018520
[00:51:03.480] iteration 22631 : model1 loss : 0.435502 model2 loss : 0.017530
[00:51:03.660] iteration 22632 : model1 loss : 0.442365 model2 loss : 0.018825
[00:51:03.864] iteration 22633 : model1 loss : 0.435333 model2 loss : 0.017863
[00:51:04.079] iteration 22634 : model1 loss : 0.441815 model2 loss : 0.017582
[00:51:04.286] iteration 22635 : model1 loss : 0.442643 model2 loss : 0.019790
[00:51:04.472] iteration 22636 : model1 loss : 0.440904 model2 loss : 0.017332
[00:51:04.673] iteration 22637 : model1 loss : 0.437155 model2 loss : 0.016253
[00:51:04.869] iteration 22638 : model1 loss : 0.437631 model2 loss : 0.019209
[00:51:07.434] iteration 22639 : model1 loss : 0.436119 model2 loss : 0.017307
[00:51:07.614] iteration 22640 : model1 loss : 0.436119 model2 loss : 0.016454
[00:51:07.793] iteration 22641 : model1 loss : 0.442176 model2 loss : 0.018237
[00:51:07.965] iteration 22642 : model1 loss : 0.437419 model2 loss : 0.016403
[00:51:08.144] iteration 22643 : model1 loss : 0.438811 model2 loss : 0.019875
[00:51:08.320] iteration 22644 : model1 loss : 0.443262 model2 loss : 0.017849
[00:51:08.496] iteration 22645 : model1 loss : 0.439324 model2 loss : 0.017542
[00:51:08.677] iteration 22646 : model1 loss : 0.442256 model2 loss : 0.017482
[00:51:08.856] iteration 22647 : model1 loss : 0.440427 model2 loss : 0.018498
[00:51:09.029] iteration 22648 : model1 loss : 0.440956 model2 loss : 0.016406
[00:51:09.209] iteration 22649 : model1 loss : 0.436867 model2 loss : 0.017504
[00:51:09.380] iteration 22650 : model1 loss : 0.438805 model2 loss : 0.017794
[00:51:09.557] iteration 22651 : model1 loss : 0.434063 model2 loss : 0.017844
[00:51:09.733] iteration 22652 : model1 loss : 0.438633 model2 loss : 0.017302
[00:51:09.914] iteration 22653 : model1 loss : 0.437642 model2 loss : 0.015584
[00:51:10.094] iteration 22654 : model1 loss : 0.437896 model2 loss : 0.019270
[00:51:10.275] iteration 22655 : model1 loss : 0.439692 model2 loss : 0.017702
[00:51:10.449] iteration 22656 : model1 loss : 0.436191 model2 loss : 0.017301
[00:51:10.627] iteration 22657 : model1 loss : 0.436261 model2 loss : 0.018592
[00:51:10.800] iteration 22658 : model1 loss : 0.443556 model2 loss : 0.017881
[00:51:10.986] iteration 22659 : model1 loss : 0.443449 model2 loss : 0.018463
[00:51:13.740] iteration 22660 : model1 loss : 0.439155 model2 loss : 0.016879
[00:51:13.946] iteration 22661 : model1 loss : 0.439159 model2 loss : 0.019729
[00:51:14.145] iteration 22662 : model1 loss : 0.436742 model2 loss : 0.017129
[00:51:14.325] iteration 22663 : model1 loss : 0.442795 model2 loss : 0.017430
[00:51:14.498] iteration 22664 : model1 loss : 0.441315 model2 loss : 0.016556
[00:51:14.672] iteration 22665 : model1 loss : 0.437795 model2 loss : 0.018379
[00:51:14.869] iteration 22666 : model1 loss : 0.437096 model2 loss : 0.015207
[00:51:15.140] iteration 22667 : model1 loss : 0.436757 model2 loss : 0.016321
[00:51:15.315] iteration 22668 : model1 loss : 0.437070 model2 loss : 0.019030
[00:51:15.495] iteration 22669 : model1 loss : 0.441832 model2 loss : 0.016017
[00:51:15.671] iteration 22670 : model1 loss : 0.435700 model2 loss : 0.018943
[00:51:15.847] iteration 22671 : model1 loss : 0.438863 model2 loss : 0.018697
[00:51:16.020] iteration 22672 : model1 loss : 0.436921 model2 loss : 0.019032
[00:51:16.212] iteration 22673 : model1 loss : 0.441588 model2 loss : 0.017926
[00:51:16.381] iteration 22674 : model1 loss : 0.441254 model2 loss : 0.018021
[00:51:16.555] iteration 22675 : model1 loss : 0.439397 model2 loss : 0.017935
[00:51:16.736] iteration 22676 : model1 loss : 0.442024 model2 loss : 0.018222
[00:51:16.919] iteration 22677 : model1 loss : 0.441400 model2 loss : 0.020091
[00:51:17.099] iteration 22678 : model1 loss : 0.434955 model2 loss : 0.017761
[00:51:17.272] iteration 22679 : model1 loss : 0.437633 model2 loss : 0.017755
[00:51:17.441] iteration 22680 : model1 loss : 0.435542 model2 loss : 0.018627
[00:51:19.606] iteration 22681 : model1 loss : 0.440217 model2 loss : 0.018099
[00:51:19.797] iteration 22682 : model1 loss : 0.435363 model2 loss : 0.017996
[00:51:19.976] iteration 22683 : model1 loss : 0.438860 model2 loss : 0.015868
[00:51:20.154] iteration 22684 : model1 loss : 0.436336 model2 loss : 0.016993
[00:51:20.337] iteration 22685 : model1 loss : 0.443159 model2 loss : 0.019370
[00:51:20.509] iteration 22686 : model1 loss : 0.438240 model2 loss : 0.019260
[00:51:20.683] iteration 22687 : model1 loss : 0.440351 model2 loss : 0.017341
[00:51:20.851] iteration 22688 : model1 loss : 0.439526 model2 loss : 0.017634
[00:51:21.023] iteration 22689 : model1 loss : 0.439926 model2 loss : 0.016644
[00:51:21.192] iteration 22690 : model1 loss : 0.439806 model2 loss : 0.015782
[00:51:21.365] iteration 22691 : model1 loss : 0.439496 model2 loss : 0.017986
[00:51:21.532] iteration 22692 : model1 loss : 0.434100 model2 loss : 0.017631
[00:51:21.706] iteration 22693 : model1 loss : 0.441538 model2 loss : 0.017622
[00:51:21.875] iteration 22694 : model1 loss : 0.444591 model2 loss : 0.022163
[00:51:22.046] iteration 22695 : model1 loss : 0.440237 model2 loss : 0.017182
[00:51:22.227] iteration 22696 : model1 loss : 0.443042 model2 loss : 0.021935
[00:51:22.426] iteration 22697 : model1 loss : 0.437305 model2 loss : 0.017957
[00:51:22.618] iteration 22698 : model1 loss : 0.437230 model2 loss : 0.019123
[00:51:22.817] iteration 22699 : model1 loss : 0.439994 model2 loss : 0.017322
[00:51:23.009] iteration 22700 : model1 loss : 0.435644 model2 loss : 0.016720
[00:51:23.214] iteration 22701 : model1 loss : 0.441847 model2 loss : 0.019076
[00:51:25.596] iteration 22702 : model1 loss : 0.440921 model2 loss : 0.017005
[00:51:25.784] iteration 22703 : model1 loss : 0.443779 model2 loss : 0.019303
[00:51:25.972] iteration 22704 : model1 loss : 0.437464 model2 loss : 0.018575
[00:51:26.161] iteration 22705 : model1 loss : 0.435206 model2 loss : 0.019831
[00:51:26.355] iteration 22706 : model1 loss : 0.441013 model2 loss : 0.018965
[00:51:26.539] iteration 22707 : model1 loss : 0.442860 model2 loss : 0.018509
[00:51:26.736] iteration 22708 : model1 loss : 0.438651 model2 loss : 0.018812
[00:51:26.959] iteration 22709 : model1 loss : 0.442794 model2 loss : 0.018678
[00:51:27.154] iteration 22710 : model1 loss : 0.446107 model2 loss : 0.020439
[00:51:27.349] iteration 22711 : model1 loss : 0.437076 model2 loss : 0.018774
[00:51:27.532] iteration 22712 : model1 loss : 0.436256 model2 loss : 0.017383
[00:51:27.722] iteration 22713 : model1 loss : 0.442270 model2 loss : 0.015731
[00:51:27.907] iteration 22714 : model1 loss : 0.436778 model2 loss : 0.019814
[00:51:28.119] iteration 22715 : model1 loss : 0.437619 model2 loss : 0.020564
[00:51:28.308] iteration 22716 : model1 loss : 0.440449 model2 loss : 0.016883
[00:51:28.494] iteration 22717 : model1 loss : 0.436535 model2 loss : 0.018687
[00:51:28.666] iteration 22718 : model1 loss : 0.432619 model2 loss : 0.016785
[00:51:28.912] iteration 22719 : model1 loss : 0.438430 model2 loss : 0.018015
[00:51:29.193] iteration 22720 : model1 loss : 0.440681 model2 loss : 0.018569
[00:51:29.382] iteration 22721 : model1 loss : 0.437534 model2 loss : 0.019780
[00:51:29.568] iteration 22722 : model1 loss : 0.441650 model2 loss : 0.020594
[00:51:31.705] iteration 22723 : model1 loss : 0.443112 model2 loss : 0.020280
[00:51:31.874] iteration 22724 : model1 loss : 0.437354 model2 loss : 0.018698
[00:51:32.048] iteration 22725 : model1 loss : 0.435300 model2 loss : 0.017327
[00:51:32.217] iteration 22726 : model1 loss : 0.438703 model2 loss : 0.017746
[00:51:32.389] iteration 22727 : model1 loss : 0.437064 model2 loss : 0.018158
[00:51:32.558] iteration 22728 : model1 loss : 0.440111 model2 loss : 0.018144
[00:51:32.731] iteration 22729 : model1 loss : 0.439388 model2 loss : 0.017950
[00:51:32.899] iteration 22730 : model1 loss : 0.435592 model2 loss : 0.017740
[00:51:33.072] iteration 22731 : model1 loss : 0.436531 model2 loss : 0.020184
[00:51:33.239] iteration 22732 : model1 loss : 0.436391 model2 loss : 0.019202
[00:51:33.411] iteration 22733 : model1 loss : 0.438387 model2 loss : 0.018972
[00:51:33.579] iteration 22734 : model1 loss : 0.446734 model2 loss : 0.021676
[00:51:33.750] iteration 22735 : model1 loss : 0.444843 model2 loss : 0.019817
[00:51:33.919] iteration 22736 : model1 loss : 0.436663 model2 loss : 0.017179
[00:51:34.090] iteration 22737 : model1 loss : 0.443240 model2 loss : 0.018425
[00:51:34.260] iteration 22738 : model1 loss : 0.441301 model2 loss : 0.016894
[00:51:34.433] iteration 22739 : model1 loss : 0.438710 model2 loss : 0.018458
[00:51:34.601] iteration 22740 : model1 loss : 0.438364 model2 loss : 0.018167
[00:51:34.774] iteration 22741 : model1 loss : 0.437337 model2 loss : 0.018789
[00:51:34.940] iteration 22742 : model1 loss : 0.439145 model2 loss : 0.018039
[00:51:35.113] iteration 22743 : model1 loss : 0.440788 model2 loss : 0.020815
[00:51:37.105] iteration 22744 : model1 loss : 0.444156 model2 loss : 0.022153
[00:51:37.273] iteration 22745 : model1 loss : 0.443316 model2 loss : 0.019461
[00:51:37.450] iteration 22746 : model1 loss : 0.437897 model2 loss : 0.016670
[00:51:37.618] iteration 22747 : model1 loss : 0.439751 model2 loss : 0.015860
[00:51:37.791] iteration 22748 : model1 loss : 0.440021 model2 loss : 0.018536
[00:51:37.959] iteration 22749 : model1 loss : 0.439294 model2 loss : 0.017688
[00:51:38.131] iteration 22750 : model1 loss : 0.440263 model2 loss : 0.018164
[00:51:38.300] iteration 22751 : model1 loss : 0.442030 model2 loss : 0.018271
[00:51:38.472] iteration 22752 : model1 loss : 0.443115 model2 loss : 0.017785
[00:51:38.638] iteration 22753 : model1 loss : 0.439953 model2 loss : 0.021312
[00:51:38.812] iteration 22754 : model1 loss : 0.438349 model2 loss : 0.019098
[00:51:38.981] iteration 22755 : model1 loss : 0.436803 model2 loss : 0.018536
[00:51:39.154] iteration 22756 : model1 loss : 0.436683 model2 loss : 0.019302
[00:51:39.324] iteration 22757 : model1 loss : 0.437454 model2 loss : 0.019247
[00:51:39.496] iteration 22758 : model1 loss : 0.435906 model2 loss : 0.020370
[00:51:39.663] iteration 22759 : model1 loss : 0.443100 model2 loss : 0.021945
[00:51:39.836] iteration 22760 : model1 loss : 0.438127 model2 loss : 0.015571
[00:51:40.005] iteration 22761 : model1 loss : 0.439745 model2 loss : 0.017742
[00:51:40.176] iteration 22762 : model1 loss : 0.435702 model2 loss : 0.019185
[00:51:40.344] iteration 22763 : model1 loss : 0.435535 model2 loss : 0.018295
[00:51:40.514] iteration 22764 : model1 loss : 0.437677 model2 loss : 0.016323
[00:51:42.483] iteration 22765 : model1 loss : 0.436406 model2 loss : 0.018487
[00:51:42.650] iteration 22766 : model1 loss : 0.436230 model2 loss : 0.015676
[00:51:42.824] iteration 22767 : model1 loss : 0.444303 model2 loss : 0.019302
[00:51:42.993] iteration 22768 : model1 loss : 0.437355 model2 loss : 0.019325
[00:51:43.167] iteration 22769 : model1 loss : 0.440109 model2 loss : 0.020697
[00:51:43.335] iteration 22770 : model1 loss : 0.438931 model2 loss : 0.017671
[00:51:43.507] iteration 22771 : model1 loss : 0.440103 model2 loss : 0.020392
[00:51:43.674] iteration 22772 : model1 loss : 0.437905 model2 loss : 0.017449
[00:51:43.845] iteration 22773 : model1 loss : 0.439946 model2 loss : 0.018720
[00:51:44.013] iteration 22774 : model1 loss : 0.439992 model2 loss : 0.020677
[00:51:44.184] iteration 22775 : model1 loss : 0.440512 model2 loss : 0.017542
[00:51:44.351] iteration 22776 : model1 loss : 0.437245 model2 loss : 0.018257
[00:51:44.529] iteration 22777 : model1 loss : 0.438490 model2 loss : 0.016422
[00:51:44.697] iteration 22778 : model1 loss : 0.436913 model2 loss : 0.018242
[00:51:44.868] iteration 22779 : model1 loss : 0.444334 model2 loss : 0.020640
[00:51:45.036] iteration 22780 : model1 loss : 0.437636 model2 loss : 0.017776
[00:51:45.208] iteration 22781 : model1 loss : 0.440634 model2 loss : 0.019590
[00:51:45.377] iteration 22782 : model1 loss : 0.438159 model2 loss : 0.017251
[00:51:45.547] iteration 22783 : model1 loss : 0.437766 model2 loss : 0.015905
[00:51:45.712] iteration 22784 : model1 loss : 0.443070 model2 loss : 0.019959
[00:51:45.884] iteration 22785 : model1 loss : 0.439080 model2 loss : 0.017966
[00:51:47.859] iteration 22786 : model1 loss : 0.440517 model2 loss : 0.017431
[00:51:48.027] iteration 22787 : model1 loss : 0.439323 model2 loss : 0.018285
[00:51:48.202] iteration 22788 : model1 loss : 0.439340 model2 loss : 0.018120
[00:51:48.370] iteration 22789 : model1 loss : 0.440091 model2 loss : 0.018867
[00:51:48.541] iteration 22790 : model1 loss : 0.441072 model2 loss : 0.019806
[00:51:48.709] iteration 22791 : model1 loss : 0.442027 model2 loss : 0.020805
[00:51:48.879] iteration 22792 : model1 loss : 0.437150 model2 loss : 0.019354
[00:51:49.046] iteration 22793 : model1 loss : 0.440914 model2 loss : 0.015678
[00:51:49.219] iteration 22794 : model1 loss : 0.440909 model2 loss : 0.017397
[00:51:49.387] iteration 22795 : model1 loss : 0.434158 model2 loss : 0.017153
[00:51:49.560] iteration 22796 : model1 loss : 0.436783 model2 loss : 0.016996
[00:51:49.726] iteration 22797 : model1 loss : 0.436913 model2 loss : 0.016991
[00:51:49.901] iteration 22798 : model1 loss : 0.437075 model2 loss : 0.018354
[00:51:50.068] iteration 22799 : model1 loss : 0.441543 model2 loss : 0.018024
[00:51:50.238] iteration 22800 : model1 loss : 0.437531 model2 loss : 0.018048
[00:51:50.406] iteration 22801 : model1 loss : 0.442048 model2 loss : 0.018666
[00:51:50.579] iteration 22802 : model1 loss : 0.438468 model2 loss : 0.018603
[00:51:50.747] iteration 22803 : model1 loss : 0.439265 model2 loss : 0.018596
[00:51:50.921] iteration 22804 : model1 loss : 0.441529 model2 loss : 0.018616
[00:51:51.088] iteration 22805 : model1 loss : 0.437957 model2 loss : 0.017504
[00:51:51.259] iteration 22806 : model1 loss : 0.440789 model2 loss : 0.018342
[00:51:53.226] iteration 22807 : model1 loss : 0.442004 model2 loss : 0.017090
[00:51:53.395] iteration 22808 : model1 loss : 0.442259 model2 loss : 0.017761
[00:51:53.571] iteration 22809 : model1 loss : 0.438070 model2 loss : 0.018357
[00:51:53.737] iteration 22810 : model1 loss : 0.437466 model2 loss : 0.016831
[00:51:53.910] iteration 22811 : model1 loss : 0.439108 model2 loss : 0.020287
[00:51:54.078] iteration 22812 : model1 loss : 0.436697 model2 loss : 0.016874
[00:51:54.251] iteration 22813 : model1 loss : 0.441303 model2 loss : 0.020167
[00:51:54.418] iteration 22814 : model1 loss : 0.437564 model2 loss : 0.018195
[00:51:54.590] iteration 22815 : model1 loss : 0.436640 model2 loss : 0.018328
[00:51:54.758] iteration 22816 : model1 loss : 0.436356 model2 loss : 0.017886
[00:51:54.930] iteration 22817 : model1 loss : 0.440848 model2 loss : 0.018539
[00:51:55.098] iteration 22818 : model1 loss : 0.439361 model2 loss : 0.018150
[00:51:55.271] iteration 22819 : model1 loss : 0.440103 model2 loss : 0.017076
[00:51:55.440] iteration 22820 : model1 loss : 0.444642 model2 loss : 0.021283
[00:51:55.611] iteration 22821 : model1 loss : 0.443096 model2 loss : 0.016618
[00:51:55.779] iteration 22822 : model1 loss : 0.438081 model2 loss : 0.017682
[00:51:55.951] iteration 22823 : model1 loss : 0.437150 model2 loss : 0.015477
[00:51:56.121] iteration 22824 : model1 loss : 0.435721 model2 loss : 0.018213
[00:51:56.293] iteration 22825 : model1 loss : 0.438967 model2 loss : 0.017430
[00:51:56.458] iteration 22826 : model1 loss : 0.438849 model2 loss : 0.019239
[00:51:56.629] iteration 22827 : model1 loss : 0.440441 model2 loss : 0.019154
[00:51:58.622] iteration 22828 : model1 loss : 0.441664 model2 loss : 0.017190
[00:51:58.789] iteration 22829 : model1 loss : 0.437006 model2 loss : 0.018512
[00:51:58.966] iteration 22830 : model1 loss : 0.439689 model2 loss : 0.017716
[00:51:59.136] iteration 22831 : model1 loss : 0.441737 model2 loss : 0.017855
[00:51:59.310] iteration 22832 : model1 loss : 0.441074 model2 loss : 0.017587
[00:51:59.478] iteration 22833 : model1 loss : 0.437529 model2 loss : 0.017141
[00:51:59.650] iteration 22834 : model1 loss : 0.441809 model2 loss : 0.019059
[00:51:59.818] iteration 22835 : model1 loss : 0.440880 model2 loss : 0.016980
[00:51:59.991] iteration 22836 : model1 loss : 0.439251 model2 loss : 0.017113
[00:52:00.164] iteration 22837 : model1 loss : 0.438744 model2 loss : 0.016005
[00:52:00.338] iteration 22838 : model1 loss : 0.436080 model2 loss : 0.016340
[00:52:00.506] iteration 22839 : model1 loss : 0.437988 model2 loss : 0.017386
[00:52:00.679] iteration 22840 : model1 loss : 0.436331 model2 loss : 0.017728
[00:52:00.849] iteration 22841 : model1 loss : 0.440285 model2 loss : 0.018262
[00:52:01.020] iteration 22842 : model1 loss : 0.438402 model2 loss : 0.016762
[00:52:01.188] iteration 22843 : model1 loss : 0.439351 model2 loss : 0.016970
[00:52:01.362] iteration 22844 : model1 loss : 0.441533 model2 loss : 0.017989
[00:52:01.530] iteration 22845 : model1 loss : 0.438797 model2 loss : 0.018078
[00:52:01.701] iteration 22846 : model1 loss : 0.440118 model2 loss : 0.019345
[00:52:01.869] iteration 22847 : model1 loss : 0.433593 model2 loss : 0.018723
[00:52:02.040] iteration 22848 : model1 loss : 0.441987 model2 loss : 0.017259
[00:52:04.026] iteration 22849 : model1 loss : 0.440750 model2 loss : 0.017480
[00:52:04.195] iteration 22850 : model1 loss : 0.438438 model2 loss : 0.016592
[00:52:04.370] iteration 22851 : model1 loss : 0.441308 model2 loss : 0.017645
[00:52:04.537] iteration 22852 : model1 loss : 0.440670 model2 loss : 0.018223
[00:52:04.709] iteration 22853 : model1 loss : 0.438470 model2 loss : 0.018489
[00:52:04.877] iteration 22854 : model1 loss : 0.438207 model2 loss : 0.017747
[00:52:05.050] iteration 22855 : model1 loss : 0.435711 model2 loss : 0.017312
[00:52:05.217] iteration 22856 : model1 loss : 0.440012 model2 loss : 0.015106
[00:52:05.390] iteration 22857 : model1 loss : 0.436107 model2 loss : 0.019183
[00:52:05.557] iteration 22858 : model1 loss : 0.438497 model2 loss : 0.018522
[00:52:05.729] iteration 22859 : model1 loss : 0.436589 model2 loss : 0.016332
[00:52:05.897] iteration 22860 : model1 loss : 0.440895 model2 loss : 0.018116
[00:52:06.067] iteration 22861 : model1 loss : 0.438854 model2 loss : 0.019276
[00:52:06.234] iteration 22862 : model1 loss : 0.433801 model2 loss : 0.017048
[00:52:06.407] iteration 22863 : model1 loss : 0.441620 model2 loss : 0.019698
[00:52:06.574] iteration 22864 : model1 loss : 0.440811 model2 loss : 0.016795
[00:52:06.748] iteration 22865 : model1 loss : 0.440929 model2 loss : 0.016611
[00:52:06.916] iteration 22866 : model1 loss : 0.439719 model2 loss : 0.019377
[00:52:07.088] iteration 22867 : model1 loss : 0.442745 model2 loss : 0.016923
[00:52:07.256] iteration 22868 : model1 loss : 0.442445 model2 loss : 0.015660
[00:52:07.429] iteration 22869 : model1 loss : 0.437021 model2 loss : 0.020391
[00:52:09.387] iteration 22870 : model1 loss : 0.438979 model2 loss : 0.019678
[00:52:09.556] iteration 22871 : model1 loss : 0.436776 model2 loss : 0.019590
[00:52:09.731] iteration 22872 : model1 loss : 0.435261 model2 loss : 0.015621
[00:52:09.900] iteration 22873 : model1 loss : 0.438764 model2 loss : 0.019287
[00:52:10.071] iteration 22874 : model1 loss : 0.438896 model2 loss : 0.017040
[00:52:10.239] iteration 22875 : model1 loss : 0.438133 model2 loss : 0.017070
[00:52:10.408] iteration 22876 : model1 loss : 0.440574 model2 loss : 0.019171
[00:52:10.576] iteration 22877 : model1 loss : 0.439921 model2 loss : 0.019074
[00:52:10.750] iteration 22878 : model1 loss : 0.439992 model2 loss : 0.017318
[00:52:10.919] iteration 22879 : model1 loss : 0.443995 model2 loss : 0.019924
[00:52:11.102] iteration 22880 : model1 loss : 0.441872 model2 loss : 0.019135
[00:52:11.268] iteration 22881 : model1 loss : 0.439277 model2 loss : 0.020824
[00:52:11.441] iteration 22882 : model1 loss : 0.439605 model2 loss : 0.018278
[00:52:11.607] iteration 22883 : model1 loss : 0.442143 model2 loss : 0.019247
[00:52:11.779] iteration 22884 : model1 loss : 0.439220 model2 loss : 0.016998
[00:52:11.946] iteration 22885 : model1 loss : 0.439664 model2 loss : 0.017092
[00:52:12.121] iteration 22886 : model1 loss : 0.442682 model2 loss : 0.019235
[00:52:12.285] iteration 22887 : model1 loss : 0.435812 model2 loss : 0.016063
[00:52:12.459] iteration 22888 : model1 loss : 0.439970 model2 loss : 0.016684
[00:52:12.625] iteration 22889 : model1 loss : 0.437524 model2 loss : 0.015687
[00:52:12.795] iteration 22890 : model1 loss : 0.438754 model2 loss : 0.017191
[00:52:14.752] iteration 22891 : model1 loss : 0.434910 model2 loss : 0.017799
[00:52:14.921] iteration 22892 : model1 loss : 0.440942 model2 loss : 0.016867
[00:52:15.094] iteration 22893 : model1 loss : 0.442040 model2 loss : 0.019307
[00:52:15.261] iteration 22894 : model1 loss : 0.440623 model2 loss : 0.018428
[00:52:15.432] iteration 22895 : model1 loss : 0.441400 model2 loss : 0.017768
[00:52:15.599] iteration 22896 : model1 loss : 0.435208 model2 loss : 0.018424
[00:52:15.770] iteration 22897 : model1 loss : 0.439510 model2 loss : 0.017103
[00:52:15.939] iteration 22898 : model1 loss : 0.442919 model2 loss : 0.019954
[00:52:16.109] iteration 22899 : model1 loss : 0.441690 model2 loss : 0.018739
[00:52:16.276] iteration 22900 : model1 loss : 0.434086 model2 loss : 0.016205
[00:52:16.447] iteration 22901 : model1 loss : 0.437159 model2 loss : 0.017303
[00:52:16.614] iteration 22902 : model1 loss : 0.439536 model2 loss : 0.015752
[00:52:16.786] iteration 22903 : model1 loss : 0.434503 model2 loss : 0.018981
[00:52:16.953] iteration 22904 : model1 loss : 0.439430 model2 loss : 0.017528
[00:52:17.127] iteration 22905 : model1 loss : 0.439096 model2 loss : 0.018184
[00:52:17.293] iteration 22906 : model1 loss : 0.437728 model2 loss : 0.016117
[00:52:17.466] iteration 22907 : model1 loss : 0.439825 model2 loss : 0.018381
[00:52:17.633] iteration 22908 : model1 loss : 0.444006 model2 loss : 0.018406
[00:52:17.805] iteration 22909 : model1 loss : 0.443656 model2 loss : 0.019309
[00:52:17.971] iteration 22910 : model1 loss : 0.436818 model2 loss : 0.017356
[00:52:18.144] iteration 22911 : model1 loss : 0.438470 model2 loss : 0.018472
[00:52:20.118] iteration 22912 : model1 loss : 0.437970 model2 loss : 0.016511
[00:52:20.286] iteration 22913 : model1 loss : 0.442422 model2 loss : 0.020764
[00:52:20.459] iteration 22914 : model1 loss : 0.437601 model2 loss : 0.018629
[00:52:20.627] iteration 22915 : model1 loss : 0.442236 model2 loss : 0.018217
[00:52:20.798] iteration 22916 : model1 loss : 0.438374 model2 loss : 0.017497
[00:52:20.965] iteration 22917 : model1 loss : 0.441041 model2 loss : 0.019464
[00:52:21.140] iteration 22918 : model1 loss : 0.438665 model2 loss : 0.018352
[00:52:21.310] iteration 22919 : model1 loss : 0.434214 model2 loss : 0.016121
[00:52:21.481] iteration 22920 : model1 loss : 0.445732 model2 loss : 0.019632
[00:52:21.648] iteration 22921 : model1 loss : 0.441356 model2 loss : 0.017501
[00:52:21.822] iteration 22922 : model1 loss : 0.440698 model2 loss : 0.019737
[00:52:21.990] iteration 22923 : model1 loss : 0.435309 model2 loss : 0.015681
[00:52:22.166] iteration 22924 : model1 loss : 0.436967 model2 loss : 0.016944
[00:52:22.333] iteration 22925 : model1 loss : 0.434993 model2 loss : 0.015863
[00:52:22.505] iteration 22926 : model1 loss : 0.442016 model2 loss : 0.019245
[00:52:22.674] iteration 22927 : model1 loss : 0.438474 model2 loss : 0.017041
[00:52:22.845] iteration 22928 : model1 loss : 0.438723 model2 loss : 0.019445
[00:52:23.015] iteration 22929 : model1 loss : 0.441674 model2 loss : 0.016343
[00:52:23.186] iteration 22930 : model1 loss : 0.440445 model2 loss : 0.017253
[00:52:23.353] iteration 22931 : model1 loss : 0.441629 model2 loss : 0.018309
[00:52:23.524] iteration 22932 : model1 loss : 0.434701 model2 loss : 0.015724
[00:52:25.512] iteration 22933 : model1 loss : 0.440059 model2 loss : 0.020546
[00:52:25.681] iteration 22934 : model1 loss : 0.437634 model2 loss : 0.016776
[00:52:25.855] iteration 22935 : model1 loss : 0.440962 model2 loss : 0.018516
[00:52:26.021] iteration 22936 : model1 loss : 0.442458 model2 loss : 0.018881
[00:52:26.196] iteration 22937 : model1 loss : 0.437016 model2 loss : 0.016440
[00:52:26.364] iteration 22938 : model1 loss : 0.441680 model2 loss : 0.019078
[00:52:26.537] iteration 22939 : model1 loss : 0.438824 model2 loss : 0.017765
[00:52:26.706] iteration 22940 : model1 loss : 0.440776 model2 loss : 0.017975
[00:52:26.878] iteration 22941 : model1 loss : 0.437898 model2 loss : 0.016476
[00:52:27.045] iteration 22942 : model1 loss : 0.439465 model2 loss : 0.018342
[00:52:27.218] iteration 22943 : model1 loss : 0.439138 model2 loss : 0.018525
[00:52:27.385] iteration 22944 : model1 loss : 0.438799 model2 loss : 0.017648
[00:52:27.556] iteration 22945 : model1 loss : 0.434832 model2 loss : 0.018491
[00:52:27.725] iteration 22946 : model1 loss : 0.443556 model2 loss : 0.017486
[00:52:27.897] iteration 22947 : model1 loss : 0.439713 model2 loss : 0.017700
[00:52:28.063] iteration 22948 : model1 loss : 0.440669 model2 loss : 0.017722
[00:52:28.235] iteration 22949 : model1 loss : 0.438916 model2 loss : 0.017313
[00:52:28.403] iteration 22950 : model1 loss : 0.439640 model2 loss : 0.019370
[00:52:28.574] iteration 22951 : model1 loss : 0.437702 model2 loss : 0.017860
[00:52:28.741] iteration 22952 : model1 loss : 0.437348 model2 loss : 0.018728
[00:52:28.914] iteration 22953 : model1 loss : 0.440312 model2 loss : 0.016248
[00:52:30.858] iteration 22954 : model1 loss : 0.435667 model2 loss : 0.017190
[00:52:31.030] iteration 22955 : model1 loss : 0.444245 model2 loss : 0.017163
[00:52:31.203] iteration 22956 : model1 loss : 0.444169 model2 loss : 0.017811
[00:52:31.370] iteration 22957 : model1 loss : 0.438828 model2 loss : 0.015556
[00:52:31.542] iteration 22958 : model1 loss : 0.437935 model2 loss : 0.019038
[00:52:31.708] iteration 22959 : model1 loss : 0.440609 model2 loss : 0.017185
[00:52:31.880] iteration 22960 : model1 loss : 0.440215 model2 loss : 0.017236
[00:52:32.050] iteration 22961 : model1 loss : 0.444049 model2 loss : 0.017609
[00:52:32.223] iteration 22962 : model1 loss : 0.439483 model2 loss : 0.017324
[00:52:32.391] iteration 22963 : model1 loss : 0.436935 model2 loss : 0.017304
[00:52:32.564] iteration 22964 : model1 loss : 0.440143 model2 loss : 0.017997
[00:52:32.731] iteration 22965 : model1 loss : 0.436857 model2 loss : 0.018604
[00:52:32.904] iteration 22966 : model1 loss : 0.438330 model2 loss : 0.016686
[00:52:33.075] iteration 22967 : model1 loss : 0.434844 model2 loss : 0.015584
[00:52:33.246] iteration 22968 : model1 loss : 0.437050 model2 loss : 0.018131
[00:52:33.411] iteration 22969 : model1 loss : 0.435136 model2 loss : 0.016444
[00:52:33.581] iteration 22970 : model1 loss : 0.438290 model2 loss : 0.019339
[00:52:33.748] iteration 22971 : model1 loss : 0.439189 model2 loss : 0.021654
[00:52:33.921] iteration 22972 : model1 loss : 0.441064 model2 loss : 0.018850
[00:52:34.086] iteration 22973 : model1 loss : 0.442503 model2 loss : 0.019796
[00:52:34.255] iteration 22974 : model1 loss : 0.440424 model2 loss : 0.017805
[00:52:36.197] iteration 22975 : model1 loss : 0.443104 model2 loss : 0.019917
[00:52:36.365] iteration 22976 : model1 loss : 0.442289 model2 loss : 0.017676
[00:52:36.539] iteration 22977 : model1 loss : 0.433397 model2 loss : 0.017270
[00:52:36.707] iteration 22978 : model1 loss : 0.438664 model2 loss : 0.019711
[00:52:36.877] iteration 22979 : model1 loss : 0.439511 model2 loss : 0.018326
[00:52:37.046] iteration 22980 : model1 loss : 0.440450 model2 loss : 0.018063
[00:52:37.218] iteration 22981 : model1 loss : 0.436233 model2 loss : 0.015492
[00:52:37.386] iteration 22982 : model1 loss : 0.436804 model2 loss : 0.019325
[00:52:37.558] iteration 22983 : model1 loss : 0.439654 model2 loss : 0.018039
[00:52:37.725] iteration 22984 : model1 loss : 0.440008 model2 loss : 0.017448
[00:52:37.898] iteration 22985 : model1 loss : 0.439317 model2 loss : 0.019099
[00:52:38.066] iteration 22986 : model1 loss : 0.435704 model2 loss : 0.016623
[00:52:38.238] iteration 22987 : model1 loss : 0.443978 model2 loss : 0.020684
[00:52:38.406] iteration 22988 : model1 loss : 0.433725 model2 loss : 0.016279
[00:52:38.578] iteration 22989 : model1 loss : 0.438946 model2 loss : 0.019448
[00:52:38.745] iteration 22990 : model1 loss : 0.442607 model2 loss : 0.020811
[00:52:38.917] iteration 22991 : model1 loss : 0.442300 model2 loss : 0.021234
[00:52:39.086] iteration 22992 : model1 loss : 0.439355 model2 loss : 0.015571
[00:52:39.257] iteration 22993 : model1 loss : 0.437697 model2 loss : 0.017431
[00:52:39.423] iteration 22994 : model1 loss : 0.438027 model2 loss : 0.016742
[00:52:39.592] iteration 22995 : model1 loss : 0.443959 model2 loss : 0.019072
[00:52:41.587] iteration 22996 : model1 loss : 0.437821 model2 loss : 0.015803
[00:52:41.756] iteration 22997 : model1 loss : 0.440476 model2 loss : 0.018288
[00:52:41.930] iteration 22998 : model1 loss : 0.438176 model2 loss : 0.018759
[00:52:42.098] iteration 22999 : model1 loss : 0.437867 model2 loss : 0.020348
[00:52:42.270] iteration 23000 : model1 loss : 0.439052 model2 loss : 0.019762
[00:52:50.682] iteration 23000 : model1_mean_dice : 0.878065 model1_mean_hd95 : 4.003734
[00:52:59.706] iteration 23000 : model2_mean_dice : 0.878929 model2_mean_hd95 : 6.341478
[00:52:59.884] iteration 23001 : model1 loss : 0.442069 model2 loss : 0.020499
[00:53:00.055] iteration 23002 : model1 loss : 0.435145 model2 loss : 0.015703
[00:53:00.227] iteration 23003 : model1 loss : 0.438610 model2 loss : 0.015614
[00:53:00.404] iteration 23004 : model1 loss : 0.440504 model2 loss : 0.016519
[00:53:00.571] iteration 23005 : model1 loss : 0.443165 model2 loss : 0.019355
[00:53:00.743] iteration 23006 : model1 loss : 0.439142 model2 loss : 0.017628
[00:53:00.916] iteration 23007 : model1 loss : 0.439297 model2 loss : 0.017555
[00:53:01.091] iteration 23008 : model1 loss : 0.439044 model2 loss : 0.019068
[00:53:01.277] iteration 23009 : model1 loss : 0.436476 model2 loss : 0.018646
[00:53:01.451] iteration 23010 : model1 loss : 0.444086 model2 loss : 0.020525
[00:53:01.619] iteration 23011 : model1 loss : 0.440656 model2 loss : 0.017583
[00:53:01.789] iteration 23012 : model1 loss : 0.441652 model2 loss : 0.018787
[00:53:01.971] iteration 23013 : model1 loss : 0.442699 model2 loss : 0.020031
[00:53:02.144] iteration 23014 : model1 loss : 0.440196 model2 loss : 0.017519
[00:53:02.318] iteration 23015 : model1 loss : 0.433494 model2 loss : 0.016093
[00:53:02.493] iteration 23016 : model1 loss : 0.437212 model2 loss : 0.017724
[00:53:04.459] iteration 23017 : model1 loss : 0.439057 model2 loss : 0.015925
[00:53:04.627] iteration 23018 : model1 loss : 0.439723 model2 loss : 0.019438
[00:53:04.799] iteration 23019 : model1 loss : 0.441776 model2 loss : 0.016937
[00:53:04.966] iteration 23020 : model1 loss : 0.443115 model2 loss : 0.020036
[00:53:05.137] iteration 23021 : model1 loss : 0.441239 model2 loss : 0.016341
[00:53:05.333] iteration 23022 : model1 loss : 0.435312 model2 loss : 0.017338
[00:53:05.503] iteration 23023 : model1 loss : 0.438868 model2 loss : 0.016980
[00:53:05.670] iteration 23024 : model1 loss : 0.437814 model2 loss : 0.018346
[00:53:05.848] iteration 23025 : model1 loss : 0.440738 model2 loss : 0.016675
[00:53:06.026] iteration 23026 : model1 loss : 0.443094 model2 loss : 0.019377
[00:53:06.234] iteration 23027 : model1 loss : 0.443177 model2 loss : 0.019139
[00:53:06.413] iteration 23028 : model1 loss : 0.439278 model2 loss : 0.018118
[00:53:06.582] iteration 23029 : model1 loss : 0.437104 model2 loss : 0.017286
[00:53:06.749] iteration 23030 : model1 loss : 0.440867 model2 loss : 0.018697
[00:53:06.916] iteration 23031 : model1 loss : 0.438325 model2 loss : 0.021331
[00:53:07.084] iteration 23032 : model1 loss : 0.437705 model2 loss : 0.017827
[00:53:07.251] iteration 23033 : model1 loss : 0.441010 model2 loss : 0.017284
[00:53:07.423] iteration 23034 : model1 loss : 0.437940 model2 loss : 0.016487
[00:53:07.590] iteration 23035 : model1 loss : 0.436298 model2 loss : 0.016058
[00:53:07.759] iteration 23036 : model1 loss : 0.440541 model2 loss : 0.018677
[00:53:07.931] iteration 23037 : model1 loss : 0.434671 model2 loss : 0.017466
[00:53:10.014] iteration 23038 : model1 loss : 0.440965 model2 loss : 0.018086
[00:53:10.183] iteration 23039 : model1 loss : 0.442605 model2 loss : 0.016660
[00:53:10.353] iteration 23040 : model1 loss : 0.437139 model2 loss : 0.019134
[00:53:10.520] iteration 23041 : model1 loss : 0.438088 model2 loss : 0.018680
[00:53:10.694] iteration 23042 : model1 loss : 0.436882 model2 loss : 0.017268
[00:53:10.871] iteration 23043 : model1 loss : 0.440491 model2 loss : 0.018897
[00:53:11.051] iteration 23044 : model1 loss : 0.436359 model2 loss : 0.014597
[00:53:11.225] iteration 23045 : model1 loss : 0.441896 model2 loss : 0.020170
[00:53:11.401] iteration 23046 : model1 loss : 0.441275 model2 loss : 0.018646
[00:53:11.577] iteration 23047 : model1 loss : 0.439621 model2 loss : 0.015667
[00:53:11.757] iteration 23048 : model1 loss : 0.440388 model2 loss : 0.019202
[00:53:11.934] iteration 23049 : model1 loss : 0.435688 model2 loss : 0.017791
[00:53:12.108] iteration 23050 : model1 loss : 0.439137 model2 loss : 0.017610
[00:53:12.286] iteration 23051 : model1 loss : 0.444941 model2 loss : 0.023916
[00:53:12.465] iteration 23052 : model1 loss : 0.435151 model2 loss : 0.017771
[00:53:12.672] iteration 23053 : model1 loss : 0.435524 model2 loss : 0.015942
[00:53:12.903] iteration 23054 : model1 loss : 0.438440 model2 loss : 0.016149
[00:53:13.091] iteration 23055 : model1 loss : 0.439953 model2 loss : 0.018569
[00:53:13.258] iteration 23056 : model1 loss : 0.437715 model2 loss : 0.018878
[00:53:13.424] iteration 23057 : model1 loss : 0.444087 model2 loss : 0.019322
[00:53:13.619] iteration 23058 : model1 loss : 0.441010 model2 loss : 0.018552
[00:53:15.657] iteration 23059 : model1 loss : 0.445459 model2 loss : 0.019166
[00:53:15.833] iteration 23060 : model1 loss : 0.438492 model2 loss : 0.016553
[00:53:16.005] iteration 23061 : model1 loss : 0.435698 model2 loss : 0.017116
[00:53:16.177] iteration 23062 : model1 loss : 0.441934 model2 loss : 0.017549
[00:53:16.353] iteration 23063 : model1 loss : 0.441606 model2 loss : 0.016908
[00:53:16.520] iteration 23064 : model1 loss : 0.436364 model2 loss : 0.017325
[00:53:16.688] iteration 23065 : model1 loss : 0.439458 model2 loss : 0.018672
[00:53:16.855] iteration 23066 : model1 loss : 0.436420 model2 loss : 0.016111
[00:53:17.030] iteration 23067 : model1 loss : 0.436573 model2 loss : 0.018353
[00:53:17.199] iteration 23068 : model1 loss : 0.442065 model2 loss : 0.020003
[00:53:17.373] iteration 23069 : model1 loss : 0.440000 model2 loss : 0.017426
[00:53:17.544] iteration 23070 : model1 loss : 0.436582 model2 loss : 0.017198
[00:53:17.728] iteration 23071 : model1 loss : 0.441792 model2 loss : 0.018965
[00:53:17.898] iteration 23072 : model1 loss : 0.437806 model2 loss : 0.019281
[00:53:18.072] iteration 23073 : model1 loss : 0.436952 model2 loss : 0.017975
[00:53:18.241] iteration 23074 : model1 loss : 0.435514 model2 loss : 0.018046
[00:53:18.409] iteration 23075 : model1 loss : 0.441997 model2 loss : 0.018529
[00:53:18.576] iteration 23076 : model1 loss : 0.441215 model2 loss : 0.017415
[00:53:18.744] iteration 23077 : model1 loss : 0.439413 model2 loss : 0.017911
[00:53:18.910] iteration 23078 : model1 loss : 0.440380 model2 loss : 0.020162
[00:53:19.087] iteration 23079 : model1 loss : 0.440376 model2 loss : 0.017370
[00:53:21.092] iteration 23080 : model1 loss : 0.438000 model2 loss : 0.015927
[00:53:21.264] iteration 23081 : model1 loss : 0.439825 model2 loss : 0.018411
[00:53:21.433] iteration 23082 : model1 loss : 0.439280 model2 loss : 0.017572
[00:53:21.602] iteration 23083 : model1 loss : 0.438604 model2 loss : 0.016697
[00:53:21.772] iteration 23084 : model1 loss : 0.440005 model2 loss : 0.018644
[00:53:21.940] iteration 23085 : model1 loss : 0.437853 model2 loss : 0.014965
[00:53:22.108] iteration 23086 : model1 loss : 0.438238 model2 loss : 0.016911
[00:53:22.277] iteration 23087 : model1 loss : 0.443109 model2 loss : 0.019809
[00:53:22.447] iteration 23088 : model1 loss : 0.441607 model2 loss : 0.019515
[00:53:22.614] iteration 23089 : model1 loss : 0.435469 model2 loss : 0.017362
[00:53:22.784] iteration 23090 : model1 loss : 0.440270 model2 loss : 0.018415
[00:53:22.952] iteration 23091 : model1 loss : 0.437651 model2 loss : 0.017399
[00:53:23.122] iteration 23092 : model1 loss : 0.446324 model2 loss : 0.020424
[00:53:23.289] iteration 23093 : model1 loss : 0.439546 model2 loss : 0.017477
[00:53:23.457] iteration 23094 : model1 loss : 0.441916 model2 loss : 0.017805
[00:53:23.638] iteration 23095 : model1 loss : 0.440786 model2 loss : 0.017827
[00:53:23.875] iteration 23096 : model1 loss : 0.435049 model2 loss : 0.016868
[00:53:24.046] iteration 23097 : model1 loss : 0.440177 model2 loss : 0.016991
[00:53:24.229] iteration 23098 : model1 loss : 0.438612 model2 loss : 0.019653
[00:53:24.464] iteration 23099 : model1 loss : 0.436622 model2 loss : 0.017285
[00:53:24.636] iteration 23100 : model1 loss : 0.438099 model2 loss : 0.017983
[00:53:26.653] iteration 23101 : model1 loss : 0.440560 model2 loss : 0.020041
[00:53:26.824] iteration 23102 : model1 loss : 0.440186 model2 loss : 0.017919
[00:53:27.007] iteration 23103 : model1 loss : 0.440479 model2 loss : 0.015661
[00:53:27.186] iteration 23104 : model1 loss : 0.439970 model2 loss : 0.016976
[00:53:27.367] iteration 23105 : model1 loss : 0.432542 model2 loss : 0.016924
[00:53:27.547] iteration 23106 : model1 loss : 0.443569 model2 loss : 0.018184
[00:53:27.727] iteration 23107 : model1 loss : 0.439087 model2 loss : 0.017989
[00:53:27.906] iteration 23108 : model1 loss : 0.434445 model2 loss : 0.017353
[00:53:28.123] iteration 23109 : model1 loss : 0.436297 model2 loss : 0.018614
[00:53:28.351] iteration 23110 : model1 loss : 0.436012 model2 loss : 0.016239
[00:53:28.550] iteration 23111 : model1 loss : 0.437989 model2 loss : 0.016773
[00:53:28.719] iteration 23112 : model1 loss : 0.442153 model2 loss : 0.017669
[00:53:28.888] iteration 23113 : model1 loss : 0.438330 model2 loss : 0.017454
[00:53:29.061] iteration 23114 : model1 loss : 0.443191 model2 loss : 0.020357
[00:53:29.239] iteration 23115 : model1 loss : 0.439862 model2 loss : 0.019132
[00:53:29.407] iteration 23116 : model1 loss : 0.439242 model2 loss : 0.018909
[00:53:29.576] iteration 23117 : model1 loss : 0.442081 model2 loss : 0.017587
[00:53:29.742] iteration 23118 : model1 loss : 0.443828 model2 loss : 0.021990
[00:53:29.911] iteration 23119 : model1 loss : 0.434893 model2 loss : 0.017347
[00:53:30.078] iteration 23120 : model1 loss : 0.444253 model2 loss : 0.019587
[00:53:30.246] iteration 23121 : model1 loss : 0.438842 model2 loss : 0.017260
[00:53:32.271] iteration 23122 : model1 loss : 0.437285 model2 loss : 0.017796
[00:53:32.446] iteration 23123 : model1 loss : 0.434427 model2 loss : 0.016645
[00:53:32.615] iteration 23124 : model1 loss : 0.438496 model2 loss : 0.017993
[00:53:32.783] iteration 23125 : model1 loss : 0.437551 model2 loss : 0.015975
[00:53:32.952] iteration 23126 : model1 loss : 0.440808 model2 loss : 0.018706
[00:53:33.123] iteration 23127 : model1 loss : 0.435437 model2 loss : 0.017430
[00:53:33.291] iteration 23128 : model1 loss : 0.437717 model2 loss : 0.017993
[00:53:33.459] iteration 23129 : model1 loss : 0.439332 model2 loss : 0.018975
[00:53:33.629] iteration 23130 : model1 loss : 0.437637 model2 loss : 0.018031
[00:53:33.796] iteration 23131 : model1 loss : 0.443526 model2 loss : 0.019861
[00:53:33.966] iteration 23132 : model1 loss : 0.440136 model2 loss : 0.017682
[00:53:34.136] iteration 23133 : model1 loss : 0.434200 model2 loss : 0.014961
[00:53:34.308] iteration 23134 : model1 loss : 0.441870 model2 loss : 0.018827
[00:53:34.475] iteration 23135 : model1 loss : 0.438931 model2 loss : 0.017693
[00:53:34.644] iteration 23136 : model1 loss : 0.442196 model2 loss : 0.017553
[00:53:34.820] iteration 23137 : model1 loss : 0.439977 model2 loss : 0.017075
[00:53:35.002] iteration 23138 : model1 loss : 0.439996 model2 loss : 0.018279
[00:53:35.180] iteration 23139 : model1 loss : 0.443184 model2 loss : 0.018897
[00:53:35.363] iteration 23140 : model1 loss : 0.435112 model2 loss : 0.018054
[00:53:35.544] iteration 23141 : model1 loss : 0.440194 model2 loss : 0.018133
[00:53:35.721] iteration 23142 : model1 loss : 0.448332 model2 loss : 0.024427
[00:53:37.729] iteration 23143 : model1 loss : 0.439371 model2 loss : 0.017779
[00:53:37.899] iteration 23144 : model1 loss : 0.440788 model2 loss : 0.015545
[00:53:38.089] iteration 23145 : model1 loss : 0.437199 model2 loss : 0.018340
[00:53:38.306] iteration 23146 : model1 loss : 0.436355 model2 loss : 0.016601
[00:53:38.476] iteration 23147 : model1 loss : 0.445017 model2 loss : 0.018367
[00:53:38.646] iteration 23148 : model1 loss : 0.438570 model2 loss : 0.016568
[00:53:38.814] iteration 23149 : model1 loss : 0.439733 model2 loss : 0.017874
[00:53:38.983] iteration 23150 : model1 loss : 0.437129 model2 loss : 0.017807
[00:53:39.165] iteration 23151 : model1 loss : 0.439292 model2 loss : 0.019249
[00:53:39.351] iteration 23152 : model1 loss : 0.440564 model2 loss : 0.020437
[00:53:39.528] iteration 23153 : model1 loss : 0.439732 model2 loss : 0.017331
[00:53:39.726] iteration 23154 : model1 loss : 0.438319 model2 loss : 0.018084
[00:53:39.900] iteration 23155 : model1 loss : 0.440367 model2 loss : 0.017855
[00:53:40.073] iteration 23156 : model1 loss : 0.437204 model2 loss : 0.019546
[00:53:40.257] iteration 23157 : model1 loss : 0.439945 model2 loss : 0.014793
[00:53:40.435] iteration 23158 : model1 loss : 0.436828 model2 loss : 0.018110
[00:53:40.621] iteration 23159 : model1 loss : 0.435280 model2 loss : 0.018372
[00:53:40.812] iteration 23160 : model1 loss : 0.439247 model2 loss : 0.016928
[00:53:40.981] iteration 23161 : model1 loss : 0.443940 model2 loss : 0.018506
[00:53:41.151] iteration 23162 : model1 loss : 0.438473 model2 loss : 0.019300
[00:53:41.339] iteration 23163 : model1 loss : 0.439618 model2 loss : 0.017296
[00:53:43.324] iteration 23164 : model1 loss : 0.439233 model2 loss : 0.019319
[00:53:43.494] iteration 23165 : model1 loss : 0.435361 model2 loss : 0.016658
[00:53:43.664] iteration 23166 : model1 loss : 0.437456 model2 loss : 0.018894
[00:53:43.831] iteration 23167 : model1 loss : 0.440258 model2 loss : 0.018645
[00:53:44.001] iteration 23168 : model1 loss : 0.439509 model2 loss : 0.016555
[00:53:44.171] iteration 23169 : model1 loss : 0.437310 model2 loss : 0.019497
[00:53:44.342] iteration 23170 : model1 loss : 0.437044 model2 loss : 0.016947
[00:53:44.508] iteration 23171 : model1 loss : 0.439873 model2 loss : 0.017777
[00:53:44.676] iteration 23172 : model1 loss : 0.444301 model2 loss : 0.019176
[00:53:44.845] iteration 23173 : model1 loss : 0.441752 model2 loss : 0.019496
[00:53:45.015] iteration 23174 : model1 loss : 0.439452 model2 loss : 0.018672
[00:53:45.182] iteration 23175 : model1 loss : 0.436911 model2 loss : 0.016739
[00:53:45.352] iteration 23176 : model1 loss : 0.438200 model2 loss : 0.016420
[00:53:45.520] iteration 23177 : model1 loss : 0.441566 model2 loss : 0.020365
[00:53:45.689] iteration 23178 : model1 loss : 0.438209 model2 loss : 0.015204
[00:53:45.857] iteration 23179 : model1 loss : 0.440222 model2 loss : 0.017797
[00:53:46.029] iteration 23180 : model1 loss : 0.439988 model2 loss : 0.018407
[00:53:46.198] iteration 23181 : model1 loss : 0.437988 model2 loss : 0.018053
[00:53:46.367] iteration 23182 : model1 loss : 0.439095 model2 loss : 0.019970
[00:53:46.532] iteration 23183 : model1 loss : 0.438535 model2 loss : 0.016247
[00:53:46.699] iteration 23184 : model1 loss : 0.440369 model2 loss : 0.018300
[00:53:48.679] iteration 23185 : model1 loss : 0.436976 model2 loss : 0.016472
[00:53:48.848] iteration 23186 : model1 loss : 0.436862 model2 loss : 0.018033
[00:53:49.021] iteration 23187 : model1 loss : 0.438745 model2 loss : 0.019142
[00:53:49.189] iteration 23188 : model1 loss : 0.436033 model2 loss : 0.018554
[00:53:49.358] iteration 23189 : model1 loss : 0.437908 model2 loss : 0.016338
[00:53:49.527] iteration 23190 : model1 loss : 0.441220 model2 loss : 0.017764
[00:53:49.695] iteration 23191 : model1 loss : 0.443052 model2 loss : 0.018660
[00:53:49.863] iteration 23192 : model1 loss : 0.436659 model2 loss : 0.020006
[00:53:50.034] iteration 23193 : model1 loss : 0.442553 model2 loss : 0.017746
[00:53:50.202] iteration 23194 : model1 loss : 0.440413 model2 loss : 0.018000
[00:53:50.373] iteration 23195 : model1 loss : 0.440131 model2 loss : 0.018959
[00:53:50.540] iteration 23196 : model1 loss : 0.440111 model2 loss : 0.016650
[00:53:50.707] iteration 23197 : model1 loss : 0.439688 model2 loss : 0.018600
[00:53:50.876] iteration 23198 : model1 loss : 0.439981 model2 loss : 0.018573
[00:53:51.045] iteration 23199 : model1 loss : 0.438172 model2 loss : 0.017180
[00:53:51.213] iteration 23200 : model1 loss : 0.444394 model2 loss : 0.018845
[00:53:51.383] iteration 23201 : model1 loss : 0.441138 model2 loss : 0.018942
[00:53:51.552] iteration 23202 : model1 loss : 0.440595 model2 loss : 0.018798
[00:53:51.720] iteration 23203 : model1 loss : 0.441434 model2 loss : 0.018019
[00:53:51.886] iteration 23204 : model1 loss : 0.435136 model2 loss : 0.017951
[00:53:52.055] iteration 23205 : model1 loss : 0.440161 model2 loss : 0.017968
[00:53:54.016] iteration 23206 : model1 loss : 0.439247 model2 loss : 0.018788
[00:53:54.188] iteration 23207 : model1 loss : 0.439322 model2 loss : 0.020109
[00:53:54.371] iteration 23208 : model1 loss : 0.434825 model2 loss : 0.015805
[00:53:54.538] iteration 23209 : model1 loss : 0.436722 model2 loss : 0.015815
[00:53:54.708] iteration 23210 : model1 loss : 0.433390 model2 loss : 0.017354
[00:53:54.875] iteration 23211 : model1 loss : 0.435670 model2 loss : 0.015649
[00:53:55.045] iteration 23212 : model1 loss : 0.441218 model2 loss : 0.020011
[00:53:55.212] iteration 23213 : model1 loss : 0.440877 model2 loss : 0.019463
[00:53:55.382] iteration 23214 : model1 loss : 0.437591 model2 loss : 0.017420
[00:53:55.550] iteration 23215 : model1 loss : 0.439758 model2 loss : 0.016211
[00:53:55.720] iteration 23216 : model1 loss : 0.444381 model2 loss : 0.020172
[00:53:55.887] iteration 23217 : model1 loss : 0.439039 model2 loss : 0.017735
[00:53:56.060] iteration 23218 : model1 loss : 0.441442 model2 loss : 0.019295
[00:53:56.228] iteration 23219 : model1 loss : 0.445569 model2 loss : 0.019405
[00:53:56.397] iteration 23220 : model1 loss : 0.440623 model2 loss : 0.018610
[00:53:56.565] iteration 23221 : model1 loss : 0.442066 model2 loss : 0.018791
[00:53:56.734] iteration 23222 : model1 loss : 0.441157 model2 loss : 0.018310
[00:53:56.900] iteration 23223 : model1 loss : 0.438966 model2 loss : 0.019074
[00:53:57.071] iteration 23224 : model1 loss : 0.436585 model2 loss : 0.017643
[00:53:57.236] iteration 23225 : model1 loss : 0.442158 model2 loss : 0.017926
[00:53:57.406] iteration 23226 : model1 loss : 0.435698 model2 loss : 0.019016
[00:53:59.406] iteration 23227 : model1 loss : 0.443557 model2 loss : 0.017108
[00:53:59.576] iteration 23228 : model1 loss : 0.439525 model2 loss : 0.017822
[00:53:59.748] iteration 23229 : model1 loss : 0.441890 model2 loss : 0.018234
[00:53:59.916] iteration 23230 : model1 loss : 0.441339 model2 loss : 0.018695
[00:54:00.085] iteration 23231 : model1 loss : 0.438845 model2 loss : 0.019467
[00:54:00.253] iteration 23232 : model1 loss : 0.440469 model2 loss : 0.018155
[00:54:00.421] iteration 23233 : model1 loss : 0.439645 model2 loss : 0.015698
[00:54:00.589] iteration 23234 : model1 loss : 0.439837 model2 loss : 0.018372
[00:54:00.761] iteration 23235 : model1 loss : 0.437366 model2 loss : 0.017060
[00:54:00.930] iteration 23236 : model1 loss : 0.437677 model2 loss : 0.016300
[00:54:01.098] iteration 23237 : model1 loss : 0.438369 model2 loss : 0.017275
[00:54:01.266] iteration 23238 : model1 loss : 0.441276 model2 loss : 0.018436
[00:54:01.434] iteration 23239 : model1 loss : 0.437595 model2 loss : 0.016925
[00:54:01.609] iteration 23240 : model1 loss : 0.441278 model2 loss : 0.018635
[00:54:01.779] iteration 23241 : model1 loss : 0.440686 model2 loss : 0.019462
[00:54:01.947] iteration 23242 : model1 loss : 0.436712 model2 loss : 0.017320
[00:54:02.117] iteration 23243 : model1 loss : 0.440502 model2 loss : 0.017704
[00:54:02.282] iteration 23244 : model1 loss : 0.435766 model2 loss : 0.015753
[00:54:02.453] iteration 23245 : model1 loss : 0.438900 model2 loss : 0.015768
[00:54:02.619] iteration 23246 : model1 loss : 0.439940 model2 loss : 0.017783
[00:54:02.786] iteration 23247 : model1 loss : 0.436786 model2 loss : 0.016781
[00:54:04.750] iteration 23248 : model1 loss : 0.438937 model2 loss : 0.019268
[00:54:04.923] iteration 23249 : model1 loss : 0.439572 model2 loss : 0.018602
[00:54:05.091] iteration 23250 : model1 loss : 0.439351 model2 loss : 0.017844
[00:54:05.258] iteration 23251 : model1 loss : 0.437302 model2 loss : 0.019362
[00:54:05.425] iteration 23252 : model1 loss : 0.441973 model2 loss : 0.018630
[00:54:05.594] iteration 23253 : model1 loss : 0.437085 model2 loss : 0.016722
[00:54:05.761] iteration 23254 : model1 loss : 0.440594 model2 loss : 0.019137
[00:54:05.929] iteration 23255 : model1 loss : 0.442124 model2 loss : 0.016954
[00:54:06.099] iteration 23256 : model1 loss : 0.442084 model2 loss : 0.017890
[00:54:06.267] iteration 23257 : model1 loss : 0.439549 model2 loss : 0.018067
[00:54:06.437] iteration 23258 : model1 loss : 0.441233 model2 loss : 0.017257
[00:54:06.604] iteration 23259 : model1 loss : 0.439858 model2 loss : 0.018849
[00:54:06.774] iteration 23260 : model1 loss : 0.442169 model2 loss : 0.018793
[00:54:06.942] iteration 23261 : model1 loss : 0.437494 model2 loss : 0.017480
[00:54:07.118] iteration 23262 : model1 loss : 0.436219 model2 loss : 0.015681
[00:54:07.284] iteration 23263 : model1 loss : 0.436262 model2 loss : 0.016676
[00:54:07.458] iteration 23264 : model1 loss : 0.439079 model2 loss : 0.017869
[00:54:07.627] iteration 23265 : model1 loss : 0.441908 model2 loss : 0.016996
[00:54:07.796] iteration 23266 : model1 loss : 0.435041 model2 loss : 0.017316
[00:54:07.964] iteration 23267 : model1 loss : 0.442598 model2 loss : 0.016925
[00:54:08.134] iteration 23268 : model1 loss : 0.437598 model2 loss : 0.016997
[00:54:10.062] iteration 23269 : model1 loss : 0.437915 model2 loss : 0.017040
[00:54:10.232] iteration 23270 : model1 loss : 0.439398 model2 loss : 0.016376
[00:54:10.402] iteration 23271 : model1 loss : 0.439817 model2 loss : 0.017377
[00:54:10.571] iteration 23272 : model1 loss : 0.440225 model2 loss : 0.018505
[00:54:10.741] iteration 23273 : model1 loss : 0.439461 model2 loss : 0.018524
[00:54:10.909] iteration 23274 : model1 loss : 0.440812 model2 loss : 0.019870
[00:54:11.080] iteration 23275 : model1 loss : 0.439003 model2 loss : 0.017488
[00:54:11.247] iteration 23276 : model1 loss : 0.435320 model2 loss : 0.017436
[00:54:11.417] iteration 23277 : model1 loss : 0.439324 model2 loss : 0.017848
[00:54:11.585] iteration 23278 : model1 loss : 0.438688 model2 loss : 0.017683
[00:54:11.758] iteration 23279 : model1 loss : 0.439106 model2 loss : 0.017193
[00:54:11.927] iteration 23280 : model1 loss : 0.436067 model2 loss : 0.015236
[00:54:12.097] iteration 23281 : model1 loss : 0.439743 model2 loss : 0.017091
[00:54:12.265] iteration 23282 : model1 loss : 0.444508 model2 loss : 0.017924
[00:54:12.436] iteration 23283 : model1 loss : 0.439895 model2 loss : 0.018087
[00:54:12.604] iteration 23284 : model1 loss : 0.439439 model2 loss : 0.018871
[00:54:12.775] iteration 23285 : model1 loss : 0.439090 model2 loss : 0.017789
[00:54:12.943] iteration 23286 : model1 loss : 0.439571 model2 loss : 0.016991
[00:54:13.113] iteration 23287 : model1 loss : 0.434609 model2 loss : 0.016953
[00:54:13.278] iteration 23288 : model1 loss : 0.442373 model2 loss : 0.019281
[00:54:13.445] iteration 23289 : model1 loss : 0.438172 model2 loss : 0.018125
[00:54:15.466] iteration 23290 : model1 loss : 0.439733 model2 loss : 0.018737
[00:54:15.659] iteration 23291 : model1 loss : 0.435629 model2 loss : 0.016538
[00:54:15.829] iteration 23292 : model1 loss : 0.440539 model2 loss : 0.018934
[00:54:15.997] iteration 23293 : model1 loss : 0.440273 model2 loss : 0.018787
[00:54:16.167] iteration 23294 : model1 loss : 0.436263 model2 loss : 0.014972
[00:54:16.336] iteration 23295 : model1 loss : 0.437343 model2 loss : 0.018592
[00:54:16.505] iteration 23296 : model1 loss : 0.440569 model2 loss : 0.017977
[00:54:16.676] iteration 23297 : model1 loss : 0.443006 model2 loss : 0.019141
[00:54:16.858] iteration 23298 : model1 loss : 0.440879 model2 loss : 0.017366
[00:54:17.028] iteration 23299 : model1 loss : 0.442444 model2 loss : 0.016977
[00:54:17.198] iteration 23300 : model1 loss : 0.442066 model2 loss : 0.019066
[00:54:17.373] iteration 23301 : model1 loss : 0.438685 model2 loss : 0.017018
[00:54:17.567] iteration 23302 : model1 loss : 0.439120 model2 loss : 0.017234
[00:54:17.735] iteration 23303 : model1 loss : 0.438569 model2 loss : 0.016696
[00:54:17.915] iteration 23304 : model1 loss : 0.438722 model2 loss : 0.018073
[00:54:18.084] iteration 23305 : model1 loss : 0.437990 model2 loss : 0.016036
[00:54:18.298] iteration 23306 : model1 loss : 0.441038 model2 loss : 0.019141
[00:54:18.496] iteration 23307 : model1 loss : 0.445351 model2 loss : 0.020555
[00:54:18.667] iteration 23308 : model1 loss : 0.439167 model2 loss : 0.018198
[00:54:18.839] iteration 23309 : model1 loss : 0.440603 model2 loss : 0.017900
[00:54:19.011] iteration 23310 : model1 loss : 0.439642 model2 loss : 0.016634
[00:54:21.146] iteration 23311 : model1 loss : 0.440268 model2 loss : 0.017773
[00:54:21.316] iteration 23312 : model1 loss : 0.444738 model2 loss : 0.019907
[00:54:21.533] iteration 23313 : model1 loss : 0.435403 model2 loss : 0.016830
[00:54:21.725] iteration 23314 : model1 loss : 0.439675 model2 loss : 0.017106
[00:54:21.895] iteration 23315 : model1 loss : 0.438572 model2 loss : 0.017710
[00:54:22.078] iteration 23316 : model1 loss : 0.437098 model2 loss : 0.018537
[00:54:22.261] iteration 23317 : model1 loss : 0.439738 model2 loss : 0.017903
[00:54:22.490] iteration 23318 : model1 loss : 0.437396 model2 loss : 0.016761
[00:54:22.684] iteration 23319 : model1 loss : 0.445167 model2 loss : 0.018906
[00:54:22.884] iteration 23320 : model1 loss : 0.438369 model2 loss : 0.016792
[00:54:23.052] iteration 23321 : model1 loss : 0.441722 model2 loss : 0.017820
[00:54:23.221] iteration 23322 : model1 loss : 0.439446 model2 loss : 0.018657
[00:54:23.391] iteration 23323 : model1 loss : 0.440939 model2 loss : 0.019558
[00:54:23.563] iteration 23324 : model1 loss : 0.436440 model2 loss : 0.014752
[00:54:23.731] iteration 23325 : model1 loss : 0.438269 model2 loss : 0.017852
[00:54:23.909] iteration 23326 : model1 loss : 0.441082 model2 loss : 0.016053
[00:54:24.079] iteration 23327 : model1 loss : 0.443616 model2 loss : 0.020851
[00:54:24.246] iteration 23328 : model1 loss : 0.440725 model2 loss : 0.018475
[00:54:24.422] iteration 23329 : model1 loss : 0.435418 model2 loss : 0.016205
[00:54:24.594] iteration 23330 : model1 loss : 0.441842 model2 loss : 0.017987
[00:54:24.764] iteration 23331 : model1 loss : 0.439536 model2 loss : 0.018129
[00:54:26.815] iteration 23332 : model1 loss : 0.439122 model2 loss : 0.018756
[00:54:26.983] iteration 23333 : model1 loss : 0.439614 model2 loss : 0.019014
[00:54:27.153] iteration 23334 : model1 loss : 0.444959 model2 loss : 0.020426
[00:54:27.341] iteration 23335 : model1 loss : 0.441393 model2 loss : 0.016843
[00:54:27.521] iteration 23336 : model1 loss : 0.437875 model2 loss : 0.016758
[00:54:27.702] iteration 23337 : model1 loss : 0.444448 model2 loss : 0.019106
[00:54:27.883] iteration 23338 : model1 loss : 0.437992 model2 loss : 0.018256
[00:54:28.060] iteration 23339 : model1 loss : 0.438602 model2 loss : 0.016731
[00:54:28.253] iteration 23340 : model1 loss : 0.437484 model2 loss : 0.017911
[00:54:28.423] iteration 23341 : model1 loss : 0.435829 model2 loss : 0.017094
[00:54:28.595] iteration 23342 : model1 loss : 0.441009 model2 loss : 0.016231
[00:54:28.787] iteration 23343 : model1 loss : 0.439875 model2 loss : 0.017668
[00:54:28.973] iteration 23344 : model1 loss : 0.440131 model2 loss : 0.018955
[00:54:29.153] iteration 23345 : model1 loss : 0.439222 model2 loss : 0.017395
[00:54:29.324] iteration 23346 : model1 loss : 0.442445 model2 loss : 0.018658
[00:54:29.492] iteration 23347 : model1 loss : 0.439487 model2 loss : 0.018025
[00:54:29.660] iteration 23348 : model1 loss : 0.437411 model2 loss : 0.018306
[00:54:29.828] iteration 23349 : model1 loss : 0.440820 model2 loss : 0.019055
[00:54:29.997] iteration 23350 : model1 loss : 0.439272 model2 loss : 0.015705
[00:54:30.164] iteration 23351 : model1 loss : 0.435375 model2 loss : 0.017503
[00:54:30.333] iteration 23352 : model1 loss : 0.437946 model2 loss : 0.016294
[00:54:32.296] iteration 23353 : model1 loss : 0.438606 model2 loss : 0.018752
[00:54:32.468] iteration 23354 : model1 loss : 0.436966 model2 loss : 0.017515
[00:54:32.639] iteration 23355 : model1 loss : 0.440320 model2 loss : 0.020960
[00:54:32.807] iteration 23356 : model1 loss : 0.436245 model2 loss : 0.014957
[00:54:32.976] iteration 23357 : model1 loss : 0.441355 model2 loss : 0.017331
[00:54:33.147] iteration 23358 : model1 loss : 0.442963 model2 loss : 0.020344
[00:54:33.319] iteration 23359 : model1 loss : 0.440196 model2 loss : 0.018458
[00:54:33.486] iteration 23360 : model1 loss : 0.438652 model2 loss : 0.018840
[00:54:33.654] iteration 23361 : model1 loss : 0.438752 model2 loss : 0.017104
[00:54:33.822] iteration 23362 : model1 loss : 0.441974 model2 loss : 0.020175
[00:54:33.991] iteration 23363 : model1 loss : 0.443494 model2 loss : 0.017912
[00:54:34.159] iteration 23364 : model1 loss : 0.440717 model2 loss : 0.016768
[00:54:34.329] iteration 23365 : model1 loss : 0.432428 model2 loss : 0.017988
[00:54:34.498] iteration 23366 : model1 loss : 0.445823 model2 loss : 0.020961
[00:54:34.668] iteration 23367 : model1 loss : 0.440815 model2 loss : 0.015645
[00:54:34.838] iteration 23368 : model1 loss : 0.436375 model2 loss : 0.015273
[00:54:35.009] iteration 23369 : model1 loss : 0.436730 model2 loss : 0.016656
[00:54:35.177] iteration 23370 : model1 loss : 0.440249 model2 loss : 0.015674
[00:54:35.348] iteration 23371 : model1 loss : 0.438740 model2 loss : 0.018251
[00:54:35.515] iteration 23372 : model1 loss : 0.442533 model2 loss : 0.021224
[00:54:35.680] iteration 23373 : model1 loss : 0.436484 model2 loss : 0.016789
[00:54:37.671] iteration 23374 : model1 loss : 0.438309 model2 loss : 0.014933
[00:54:37.841] iteration 23375 : model1 loss : 0.437858 model2 loss : 0.017971
[00:54:38.014] iteration 23376 : model1 loss : 0.442678 model2 loss : 0.017380
[00:54:38.180] iteration 23377 : model1 loss : 0.440432 model2 loss : 0.016751
[00:54:38.349] iteration 23378 : model1 loss : 0.439980 model2 loss : 0.016893
[00:54:38.518] iteration 23379 : model1 loss : 0.444014 model2 loss : 0.020987
[00:54:38.687] iteration 23380 : model1 loss : 0.439502 model2 loss : 0.018326
[00:54:38.856] iteration 23381 : model1 loss : 0.438774 model2 loss : 0.018203
[00:54:39.027] iteration 23382 : model1 loss : 0.434474 model2 loss : 0.015348
[00:54:39.195] iteration 23383 : model1 loss : 0.434472 model2 loss : 0.017139
[00:54:39.365] iteration 23384 : model1 loss : 0.441068 model2 loss : 0.016879
[00:54:39.533] iteration 23385 : model1 loss : 0.437683 model2 loss : 0.016683
[00:54:39.703] iteration 23386 : model1 loss : 0.440126 model2 loss : 0.018086
[00:54:39.873] iteration 23387 : model1 loss : 0.439953 model2 loss : 0.016611
[00:54:40.043] iteration 23388 : model1 loss : 0.439329 model2 loss : 0.016662
[00:54:40.210] iteration 23389 : model1 loss : 0.438244 model2 loss : 0.016147
[00:54:40.377] iteration 23390 : model1 loss : 0.443389 model2 loss : 0.018111
[00:54:40.545] iteration 23391 : model1 loss : 0.437658 model2 loss : 0.018373
[00:54:40.716] iteration 23392 : model1 loss : 0.440272 model2 loss : 0.018017
[00:54:40.881] iteration 23393 : model1 loss : 0.441660 model2 loss : 0.017746
[00:54:41.058] iteration 23394 : model1 loss : 0.437940 model2 loss : 0.018532
[00:54:43.059] iteration 23395 : model1 loss : 0.435032 model2 loss : 0.016548
[00:54:43.228] iteration 23396 : model1 loss : 0.442958 model2 loss : 0.020033
[00:54:43.398] iteration 23397 : model1 loss : 0.440234 model2 loss : 0.015998
[00:54:43.573] iteration 23398 : model1 loss : 0.439323 model2 loss : 0.017417
[00:54:43.742] iteration 23399 : model1 loss : 0.435780 model2 loss : 0.015960
[00:54:43.918] iteration 23400 : model1 loss : 0.437487 model2 loss : 0.016043
[00:54:44.093] iteration 23401 : model1 loss : 0.439267 model2 loss : 0.018704
[00:54:44.270] iteration 23402 : model1 loss : 0.435460 model2 loss : 0.017750
[00:54:44.450] iteration 23403 : model1 loss : 0.438595 model2 loss : 0.017421
[00:54:44.618] iteration 23404 : model1 loss : 0.442645 model2 loss : 0.018499
[00:54:44.788] iteration 23405 : model1 loss : 0.441945 model2 loss : 0.017715
[00:54:44.997] iteration 23406 : model1 loss : 0.446774 model2 loss : 0.019204
[00:54:45.200] iteration 23407 : model1 loss : 0.435445 model2 loss : 0.016344
[00:54:45.390] iteration 23408 : model1 loss : 0.438942 model2 loss : 0.018325
[00:54:45.597] iteration 23409 : model1 loss : 0.437388 model2 loss : 0.017521
[00:54:45.856] iteration 23410 : model1 loss : 0.439724 model2 loss : 0.017456
[00:54:46.077] iteration 23411 : model1 loss : 0.442275 model2 loss : 0.021228
[00:54:46.265] iteration 23412 : model1 loss : 0.443926 model2 loss : 0.017907
[00:54:46.445] iteration 23413 : model1 loss : 0.437747 model2 loss : 0.016897
[00:54:46.611] iteration 23414 : model1 loss : 0.441380 model2 loss : 0.018719
[00:54:46.778] iteration 23415 : model1 loss : 0.435300 model2 loss : 0.017593
[00:54:48.781] iteration 23416 : model1 loss : 0.438576 model2 loss : 0.018663
[00:54:48.958] iteration 23417 : model1 loss : 0.441887 model2 loss : 0.017640
[00:54:49.161] iteration 23418 : model1 loss : 0.439576 model2 loss : 0.018332
[00:54:49.334] iteration 23419 : model1 loss : 0.440069 model2 loss : 0.018622
[00:54:49.509] iteration 23420 : model1 loss : 0.440971 model2 loss : 0.017345
[00:54:49.684] iteration 23421 : model1 loss : 0.439062 model2 loss : 0.017666
[00:54:49.862] iteration 23422 : model1 loss : 0.437861 model2 loss : 0.017077
[00:54:50.039] iteration 23423 : model1 loss : 0.442338 model2 loss : 0.017231
[00:54:50.217] iteration 23424 : model1 loss : 0.437392 model2 loss : 0.017439
[00:54:50.393] iteration 23425 : model1 loss : 0.437867 model2 loss : 0.017003
[00:54:50.569] iteration 23426 : model1 loss : 0.441592 model2 loss : 0.020721
[00:54:50.750] iteration 23427 : model1 loss : 0.437456 model2 loss : 0.018333
[00:54:50.929] iteration 23428 : model1 loss : 0.437433 model2 loss : 0.017580
[00:54:51.112] iteration 23429 : model1 loss : 0.440702 model2 loss : 0.016110
[00:54:51.291] iteration 23430 : model1 loss : 0.436299 model2 loss : 0.016922
[00:54:51.461] iteration 23431 : model1 loss : 0.440290 model2 loss : 0.017388
[00:54:51.646] iteration 23432 : model1 loss : 0.434068 model2 loss : 0.016609
[00:54:51.824] iteration 23433 : model1 loss : 0.436142 model2 loss : 0.017153
[00:54:51.997] iteration 23434 : model1 loss : 0.445343 model2 loss : 0.020699
[00:54:52.162] iteration 23435 : model1 loss : 0.442214 model2 loss : 0.017980
[00:54:52.341] iteration 23436 : model1 loss : 0.444274 model2 loss : 0.017714
[00:54:54.432] iteration 23437 : model1 loss : 0.439156 model2 loss : 0.018082
[00:54:54.612] iteration 23438 : model1 loss : 0.441573 model2 loss : 0.016977
[00:54:54.787] iteration 23439 : model1 loss : 0.436458 model2 loss : 0.016336
[00:54:54.963] iteration 23440 : model1 loss : 0.436341 model2 loss : 0.017443
[00:54:55.133] iteration 23441 : model1 loss : 0.439875 model2 loss : 0.017323
[00:54:55.303] iteration 23442 : model1 loss : 0.437517 model2 loss : 0.017347
[00:54:55.473] iteration 23443 : model1 loss : 0.438474 model2 loss : 0.017022
[00:54:55.641] iteration 23444 : model1 loss : 0.437209 model2 loss : 0.016425
[00:54:55.811] iteration 23445 : model1 loss : 0.437578 model2 loss : 0.016488
[00:54:55.979] iteration 23446 : model1 loss : 0.443960 model2 loss : 0.020708
[00:54:56.150] iteration 23447 : model1 loss : 0.437037 model2 loss : 0.019355
[00:54:56.331] iteration 23448 : model1 loss : 0.439113 model2 loss : 0.017920
[00:54:56.509] iteration 23449 : model1 loss : 0.439070 model2 loss : 0.017856
[00:54:56.678] iteration 23450 : model1 loss : 0.442754 model2 loss : 0.018732
[00:54:56.846] iteration 23451 : model1 loss : 0.441189 model2 loss : 0.019671
[00:54:57.024] iteration 23452 : model1 loss : 0.442239 model2 loss : 0.019121
[00:54:57.199] iteration 23453 : model1 loss : 0.443022 model2 loss : 0.019750
[00:54:57.369] iteration 23454 : model1 loss : 0.434801 model2 loss : 0.016312
[00:54:57.548] iteration 23455 : model1 loss : 0.436586 model2 loss : 0.014965
[00:54:57.720] iteration 23456 : model1 loss : 0.440762 model2 loss : 0.019680
[00:54:57.895] iteration 23457 : model1 loss : 0.445355 model2 loss : 0.019234
[00:54:59.879] iteration 23458 : model1 loss : 0.438398 model2 loss : 0.015980
[00:55:00.048] iteration 23459 : model1 loss : 0.446568 model2 loss : 0.018717
[00:55:00.217] iteration 23460 : model1 loss : 0.434847 model2 loss : 0.016752
[00:55:00.394] iteration 23461 : model1 loss : 0.441575 model2 loss : 0.018437
[00:55:00.562] iteration 23462 : model1 loss : 0.441335 model2 loss : 0.019892
[00:55:00.729] iteration 23463 : model1 loss : 0.434767 model2 loss : 0.016133
[00:55:00.907] iteration 23464 : model1 loss : 0.438426 model2 loss : 0.015844
[00:55:01.086] iteration 23465 : model1 loss : 0.437473 model2 loss : 0.016043
[00:55:01.260] iteration 23466 : model1 loss : 0.441261 model2 loss : 0.019932
[00:55:01.435] iteration 23467 : model1 loss : 0.436695 model2 loss : 0.015689
[00:55:01.616] iteration 23468 : model1 loss : 0.442178 model2 loss : 0.019167
[00:55:01.794] iteration 23469 : model1 loss : 0.441376 model2 loss : 0.018497
[00:55:01.974] iteration 23470 : model1 loss : 0.437862 model2 loss : 0.017548
[00:55:02.152] iteration 23471 : model1 loss : 0.439750 model2 loss : 0.019140
[00:55:02.336] iteration 23472 : model1 loss : 0.438462 model2 loss : 0.016045
[00:55:02.511] iteration 23473 : model1 loss : 0.437804 model2 loss : 0.018010
[00:55:02.679] iteration 23474 : model1 loss : 0.440461 model2 loss : 0.018346
[00:55:02.850] iteration 23475 : model1 loss : 0.435342 model2 loss : 0.014716
[00:55:03.023] iteration 23476 : model1 loss : 0.441936 model2 loss : 0.018599
[00:55:03.190] iteration 23477 : model1 loss : 0.437613 model2 loss : 0.017419
[00:55:03.357] iteration 23478 : model1 loss : 0.440962 model2 loss : 0.016750
[00:55:05.321] iteration 23479 : model1 loss : 0.439715 model2 loss : 0.016986
[00:55:05.491] iteration 23480 : model1 loss : 0.438986 model2 loss : 0.017542
[00:55:05.665] iteration 23481 : model1 loss : 0.439165 model2 loss : 0.018057
[00:55:05.833] iteration 23482 : model1 loss : 0.438348 model2 loss : 0.016537
[00:55:06.011] iteration 23483 : model1 loss : 0.437739 model2 loss : 0.015114
[00:55:06.188] iteration 23484 : model1 loss : 0.437186 model2 loss : 0.016344
[00:55:06.358] iteration 23485 : model1 loss : 0.444169 model2 loss : 0.017492
[00:55:06.527] iteration 23486 : model1 loss : 0.443856 model2 loss : 0.017614
[00:55:06.695] iteration 23487 : model1 loss : 0.439901 model2 loss : 0.017858
[00:55:06.866] iteration 23488 : model1 loss : 0.436036 model2 loss : 0.015114
[00:55:07.037] iteration 23489 : model1 loss : 0.437367 model2 loss : 0.016152
[00:55:07.204] iteration 23490 : model1 loss : 0.438176 model2 loss : 0.016422
[00:55:07.375] iteration 23491 : model1 loss : 0.439258 model2 loss : 0.017875
[00:55:07.545] iteration 23492 : model1 loss : 0.435389 model2 loss : 0.016380
[00:55:07.713] iteration 23493 : model1 loss : 0.441464 model2 loss : 0.020077
[00:55:07.880] iteration 23494 : model1 loss : 0.434957 model2 loss : 0.016452
[00:55:08.052] iteration 23495 : model1 loss : 0.439162 model2 loss : 0.018637
[00:55:08.220] iteration 23496 : model1 loss : 0.439338 model2 loss : 0.020656
[00:55:08.390] iteration 23497 : model1 loss : 0.443673 model2 loss : 0.019617
[00:55:08.556] iteration 23498 : model1 loss : 0.437238 model2 loss : 0.018099
[00:55:08.727] iteration 23499 : model1 loss : 0.442990 model2 loss : 0.017821
[00:55:10.729] iteration 23500 : model1 loss : 0.444588 model2 loss : 0.019317
[00:55:10.902] iteration 23501 : model1 loss : 0.444766 model2 loss : 0.021176
[00:55:11.078] iteration 23502 : model1 loss : 0.439882 model2 loss : 0.017996
[00:55:11.249] iteration 23503 : model1 loss : 0.436266 model2 loss : 0.017343
[00:55:11.420] iteration 23504 : model1 loss : 0.443927 model2 loss : 0.018592
[00:55:11.590] iteration 23505 : model1 loss : 0.439221 model2 loss : 0.017494
[00:55:11.764] iteration 23506 : model1 loss : 0.434407 model2 loss : 0.016101
[00:55:11.938] iteration 23507 : model1 loss : 0.437494 model2 loss : 0.019482
[00:55:12.112] iteration 23508 : model1 loss : 0.441371 model2 loss : 0.019069
[00:55:12.283] iteration 23509 : model1 loss : 0.439516 model2 loss : 0.018101
[00:55:12.458] iteration 23510 : model1 loss : 0.438151 model2 loss : 0.018321
[00:55:12.631] iteration 23511 : model1 loss : 0.442046 model2 loss : 0.020196
[00:55:12.807] iteration 23512 : model1 loss : 0.439314 model2 loss : 0.013827
[00:55:12.992] iteration 23513 : model1 loss : 0.436443 model2 loss : 0.016932
[00:55:13.185] iteration 23514 : model1 loss : 0.442721 model2 loss : 0.018938
[00:55:13.360] iteration 23515 : model1 loss : 0.431638 model2 loss : 0.016158
[00:55:13.539] iteration 23516 : model1 loss : 0.442154 model2 loss : 0.019592
[00:55:13.744] iteration 23517 : model1 loss : 0.442311 model2 loss : 0.017976
[00:55:13.916] iteration 23518 : model1 loss : 0.436399 model2 loss : 0.017655
[00:55:14.085] iteration 23519 : model1 loss : 0.439458 model2 loss : 0.019799
[00:55:14.252] iteration 23520 : model1 loss : 0.437357 model2 loss : 0.016592
[00:55:17.060] iteration 23521 : model1 loss : 0.438364 model2 loss : 0.018293
[00:55:17.235] iteration 23522 : model1 loss : 0.445342 model2 loss : 0.018336
[00:55:17.407] iteration 23523 : model1 loss : 0.435603 model2 loss : 0.016413
[00:55:17.573] iteration 23524 : model1 loss : 0.439980 model2 loss : 0.017990
[00:55:17.744] iteration 23525 : model1 loss : 0.436799 model2 loss : 0.017079
[00:55:17.920] iteration 23526 : model1 loss : 0.441053 model2 loss : 0.019809
[00:55:18.104] iteration 23527 : model1 loss : 0.442198 model2 loss : 0.018902
[00:55:18.302] iteration 23528 : model1 loss : 0.436830 model2 loss : 0.015627
[00:55:18.480] iteration 23529 : model1 loss : 0.444076 model2 loss : 0.017803
[00:55:18.646] iteration 23530 : model1 loss : 0.439216 model2 loss : 0.017687
[00:55:18.815] iteration 23531 : model1 loss : 0.437956 model2 loss : 0.018457
[00:55:19.013] iteration 23532 : model1 loss : 0.439149 model2 loss : 0.018126
[00:55:19.186] iteration 23533 : model1 loss : 0.442442 model2 loss : 0.018105
[00:55:19.355] iteration 23534 : model1 loss : 0.441634 model2 loss : 0.021394
[00:55:19.532] iteration 23535 : model1 loss : 0.437282 model2 loss : 0.018296
[00:55:19.711] iteration 23536 : model1 loss : 0.437105 model2 loss : 0.018215
[00:55:19.906] iteration 23537 : model1 loss : 0.437304 model2 loss : 0.018398
[00:55:20.086] iteration 23538 : model1 loss : 0.438345 model2 loss : 0.016796
[00:55:20.271] iteration 23539 : model1 loss : 0.440373 model2 loss : 0.017700
[00:55:20.464] iteration 23540 : model1 loss : 0.438777 model2 loss : 0.018067
[00:55:20.638] iteration 23541 : model1 loss : 0.440546 model2 loss : 0.017907
[00:55:22.778] iteration 23542 : model1 loss : 0.438694 model2 loss : 0.018797
[00:55:22.944] iteration 23543 : model1 loss : 0.436689 model2 loss : 0.016291
[00:55:23.117] iteration 23544 : model1 loss : 0.438491 model2 loss : 0.019217
[00:55:23.298] iteration 23545 : model1 loss : 0.442584 model2 loss : 0.017922
[00:55:23.486] iteration 23546 : model1 loss : 0.440065 model2 loss : 0.017494
[00:55:23.677] iteration 23547 : model1 loss : 0.439505 model2 loss : 0.016654
[00:55:23.862] iteration 23548 : model1 loss : 0.436504 model2 loss : 0.018005
[00:55:24.057] iteration 23549 : model1 loss : 0.441305 model2 loss : 0.017670
[00:55:24.235] iteration 23550 : model1 loss : 0.437680 model2 loss : 0.016765
[00:55:24.422] iteration 23551 : model1 loss : 0.440592 model2 loss : 0.019971
[00:55:24.610] iteration 23552 : model1 loss : 0.440046 model2 loss : 0.016911
[00:55:24.778] iteration 23553 : model1 loss : 0.440087 model2 loss : 0.018761
[00:55:24.948] iteration 23554 : model1 loss : 0.445435 model2 loss : 0.020366
[00:55:25.118] iteration 23555 : model1 loss : 0.437589 model2 loss : 0.016558
[00:55:25.288] iteration 23556 : model1 loss : 0.440751 model2 loss : 0.016945
[00:55:25.462] iteration 23557 : model1 loss : 0.435754 model2 loss : 0.017336
[00:55:25.632] iteration 23558 : model1 loss : 0.439466 model2 loss : 0.017439
[00:55:25.800] iteration 23559 : model1 loss : 0.440403 model2 loss : 0.016782
[00:55:25.969] iteration 23560 : model1 loss : 0.439725 model2 loss : 0.017484
[00:55:26.143] iteration 23561 : model1 loss : 0.435119 model2 loss : 0.017259
[00:55:26.336] iteration 23562 : model1 loss : 0.439490 model2 loss : 0.017618
[00:55:28.367] iteration 23563 : model1 loss : 0.442110 model2 loss : 0.018690
[00:55:28.538] iteration 23564 : model1 loss : 0.438472 model2 loss : 0.017077
[00:55:28.707] iteration 23565 : model1 loss : 0.442645 model2 loss : 0.017254
[00:55:28.878] iteration 23566 : model1 loss : 0.442352 model2 loss : 0.017885
[00:55:29.048] iteration 23567 : model1 loss : 0.432906 model2 loss : 0.014942
[00:55:29.215] iteration 23568 : model1 loss : 0.440697 model2 loss : 0.017542
[00:55:29.385] iteration 23569 : model1 loss : 0.435055 model2 loss : 0.017223
[00:55:29.554] iteration 23570 : model1 loss : 0.440209 model2 loss : 0.017102
[00:55:29.723] iteration 23571 : model1 loss : 0.440197 model2 loss : 0.017076
[00:55:29.892] iteration 23572 : model1 loss : 0.442466 model2 loss : 0.015747
[00:55:30.062] iteration 23573 : model1 loss : 0.439313 model2 loss : 0.019041
[00:55:30.229] iteration 23574 : model1 loss : 0.439316 model2 loss : 0.018244
[00:55:30.398] iteration 23575 : model1 loss : 0.436124 model2 loss : 0.017900
[00:55:30.565] iteration 23576 : model1 loss : 0.439487 model2 loss : 0.018131
[00:55:30.735] iteration 23577 : model1 loss : 0.437595 model2 loss : 0.019830
[00:55:30.903] iteration 23578 : model1 loss : 0.443171 model2 loss : 0.019737
[00:55:31.073] iteration 23579 : model1 loss : 0.438797 model2 loss : 0.018207
[00:55:31.242] iteration 23580 : model1 loss : 0.440333 model2 loss : 0.018109
[00:55:31.411] iteration 23581 : model1 loss : 0.437556 model2 loss : 0.017179
[00:55:31.577] iteration 23582 : model1 loss : 0.439567 model2 loss : 0.017405
[00:55:31.744] iteration 23583 : model1 loss : 0.438487 model2 loss : 0.020044
[00:55:33.712] iteration 23584 : model1 loss : 0.437636 model2 loss : 0.016501
[00:55:33.896] iteration 23585 : model1 loss : 0.433351 model2 loss : 0.016796
[00:55:34.085] iteration 23586 : model1 loss : 0.440811 model2 loss : 0.015407
[00:55:34.278] iteration 23587 : model1 loss : 0.438036 model2 loss : 0.016703
[00:55:34.475] iteration 23588 : model1 loss : 0.439390 model2 loss : 0.016840
[00:55:34.673] iteration 23589 : model1 loss : 0.440104 model2 loss : 0.018267
[00:55:34.867] iteration 23590 : model1 loss : 0.434260 model2 loss : 0.017375
[00:55:35.072] iteration 23591 : model1 loss : 0.440213 model2 loss : 0.018557
[00:55:35.267] iteration 23592 : model1 loss : 0.442436 model2 loss : 0.020522
[00:55:35.458] iteration 23593 : model1 loss : 0.440876 model2 loss : 0.016403
[00:55:35.654] iteration 23594 : model1 loss : 0.442853 model2 loss : 0.018001
[00:55:35.826] iteration 23595 : model1 loss : 0.435911 model2 loss : 0.018753
[00:55:36.003] iteration 23596 : model1 loss : 0.439097 model2 loss : 0.017359
[00:55:36.195] iteration 23597 : model1 loss : 0.439986 model2 loss : 0.019176
[00:55:36.380] iteration 23598 : model1 loss : 0.442233 model2 loss : 0.017221
[00:55:36.547] iteration 23599 : model1 loss : 0.439387 model2 loss : 0.020242
[00:55:36.728] iteration 23600 : model1 loss : 0.442627 model2 loss : 0.019752
[00:55:36.901] iteration 23601 : model1 loss : 0.438339 model2 loss : 0.014672
[00:55:37.069] iteration 23602 : model1 loss : 0.435334 model2 loss : 0.016804
[00:55:37.235] iteration 23603 : model1 loss : 0.442169 model2 loss : 0.019958
[00:55:37.403] iteration 23604 : model1 loss : 0.443075 model2 loss : 0.018955
[00:55:39.389] iteration 23605 : model1 loss : 0.436522 model2 loss : 0.017059
[00:55:39.561] iteration 23606 : model1 loss : 0.441678 model2 loss : 0.017140
[00:55:39.731] iteration 23607 : model1 loss : 0.441398 model2 loss : 0.016546
[00:55:39.903] iteration 23608 : model1 loss : 0.440245 model2 loss : 0.016885
[00:55:40.098] iteration 23609 : model1 loss : 0.439722 model2 loss : 0.017375
[00:55:40.266] iteration 23610 : model1 loss : 0.441971 model2 loss : 0.018509
[00:55:40.434] iteration 23611 : model1 loss : 0.439025 model2 loss : 0.018173
[00:55:40.602] iteration 23612 : model1 loss : 0.442181 model2 loss : 0.018465
[00:55:40.769] iteration 23613 : model1 loss : 0.441111 model2 loss : 0.017709
[00:55:40.942] iteration 23614 : model1 loss : 0.441763 model2 loss : 0.018787
[00:55:41.129] iteration 23615 : model1 loss : 0.436516 model2 loss : 0.015512
[00:55:41.317] iteration 23616 : model1 loss : 0.440803 model2 loss : 0.016252
[00:55:41.486] iteration 23617 : model1 loss : 0.440438 model2 loss : 0.019436
[00:55:41.658] iteration 23618 : model1 loss : 0.442544 model2 loss : 0.016779
[00:55:41.826] iteration 23619 : model1 loss : 0.438494 model2 loss : 0.019725
[00:55:41.994] iteration 23620 : model1 loss : 0.438090 model2 loss : 0.018242
[00:55:42.165] iteration 23621 : model1 loss : 0.439673 model2 loss : 0.018110
[00:55:42.336] iteration 23622 : model1 loss : 0.438157 model2 loss : 0.018415
[00:55:42.508] iteration 23623 : model1 loss : 0.434422 model2 loss : 0.017830
[00:55:42.673] iteration 23624 : model1 loss : 0.435072 model2 loss : 0.015276
[00:55:42.843] iteration 23625 : model1 loss : 0.439696 model2 loss : 0.018222
[00:55:44.861] iteration 23626 : model1 loss : 0.439810 model2 loss : 0.018678
[00:55:45.032] iteration 23627 : model1 loss : 0.443261 model2 loss : 0.017048
[00:55:45.208] iteration 23628 : model1 loss : 0.440508 model2 loss : 0.017571
[00:55:45.389] iteration 23629 : model1 loss : 0.437745 model2 loss : 0.015088
[00:55:45.558] iteration 23630 : model1 loss : 0.439452 model2 loss : 0.017939
[00:55:45.752] iteration 23631 : model1 loss : 0.438938 model2 loss : 0.020613
[00:55:45.952] iteration 23632 : model1 loss : 0.435781 model2 loss : 0.017135
[00:55:46.160] iteration 23633 : model1 loss : 0.438225 model2 loss : 0.017645
[00:55:46.350] iteration 23634 : model1 loss : 0.444581 model2 loss : 0.019247
[00:55:46.547] iteration 23635 : model1 loss : 0.441558 model2 loss : 0.018727
[00:55:46.729] iteration 23636 : model1 loss : 0.439664 model2 loss : 0.020448
[00:55:46.902] iteration 23637 : model1 loss : 0.439771 model2 loss : 0.018794
[00:55:47.073] iteration 23638 : model1 loss : 0.437809 model2 loss : 0.018573
[00:55:47.287] iteration 23639 : model1 loss : 0.438025 model2 loss : 0.017870
[00:55:47.536] iteration 23640 : model1 loss : 0.439991 model2 loss : 0.018012
[00:55:47.731] iteration 23641 : model1 loss : 0.439632 model2 loss : 0.018169
[00:55:47.901] iteration 23642 : model1 loss : 0.444479 model2 loss : 0.015053
[00:55:48.077] iteration 23643 : model1 loss : 0.441866 model2 loss : 0.017689
[00:55:48.255] iteration 23644 : model1 loss : 0.436060 model2 loss : 0.017470
[00:55:48.424] iteration 23645 : model1 loss : 0.442396 model2 loss : 0.019760
[00:55:48.603] iteration 23646 : model1 loss : 0.435519 model2 loss : 0.018475
[00:55:50.622] iteration 23647 : model1 loss : 0.441083 model2 loss : 0.018513
[00:55:50.792] iteration 23648 : model1 loss : 0.442672 model2 loss : 0.016589
[00:55:50.962] iteration 23649 : model1 loss : 0.438928 model2 loss : 0.019148
[00:55:51.162] iteration 23650 : model1 loss : 0.439728 model2 loss : 0.017132
[00:55:51.341] iteration 23651 : model1 loss : 0.439084 model2 loss : 0.017891
[00:55:51.529] iteration 23652 : model1 loss : 0.440111 model2 loss : 0.018296
[00:55:51.728] iteration 23653 : model1 loss : 0.440952 model2 loss : 0.017510
[00:55:51.932] iteration 23654 : model1 loss : 0.442564 model2 loss : 0.017392
[00:55:52.149] iteration 23655 : model1 loss : 0.442994 model2 loss : 0.019905
[00:55:52.374] iteration 23656 : model1 loss : 0.436285 model2 loss : 0.017091
[00:55:52.579] iteration 23657 : model1 loss : 0.438903 model2 loss : 0.018451
[00:55:52.748] iteration 23658 : model1 loss : 0.436165 model2 loss : 0.017814
[00:55:52.945] iteration 23659 : model1 loss : 0.435558 model2 loss : 0.017770
[00:55:53.123] iteration 23660 : model1 loss : 0.443618 model2 loss : 0.016532
[00:55:53.294] iteration 23661 : model1 loss : 0.438899 model2 loss : 0.017453
[00:55:53.464] iteration 23662 : model1 loss : 0.439425 model2 loss : 0.016631
[00:55:53.650] iteration 23663 : model1 loss : 0.438221 model2 loss : 0.016998
[00:55:53.840] iteration 23664 : model1 loss : 0.439561 model2 loss : 0.020009
[00:55:54.015] iteration 23665 : model1 loss : 0.446534 model2 loss : 0.019837
[00:55:54.183] iteration 23666 : model1 loss : 0.436489 model2 loss : 0.017167
[00:55:54.361] iteration 23667 : model1 loss : 0.439665 model2 loss : 0.018832
[00:55:56.702] iteration 23668 : model1 loss : 0.437493 model2 loss : 0.019082
[00:55:56.925] iteration 23669 : model1 loss : 0.443994 model2 loss : 0.019947
[00:55:57.149] iteration 23670 : model1 loss : 0.442474 model2 loss : 0.017835
[00:55:57.381] iteration 23671 : model1 loss : 0.438882 model2 loss : 0.018426
[00:55:57.613] iteration 23672 : model1 loss : 0.436522 model2 loss : 0.016582
[00:55:57.843] iteration 23673 : model1 loss : 0.436252 model2 loss : 0.016668
[00:55:58.088] iteration 23674 : model1 loss : 0.438613 model2 loss : 0.016207
[00:55:58.323] iteration 23675 : model1 loss : 0.436175 model2 loss : 0.017058
[00:55:58.557] iteration 23676 : model1 loss : 0.438498 model2 loss : 0.015464
[00:55:58.785] iteration 23677 : model1 loss : 0.439341 model2 loss : 0.017655
[00:55:59.003] iteration 23678 : model1 loss : 0.435327 model2 loss : 0.016572
[00:55:59.226] iteration 23679 : model1 loss : 0.440195 model2 loss : 0.016810
[00:55:59.454] iteration 23680 : model1 loss : 0.444120 model2 loss : 0.018598
[00:55:59.678] iteration 23681 : model1 loss : 0.442654 model2 loss : 0.020038
[00:55:59.899] iteration 23682 : model1 loss : 0.443257 model2 loss : 0.018603
[00:56:00.117] iteration 23683 : model1 loss : 0.438101 model2 loss : 0.016000
[00:56:00.344] iteration 23684 : model1 loss : 0.434776 model2 loss : 0.017632
[00:56:00.564] iteration 23685 : model1 loss : 0.440633 model2 loss : 0.017748
[00:56:00.782] iteration 23686 : model1 loss : 0.438849 model2 loss : 0.018936
[00:56:00.986] iteration 23687 : model1 loss : 0.445110 model2 loss : 0.019334
[00:56:01.157] iteration 23688 : model1 loss : 0.441061 model2 loss : 0.017979
[00:56:03.202] iteration 23689 : model1 loss : 0.440895 model2 loss : 0.017446
[00:56:03.386] iteration 23690 : model1 loss : 0.435578 model2 loss : 0.016367
[00:56:03.560] iteration 23691 : model1 loss : 0.441519 model2 loss : 0.015938
[00:56:03.749] iteration 23692 : model1 loss : 0.440465 model2 loss : 0.018465
[00:56:03.934] iteration 23693 : model1 loss : 0.436949 model2 loss : 0.017937
[00:56:04.106] iteration 23694 : model1 loss : 0.436459 model2 loss : 0.017397
[00:56:04.273] iteration 23695 : model1 loss : 0.439666 model2 loss : 0.017600
[00:56:04.440] iteration 23696 : model1 loss : 0.440439 model2 loss : 0.019750
[00:56:04.608] iteration 23697 : model1 loss : 0.436350 model2 loss : 0.017257
[00:56:04.775] iteration 23698 : model1 loss : 0.441419 model2 loss : 0.018150
[00:56:04.952] iteration 23699 : model1 loss : 0.444451 model2 loss : 0.018780
[00:56:05.139] iteration 23700 : model1 loss : 0.438725 model2 loss : 0.018323
[00:56:05.320] iteration 23701 : model1 loss : 0.441508 model2 loss : 0.016250
[00:56:05.503] iteration 23702 : model1 loss : 0.438755 model2 loss : 0.016476
[00:56:05.690] iteration 23703 : model1 loss : 0.440789 model2 loss : 0.017447
[00:56:05.883] iteration 23704 : model1 loss : 0.440047 model2 loss : 0.018274
[00:56:06.070] iteration 23705 : model1 loss : 0.437739 model2 loss : 0.015767
[00:56:06.254] iteration 23706 : model1 loss : 0.435621 model2 loss : 0.016093
[00:56:06.438] iteration 23707 : model1 loss : 0.443185 model2 loss : 0.019915
[00:56:06.607] iteration 23708 : model1 loss : 0.439906 model2 loss : 0.017058
[00:56:06.776] iteration 23709 : model1 loss : 0.437928 model2 loss : 0.017880
[00:56:08.797] iteration 23710 : model1 loss : 0.438281 model2 loss : 0.015435
[00:56:08.970] iteration 23711 : model1 loss : 0.439092 model2 loss : 0.017343
[00:56:09.144] iteration 23712 : model1 loss : 0.439338 model2 loss : 0.015947
[00:56:09.317] iteration 23713 : model1 loss : 0.433570 model2 loss : 0.016815
[00:56:09.498] iteration 23714 : model1 loss : 0.438138 model2 loss : 0.017245
[00:56:09.679] iteration 23715 : model1 loss : 0.437963 model2 loss : 0.015804
[00:56:09.863] iteration 23716 : model1 loss : 0.441672 model2 loss : 0.017595
[00:56:10.047] iteration 23717 : model1 loss : 0.433936 model2 loss : 0.016800
[00:56:10.215] iteration 23718 : model1 loss : 0.440251 model2 loss : 0.017882
[00:56:10.384] iteration 23719 : model1 loss : 0.443554 model2 loss : 0.021872
[00:56:10.553] iteration 23720 : model1 loss : 0.438491 model2 loss : 0.017796
[00:56:10.720] iteration 23721 : model1 loss : 0.443433 model2 loss : 0.018726
[00:56:10.895] iteration 23722 : model1 loss : 0.443468 model2 loss : 0.019280
[00:56:11.077] iteration 23723 : model1 loss : 0.437120 model2 loss : 0.015687
[00:56:11.250] iteration 23724 : model1 loss : 0.438303 model2 loss : 0.017213
[00:56:11.417] iteration 23725 : model1 loss : 0.434852 model2 loss : 0.016561
[00:56:11.596] iteration 23726 : model1 loss : 0.442713 model2 loss : 0.018471
[00:56:11.778] iteration 23727 : model1 loss : 0.439738 model2 loss : 0.017915
[00:56:11.950] iteration 23728 : model1 loss : 0.443204 model2 loss : 0.019483
[00:56:12.120] iteration 23729 : model1 loss : 0.443121 model2 loss : 0.020055
[00:56:12.289] iteration 23730 : model1 loss : 0.437032 model2 loss : 0.017026
[00:56:14.533] iteration 23731 : model1 loss : 0.438408 model2 loss : 0.017162
[00:56:14.715] iteration 23732 : model1 loss : 0.438771 model2 loss : 0.017066
[00:56:14.892] iteration 23733 : model1 loss : 0.438274 model2 loss : 0.014444
[00:56:15.061] iteration 23734 : model1 loss : 0.437866 model2 loss : 0.017586
[00:56:15.233] iteration 23735 : model1 loss : 0.438940 model2 loss : 0.017161
[00:56:15.403] iteration 23736 : model1 loss : 0.434821 model2 loss : 0.017827
[00:56:15.611] iteration 23737 : model1 loss : 0.444572 model2 loss : 0.021150
[00:56:15.845] iteration 23738 : model1 loss : 0.442249 model2 loss : 0.017760
[00:56:16.021] iteration 23739 : model1 loss : 0.438647 model2 loss : 0.018794
[00:56:16.191] iteration 23740 : model1 loss : 0.438752 model2 loss : 0.017979
[00:56:16.363] iteration 23741 : model1 loss : 0.439825 model2 loss : 0.018998
[00:56:16.532] iteration 23742 : model1 loss : 0.440543 model2 loss : 0.018501
[00:56:16.699] iteration 23743 : model1 loss : 0.442317 model2 loss : 0.019940
[00:56:16.885] iteration 23744 : model1 loss : 0.438290 model2 loss : 0.016768
[00:56:17.081] iteration 23745 : model1 loss : 0.442884 model2 loss : 0.017382
[00:56:17.276] iteration 23746 : model1 loss : 0.435167 model2 loss : 0.017504
[00:56:17.457] iteration 23747 : model1 loss : 0.440849 model2 loss : 0.019921
[00:56:17.633] iteration 23748 : model1 loss : 0.439273 model2 loss : 0.016818
[00:56:17.816] iteration 23749 : model1 loss : 0.437617 model2 loss : 0.016300
[00:56:18.005] iteration 23750 : model1 loss : 0.442681 model2 loss : 0.016728
[00:56:18.185] iteration 23751 : model1 loss : 0.436901 model2 loss : 0.018109
[00:56:20.407] iteration 23752 : model1 loss : 0.441850 model2 loss : 0.017259
[00:56:20.606] iteration 23753 : model1 loss : 0.441106 model2 loss : 0.017289
[00:56:20.775] iteration 23754 : model1 loss : 0.437841 model2 loss : 0.016925
[00:56:20.944] iteration 23755 : model1 loss : 0.438057 model2 loss : 0.016824
[00:56:21.116] iteration 23756 : model1 loss : 0.441953 model2 loss : 0.019275
[00:56:21.282] iteration 23757 : model1 loss : 0.438506 model2 loss : 0.018301
[00:56:21.450] iteration 23758 : model1 loss : 0.437176 model2 loss : 0.017856
[00:56:21.617] iteration 23759 : model1 loss : 0.439937 model2 loss : 0.018331
[00:56:21.786] iteration 23760 : model1 loss : 0.438376 model2 loss : 0.017563
[00:56:21.955] iteration 23761 : model1 loss : 0.439834 model2 loss : 0.016769
[00:56:22.125] iteration 23762 : model1 loss : 0.440039 model2 loss : 0.016619
[00:56:22.292] iteration 23763 : model1 loss : 0.440387 model2 loss : 0.018676
[00:56:22.464] iteration 23764 : model1 loss : 0.436394 model2 loss : 0.015426
[00:56:22.632] iteration 23765 : model1 loss : 0.438953 model2 loss : 0.018073
[00:56:22.802] iteration 23766 : model1 loss : 0.435986 model2 loss : 0.018985
[00:56:22.970] iteration 23767 : model1 loss : 0.437414 model2 loss : 0.017544
[00:56:23.147] iteration 23768 : model1 loss : 0.437223 model2 loss : 0.017189
[00:56:23.317] iteration 23769 : model1 loss : 0.438302 model2 loss : 0.017417
[00:56:23.497] iteration 23770 : model1 loss : 0.443140 model2 loss : 0.019385
[00:56:23.682] iteration 23771 : model1 loss : 0.445808 model2 loss : 0.017438
[00:56:23.871] iteration 23772 : model1 loss : 0.442110 model2 loss : 0.016471
[00:56:26.024] iteration 23773 : model1 loss : 0.437889 model2 loss : 0.017660
[00:56:26.195] iteration 23774 : model1 loss : 0.440976 model2 loss : 0.017166
[00:56:26.365] iteration 23775 : model1 loss : 0.436636 model2 loss : 0.015585
[00:56:26.532] iteration 23776 : model1 loss : 0.441078 model2 loss : 0.017563
[00:56:26.701] iteration 23777 : model1 loss : 0.441861 model2 loss : 0.018592
[00:56:26.870] iteration 23778 : model1 loss : 0.439714 model2 loss : 0.017434
[00:56:27.043] iteration 23779 : model1 loss : 0.442402 model2 loss : 0.020489
[00:56:27.268] iteration 23780 : model1 loss : 0.437373 model2 loss : 0.015866
[00:56:27.490] iteration 23781 : model1 loss : 0.439826 model2 loss : 0.019228
[00:56:27.700] iteration 23782 : model1 loss : 0.439316 model2 loss : 0.016522
[00:56:27.869] iteration 23783 : model1 loss : 0.437946 model2 loss : 0.016549
[00:56:28.042] iteration 23784 : model1 loss : 0.443585 model2 loss : 0.018892
[00:56:28.213] iteration 23785 : model1 loss : 0.438127 model2 loss : 0.018848
[00:56:28.383] iteration 23786 : model1 loss : 0.440256 model2 loss : 0.018663
[00:56:28.550] iteration 23787 : model1 loss : 0.442715 model2 loss : 0.018934
[00:56:28.725] iteration 23788 : model1 loss : 0.439629 model2 loss : 0.016982
[00:56:28.897] iteration 23789 : model1 loss : 0.438458 model2 loss : 0.018191
[00:56:29.068] iteration 23790 : model1 loss : 0.436430 model2 loss : 0.017443
[00:56:29.241] iteration 23791 : model1 loss : 0.438773 model2 loss : 0.016691
[00:56:29.410] iteration 23792 : model1 loss : 0.435788 model2 loss : 0.016675
[00:56:29.577] iteration 23793 : model1 loss : 0.439945 model2 loss : 0.019464
[00:56:31.648] iteration 23794 : model1 loss : 0.439715 model2 loss : 0.016668
[00:56:31.822] iteration 23795 : model1 loss : 0.437805 model2 loss : 0.017383
[00:56:31.993] iteration 23796 : model1 loss : 0.438028 model2 loss : 0.016340
[00:56:32.165] iteration 23797 : model1 loss : 0.440055 model2 loss : 0.016824
[00:56:32.337] iteration 23798 : model1 loss : 0.436110 model2 loss : 0.015889
[00:56:32.510] iteration 23799 : model1 loss : 0.436878 model2 loss : 0.016419
[00:56:32.720] iteration 23800 : model1 loss : 0.437107 model2 loss : 0.018032
[00:56:32.940] iteration 23801 : model1 loss : 0.440095 model2 loss : 0.017833
[00:56:33.163] iteration 23802 : model1 loss : 0.442943 model2 loss : 0.018660
[00:56:33.387] iteration 23803 : model1 loss : 0.441001 model2 loss : 0.015824
[00:56:33.607] iteration 23804 : model1 loss : 0.436115 model2 loss : 0.017687
[00:56:33.828] iteration 23805 : model1 loss : 0.434889 model2 loss : 0.016891
[00:56:34.050] iteration 23806 : model1 loss : 0.444239 model2 loss : 0.019525
[00:56:34.268] iteration 23807 : model1 loss : 0.438114 model2 loss : 0.019060
[00:56:34.491] iteration 23808 : model1 loss : 0.437983 model2 loss : 0.017054
[00:56:34.712] iteration 23809 : model1 loss : 0.441982 model2 loss : 0.019337
[00:56:34.933] iteration 23810 : model1 loss : 0.440455 model2 loss : 0.017294
[00:56:35.156] iteration 23811 : model1 loss : 0.442371 model2 loss : 0.018954
[00:56:35.376] iteration 23812 : model1 loss : 0.441117 model2 loss : 0.017899
[00:56:35.597] iteration 23813 : model1 loss : 0.440397 model2 loss : 0.017345
[00:56:35.815] iteration 23814 : model1 loss : 0.444077 model2 loss : 0.019027
[00:56:37.844] iteration 23815 : model1 loss : 0.443243 model2 loss : 0.021658
[00:56:38.020] iteration 23816 : model1 loss : 0.442080 model2 loss : 0.018793
[00:56:38.189] iteration 23817 : model1 loss : 0.435939 model2 loss : 0.016822
[00:56:38.360] iteration 23818 : model1 loss : 0.438855 model2 loss : 0.018834
[00:56:38.549] iteration 23819 : model1 loss : 0.436032 model2 loss : 0.017725
[00:56:38.718] iteration 23820 : model1 loss : 0.439424 model2 loss : 0.017636
[00:56:38.891] iteration 23821 : model1 loss : 0.441617 model2 loss : 0.016459
[00:56:39.059] iteration 23822 : model1 loss : 0.443258 model2 loss : 0.019418
[00:56:39.233] iteration 23823 : model1 loss : 0.439831 model2 loss : 0.022024
[00:56:39.403] iteration 23824 : model1 loss : 0.438335 model2 loss : 0.019263
[00:56:39.574] iteration 23825 : model1 loss : 0.437014 model2 loss : 0.025457
[00:56:39.744] iteration 23826 : model1 loss : 0.439755 model2 loss : 0.018603
[00:56:39.922] iteration 23827 : model1 loss : 0.434150 model2 loss : 0.016715
[00:56:40.111] iteration 23828 : model1 loss : 0.441423 model2 loss : 0.018817
[00:56:40.293] iteration 23829 : model1 loss : 0.440335 model2 loss : 0.019221
[00:56:40.466] iteration 23830 : model1 loss : 0.442382 model2 loss : 0.017320
[00:56:40.636] iteration 23831 : model1 loss : 0.438712 model2 loss : 0.016615
[00:56:40.805] iteration 23832 : model1 loss : 0.440886 model2 loss : 0.018921
[00:56:40.978] iteration 23833 : model1 loss : 0.442510 model2 loss : 0.022975
[00:56:41.151] iteration 23834 : model1 loss : 0.439591 model2 loss : 0.017547
[00:56:41.321] iteration 23835 : model1 loss : 0.439140 model2 loss : 0.019115
[00:56:43.333] iteration 23836 : model1 loss : 0.439654 model2 loss : 0.019217
[00:56:43.503] iteration 23837 : model1 loss : 0.437822 model2 loss : 0.017299
[00:56:43.676] iteration 23838 : model1 loss : 0.442265 model2 loss : 0.023219
[00:56:43.847] iteration 23839 : model1 loss : 0.437749 model2 loss : 0.023943
[00:56:44.018] iteration 23840 : model1 loss : 0.442316 model2 loss : 0.018430
[00:56:44.189] iteration 23841 : model1 loss : 0.441988 model2 loss : 0.019298
[00:56:44.360] iteration 23842 : model1 loss : 0.438235 model2 loss : 0.022151
[00:56:44.531] iteration 23843 : model1 loss : 0.440801 model2 loss : 0.019745
[00:56:44.704] iteration 23844 : model1 loss : 0.441433 model2 loss : 0.020476
[00:56:44.873] iteration 23845 : model1 loss : 0.438191 model2 loss : 0.021285
[00:56:45.045] iteration 23846 : model1 loss : 0.442636 model2 loss : 0.018397
[00:56:45.220] iteration 23847 : model1 loss : 0.437686 model2 loss : 0.017535
[00:56:45.389] iteration 23848 : model1 loss : 0.439877 model2 loss : 0.021162
[00:56:45.558] iteration 23849 : model1 loss : 0.435814 model2 loss : 0.017880
[00:56:45.730] iteration 23850 : model1 loss : 0.438120 model2 loss : 0.022434
[00:56:45.903] iteration 23851 : model1 loss : 0.444297 model2 loss : 0.021644
[00:56:46.072] iteration 23852 : model1 loss : 0.436939 model2 loss : 0.017087
[00:56:46.241] iteration 23853 : model1 loss : 0.441923 model2 loss : 0.018725
[00:56:46.416] iteration 23854 : model1 loss : 0.441863 model2 loss : 0.019789
[00:56:46.582] iteration 23855 : model1 loss : 0.436244 model2 loss : 0.019259
[00:56:46.750] iteration 23856 : model1 loss : 0.439434 model2 loss : 0.018483
[00:56:48.764] iteration 23857 : model1 loss : 0.439380 model2 loss : 0.018577
[00:56:48.936] iteration 23858 : model1 loss : 0.440238 model2 loss : 0.019494
[00:56:49.109] iteration 23859 : model1 loss : 0.438855 model2 loss : 0.017927
[00:56:49.277] iteration 23860 : model1 loss : 0.439250 model2 loss : 0.020006
[00:56:49.452] iteration 23861 : model1 loss : 0.443484 model2 loss : 0.019189
[00:56:49.621] iteration 23862 : model1 loss : 0.437506 model2 loss : 0.016540
[00:56:49.789] iteration 23863 : model1 loss : 0.441011 model2 loss : 0.017765
[00:56:49.960] iteration 23864 : model1 loss : 0.441432 model2 loss : 0.024035
[00:56:50.137] iteration 23865 : model1 loss : 0.442432 model2 loss : 0.019037
[00:56:50.308] iteration 23866 : model1 loss : 0.437754 model2 loss : 0.017508
[00:56:50.477] iteration 23867 : model1 loss : 0.441679 model2 loss : 0.021150
[00:56:50.650] iteration 23868 : model1 loss : 0.439194 model2 loss : 0.019367
[00:56:50.818] iteration 23869 : model1 loss : 0.439017 model2 loss : 0.022816
[00:56:50.987] iteration 23870 : model1 loss : 0.443876 model2 loss : 0.019847
[00:56:51.164] iteration 23871 : model1 loss : 0.435020 model2 loss : 0.018804
[00:56:51.335] iteration 23872 : model1 loss : 0.438902 model2 loss : 0.018847
[00:56:51.505] iteration 23873 : model1 loss : 0.438571 model2 loss : 0.020646
[00:56:51.676] iteration 23874 : model1 loss : 0.437171 model2 loss : 0.017736
[00:56:51.850] iteration 23875 : model1 loss : 0.438811 model2 loss : 0.018016
[00:56:52.016] iteration 23876 : model1 loss : 0.441705 model2 loss : 0.017916
[00:56:52.188] iteration 23877 : model1 loss : 0.440298 model2 loss : 0.021180
[00:56:54.173] iteration 23878 : model1 loss : 0.435440 model2 loss : 0.016189
[00:56:54.354] iteration 23879 : model1 loss : 0.439722 model2 loss : 0.019532
[00:56:54.523] iteration 23880 : model1 loss : 0.440435 model2 loss : 0.020283
[00:56:54.692] iteration 23881 : model1 loss : 0.436269 model2 loss : 0.018325
[00:56:54.865] iteration 23882 : model1 loss : 0.437400 model2 loss : 0.019280
[00:56:55.032] iteration 23883 : model1 loss : 0.437671 model2 loss : 0.020451
[00:56:55.201] iteration 23884 : model1 loss : 0.437450 model2 loss : 0.016635
[00:56:55.375] iteration 23885 : model1 loss : 0.436949 model2 loss : 0.018075
[00:56:55.544] iteration 23886 : model1 loss : 0.440808 model2 loss : 0.017523
[00:56:55.712] iteration 23887 : model1 loss : 0.437226 model2 loss : 0.018327
[00:56:55.885] iteration 23888 : model1 loss : 0.439045 model2 loss : 0.018902
[00:56:56.056] iteration 23889 : model1 loss : 0.442634 model2 loss : 0.018263
[00:56:56.225] iteration 23890 : model1 loss : 0.443328 model2 loss : 0.018162
[00:56:56.395] iteration 23891 : model1 loss : 0.445179 model2 loss : 0.017835
[00:56:56.568] iteration 23892 : model1 loss : 0.439596 model2 loss : 0.016681
[00:56:56.736] iteration 23893 : model1 loss : 0.436913 model2 loss : 0.019546
[00:56:56.909] iteration 23894 : model1 loss : 0.437657 model2 loss : 0.017375
[00:56:57.079] iteration 23895 : model1 loss : 0.442097 model2 loss : 0.020504
[00:56:57.250] iteration 23896 : model1 loss : 0.437841 model2 loss : 0.018660
[00:56:57.422] iteration 23897 : model1 loss : 0.444167 model2 loss : 0.018391
[00:56:57.599] iteration 23898 : model1 loss : 0.444921 model2 loss : 0.021272
[00:56:59.610] iteration 23899 : model1 loss : 0.440358 model2 loss : 0.019154
[00:56:59.782] iteration 23900 : model1 loss : 0.440315 model2 loss : 0.018782
[00:56:59.950] iteration 23901 : model1 loss : 0.439113 model2 loss : 0.019172
[00:57:00.128] iteration 23902 : model1 loss : 0.441887 model2 loss : 0.018330
[00:57:00.298] iteration 23903 : model1 loss : 0.436688 model2 loss : 0.018409
[00:57:00.467] iteration 23904 : model1 loss : 0.440374 model2 loss : 0.018304
[00:57:00.640] iteration 23905 : model1 loss : 0.440485 model2 loss : 0.019106
[00:57:00.815] iteration 23906 : model1 loss : 0.437518 model2 loss : 0.017172
[00:57:00.985] iteration 23907 : model1 loss : 0.437465 model2 loss : 0.018316
[00:57:01.158] iteration 23908 : model1 loss : 0.441477 model2 loss : 0.017570
[00:57:01.333] iteration 23909 : model1 loss : 0.437061 model2 loss : 0.017849
[00:57:01.501] iteration 23910 : model1 loss : 0.440662 model2 loss : 0.018124
[00:57:01.673] iteration 23911 : model1 loss : 0.440541 model2 loss : 0.017321
[00:57:01.842] iteration 23912 : model1 loss : 0.440979 model2 loss : 0.018784
[00:57:02.014] iteration 23913 : model1 loss : 0.437879 model2 loss : 0.018533
[00:57:02.184] iteration 23914 : model1 loss : 0.439556 model2 loss : 0.018974
[00:57:02.354] iteration 23915 : model1 loss : 0.443613 model2 loss : 0.018092
[00:57:02.527] iteration 23916 : model1 loss : 0.439718 model2 loss : 0.018071
[00:57:02.697] iteration 23917 : model1 loss : 0.437391 model2 loss : 0.016765
[00:57:02.867] iteration 23918 : model1 loss : 0.440605 model2 loss : 0.017634
[00:57:03.035] iteration 23919 : model1 loss : 0.435642 model2 loss : 0.015385
[00:57:05.031] iteration 23920 : model1 loss : 0.439792 model2 loss : 0.016598
[00:57:05.201] iteration 23921 : model1 loss : 0.439864 model2 loss : 0.019827
[00:57:05.372] iteration 23922 : model1 loss : 0.440470 model2 loss : 0.019198
[00:57:05.546] iteration 23923 : model1 loss : 0.439920 model2 loss : 0.019219
[00:57:05.716] iteration 23924 : model1 loss : 0.438307 model2 loss : 0.014746
[00:57:05.884] iteration 23925 : model1 loss : 0.438881 model2 loss : 0.017503
[00:57:06.058] iteration 23926 : model1 loss : 0.442725 model2 loss : 0.018777
[00:57:06.228] iteration 23927 : model1 loss : 0.438637 model2 loss : 0.015858
[00:57:06.398] iteration 23928 : model1 loss : 0.436689 model2 loss : 0.017009
[00:57:06.571] iteration 23929 : model1 loss : 0.443056 model2 loss : 0.020248
[00:57:06.742] iteration 23930 : model1 loss : 0.437927 model2 loss : 0.016138
[00:57:06.911] iteration 23931 : model1 loss : 0.443723 model2 loss : 0.020418
[00:57:07.082] iteration 23932 : model1 loss : 0.444462 model2 loss : 0.018276
[00:57:07.250] iteration 23933 : model1 loss : 0.431874 model2 loss : 0.015738
[00:57:07.422] iteration 23934 : model1 loss : 0.437253 model2 loss : 0.018230
[00:57:07.593] iteration 23935 : model1 loss : 0.441905 model2 loss : 0.019049
[00:57:07.760] iteration 23936 : model1 loss : 0.438554 model2 loss : 0.019459
[00:57:07.931] iteration 23937 : model1 loss : 0.443880 model2 loss : 0.016863
[00:57:08.106] iteration 23938 : model1 loss : 0.439972 model2 loss : 0.019049
[00:57:08.273] iteration 23939 : model1 loss : 0.442770 model2 loss : 0.020359
[00:57:08.441] iteration 23940 : model1 loss : 0.434368 model2 loss : 0.017347
[00:57:10.431] iteration 23941 : model1 loss : 0.441212 model2 loss : 0.017161
[00:57:10.598] iteration 23942 : model1 loss : 0.443999 model2 loss : 0.021316
[00:57:10.774] iteration 23943 : model1 loss : 0.440079 model2 loss : 0.016938
[00:57:10.944] iteration 23944 : model1 loss : 0.438345 model2 loss : 0.017460
[00:57:11.115] iteration 23945 : model1 loss : 0.442406 model2 loss : 0.016884
[00:57:11.287] iteration 23946 : model1 loss : 0.435627 model2 loss : 0.015941
[00:57:11.455] iteration 23947 : model1 loss : 0.437498 model2 loss : 0.018894
[00:57:11.626] iteration 23948 : model1 loss : 0.439211 model2 loss : 0.017362
[00:57:11.799] iteration 23949 : model1 loss : 0.440441 model2 loss : 0.018455
[00:57:11.968] iteration 23950 : model1 loss : 0.441948 model2 loss : 0.018123
[00:57:12.142] iteration 23951 : model1 loss : 0.441881 model2 loss : 0.020489
[00:57:12.315] iteration 23952 : model1 loss : 0.438777 model2 loss : 0.016872
[00:57:12.487] iteration 23953 : model1 loss : 0.440841 model2 loss : 0.018396
[00:57:12.655] iteration 23954 : model1 loss : 0.445541 model2 loss : 0.022788
[00:57:12.829] iteration 23955 : model1 loss : 0.435796 model2 loss : 0.018195
[00:57:12.997] iteration 23956 : model1 loss : 0.435631 model2 loss : 0.016197
[00:57:13.168] iteration 23957 : model1 loss : 0.438830 model2 loss : 0.017509
[00:57:13.342] iteration 23958 : model1 loss : 0.440875 model2 loss : 0.017058
[00:57:13.513] iteration 23959 : model1 loss : 0.438518 model2 loss : 0.018818
[00:57:13.680] iteration 23960 : model1 loss : 0.436453 model2 loss : 0.016360
[00:57:13.851] iteration 23961 : model1 loss : 0.437032 model2 loss : 0.017566
[00:57:15.859] iteration 23962 : model1 loss : 0.439162 model2 loss : 0.016481
[00:57:16.031] iteration 23963 : model1 loss : 0.440524 model2 loss : 0.018695
[00:57:16.201] iteration 23964 : model1 loss : 0.436840 model2 loss : 0.018125
[00:57:16.372] iteration 23965 : model1 loss : 0.440935 model2 loss : 0.018453
[00:57:16.557] iteration 23966 : model1 loss : 0.440650 model2 loss : 0.017800
[00:57:16.727] iteration 23967 : model1 loss : 0.441528 model2 loss : 0.015973
[00:57:16.901] iteration 23968 : model1 loss : 0.442808 model2 loss : 0.016583
[00:57:17.070] iteration 23969 : model1 loss : 0.435860 model2 loss : 0.017270
[00:57:17.239] iteration 23970 : model1 loss : 0.439246 model2 loss : 0.018122
[00:57:17.411] iteration 23971 : model1 loss : 0.440439 model2 loss : 0.016280
[00:57:17.584] iteration 23972 : model1 loss : 0.438999 model2 loss : 0.018916
[00:57:17.751] iteration 23973 : model1 loss : 0.442436 model2 loss : 0.019628
[00:57:17.924] iteration 23974 : model1 loss : 0.444944 model2 loss : 0.019157
[00:57:18.096] iteration 23975 : model1 loss : 0.435665 model2 loss : 0.014940
[00:57:18.265] iteration 23976 : model1 loss : 0.439383 model2 loss : 0.016821
[00:57:18.434] iteration 23977 : model1 loss : 0.435030 model2 loss : 0.016491
[00:57:18.606] iteration 23978 : model1 loss : 0.438022 model2 loss : 0.017564
[00:57:18.776] iteration 23979 : model1 loss : 0.440588 model2 loss : 0.017433
[00:57:18.947] iteration 23980 : model1 loss : 0.438374 model2 loss : 0.017328
[00:57:19.117] iteration 23981 : model1 loss : 0.437196 model2 loss : 0.017615
[00:57:19.289] iteration 23982 : model1 loss : 0.440336 model2 loss : 0.018852
[00:57:21.284] iteration 23983 : model1 loss : 0.440685 model2 loss : 0.018457
[00:57:21.457] iteration 23984 : model1 loss : 0.441511 model2 loss : 0.018735
[00:57:21.634] iteration 23985 : model1 loss : 0.437969 model2 loss : 0.016399
[00:57:21.803] iteration 23986 : model1 loss : 0.441730 model2 loss : 0.018662
[00:57:21.973] iteration 23987 : model1 loss : 0.438019 model2 loss : 0.016860
[00:57:22.147] iteration 23988 : model1 loss : 0.440932 model2 loss : 0.019219
[00:57:22.326] iteration 23989 : model1 loss : 0.440221 model2 loss : 0.018191
[00:57:22.499] iteration 23990 : model1 loss : 0.437057 model2 loss : 0.018489
[00:57:22.669] iteration 23991 : model1 loss : 0.439619 model2 loss : 0.018604
[00:57:22.839] iteration 23992 : model1 loss : 0.435012 model2 loss : 0.016850
[00:57:23.011] iteration 23993 : model1 loss : 0.438526 model2 loss : 0.016786
[00:57:23.179] iteration 23994 : model1 loss : 0.438487 model2 loss : 0.017232
[00:57:23.352] iteration 23995 : model1 loss : 0.440030 model2 loss : 0.019238
[00:57:23.523] iteration 23996 : model1 loss : 0.443317 model2 loss : 0.017578
[00:57:23.692] iteration 23997 : model1 loss : 0.440367 model2 loss : 0.017478
[00:57:23.865] iteration 23998 : model1 loss : 0.441472 model2 loss : 0.019442
[00:57:24.038] iteration 23999 : model1 loss : 0.439068 model2 loss : 0.015502
[00:57:24.210] iteration 24000 : model1 loss : 0.438315 model2 loss : 0.018372
[00:57:33.002] iteration 24000 : model1_mean_dice : 0.884670 model1_mean_hd95 : 4.878447
[00:57:41.987] iteration 24000 : model2_mean_dice : 0.878312 model2_mean_hd95 : 4.418428
[00:57:42.008] save model1 to ../model/ACDC/EVILv1_kl0.5_tau0.25_14_1337/unet\model1_iter_24000.pth
[00:57:42.030] save model2 to ../model/ACDC/EVILv1_kl0.5_tau0.25_14_1337/unet\model2_iter_24000.pth
[00:57:42.230] iteration 24001 : model1 loss : 0.437200 model2 loss : 0.019937
[00:57:42.397] iteration 24002 : model1 loss : 0.443358 model2 loss : 0.017294
[00:57:42.564] iteration 24003 : model1 loss : 0.438029 model2 loss : 0.017644
[00:57:44.626] iteration 24004 : model1 loss : 0.438514 model2 loss : 0.018214
[00:57:44.799] iteration 24005 : model1 loss : 0.437189 model2 loss : 0.016972
[00:57:44.977] iteration 24006 : model1 loss : 0.445974 model2 loss : 0.021994
[00:57:45.182] iteration 24007 : model1 loss : 0.437314 model2 loss : 0.017849
[00:57:45.363] iteration 24008 : model1 loss : 0.441332 model2 loss : 0.018154
[00:57:45.552] iteration 24009 : model1 loss : 0.440127 model2 loss : 0.018791
[00:57:45.742] iteration 24010 : model1 loss : 0.438547 model2 loss : 0.016503
[00:57:45.927] iteration 24011 : model1 loss : 0.440143 model2 loss : 0.019137
[00:57:46.094] iteration 24012 : model1 loss : 0.439997 model2 loss : 0.015543
[00:57:46.263] iteration 24013 : model1 loss : 0.442374 model2 loss : 0.020402
[00:57:46.430] iteration 24014 : model1 loss : 0.442638 model2 loss : 0.025412
[00:57:46.599] iteration 24015 : model1 loss : 0.442708 model2 loss : 0.017691
[00:57:46.766] iteration 24016 : model1 loss : 0.437904 model2 loss : 0.020437
[00:57:46.936] iteration 24017 : model1 loss : 0.438072 model2 loss : 0.015711
[00:57:47.109] iteration 24018 : model1 loss : 0.437372 model2 loss : 0.019281
[00:57:47.278] iteration 24019 : model1 loss : 0.439759 model2 loss : 0.018988
[00:57:47.448] iteration 24020 : model1 loss : 0.442066 model2 loss : 0.016832
[00:57:47.615] iteration 24021 : model1 loss : 0.437903 model2 loss : 0.017675
[00:57:47.782] iteration 24022 : model1 loss : 0.439022 model2 loss : 0.018957
[00:57:47.950] iteration 24023 : model1 loss : 0.438028 model2 loss : 0.017406
[00:57:48.118] iteration 24024 : model1 loss : 0.438429 model2 loss : 0.017033
[00:57:50.104] iteration 24025 : model1 loss : 0.442434 model2 loss : 0.018512
[00:57:50.272] iteration 24026 : model1 loss : 0.443657 model2 loss : 0.018309
[00:57:50.441] iteration 24027 : model1 loss : 0.436657 model2 loss : 0.016283
[00:57:50.608] iteration 24028 : model1 loss : 0.440895 model2 loss : 0.017293
[00:57:50.778] iteration 24029 : model1 loss : 0.439048 model2 loss : 0.016089
[00:57:50.947] iteration 24030 : model1 loss : 0.442661 model2 loss : 0.016157
[00:57:51.119] iteration 24031 : model1 loss : 0.437540 model2 loss : 0.018341
[00:57:51.285] iteration 24032 : model1 loss : 0.436515 model2 loss : 0.017634
[00:57:51.455] iteration 24033 : model1 loss : 0.435082 model2 loss : 0.018944
[00:57:51.623] iteration 24034 : model1 loss : 0.439226 model2 loss : 0.018160
[00:57:51.796] iteration 24035 : model1 loss : 0.438252 model2 loss : 0.017824
[00:57:51.964] iteration 24036 : model1 loss : 0.439643 model2 loss : 0.017073
[00:57:52.139] iteration 24037 : model1 loss : 0.442861 model2 loss : 0.017738
[00:57:52.308] iteration 24038 : model1 loss : 0.438794 model2 loss : 0.018270
[00:57:52.479] iteration 24039 : model1 loss : 0.439799 model2 loss : 0.018967
[00:57:52.646] iteration 24040 : model1 loss : 0.435849 model2 loss : 0.016597
[00:57:52.815] iteration 24041 : model1 loss : 0.440388 model2 loss : 0.017359
[00:57:52.984] iteration 24042 : model1 loss : 0.442235 model2 loss : 0.019678
[00:57:53.155] iteration 24043 : model1 loss : 0.438468 model2 loss : 0.016725
[00:57:53.323] iteration 24044 : model1 loss : 0.440213 model2 loss : 0.017984
[00:57:53.492] iteration 24045 : model1 loss : 0.439586 model2 loss : 0.018155
[00:57:55.451] iteration 24046 : model1 loss : 0.439406 model2 loss : 0.018046
[00:57:55.618] iteration 24047 : model1 loss : 0.437351 model2 loss : 0.018482
[00:57:55.791] iteration 24048 : model1 loss : 0.443294 model2 loss : 0.019522
[00:57:55.958] iteration 24049 : model1 loss : 0.440443 model2 loss : 0.018269
[00:57:56.131] iteration 24050 : model1 loss : 0.439549 model2 loss : 0.018505
[00:57:56.300] iteration 24051 : model1 loss : 0.441643 model2 loss : 0.017076
[00:57:56.467] iteration 24052 : model1 loss : 0.442289 model2 loss : 0.017425
[00:57:56.634] iteration 24053 : model1 loss : 0.439575 model2 loss : 0.017780
[00:57:56.803] iteration 24054 : model1 loss : 0.442764 model2 loss : 0.020035
[00:57:56.971] iteration 24055 : model1 loss : 0.441626 model2 loss : 0.017586
[00:57:57.140] iteration 24056 : model1 loss : 0.440158 model2 loss : 0.018034
[00:57:57.311] iteration 24057 : model1 loss : 0.445277 model2 loss : 0.019946
[00:57:57.483] iteration 24058 : model1 loss : 0.434113 model2 loss : 0.017254
[00:57:57.649] iteration 24059 : model1 loss : 0.434765 model2 loss : 0.017546
[00:57:57.817] iteration 24060 : model1 loss : 0.436630 model2 loss : 0.015323
[00:57:57.987] iteration 24061 : model1 loss : 0.436750 model2 loss : 0.018219
[00:57:58.159] iteration 24062 : model1 loss : 0.437093 model2 loss : 0.015735
[00:57:58.333] iteration 24063 : model1 loss : 0.439128 model2 loss : 0.017554
[00:57:58.502] iteration 24064 : model1 loss : 0.439783 model2 loss : 0.016872
[00:57:58.668] iteration 24065 : model1 loss : 0.443092 model2 loss : 0.017254
[00:57:58.836] iteration 24066 : model1 loss : 0.436964 model2 loss : 0.016363
[00:58:00.830] iteration 24067 : model1 loss : 0.434671 model2 loss : 0.017458
[00:58:00.996] iteration 24068 : model1 loss : 0.437987 model2 loss : 0.016248
[00:58:01.165] iteration 24069 : model1 loss : 0.434612 model2 loss : 0.015516
[00:58:01.333] iteration 24070 : model1 loss : 0.439178 model2 loss : 0.018332
[00:58:01.502] iteration 24071 : model1 loss : 0.445310 model2 loss : 0.018457
[00:58:01.671] iteration 24072 : model1 loss : 0.443059 model2 loss : 0.016021
[00:58:01.842] iteration 24073 : model1 loss : 0.444662 model2 loss : 0.018173
[00:58:02.011] iteration 24074 : model1 loss : 0.438222 model2 loss : 0.017947
[00:58:02.178] iteration 24075 : model1 loss : 0.438808 model2 loss : 0.015620
[00:58:02.350] iteration 24076 : model1 loss : 0.440880 model2 loss : 0.018802
[00:58:02.519] iteration 24077 : model1 loss : 0.439613 model2 loss : 0.016758
[00:58:02.687] iteration 24078 : model1 loss : 0.438820 model2 loss : 0.018472
[00:58:02.855] iteration 24079 : model1 loss : 0.437124 model2 loss : 0.017654
[00:58:03.022] iteration 24080 : model1 loss : 0.439619 model2 loss : 0.017717
[00:58:03.190] iteration 24081 : model1 loss : 0.436777 model2 loss : 0.016753
[00:58:03.358] iteration 24082 : model1 loss : 0.436601 model2 loss : 0.016683
[00:58:03.526] iteration 24083 : model1 loss : 0.437501 model2 loss : 0.017332
[00:58:03.695] iteration 24084 : model1 loss : 0.439430 model2 loss : 0.016856
[00:58:03.864] iteration 24085 : model1 loss : 0.441674 model2 loss : 0.021592
[00:58:04.031] iteration 24086 : model1 loss : 0.444711 model2 loss : 0.018124
[00:58:04.199] iteration 24087 : model1 loss : 0.438734 model2 loss : 0.017525
[00:58:06.167] iteration 24088 : model1 loss : 0.434322 model2 loss : 0.017378
[00:58:06.341] iteration 24089 : model1 loss : 0.437109 model2 loss : 0.016024
[00:58:06.511] iteration 24090 : model1 loss : 0.435731 model2 loss : 0.018235
[00:58:06.677] iteration 24091 : model1 loss : 0.438195 model2 loss : 0.016474
[00:58:06.846] iteration 24092 : model1 loss : 0.442402 model2 loss : 0.016517
[00:58:07.013] iteration 24093 : model1 loss : 0.440889 model2 loss : 0.018719
[00:58:07.184] iteration 24094 : model1 loss : 0.439549 model2 loss : 0.016934
[00:58:07.352] iteration 24095 : model1 loss : 0.440057 model2 loss : 0.018066
[00:58:07.522] iteration 24096 : model1 loss : 0.439515 model2 loss : 0.017170
[00:58:07.691] iteration 24097 : model1 loss : 0.445575 model2 loss : 0.017830
[00:58:07.859] iteration 24098 : model1 loss : 0.434596 model2 loss : 0.015238
[00:58:08.027] iteration 24099 : model1 loss : 0.440188 model2 loss : 0.015699
[00:58:08.197] iteration 24100 : model1 loss : 0.442102 model2 loss : 0.017388
[00:58:08.365] iteration 24101 : model1 loss : 0.439463 model2 loss : 0.018148
[00:58:08.536] iteration 24102 : model1 loss : 0.438984 model2 loss : 0.019816
[00:58:08.705] iteration 24103 : model1 loss : 0.437904 model2 loss : 0.019091
[00:58:08.875] iteration 24104 : model1 loss : 0.439007 model2 loss : 0.016185
[00:58:09.045] iteration 24105 : model1 loss : 0.440626 model2 loss : 0.019619
[00:58:09.214] iteration 24106 : model1 loss : 0.444081 model2 loss : 0.017525
[00:58:09.381] iteration 24107 : model1 loss : 0.440477 model2 loss : 0.017219
[00:58:09.549] iteration 24108 : model1 loss : 0.440981 model2 loss : 0.017521
[00:58:11.513] iteration 24109 : model1 loss : 0.443184 model2 loss : 0.019606
[00:58:11.682] iteration 24110 : model1 loss : 0.440499 model2 loss : 0.017484
[00:58:11.852] iteration 24111 : model1 loss : 0.439737 model2 loss : 0.018666
[00:58:12.020] iteration 24112 : model1 loss : 0.438901 model2 loss : 0.017042
[00:58:12.190] iteration 24113 : model1 loss : 0.438446 model2 loss : 0.018063
[00:58:12.359] iteration 24114 : model1 loss : 0.444267 model2 loss : 0.017948
[00:58:12.526] iteration 24115 : model1 loss : 0.438867 model2 loss : 0.018771
[00:58:12.695] iteration 24116 : model1 loss : 0.435733 model2 loss : 0.017786
[00:58:12.863] iteration 24117 : model1 loss : 0.439325 model2 loss : 0.017524
[00:58:13.031] iteration 24118 : model1 loss : 0.436616 model2 loss : 0.016617
[00:58:13.200] iteration 24119 : model1 loss : 0.442091 model2 loss : 0.018390
[00:58:13.368] iteration 24120 : model1 loss : 0.438373 model2 loss : 0.017874
[00:58:13.537] iteration 24121 : model1 loss : 0.435557 model2 loss : 0.018270
[00:58:13.705] iteration 24122 : model1 loss : 0.437333 model2 loss : 0.017430
[00:58:13.875] iteration 24123 : model1 loss : 0.439981 model2 loss : 0.018152
[00:58:14.044] iteration 24124 : model1 loss : 0.436640 model2 loss : 0.016541
[00:58:14.213] iteration 24125 : model1 loss : 0.441020 model2 loss : 0.018279
[00:58:14.385] iteration 24126 : model1 loss : 0.441471 model2 loss : 0.018452
[00:58:14.553] iteration 24127 : model1 loss : 0.440909 model2 loss : 0.018343
[00:58:14.718] iteration 24128 : model1 loss : 0.436981 model2 loss : 0.014690
[00:58:14.887] iteration 24129 : model1 loss : 0.440992 model2 loss : 0.016707
[00:58:16.859] iteration 24130 : model1 loss : 0.439085 model2 loss : 0.018382
[00:58:17.031] iteration 24131 : model1 loss : 0.441888 model2 loss : 0.019331
[00:58:17.200] iteration 24132 : model1 loss : 0.436898 model2 loss : 0.016572
[00:58:17.367] iteration 24133 : model1 loss : 0.439783 model2 loss : 0.017944
[00:58:17.537] iteration 24134 : model1 loss : 0.437312 model2 loss : 0.016375
[00:58:17.706] iteration 24135 : model1 loss : 0.435006 model2 loss : 0.015125
[00:58:17.874] iteration 24136 : model1 loss : 0.441682 model2 loss : 0.015864
[00:58:18.045] iteration 24137 : model1 loss : 0.439546 model2 loss : 0.017120
[00:58:18.212] iteration 24138 : model1 loss : 0.439067 model2 loss : 0.017661
[00:58:18.380] iteration 24139 : model1 loss : 0.442278 model2 loss : 0.018492
[00:58:18.548] iteration 24140 : model1 loss : 0.438866 model2 loss : 0.016025
[00:58:18.715] iteration 24141 : model1 loss : 0.436913 model2 loss : 0.017120
[00:58:18.885] iteration 24142 : model1 loss : 0.445453 model2 loss : 0.020583
[00:58:19.054] iteration 24143 : model1 loss : 0.434713 model2 loss : 0.016769
[00:58:19.222] iteration 24144 : model1 loss : 0.441721 model2 loss : 0.018920
[00:58:19.405] iteration 24145 : model1 loss : 0.443458 model2 loss : 0.021799
[00:58:19.572] iteration 24146 : model1 loss : 0.439095 model2 loss : 0.015839
[00:58:19.740] iteration 24147 : model1 loss : 0.438632 model2 loss : 0.016445
[00:58:19.909] iteration 24148 : model1 loss : 0.444499 model2 loss : 0.019527
[00:58:20.077] iteration 24149 : model1 loss : 0.437170 model2 loss : 0.016032
[00:58:20.244] iteration 24150 : model1 loss : 0.437261 model2 loss : 0.018636
[00:58:22.198] iteration 24151 : model1 loss : 0.439373 model2 loss : 0.017236
[00:58:22.372] iteration 24152 : model1 loss : 0.442237 model2 loss : 0.018731
[00:58:22.543] iteration 24153 : model1 loss : 0.435415 model2 loss : 0.017649
[00:58:22.711] iteration 24154 : model1 loss : 0.439553 model2 loss : 0.017208
[00:58:22.880] iteration 24155 : model1 loss : 0.439443 model2 loss : 0.016946
[00:58:23.050] iteration 24156 : model1 loss : 0.439432 model2 loss : 0.020385
[00:58:23.217] iteration 24157 : model1 loss : 0.441962 model2 loss : 0.016316
[00:58:23.385] iteration 24158 : model1 loss : 0.441783 model2 loss : 0.017821
[00:58:23.555] iteration 24159 : model1 loss : 0.439511 model2 loss : 0.015789
[00:58:23.722] iteration 24160 : model1 loss : 0.442528 model2 loss : 0.017274
[00:58:23.893] iteration 24161 : model1 loss : 0.443983 model2 loss : 0.020545
[00:58:24.061] iteration 24162 : model1 loss : 0.437267 model2 loss : 0.017976
[00:58:24.229] iteration 24163 : model1 loss : 0.441136 model2 loss : 0.017666
[00:58:24.397] iteration 24164 : model1 loss : 0.440367 model2 loss : 0.016810
[00:58:24.566] iteration 24165 : model1 loss : 0.435201 model2 loss : 0.016870
[00:58:24.733] iteration 24166 : model1 loss : 0.436143 model2 loss : 0.016146
[00:58:24.901] iteration 24167 : model1 loss : 0.438600 model2 loss : 0.017518
[00:58:25.071] iteration 24168 : model1 loss : 0.443855 model2 loss : 0.018218
[00:58:25.241] iteration 24169 : model1 loss : 0.438893 model2 loss : 0.016751
[00:58:25.409] iteration 24170 : model1 loss : 0.437919 model2 loss : 0.019145
[00:58:25.576] iteration 24171 : model1 loss : 0.437408 model2 loss : 0.017186
[00:58:27.557] iteration 24172 : model1 loss : 0.440378 model2 loss : 0.018053
[00:58:27.731] iteration 24173 : model1 loss : 0.439051 model2 loss : 0.017051
[00:58:27.899] iteration 24174 : model1 loss : 0.441863 model2 loss : 0.020065
[00:58:28.069] iteration 24175 : model1 loss : 0.436749 model2 loss : 0.016531
[00:58:28.237] iteration 24176 : model1 loss : 0.440582 model2 loss : 0.016711
[00:58:28.406] iteration 24177 : model1 loss : 0.436951 model2 loss : 0.018426
[00:58:28.574] iteration 24178 : model1 loss : 0.432799 model2 loss : 0.016661
[00:58:28.742] iteration 24179 : model1 loss : 0.438836 model2 loss : 0.016843
[00:58:28.911] iteration 24180 : model1 loss : 0.439452 model2 loss : 0.018255
[00:58:29.080] iteration 24181 : model1 loss : 0.438293 model2 loss : 0.017290
[00:58:29.250] iteration 24182 : model1 loss : 0.445175 model2 loss : 0.021384
[00:58:29.417] iteration 24183 : model1 loss : 0.437610 model2 loss : 0.018991
[00:58:29.588] iteration 24184 : model1 loss : 0.442077 model2 loss : 0.019472
[00:58:29.756] iteration 24185 : model1 loss : 0.442361 model2 loss : 0.017860
[00:58:29.925] iteration 24186 : model1 loss : 0.440376 model2 loss : 0.017153
[00:58:30.092] iteration 24187 : model1 loss : 0.436919 model2 loss : 0.017482
[00:58:30.261] iteration 24188 : model1 loss : 0.438034 model2 loss : 0.016570
[00:58:30.427] iteration 24189 : model1 loss : 0.440556 model2 loss : 0.018789
[00:58:30.596] iteration 24190 : model1 loss : 0.441028 model2 loss : 0.017241
[00:58:30.761] iteration 24191 : model1 loss : 0.444077 model2 loss : 0.019856
[00:58:30.929] iteration 24192 : model1 loss : 0.440426 model2 loss : 0.016686
[00:58:32.923] iteration 24193 : model1 loss : 0.436736 model2 loss : 0.017959
[00:58:33.096] iteration 24194 : model1 loss : 0.439172 model2 loss : 0.017976
[00:58:33.266] iteration 24195 : model1 loss : 0.436622 model2 loss : 0.017086
[00:58:33.435] iteration 24196 : model1 loss : 0.442076 model2 loss : 0.019658
[00:58:33.603] iteration 24197 : model1 loss : 0.436539 model2 loss : 0.016498
[00:58:33.771] iteration 24198 : model1 loss : 0.441941 model2 loss : 0.017749
[00:58:33.945] iteration 24199 : model1 loss : 0.440124 model2 loss : 0.017060
[00:58:34.114] iteration 24200 : model1 loss : 0.439909 model2 loss : 0.015804
[00:58:34.283] iteration 24201 : model1 loss : 0.440597 model2 loss : 0.016988
[00:58:34.449] iteration 24202 : model1 loss : 0.439526 model2 loss : 0.017437
[00:58:34.618] iteration 24203 : model1 loss : 0.440149 model2 loss : 0.018643
[00:58:34.786] iteration 24204 : model1 loss : 0.440172 model2 loss : 0.019382
[00:58:34.954] iteration 24205 : model1 loss : 0.442203 model2 loss : 0.018986
[00:58:35.127] iteration 24206 : model1 loss : 0.439523 model2 loss : 0.016940
[00:58:35.300] iteration 24207 : model1 loss : 0.438453 model2 loss : 0.016701
[00:58:35.467] iteration 24208 : model1 loss : 0.441952 model2 loss : 0.018001
[00:58:35.635] iteration 24209 : model1 loss : 0.443049 model2 loss : 0.018974
[00:58:35.803] iteration 24210 : model1 loss : 0.439117 model2 loss : 0.016950
[00:58:35.974] iteration 24211 : model1 loss : 0.436067 model2 loss : 0.016869
[00:58:36.142] iteration 24212 : model1 loss : 0.439816 model2 loss : 0.017702
[00:58:36.313] iteration 24213 : model1 loss : 0.436786 model2 loss : 0.015949
[00:58:38.292] iteration 24214 : model1 loss : 0.444918 model2 loss : 0.020288
[00:58:38.460] iteration 24215 : model1 loss : 0.441472 model2 loss : 0.016838
[00:58:38.629] iteration 24216 : model1 loss : 0.444552 model2 loss : 0.017392
[00:58:38.796] iteration 24217 : model1 loss : 0.438702 model2 loss : 0.015747
[00:58:38.966] iteration 24218 : model1 loss : 0.440077 model2 loss : 0.016416
[00:58:39.135] iteration 24219 : model1 loss : 0.438456 model2 loss : 0.016871
[00:58:39.304] iteration 24220 : model1 loss : 0.435679 model2 loss : 0.018381
[00:58:39.473] iteration 24221 : model1 loss : 0.439452 model2 loss : 0.016865
[00:58:39.641] iteration 24222 : model1 loss : 0.442583 model2 loss : 0.015904
[00:58:39.809] iteration 24223 : model1 loss : 0.436462 model2 loss : 0.016980
[00:58:39.979] iteration 24224 : model1 loss : 0.438858 model2 loss : 0.015640
[00:58:40.152] iteration 24225 : model1 loss : 0.436769 model2 loss : 0.017478
[00:58:40.323] iteration 24226 : model1 loss : 0.441100 model2 loss : 0.016061
[00:58:40.490] iteration 24227 : model1 loss : 0.438649 model2 loss : 0.016663
[00:58:40.661] iteration 24228 : model1 loss : 0.440419 model2 loss : 0.017117
[00:58:40.828] iteration 24229 : model1 loss : 0.438453 model2 loss : 0.017693
[00:58:40.998] iteration 24230 : model1 loss : 0.440321 model2 loss : 0.016622
[00:58:41.166] iteration 24231 : model1 loss : 0.437036 model2 loss : 0.017300
[00:58:41.336] iteration 24232 : model1 loss : 0.442066 model2 loss : 0.020151
[00:58:41.504] iteration 24233 : model1 loss : 0.440117 model2 loss : 0.019645
[00:58:41.671] iteration 24234 : model1 loss : 0.437585 model2 loss : 0.019906
[00:58:43.627] iteration 24235 : model1 loss : 0.441898 model2 loss : 0.018878
[00:58:43.794] iteration 24236 : model1 loss : 0.437223 model2 loss : 0.017832
[00:58:43.966] iteration 24237 : model1 loss : 0.438835 model2 loss : 0.016708
[00:58:44.141] iteration 24238 : model1 loss : 0.445333 model2 loss : 0.019361
[00:58:44.319] iteration 24239 : model1 loss : 0.441624 model2 loss : 0.019870
[00:58:44.487] iteration 24240 : model1 loss : 0.444950 model2 loss : 0.016458
[00:58:44.658] iteration 24241 : model1 loss : 0.441206 model2 loss : 0.016013
[00:58:44.825] iteration 24242 : model1 loss : 0.440984 model2 loss : 0.019557
[00:58:44.994] iteration 24243 : model1 loss : 0.435193 model2 loss : 0.017553
[00:58:45.167] iteration 24244 : model1 loss : 0.439741 model2 loss : 0.017405
[00:58:45.339] iteration 24245 : model1 loss : 0.438641 model2 loss : 0.017147
[00:58:45.508] iteration 24246 : model1 loss : 0.437789 model2 loss : 0.017066
[00:58:45.677] iteration 24247 : model1 loss : 0.440621 model2 loss : 0.017523
[00:58:45.844] iteration 24248 : model1 loss : 0.438103 model2 loss : 0.017176
[00:58:46.013] iteration 24249 : model1 loss : 0.439855 model2 loss : 0.018930
[00:58:46.184] iteration 24250 : model1 loss : 0.437222 model2 loss : 0.017166
[00:58:46.354] iteration 24251 : model1 loss : 0.444617 model2 loss : 0.019727
[00:58:46.521] iteration 24252 : model1 loss : 0.437496 model2 loss : 0.015188
[00:58:46.690] iteration 24253 : model1 loss : 0.436346 model2 loss : 0.017402
[00:58:46.865] iteration 24254 : model1 loss : 0.436305 model2 loss : 0.017926
[00:58:47.033] iteration 24255 : model1 loss : 0.439898 model2 loss : 0.017154
[00:58:48.996] iteration 24256 : model1 loss : 0.440864 model2 loss : 0.015814
[00:58:49.164] iteration 24257 : model1 loss : 0.435119 model2 loss : 0.018582
[00:58:49.335] iteration 24258 : model1 loss : 0.440599 model2 loss : 0.019792
[00:58:49.504] iteration 24259 : model1 loss : 0.440021 model2 loss : 0.016551
[00:58:49.673] iteration 24260 : model1 loss : 0.440996 model2 loss : 0.014963
[00:58:49.842] iteration 24261 : model1 loss : 0.439297 model2 loss : 0.016961
[00:58:50.012] iteration 24262 : model1 loss : 0.444791 model2 loss : 0.019935
[00:58:50.179] iteration 24263 : model1 loss : 0.443164 model2 loss : 0.019765
[00:58:50.348] iteration 24264 : model1 loss : 0.441511 model2 loss : 0.017405
[00:58:50.516] iteration 24265 : model1 loss : 0.446568 model2 loss : 0.018886
[00:58:50.686] iteration 24266 : model1 loss : 0.439543 model2 loss : 0.015290
[00:58:50.854] iteration 24267 : model1 loss : 0.434256 model2 loss : 0.015867
[00:58:51.025] iteration 24268 : model1 loss : 0.440351 model2 loss : 0.017710
[00:58:51.194] iteration 24269 : model1 loss : 0.437865 model2 loss : 0.018014
[00:58:51.362] iteration 24270 : model1 loss : 0.438715 model2 loss : 0.017744
[00:58:51.530] iteration 24271 : model1 loss : 0.442710 model2 loss : 0.020026
[00:58:51.698] iteration 24272 : model1 loss : 0.439006 model2 loss : 0.018511
[00:58:51.867] iteration 24273 : model1 loss : 0.436978 model2 loss : 0.019644
[00:58:52.036] iteration 24274 : model1 loss : 0.435424 model2 loss : 0.016462
[00:58:52.203] iteration 24275 : model1 loss : 0.438934 model2 loss : 0.016524
[00:58:52.372] iteration 24276 : model1 loss : 0.438819 model2 loss : 0.016371
[00:58:54.297] iteration 24277 : model1 loss : 0.439296 model2 loss : 0.016298
[00:58:54.465] iteration 24278 : model1 loss : 0.439473 model2 loss : 0.016590
[00:58:54.638] iteration 24279 : model1 loss : 0.440782 model2 loss : 0.016750
[00:58:54.806] iteration 24280 : model1 loss : 0.436465 model2 loss : 0.015819
[00:58:54.976] iteration 24281 : model1 loss : 0.436980 model2 loss : 0.015080
[00:58:55.146] iteration 24282 : model1 loss : 0.439789 model2 loss : 0.018183
[00:58:55.317] iteration 24283 : model1 loss : 0.439917 model2 loss : 0.017386
[00:58:55.485] iteration 24284 : model1 loss : 0.437063 model2 loss : 0.016856
[00:58:55.655] iteration 24285 : model1 loss : 0.441235 model2 loss : 0.016548
[00:58:55.823] iteration 24286 : model1 loss : 0.435979 model2 loss : 0.017636
[00:58:55.991] iteration 24287 : model1 loss : 0.441889 model2 loss : 0.016605
[00:58:56.161] iteration 24288 : model1 loss : 0.437578 model2 loss : 0.018850
[00:58:56.331] iteration 24289 : model1 loss : 0.443938 model2 loss : 0.017074
[00:58:56.499] iteration 24290 : model1 loss : 0.436591 model2 loss : 0.017433
[00:58:56.669] iteration 24291 : model1 loss : 0.439464 model2 loss : 0.018392
[00:58:56.838] iteration 24292 : model1 loss : 0.441398 model2 loss : 0.017706
[00:58:57.008] iteration 24293 : model1 loss : 0.444585 model2 loss : 0.018650
[00:58:57.177] iteration 24294 : model1 loss : 0.438728 model2 loss : 0.017486
[00:58:57.347] iteration 24295 : model1 loss : 0.436952 model2 loss : 0.017648
[00:58:57.513] iteration 24296 : model1 loss : 0.442431 model2 loss : 0.017081
[00:58:57.680] iteration 24297 : model1 loss : 0.439693 model2 loss : 0.018391
[00:58:59.640] iteration 24298 : model1 loss : 0.442948 model2 loss : 0.017124
[00:58:59.810] iteration 24299 : model1 loss : 0.439584 model2 loss : 0.016413
[00:58:59.981] iteration 24300 : model1 loss : 0.438637 model2 loss : 0.016053
[00:59:00.153] iteration 24301 : model1 loss : 0.440396 model2 loss : 0.018606
[00:59:00.323] iteration 24302 : model1 loss : 0.436029 model2 loss : 0.016230
[00:59:00.492] iteration 24303 : model1 loss : 0.436441 model2 loss : 0.017238
[00:59:00.661] iteration 24304 : model1 loss : 0.436995 model2 loss : 0.015762
[00:59:00.833] iteration 24305 : model1 loss : 0.439608 model2 loss : 0.017797
[00:59:01.002] iteration 24306 : model1 loss : 0.438782 model2 loss : 0.016528
[00:59:01.169] iteration 24307 : model1 loss : 0.441799 model2 loss : 0.017290
[00:59:01.341] iteration 24308 : model1 loss : 0.443080 model2 loss : 0.018903
[00:59:01.509] iteration 24309 : model1 loss : 0.436466 model2 loss : 0.017739
[00:59:01.679] iteration 24310 : model1 loss : 0.439812 model2 loss : 0.016197
[00:59:01.847] iteration 24311 : model1 loss : 0.438711 model2 loss : 0.016697
[00:59:02.017] iteration 24312 : model1 loss : 0.435457 model2 loss : 0.016700
[00:59:02.186] iteration 24313 : model1 loss : 0.440724 model2 loss : 0.016072
[00:59:02.354] iteration 24314 : model1 loss : 0.440744 model2 loss : 0.015717
[00:59:02.523] iteration 24315 : model1 loss : 0.443651 model2 loss : 0.020101
[00:59:02.691] iteration 24316 : model1 loss : 0.439554 model2 loss : 0.018389
[00:59:02.860] iteration 24317 : model1 loss : 0.441848 model2 loss : 0.018766
[00:59:03.027] iteration 24318 : model1 loss : 0.439629 model2 loss : 0.016940
[00:59:04.998] iteration 24319 : model1 loss : 0.437010 model2 loss : 0.016670
[00:59:05.169] iteration 24320 : model1 loss : 0.438755 model2 loss : 0.016954
[00:59:05.340] iteration 24321 : model1 loss : 0.440306 model2 loss : 0.017826
[00:59:05.508] iteration 24322 : model1 loss : 0.440034 model2 loss : 0.020262
[00:59:05.677] iteration 24323 : model1 loss : 0.442133 model2 loss : 0.018476
[00:59:05.844] iteration 24324 : model1 loss : 0.433694 model2 loss : 0.016986
[00:59:06.014] iteration 24325 : model1 loss : 0.445269 model2 loss : 0.018840
[00:59:06.182] iteration 24326 : model1 loss : 0.438868 model2 loss : 0.018908
[00:59:06.351] iteration 24327 : model1 loss : 0.442019 model2 loss : 0.017039
[00:59:06.519] iteration 24328 : model1 loss : 0.437504 model2 loss : 0.014792
[00:59:06.687] iteration 24329 : model1 loss : 0.441151 model2 loss : 0.017652
[00:59:06.856] iteration 24330 : model1 loss : 0.440304 model2 loss : 0.017926
[00:59:07.023] iteration 24331 : model1 loss : 0.435934 model2 loss : 0.016309
[00:59:07.192] iteration 24332 : model1 loss : 0.442189 model2 loss : 0.017126
[00:59:07.360] iteration 24333 : model1 loss : 0.437930 model2 loss : 0.016007
[00:59:07.530] iteration 24334 : model1 loss : 0.439052 model2 loss : 0.016406
[00:59:07.699] iteration 24335 : model1 loss : 0.437371 model2 loss : 0.017114
[00:59:07.867] iteration 24336 : model1 loss : 0.442683 model2 loss : 0.017535
[00:59:08.036] iteration 24337 : model1 loss : 0.439938 model2 loss : 0.018565
[00:59:08.203] iteration 24338 : model1 loss : 0.439119 model2 loss : 0.016855
[00:59:08.371] iteration 24339 : model1 loss : 0.440280 model2 loss : 0.017621
[00:59:10.302] iteration 24340 : model1 loss : 0.441102 model2 loss : 0.015967
[00:59:10.487] iteration 24341 : model1 loss : 0.437879 model2 loss : 0.017804
[00:59:10.656] iteration 24342 : model1 loss : 0.438186 model2 loss : 0.017367
[00:59:10.824] iteration 24343 : model1 loss : 0.437240 model2 loss : 0.019044
[00:59:10.995] iteration 24344 : model1 loss : 0.434576 model2 loss : 0.015203
[00:59:11.164] iteration 24345 : model1 loss : 0.437770 model2 loss : 0.017594
[00:59:11.336] iteration 24346 : model1 loss : 0.438496 model2 loss : 0.017603
[00:59:11.504] iteration 24347 : model1 loss : 0.437932 model2 loss : 0.016848
[00:59:11.672] iteration 24348 : model1 loss : 0.439863 model2 loss : 0.016268
[00:59:11.841] iteration 24349 : model1 loss : 0.439399 model2 loss : 0.016078
[00:59:12.012] iteration 24350 : model1 loss : 0.439001 model2 loss : 0.017674
[00:59:12.180] iteration 24351 : model1 loss : 0.439230 model2 loss : 0.018629
[00:59:12.349] iteration 24352 : model1 loss : 0.441738 model2 loss : 0.019105
[00:59:12.517] iteration 24353 : model1 loss : 0.444132 model2 loss : 0.020288
[00:59:12.685] iteration 24354 : model1 loss : 0.442208 model2 loss : 0.017839
[00:59:12.852] iteration 24355 : model1 loss : 0.439448 model2 loss : 0.014961
[00:59:13.021] iteration 24356 : model1 loss : 0.438237 model2 loss : 0.016397
[00:59:13.190] iteration 24357 : model1 loss : 0.442614 model2 loss : 0.016129
[00:59:13.359] iteration 24358 : model1 loss : 0.440517 model2 loss : 0.018045
[00:59:13.526] iteration 24359 : model1 loss : 0.441641 model2 loss : 0.016319
[00:59:13.694] iteration 24360 : model1 loss : 0.440670 model2 loss : 0.018371
[00:59:15.663] iteration 24361 : model1 loss : 0.441136 model2 loss : 0.017889
[00:59:15.830] iteration 24362 : model1 loss : 0.442691 model2 loss : 0.020651
[00:59:16.004] iteration 24363 : model1 loss : 0.441183 model2 loss : 0.016693
[00:59:16.170] iteration 24364 : model1 loss : 0.442349 model2 loss : 0.019693
[00:59:16.339] iteration 24365 : model1 loss : 0.442506 model2 loss : 0.018802
[00:59:16.508] iteration 24366 : model1 loss : 0.438016 model2 loss : 0.017423
[00:59:16.678] iteration 24367 : model1 loss : 0.437908 model2 loss : 0.015907
[00:59:16.846] iteration 24368 : model1 loss : 0.436409 model2 loss : 0.017913
[00:59:17.015] iteration 24369 : model1 loss : 0.439959 model2 loss : 0.016142
[00:59:17.184] iteration 24370 : model1 loss : 0.441160 model2 loss : 0.018390
[00:59:17.354] iteration 24371 : model1 loss : 0.442948 model2 loss : 0.018269
[00:59:17.520] iteration 24372 : model1 loss : 0.438246 model2 loss : 0.014015
[00:59:17.688] iteration 24373 : model1 loss : 0.439233 model2 loss : 0.017879
[00:59:17.856] iteration 24374 : model1 loss : 0.437955 model2 loss : 0.019031
[00:59:18.025] iteration 24375 : model1 loss : 0.435664 model2 loss : 0.015999
[00:59:18.193] iteration 24376 : model1 loss : 0.440740 model2 loss : 0.018966
[00:59:18.364] iteration 24377 : model1 loss : 0.435663 model2 loss : 0.017819
[00:59:18.532] iteration 24378 : model1 loss : 0.435749 model2 loss : 0.016059
[00:59:18.702] iteration 24379 : model1 loss : 0.441713 model2 loss : 0.016375
[00:59:18.869] iteration 24380 : model1 loss : 0.441893 model2 loss : 0.017473
[00:59:19.039] iteration 24381 : model1 loss : 0.443625 model2 loss : 0.016900
[00:59:20.977] iteration 24382 : model1 loss : 0.438520 model2 loss : 0.016815
[00:59:21.147] iteration 24383 : model1 loss : 0.441380 model2 loss : 0.016867
[00:59:21.321] iteration 24384 : model1 loss : 0.437953 model2 loss : 0.017642
[00:59:21.489] iteration 24385 : model1 loss : 0.439517 model2 loss : 0.020605
[00:59:21.659] iteration 24386 : model1 loss : 0.441620 model2 loss : 0.018085
[00:59:21.827] iteration 24387 : model1 loss : 0.435145 model2 loss : 0.017227
[00:59:21.998] iteration 24388 : model1 loss : 0.435387 model2 loss : 0.016928
[00:59:22.166] iteration 24389 : model1 loss : 0.438252 model2 loss : 0.017633
[00:59:22.336] iteration 24390 : model1 loss : 0.444095 model2 loss : 0.021931
[00:59:22.505] iteration 24391 : model1 loss : 0.439483 model2 loss : 0.017938
[00:59:22.676] iteration 24392 : model1 loss : 0.434701 model2 loss : 0.017954
[00:59:22.843] iteration 24393 : model1 loss : 0.437062 model2 loss : 0.016903
[00:59:23.013] iteration 24394 : model1 loss : 0.440092 model2 loss : 0.014102
[00:59:23.182] iteration 24395 : model1 loss : 0.440736 model2 loss : 0.016911
[00:59:23.349] iteration 24396 : model1 loss : 0.440244 model2 loss : 0.016084
[00:59:23.516] iteration 24397 : model1 loss : 0.439656 model2 loss : 0.016633
[00:59:23.684] iteration 24398 : model1 loss : 0.441111 model2 loss : 0.018510
[00:59:23.853] iteration 24399 : model1 loss : 0.439161 model2 loss : 0.016989
[00:59:24.022] iteration 24400 : model1 loss : 0.444316 model2 loss : 0.019136
[00:59:24.189] iteration 24401 : model1 loss : 0.444494 model2 loss : 0.023476
[00:59:24.357] iteration 24402 : model1 loss : 0.442076 model2 loss : 0.017601
[00:59:26.328] iteration 24403 : model1 loss : 0.441845 model2 loss : 0.016959
[00:59:26.500] iteration 24404 : model1 loss : 0.437414 model2 loss : 0.016240
[00:59:26.669] iteration 24405 : model1 loss : 0.440121 model2 loss : 0.017544
[00:59:26.838] iteration 24406 : model1 loss : 0.438238 model2 loss : 0.017641
[00:59:27.005] iteration 24407 : model1 loss : 0.437466 model2 loss : 0.016866
[00:59:27.175] iteration 24408 : model1 loss : 0.439461 model2 loss : 0.016445
[00:59:27.346] iteration 24409 : model1 loss : 0.439442 model2 loss : 0.020222
[00:59:27.515] iteration 24410 : model1 loss : 0.438907 model2 loss : 0.018387
[00:59:27.686] iteration 24411 : model1 loss : 0.443382 model2 loss : 0.016454
[00:59:27.854] iteration 24412 : model1 loss : 0.440786 model2 loss : 0.019728
[00:59:28.024] iteration 24413 : model1 loss : 0.440771 model2 loss : 0.020357
[00:59:28.192] iteration 24414 : model1 loss : 0.440344 model2 loss : 0.018450
[00:59:28.359] iteration 24415 : model1 loss : 0.443175 model2 loss : 0.018703
[00:59:28.528] iteration 24416 : model1 loss : 0.436734 model2 loss : 0.017427
[00:59:28.696] iteration 24417 : model1 loss : 0.434428 model2 loss : 0.018225
[00:59:28.865] iteration 24418 : model1 loss : 0.448275 model2 loss : 0.021660
[00:59:29.037] iteration 24419 : model1 loss : 0.436146 model2 loss : 0.016913
[00:59:29.205] iteration 24420 : model1 loss : 0.439593 model2 loss : 0.016180
[00:59:29.375] iteration 24421 : model1 loss : 0.444054 model2 loss : 0.018466
[00:59:29.541] iteration 24422 : model1 loss : 0.440309 model2 loss : 0.017471
[00:59:29.710] iteration 24423 : model1 loss : 0.435016 model2 loss : 0.017098
[00:59:31.696] iteration 24424 : model1 loss : 0.438240 model2 loss : 0.017387
[00:59:31.867] iteration 24425 : model1 loss : 0.436455 model2 loss : 0.017801
[00:59:32.037] iteration 24426 : model1 loss : 0.442304 model2 loss : 0.017700
[00:59:32.206] iteration 24427 : model1 loss : 0.440561 model2 loss : 0.017925
[00:59:32.375] iteration 24428 : model1 loss : 0.440284 model2 loss : 0.017734
[00:59:32.543] iteration 24429 : model1 loss : 0.444419 model2 loss : 0.021870
[00:59:32.710] iteration 24430 : model1 loss : 0.433603 model2 loss : 0.018448
[00:59:32.879] iteration 24431 : model1 loss : 0.439291 model2 loss : 0.018895
[00:59:33.050] iteration 24432 : model1 loss : 0.434866 model2 loss : 0.017719
[00:59:33.217] iteration 24433 : model1 loss : 0.436805 model2 loss : 0.017606
[00:59:33.387] iteration 24434 : model1 loss : 0.441511 model2 loss : 0.019068
[00:59:33.554] iteration 24435 : model1 loss : 0.437329 model2 loss : 0.017293
[00:59:33.724] iteration 24436 : model1 loss : 0.440459 model2 loss : 0.016979
[00:59:33.892] iteration 24437 : model1 loss : 0.442494 model2 loss : 0.017951
[00:59:34.060] iteration 24438 : model1 loss : 0.445756 model2 loss : 0.018752
[00:59:34.229] iteration 24439 : model1 loss : 0.439476 model2 loss : 0.017181
[00:59:34.399] iteration 24440 : model1 loss : 0.438865 model2 loss : 0.017737
[00:59:34.568] iteration 24441 : model1 loss : 0.443138 model2 loss : 0.018240
[00:59:34.738] iteration 24442 : model1 loss : 0.442437 model2 loss : 0.017000
[00:59:34.905] iteration 24443 : model1 loss : 0.436533 model2 loss : 0.018597
[00:59:35.073] iteration 24444 : model1 loss : 0.436457 model2 loss : 0.017638
[00:59:37.024] iteration 24445 : model1 loss : 0.441121 model2 loss : 0.016311
[00:59:37.196] iteration 24446 : model1 loss : 0.438274 model2 loss : 0.016032
[00:59:37.366] iteration 24447 : model1 loss : 0.439206 model2 loss : 0.020481
[00:59:37.533] iteration 24448 : model1 loss : 0.438342 model2 loss : 0.018581
[00:59:37.702] iteration 24449 : model1 loss : 0.441432 model2 loss : 0.018283
[00:59:37.871] iteration 24450 : model1 loss : 0.440909 model2 loss : 0.019626
[00:59:38.040] iteration 24451 : model1 loss : 0.442271 model2 loss : 0.018054
[00:59:38.210] iteration 24452 : model1 loss : 0.441874 model2 loss : 0.018024
[00:59:38.378] iteration 24453 : model1 loss : 0.439920 model2 loss : 0.016596
[00:59:38.546] iteration 24454 : model1 loss : 0.442354 model2 loss : 0.018382
[00:59:38.716] iteration 24455 : model1 loss : 0.435767 model2 loss : 0.016517
[00:59:38.884] iteration 24456 : model1 loss : 0.442762 model2 loss : 0.020959
[00:59:39.055] iteration 24457 : model1 loss : 0.444938 model2 loss : 0.019899
[00:59:39.222] iteration 24458 : model1 loss : 0.440128 model2 loss : 0.017801
[00:59:39.393] iteration 24459 : model1 loss : 0.435571 model2 loss : 0.017468
[00:59:39.562] iteration 24460 : model1 loss : 0.438903 model2 loss : 0.017084
[00:59:39.731] iteration 24461 : model1 loss : 0.435904 model2 loss : 0.016752
[00:59:39.900] iteration 24462 : model1 loss : 0.439028 model2 loss : 0.018187
[00:59:40.070] iteration 24463 : model1 loss : 0.441391 model2 loss : 0.017047
[00:59:40.238] iteration 24464 : model1 loss : 0.435676 model2 loss : 0.017659
[00:59:40.407] iteration 24465 : model1 loss : 0.439524 model2 loss : 0.017866
[00:59:42.361] iteration 24466 : model1 loss : 0.439397 model2 loss : 0.016337
[00:59:42.536] iteration 24467 : model1 loss : 0.442652 model2 loss : 0.016216
[00:59:42.708] iteration 24468 : model1 loss : 0.436558 model2 loss : 0.016243
[00:59:42.875] iteration 24469 : model1 loss : 0.441003 model2 loss : 0.017243
[00:59:43.045] iteration 24470 : model1 loss : 0.442572 model2 loss : 0.018637
[00:59:43.213] iteration 24471 : model1 loss : 0.439789 model2 loss : 0.018734
[00:59:43.384] iteration 24472 : model1 loss : 0.437175 model2 loss : 0.017619
[00:59:43.552] iteration 24473 : model1 loss : 0.439224 model2 loss : 0.017776
[00:59:43.721] iteration 24474 : model1 loss : 0.439469 model2 loss : 0.017656
[00:59:43.890] iteration 24475 : model1 loss : 0.437856 model2 loss : 0.016407
[00:59:44.059] iteration 24476 : model1 loss : 0.436381 model2 loss : 0.017426
[00:59:44.227] iteration 24477 : model1 loss : 0.446832 model2 loss : 0.019614
[00:59:44.396] iteration 24478 : model1 loss : 0.440584 model2 loss : 0.015786
[00:59:44.564] iteration 24479 : model1 loss : 0.437600 model2 loss : 0.018230
[00:59:44.733] iteration 24480 : model1 loss : 0.438066 model2 loss : 0.019488
[00:59:44.899] iteration 24481 : model1 loss : 0.444569 model2 loss : 0.020370
[00:59:45.070] iteration 24482 : model1 loss : 0.440023 model2 loss : 0.018599
[00:59:45.238] iteration 24483 : model1 loss : 0.435559 model2 loss : 0.015810
[00:59:45.408] iteration 24484 : model1 loss : 0.439679 model2 loss : 0.018441
[00:59:45.574] iteration 24485 : model1 loss : 0.438684 model2 loss : 0.017351
[00:59:45.741] iteration 24486 : model1 loss : 0.443954 model2 loss : 0.019351
[00:59:47.686] iteration 24487 : model1 loss : 0.437549 model2 loss : 0.017644
[00:59:47.854] iteration 24488 : model1 loss : 0.440399 model2 loss : 0.017961
[00:59:48.024] iteration 24489 : model1 loss : 0.442633 model2 loss : 0.020252
[00:59:48.193] iteration 24490 : model1 loss : 0.435226 model2 loss : 0.016039
[00:59:48.362] iteration 24491 : model1 loss : 0.441828 model2 loss : 0.018583
[00:59:48.530] iteration 24492 : model1 loss : 0.436510 model2 loss : 0.017748
[00:59:48.720] iteration 24493 : model1 loss : 0.441765 model2 loss : 0.017405
[00:59:48.895] iteration 24494 : model1 loss : 0.446720 model2 loss : 0.018174
[00:59:49.065] iteration 24495 : model1 loss : 0.438088 model2 loss : 0.019551
[00:59:49.233] iteration 24496 : model1 loss : 0.435444 model2 loss : 0.018146
[00:59:49.403] iteration 24497 : model1 loss : 0.438937 model2 loss : 0.018043
[00:59:49.570] iteration 24498 : model1 loss : 0.439402 model2 loss : 0.017255
[00:59:49.740] iteration 24499 : model1 loss : 0.439486 model2 loss : 0.019364
[00:59:49.913] iteration 24500 : model1 loss : 0.438914 model2 loss : 0.019577
[00:59:50.104] iteration 24501 : model1 loss : 0.438231 model2 loss : 0.016189
[00:59:50.293] iteration 24502 : model1 loss : 0.443129 model2 loss : 0.017672
[00:59:50.496] iteration 24503 : model1 loss : 0.441855 model2 loss : 0.018391
[00:59:50.676] iteration 24504 : model1 loss : 0.439300 model2 loss : 0.018337
[00:59:50.847] iteration 24505 : model1 loss : 0.438116 model2 loss : 0.017470
[00:59:51.015] iteration 24506 : model1 loss : 0.439100 model2 loss : 0.017655
[00:59:51.205] iteration 24507 : model1 loss : 0.442938 model2 loss : 0.017242
[00:59:53.245] iteration 24508 : model1 loss : 0.436057 model2 loss : 0.017440
[00:59:53.413] iteration 24509 : model1 loss : 0.435495 model2 loss : 0.017136
[00:59:53.586] iteration 24510 : model1 loss : 0.445208 model2 loss : 0.018749
[00:59:53.754] iteration 24511 : model1 loss : 0.435083 model2 loss : 0.016969
[00:59:53.924] iteration 24512 : model1 loss : 0.440488 model2 loss : 0.016409
[00:59:54.093] iteration 24513 : model1 loss : 0.437327 model2 loss : 0.015482
[00:59:54.264] iteration 24514 : model1 loss : 0.441016 model2 loss : 0.016752
[00:59:54.433] iteration 24515 : model1 loss : 0.441070 model2 loss : 0.016892
[00:59:54.602] iteration 24516 : model1 loss : 0.439627 model2 loss : 0.018130
[00:59:54.771] iteration 24517 : model1 loss : 0.440400 model2 loss : 0.018338
[00:59:54.951] iteration 24518 : model1 loss : 0.442738 model2 loss : 0.017895
[00:59:55.133] iteration 24519 : model1 loss : 0.438506 model2 loss : 0.016578
[00:59:55.317] iteration 24520 : model1 loss : 0.435829 model2 loss : 0.016771
[00:59:55.498] iteration 24521 : model1 loss : 0.439576 model2 loss : 0.015487
[00:59:55.672] iteration 24522 : model1 loss : 0.433772 model2 loss : 0.015742
[00:59:55.841] iteration 24523 : model1 loss : 0.443197 model2 loss : 0.016415
[00:59:56.046] iteration 24524 : model1 loss : 0.438948 model2 loss : 0.016148
[00:59:56.214] iteration 24525 : model1 loss : 0.442091 model2 loss : 0.018874
[00:59:56.418] iteration 24526 : model1 loss : 0.444027 model2 loss : 0.016448
[00:59:56.599] iteration 24527 : model1 loss : 0.440939 model2 loss : 0.019039
[00:59:56.790] iteration 24528 : model1 loss : 0.442259 model2 loss : 0.017833
[00:59:58.843] iteration 24529 : model1 loss : 0.438647 model2 loss : 0.016613
[00:59:59.021] iteration 24530 : model1 loss : 0.440384 model2 loss : 0.018665
[00:59:59.198] iteration 24531 : model1 loss : 0.435529 model2 loss : 0.016702
[00:59:59.370] iteration 24532 : model1 loss : 0.442063 model2 loss : 0.015281
[00:59:59.538] iteration 24533 : model1 loss : 0.437492 model2 loss : 0.015757
[00:59:59.706] iteration 24534 : model1 loss : 0.439960 model2 loss : 0.016847
[00:59:59.877] iteration 24535 : model1 loss : 0.439404 model2 loss : 0.016376
[01:00:00.045] iteration 24536 : model1 loss : 0.444503 model2 loss : 0.019053
[01:00:00.214] iteration 24537 : model1 loss : 0.442960 model2 loss : 0.018765
[01:00:00.381] iteration 24538 : model1 loss : 0.439672 model2 loss : 0.016909
[01:00:00.558] iteration 24539 : model1 loss : 0.441154 model2 loss : 0.016891
[01:00:00.731] iteration 24540 : model1 loss : 0.443403 model2 loss : 0.017971
[01:00:00.968] iteration 24541 : model1 loss : 0.437648 model2 loss : 0.015118
[01:00:01.152] iteration 24542 : model1 loss : 0.438529 model2 loss : 0.016549
[01:00:01.322] iteration 24543 : model1 loss : 0.441096 model2 loss : 0.018033
[01:00:01.504] iteration 24544 : model1 loss : 0.438862 model2 loss : 0.017644
[01:00:01.685] iteration 24545 : model1 loss : 0.438497 model2 loss : 0.017403
[01:00:01.863] iteration 24546 : model1 loss : 0.434624 model2 loss : 0.017420
[01:00:02.065] iteration 24547 : model1 loss : 0.441473 model2 loss : 0.017278
[01:00:02.239] iteration 24548 : model1 loss : 0.437219 model2 loss : 0.016952
[01:00:02.422] iteration 24549 : model1 loss : 0.441914 model2 loss : 0.018693
[01:00:04.441] iteration 24550 : model1 loss : 0.442114 model2 loss : 0.017670
[01:00:04.615] iteration 24551 : model1 loss : 0.436108 model2 loss : 0.015872
[01:00:04.792] iteration 24552 : model1 loss : 0.440930 model2 loss : 0.017994
[01:00:04.958] iteration 24553 : model1 loss : 0.436246 model2 loss : 0.016358
[01:00:05.133] iteration 24554 : model1 loss : 0.438374 model2 loss : 0.016494
[01:00:05.311] iteration 24555 : model1 loss : 0.438691 model2 loss : 0.018094
[01:00:05.482] iteration 24556 : model1 loss : 0.440770 model2 loss : 0.017724
[01:00:05.650] iteration 24557 : model1 loss : 0.438942 model2 loss : 0.016713
[01:00:05.819] iteration 24558 : model1 loss : 0.440506 model2 loss : 0.018828
[01:00:05.985] iteration 24559 : model1 loss : 0.439452 model2 loss : 0.015299
[01:00:06.158] iteration 24560 : model1 loss : 0.445102 model2 loss : 0.021143
[01:00:06.337] iteration 24561 : model1 loss : 0.438194 model2 loss : 0.016921
[01:00:06.538] iteration 24562 : model1 loss : 0.442331 model2 loss : 0.018283
[01:00:06.759] iteration 24563 : model1 loss : 0.434606 model2 loss : 0.017080
[01:00:06.928] iteration 24564 : model1 loss : 0.440277 model2 loss : 0.015762
[01:00:07.103] iteration 24565 : model1 loss : 0.442364 model2 loss : 0.017530
[01:00:07.283] iteration 24566 : model1 loss : 0.441549 model2 loss : 0.018447
[01:00:07.464] iteration 24567 : model1 loss : 0.442087 model2 loss : 0.017370
[01:00:07.644] iteration 24568 : model1 loss : 0.436185 model2 loss : 0.016711
[01:00:07.822] iteration 24569 : model1 loss : 0.439479 model2 loss : 0.018553
[01:00:08.026] iteration 24570 : model1 loss : 0.439420 model2 loss : 0.017816
[01:00:10.052] iteration 24571 : model1 loss : 0.443449 model2 loss : 0.017371
[01:00:10.231] iteration 24572 : model1 loss : 0.439163 model2 loss : 0.018003
[01:00:10.400] iteration 24573 : model1 loss : 0.442223 model2 loss : 0.016922
[01:00:10.566] iteration 24574 : model1 loss : 0.440142 model2 loss : 0.015656
[01:00:10.734] iteration 24575 : model1 loss : 0.439742 model2 loss : 0.015805
[01:00:10.904] iteration 24576 : model1 loss : 0.437327 model2 loss : 0.016962
[01:00:11.075] iteration 24577 : model1 loss : 0.442049 model2 loss : 0.016928
[01:00:11.243] iteration 24578 : model1 loss : 0.435990 model2 loss : 0.017564
[01:00:11.414] iteration 24579 : model1 loss : 0.436125 model2 loss : 0.017106
[01:00:11.581] iteration 24580 : model1 loss : 0.441185 model2 loss : 0.017500
[01:00:11.750] iteration 24581 : model1 loss : 0.440029 model2 loss : 0.018363
[01:00:11.919] iteration 24582 : model1 loss : 0.437926 model2 loss : 0.017652
[01:00:12.091] iteration 24583 : model1 loss : 0.438054 model2 loss : 0.017261
[01:00:12.260] iteration 24584 : model1 loss : 0.438289 model2 loss : 0.015597
[01:00:12.431] iteration 24585 : model1 loss : 0.437841 model2 loss : 0.017088
[01:00:12.599] iteration 24586 : model1 loss : 0.440387 model2 loss : 0.017625
[01:00:12.768] iteration 24587 : model1 loss : 0.442632 model2 loss : 0.017423
[01:00:12.936] iteration 24588 : model1 loss : 0.435959 model2 loss : 0.017083
[01:00:13.106] iteration 24589 : model1 loss : 0.442427 model2 loss : 0.018436
[01:00:13.274] iteration 24590 : model1 loss : 0.437338 model2 loss : 0.017443
[01:00:13.444] iteration 24591 : model1 loss : 0.441636 model2 loss : 0.017773
[01:00:15.395] iteration 24592 : model1 loss : 0.443327 model2 loss : 0.016661
[01:00:15.582] iteration 24593 : model1 loss : 0.439395 model2 loss : 0.017293
[01:00:15.762] iteration 24594 : model1 loss : 0.435562 model2 loss : 0.016862
[01:00:15.953] iteration 24595 : model1 loss : 0.440040 model2 loss : 0.016690
[01:00:16.138] iteration 24596 : model1 loss : 0.440342 model2 loss : 0.017185
[01:00:16.322] iteration 24597 : model1 loss : 0.438294 model2 loss : 0.018036
[01:00:16.494] iteration 24598 : model1 loss : 0.438536 model2 loss : 0.016834
[01:00:16.667] iteration 24599 : model1 loss : 0.440529 model2 loss : 0.018856
[01:00:16.838] iteration 24600 : model1 loss : 0.440409 model2 loss : 0.018214
[01:00:17.006] iteration 24601 : model1 loss : 0.443168 model2 loss : 0.016520
[01:00:17.179] iteration 24602 : model1 loss : 0.437486 model2 loss : 0.018285
[01:00:17.346] iteration 24603 : model1 loss : 0.435725 model2 loss : 0.017718
[01:00:17.514] iteration 24604 : model1 loss : 0.440481 model2 loss : 0.016991
[01:00:17.681] iteration 24605 : model1 loss : 0.442171 model2 loss : 0.019338
[01:00:17.856] iteration 24606 : model1 loss : 0.440167 model2 loss : 0.017933
[01:00:18.025] iteration 24607 : model1 loss : 0.446681 model2 loss : 0.022133
[01:00:18.194] iteration 24608 : model1 loss : 0.437489 model2 loss : 0.015133
[01:00:18.361] iteration 24609 : model1 loss : 0.440835 model2 loss : 0.017407
[01:00:18.530] iteration 24610 : model1 loss : 0.439542 model2 loss : 0.017629
[01:00:18.696] iteration 24611 : model1 loss : 0.440866 model2 loss : 0.018343
[01:00:18.864] iteration 24612 : model1 loss : 0.436265 model2 loss : 0.016327
[01:00:20.860] iteration 24613 : model1 loss : 0.443583 model2 loss : 0.019303
[01:00:21.047] iteration 24614 : model1 loss : 0.438521 model2 loss : 0.016724
[01:00:21.225] iteration 24615 : model1 loss : 0.440450 model2 loss : 0.017316
[01:00:21.394] iteration 24616 : model1 loss : 0.436826 model2 loss : 0.016192
[01:00:21.572] iteration 24617 : model1 loss : 0.441910 model2 loss : 0.016902
[01:00:21.760] iteration 24618 : model1 loss : 0.439918 model2 loss : 0.015015
[01:00:21.932] iteration 24619 : model1 loss : 0.434454 model2 loss : 0.015220
[01:00:22.109] iteration 24620 : model1 loss : 0.440131 model2 loss : 0.017629
[01:00:22.283] iteration 24621 : model1 loss : 0.439811 model2 loss : 0.017390
[01:00:22.476] iteration 24622 : model1 loss : 0.443312 model2 loss : 0.020355
[01:00:22.657] iteration 24623 : model1 loss : 0.438823 model2 loss : 0.014393
[01:00:22.838] iteration 24624 : model1 loss : 0.437908 model2 loss : 0.016805
[01:00:23.018] iteration 24625 : model1 loss : 0.442039 model2 loss : 0.015978
[01:00:23.195] iteration 24626 : model1 loss : 0.437761 model2 loss : 0.016727
[01:00:23.377] iteration 24627 : model1 loss : 0.436208 model2 loss : 0.017611
[01:00:23.554] iteration 24628 : model1 loss : 0.440232 model2 loss : 0.017478
[01:00:23.727] iteration 24629 : model1 loss : 0.437729 model2 loss : 0.015825
[01:00:23.900] iteration 24630 : model1 loss : 0.438691 model2 loss : 0.016614
[01:00:24.083] iteration 24631 : model1 loss : 0.438609 model2 loss : 0.017715
[01:00:24.258] iteration 24632 : model1 loss : 0.439920 model2 loss : 0.016564
[01:00:24.425] iteration 24633 : model1 loss : 0.438634 model2 loss : 0.017238
[01:00:26.444] iteration 24634 : model1 loss : 0.434237 model2 loss : 0.016954
[01:00:26.615] iteration 24635 : model1 loss : 0.437742 model2 loss : 0.016539
[01:00:26.788] iteration 24636 : model1 loss : 0.440862 model2 loss : 0.016738
[01:00:26.960] iteration 24637 : model1 loss : 0.441355 model2 loss : 0.017990
[01:00:27.133] iteration 24638 : model1 loss : 0.438219 model2 loss : 0.017265
[01:00:27.304] iteration 24639 : model1 loss : 0.438695 model2 loss : 0.017756
[01:00:27.477] iteration 24640 : model1 loss : 0.438167 model2 loss : 0.016612
[01:00:27.658] iteration 24641 : model1 loss : 0.439687 model2 loss : 0.017310
[01:00:27.839] iteration 24642 : model1 loss : 0.436977 model2 loss : 0.016010
[01:00:28.033] iteration 24643 : model1 loss : 0.438728 model2 loss : 0.018133
[01:00:28.203] iteration 24644 : model1 loss : 0.439095 model2 loss : 0.019612
[01:00:28.375] iteration 24645 : model1 loss : 0.441393 model2 loss : 0.018424
[01:00:28.577] iteration 24646 : model1 loss : 0.439800 model2 loss : 0.018306
[01:00:28.763] iteration 24647 : model1 loss : 0.434053 model2 loss : 0.016694
[01:00:28.940] iteration 24648 : model1 loss : 0.444526 model2 loss : 0.019169
[01:00:29.109] iteration 24649 : model1 loss : 0.439438 model2 loss : 0.017850
[01:00:29.276] iteration 24650 : model1 loss : 0.442698 model2 loss : 0.019569
[01:00:29.443] iteration 24651 : model1 loss : 0.443265 model2 loss : 0.018377
[01:00:29.612] iteration 24652 : model1 loss : 0.442766 model2 loss : 0.017389
[01:00:29.779] iteration 24653 : model1 loss : 0.443250 model2 loss : 0.018808
[01:00:29.946] iteration 24654 : model1 loss : 0.442415 model2 loss : 0.018976
[01:00:31.923] iteration 24655 : model1 loss : 0.446040 model2 loss : 0.020987
[01:00:32.091] iteration 24656 : model1 loss : 0.441683 model2 loss : 0.018289
[01:00:32.262] iteration 24657 : model1 loss : 0.435480 model2 loss : 0.015789
[01:00:32.432] iteration 24658 : model1 loss : 0.438207 model2 loss : 0.018508
[01:00:32.602] iteration 24659 : model1 loss : 0.440856 model2 loss : 0.017806
[01:00:32.771] iteration 24660 : model1 loss : 0.440554 model2 loss : 0.016664
[01:00:32.940] iteration 24661 : model1 loss : 0.435350 model2 loss : 0.016754
[01:00:33.109] iteration 24662 : model1 loss : 0.439549 model2 loss : 0.017221
[01:00:33.278] iteration 24663 : model1 loss : 0.438156 model2 loss : 0.016162
[01:00:33.446] iteration 24664 : model1 loss : 0.439506 model2 loss : 0.017530
[01:00:33.615] iteration 24665 : model1 loss : 0.440690 model2 loss : 0.017898
[01:00:33.782] iteration 24666 : model1 loss : 0.442016 model2 loss : 0.020485
[01:00:33.952] iteration 24667 : model1 loss : 0.441561 model2 loss : 0.015899
[01:00:34.121] iteration 24668 : model1 loss : 0.441864 model2 loss : 0.018427
[01:00:34.291] iteration 24669 : model1 loss : 0.438867 model2 loss : 0.017299
[01:00:34.460] iteration 24670 : model1 loss : 0.442091 model2 loss : 0.018710
[01:00:34.629] iteration 24671 : model1 loss : 0.432869 model2 loss : 0.015666
[01:00:34.797] iteration 24672 : model1 loss : 0.438270 model2 loss : 0.016581
[01:00:34.968] iteration 24673 : model1 loss : 0.436485 model2 loss : 0.016575
[01:00:35.138] iteration 24674 : model1 loss : 0.442529 model2 loss : 0.017459
[01:00:35.308] iteration 24675 : model1 loss : 0.440212 model2 loss : 0.019114
[01:00:37.254] iteration 24676 : model1 loss : 0.440256 model2 loss : 0.017342
[01:00:37.426] iteration 24677 : model1 loss : 0.441691 model2 loss : 0.015672
[01:00:37.595] iteration 24678 : model1 loss : 0.435888 model2 loss : 0.016181
[01:00:37.764] iteration 24679 : model1 loss : 0.443545 model2 loss : 0.016240
[01:00:37.932] iteration 24680 : model1 loss : 0.439003 model2 loss : 0.016191
[01:00:38.100] iteration 24681 : model1 loss : 0.438634 model2 loss : 0.016388
[01:00:38.269] iteration 24682 : model1 loss : 0.437770 model2 loss : 0.017077
[01:00:38.438] iteration 24683 : model1 loss : 0.438414 model2 loss : 0.017524
[01:00:38.608] iteration 24684 : model1 loss : 0.439448 model2 loss : 0.016132
[01:00:38.776] iteration 24685 : model1 loss : 0.438321 model2 loss : 0.018766
[01:00:38.946] iteration 24686 : model1 loss : 0.439464 model2 loss : 0.016781
[01:00:39.114] iteration 24687 : model1 loss : 0.442619 model2 loss : 0.019268
[01:00:39.283] iteration 24688 : model1 loss : 0.439984 model2 loss : 0.018092
[01:00:39.449] iteration 24689 : model1 loss : 0.438925 model2 loss : 0.017221
[01:00:39.618] iteration 24690 : model1 loss : 0.439646 model2 loss : 0.017905
[01:00:39.787] iteration 24691 : model1 loss : 0.438706 model2 loss : 0.016880
[01:00:39.957] iteration 24692 : model1 loss : 0.438255 model2 loss : 0.017995
[01:00:40.129] iteration 24693 : model1 loss : 0.442480 model2 loss : 0.019032
[01:00:40.299] iteration 24694 : model1 loss : 0.434202 model2 loss : 0.018470
[01:00:40.465] iteration 24695 : model1 loss : 0.442063 model2 loss : 0.018763
[01:00:40.636] iteration 24696 : model1 loss : 0.440874 model2 loss : 0.017971
[01:00:42.632] iteration 24697 : model1 loss : 0.438205 model2 loss : 0.016632
[01:00:42.801] iteration 24698 : model1 loss : 0.440311 model2 loss : 0.017320
[01:00:42.972] iteration 24699 : model1 loss : 0.442615 model2 loss : 0.019803
[01:00:43.141] iteration 24700 : model1 loss : 0.438990 model2 loss : 0.017294
[01:00:43.311] iteration 24701 : model1 loss : 0.436917 model2 loss : 0.016999
[01:00:43.480] iteration 24702 : model1 loss : 0.440514 model2 loss : 0.019262
[01:00:43.648] iteration 24703 : model1 loss : 0.441609 model2 loss : 0.019034
[01:00:43.816] iteration 24704 : model1 loss : 0.440197 model2 loss : 0.018118
[01:00:43.986] iteration 24705 : model1 loss : 0.438698 model2 loss : 0.015592
[01:00:44.158] iteration 24706 : model1 loss : 0.435210 model2 loss : 0.018374
[01:00:44.330] iteration 24707 : model1 loss : 0.441989 model2 loss : 0.018382
[01:00:44.498] iteration 24708 : model1 loss : 0.440043 model2 loss : 0.015259
[01:00:44.666] iteration 24709 : model1 loss : 0.440376 model2 loss : 0.019004
[01:00:44.838] iteration 24710 : model1 loss : 0.441658 model2 loss : 0.018968
[01:00:45.008] iteration 24711 : model1 loss : 0.437720 model2 loss : 0.015592
[01:00:45.178] iteration 24712 : model1 loss : 0.442584 model2 loss : 0.018103
[01:00:45.349] iteration 24713 : model1 loss : 0.436463 model2 loss : 0.016822
[01:00:45.518] iteration 24714 : model1 loss : 0.436194 model2 loss : 0.016695
[01:00:45.687] iteration 24715 : model1 loss : 0.441381 model2 loss : 0.018863
[01:00:45.853] iteration 24716 : model1 loss : 0.442320 model2 loss : 0.018589
[01:00:46.020] iteration 24717 : model1 loss : 0.440803 model2 loss : 0.018246
[01:00:47.991] iteration 24718 : model1 loss : 0.434648 model2 loss : 0.015878
[01:00:48.162] iteration 24719 : model1 loss : 0.442639 model2 loss : 0.017914
[01:00:48.331] iteration 24720 : model1 loss : 0.438102 model2 loss : 0.019065
[01:00:48.499] iteration 24721 : model1 loss : 0.438124 model2 loss : 0.017111
[01:00:48.669] iteration 24722 : model1 loss : 0.438056 model2 loss : 0.015690
[01:00:48.838] iteration 24723 : model1 loss : 0.445400 model2 loss : 0.020055
[01:00:49.008] iteration 24724 : model1 loss : 0.437613 model2 loss : 0.018116
[01:00:49.177] iteration 24725 : model1 loss : 0.437584 model2 loss : 0.019211
[01:00:49.347] iteration 24726 : model1 loss : 0.436825 model2 loss : 0.017204
[01:00:49.515] iteration 24727 : model1 loss : 0.441191 model2 loss : 0.015536
[01:00:49.683] iteration 24728 : model1 loss : 0.442685 model2 loss : 0.018518
[01:00:49.852] iteration 24729 : model1 loss : 0.435983 model2 loss : 0.016624
[01:00:50.021] iteration 24730 : model1 loss : 0.438347 model2 loss : 0.016237
[01:00:50.190] iteration 24731 : model1 loss : 0.440269 model2 loss : 0.018122
[01:00:50.366] iteration 24732 : model1 loss : 0.436539 model2 loss : 0.017172
[01:00:50.535] iteration 24733 : model1 loss : 0.444388 model2 loss : 0.021134
[01:00:50.704] iteration 24734 : model1 loss : 0.439478 model2 loss : 0.016661
[01:00:50.872] iteration 24735 : model1 loss : 0.442732 model2 loss : 0.016424
[01:00:51.043] iteration 24736 : model1 loss : 0.439037 model2 loss : 0.017601
[01:00:51.209] iteration 24737 : model1 loss : 0.444027 model2 loss : 0.018978
[01:00:51.379] iteration 24738 : model1 loss : 0.436324 model2 loss : 0.017917
[01:00:53.371] iteration 24739 : model1 loss : 0.438277 model2 loss : 0.016388
[01:00:53.539] iteration 24740 : model1 loss : 0.440872 model2 loss : 0.018977
[01:00:53.708] iteration 24741 : model1 loss : 0.439677 model2 loss : 0.016907
[01:00:53.876] iteration 24742 : model1 loss : 0.439105 model2 loss : 0.017576
[01:00:54.044] iteration 24743 : model1 loss : 0.441292 model2 loss : 0.017911
[01:00:54.213] iteration 24744 : model1 loss : 0.443796 model2 loss : 0.017212
[01:00:54.384] iteration 24745 : model1 loss : 0.436485 model2 loss : 0.016331
[01:00:54.553] iteration 24746 : model1 loss : 0.443721 model2 loss : 0.017187
[01:00:54.721] iteration 24747 : model1 loss : 0.443671 model2 loss : 0.018571
[01:00:54.891] iteration 24748 : model1 loss : 0.438949 model2 loss : 0.019342
[01:00:55.061] iteration 24749 : model1 loss : 0.435113 model2 loss : 0.018111
[01:00:55.229] iteration 24750 : model1 loss : 0.442175 model2 loss : 0.019832
[01:00:55.397] iteration 24751 : model1 loss : 0.437010 model2 loss : 0.018708
[01:00:55.564] iteration 24752 : model1 loss : 0.439872 model2 loss : 0.016007
[01:00:55.734] iteration 24753 : model1 loss : 0.440650 model2 loss : 0.018780
[01:00:55.902] iteration 24754 : model1 loss : 0.438164 model2 loss : 0.015777
[01:00:56.071] iteration 24755 : model1 loss : 0.440992 model2 loss : 0.019817
[01:00:56.240] iteration 24756 : model1 loss : 0.439323 model2 loss : 0.019772
[01:00:56.410] iteration 24757 : model1 loss : 0.439678 model2 loss : 0.018516
[01:00:56.576] iteration 24758 : model1 loss : 0.439102 model2 loss : 0.019376
[01:00:56.743] iteration 24759 : model1 loss : 0.438774 model2 loss : 0.016916
[01:00:58.725] iteration 24760 : model1 loss : 0.439692 model2 loss : 0.018642
[01:00:58.895] iteration 24761 : model1 loss : 0.436150 model2 loss : 0.017807
[01:00:59.064] iteration 24762 : model1 loss : 0.440317 model2 loss : 0.016064
[01:00:59.233] iteration 24763 : model1 loss : 0.435970 model2 loss : 0.016703
[01:00:59.405] iteration 24764 : model1 loss : 0.435102 model2 loss : 0.017173
[01:00:59.573] iteration 24765 : model1 loss : 0.444283 model2 loss : 0.017825
[01:00:59.743] iteration 24766 : model1 loss : 0.436393 model2 loss : 0.019032
[01:00:59.909] iteration 24767 : model1 loss : 0.440912 model2 loss : 0.019556
[01:01:00.078] iteration 24768 : model1 loss : 0.440501 model2 loss : 0.017684
[01:01:00.247] iteration 24769 : model1 loss : 0.438540 model2 loss : 0.016280
[01:01:00.415] iteration 24770 : model1 loss : 0.442453 model2 loss : 0.019459
[01:01:00.584] iteration 24771 : model1 loss : 0.439670 model2 loss : 0.017218
[01:01:00.752] iteration 24772 : model1 loss : 0.439788 model2 loss : 0.017784
[01:01:00.924] iteration 24773 : model1 loss : 0.440400 model2 loss : 0.017647
[01:01:01.096] iteration 24774 : model1 loss : 0.437433 model2 loss : 0.014821
[01:01:01.263] iteration 24775 : model1 loss : 0.440214 model2 loss : 0.018198
[01:01:01.431] iteration 24776 : model1 loss : 0.443726 model2 loss : 0.019791
[01:01:01.598] iteration 24777 : model1 loss : 0.441327 model2 loss : 0.016871
[01:01:01.767] iteration 24778 : model1 loss : 0.438550 model2 loss : 0.017023
[01:01:01.933] iteration 24779 : model1 loss : 0.441684 model2 loss : 0.018452
[01:01:02.102] iteration 24780 : model1 loss : 0.443106 model2 loss : 0.016113
[01:01:04.074] iteration 24781 : model1 loss : 0.438282 model2 loss : 0.018638
[01:01:04.244] iteration 24782 : model1 loss : 0.439577 model2 loss : 0.017218
[01:01:04.415] iteration 24783 : model1 loss : 0.443005 model2 loss : 0.018417
[01:01:04.583] iteration 24784 : model1 loss : 0.440543 model2 loss : 0.016119
[01:01:04.752] iteration 24785 : model1 loss : 0.440469 model2 loss : 0.017775
[01:01:04.921] iteration 24786 : model1 loss : 0.438222 model2 loss : 0.017005
[01:01:05.101] iteration 24787 : model1 loss : 0.438196 model2 loss : 0.017129
[01:01:05.270] iteration 24788 : model1 loss : 0.441358 model2 loss : 0.017771
[01:01:05.437] iteration 24789 : model1 loss : 0.443627 model2 loss : 0.018483
[01:01:05.606] iteration 24790 : model1 loss : 0.437477 model2 loss : 0.016389
[01:01:05.774] iteration 24791 : model1 loss : 0.438735 model2 loss : 0.017855
[01:01:05.942] iteration 24792 : model1 loss : 0.436521 model2 loss : 0.015990
[01:01:06.115] iteration 24793 : model1 loss : 0.445658 model2 loss : 0.018642
[01:01:06.283] iteration 24794 : model1 loss : 0.441235 model2 loss : 0.019059
[01:01:06.450] iteration 24795 : model1 loss : 0.437167 model2 loss : 0.016216
[01:01:06.619] iteration 24796 : model1 loss : 0.439678 model2 loss : 0.016209
[01:01:06.789] iteration 24797 : model1 loss : 0.439422 model2 loss : 0.015847
[01:01:06.957] iteration 24798 : model1 loss : 0.436506 model2 loss : 0.018167
[01:01:07.129] iteration 24799 : model1 loss : 0.440394 model2 loss : 0.016590
[01:01:07.297] iteration 24800 : model1 loss : 0.438407 model2 loss : 0.017438
[01:01:07.470] iteration 24801 : model1 loss : 0.440532 model2 loss : 0.018735
[01:01:09.442] iteration 24802 : model1 loss : 0.440036 model2 loss : 0.017667
[01:01:09.613] iteration 24803 : model1 loss : 0.436022 model2 loss : 0.015913
[01:01:09.783] iteration 24804 : model1 loss : 0.440763 model2 loss : 0.017609
[01:01:09.952] iteration 24805 : model1 loss : 0.440585 model2 loss : 0.016357
[01:01:10.122] iteration 24806 : model1 loss : 0.439240 model2 loss : 0.017779
[01:01:10.290] iteration 24807 : model1 loss : 0.440187 model2 loss : 0.017024
[01:01:10.461] iteration 24808 : model1 loss : 0.443897 model2 loss : 0.016365
[01:01:10.628] iteration 24809 : model1 loss : 0.441413 model2 loss : 0.016705
[01:01:10.798] iteration 24810 : model1 loss : 0.444716 model2 loss : 0.017214
[01:01:10.965] iteration 24811 : model1 loss : 0.438430 model2 loss : 0.016844
[01:01:11.137] iteration 24812 : model1 loss : 0.439147 model2 loss : 0.017661
[01:01:11.306] iteration 24813 : model1 loss : 0.443069 model2 loss : 0.019215
[01:01:11.474] iteration 24814 : model1 loss : 0.442624 model2 loss : 0.017110
[01:01:11.643] iteration 24815 : model1 loss : 0.438844 model2 loss : 0.016122
[01:01:11.813] iteration 24816 : model1 loss : 0.439566 model2 loss : 0.018281
[01:01:11.981] iteration 24817 : model1 loss : 0.438702 model2 loss : 0.017765
[01:01:12.152] iteration 24818 : model1 loss : 0.438459 model2 loss : 0.017192
[01:01:12.323] iteration 24819 : model1 loss : 0.438846 model2 loss : 0.018251
[01:01:12.495] iteration 24820 : model1 loss : 0.433987 model2 loss : 0.017315
[01:01:12.662] iteration 24821 : model1 loss : 0.436137 model2 loss : 0.019140
[01:01:12.829] iteration 24822 : model1 loss : 0.440477 model2 loss : 0.018920
[01:01:14.780] iteration 24823 : model1 loss : 0.439896 model2 loss : 0.017775
[01:01:14.953] iteration 24824 : model1 loss : 0.436895 model2 loss : 0.017130
[01:01:15.128] iteration 24825 : model1 loss : 0.439474 model2 loss : 0.016527
[01:01:15.300] iteration 24826 : model1 loss : 0.438764 model2 loss : 0.017553
[01:01:15.468] iteration 24827 : model1 loss : 0.438159 model2 loss : 0.017547
[01:01:15.634] iteration 24828 : model1 loss : 0.444623 model2 loss : 0.018743
[01:01:15.803] iteration 24829 : model1 loss : 0.434229 model2 loss : 0.015219
[01:01:15.971] iteration 24830 : model1 loss : 0.438389 model2 loss : 0.019650
[01:01:16.146] iteration 24831 : model1 loss : 0.438609 model2 loss : 0.018510
[01:01:16.315] iteration 24832 : model1 loss : 0.440717 model2 loss : 0.018353
[01:01:16.484] iteration 24833 : model1 loss : 0.444510 model2 loss : 0.017150
[01:01:16.652] iteration 24834 : model1 loss : 0.442290 model2 loss : 0.016272
[01:01:16.820] iteration 24835 : model1 loss : 0.438263 model2 loss : 0.018350
[01:01:16.987] iteration 24836 : model1 loss : 0.438234 model2 loss : 0.016423
[01:01:17.159] iteration 24837 : model1 loss : 0.439865 model2 loss : 0.016644
[01:01:17.328] iteration 24838 : model1 loss : 0.437574 model2 loss : 0.015987
[01:01:17.499] iteration 24839 : model1 loss : 0.443767 model2 loss : 0.019005
[01:01:17.666] iteration 24840 : model1 loss : 0.442030 model2 loss : 0.016908
[01:01:17.835] iteration 24841 : model1 loss : 0.439006 model2 loss : 0.017390
[01:01:18.004] iteration 24842 : model1 loss : 0.441163 model2 loss : 0.018890
[01:01:18.172] iteration 24843 : model1 loss : 0.443175 model2 loss : 0.016960
[01:01:20.121] iteration 24844 : model1 loss : 0.439086 model2 loss : 0.016795
[01:01:20.295] iteration 24845 : model1 loss : 0.437579 model2 loss : 0.017165
[01:01:20.465] iteration 24846 : model1 loss : 0.442801 model2 loss : 0.015828
[01:01:20.632] iteration 24847 : model1 loss : 0.439594 model2 loss : 0.017673
[01:01:20.803] iteration 24848 : model1 loss : 0.435295 model2 loss : 0.016062
[01:01:20.971] iteration 24849 : model1 loss : 0.439065 model2 loss : 0.018547
[01:01:21.143] iteration 24850 : model1 loss : 0.442228 model2 loss : 0.017756
[01:01:21.314] iteration 24851 : model1 loss : 0.439140 model2 loss : 0.017744
[01:01:21.482] iteration 24852 : model1 loss : 0.441937 model2 loss : 0.019424
[01:01:21.649] iteration 24853 : model1 loss : 0.440062 model2 loss : 0.016226
[01:01:21.819] iteration 24854 : model1 loss : 0.439745 model2 loss : 0.018172
[01:01:21.989] iteration 24855 : model1 loss : 0.437598 model2 loss : 0.017705
[01:01:22.161] iteration 24856 : model1 loss : 0.439144 model2 loss : 0.016710
[01:01:22.329] iteration 24857 : model1 loss : 0.443475 model2 loss : 0.018101
[01:01:22.500] iteration 24858 : model1 loss : 0.439697 model2 loss : 0.017364
[01:01:22.667] iteration 24859 : model1 loss : 0.438756 model2 loss : 0.016191
[01:01:22.850] iteration 24860 : model1 loss : 0.442926 model2 loss : 0.018650
[01:01:23.018] iteration 24861 : model1 loss : 0.436904 model2 loss : 0.015490
[01:01:23.189] iteration 24862 : model1 loss : 0.437061 model2 loss : 0.016679
[01:01:23.357] iteration 24863 : model1 loss : 0.439636 model2 loss : 0.016381
[01:01:23.524] iteration 24864 : model1 loss : 0.442186 model2 loss : 0.018052
[01:01:25.451] iteration 24865 : model1 loss : 0.440056 model2 loss : 0.016695
[01:01:25.620] iteration 24866 : model1 loss : 0.437273 model2 loss : 0.016010
[01:01:25.789] iteration 24867 : model1 loss : 0.437369 model2 loss : 0.017187
[01:01:25.958] iteration 24868 : model1 loss : 0.441483 model2 loss : 0.016668
[01:01:26.130] iteration 24869 : model1 loss : 0.441128 model2 loss : 0.017578
[01:01:26.298] iteration 24870 : model1 loss : 0.441989 model2 loss : 0.018423
[01:01:26.467] iteration 24871 : model1 loss : 0.440805 model2 loss : 0.017303
[01:01:26.634] iteration 24872 : model1 loss : 0.437498 model2 loss : 0.017986
[01:01:26.806] iteration 24873 : model1 loss : 0.443486 model2 loss : 0.017692
[01:01:26.975] iteration 24874 : model1 loss : 0.437949 model2 loss : 0.018640
[01:01:27.148] iteration 24875 : model1 loss : 0.442501 model2 loss : 0.018533
[01:01:27.317] iteration 24876 : model1 loss : 0.441889 model2 loss : 0.018297
[01:01:27.490] iteration 24877 : model1 loss : 0.438612 model2 loss : 0.019108
[01:01:27.657] iteration 24878 : model1 loss : 0.436163 model2 loss : 0.017125
[01:01:27.828] iteration 24879 : model1 loss : 0.441856 model2 loss : 0.016797
[01:01:27.997] iteration 24880 : model1 loss : 0.439398 model2 loss : 0.018596
[01:01:28.166] iteration 24881 : model1 loss : 0.437348 model2 loss : 0.016619
[01:01:28.337] iteration 24882 : model1 loss : 0.436649 model2 loss : 0.015681
[01:01:28.506] iteration 24883 : model1 loss : 0.440912 model2 loss : 0.016699
[01:01:28.673] iteration 24884 : model1 loss : 0.438862 model2 loss : 0.017278
[01:01:28.842] iteration 24885 : model1 loss : 0.440299 model2 loss : 0.015928
[01:01:30.791] iteration 24886 : model1 loss : 0.439582 model2 loss : 0.015310
[01:01:30.961] iteration 24887 : model1 loss : 0.440345 model2 loss : 0.016473
[01:01:31.134] iteration 24888 : model1 loss : 0.438506 model2 loss : 0.017416
[01:01:31.304] iteration 24889 : model1 loss : 0.438393 model2 loss : 0.017500
[01:01:31.473] iteration 24890 : model1 loss : 0.441206 model2 loss : 0.017627
[01:01:31.641] iteration 24891 : model1 loss : 0.439942 model2 loss : 0.017879
[01:01:31.812] iteration 24892 : model1 loss : 0.439811 model2 loss : 0.018019
[01:01:31.979] iteration 24893 : model1 loss : 0.436172 model2 loss : 0.015756
[01:01:32.151] iteration 24894 : model1 loss : 0.437753 model2 loss : 0.015208
[01:01:32.321] iteration 24895 : model1 loss : 0.440506 model2 loss : 0.017914
[01:01:32.494] iteration 24896 : model1 loss : 0.442505 model2 loss : 0.018452
[01:01:32.660] iteration 24897 : model1 loss : 0.441111 model2 loss : 0.015351
[01:01:32.829] iteration 24898 : model1 loss : 0.443753 model2 loss : 0.018131
[01:01:32.994] iteration 24899 : model1 loss : 0.439362 model2 loss : 0.016509
[01:01:33.167] iteration 24900 : model1 loss : 0.437443 model2 loss : 0.016788
[01:01:33.336] iteration 24901 : model1 loss : 0.438051 model2 loss : 0.017390
[01:01:33.505] iteration 24902 : model1 loss : 0.439346 model2 loss : 0.018376
[01:01:33.673] iteration 24903 : model1 loss : 0.441225 model2 loss : 0.019832
[01:01:33.841] iteration 24904 : model1 loss : 0.437388 model2 loss : 0.016500
[01:01:34.007] iteration 24905 : model1 loss : 0.437996 model2 loss : 0.015625
[01:01:34.178] iteration 24906 : model1 loss : 0.444210 model2 loss : 0.017159
[01:01:36.134] iteration 24907 : model1 loss : 0.439360 model2 loss : 0.018374
[01:01:36.304] iteration 24908 : model1 loss : 0.438517 model2 loss : 0.017484
[01:01:36.474] iteration 24909 : model1 loss : 0.442957 model2 loss : 0.018668
[01:01:36.642] iteration 24910 : model1 loss : 0.443553 model2 loss : 0.019783
[01:01:36.811] iteration 24911 : model1 loss : 0.440821 model2 loss : 0.020547
[01:01:36.978] iteration 24912 : model1 loss : 0.440667 model2 loss : 0.014250
[01:01:37.150] iteration 24913 : model1 loss : 0.441742 model2 loss : 0.017673
[01:01:37.320] iteration 24914 : model1 loss : 0.437371 model2 loss : 0.016347
[01:01:37.490] iteration 24915 : model1 loss : 0.442261 model2 loss : 0.018340
[01:01:37.658] iteration 24916 : model1 loss : 0.435754 model2 loss : 0.016774
[01:01:37.828] iteration 24917 : model1 loss : 0.443212 model2 loss : 0.016366
[01:01:37.995] iteration 24918 : model1 loss : 0.437780 model2 loss : 0.016294
[01:01:38.168] iteration 24919 : model1 loss : 0.438493 model2 loss : 0.015711
[01:01:38.339] iteration 24920 : model1 loss : 0.437360 model2 loss : 0.014993
[01:01:38.507] iteration 24921 : model1 loss : 0.437510 model2 loss : 0.017514
[01:01:38.675] iteration 24922 : model1 loss : 0.440532 model2 loss : 0.015817
[01:01:38.845] iteration 24923 : model1 loss : 0.436343 model2 loss : 0.016538
[01:01:39.012] iteration 24924 : model1 loss : 0.437428 model2 loss : 0.015192
[01:01:39.181] iteration 24925 : model1 loss : 0.439563 model2 loss : 0.017550
[01:01:39.348] iteration 24926 : model1 loss : 0.442395 model2 loss : 0.017872
[01:01:39.516] iteration 24927 : model1 loss : 0.439498 model2 loss : 0.017981
[01:01:41.546] iteration 24928 : model1 loss : 0.439856 model2 loss : 0.015652
[01:01:41.718] iteration 24929 : model1 loss : 0.439858 model2 loss : 0.016939
[01:01:41.890] iteration 24930 : model1 loss : 0.441860 model2 loss : 0.018259
[01:01:42.058] iteration 24931 : model1 loss : 0.442396 model2 loss : 0.017757
[01:01:42.228] iteration 24932 : model1 loss : 0.439366 model2 loss : 0.017180
[01:01:42.395] iteration 24933 : model1 loss : 0.444540 model2 loss : 0.019090
[01:01:42.565] iteration 24934 : model1 loss : 0.438787 model2 loss : 0.015435
[01:01:42.735] iteration 24935 : model1 loss : 0.440231 model2 loss : 0.017031
[01:01:42.905] iteration 24936 : model1 loss : 0.442673 model2 loss : 0.016523
[01:01:43.073] iteration 24937 : model1 loss : 0.438756 model2 loss : 0.018463
[01:01:43.244] iteration 24938 : model1 loss : 0.439762 model2 loss : 0.017292
[01:01:43.412] iteration 24939 : model1 loss : 0.443312 model2 loss : 0.016738
[01:01:43.581] iteration 24940 : model1 loss : 0.437439 model2 loss : 0.014703
[01:01:43.750] iteration 24941 : model1 loss : 0.436884 model2 loss : 0.018638
[01:01:43.917] iteration 24942 : model1 loss : 0.438792 model2 loss : 0.017228
[01:01:44.087] iteration 24943 : model1 loss : 0.440205 model2 loss : 0.019207
[01:01:44.255] iteration 24944 : model1 loss : 0.439611 model2 loss : 0.019481
[01:01:44.436] iteration 24945 : model1 loss : 0.446022 model2 loss : 0.021870
[01:01:44.617] iteration 24946 : model1 loss : 0.438693 model2 loss : 0.016357
[01:01:44.796] iteration 24947 : model1 loss : 0.432900 model2 loss : 0.016027
[01:01:44.973] iteration 24948 : model1 loss : 0.436731 model2 loss : 0.017720
[01:01:47.024] iteration 24949 : model1 loss : 0.443614 model2 loss : 0.018688
[01:01:47.214] iteration 24950 : model1 loss : 0.441112 model2 loss : 0.017621
[01:01:47.397] iteration 24951 : model1 loss : 0.436471 model2 loss : 0.016998
[01:01:47.567] iteration 24952 : model1 loss : 0.442434 model2 loss : 0.017687
[01:01:47.745] iteration 24953 : model1 loss : 0.437109 model2 loss : 0.017272
[01:01:47.913] iteration 24954 : model1 loss : 0.434345 model2 loss : 0.018030
[01:01:48.086] iteration 24955 : model1 loss : 0.440057 model2 loss : 0.017863
[01:01:48.259] iteration 24956 : model1 loss : 0.440251 model2 loss : 0.016353
[01:01:48.435] iteration 24957 : model1 loss : 0.441585 model2 loss : 0.017287
[01:01:48.609] iteration 24958 : model1 loss : 0.437190 model2 loss : 0.018025
[01:01:48.778] iteration 24959 : model1 loss : 0.441800 model2 loss : 0.016427
[01:01:48.945] iteration 24960 : model1 loss : 0.442399 model2 loss : 0.018975
[01:01:49.120] iteration 24961 : model1 loss : 0.441669 model2 loss : 0.016330
[01:01:49.291] iteration 24962 : model1 loss : 0.438255 model2 loss : 0.018090
[01:01:49.466] iteration 24963 : model1 loss : 0.441925 model2 loss : 0.018202
[01:01:49.634] iteration 24964 : model1 loss : 0.441633 model2 loss : 0.018529
[01:01:49.803] iteration 24965 : model1 loss : 0.435208 model2 loss : 0.018233
[01:01:49.971] iteration 24966 : model1 loss : 0.441676 model2 loss : 0.017072
[01:01:50.147] iteration 24967 : model1 loss : 0.440121 model2 loss : 0.015485
[01:01:50.326] iteration 24968 : model1 loss : 0.438823 model2 loss : 0.017569
[01:01:50.495] iteration 24969 : model1 loss : 0.441896 model2 loss : 0.016685
[01:01:52.511] iteration 24970 : model1 loss : 0.441387 model2 loss : 0.016448
[01:01:52.680] iteration 24971 : model1 loss : 0.443481 model2 loss : 0.018346
[01:01:52.895] iteration 24972 : model1 loss : 0.439864 model2 loss : 0.017744
[01:01:53.065] iteration 24973 : model1 loss : 0.441568 model2 loss : 0.017601
[01:01:53.234] iteration 24974 : model1 loss : 0.434161 model2 loss : 0.014174
[01:01:53.439] iteration 24975 : model1 loss : 0.437401 model2 loss : 0.017307
[01:01:53.609] iteration 24976 : model1 loss : 0.439532 model2 loss : 0.017906
[01:01:53.778] iteration 24977 : model1 loss : 0.441200 model2 loss : 0.016612
[01:01:53.978] iteration 24978 : model1 loss : 0.438550 model2 loss : 0.018184
[01:01:54.148] iteration 24979 : model1 loss : 0.438764 model2 loss : 0.014745
[01:01:54.319] iteration 24980 : model1 loss : 0.441626 model2 loss : 0.017946
[01:01:54.487] iteration 24981 : model1 loss : 0.437594 model2 loss : 0.015130
[01:01:54.655] iteration 24982 : model1 loss : 0.436795 model2 loss : 0.016858
[01:01:54.822] iteration 24983 : model1 loss : 0.441487 model2 loss : 0.017325
[01:01:54.992] iteration 24984 : model1 loss : 0.438293 model2 loss : 0.016860
[01:01:55.177] iteration 24985 : model1 loss : 0.438086 model2 loss : 0.016715
[01:01:55.359] iteration 24986 : model1 loss : 0.436585 model2 loss : 0.016013
[01:01:55.539] iteration 24987 : model1 loss : 0.444463 model2 loss : 0.019175
[01:01:55.715] iteration 24988 : model1 loss : 0.438769 model2 loss : 0.017047
[01:01:55.894] iteration 24989 : model1 loss : 0.444261 model2 loss : 0.017936
[01:01:56.061] iteration 24990 : model1 loss : 0.440169 model2 loss : 0.016380
[01:01:58.126] iteration 24991 : model1 loss : 0.437993 model2 loss : 0.015254
[01:01:58.297] iteration 24992 : model1 loss : 0.440167 model2 loss : 0.017621
[01:01:58.465] iteration 24993 : model1 loss : 0.439390 model2 loss : 0.017616
[01:01:58.634] iteration 24994 : model1 loss : 0.443498 model2 loss : 0.017864
[01:01:58.817] iteration 24995 : model1 loss : 0.441721 model2 loss : 0.016330
[01:01:59.005] iteration 24996 : model1 loss : 0.438016 model2 loss : 0.017108
[01:01:59.196] iteration 24997 : model1 loss : 0.438584 model2 loss : 0.016610
[01:01:59.378] iteration 24998 : model1 loss : 0.440876 model2 loss : 0.017933
[01:01:59.562] iteration 24999 : model1 loss : 0.441129 model2 loss : 0.018234
[01:01:59.742] iteration 25000 : model1 loss : 0.437629 model2 loss : 0.018759
[01:02:08.282] iteration 25000 : model1_mean_dice : 0.881979 model1_mean_hd95 : 3.355794
[01:02:16.736] iteration 25000 : model2_mean_dice : 0.875321 model2_mean_hd95 : 6.583100
[01:02:16.930] iteration 25001 : model1 loss : 0.438038 model2 loss : 0.018459
[01:02:17.127] iteration 25002 : model1 loss : 0.442165 model2 loss : 0.018437
[01:02:17.364] iteration 25003 : model1 loss : 0.437993 model2 loss : 0.016712
[01:02:17.570] iteration 25004 : model1 loss : 0.439325 model2 loss : 0.018052
[01:02:17.784] iteration 25005 : model1 loss : 0.439976 model2 loss : 0.018169
[01:02:17.953] iteration 25006 : model1 loss : 0.436911 model2 loss : 0.016886
[01:02:18.126] iteration 25007 : model1 loss : 0.442818 model2 loss : 0.016954
[01:02:18.294] iteration 25008 : model1 loss : 0.441040 model2 loss : 0.016042
[01:02:18.463] iteration 25009 : model1 loss : 0.439657 model2 loss : 0.016565
[01:02:18.629] iteration 25010 : model1 loss : 0.437221 model2 loss : 0.017462
[01:02:18.796] iteration 25011 : model1 loss : 0.439784 model2 loss : 0.017414
[01:02:20.794] iteration 25012 : model1 loss : 0.438676 model2 loss : 0.017779
[01:02:20.966] iteration 25013 : model1 loss : 0.438758 model2 loss : 0.017633
[01:02:21.138] iteration 25014 : model1 loss : 0.436121 model2 loss : 0.017398
[01:02:21.314] iteration 25015 : model1 loss : 0.438445 model2 loss : 0.016922
[01:02:21.480] iteration 25016 : model1 loss : 0.440900 model2 loss : 0.016420
[01:02:21.660] iteration 25017 : model1 loss : 0.436205 model2 loss : 0.017456
[01:02:21.854] iteration 25018 : model1 loss : 0.444875 model2 loss : 0.018012
[01:02:22.086] iteration 25019 : model1 loss : 0.442243 model2 loss : 0.016187
[01:02:22.265] iteration 25020 : model1 loss : 0.436927 model2 loss : 0.016073
[01:02:22.435] iteration 25021 : model1 loss : 0.437954 model2 loss : 0.016199
[01:02:22.633] iteration 25022 : model1 loss : 0.438755 model2 loss : 0.016616
[01:02:22.802] iteration 25023 : model1 loss : 0.441476 model2 loss : 0.015907
[01:02:22.969] iteration 25024 : model1 loss : 0.438831 model2 loss : 0.017728
[01:02:23.140] iteration 25025 : model1 loss : 0.440823 model2 loss : 0.015943
[01:02:23.311] iteration 25026 : model1 loss : 0.442307 model2 loss : 0.017355
[01:02:23.478] iteration 25027 : model1 loss : 0.439426 model2 loss : 0.016559
[01:02:23.684] iteration 25028 : model1 loss : 0.438761 model2 loss : 0.016007
[01:02:23.865] iteration 25029 : model1 loss : 0.440676 model2 loss : 0.016951
[01:02:24.033] iteration 25030 : model1 loss : 0.438696 model2 loss : 0.018849
[01:02:24.202] iteration 25031 : model1 loss : 0.440090 model2 loss : 0.016798
[01:02:24.370] iteration 25032 : model1 loss : 0.442140 model2 loss : 0.019005
[01:02:26.400] iteration 25033 : model1 loss : 0.439833 model2 loss : 0.017428
[01:02:26.575] iteration 25034 : model1 loss : 0.433897 model2 loss : 0.016001
[01:02:26.746] iteration 25035 : model1 loss : 0.438751 model2 loss : 0.015920
[01:02:26.973] iteration 25036 : model1 loss : 0.439154 model2 loss : 0.016812
[01:02:27.164] iteration 25037 : model1 loss : 0.436564 model2 loss : 0.016752
[01:02:27.334] iteration 25038 : model1 loss : 0.440551 model2 loss : 0.018280
[01:02:27.502] iteration 25039 : model1 loss : 0.439484 model2 loss : 0.016307
[01:02:27.682] iteration 25040 : model1 loss : 0.440635 model2 loss : 0.018105
[01:02:27.848] iteration 25041 : model1 loss : 0.443716 model2 loss : 0.016954
[01:02:28.054] iteration 25042 : model1 loss : 0.441067 model2 loss : 0.014921
[01:02:28.224] iteration 25043 : model1 loss : 0.438027 model2 loss : 0.015915
[01:02:28.393] iteration 25044 : model1 loss : 0.434341 model2 loss : 0.017071
[01:02:28.582] iteration 25045 : model1 loss : 0.436702 model2 loss : 0.016060
[01:02:28.810] iteration 25046 : model1 loss : 0.440735 model2 loss : 0.016738
[01:02:29.054] iteration 25047 : model1 loss : 0.441068 model2 loss : 0.017655
[01:02:29.223] iteration 25048 : model1 loss : 0.438664 model2 loss : 0.016446
[01:02:29.392] iteration 25049 : model1 loss : 0.440704 model2 loss : 0.017778
[01:02:29.604] iteration 25050 : model1 loss : 0.439631 model2 loss : 0.018594
[01:02:29.772] iteration 25051 : model1 loss : 0.441407 model2 loss : 0.017206
[01:02:29.941] iteration 25052 : model1 loss : 0.443656 model2 loss : 0.018389
[01:02:30.108] iteration 25053 : model1 loss : 0.443293 model2 loss : 0.019286
[01:02:32.288] iteration 25054 : model1 loss : 0.435825 model2 loss : 0.018036
[01:02:32.461] iteration 25055 : model1 loss : 0.438652 model2 loss : 0.018455
[01:02:32.631] iteration 25056 : model1 loss : 0.436214 model2 loss : 0.014656
[01:02:32.801] iteration 25057 : model1 loss : 0.442348 model2 loss : 0.017265
[01:02:32.971] iteration 25058 : model1 loss : 0.442506 model2 loss : 0.016083
[01:02:33.143] iteration 25059 : model1 loss : 0.441759 model2 loss : 0.016317
[01:02:33.315] iteration 25060 : model1 loss : 0.440263 model2 loss : 0.017019
[01:02:33.483] iteration 25061 : model1 loss : 0.439837 model2 loss : 0.017639
[01:02:33.653] iteration 25062 : model1 loss : 0.439131 model2 loss : 0.018005
[01:02:33.820] iteration 25063 : model1 loss : 0.441317 model2 loss : 0.015983
[01:02:33.989] iteration 25064 : model1 loss : 0.438712 model2 loss : 0.018252
[01:02:34.162] iteration 25065 : model1 loss : 0.441725 model2 loss : 0.019046
[01:02:34.337] iteration 25066 : model1 loss : 0.442019 model2 loss : 0.018256
[01:02:34.514] iteration 25067 : model1 loss : 0.440889 model2 loss : 0.018838
[01:02:34.691] iteration 25068 : model1 loss : 0.443338 model2 loss : 0.018103
[01:02:34.870] iteration 25069 : model1 loss : 0.442760 model2 loss : 0.018204
[01:02:35.048] iteration 25070 : model1 loss : 0.437244 model2 loss : 0.016116
[01:02:35.221] iteration 25071 : model1 loss : 0.438081 model2 loss : 0.017681
[01:02:35.398] iteration 25072 : model1 loss : 0.439407 model2 loss : 0.016408
[01:02:35.572] iteration 25073 : model1 loss : 0.442546 model2 loss : 0.018812
[01:02:35.746] iteration 25074 : model1 loss : 0.437671 model2 loss : 0.018935
[01:02:37.970] iteration 25075 : model1 loss : 0.441511 model2 loss : 0.017582
[01:02:38.142] iteration 25076 : model1 loss : 0.440049 model2 loss : 0.015904
[01:02:38.320] iteration 25077 : model1 loss : 0.437433 model2 loss : 0.016655
[01:02:38.491] iteration 25078 : model1 loss : 0.438170 model2 loss : 0.017976
[01:02:38.664] iteration 25079 : model1 loss : 0.438121 model2 loss : 0.015847
[01:02:38.899] iteration 25080 : model1 loss : 0.441329 model2 loss : 0.019010
[01:02:39.085] iteration 25081 : model1 loss : 0.438930 model2 loss : 0.017057
[01:02:39.288] iteration 25082 : model1 loss : 0.438029 model2 loss : 0.016566
[01:02:39.497] iteration 25083 : model1 loss : 0.437007 model2 loss : 0.017216
[01:02:39.684] iteration 25084 : model1 loss : 0.435610 model2 loss : 0.016446
[01:02:39.914] iteration 25085 : model1 loss : 0.442158 model2 loss : 0.017526
[01:02:40.136] iteration 25086 : model1 loss : 0.437707 model2 loss : 0.015200
[01:02:40.332] iteration 25087 : model1 loss : 0.439854 model2 loss : 0.016830
[01:02:40.499] iteration 25088 : model1 loss : 0.441992 model2 loss : 0.017075
[01:02:40.667] iteration 25089 : model1 loss : 0.436623 model2 loss : 0.016942
[01:02:40.853] iteration 25090 : model1 loss : 0.442289 model2 loss : 0.016197
[01:02:41.022] iteration 25091 : model1 loss : 0.439360 model2 loss : 0.017389
[01:02:41.191] iteration 25092 : model1 loss : 0.442262 model2 loss : 0.017393
[01:02:41.367] iteration 25093 : model1 loss : 0.441607 model2 loss : 0.017960
[01:02:41.537] iteration 25094 : model1 loss : 0.440092 model2 loss : 0.017555
[01:02:41.704] iteration 25095 : model1 loss : 0.441357 model2 loss : 0.017671
[01:02:43.740] iteration 25096 : model1 loss : 0.439324 model2 loss : 0.017390
[01:02:43.921] iteration 25097 : model1 loss : 0.438199 model2 loss : 0.016040
[01:02:44.092] iteration 25098 : model1 loss : 0.437537 model2 loss : 0.016877
[01:02:44.257] iteration 25099 : model1 loss : 0.436931 model2 loss : 0.018090
[01:02:44.427] iteration 25100 : model1 loss : 0.439750 model2 loss : 0.016758
[01:02:44.596] iteration 25101 : model1 loss : 0.441768 model2 loss : 0.017252
[01:02:44.775] iteration 25102 : model1 loss : 0.437009 model2 loss : 0.015903
[01:02:44.943] iteration 25103 : model1 loss : 0.440195 model2 loss : 0.016811
[01:02:45.117] iteration 25104 : model1 loss : 0.442000 model2 loss : 0.017271
[01:02:45.284] iteration 25105 : model1 loss : 0.434027 model2 loss : 0.016667
[01:02:45.460] iteration 25106 : model1 loss : 0.439192 model2 loss : 0.015702
[01:02:45.655] iteration 25107 : model1 loss : 0.438995 model2 loss : 0.016724
[01:02:45.889] iteration 25108 : model1 loss : 0.441001 model2 loss : 0.015899
[01:02:46.129] iteration 25109 : model1 loss : 0.443573 model2 loss : 0.018459
[01:02:46.349] iteration 25110 : model1 loss : 0.438533 model2 loss : 0.017770
[01:02:46.549] iteration 25111 : model1 loss : 0.441079 model2 loss : 0.017816
[01:02:46.727] iteration 25112 : model1 loss : 0.438482 model2 loss : 0.018858
[01:02:46.903] iteration 25113 : model1 loss : 0.441145 model2 loss : 0.018949
[01:02:47.079] iteration 25114 : model1 loss : 0.442154 model2 loss : 0.019224
[01:02:47.246] iteration 25115 : model1 loss : 0.440131 model2 loss : 0.016788
[01:02:47.419] iteration 25116 : model1 loss : 0.445891 model2 loss : 0.019144
[01:02:49.442] iteration 25117 : model1 loss : 0.446922 model2 loss : 0.019966
[01:02:49.616] iteration 25118 : model1 loss : 0.445438 model2 loss : 0.022800
[01:02:49.786] iteration 25119 : model1 loss : 0.439314 model2 loss : 0.018809
[01:02:49.961] iteration 25120 : model1 loss : 0.434364 model2 loss : 0.016386
[01:02:50.149] iteration 25121 : model1 loss : 0.435239 model2 loss : 0.016624
[01:02:50.387] iteration 25122 : model1 loss : 0.440526 model2 loss : 0.017292
[01:02:50.568] iteration 25123 : model1 loss : 0.437603 model2 loss : 0.016097
[01:02:50.746] iteration 25124 : model1 loss : 0.438015 model2 loss : 0.015688
[01:02:50.930] iteration 25125 : model1 loss : 0.438686 model2 loss : 0.018805
[01:02:51.106] iteration 25126 : model1 loss : 0.441838 model2 loss : 0.020640
[01:02:51.280] iteration 25127 : model1 loss : 0.445066 model2 loss : 0.019303
[01:02:51.461] iteration 25128 : model1 loss : 0.435801 model2 loss : 0.016705
[01:02:51.653] iteration 25129 : model1 loss : 0.440639 model2 loss : 0.018218
[01:02:51.822] iteration 25130 : model1 loss : 0.437380 model2 loss : 0.015677
[01:02:51.992] iteration 25131 : model1 loss : 0.438648 model2 loss : 0.017794
[01:02:52.162] iteration 25132 : model1 loss : 0.441401 model2 loss : 0.017841
[01:02:52.340] iteration 25133 : model1 loss : 0.439279 model2 loss : 0.017642
[01:02:52.514] iteration 25134 : model1 loss : 0.444585 model2 loss : 0.017077
[01:02:52.692] iteration 25135 : model1 loss : 0.439355 model2 loss : 0.015998
[01:02:52.901] iteration 25136 : model1 loss : 0.437206 model2 loss : 0.015575
[01:02:53.119] iteration 25137 : model1 loss : 0.438673 model2 loss : 0.018527
[01:02:55.153] iteration 25138 : model1 loss : 0.438355 model2 loss : 0.016662
[01:02:55.328] iteration 25139 : model1 loss : 0.441242 model2 loss : 0.017815
[01:02:55.507] iteration 25140 : model1 loss : 0.439470 model2 loss : 0.017361
[01:02:55.689] iteration 25141 : model1 loss : 0.438010 model2 loss : 0.017393
[01:02:55.862] iteration 25142 : model1 loss : 0.441202 model2 loss : 0.018123
[01:02:56.043] iteration 25143 : model1 loss : 0.442802 model2 loss : 0.018695
[01:02:56.216] iteration 25144 : model1 loss : 0.439689 model2 loss : 0.017171
[01:02:56.382] iteration 25145 : model1 loss : 0.442434 model2 loss : 0.015262
[01:02:56.552] iteration 25146 : model1 loss : 0.439393 model2 loss : 0.016743
[01:02:56.725] iteration 25147 : model1 loss : 0.439839 model2 loss : 0.018618
[01:02:56.897] iteration 25148 : model1 loss : 0.439204 model2 loss : 0.018611
[01:02:57.078] iteration 25149 : model1 loss : 0.438310 model2 loss : 0.016663
[01:02:57.257] iteration 25150 : model1 loss : 0.436069 model2 loss : 0.018414
[01:02:57.455] iteration 25151 : model1 loss : 0.441210 model2 loss : 0.015812
[01:02:57.672] iteration 25152 : model1 loss : 0.440205 model2 loss : 0.016548
[01:02:57.842] iteration 25153 : model1 loss : 0.436330 model2 loss : 0.016069
[01:02:58.025] iteration 25154 : model1 loss : 0.442361 model2 loss : 0.018717
[01:02:58.199] iteration 25155 : model1 loss : 0.438791 model2 loss : 0.014259
[01:02:58.378] iteration 25156 : model1 loss : 0.442569 model2 loss : 0.016474
[01:02:58.585] iteration 25157 : model1 loss : 0.442987 model2 loss : 0.019598
[01:02:58.801] iteration 25158 : model1 loss : 0.433947 model2 loss : 0.017144
[01:03:00.869] iteration 25159 : model1 loss : 0.439919 model2 loss : 0.016598
[01:03:01.038] iteration 25160 : model1 loss : 0.435484 model2 loss : 0.016998
[01:03:01.207] iteration 25161 : model1 loss : 0.438196 model2 loss : 0.017169
[01:03:01.389] iteration 25162 : model1 loss : 0.437657 model2 loss : 0.016991
[01:03:01.567] iteration 25163 : model1 loss : 0.439439 model2 loss : 0.016498
[01:03:01.736] iteration 25164 : model1 loss : 0.439948 model2 loss : 0.016041
[01:03:01.918] iteration 25165 : model1 loss : 0.437935 model2 loss : 0.018372
[01:03:02.087] iteration 25166 : model1 loss : 0.439713 model2 loss : 0.015268
[01:03:02.255] iteration 25167 : model1 loss : 0.442047 model2 loss : 0.017068
[01:03:02.424] iteration 25168 : model1 loss : 0.435235 model2 loss : 0.016433
[01:03:02.600] iteration 25169 : model1 loss : 0.443794 model2 loss : 0.019479
[01:03:02.781] iteration 25170 : model1 loss : 0.439945 model2 loss : 0.018379
[01:03:03.018] iteration 25171 : model1 loss : 0.443182 model2 loss : 0.020292
[01:03:03.195] iteration 25172 : model1 loss : 0.440979 model2 loss : 0.017632
[01:03:03.374] iteration 25173 : model1 loss : 0.442343 model2 loss : 0.015898
[01:03:03.579] iteration 25174 : model1 loss : 0.436264 model2 loss : 0.016991
[01:03:03.748] iteration 25175 : model1 loss : 0.440145 model2 loss : 0.016897
[01:03:03.928] iteration 25176 : model1 loss : 0.442366 model2 loss : 0.018170
[01:03:04.115] iteration 25177 : model1 loss : 0.439864 model2 loss : 0.016896
[01:03:04.282] iteration 25178 : model1 loss : 0.445366 model2 loss : 0.018353
[01:03:04.455] iteration 25179 : model1 loss : 0.440061 model2 loss : 0.018704
[01:03:06.469] iteration 25180 : model1 loss : 0.442946 model2 loss : 0.017349
[01:03:06.676] iteration 25181 : model1 loss : 0.436583 model2 loss : 0.015048
[01:03:06.847] iteration 25182 : model1 loss : 0.438006 model2 loss : 0.017005
[01:03:07.024] iteration 25183 : model1 loss : 0.435190 model2 loss : 0.017555
[01:03:07.219] iteration 25184 : model1 loss : 0.443450 model2 loss : 0.018652
[01:03:07.398] iteration 25185 : model1 loss : 0.439211 model2 loss : 0.015332
[01:03:07.575] iteration 25186 : model1 loss : 0.436623 model2 loss : 0.016934
[01:03:07.745] iteration 25187 : model1 loss : 0.439686 model2 loss : 0.017763
[01:03:07.917] iteration 25188 : model1 loss : 0.441567 model2 loss : 0.018007
[01:03:08.087] iteration 25189 : model1 loss : 0.440808 model2 loss : 0.017950
[01:03:08.255] iteration 25190 : model1 loss : 0.440641 model2 loss : 0.016021
[01:03:08.429] iteration 25191 : model1 loss : 0.441265 model2 loss : 0.018079
[01:03:08.637] iteration 25192 : model1 loss : 0.439460 model2 loss : 0.018039
[01:03:08.853] iteration 25193 : model1 loss : 0.441403 model2 loss : 0.018849
[01:03:09.064] iteration 25194 : model1 loss : 0.439812 model2 loss : 0.014726
[01:03:09.241] iteration 25195 : model1 loss : 0.442759 model2 loss : 0.016583
[01:03:09.411] iteration 25196 : model1 loss : 0.439966 model2 loss : 0.016945
[01:03:09.578] iteration 25197 : model1 loss : 0.440160 model2 loss : 0.018191
[01:03:09.747] iteration 25198 : model1 loss : 0.437425 model2 loss : 0.017177
[01:03:09.915] iteration 25199 : model1 loss : 0.437295 model2 loss : 0.017134
[01:03:10.092] iteration 25200 : model1 loss : 0.439925 model2 loss : 0.016868
[01:03:12.140] iteration 25201 : model1 loss : 0.440698 model2 loss : 0.018441
[01:03:12.310] iteration 25202 : model1 loss : 0.438205 model2 loss : 0.016749
[01:03:12.487] iteration 25203 : model1 loss : 0.434353 model2 loss : 0.015659
[01:03:12.663] iteration 25204 : model1 loss : 0.440374 model2 loss : 0.016236
[01:03:12.831] iteration 25205 : model1 loss : 0.442649 model2 loss : 0.018359
[01:03:13.024] iteration 25206 : model1 loss : 0.438660 model2 loss : 0.016448
[01:03:13.217] iteration 25207 : model1 loss : 0.441587 model2 loss : 0.016603
[01:03:13.387] iteration 25208 : model1 loss : 0.440714 model2 loss : 0.016550
[01:03:13.557] iteration 25209 : model1 loss : 0.442255 model2 loss : 0.016737
[01:03:13.739] iteration 25210 : model1 loss : 0.438408 model2 loss : 0.017656
[01:03:13.926] iteration 25211 : model1 loss : 0.441441 model2 loss : 0.017062
[01:03:14.109] iteration 25212 : model1 loss : 0.438668 model2 loss : 0.018006
[01:03:14.291] iteration 25213 : model1 loss : 0.437917 model2 loss : 0.017860
[01:03:14.468] iteration 25214 : model1 loss : 0.440549 model2 loss : 0.018244
[01:03:14.646] iteration 25215 : model1 loss : 0.437315 model2 loss : 0.017980
[01:03:14.820] iteration 25216 : model1 loss : 0.438254 model2 loss : 0.016441
[01:03:15.002] iteration 25217 : model1 loss : 0.435647 model2 loss : 0.016077
[01:03:15.169] iteration 25218 : model1 loss : 0.437202 model2 loss : 0.015937
[01:03:15.341] iteration 25219 : model1 loss : 0.444032 model2 loss : 0.018872
[01:03:15.514] iteration 25220 : model1 loss : 0.443469 model2 loss : 0.017639
[01:03:15.683] iteration 25221 : model1 loss : 0.443481 model2 loss : 0.016543
[01:03:18.134] iteration 25222 : model1 loss : 0.441823 model2 loss : 0.016105
[01:03:18.310] iteration 25223 : model1 loss : 0.439738 model2 loss : 0.018543
[01:03:18.479] iteration 25224 : model1 loss : 0.439966 model2 loss : 0.015224
[01:03:18.650] iteration 25225 : model1 loss : 0.436284 model2 loss : 0.013904
[01:03:18.820] iteration 25226 : model1 loss : 0.437486 model2 loss : 0.016049
[01:03:18.994] iteration 25227 : model1 loss : 0.443359 model2 loss : 0.017616
[01:03:19.175] iteration 25228 : model1 loss : 0.437852 model2 loss : 0.017599
[01:03:19.403] iteration 25229 : model1 loss : 0.438615 model2 loss : 0.016688
[01:03:19.594] iteration 25230 : model1 loss : 0.444037 model2 loss : 0.017235
[01:03:19.767] iteration 25231 : model1 loss : 0.441524 model2 loss : 0.017336
[01:03:19.939] iteration 25232 : model1 loss : 0.440760 model2 loss : 0.018121
[01:03:20.163] iteration 25233 : model1 loss : 0.437068 model2 loss : 0.016670
[01:03:20.368] iteration 25234 : model1 loss : 0.435402 model2 loss : 0.015952
[01:03:20.539] iteration 25235 : model1 loss : 0.440269 model2 loss : 0.017110
[01:03:20.709] iteration 25236 : model1 loss : 0.443329 model2 loss : 0.017153
[01:03:20.891] iteration 25237 : model1 loss : 0.440727 model2 loss : 0.017458
[01:03:21.085] iteration 25238 : model1 loss : 0.440480 model2 loss : 0.016031
[01:03:21.280] iteration 25239 : model1 loss : 0.441314 model2 loss : 0.019868
[01:03:21.452] iteration 25240 : model1 loss : 0.440618 model2 loss : 0.016931
[01:03:21.617] iteration 25241 : model1 loss : 0.440040 model2 loss : 0.016795
[01:03:21.785] iteration 25242 : model1 loss : 0.438972 model2 loss : 0.015721
[01:03:23.827] iteration 25243 : model1 loss : 0.441808 model2 loss : 0.017518
[01:03:24.003] iteration 25244 : model1 loss : 0.438103 model2 loss : 0.015833
[01:03:24.173] iteration 25245 : model1 loss : 0.438887 model2 loss : 0.017885
[01:03:24.378] iteration 25246 : model1 loss : 0.442630 model2 loss : 0.016229
[01:03:24.548] iteration 25247 : model1 loss : 0.440360 model2 loss : 0.017493
[01:03:24.716] iteration 25248 : model1 loss : 0.436535 model2 loss : 0.017252
[01:03:24.885] iteration 25249 : model1 loss : 0.436681 model2 loss : 0.017040
[01:03:25.056] iteration 25250 : model1 loss : 0.440283 model2 loss : 0.017753
[01:03:25.233] iteration 25251 : model1 loss : 0.441107 model2 loss : 0.018551
[01:03:25.406] iteration 25252 : model1 loss : 0.439109 model2 loss : 0.016492
[01:03:25.623] iteration 25253 : model1 loss : 0.443410 model2 loss : 0.017480
[01:03:25.829] iteration 25254 : model1 loss : 0.435058 model2 loss : 0.016154
[01:03:26.002] iteration 25255 : model1 loss : 0.438966 model2 loss : 0.016859
[01:03:26.172] iteration 25256 : model1 loss : 0.437084 model2 loss : 0.017252
[01:03:26.342] iteration 25257 : model1 loss : 0.439012 model2 loss : 0.016864
[01:03:26.513] iteration 25258 : model1 loss : 0.439866 model2 loss : 0.014378
[01:03:26.681] iteration 25259 : model1 loss : 0.441370 model2 loss : 0.018709
[01:03:26.907] iteration 25260 : model1 loss : 0.443708 model2 loss : 0.017404
[01:03:27.085] iteration 25261 : model1 loss : 0.447519 model2 loss : 0.018237
[01:03:27.252] iteration 25262 : model1 loss : 0.437967 model2 loss : 0.017312
[01:03:27.461] iteration 25263 : model1 loss : 0.435766 model2 loss : 0.018043
[01:03:29.460] iteration 25264 : model1 loss : 0.437272 model2 loss : 0.017948
[01:03:29.660] iteration 25265 : model1 loss : 0.437860 model2 loss : 0.017511
[01:03:29.828] iteration 25266 : model1 loss : 0.438341 model2 loss : 0.014841
[01:03:29.998] iteration 25267 : model1 loss : 0.436109 model2 loss : 0.015203
[01:03:30.198] iteration 25268 : model1 loss : 0.440914 model2 loss : 0.017677
[01:03:30.385] iteration 25269 : model1 loss : 0.438392 model2 loss : 0.016666
[01:03:30.554] iteration 25270 : model1 loss : 0.439942 model2 loss : 0.016537
[01:03:30.735] iteration 25271 : model1 loss : 0.439924 model2 loss : 0.016416
[01:03:30.915] iteration 25272 : model1 loss : 0.440854 model2 loss : 0.018830
[01:03:31.106] iteration 25273 : model1 loss : 0.439319 model2 loss : 0.016119
[01:03:31.341] iteration 25274 : model1 loss : 0.440367 model2 loss : 0.016674
[01:03:31.511] iteration 25275 : model1 loss : 0.436318 model2 loss : 0.017829
[01:03:31.679] iteration 25276 : model1 loss : 0.443213 model2 loss : 0.020140
[01:03:31.847] iteration 25277 : model1 loss : 0.434273 model2 loss : 0.015432
[01:03:32.073] iteration 25278 : model1 loss : 0.442466 model2 loss : 0.017613
[01:03:32.274] iteration 25279 : model1 loss : 0.446940 model2 loss : 0.015643
[01:03:32.493] iteration 25280 : model1 loss : 0.440913 model2 loss : 0.017078
[01:03:32.661] iteration 25281 : model1 loss : 0.438787 model2 loss : 0.017501
[01:03:32.832] iteration 25282 : model1 loss : 0.443536 model2 loss : 0.018628
[01:03:33.001] iteration 25283 : model1 loss : 0.436845 model2 loss : 0.017058
[01:03:33.170] iteration 25284 : model1 loss : 0.445362 model2 loss : 0.021659
[01:03:35.240] iteration 25285 : model1 loss : 0.440102 model2 loss : 0.017969
[01:03:35.414] iteration 25286 : model1 loss : 0.439746 model2 loss : 0.018330
[01:03:35.583] iteration 25287 : model1 loss : 0.440577 model2 loss : 0.017562
[01:03:35.752] iteration 25288 : model1 loss : 0.438273 model2 loss : 0.018162
[01:03:35.924] iteration 25289 : model1 loss : 0.441604 model2 loss : 0.019952
[01:03:36.094] iteration 25290 : model1 loss : 0.442427 model2 loss : 0.018773
[01:03:36.263] iteration 25291 : model1 loss : 0.440648 model2 loss : 0.015465
[01:03:36.431] iteration 25292 : model1 loss : 0.441569 model2 loss : 0.016091
[01:03:36.599] iteration 25293 : model1 loss : 0.442843 model2 loss : 0.017933
[01:03:36.817] iteration 25294 : model1 loss : 0.439180 model2 loss : 0.015898
[01:03:36.993] iteration 25295 : model1 loss : 0.439110 model2 loss : 0.017261
[01:03:37.167] iteration 25296 : model1 loss : 0.440784 model2 loss : 0.018314
[01:03:37.372] iteration 25297 : model1 loss : 0.433173 model2 loss : 0.016529
[01:03:37.540] iteration 25298 : model1 loss : 0.441042 model2 loss : 0.018064
[01:03:37.716] iteration 25299 : model1 loss : 0.439189 model2 loss : 0.015436
[01:03:37.917] iteration 25300 : model1 loss : 0.440205 model2 loss : 0.017106
[01:03:38.089] iteration 25301 : model1 loss : 0.436663 model2 loss : 0.016472
[01:03:38.265] iteration 25302 : model1 loss : 0.442001 model2 loss : 0.018089
[01:03:38.447] iteration 25303 : model1 loss : 0.442396 model2 loss : 0.016052
[01:03:38.626] iteration 25304 : model1 loss : 0.440868 model2 loss : 0.016562
[01:03:38.800] iteration 25305 : model1 loss : 0.436204 model2 loss : 0.015374
[01:03:40.854] iteration 25306 : model1 loss : 0.438808 model2 loss : 0.017779
[01:03:41.038] iteration 25307 : model1 loss : 0.438523 model2 loss : 0.017272
[01:03:41.210] iteration 25308 : model1 loss : 0.436498 model2 loss : 0.015967
[01:03:41.389] iteration 25309 : model1 loss : 0.444272 model2 loss : 0.018337
[01:03:41.563] iteration 25310 : model1 loss : 0.441912 model2 loss : 0.014124
[01:03:41.739] iteration 25311 : model1 loss : 0.440215 model2 loss : 0.018029
[01:03:41.913] iteration 25312 : model1 loss : 0.438825 model2 loss : 0.017315
[01:03:42.093] iteration 25313 : model1 loss : 0.441858 model2 loss : 0.019137
[01:03:42.271] iteration 25314 : model1 loss : 0.438974 model2 loss : 0.017619
[01:03:42.443] iteration 25315 : model1 loss : 0.440394 model2 loss : 0.015986
[01:03:42.612] iteration 25316 : model1 loss : 0.445307 model2 loss : 0.018111
[01:03:42.823] iteration 25317 : model1 loss : 0.438467 model2 loss : 0.016904
[01:03:42.996] iteration 25318 : model1 loss : 0.440607 model2 loss : 0.017280
[01:03:43.166] iteration 25319 : model1 loss : 0.437146 model2 loss : 0.016467
[01:03:43.334] iteration 25320 : model1 loss : 0.440301 model2 loss : 0.018645
[01:03:43.504] iteration 25321 : model1 loss : 0.439352 model2 loss : 0.017526
[01:03:43.672] iteration 25322 : model1 loss : 0.440217 model2 loss : 0.017834
[01:03:43.843] iteration 25323 : model1 loss : 0.441185 model2 loss : 0.018169
[01:03:44.022] iteration 25324 : model1 loss : 0.440587 model2 loss : 0.017149
[01:03:44.223] iteration 25325 : model1 loss : 0.435584 model2 loss : 0.017019
[01:03:44.436] iteration 25326 : model1 loss : 0.438121 model2 loss : 0.016561
[01:03:46.423] iteration 25327 : model1 loss : 0.440143 model2 loss : 0.016560
[01:03:46.602] iteration 25328 : model1 loss : 0.443737 model2 loss : 0.017199
[01:03:46.791] iteration 25329 : model1 loss : 0.438447 model2 loss : 0.016077
[01:03:46.969] iteration 25330 : model1 loss : 0.440297 model2 loss : 0.015771
[01:03:47.153] iteration 25331 : model1 loss : 0.438450 model2 loss : 0.016217
[01:03:47.347] iteration 25332 : model1 loss : 0.435595 model2 loss : 0.016651
[01:03:47.559] iteration 25333 : model1 loss : 0.441255 model2 loss : 0.014882
[01:03:47.730] iteration 25334 : model1 loss : 0.438321 model2 loss : 0.016846
[01:03:47.901] iteration 25335 : model1 loss : 0.441955 model2 loss : 0.016686
[01:03:48.070] iteration 25336 : model1 loss : 0.440898 model2 loss : 0.021107
[01:03:48.240] iteration 25337 : model1 loss : 0.439000 model2 loss : 0.018818
[01:03:48.409] iteration 25338 : model1 loss : 0.439948 model2 loss : 0.017886
[01:03:48.585] iteration 25339 : model1 loss : 0.440233 model2 loss : 0.018042
[01:03:48.790] iteration 25340 : model1 loss : 0.441728 model2 loss : 0.016156
[01:03:49.007] iteration 25341 : model1 loss : 0.438700 model2 loss : 0.015961
[01:03:49.178] iteration 25342 : model1 loss : 0.438643 model2 loss : 0.015985
[01:03:49.355] iteration 25343 : model1 loss : 0.440177 model2 loss : 0.018020
[01:03:49.563] iteration 25344 : model1 loss : 0.439446 model2 loss : 0.016925
[01:03:49.784] iteration 25345 : model1 loss : 0.436842 model2 loss : 0.017105
[01:03:49.951] iteration 25346 : model1 loss : 0.444741 model2 loss : 0.016802
[01:03:50.126] iteration 25347 : model1 loss : 0.440768 model2 loss : 0.017470
[01:03:52.156] iteration 25348 : model1 loss : 0.441013 model2 loss : 0.018104
[01:03:52.335] iteration 25349 : model1 loss : 0.440311 model2 loss : 0.015752
[01:03:52.520] iteration 25350 : model1 loss : 0.435801 model2 loss : 0.016017
[01:03:52.699] iteration 25351 : model1 loss : 0.443743 model2 loss : 0.017025
[01:03:52.877] iteration 25352 : model1 loss : 0.435118 model2 loss : 0.016085
[01:03:53.058] iteration 25353 : model1 loss : 0.440154 model2 loss : 0.014960
[01:03:53.229] iteration 25354 : model1 loss : 0.439968 model2 loss : 0.017964
[01:03:53.431] iteration 25355 : model1 loss : 0.437389 model2 loss : 0.016717
[01:03:53.610] iteration 25356 : model1 loss : 0.441355 model2 loss : 0.017302
[01:03:53.778] iteration 25357 : model1 loss : 0.445225 model2 loss : 0.018266
[01:03:53.960] iteration 25358 : model1 loss : 0.435490 model2 loss : 0.015965
[01:03:54.133] iteration 25359 : model1 loss : 0.441459 model2 loss : 0.016581
[01:03:54.344] iteration 25360 : model1 loss : 0.440897 model2 loss : 0.018083
[01:03:54.554] iteration 25361 : model1 loss : 0.438485 model2 loss : 0.017211
[01:03:54.766] iteration 25362 : model1 loss : 0.444023 model2 loss : 0.020438
[01:03:54.997] iteration 25363 : model1 loss : 0.433448 model2 loss : 0.015912
[01:03:55.206] iteration 25364 : model1 loss : 0.442929 model2 loss : 0.015774
[01:03:55.379] iteration 25365 : model1 loss : 0.439169 model2 loss : 0.014471
[01:03:55.549] iteration 25366 : model1 loss : 0.440503 model2 loss : 0.017618
[01:03:55.716] iteration 25367 : model1 loss : 0.441144 model2 loss : 0.015863
[01:03:55.885] iteration 25368 : model1 loss : 0.441042 model2 loss : 0.018566
[01:03:57.926] iteration 25369 : model1 loss : 0.438711 model2 loss : 0.017074
[01:03:58.096] iteration 25370 : model1 loss : 0.439393 model2 loss : 0.017359
[01:03:58.271] iteration 25371 : model1 loss : 0.434801 model2 loss : 0.017515
[01:03:58.439] iteration 25372 : model1 loss : 0.440373 model2 loss : 0.016423
[01:03:58.606] iteration 25373 : model1 loss : 0.441446 model2 loss : 0.018860
[01:03:58.776] iteration 25374 : model1 loss : 0.441045 model2 loss : 0.016143
[01:03:58.948] iteration 25375 : model1 loss : 0.438422 model2 loss : 0.018685
[01:03:59.130] iteration 25376 : model1 loss : 0.439768 model2 loss : 0.016400
[01:03:59.303] iteration 25377 : model1 loss : 0.442992 model2 loss : 0.020345
[01:03:59.525] iteration 25378 : model1 loss : 0.436860 model2 loss : 0.016063
[01:03:59.718] iteration 25379 : model1 loss : 0.442768 model2 loss : 0.017441
[01:03:59.887] iteration 25380 : model1 loss : 0.442596 model2 loss : 0.016186
[01:04:00.058] iteration 25381 : model1 loss : 0.437467 model2 loss : 0.017418
[01:04:00.234] iteration 25382 : model1 loss : 0.440032 model2 loss : 0.018686
[01:04:00.424] iteration 25383 : model1 loss : 0.440095 model2 loss : 0.016475
[01:04:00.660] iteration 25384 : model1 loss : 0.439454 model2 loss : 0.017641
[01:04:00.839] iteration 25385 : model1 loss : 0.438129 model2 loss : 0.016541
[01:04:01.013] iteration 25386 : model1 loss : 0.439966 model2 loss : 0.016423
[01:04:01.238] iteration 25387 : model1 loss : 0.443521 model2 loss : 0.017280
[01:04:01.432] iteration 25388 : model1 loss : 0.441226 model2 loss : 0.016062
[01:04:01.606] iteration 25389 : model1 loss : 0.439093 model2 loss : 0.020672
[01:04:03.708] iteration 25390 : model1 loss : 0.442390 model2 loss : 0.015524
[01:04:03.921] iteration 25391 : model1 loss : 0.440253 model2 loss : 0.016105
[01:04:04.091] iteration 25392 : model1 loss : 0.441097 model2 loss : 0.018116
[01:04:04.259] iteration 25393 : model1 loss : 0.441833 model2 loss : 0.017282
[01:04:04.428] iteration 25394 : model1 loss : 0.442565 model2 loss : 0.016914
[01:04:04.595] iteration 25395 : model1 loss : 0.435862 model2 loss : 0.017771
[01:04:04.763] iteration 25396 : model1 loss : 0.443709 model2 loss : 0.018447
[01:04:04.933] iteration 25397 : model1 loss : 0.436088 model2 loss : 0.017650
[01:04:05.110] iteration 25398 : model1 loss : 0.443767 model2 loss : 0.015659
[01:04:05.279] iteration 25399 : model1 loss : 0.438712 model2 loss : 0.017461
[01:04:05.446] iteration 25400 : model1 loss : 0.443858 model2 loss : 0.016720
[01:04:05.641] iteration 25401 : model1 loss : 0.440852 model2 loss : 0.016940
[01:04:05.826] iteration 25402 : model1 loss : 0.436232 model2 loss : 0.017048
[01:04:06.012] iteration 25403 : model1 loss : 0.435480 model2 loss : 0.016827
[01:04:06.191] iteration 25404 : model1 loss : 0.440109 model2 loss : 0.017659
[01:04:06.372] iteration 25405 : model1 loss : 0.438917 model2 loss : 0.016534
[01:04:06.553] iteration 25406 : model1 loss : 0.437057 model2 loss : 0.017674
[01:04:06.724] iteration 25407 : model1 loss : 0.436919 model2 loss : 0.016679
[01:04:06.907] iteration 25408 : model1 loss : 0.442953 model2 loss : 0.017177
[01:04:07.107] iteration 25409 : model1 loss : 0.438469 model2 loss : 0.016436
[01:04:07.275] iteration 25410 : model1 loss : 0.440175 model2 loss : 0.019379
[01:04:09.332] iteration 25411 : model1 loss : 0.439324 model2 loss : 0.018443
[01:04:09.512] iteration 25412 : model1 loss : 0.442724 model2 loss : 0.018915
[01:04:09.689] iteration 25413 : model1 loss : 0.439610 model2 loss : 0.015875
[01:04:09.867] iteration 25414 : model1 loss : 0.439553 model2 loss : 0.015267
[01:04:10.037] iteration 25415 : model1 loss : 0.441336 model2 loss : 0.019012
[01:04:10.205] iteration 25416 : model1 loss : 0.440081 model2 loss : 0.015300
[01:04:10.374] iteration 25417 : model1 loss : 0.438214 model2 loss : 0.015518
[01:04:10.540] iteration 25418 : model1 loss : 0.442510 model2 loss : 0.018076
[01:04:10.710] iteration 25419 : model1 loss : 0.441423 model2 loss : 0.017923
[01:04:10.880] iteration 25420 : model1 loss : 0.443589 model2 loss : 0.017803
[01:04:11.058] iteration 25421 : model1 loss : 0.435911 model2 loss : 0.015633
[01:04:11.233] iteration 25422 : model1 loss : 0.440603 model2 loss : 0.017455
[01:04:11.416] iteration 25423 : model1 loss : 0.440823 model2 loss : 0.017927
[01:04:11.594] iteration 25424 : model1 loss : 0.439928 model2 loss : 0.017765
[01:04:11.775] iteration 25425 : model1 loss : 0.437211 model2 loss : 0.017499
[01:04:11.955] iteration 25426 : model1 loss : 0.439350 model2 loss : 0.016706
[01:04:12.166] iteration 25427 : model1 loss : 0.436050 model2 loss : 0.014694
[01:04:12.336] iteration 25428 : model1 loss : 0.438541 model2 loss : 0.016120
[01:04:12.506] iteration 25429 : model1 loss : 0.438866 model2 loss : 0.016816
[01:04:12.673] iteration 25430 : model1 loss : 0.440395 model2 loss : 0.014416
[01:04:12.841] iteration 25431 : model1 loss : 0.440926 model2 loss : 0.018223
[01:04:14.885] iteration 25432 : model1 loss : 0.442323 model2 loss : 0.018675
[01:04:15.089] iteration 25433 : model1 loss : 0.439010 model2 loss : 0.017146
[01:04:15.271] iteration 25434 : model1 loss : 0.440099 model2 loss : 0.016173
[01:04:15.438] iteration 25435 : model1 loss : 0.438730 model2 loss : 0.017755
[01:04:15.606] iteration 25436 : model1 loss : 0.436986 model2 loss : 0.016555
[01:04:15.774] iteration 25437 : model1 loss : 0.442204 model2 loss : 0.018799
[01:04:15.943] iteration 25438 : model1 loss : 0.440501 model2 loss : 0.016325
[01:04:16.124] iteration 25439 : model1 loss : 0.436473 model2 loss : 0.016685
[01:04:16.310] iteration 25440 : model1 loss : 0.443095 model2 loss : 0.017757
[01:04:16.539] iteration 25441 : model1 loss : 0.439040 model2 loss : 0.016644
[01:04:16.714] iteration 25442 : model1 loss : 0.439334 model2 loss : 0.016118
[01:04:16.889] iteration 25443 : model1 loss : 0.439560 model2 loss : 0.017701
[01:04:17.106] iteration 25444 : model1 loss : 0.439549 model2 loss : 0.017170
[01:04:17.313] iteration 25445 : model1 loss : 0.434915 model2 loss : 0.016497
[01:04:17.487] iteration 25446 : model1 loss : 0.443043 model2 loss : 0.016731
[01:04:17.657] iteration 25447 : model1 loss : 0.434609 model2 loss : 0.016900
[01:04:17.822] iteration 25448 : model1 loss : 0.443576 model2 loss : 0.019342
[01:04:18.003] iteration 25449 : model1 loss : 0.443644 model2 loss : 0.019601
[01:04:18.175] iteration 25450 : model1 loss : 0.438402 model2 loss : 0.015754
[01:04:18.351] iteration 25451 : model1 loss : 0.438509 model2 loss : 0.016843
[01:04:18.518] iteration 25452 : model1 loss : 0.442111 model2 loss : 0.017952
[01:04:20.551] iteration 25453 : model1 loss : 0.438916 model2 loss : 0.016229
[01:04:20.724] iteration 25454 : model1 loss : 0.439453 model2 loss : 0.016843
[01:04:20.895] iteration 25455 : model1 loss : 0.440363 model2 loss : 0.019239
[01:04:21.064] iteration 25456 : model1 loss : 0.433863 model2 loss : 0.016344
[01:04:21.232] iteration 25457 : model1 loss : 0.444134 model2 loss : 0.018421
[01:04:21.401] iteration 25458 : model1 loss : 0.442207 model2 loss : 0.016906
[01:04:21.570] iteration 25459 : model1 loss : 0.438829 model2 loss : 0.016648
[01:04:21.738] iteration 25460 : model1 loss : 0.442796 model2 loss : 0.017601
[01:04:21.917] iteration 25461 : model1 loss : 0.440459 model2 loss : 0.018775
[01:04:22.095] iteration 25462 : model1 loss : 0.435334 model2 loss : 0.018885
[01:04:22.321] iteration 25463 : model1 loss : 0.438787 model2 loss : 0.018690
[01:04:22.557] iteration 25464 : model1 loss : 0.442499 model2 loss : 0.019625
[01:04:22.787] iteration 25465 : model1 loss : 0.442302 model2 loss : 0.018368
[01:04:22.958] iteration 25466 : model1 loss : 0.441877 model2 loss : 0.015945
[01:04:23.161] iteration 25467 : model1 loss : 0.441335 model2 loss : 0.015767
[01:04:23.332] iteration 25468 : model1 loss : 0.442033 model2 loss : 0.019560
[01:04:23.500] iteration 25469 : model1 loss : 0.436523 model2 loss : 0.018265
[01:04:23.687] iteration 25470 : model1 loss : 0.438642 model2 loss : 0.017529
[01:04:23.876] iteration 25471 : model1 loss : 0.438548 model2 loss : 0.018903
[01:04:24.063] iteration 25472 : model1 loss : 0.439894 model2 loss : 0.017608
[01:04:24.241] iteration 25473 : model1 loss : 0.442045 model2 loss : 0.016543
[01:04:26.243] iteration 25474 : model1 loss : 0.439331 model2 loss : 0.018525
[01:04:26.410] iteration 25475 : model1 loss : 0.443583 model2 loss : 0.019370
[01:04:26.580] iteration 25476 : model1 loss : 0.437390 model2 loss : 0.016152
[01:04:26.749] iteration 25477 : model1 loss : 0.438327 model2 loss : 0.017688
[01:04:26.919] iteration 25478 : model1 loss : 0.437421 model2 loss : 0.017254
[01:04:27.090] iteration 25479 : model1 loss : 0.436629 model2 loss : 0.017366
[01:04:27.261] iteration 25480 : model1 loss : 0.443541 model2 loss : 0.020073
[01:04:27.431] iteration 25481 : model1 loss : 0.437296 model2 loss : 0.023797
[01:04:27.609] iteration 25482 : model1 loss : 0.435410 model2 loss : 0.017760
[01:04:27.781] iteration 25483 : model1 loss : 0.440932 model2 loss : 0.018740
[01:04:27.950] iteration 25484 : model1 loss : 0.438459 model2 loss : 0.018136
[01:04:28.127] iteration 25485 : model1 loss : 0.442392 model2 loss : 0.017087
[01:04:28.306] iteration 25486 : model1 loss : 0.440881 model2 loss : 0.019819
[01:04:28.474] iteration 25487 : model1 loss : 0.442802 model2 loss : 0.020481
[01:04:28.642] iteration 25488 : model1 loss : 0.437570 model2 loss : 0.015024
[01:04:28.810] iteration 25489 : model1 loss : 0.445080 model2 loss : 0.022004
[01:04:28.985] iteration 25490 : model1 loss : 0.439606 model2 loss : 0.017643
[01:04:29.168] iteration 25491 : model1 loss : 0.438573 model2 loss : 0.018813
[01:04:29.344] iteration 25492 : model1 loss : 0.443597 model2 loss : 0.019527
[01:04:29.510] iteration 25493 : model1 loss : 0.442560 model2 loss : 0.018454
[01:04:29.678] iteration 25494 : model1 loss : 0.437054 model2 loss : 0.018864
[01:04:31.674] iteration 25495 : model1 loss : 0.438378 model2 loss : 0.018031
[01:04:31.851] iteration 25496 : model1 loss : 0.444731 model2 loss : 0.019106
[01:04:32.082] iteration 25497 : model1 loss : 0.441802 model2 loss : 0.020720
[01:04:32.275] iteration 25498 : model1 loss : 0.444294 model2 loss : 0.020960
[01:04:32.448] iteration 25499 : model1 loss : 0.443466 model2 loss : 0.018192
[01:04:32.620] iteration 25500 : model1 loss : 0.440763 model2 loss : 0.017984
[01:04:32.790] iteration 25501 : model1 loss : 0.439834 model2 loss : 0.018294
[01:04:32.970] iteration 25502 : model1 loss : 0.441951 model2 loss : 0.018555
[01:04:33.154] iteration 25503 : model1 loss : 0.436390 model2 loss : 0.019611
[01:04:33.341] iteration 25504 : model1 loss : 0.438029 model2 loss : 0.018347
[01:04:33.522] iteration 25505 : model1 loss : 0.441220 model2 loss : 0.015399
[01:04:33.701] iteration 25506 : model1 loss : 0.437565 model2 loss : 0.014370
[01:04:33.883] iteration 25507 : model1 loss : 0.438999 model2 loss : 0.018631
[01:04:34.054] iteration 25508 : model1 loss : 0.432852 model2 loss : 0.015191
[01:04:34.250] iteration 25509 : model1 loss : 0.441194 model2 loss : 0.018491
[01:04:34.434] iteration 25510 : model1 loss : 0.442117 model2 loss : 0.017264
[01:04:34.603] iteration 25511 : model1 loss : 0.432880 model2 loss : 0.018640
[01:04:34.772] iteration 25512 : model1 loss : 0.435132 model2 loss : 0.016005
[01:04:34.969] iteration 25513 : model1 loss : 0.441195 model2 loss : 0.018283
[01:04:35.144] iteration 25514 : model1 loss : 0.445405 model2 loss : 0.019273
[01:04:35.313] iteration 25515 : model1 loss : 0.442372 model2 loss : 0.017594
[01:04:37.347] iteration 25516 : model1 loss : 0.445649 model2 loss : 0.018581
[01:04:37.527] iteration 25517 : model1 loss : 0.439650 model2 loss : 0.018282
[01:04:37.695] iteration 25518 : model1 loss : 0.439307 model2 loss : 0.018802
[01:04:37.864] iteration 25519 : model1 loss : 0.442754 model2 loss : 0.016371
[01:04:38.043] iteration 25520 : model1 loss : 0.438836 model2 loss : 0.015806
[01:04:38.214] iteration 25521 : model1 loss : 0.441193 model2 loss : 0.019410
[01:04:38.388] iteration 25522 : model1 loss : 0.441624 model2 loss : 0.017768
[01:04:38.601] iteration 25523 : model1 loss : 0.440196 model2 loss : 0.016677
[01:04:38.806] iteration 25524 : model1 loss : 0.439492 model2 loss : 0.017735
[01:04:38.985] iteration 25525 : model1 loss : 0.440082 model2 loss : 0.018150
[01:04:39.213] iteration 25526 : model1 loss : 0.439814 model2 loss : 0.019353
[01:04:39.422] iteration 25527 : model1 loss : 0.437309 model2 loss : 0.017372
[01:04:39.597] iteration 25528 : model1 loss : 0.438546 model2 loss : 0.017449
[01:04:39.783] iteration 25529 : model1 loss : 0.438263 model2 loss : 0.018106
[01:04:40.010] iteration 25530 : model1 loss : 0.441192 model2 loss : 0.015794
[01:04:40.200] iteration 25531 : model1 loss : 0.440536 model2 loss : 0.018627
[01:04:40.371] iteration 25532 : model1 loss : 0.437231 model2 loss : 0.016573
[01:04:40.539] iteration 25533 : model1 loss : 0.441842 model2 loss : 0.019192
[01:04:40.715] iteration 25534 : model1 loss : 0.439216 model2 loss : 0.016675
[01:04:40.910] iteration 25535 : model1 loss : 0.438099 model2 loss : 0.014430
[01:04:41.127] iteration 25536 : model1 loss : 0.437612 model2 loss : 0.017249
[01:04:43.228] iteration 25537 : model1 loss : 0.443941 model2 loss : 0.018092
[01:04:43.421] iteration 25538 : model1 loss : 0.438233 model2 loss : 0.019232
[01:04:43.659] iteration 25539 : model1 loss : 0.434888 model2 loss : 0.016473
[01:04:43.892] iteration 25540 : model1 loss : 0.438428 model2 loss : 0.016914
[01:04:44.104] iteration 25541 : model1 loss : 0.441884 model2 loss : 0.018302
[01:04:44.274] iteration 25542 : model1 loss : 0.439374 model2 loss : 0.016232
[01:04:44.445] iteration 25543 : model1 loss : 0.442143 model2 loss : 0.018795
[01:04:44.615] iteration 25544 : model1 loss : 0.441666 model2 loss : 0.018016
[01:04:44.808] iteration 25545 : model1 loss : 0.441332 model2 loss : 0.017441
[01:04:44.998] iteration 25546 : model1 loss : 0.441021 model2 loss : 0.015332
[01:04:45.226] iteration 25547 : model1 loss : 0.443335 model2 loss : 0.017013
[01:04:45.395] iteration 25548 : model1 loss : 0.439995 model2 loss : 0.016470
[01:04:45.564] iteration 25549 : model1 loss : 0.435799 model2 loss : 0.015429
[01:04:45.753] iteration 25550 : model1 loss : 0.445616 model2 loss : 0.019246
[01:04:45.938] iteration 25551 : model1 loss : 0.440858 model2 loss : 0.017813
[01:04:46.119] iteration 25552 : model1 loss : 0.439606 model2 loss : 0.017663
[01:04:46.299] iteration 25553 : model1 loss : 0.436864 model2 loss : 0.017254
[01:04:46.479] iteration 25554 : model1 loss : 0.436208 model2 loss : 0.016942
[01:04:46.650] iteration 25555 : model1 loss : 0.439262 model2 loss : 0.017017
[01:04:46.822] iteration 25556 : model1 loss : 0.439554 model2 loss : 0.016427
[01:04:46.992] iteration 25557 : model1 loss : 0.439660 model2 loss : 0.018269
[01:04:48.998] iteration 25558 : model1 loss : 0.443816 model2 loss : 0.018867
[01:04:49.234] iteration 25559 : model1 loss : 0.439729 model2 loss : 0.017500
[01:04:49.415] iteration 25560 : model1 loss : 0.439846 model2 loss : 0.017082
[01:04:49.587] iteration 25561 : model1 loss : 0.437195 model2 loss : 0.016786
[01:04:49.794] iteration 25562 : model1 loss : 0.436715 model2 loss : 0.016129
[01:04:50.020] iteration 25563 : model1 loss : 0.440726 model2 loss : 0.015775
[01:04:50.204] iteration 25564 : model1 loss : 0.440111 model2 loss : 0.017852
[01:04:50.373] iteration 25565 : model1 loss : 0.443036 model2 loss : 0.020684
[01:04:50.549] iteration 25566 : model1 loss : 0.441284 model2 loss : 0.016476
[01:04:50.758] iteration 25567 : model1 loss : 0.434604 model2 loss : 0.016107
[01:04:50.984] iteration 25568 : model1 loss : 0.442284 model2 loss : 0.017526
[01:04:51.156] iteration 25569 : model1 loss : 0.436272 model2 loss : 0.018219
[01:04:51.327] iteration 25570 : model1 loss : 0.446139 model2 loss : 0.017851
[01:04:51.494] iteration 25571 : model1 loss : 0.440990 model2 loss : 0.017199
[01:04:51.664] iteration 25572 : model1 loss : 0.437201 model2 loss : 0.014734
[01:04:51.831] iteration 25573 : model1 loss : 0.442730 model2 loss : 0.016959
[01:04:52.017] iteration 25574 : model1 loss : 0.441274 model2 loss : 0.018945
[01:04:52.191] iteration 25575 : model1 loss : 0.438687 model2 loss : 0.017742
[01:04:52.368] iteration 25576 : model1 loss : 0.441408 model2 loss : 0.017147
[01:04:52.539] iteration 25577 : model1 loss : 0.437939 model2 loss : 0.017363
[01:04:52.709] iteration 25578 : model1 loss : 0.439929 model2 loss : 0.016478
[01:04:54.792] iteration 25579 : model1 loss : 0.437441 model2 loss : 0.016211
[01:04:54.960] iteration 25580 : model1 loss : 0.441813 model2 loss : 0.017768
[01:04:55.140] iteration 25581 : model1 loss : 0.439544 model2 loss : 0.018216
[01:04:55.348] iteration 25582 : model1 loss : 0.440598 model2 loss : 0.019266
[01:04:55.521] iteration 25583 : model1 loss : 0.445904 model2 loss : 0.017552
[01:04:55.689] iteration 25584 : model1 loss : 0.438021 model2 loss : 0.016876
[01:04:55.857] iteration 25585 : model1 loss : 0.443214 model2 loss : 0.018186
[01:04:56.027] iteration 25586 : model1 loss : 0.439699 model2 loss : 0.016146
[01:04:56.207] iteration 25587 : model1 loss : 0.439976 model2 loss : 0.018174
[01:04:56.399] iteration 25588 : model1 loss : 0.438489 model2 loss : 0.015517
[01:04:56.628] iteration 25589 : model1 loss : 0.441880 model2 loss : 0.017437
[01:04:56.799] iteration 25590 : model1 loss : 0.437049 model2 loss : 0.016360
[01:04:56.969] iteration 25591 : model1 loss : 0.436592 model2 loss : 0.017723
[01:04:57.141] iteration 25592 : model1 loss : 0.439625 model2 loss : 0.016325
[01:04:57.330] iteration 25593 : model1 loss : 0.440679 model2 loss : 0.018108
[01:04:57.524] iteration 25594 : model1 loss : 0.442905 model2 loss : 0.016759
[01:04:57.705] iteration 25595 : model1 loss : 0.439508 model2 loss : 0.016444
[01:04:57.915] iteration 25596 : model1 loss : 0.437928 model2 loss : 0.015031
[01:04:58.152] iteration 25597 : model1 loss : 0.436582 model2 loss : 0.018928
[01:04:58.356] iteration 25598 : model1 loss : 0.444098 model2 loss : 0.015838
[01:04:58.528] iteration 25599 : model1 loss : 0.436763 model2 loss : 0.016046
[01:05:00.613] iteration 25600 : model1 loss : 0.439953 model2 loss : 0.015970
[01:05:00.833] iteration 25601 : model1 loss : 0.438953 model2 loss : 0.016801
[01:05:01.061] iteration 25602 : model1 loss : 0.439268 model2 loss : 0.016710
[01:05:01.250] iteration 25603 : model1 loss : 0.440488 model2 loss : 0.019221
[01:05:01.419] iteration 25604 : model1 loss : 0.442050 model2 loss : 0.017691
[01:05:01.615] iteration 25605 : model1 loss : 0.438690 model2 loss : 0.019168
[01:05:01.800] iteration 25606 : model1 loss : 0.439664 model2 loss : 0.017654
[01:05:01.984] iteration 25607 : model1 loss : 0.441372 model2 loss : 0.017621
[01:05:02.163] iteration 25608 : model1 loss : 0.436856 model2 loss : 0.017166
[01:05:02.332] iteration 25609 : model1 loss : 0.442015 model2 loss : 0.017277
[01:05:02.505] iteration 25610 : model1 loss : 0.437056 model2 loss : 0.016315
[01:05:02.681] iteration 25611 : model1 loss : 0.437975 model2 loss : 0.017526
[01:05:02.887] iteration 25612 : model1 loss : 0.442942 model2 loss : 0.015877
[01:05:03.109] iteration 25613 : model1 loss : 0.440518 model2 loss : 0.019429
[01:05:03.286] iteration 25614 : model1 loss : 0.437043 model2 loss : 0.015506
[01:05:03.458] iteration 25615 : model1 loss : 0.438204 model2 loss : 0.017557
[01:05:03.630] iteration 25616 : model1 loss : 0.442048 model2 loss : 0.015741
[01:05:03.856] iteration 25617 : model1 loss : 0.436423 model2 loss : 0.016734
[01:05:04.046] iteration 25618 : model1 loss : 0.440157 model2 loss : 0.017739
[01:05:04.221] iteration 25619 : model1 loss : 0.444883 model2 loss : 0.019557
[01:05:04.387] iteration 25620 : model1 loss : 0.439253 model2 loss : 0.017126
[01:05:06.463] iteration 25621 : model1 loss : 0.439412 model2 loss : 0.019133
[01:05:06.686] iteration 25622 : model1 loss : 0.435027 model2 loss : 0.017242
[01:05:06.901] iteration 25623 : model1 loss : 0.442767 model2 loss : 0.019292
[01:05:07.137] iteration 25624 : model1 loss : 0.442958 model2 loss : 0.017541
[01:05:07.332] iteration 25625 : model1 loss : 0.439612 model2 loss : 0.015774
[01:05:07.503] iteration 25626 : model1 loss : 0.437190 model2 loss : 0.016031
[01:05:07.669] iteration 25627 : model1 loss : 0.440444 model2 loss : 0.017882
[01:05:07.843] iteration 25628 : model1 loss : 0.435384 model2 loss : 0.015629
[01:05:08.066] iteration 25629 : model1 loss : 0.441535 model2 loss : 0.018731
[01:05:08.253] iteration 25630 : model1 loss : 0.440062 model2 loss : 0.016636
[01:05:08.431] iteration 25631 : model1 loss : 0.442105 model2 loss : 0.018710
[01:05:08.611] iteration 25632 : model1 loss : 0.438467 model2 loss : 0.016593
[01:05:08.791] iteration 25633 : model1 loss : 0.440799 model2 loss : 0.018500
[01:05:08.961] iteration 25634 : model1 loss : 0.438240 model2 loss : 0.015707
[01:05:09.135] iteration 25635 : model1 loss : 0.443802 model2 loss : 0.018786
[01:05:09.310] iteration 25636 : model1 loss : 0.439827 model2 loss : 0.015112
[01:05:09.484] iteration 25637 : model1 loss : 0.441659 model2 loss : 0.019609
[01:05:09.652] iteration 25638 : model1 loss : 0.438252 model2 loss : 0.015980
[01:05:09.821] iteration 25639 : model1 loss : 0.442240 model2 loss : 0.018052
[01:05:09.987] iteration 25640 : model1 loss : 0.442427 model2 loss : 0.016721
[01:05:10.171] iteration 25641 : model1 loss : 0.439134 model2 loss : 0.016749
[01:05:12.296] iteration 25642 : model1 loss : 0.438773 model2 loss : 0.017792
[01:05:12.482] iteration 25643 : model1 loss : 0.439451 model2 loss : 0.017053
[01:05:12.655] iteration 25644 : model1 loss : 0.438246 model2 loss : 0.017836
[01:05:12.858] iteration 25645 : model1 loss : 0.437698 model2 loss : 0.015368
[01:05:13.037] iteration 25646 : model1 loss : 0.443009 model2 loss : 0.021500
[01:05:13.206] iteration 25647 : model1 loss : 0.437366 model2 loss : 0.016262
[01:05:13.387] iteration 25648 : model1 loss : 0.436458 model2 loss : 0.016781
[01:05:13.583] iteration 25649 : model1 loss : 0.439458 model2 loss : 0.016049
[01:05:13.767] iteration 25650 : model1 loss : 0.440672 model2 loss : 0.017468
[01:05:13.948] iteration 25651 : model1 loss : 0.443725 model2 loss : 0.017469
[01:05:14.125] iteration 25652 : model1 loss : 0.441568 model2 loss : 0.019105
[01:05:14.299] iteration 25653 : model1 loss : 0.440395 model2 loss : 0.017838
[01:05:14.468] iteration 25654 : model1 loss : 0.441113 model2 loss : 0.016058
[01:05:14.638] iteration 25655 : model1 loss : 0.436812 model2 loss : 0.017126
[01:05:14.806] iteration 25656 : model1 loss : 0.440806 model2 loss : 0.016818
[01:05:14.977] iteration 25657 : model1 loss : 0.441660 model2 loss : 0.016423
[01:05:15.150] iteration 25658 : model1 loss : 0.439285 model2 loss : 0.017305
[01:05:15.321] iteration 25659 : model1 loss : 0.436671 model2 loss : 0.021002
[01:05:15.489] iteration 25660 : model1 loss : 0.441350 model2 loss : 0.018200
[01:05:15.655] iteration 25661 : model1 loss : 0.443041 model2 loss : 0.017148
[01:05:15.832] iteration 25662 : model1 loss : 0.442642 model2 loss : 0.018987
[01:05:17.841] iteration 25663 : model1 loss : 0.439027 model2 loss : 0.016738
[01:05:18.011] iteration 25664 : model1 loss : 0.438923 model2 loss : 0.016401
[01:05:18.181] iteration 25665 : model1 loss : 0.443237 model2 loss : 0.018972
[01:05:18.350] iteration 25666 : model1 loss : 0.440090 model2 loss : 0.017136
[01:05:18.518] iteration 25667 : model1 loss : 0.441491 model2 loss : 0.020081
[01:05:18.686] iteration 25668 : model1 loss : 0.441042 model2 loss : 0.017697
[01:05:18.854] iteration 25669 : model1 loss : 0.443131 model2 loss : 0.016273
[01:05:19.025] iteration 25670 : model1 loss : 0.438933 model2 loss : 0.019143
[01:05:19.199] iteration 25671 : model1 loss : 0.433538 model2 loss : 0.019274
[01:05:19.371] iteration 25672 : model1 loss : 0.436882 model2 loss : 0.016799
[01:05:19.549] iteration 25673 : model1 loss : 0.437746 model2 loss : 0.016591
[01:05:19.719] iteration 25674 : model1 loss : 0.444487 model2 loss : 0.017903
[01:05:19.888] iteration 25675 : model1 loss : 0.438393 model2 loss : 0.016819
[01:05:20.058] iteration 25676 : model1 loss : 0.437833 model2 loss : 0.017750
[01:05:20.227] iteration 25677 : model1 loss : 0.439293 model2 loss : 0.018709
[01:05:20.395] iteration 25678 : model1 loss : 0.441898 model2 loss : 0.018756
[01:05:20.567] iteration 25679 : model1 loss : 0.438304 model2 loss : 0.018471
[01:05:20.738] iteration 25680 : model1 loss : 0.440036 model2 loss : 0.016133
[01:05:20.920] iteration 25681 : model1 loss : 0.443264 model2 loss : 0.016845
[01:05:21.097] iteration 25682 : model1 loss : 0.442514 model2 loss : 0.015562
[01:05:21.266] iteration 25683 : model1 loss : 0.441306 model2 loss : 0.018121
[01:05:23.247] iteration 25684 : model1 loss : 0.435910 model2 loss : 0.017631
[01:05:23.416] iteration 25685 : model1 loss : 0.436415 model2 loss : 0.016482
[01:05:23.586] iteration 25686 : model1 loss : 0.436941 model2 loss : 0.016752
[01:05:23.756] iteration 25687 : model1 loss : 0.441511 model2 loss : 0.017121
[01:05:23.926] iteration 25688 : model1 loss : 0.438802 model2 loss : 0.017204
[01:05:24.097] iteration 25689 : model1 loss : 0.437411 model2 loss : 0.016193
[01:05:24.266] iteration 25690 : model1 loss : 0.440234 model2 loss : 0.019902
[01:05:24.434] iteration 25691 : model1 loss : 0.441954 model2 loss : 0.020566
[01:05:24.622] iteration 25692 : model1 loss : 0.437599 model2 loss : 0.017453
[01:05:24.812] iteration 25693 : model1 loss : 0.441117 model2 loss : 0.017960
[01:05:24.987] iteration 25694 : model1 loss : 0.438667 model2 loss : 0.014653
[01:05:25.176] iteration 25695 : model1 loss : 0.441214 model2 loss : 0.016888
[01:05:25.358] iteration 25696 : model1 loss : 0.437104 model2 loss : 0.016339
[01:05:25.541] iteration 25697 : model1 loss : 0.442552 model2 loss : 0.017820
[01:05:25.736] iteration 25698 : model1 loss : 0.439849 model2 loss : 0.015089
[01:05:25.922] iteration 25699 : model1 loss : 0.440760 model2 loss : 0.016558
[01:05:26.117] iteration 25700 : model1 loss : 0.439947 model2 loss : 0.017559
[01:05:26.301] iteration 25701 : model1 loss : 0.439690 model2 loss : 0.016509
[01:05:26.484] iteration 25702 : model1 loss : 0.446371 model2 loss : 0.018699
[01:05:26.654] iteration 25703 : model1 loss : 0.442750 model2 loss : 0.019491
[01:05:26.829] iteration 25704 : model1 loss : 0.439478 model2 loss : 0.018120
[01:05:28.875] iteration 25705 : model1 loss : 0.443850 model2 loss : 0.018114
[01:05:29.051] iteration 25706 : model1 loss : 0.443095 model2 loss : 0.016166
[01:05:29.232] iteration 25707 : model1 loss : 0.439541 model2 loss : 0.017526
[01:05:29.415] iteration 25708 : model1 loss : 0.441962 model2 loss : 0.016681
[01:05:29.591] iteration 25709 : model1 loss : 0.442393 model2 loss : 0.020128
[01:05:29.772] iteration 25710 : model1 loss : 0.437970 model2 loss : 0.016769
[01:05:29.971] iteration 25711 : model1 loss : 0.436303 model2 loss : 0.016120
[01:05:30.157] iteration 25712 : model1 loss : 0.439633 model2 loss : 0.015002
[01:05:30.327] iteration 25713 : model1 loss : 0.438945 model2 loss : 0.016757
[01:05:30.506] iteration 25714 : model1 loss : 0.442422 model2 loss : 0.018157
[01:05:30.713] iteration 25715 : model1 loss : 0.441915 model2 loss : 0.018860
[01:05:30.903] iteration 25716 : model1 loss : 0.441231 model2 loss : 0.018550
[01:05:31.099] iteration 25717 : model1 loss : 0.441722 model2 loss : 0.015474
[01:05:31.280] iteration 25718 : model1 loss : 0.440060 model2 loss : 0.017389
[01:05:31.452] iteration 25719 : model1 loss : 0.438905 model2 loss : 0.017199
[01:05:31.622] iteration 25720 : model1 loss : 0.430962 model2 loss : 0.016541
[01:05:31.791] iteration 25721 : model1 loss : 0.435386 model2 loss : 0.014884
[01:05:31.960] iteration 25722 : model1 loss : 0.439721 model2 loss : 0.017501
[01:05:32.147] iteration 25723 : model1 loss : 0.444428 model2 loss : 0.017167
[01:05:32.331] iteration 25724 : model1 loss : 0.442124 model2 loss : 0.017843
[01:05:32.513] iteration 25725 : model1 loss : 0.436929 model2 loss : 0.016706
[01:05:34.541] iteration 25726 : model1 loss : 0.442196 model2 loss : 0.018235
[01:05:34.721] iteration 25727 : model1 loss : 0.436594 model2 loss : 0.016318
[01:05:34.899] iteration 25728 : model1 loss : 0.443668 model2 loss : 0.018320
[01:05:35.076] iteration 25729 : model1 loss : 0.439450 model2 loss : 0.016438
[01:05:35.274] iteration 25730 : model1 loss : 0.442496 model2 loss : 0.017836
[01:05:35.444] iteration 25731 : model1 loss : 0.441209 model2 loss : 0.017599
[01:05:35.631] iteration 25732 : model1 loss : 0.442153 model2 loss : 0.017049
[01:05:35.821] iteration 25733 : model1 loss : 0.438996 model2 loss : 0.018314
[01:05:36.017] iteration 25734 : model1 loss : 0.437829 model2 loss : 0.016183
[01:05:36.196] iteration 25735 : model1 loss : 0.442014 model2 loss : 0.017859
[01:05:36.392] iteration 25736 : model1 loss : 0.441066 model2 loss : 0.016645
[01:05:36.585] iteration 25737 : model1 loss : 0.441064 model2 loss : 0.018123
[01:05:36.772] iteration 25738 : model1 loss : 0.442764 model2 loss : 0.017905
[01:05:36.943] iteration 25739 : model1 loss : 0.440065 model2 loss : 0.017163
[01:05:37.116] iteration 25740 : model1 loss : 0.435058 model2 loss : 0.016904
[01:05:37.288] iteration 25741 : model1 loss : 0.435773 model2 loss : 0.016883
[01:05:37.470] iteration 25742 : model1 loss : 0.439803 model2 loss : 0.016683
[01:05:37.643] iteration 25743 : model1 loss : 0.432613 model2 loss : 0.016080
[01:05:37.814] iteration 25744 : model1 loss : 0.443453 model2 loss : 0.016327
[01:05:37.980] iteration 25745 : model1 loss : 0.441243 model2 loss : 0.016861
[01:05:38.150] iteration 25746 : model1 loss : 0.437813 model2 loss : 0.016532
[01:05:40.105] iteration 25747 : model1 loss : 0.441118 model2 loss : 0.017762
[01:05:40.276] iteration 25748 : model1 loss : 0.442451 model2 loss : 0.016651
[01:05:40.451] iteration 25749 : model1 loss : 0.435776 model2 loss : 0.015405
[01:05:40.631] iteration 25750 : model1 loss : 0.438320 model2 loss : 0.017075
[01:05:40.849] iteration 25751 : model1 loss : 0.440065 model2 loss : 0.014206
[01:05:41.047] iteration 25752 : model1 loss : 0.442260 model2 loss : 0.017697
[01:05:41.215] iteration 25753 : model1 loss : 0.442968 model2 loss : 0.016704
[01:05:41.384] iteration 25754 : model1 loss : 0.443018 model2 loss : 0.018848
[01:05:41.555] iteration 25755 : model1 loss : 0.439327 model2 loss : 0.016030
[01:05:41.724] iteration 25756 : model1 loss : 0.438353 model2 loss : 0.016255
[01:05:41.903] iteration 25757 : model1 loss : 0.441055 model2 loss : 0.019863
[01:05:42.086] iteration 25758 : model1 loss : 0.436217 model2 loss : 0.015484
[01:05:42.266] iteration 25759 : model1 loss : 0.441097 model2 loss : 0.017894
[01:05:42.449] iteration 25760 : model1 loss : 0.439844 model2 loss : 0.016828
[01:05:42.627] iteration 25761 : model1 loss : 0.444281 model2 loss : 0.017882
[01:05:42.796] iteration 25762 : model1 loss : 0.442535 model2 loss : 0.016861
[01:05:42.979] iteration 25763 : model1 loss : 0.436197 model2 loss : 0.015674
[01:05:43.154] iteration 25764 : model1 loss : 0.439788 model2 loss : 0.017860
[01:05:43.326] iteration 25765 : model1 loss : 0.435626 model2 loss : 0.016593
[01:05:43.505] iteration 25766 : model1 loss : 0.437541 model2 loss : 0.016600
[01:05:43.684] iteration 25767 : model1 loss : 0.440008 model2 loss : 0.017089
[01:05:45.709] iteration 25768 : model1 loss : 0.441027 model2 loss : 0.015815
[01:05:45.893] iteration 25769 : model1 loss : 0.442612 model2 loss : 0.014026
[01:05:46.087] iteration 25770 : model1 loss : 0.439609 model2 loss : 0.018107
[01:05:46.268] iteration 25771 : model1 loss : 0.434500 model2 loss : 0.016022
[01:05:46.437] iteration 25772 : model1 loss : 0.435325 model2 loss : 0.015227
[01:05:46.606] iteration 25773 : model1 loss : 0.440839 model2 loss : 0.016802
[01:05:46.794] iteration 25774 : model1 loss : 0.441904 model2 loss : 0.017761
[01:05:46.980] iteration 25775 : model1 loss : 0.445417 model2 loss : 0.018256
[01:05:47.159] iteration 25776 : model1 loss : 0.440307 model2 loss : 0.018648
[01:05:47.328] iteration 25777 : model1 loss : 0.436712 model2 loss : 0.016989
[01:05:47.519] iteration 25778 : model1 loss : 0.439065 model2 loss : 0.017762
[01:05:47.690] iteration 25779 : model1 loss : 0.443644 model2 loss : 0.016991
[01:05:47.859] iteration 25780 : model1 loss : 0.440483 model2 loss : 0.020190
[01:05:48.035] iteration 25781 : model1 loss : 0.434607 model2 loss : 0.016388
[01:05:48.211] iteration 25782 : model1 loss : 0.437678 model2 loss : 0.016756
[01:05:48.389] iteration 25783 : model1 loss : 0.440338 model2 loss : 0.016900
[01:05:48.558] iteration 25784 : model1 loss : 0.443213 model2 loss : 0.016540
[01:05:48.727] iteration 25785 : model1 loss : 0.440652 model2 loss : 0.018053
[01:05:48.897] iteration 25786 : model1 loss : 0.439783 model2 loss : 0.017542
[01:05:49.064] iteration 25787 : model1 loss : 0.438774 model2 loss : 0.016450
[01:05:49.232] iteration 25788 : model1 loss : 0.442589 model2 loss : 0.016121
[01:05:51.275] iteration 25789 : model1 loss : 0.439173 model2 loss : 0.018153
[01:05:51.477] iteration 25790 : model1 loss : 0.439521 model2 loss : 0.016987
[01:05:51.644] iteration 25791 : model1 loss : 0.439488 model2 loss : 0.016440
[01:05:51.812] iteration 25792 : model1 loss : 0.443896 model2 loss : 0.018790
[01:05:51.980] iteration 25793 : model1 loss : 0.442537 model2 loss : 0.018987
[01:05:52.150] iteration 25794 : model1 loss : 0.437403 model2 loss : 0.018602
[01:05:52.330] iteration 25795 : model1 loss : 0.440990 model2 loss : 0.015787
[01:05:52.505] iteration 25796 : model1 loss : 0.439454 model2 loss : 0.017137
[01:05:52.680] iteration 25797 : model1 loss : 0.437005 model2 loss : 0.016696
[01:05:52.847] iteration 25798 : model1 loss : 0.440404 model2 loss : 0.016300
[01:05:53.018] iteration 25799 : model1 loss : 0.440711 model2 loss : 0.015293
[01:05:53.196] iteration 25800 : model1 loss : 0.438973 model2 loss : 0.015173
[01:05:53.366] iteration 25801 : model1 loss : 0.439290 model2 loss : 0.018243
[01:05:53.532] iteration 25802 : model1 loss : 0.439088 model2 loss : 0.017022
[01:05:53.701] iteration 25803 : model1 loss : 0.440232 model2 loss : 0.016237
[01:05:53.875] iteration 25804 : model1 loss : 0.442156 model2 loss : 0.018528
[01:05:54.063] iteration 25805 : model1 loss : 0.440003 model2 loss : 0.017108
[01:05:54.230] iteration 25806 : model1 loss : 0.442633 model2 loss : 0.018855
[01:05:54.400] iteration 25807 : model1 loss : 0.441512 model2 loss : 0.017059
[01:05:54.593] iteration 25808 : model1 loss : 0.434054 model2 loss : 0.015590
[01:05:54.769] iteration 25809 : model1 loss : 0.443477 model2 loss : 0.016308
[01:05:56.748] iteration 25810 : model1 loss : 0.438451 model2 loss : 0.016935
[01:05:56.916] iteration 25811 : model1 loss : 0.438812 model2 loss : 0.016621
[01:05:57.085] iteration 25812 : model1 loss : 0.441711 model2 loss : 0.016562
[01:05:57.252] iteration 25813 : model1 loss : 0.438391 model2 loss : 0.016630
[01:05:57.427] iteration 25814 : model1 loss : 0.442873 model2 loss : 0.017861
[01:05:57.601] iteration 25815 : model1 loss : 0.444914 model2 loss : 0.017886
[01:05:57.773] iteration 25816 : model1 loss : 0.437908 model2 loss : 0.018370
[01:05:57.942] iteration 25817 : model1 loss : 0.440277 model2 loss : 0.016744
[01:05:58.118] iteration 25818 : model1 loss : 0.432298 model2 loss : 0.016766
[01:05:58.306] iteration 25819 : model1 loss : 0.440002 model2 loss : 0.017549
[01:05:58.485] iteration 25820 : model1 loss : 0.445560 model2 loss : 0.020319
[01:05:58.721] iteration 25821 : model1 loss : 0.436826 model2 loss : 0.016533
[01:05:58.898] iteration 25822 : model1 loss : 0.439135 model2 loss : 0.017427
[01:05:59.069] iteration 25823 : model1 loss : 0.436889 model2 loss : 0.016399
[01:05:59.236] iteration 25824 : model1 loss : 0.439761 model2 loss : 0.018076
[01:05:59.409] iteration 25825 : model1 loss : 0.441041 model2 loss : 0.016579
[01:05:59.576] iteration 25826 : model1 loss : 0.444983 model2 loss : 0.020925
[01:05:59.745] iteration 25827 : model1 loss : 0.442060 model2 loss : 0.017606
[01:05:59.914] iteration 25828 : model1 loss : 0.437511 model2 loss : 0.016846
[01:06:00.084] iteration 25829 : model1 loss : 0.441684 model2 loss : 0.016622
[01:06:00.250] iteration 25830 : model1 loss : 0.439761 model2 loss : 0.014893
[01:06:02.240] iteration 25831 : model1 loss : 0.445678 model2 loss : 0.018263
[01:06:02.425] iteration 25832 : model1 loss : 0.435362 model2 loss : 0.017123
[01:06:02.617] iteration 25833 : model1 loss : 0.439353 model2 loss : 0.017618
[01:06:02.803] iteration 25834 : model1 loss : 0.441811 model2 loss : 0.017015
[01:06:02.999] iteration 25835 : model1 loss : 0.442378 model2 loss : 0.018447
[01:06:03.168] iteration 25836 : model1 loss : 0.439837 model2 loss : 0.017936
[01:06:03.336] iteration 25837 : model1 loss : 0.441069 model2 loss : 0.015769
[01:06:03.504] iteration 25838 : model1 loss : 0.441269 model2 loss : 0.017372
[01:06:03.683] iteration 25839 : model1 loss : 0.443206 model2 loss : 0.018807
[01:06:03.851] iteration 25840 : model1 loss : 0.437270 model2 loss : 0.017319
[01:06:04.031] iteration 25841 : model1 loss : 0.439680 model2 loss : 0.016282
[01:06:04.211] iteration 25842 : model1 loss : 0.438933 model2 loss : 0.016151
[01:06:04.391] iteration 25843 : model1 loss : 0.437656 model2 loss : 0.017690
[01:06:04.575] iteration 25844 : model1 loss : 0.441464 model2 loss : 0.018235
[01:06:04.749] iteration 25845 : model1 loss : 0.437026 model2 loss : 0.016789
[01:06:04.922] iteration 25846 : model1 loss : 0.440494 model2 loss : 0.018493
[01:06:05.132] iteration 25847 : model1 loss : 0.442873 model2 loss : 0.015228
[01:06:05.304] iteration 25848 : model1 loss : 0.438579 model2 loss : 0.016968
[01:06:05.473] iteration 25849 : model1 loss : 0.436835 model2 loss : 0.018024
[01:06:05.639] iteration 25850 : model1 loss : 0.443457 model2 loss : 0.019967
[01:06:05.849] iteration 25851 : model1 loss : 0.437086 model2 loss : 0.015570
[01:06:07.879] iteration 25852 : model1 loss : 0.437044 model2 loss : 0.016565
[01:06:08.050] iteration 25853 : model1 loss : 0.445843 model2 loss : 0.019220
[01:06:08.219] iteration 25854 : model1 loss : 0.440456 model2 loss : 0.017826
[01:06:08.386] iteration 25855 : model1 loss : 0.436884 model2 loss : 0.018250
[01:06:08.558] iteration 25856 : model1 loss : 0.436878 model2 loss : 0.016205
[01:06:08.728] iteration 25857 : model1 loss : 0.441843 model2 loss : 0.017374
[01:06:08.897] iteration 25858 : model1 loss : 0.439874 model2 loss : 0.016544
[01:06:09.068] iteration 25859 : model1 loss : 0.441075 model2 loss : 0.017426
[01:06:09.241] iteration 25860 : model1 loss : 0.435524 model2 loss : 0.016851
[01:06:09.408] iteration 25861 : model1 loss : 0.435059 model2 loss : 0.016108
[01:06:09.583] iteration 25862 : model1 loss : 0.442591 model2 loss : 0.017233
[01:06:09.752] iteration 25863 : model1 loss : 0.439052 model2 loss : 0.017574
[01:06:09.921] iteration 25864 : model1 loss : 0.438786 model2 loss : 0.015798
[01:06:10.091] iteration 25865 : model1 loss : 0.438773 model2 loss : 0.017675
[01:06:10.259] iteration 25866 : model1 loss : 0.444909 model2 loss : 0.017824
[01:06:10.428] iteration 25867 : model1 loss : 0.445066 model2 loss : 0.020135
[01:06:10.596] iteration 25868 : model1 loss : 0.437813 model2 loss : 0.015866
[01:06:10.768] iteration 25869 : model1 loss : 0.440288 model2 loss : 0.019571
[01:06:10.941] iteration 25870 : model1 loss : 0.444667 model2 loss : 0.015175
[01:06:11.111] iteration 25871 : model1 loss : 0.442884 model2 loss : 0.016452
[01:06:11.290] iteration 25872 : model1 loss : 0.437573 model2 loss : 0.017484
[01:06:13.269] iteration 25873 : model1 loss : 0.438711 model2 loss : 0.016386
[01:06:13.443] iteration 25874 : model1 loss : 0.443249 model2 loss : 0.018377
[01:06:13.618] iteration 25875 : model1 loss : 0.443279 model2 loss : 0.018942
[01:06:13.788] iteration 25876 : model1 loss : 0.438311 model2 loss : 0.015939
[01:06:13.959] iteration 25877 : model1 loss : 0.437217 model2 loss : 0.016989
[01:06:14.141] iteration 25878 : model1 loss : 0.437636 model2 loss : 0.016249
[01:06:14.318] iteration 25879 : model1 loss : 0.440282 model2 loss : 0.018534
[01:06:14.485] iteration 25880 : model1 loss : 0.443053 model2 loss : 0.018757
[01:06:14.659] iteration 25881 : model1 loss : 0.438025 model2 loss : 0.017173
[01:06:14.830] iteration 25882 : model1 loss : 0.442577 model2 loss : 0.016507
[01:06:15.001] iteration 25883 : model1 loss : 0.436916 model2 loss : 0.018178
[01:06:15.175] iteration 25884 : model1 loss : 0.440828 model2 loss : 0.017462
[01:06:15.347] iteration 25885 : model1 loss : 0.440058 model2 loss : 0.017860
[01:06:15.579] iteration 25886 : model1 loss : 0.439312 model2 loss : 0.017893
[01:06:15.767] iteration 25887 : model1 loss : 0.437389 model2 loss : 0.017273
[01:06:15.943] iteration 25888 : model1 loss : 0.439588 model2 loss : 0.017061
[01:06:16.121] iteration 25889 : model1 loss : 0.443078 model2 loss : 0.017965
[01:06:16.291] iteration 25890 : model1 loss : 0.440590 model2 loss : 0.017397
[01:06:16.469] iteration 25891 : model1 loss : 0.440551 model2 loss : 0.017834
[01:06:16.636] iteration 25892 : model1 loss : 0.439417 model2 loss : 0.018865
[01:06:16.804] iteration 25893 : model1 loss : 0.445124 model2 loss : 0.017528
[01:06:18.820] iteration 25894 : model1 loss : 0.440123 model2 loss : 0.014629
[01:06:18.987] iteration 25895 : model1 loss : 0.441883 model2 loss : 0.017839
[01:06:19.158] iteration 25896 : model1 loss : 0.442104 model2 loss : 0.018272
[01:06:19.329] iteration 25897 : model1 loss : 0.441542 model2 loss : 0.017759
[01:06:19.511] iteration 25898 : model1 loss : 0.440291 model2 loss : 0.018121
[01:06:19.690] iteration 25899 : model1 loss : 0.441488 model2 loss : 0.016846
[01:06:19.872] iteration 25900 : model1 loss : 0.436771 model2 loss : 0.016967
[01:06:20.055] iteration 25901 : model1 loss : 0.441758 model2 loss : 0.018267
[01:06:20.225] iteration 25902 : model1 loss : 0.436869 model2 loss : 0.016130
[01:06:20.422] iteration 25903 : model1 loss : 0.441870 model2 loss : 0.017341
[01:06:20.606] iteration 25904 : model1 loss : 0.439915 model2 loss : 0.015296
[01:06:20.774] iteration 25905 : model1 loss : 0.436005 model2 loss : 0.015777
[01:06:20.944] iteration 25906 : model1 loss : 0.442443 model2 loss : 0.016785
[01:06:21.117] iteration 25907 : model1 loss : 0.438937 model2 loss : 0.017166
[01:06:21.286] iteration 25908 : model1 loss : 0.439730 model2 loss : 0.016740
[01:06:21.455] iteration 25909 : model1 loss : 0.437369 model2 loss : 0.016354
[01:06:21.624] iteration 25910 : model1 loss : 0.440986 model2 loss : 0.014366
[01:06:21.794] iteration 25911 : model1 loss : 0.442853 model2 loss : 0.016284
[01:06:21.981] iteration 25912 : model1 loss : 0.435551 model2 loss : 0.015765
[01:06:22.160] iteration 25913 : model1 loss : 0.438734 model2 loss : 0.018985
[01:06:22.340] iteration 25914 : model1 loss : 0.441340 model2 loss : 0.016108
[01:06:24.377] iteration 25915 : model1 loss : 0.437076 model2 loss : 0.015332
[01:06:24.546] iteration 25916 : model1 loss : 0.440385 model2 loss : 0.016862
[01:06:24.721] iteration 25917 : model1 loss : 0.436266 model2 loss : 0.015694
[01:06:24.890] iteration 25918 : model1 loss : 0.438946 model2 loss : 0.017452
[01:06:25.062] iteration 25919 : model1 loss : 0.441631 model2 loss : 0.017783
[01:06:25.236] iteration 25920 : model1 loss : 0.442914 model2 loss : 0.017395
[01:06:25.405] iteration 25921 : model1 loss : 0.441081 model2 loss : 0.015367
[01:06:25.604] iteration 25922 : model1 loss : 0.438960 model2 loss : 0.016779
[01:06:25.780] iteration 25923 : model1 loss : 0.440683 model2 loss : 0.016422
[01:06:25.952] iteration 25924 : model1 loss : 0.437563 model2 loss : 0.017103
[01:06:26.133] iteration 25925 : model1 loss : 0.439291 model2 loss : 0.016424
[01:06:26.302] iteration 25926 : model1 loss : 0.439104 model2 loss : 0.017677
[01:06:26.486] iteration 25927 : model1 loss : 0.442628 model2 loss : 0.019371
[01:06:26.683] iteration 25928 : model1 loss : 0.437615 model2 loss : 0.015382
[01:06:26.856] iteration 25929 : model1 loss : 0.439460 model2 loss : 0.017023
[01:06:27.025] iteration 25930 : model1 loss : 0.439079 model2 loss : 0.016813
[01:06:27.194] iteration 25931 : model1 loss : 0.433858 model2 loss : 0.015441
[01:06:27.361] iteration 25932 : model1 loss : 0.442853 model2 loss : 0.017843
[01:06:27.531] iteration 25933 : model1 loss : 0.446746 model2 loss : 0.019304
[01:06:27.697] iteration 25934 : model1 loss : 0.440801 model2 loss : 0.019470
[01:06:27.866] iteration 25935 : model1 loss : 0.440382 model2 loss : 0.018416
[01:06:29.860] iteration 25936 : model1 loss : 0.435288 model2 loss : 0.017364
[01:06:30.090] iteration 25937 : model1 loss : 0.441032 model2 loss : 0.016462
[01:06:30.259] iteration 25938 : model1 loss : 0.440916 model2 loss : 0.017565
[01:06:30.426] iteration 25939 : model1 loss : 0.446711 model2 loss : 0.021412
[01:06:30.600] iteration 25940 : model1 loss : 0.434350 model2 loss : 0.017521
[01:06:30.773] iteration 25941 : model1 loss : 0.439083 model2 loss : 0.016825
[01:06:31.006] iteration 25942 : model1 loss : 0.437840 model2 loss : 0.016411
[01:06:31.192] iteration 25943 : model1 loss : 0.442590 model2 loss : 0.018615
[01:06:31.361] iteration 25944 : model1 loss : 0.438027 model2 loss : 0.018414
[01:06:31.532] iteration 25945 : model1 loss : 0.443124 model2 loss : 0.018382
[01:06:31.701] iteration 25946 : model1 loss : 0.441480 model2 loss : 0.017537
[01:06:31.869] iteration 25947 : model1 loss : 0.440646 model2 loss : 0.015760
[01:06:32.039] iteration 25948 : model1 loss : 0.438501 model2 loss : 0.014808
[01:06:32.208] iteration 25949 : model1 loss : 0.437265 model2 loss : 0.015618
[01:06:32.381] iteration 25950 : model1 loss : 0.437137 model2 loss : 0.017309
[01:06:32.549] iteration 25951 : model1 loss : 0.443944 model2 loss : 0.018244
[01:06:32.719] iteration 25952 : model1 loss : 0.442230 model2 loss : 0.017287
[01:06:32.889] iteration 25953 : model1 loss : 0.443390 model2 loss : 0.018105
[01:06:33.061] iteration 25954 : model1 loss : 0.439384 model2 loss : 0.016483
[01:06:33.233] iteration 25955 : model1 loss : 0.438173 model2 loss : 0.016892
[01:06:33.417] iteration 25956 : model1 loss : 0.441393 model2 loss : 0.017397
[01:06:35.424] iteration 25957 : model1 loss : 0.441212 model2 loss : 0.018937
[01:06:35.608] iteration 25958 : model1 loss : 0.434436 model2 loss : 0.016681
[01:06:35.779] iteration 25959 : model1 loss : 0.441024 model2 loss : 0.016435
[01:06:35.948] iteration 25960 : model1 loss : 0.445297 model2 loss : 0.016624
[01:06:36.122] iteration 25961 : model1 loss : 0.441278 model2 loss : 0.017476
[01:06:36.292] iteration 25962 : model1 loss : 0.436667 model2 loss : 0.017496
[01:06:36.461] iteration 25963 : model1 loss : 0.439651 model2 loss : 0.017454
[01:06:36.629] iteration 25964 : model1 loss : 0.442087 model2 loss : 0.018824
[01:06:36.808] iteration 25965 : model1 loss : 0.436659 model2 loss : 0.017322
[01:06:36.979] iteration 25966 : model1 loss : 0.438322 model2 loss : 0.017380
[01:06:37.183] iteration 25967 : model1 loss : 0.439225 model2 loss : 0.017800
[01:06:37.350] iteration 25968 : model1 loss : 0.446143 model2 loss : 0.017756
[01:06:37.520] iteration 25969 : model1 loss : 0.434993 model2 loss : 0.017515
[01:06:37.688] iteration 25970 : model1 loss : 0.443784 model2 loss : 0.016757
[01:06:37.864] iteration 25971 : model1 loss : 0.438965 model2 loss : 0.017118
[01:06:38.038] iteration 25972 : model1 loss : 0.438554 model2 loss : 0.016235
[01:06:38.212] iteration 25973 : model1 loss : 0.446979 model2 loss : 0.016770
[01:06:38.386] iteration 25974 : model1 loss : 0.437521 model2 loss : 0.017186
[01:06:38.556] iteration 25975 : model1 loss : 0.440795 model2 loss : 0.014957
[01:06:38.726] iteration 25976 : model1 loss : 0.439691 model2 loss : 0.017491
[01:06:38.907] iteration 25977 : model1 loss : 0.436424 model2 loss : 0.015637
[01:06:40.937] iteration 25978 : model1 loss : 0.440434 model2 loss : 0.018936
[01:06:41.135] iteration 25979 : model1 loss : 0.441195 model2 loss : 0.015310
[01:06:41.314] iteration 25980 : model1 loss : 0.439224 model2 loss : 0.017633
[01:06:41.483] iteration 25981 : model1 loss : 0.440028 model2 loss : 0.018206
[01:06:41.657] iteration 25982 : model1 loss : 0.443312 model2 loss : 0.017111
[01:06:41.830] iteration 25983 : model1 loss : 0.440022 model2 loss : 0.016773
[01:06:42.005] iteration 25984 : model1 loss : 0.436843 model2 loss : 0.015504
[01:06:42.173] iteration 25985 : model1 loss : 0.442143 model2 loss : 0.018965
[01:06:42.346] iteration 25986 : model1 loss : 0.436617 model2 loss : 0.015875
[01:06:42.514] iteration 25987 : model1 loss : 0.438131 model2 loss : 0.017771
[01:06:42.683] iteration 25988 : model1 loss : 0.441669 model2 loss : 0.015456
[01:06:42.851] iteration 25989 : model1 loss : 0.441167 model2 loss : 0.016659
[01:06:43.028] iteration 25990 : model1 loss : 0.443798 model2 loss : 0.018955
[01:06:43.196] iteration 25991 : model1 loss : 0.439619 model2 loss : 0.017715
[01:06:43.368] iteration 25992 : model1 loss : 0.429972 model2 loss : 0.014866
[01:06:43.536] iteration 25993 : model1 loss : 0.436714 model2 loss : 0.015988
[01:06:43.703] iteration 25994 : model1 loss : 0.443151 model2 loss : 0.019231
[01:06:43.874] iteration 25995 : model1 loss : 0.442697 model2 loss : 0.018427
[01:06:44.061] iteration 25996 : model1 loss : 0.441908 model2 loss : 0.016670
[01:06:44.254] iteration 25997 : model1 loss : 0.441280 model2 loss : 0.017687
[01:06:44.474] iteration 25998 : model1 loss : 0.441660 model2 loss : 0.016350
[01:06:46.456] iteration 25999 : model1 loss : 0.441988 model2 loss : 0.018575
[01:06:46.626] iteration 26000 : model1 loss : 0.443146 model2 loss : 0.017317
[01:06:55.446] iteration 26000 : model1_mean_dice : 0.886186 model1_mean_hd95 : 3.414904
[01:07:04.358] iteration 26000 : model2_mean_dice : 0.880601 model2_mean_hd95 : 4.248446
[01:07:04.536] iteration 26001 : model1 loss : 0.438424 model2 loss : 0.015881
[01:07:04.714] iteration 26002 : model1 loss : 0.438286 model2 loss : 0.015806
[01:07:04.915] iteration 26003 : model1 loss : 0.438724 model2 loss : 0.018600
[01:07:05.087] iteration 26004 : model1 loss : 0.439822 model2 loss : 0.017237
[01:07:05.290] iteration 26005 : model1 loss : 0.439647 model2 loss : 0.017398
[01:07:05.491] iteration 26006 : model1 loss : 0.442314 model2 loss : 0.016142
[01:07:05.703] iteration 26007 : model1 loss : 0.437588 model2 loss : 0.017654
[01:07:05.899] iteration 26008 : model1 loss : 0.440347 model2 loss : 0.015387
[01:07:06.075] iteration 26009 : model1 loss : 0.441427 model2 loss : 0.017511
[01:07:06.240] iteration 26010 : model1 loss : 0.441093 model2 loss : 0.018909
[01:07:06.433] iteration 26011 : model1 loss : 0.441468 model2 loss : 0.017661
[01:07:06.643] iteration 26012 : model1 loss : 0.438107 model2 loss : 0.016327
[01:07:06.851] iteration 26013 : model1 loss : 0.441034 model2 loss : 0.015629
[01:07:07.069] iteration 26014 : model1 loss : 0.437403 model2 loss : 0.015998
[01:07:07.294] iteration 26015 : model1 loss : 0.441978 model2 loss : 0.019623
[01:07:07.475] iteration 26016 : model1 loss : 0.440926 model2 loss : 0.018578
[01:07:07.674] iteration 26017 : model1 loss : 0.438708 model2 loss : 0.016819
[01:07:07.839] iteration 26018 : model1 loss : 0.436235 model2 loss : 0.014868
[01:07:08.032] iteration 26019 : model1 loss : 0.438919 model2 loss : 0.017797
[01:07:10.094] iteration 26020 : model1 loss : 0.437708 model2 loss : 0.016972
[01:07:10.317] iteration 26021 : model1 loss : 0.439402 model2 loss : 0.015719
[01:07:10.540] iteration 26022 : model1 loss : 0.437863 model2 loss : 0.018086
[01:07:10.727] iteration 26023 : model1 loss : 0.442090 model2 loss : 0.016986
[01:07:10.959] iteration 26024 : model1 loss : 0.436622 model2 loss : 0.015799
[01:07:11.181] iteration 26025 : model1 loss : 0.440651 model2 loss : 0.016221
[01:07:11.405] iteration 26026 : model1 loss : 0.438918 model2 loss : 0.015260
[01:07:11.611] iteration 26027 : model1 loss : 0.437860 model2 loss : 0.018339
[01:07:11.795] iteration 26028 : model1 loss : 0.437439 model2 loss : 0.016456
[01:07:11.963] iteration 26029 : model1 loss : 0.443556 model2 loss : 0.017576
[01:07:12.132] iteration 26030 : model1 loss : 0.438785 model2 loss : 0.018276
[01:07:12.333] iteration 26031 : model1 loss : 0.440699 model2 loss : 0.017606
[01:07:12.508] iteration 26032 : model1 loss : 0.442650 model2 loss : 0.016751
[01:07:12.677] iteration 26033 : model1 loss : 0.434203 model2 loss : 0.017117
[01:07:12.884] iteration 26034 : model1 loss : 0.438116 model2 loss : 0.017016
[01:07:13.097] iteration 26035 : model1 loss : 0.444287 model2 loss : 0.018030
[01:07:13.305] iteration 26036 : model1 loss : 0.441209 model2 loss : 0.016525
[01:07:13.503] iteration 26037 : model1 loss : 0.438863 model2 loss : 0.015417
[01:07:13.672] iteration 26038 : model1 loss : 0.438549 model2 loss : 0.015102
[01:07:13.838] iteration 26039 : model1 loss : 0.443008 model2 loss : 0.019074
[01:07:14.051] iteration 26040 : model1 loss : 0.445858 model2 loss : 0.019819
[01:07:16.087] iteration 26041 : model1 loss : 0.444835 model2 loss : 0.018719
[01:07:16.258] iteration 26042 : model1 loss : 0.439216 model2 loss : 0.016004
[01:07:16.441] iteration 26043 : model1 loss : 0.438682 model2 loss : 0.017862
[01:07:16.622] iteration 26044 : model1 loss : 0.440716 model2 loss : 0.018838
[01:07:16.801] iteration 26045 : model1 loss : 0.436808 model2 loss : 0.015268
[01:07:17.007] iteration 26046 : model1 loss : 0.436453 model2 loss : 0.016301
[01:07:17.180] iteration 26047 : model1 loss : 0.439931 model2 loss : 0.017500
[01:07:17.348] iteration 26048 : model1 loss : 0.440259 model2 loss : 0.016759
[01:07:17.514] iteration 26049 : model1 loss : 0.440148 model2 loss : 0.018147
[01:07:17.681] iteration 26050 : model1 loss : 0.444516 model2 loss : 0.018346
[01:07:17.849] iteration 26051 : model1 loss : 0.446135 model2 loss : 0.019830
[01:07:18.022] iteration 26052 : model1 loss : 0.438829 model2 loss : 0.016652
[01:07:18.190] iteration 26053 : model1 loss : 0.445684 model2 loss : 0.018123
[01:07:18.360] iteration 26054 : model1 loss : 0.437965 model2 loss : 0.016716
[01:07:18.528] iteration 26055 : model1 loss : 0.436844 model2 loss : 0.016250
[01:07:18.695] iteration 26056 : model1 loss : 0.439709 model2 loss : 0.017426
[01:07:18.868] iteration 26057 : model1 loss : 0.437639 model2 loss : 0.016667
[01:07:19.061] iteration 26058 : model1 loss : 0.439990 model2 loss : 0.018088
[01:07:19.231] iteration 26059 : model1 loss : 0.439949 model2 loss : 0.016311
[01:07:19.404] iteration 26060 : model1 loss : 0.435382 model2 loss : 0.015874
[01:07:19.575] iteration 26061 : model1 loss : 0.439372 model2 loss : 0.016620
[01:07:21.587] iteration 26062 : model1 loss : 0.437974 model2 loss : 0.017089
[01:07:21.780] iteration 26063 : model1 loss : 0.439969 model2 loss : 0.015984
[01:07:21.949] iteration 26064 : model1 loss : 0.442405 model2 loss : 0.017743
[01:07:22.120] iteration 26065 : model1 loss : 0.436072 model2 loss : 0.016588
[01:07:22.289] iteration 26066 : model1 loss : 0.439999 model2 loss : 0.016508
[01:07:22.463] iteration 26067 : model1 loss : 0.439840 model2 loss : 0.017323
[01:07:22.632] iteration 26068 : model1 loss : 0.438186 model2 loss : 0.016227
[01:07:22.800] iteration 26069 : model1 loss : 0.439098 model2 loss : 0.018945
[01:07:22.967] iteration 26070 : model1 loss : 0.439940 model2 loss : 0.016783
[01:07:23.156] iteration 26071 : model1 loss : 0.440601 model2 loss : 0.016123
[01:07:23.325] iteration 26072 : model1 loss : 0.445274 model2 loss : 0.019697
[01:07:23.543] iteration 26073 : model1 loss : 0.439551 model2 loss : 0.016353
[01:07:23.736] iteration 26074 : model1 loss : 0.441647 model2 loss : 0.017229
[01:07:23.904] iteration 26075 : model1 loss : 0.435865 model2 loss : 0.018034
[01:07:24.072] iteration 26076 : model1 loss : 0.441266 model2 loss : 0.017630
[01:07:24.241] iteration 26077 : model1 loss : 0.442257 model2 loss : 0.015993
[01:07:24.414] iteration 26078 : model1 loss : 0.439309 model2 loss : 0.017794
[01:07:24.607] iteration 26079 : model1 loss : 0.443445 model2 loss : 0.016673
[01:07:24.834] iteration 26080 : model1 loss : 0.435716 model2 loss : 0.017297
[01:07:25.007] iteration 26081 : model1 loss : 0.441781 model2 loss : 0.016176
[01:07:25.182] iteration 26082 : model1 loss : 0.439250 model2 loss : 0.017353
[01:07:27.220] iteration 26083 : model1 loss : 0.438550 model2 loss : 0.016370
[01:07:27.389] iteration 26084 : model1 loss : 0.441307 model2 loss : 0.017513
[01:07:27.569] iteration 26085 : model1 loss : 0.444736 model2 loss : 0.018254
[01:07:27.742] iteration 26086 : model1 loss : 0.440682 model2 loss : 0.016359
[01:07:27.915] iteration 26087 : model1 loss : 0.440532 model2 loss : 0.018314
[01:07:28.085] iteration 26088 : model1 loss : 0.438846 model2 loss : 0.017855
[01:07:28.253] iteration 26089 : model1 loss : 0.437790 model2 loss : 0.016267
[01:07:28.431] iteration 26090 : model1 loss : 0.440253 model2 loss : 0.016832
[01:07:28.607] iteration 26091 : model1 loss : 0.439486 model2 loss : 0.015365
[01:07:28.775] iteration 26092 : model1 loss : 0.439639 model2 loss : 0.016554
[01:07:28.945] iteration 26093 : model1 loss : 0.444636 model2 loss : 0.015951
[01:07:29.115] iteration 26094 : model1 loss : 0.441188 model2 loss : 0.017603
[01:07:29.284] iteration 26095 : model1 loss : 0.437814 model2 loss : 0.016415
[01:07:29.450] iteration 26096 : model1 loss : 0.440363 model2 loss : 0.020145
[01:07:29.627] iteration 26097 : model1 loss : 0.432235 model2 loss : 0.016088
[01:07:29.808] iteration 26098 : model1 loss : 0.441627 model2 loss : 0.018010
[01:07:29.978] iteration 26099 : model1 loss : 0.442598 model2 loss : 0.018186
[01:07:30.157] iteration 26100 : model1 loss : 0.445326 model2 loss : 0.016942
[01:07:30.329] iteration 26101 : model1 loss : 0.438369 model2 loss : 0.017075
[01:07:30.495] iteration 26102 : model1 loss : 0.437717 model2 loss : 0.018076
[01:07:30.663] iteration 26103 : model1 loss : 0.438273 model2 loss : 0.015068
[01:07:32.683] iteration 26104 : model1 loss : 0.441878 model2 loss : 0.017530
[01:07:32.853] iteration 26105 : model1 loss : 0.439651 model2 loss : 0.016999
[01:07:33.022] iteration 26106 : model1 loss : 0.439804 model2 loss : 0.016545
[01:07:33.190] iteration 26107 : model1 loss : 0.440100 model2 loss : 0.018946
[01:07:33.358] iteration 26108 : model1 loss : 0.434290 model2 loss : 0.017010
[01:07:33.525] iteration 26109 : model1 loss : 0.440595 model2 loss : 0.017012
[01:07:33.694] iteration 26110 : model1 loss : 0.436378 model2 loss : 0.015785
[01:07:33.877] iteration 26111 : model1 loss : 0.442798 model2 loss : 0.018173
[01:07:34.052] iteration 26112 : model1 loss : 0.444592 model2 loss : 0.022943
[01:07:34.227] iteration 26113 : model1 loss : 0.439021 model2 loss : 0.016100
[01:07:34.399] iteration 26114 : model1 loss : 0.438562 model2 loss : 0.015985
[01:07:34.582] iteration 26115 : model1 loss : 0.440645 model2 loss : 0.016375
[01:07:34.768] iteration 26116 : model1 loss : 0.441521 model2 loss : 0.016917
[01:07:34.936] iteration 26117 : model1 loss : 0.438428 model2 loss : 0.016116
[01:07:35.109] iteration 26118 : model1 loss : 0.437961 model2 loss : 0.017440
[01:07:35.281] iteration 26119 : model1 loss : 0.438973 model2 loss : 0.017182
[01:07:35.454] iteration 26120 : model1 loss : 0.441134 model2 loss : 0.017098
[01:07:35.622] iteration 26121 : model1 loss : 0.441220 model2 loss : 0.016907
[01:07:35.815] iteration 26122 : model1 loss : 0.442728 model2 loss : 0.019007
[01:07:35.983] iteration 26123 : model1 loss : 0.439005 model2 loss : 0.016587
[01:07:36.153] iteration 26124 : model1 loss : 0.443842 model2 loss : 0.017676
[01:07:38.215] iteration 26125 : model1 loss : 0.434682 model2 loss : 0.016589
[01:07:38.384] iteration 26126 : model1 loss : 0.440062 model2 loss : 0.017929
[01:07:38.555] iteration 26127 : model1 loss : 0.438372 model2 loss : 0.016854
[01:07:38.733] iteration 26128 : model1 loss : 0.433015 model2 loss : 0.016527
[01:07:38.904] iteration 26129 : model1 loss : 0.438455 model2 loss : 0.016984
[01:07:39.074] iteration 26130 : model1 loss : 0.441162 model2 loss : 0.017082
[01:07:39.244] iteration 26131 : model1 loss : 0.442543 model2 loss : 0.018648
[01:07:39.410] iteration 26132 : model1 loss : 0.442388 model2 loss : 0.016810
[01:07:39.579] iteration 26133 : model1 loss : 0.443477 model2 loss : 0.018159
[01:07:39.763] iteration 26134 : model1 loss : 0.441890 model2 loss : 0.018695
[01:07:39.943] iteration 26135 : model1 loss : 0.442148 model2 loss : 0.018150
[01:07:40.118] iteration 26136 : model1 loss : 0.441753 model2 loss : 0.015322
[01:07:40.291] iteration 26137 : model1 loss : 0.441740 model2 loss : 0.016605
[01:07:40.460] iteration 26138 : model1 loss : 0.442994 model2 loss : 0.017129
[01:07:40.628] iteration 26139 : model1 loss : 0.439684 model2 loss : 0.015833
[01:07:40.833] iteration 26140 : model1 loss : 0.437390 model2 loss : 0.017282
[01:07:41.001] iteration 26141 : model1 loss : 0.438394 model2 loss : 0.016041
[01:07:41.177] iteration 26142 : model1 loss : 0.437273 model2 loss : 0.017277
[01:07:41.354] iteration 26143 : model1 loss : 0.445117 model2 loss : 0.018239
[01:07:41.531] iteration 26144 : model1 loss : 0.439287 model2 loss : 0.018734
[01:07:41.706] iteration 26145 : model1 loss : 0.442508 model2 loss : 0.018228
[01:07:43.750] iteration 26146 : model1 loss : 0.439837 model2 loss : 0.015124
[01:07:43.919] iteration 26147 : model1 loss : 0.441459 model2 loss : 0.016427
[01:07:44.089] iteration 26148 : model1 loss : 0.436256 model2 loss : 0.014367
[01:07:44.257] iteration 26149 : model1 loss : 0.439235 model2 loss : 0.016126
[01:07:44.431] iteration 26150 : model1 loss : 0.438137 model2 loss : 0.016935
[01:07:44.601] iteration 26151 : model1 loss : 0.443532 model2 loss : 0.019677
[01:07:44.770] iteration 26152 : model1 loss : 0.441562 model2 loss : 0.017183
[01:07:44.944] iteration 26153 : model1 loss : 0.438369 model2 loss : 0.016154
[01:07:45.120] iteration 26154 : model1 loss : 0.443151 model2 loss : 0.018916
[01:07:45.295] iteration 26155 : model1 loss : 0.436565 model2 loss : 0.015717
[01:07:45.468] iteration 26156 : model1 loss : 0.437323 model2 loss : 0.015801
[01:07:45.646] iteration 26157 : model1 loss : 0.438809 model2 loss : 0.016292
[01:07:45.824] iteration 26158 : model1 loss : 0.439785 model2 loss : 0.015768
[01:07:46.059] iteration 26159 : model1 loss : 0.438051 model2 loss : 0.015949
[01:07:46.240] iteration 26160 : model1 loss : 0.438635 model2 loss : 0.015836
[01:07:46.413] iteration 26161 : model1 loss : 0.436614 model2 loss : 0.016502
[01:07:46.624] iteration 26162 : model1 loss : 0.442420 model2 loss : 0.017498
[01:07:46.827] iteration 26163 : model1 loss : 0.440946 model2 loss : 0.016327
[01:07:46.995] iteration 26164 : model1 loss : 0.443334 model2 loss : 0.018145
[01:07:47.164] iteration 26165 : model1 loss : 0.439081 model2 loss : 0.018399
[01:07:47.333] iteration 26166 : model1 loss : 0.441510 model2 loss : 0.015795
[01:07:49.337] iteration 26167 : model1 loss : 0.440645 model2 loss : 0.017096
[01:07:49.509] iteration 26168 : model1 loss : 0.445471 model2 loss : 0.017970
[01:07:49.678] iteration 26169 : model1 loss : 0.431959 model2 loss : 0.014765
[01:07:49.848] iteration 26170 : model1 loss : 0.441693 model2 loss : 0.014862
[01:07:50.018] iteration 26171 : model1 loss : 0.440038 model2 loss : 0.015344
[01:07:50.188] iteration 26172 : model1 loss : 0.440493 model2 loss : 0.017756
[01:07:50.356] iteration 26173 : model1 loss : 0.440001 model2 loss : 0.017094
[01:07:50.524] iteration 26174 : model1 loss : 0.438093 model2 loss : 0.016437
[01:07:50.691] iteration 26175 : model1 loss : 0.438184 model2 loss : 0.016801
[01:07:50.862] iteration 26176 : model1 loss : 0.444168 model2 loss : 0.019633
[01:07:51.034] iteration 26177 : model1 loss : 0.438183 model2 loss : 0.016561
[01:07:51.203] iteration 26178 : model1 loss : 0.440888 model2 loss : 0.016894
[01:07:51.373] iteration 26179 : model1 loss : 0.439319 model2 loss : 0.016578
[01:07:51.540] iteration 26180 : model1 loss : 0.438008 model2 loss : 0.017336
[01:07:51.709] iteration 26181 : model1 loss : 0.434365 model2 loss : 0.014840
[01:07:51.876] iteration 26182 : model1 loss : 0.442222 model2 loss : 0.016515
[01:07:52.047] iteration 26183 : model1 loss : 0.445758 model2 loss : 0.016734
[01:07:52.216] iteration 26184 : model1 loss : 0.440919 model2 loss : 0.017751
[01:07:52.385] iteration 26185 : model1 loss : 0.439167 model2 loss : 0.016354
[01:07:52.551] iteration 26186 : model1 loss : 0.441381 model2 loss : 0.016820
[01:07:52.719] iteration 26187 : model1 loss : 0.434893 model2 loss : 0.015633
[01:07:54.725] iteration 26188 : model1 loss : 0.444716 model2 loss : 0.016586
[01:07:54.893] iteration 26189 : model1 loss : 0.438424 model2 loss : 0.015977
[01:07:55.128] iteration 26190 : model1 loss : 0.440520 model2 loss : 0.015313
[01:07:55.322] iteration 26191 : model1 loss : 0.439892 model2 loss : 0.018093
[01:07:55.506] iteration 26192 : model1 loss : 0.437893 model2 loss : 0.016068
[01:07:55.683] iteration 26193 : model1 loss : 0.435698 model2 loss : 0.015629
[01:07:55.890] iteration 26194 : model1 loss : 0.443260 model2 loss : 0.018301
[01:07:56.061] iteration 26195 : model1 loss : 0.441558 model2 loss : 0.017065
[01:07:56.229] iteration 26196 : model1 loss : 0.440072 model2 loss : 0.015064
[01:07:56.395] iteration 26197 : model1 loss : 0.438844 model2 loss : 0.018984
[01:07:56.564] iteration 26198 : model1 loss : 0.440763 model2 loss : 0.015061
[01:07:56.740] iteration 26199 : model1 loss : 0.443867 model2 loss : 0.017813
[01:07:56.910] iteration 26200 : model1 loss : 0.438945 model2 loss : 0.016951
[01:07:57.079] iteration 26201 : model1 loss : 0.437762 model2 loss : 0.016539
[01:07:57.247] iteration 26202 : model1 loss : 0.441811 model2 loss : 0.017787
[01:07:57.421] iteration 26203 : model1 loss : 0.436570 model2 loss : 0.017060
[01:07:57.594] iteration 26204 : model1 loss : 0.440284 model2 loss : 0.018588
[01:07:57.806] iteration 26205 : model1 loss : 0.441674 model2 loss : 0.019428
[01:07:58.004] iteration 26206 : model1 loss : 0.436168 model2 loss : 0.016237
[01:07:58.173] iteration 26207 : model1 loss : 0.439169 model2 loss : 0.015094
[01:07:58.339] iteration 26208 : model1 loss : 0.437514 model2 loss : 0.017442
[01:08:00.395] iteration 26209 : model1 loss : 0.441416 model2 loss : 0.017027
[01:08:00.565] iteration 26210 : model1 loss : 0.437248 model2 loss : 0.015496
[01:08:00.735] iteration 26211 : model1 loss : 0.441736 model2 loss : 0.018105
[01:08:00.909] iteration 26212 : model1 loss : 0.442295 model2 loss : 0.018550
[01:08:01.079] iteration 26213 : model1 loss : 0.437007 model2 loss : 0.017451
[01:08:01.247] iteration 26214 : model1 loss : 0.442834 model2 loss : 0.019805
[01:08:01.456] iteration 26215 : model1 loss : 0.440187 model2 loss : 0.018996
[01:08:01.628] iteration 26216 : model1 loss : 0.439033 model2 loss : 0.017511
[01:08:01.798] iteration 26217 : model1 loss : 0.437006 model2 loss : 0.017214
[01:08:01.966] iteration 26218 : model1 loss : 0.444525 model2 loss : 0.017798
[01:08:02.142] iteration 26219 : model1 loss : 0.437521 model2 loss : 0.016951
[01:08:02.314] iteration 26220 : model1 loss : 0.440326 model2 loss : 0.016799
[01:08:02.490] iteration 26221 : model1 loss : 0.444092 model2 loss : 0.017285
[01:08:02.658] iteration 26222 : model1 loss : 0.438515 model2 loss : 0.016496
[01:08:02.858] iteration 26223 : model1 loss : 0.440045 model2 loss : 0.017257
[01:08:03.032] iteration 26224 : model1 loss : 0.441967 model2 loss : 0.016873
[01:08:03.208] iteration 26225 : model1 loss : 0.439501 model2 loss : 0.016595
[01:08:03.377] iteration 26226 : model1 loss : 0.439045 model2 loss : 0.018297
[01:08:03.551] iteration 26227 : model1 loss : 0.437183 model2 loss : 0.017743
[01:08:03.724] iteration 26228 : model1 loss : 0.442548 model2 loss : 0.016957
[01:08:03.893] iteration 26229 : model1 loss : 0.442047 model2 loss : 0.017590
[01:08:05.941] iteration 26230 : model1 loss : 0.443669 model2 loss : 0.017387
[01:08:06.119] iteration 26231 : model1 loss : 0.441383 model2 loss : 0.018369
[01:08:06.289] iteration 26232 : model1 loss : 0.442822 model2 loss : 0.016548
[01:08:06.463] iteration 26233 : model1 loss : 0.441688 model2 loss : 0.016758
[01:08:06.636] iteration 26234 : model1 loss : 0.441499 model2 loss : 0.016258
[01:08:06.822] iteration 26235 : model1 loss : 0.444409 model2 loss : 0.019242
[01:08:07.000] iteration 26236 : model1 loss : 0.437517 model2 loss : 0.015911
[01:08:07.167] iteration 26237 : model1 loss : 0.440261 model2 loss : 0.015767
[01:08:07.339] iteration 26238 : model1 loss : 0.439938 model2 loss : 0.017302
[01:08:07.518] iteration 26239 : model1 loss : 0.441955 model2 loss : 0.016211
[01:08:07.716] iteration 26240 : model1 loss : 0.441906 model2 loss : 0.017211
[01:08:07.885] iteration 26241 : model1 loss : 0.440133 model2 loss : 0.015414
[01:08:08.057] iteration 26242 : model1 loss : 0.434203 model2 loss : 0.015743
[01:08:08.224] iteration 26243 : model1 loss : 0.436711 model2 loss : 0.017596
[01:08:08.393] iteration 26244 : model1 loss : 0.440120 model2 loss : 0.015362
[01:08:08.563] iteration 26245 : model1 loss : 0.439138 model2 loss : 0.015934
[01:08:08.769] iteration 26246 : model1 loss : 0.437419 model2 loss : 0.018257
[01:08:08.938] iteration 26247 : model1 loss : 0.437104 model2 loss : 0.018141
[01:08:09.109] iteration 26248 : model1 loss : 0.437197 model2 loss : 0.017243
[01:08:09.274] iteration 26249 : model1 loss : 0.440952 model2 loss : 0.018396
[01:08:09.443] iteration 26250 : model1 loss : 0.440551 model2 loss : 0.017240
[01:08:11.472] iteration 26251 : model1 loss : 0.439394 model2 loss : 0.016279
[01:08:11.639] iteration 26252 : model1 loss : 0.435077 model2 loss : 0.016748
[01:08:11.810] iteration 26253 : model1 loss : 0.442782 model2 loss : 0.018177
[01:08:11.982] iteration 26254 : model1 loss : 0.440359 model2 loss : 0.019344
[01:08:12.161] iteration 26255 : model1 loss : 0.439258 model2 loss : 0.016098
[01:08:12.335] iteration 26256 : model1 loss : 0.444708 model2 loss : 0.019776
[01:08:12.531] iteration 26257 : model1 loss : 0.444282 model2 loss : 0.018029
[01:08:12.707] iteration 26258 : model1 loss : 0.437130 model2 loss : 0.017068
[01:08:12.879] iteration 26259 : model1 loss : 0.437905 model2 loss : 0.017081
[01:08:13.050] iteration 26260 : model1 loss : 0.442559 model2 loss : 0.017616
[01:08:13.219] iteration 26261 : model1 loss : 0.438284 model2 loss : 0.017175
[01:08:13.419] iteration 26262 : model1 loss : 0.440376 model2 loss : 0.015653
[01:08:13.592] iteration 26263 : model1 loss : 0.437076 model2 loss : 0.014708
[01:08:13.759] iteration 26264 : model1 loss : 0.437974 model2 loss : 0.016863
[01:08:13.948] iteration 26265 : model1 loss : 0.437524 model2 loss : 0.016099
[01:08:14.125] iteration 26266 : model1 loss : 0.443045 model2 loss : 0.015785
[01:08:14.357] iteration 26267 : model1 loss : 0.441994 model2 loss : 0.016719
[01:08:14.544] iteration 26268 : model1 loss : 0.441529 model2 loss : 0.016855
[01:08:14.715] iteration 26269 : model1 loss : 0.437592 model2 loss : 0.015578
[01:08:14.888] iteration 26270 : model1 loss : 0.441098 model2 loss : 0.017277
[01:08:15.059] iteration 26271 : model1 loss : 0.439571 model2 loss : 0.016270
[01:08:17.462] iteration 26272 : model1 loss : 0.440155 model2 loss : 0.018008
[01:08:17.648] iteration 26273 : model1 loss : 0.439799 model2 loss : 0.014166
[01:08:17.824] iteration 26274 : model1 loss : 0.443429 model2 loss : 0.017879
[01:08:17.990] iteration 26275 : model1 loss : 0.443473 model2 loss : 0.020102
[01:08:18.159] iteration 26276 : model1 loss : 0.437096 model2 loss : 0.016467
[01:08:18.330] iteration 26277 : model1 loss : 0.441067 model2 loss : 0.014685
[01:08:18.501] iteration 26278 : model1 loss : 0.436012 model2 loss : 0.018272
[01:08:18.669] iteration 26279 : model1 loss : 0.438540 model2 loss : 0.017513
[01:08:18.839] iteration 26280 : model1 loss : 0.441568 model2 loss : 0.018051
[01:08:19.012] iteration 26281 : model1 loss : 0.440073 model2 loss : 0.017589
[01:08:19.189] iteration 26282 : model1 loss : 0.437358 model2 loss : 0.016323
[01:08:19.374] iteration 26283 : model1 loss : 0.439988 model2 loss : 0.016365
[01:08:19.554] iteration 26284 : model1 loss : 0.440391 model2 loss : 0.015720
[01:08:19.733] iteration 26285 : model1 loss : 0.439590 model2 loss : 0.016742
[01:08:19.915] iteration 26286 : model1 loss : 0.442507 model2 loss : 0.017417
[01:08:20.087] iteration 26287 : model1 loss : 0.436847 model2 loss : 0.016997
[01:08:20.262] iteration 26288 : model1 loss : 0.438383 model2 loss : 0.015842
[01:08:20.437] iteration 26289 : model1 loss : 0.439231 model2 loss : 0.016455
[01:08:20.619] iteration 26290 : model1 loss : 0.444918 model2 loss : 0.017647
[01:08:20.790] iteration 26291 : model1 loss : 0.441446 model2 loss : 0.015134
[01:08:20.968] iteration 26292 : model1 loss : 0.438122 model2 loss : 0.017882
[01:08:23.030] iteration 26293 : model1 loss : 0.445739 model2 loss : 0.018066
[01:08:23.204] iteration 26294 : model1 loss : 0.443752 model2 loss : 0.017425
[01:08:23.388] iteration 26295 : model1 loss : 0.442117 model2 loss : 0.020255
[01:08:23.554] iteration 26296 : model1 loss : 0.442571 model2 loss : 0.018107
[01:08:23.723] iteration 26297 : model1 loss : 0.438648 model2 loss : 0.017167
[01:08:23.896] iteration 26298 : model1 loss : 0.438589 model2 loss : 0.016615
[01:08:24.068] iteration 26299 : model1 loss : 0.437107 model2 loss : 0.015890
[01:08:24.236] iteration 26300 : model1 loss : 0.437851 model2 loss : 0.017032
[01:08:24.409] iteration 26301 : model1 loss : 0.442577 model2 loss : 0.016290
[01:08:24.576] iteration 26302 : model1 loss : 0.438642 model2 loss : 0.017453
[01:08:24.745] iteration 26303 : model1 loss : 0.437396 model2 loss : 0.015768
[01:08:24.919] iteration 26304 : model1 loss : 0.436925 model2 loss : 0.017663
[01:08:25.088] iteration 26305 : model1 loss : 0.437029 model2 loss : 0.016405
[01:08:25.256] iteration 26306 : model1 loss : 0.441553 model2 loss : 0.017890
[01:08:25.436] iteration 26307 : model1 loss : 0.439871 model2 loss : 0.016706
[01:08:25.603] iteration 26308 : model1 loss : 0.435090 model2 loss : 0.016027
[01:08:25.771] iteration 26309 : model1 loss : 0.441480 model2 loss : 0.016981
[01:08:25.942] iteration 26310 : model1 loss : 0.444615 model2 loss : 0.015268
[01:08:26.117] iteration 26311 : model1 loss : 0.440228 model2 loss : 0.014526
[01:08:26.283] iteration 26312 : model1 loss : 0.439437 model2 loss : 0.018015
[01:08:26.453] iteration 26313 : model1 loss : 0.437894 model2 loss : 0.016525
[01:08:28.497] iteration 26314 : model1 loss : 0.440848 model2 loss : 0.017724
[01:08:28.725] iteration 26315 : model1 loss : 0.442154 model2 loss : 0.018108
[01:08:28.925] iteration 26316 : model1 loss : 0.445077 model2 loss : 0.017517
[01:08:29.100] iteration 26317 : model1 loss : 0.436940 model2 loss : 0.015398
[01:08:29.268] iteration 26318 : model1 loss : 0.439398 model2 loss : 0.018192
[01:08:29.437] iteration 26319 : model1 loss : 0.445761 model2 loss : 0.018750
[01:08:29.606] iteration 26320 : model1 loss : 0.444156 model2 loss : 0.016068
[01:08:29.783] iteration 26321 : model1 loss : 0.438695 model2 loss : 0.016092
[01:08:29.959] iteration 26322 : model1 loss : 0.442065 model2 loss : 0.017683
[01:08:30.143] iteration 26323 : model1 loss : 0.441657 model2 loss : 0.016431
[01:08:30.326] iteration 26324 : model1 loss : 0.442231 model2 loss : 0.017758
[01:08:30.506] iteration 26325 : model1 loss : 0.441538 model2 loss : 0.018995
[01:08:30.687] iteration 26326 : model1 loss : 0.437572 model2 loss : 0.016618
[01:08:30.881] iteration 26327 : model1 loss : 0.444447 model2 loss : 0.018322
[01:08:31.063] iteration 26328 : model1 loss : 0.438436 model2 loss : 0.016399
[01:08:31.255] iteration 26329 : model1 loss : 0.433334 model2 loss : 0.016571
[01:08:31.437] iteration 26330 : model1 loss : 0.438457 model2 loss : 0.017240
[01:08:31.651] iteration 26331 : model1 loss : 0.433784 model2 loss : 0.016792
[01:08:31.821] iteration 26332 : model1 loss : 0.434994 model2 loss : 0.015775
[01:08:31.989] iteration 26333 : model1 loss : 0.440920 model2 loss : 0.017150
[01:08:32.186] iteration 26334 : model1 loss : 0.439849 model2 loss : 0.015698
[01:08:34.183] iteration 26335 : model1 loss : 0.441661 model2 loss : 0.016665
[01:08:34.351] iteration 26336 : model1 loss : 0.437726 model2 loss : 0.017816
[01:08:34.522] iteration 26337 : model1 loss : 0.437007 model2 loss : 0.016638
[01:08:34.689] iteration 26338 : model1 loss : 0.441183 model2 loss : 0.016632
[01:08:34.860] iteration 26339 : model1 loss : 0.437861 model2 loss : 0.016283
[01:08:35.028] iteration 26340 : model1 loss : 0.439397 model2 loss : 0.016738
[01:08:35.199] iteration 26341 : model1 loss : 0.443328 model2 loss : 0.016800
[01:08:35.373] iteration 26342 : model1 loss : 0.442053 model2 loss : 0.017472
[01:08:35.556] iteration 26343 : model1 loss : 0.438443 model2 loss : 0.014991
[01:08:35.789] iteration 26344 : model1 loss : 0.435925 model2 loss : 0.016613
[01:08:35.973] iteration 26345 : model1 loss : 0.441119 model2 loss : 0.018024
[01:08:36.148] iteration 26346 : model1 loss : 0.443053 model2 loss : 0.018246
[01:08:36.318] iteration 26347 : model1 loss : 0.438508 model2 loss : 0.015345
[01:08:36.485] iteration 26348 : model1 loss : 0.440946 model2 loss : 0.017458
[01:08:36.655] iteration 26349 : model1 loss : 0.441349 model2 loss : 0.015821
[01:08:36.822] iteration 26350 : model1 loss : 0.440997 model2 loss : 0.018097
[01:08:37.007] iteration 26351 : model1 loss : 0.436672 model2 loss : 0.016816
[01:08:37.193] iteration 26352 : model1 loss : 0.436638 model2 loss : 0.016850
[01:08:37.374] iteration 26353 : model1 loss : 0.441131 model2 loss : 0.015777
[01:08:37.552] iteration 26354 : model1 loss : 0.443550 model2 loss : 0.017454
[01:08:37.718] iteration 26355 : model1 loss : 0.441758 model2 loss : 0.017579
[01:08:39.722] iteration 26356 : model1 loss : 0.440759 model2 loss : 0.018692
[01:08:39.910] iteration 26357 : model1 loss : 0.439803 model2 loss : 0.018361
[01:08:40.095] iteration 26358 : model1 loss : 0.437158 model2 loss : 0.016612
[01:08:40.273] iteration 26359 : model1 loss : 0.444395 model2 loss : 0.019467
[01:08:40.459] iteration 26360 : model1 loss : 0.439495 model2 loss : 0.014081
[01:08:40.633] iteration 26361 : model1 loss : 0.437310 model2 loss : 0.017272
[01:08:40.812] iteration 26362 : model1 loss : 0.435663 model2 loss : 0.015877
[01:08:40.988] iteration 26363 : model1 loss : 0.439387 model2 loss : 0.016608
[01:08:41.170] iteration 26364 : model1 loss : 0.440090 model2 loss : 0.019337
[01:08:41.340] iteration 26365 : model1 loss : 0.443612 model2 loss : 0.016806
[01:08:41.509] iteration 26366 : model1 loss : 0.436327 model2 loss : 0.017431
[01:08:41.681] iteration 26367 : model1 loss : 0.438338 model2 loss : 0.017156
[01:08:41.850] iteration 26368 : model1 loss : 0.442333 model2 loss : 0.018392
[01:08:42.016] iteration 26369 : model1 loss : 0.437328 model2 loss : 0.015198
[01:08:42.187] iteration 26370 : model1 loss : 0.438585 model2 loss : 0.016535
[01:08:42.355] iteration 26371 : model1 loss : 0.441662 model2 loss : 0.017811
[01:08:42.523] iteration 26372 : model1 loss : 0.448437 model2 loss : 0.019169
[01:08:42.699] iteration 26373 : model1 loss : 0.441717 model2 loss : 0.017676
[01:08:42.881] iteration 26374 : model1 loss : 0.437118 model2 loss : 0.016034
[01:08:43.048] iteration 26375 : model1 loss : 0.444334 model2 loss : 0.018117
[01:08:43.215] iteration 26376 : model1 loss : 0.439490 model2 loss : 0.016781
[01:08:45.305] iteration 26377 : model1 loss : 0.437844 model2 loss : 0.016500
[01:08:45.479] iteration 26378 : model1 loss : 0.440227 model2 loss : 0.015534
[01:08:45.651] iteration 26379 : model1 loss : 0.436844 model2 loss : 0.016240
[01:08:45.818] iteration 26380 : model1 loss : 0.439331 model2 loss : 0.016127
[01:08:45.988] iteration 26381 : model1 loss : 0.440894 model2 loss : 0.016314
[01:08:46.161] iteration 26382 : model1 loss : 0.440539 model2 loss : 0.017742
[01:08:46.342] iteration 26383 : model1 loss : 0.441201 model2 loss : 0.016566
[01:08:46.519] iteration 26384 : model1 loss : 0.437811 model2 loss : 0.016948
[01:08:46.689] iteration 26385 : model1 loss : 0.445261 model2 loss : 0.018899
[01:08:46.857] iteration 26386 : model1 loss : 0.435879 model2 loss : 0.016461
[01:08:47.040] iteration 26387 : model1 loss : 0.439389 model2 loss : 0.014390
[01:08:47.217] iteration 26388 : model1 loss : 0.440144 model2 loss : 0.018641
[01:08:47.400] iteration 26389 : model1 loss : 0.438671 model2 loss : 0.017577
[01:08:47.580] iteration 26390 : model1 loss : 0.439096 model2 loss : 0.016810
[01:08:47.767] iteration 26391 : model1 loss : 0.441162 model2 loss : 0.016838
[01:08:47.949] iteration 26392 : model1 loss : 0.439721 model2 loss : 0.016964
[01:08:48.133] iteration 26393 : model1 loss : 0.443978 model2 loss : 0.016695
[01:08:48.303] iteration 26394 : model1 loss : 0.441624 model2 loss : 0.019549
[01:08:48.508] iteration 26395 : model1 loss : 0.442566 model2 loss : 0.018797
[01:08:48.676] iteration 26396 : model1 loss : 0.439395 model2 loss : 0.016726
[01:08:48.850] iteration 26397 : model1 loss : 0.442205 model2 loss : 0.015059
[01:08:50.914] iteration 26398 : model1 loss : 0.437534 model2 loss : 0.014739
[01:08:51.088] iteration 26399 : model1 loss : 0.437981 model2 loss : 0.016301
[01:08:51.271] iteration 26400 : model1 loss : 0.440527 model2 loss : 0.015933
[01:08:51.453] iteration 26401 : model1 loss : 0.440687 model2 loss : 0.016398
[01:08:51.630] iteration 26402 : model1 loss : 0.437636 model2 loss : 0.018031
[01:08:51.809] iteration 26403 : model1 loss : 0.438401 model2 loss : 0.015819
[01:08:51.980] iteration 26404 : model1 loss : 0.440969 model2 loss : 0.016191
[01:08:52.152] iteration 26405 : model1 loss : 0.439813 model2 loss : 0.015323
[01:08:52.325] iteration 26406 : model1 loss : 0.440953 model2 loss : 0.016776
[01:08:52.497] iteration 26407 : model1 loss : 0.441914 model2 loss : 0.017078
[01:08:52.665] iteration 26408 : model1 loss : 0.440842 model2 loss : 0.016480
[01:08:52.834] iteration 26409 : model1 loss : 0.442106 model2 loss : 0.016496
[01:08:53.003] iteration 26410 : model1 loss : 0.435327 model2 loss : 0.019259
[01:08:53.178] iteration 26411 : model1 loss : 0.439039 model2 loss : 0.017572
[01:08:53.347] iteration 26412 : model1 loss : 0.441693 model2 loss : 0.017901
[01:08:53.528] iteration 26413 : model1 loss : 0.440245 model2 loss : 0.018569
[01:08:53.705] iteration 26414 : model1 loss : 0.443293 model2 loss : 0.019344
[01:08:53.874] iteration 26415 : model1 loss : 0.441419 model2 loss : 0.017884
[01:08:54.042] iteration 26416 : model1 loss : 0.439109 model2 loss : 0.016808
[01:08:54.214] iteration 26417 : model1 loss : 0.436219 model2 loss : 0.015996
[01:08:54.382] iteration 26418 : model1 loss : 0.445904 model2 loss : 0.017398
[01:08:56.458] iteration 26419 : model1 loss : 0.442108 model2 loss : 0.015858
[01:08:56.634] iteration 26420 : model1 loss : 0.439237 model2 loss : 0.016563
[01:08:56.807] iteration 26421 : model1 loss : 0.441749 model2 loss : 0.018809
[01:08:56.976] iteration 26422 : model1 loss : 0.444197 model2 loss : 0.016338
[01:08:57.152] iteration 26423 : model1 loss : 0.438335 model2 loss : 0.017283
[01:08:57.321] iteration 26424 : model1 loss : 0.436908 model2 loss : 0.013946
[01:08:57.490] iteration 26425 : model1 loss : 0.441927 model2 loss : 0.017385
[01:08:57.664] iteration 26426 : model1 loss : 0.440524 model2 loss : 0.015625
[01:08:57.842] iteration 26427 : model1 loss : 0.437480 model2 loss : 0.015034
[01:08:58.009] iteration 26428 : model1 loss : 0.441591 model2 loss : 0.017192
[01:08:58.187] iteration 26429 : model1 loss : 0.436148 model2 loss : 0.015371
[01:08:58.359] iteration 26430 : model1 loss : 0.444638 model2 loss : 0.018817
[01:08:58.528] iteration 26431 : model1 loss : 0.444623 model2 loss : 0.019320
[01:08:58.705] iteration 26432 : model1 loss : 0.439042 model2 loss : 0.018006
[01:08:58.882] iteration 26433 : model1 loss : 0.440940 model2 loss : 0.018094
[01:08:59.115] iteration 26434 : model1 loss : 0.437772 model2 loss : 0.015942
[01:08:59.296] iteration 26435 : model1 loss : 0.438624 model2 loss : 0.017248
[01:08:59.475] iteration 26436 : model1 loss : 0.438021 model2 loss : 0.015873
[01:08:59.660] iteration 26437 : model1 loss : 0.438471 model2 loss : 0.016531
[01:08:59.840] iteration 26438 : model1 loss : 0.439914 model2 loss : 0.017097
[01:09:00.019] iteration 26439 : model1 loss : 0.438956 model2 loss : 0.016282
[01:09:02.035] iteration 26440 : model1 loss : 0.436451 model2 loss : 0.017294
[01:09:02.210] iteration 26441 : model1 loss : 0.442646 model2 loss : 0.017911
[01:09:02.423] iteration 26442 : model1 loss : 0.442785 model2 loss : 0.016984
[01:09:02.637] iteration 26443 : model1 loss : 0.437902 model2 loss : 0.016700
[01:09:02.819] iteration 26444 : model1 loss : 0.442195 model2 loss : 0.018105
[01:09:03.007] iteration 26445 : model1 loss : 0.438174 model2 loss : 0.016383
[01:09:03.237] iteration 26446 : model1 loss : 0.436424 model2 loss : 0.016532
[01:09:03.406] iteration 26447 : model1 loss : 0.434657 model2 loss : 0.016763
[01:09:03.574] iteration 26448 : model1 loss : 0.440949 model2 loss : 0.018142
[01:09:03.742] iteration 26449 : model1 loss : 0.442665 model2 loss : 0.018933
[01:09:03.912] iteration 26450 : model1 loss : 0.442381 model2 loss : 0.018271
[01:09:04.089] iteration 26451 : model1 loss : 0.442505 model2 loss : 0.017428
[01:09:04.258] iteration 26452 : model1 loss : 0.441363 model2 loss : 0.015525
[01:09:04.427] iteration 26453 : model1 loss : 0.437907 model2 loss : 0.017225
[01:09:04.605] iteration 26454 : model1 loss : 0.436162 model2 loss : 0.015145
[01:09:04.783] iteration 26455 : model1 loss : 0.439841 model2 loss : 0.016168
[01:09:04.964] iteration 26456 : model1 loss : 0.440866 model2 loss : 0.018420
[01:09:05.147] iteration 26457 : model1 loss : 0.447177 model2 loss : 0.017616
[01:09:05.348] iteration 26458 : model1 loss : 0.438579 model2 loss : 0.017524
[01:09:05.536] iteration 26459 : model1 loss : 0.442293 model2 loss : 0.018022
[01:09:05.702] iteration 26460 : model1 loss : 0.439729 model2 loss : 0.016353
[01:09:07.725] iteration 26461 : model1 loss : 0.442823 model2 loss : 0.018131
[01:09:07.899] iteration 26462 : model1 loss : 0.433309 model2 loss : 0.017221
[01:09:08.070] iteration 26463 : model1 loss : 0.443413 model2 loss : 0.018629
[01:09:08.239] iteration 26464 : model1 loss : 0.437611 model2 loss : 0.014853
[01:09:08.409] iteration 26465 : model1 loss : 0.437693 model2 loss : 0.015867
[01:09:08.584] iteration 26466 : model1 loss : 0.436016 model2 loss : 0.018667
[01:09:08.771] iteration 26467 : model1 loss : 0.441074 model2 loss : 0.017308
[01:09:09.002] iteration 26468 : model1 loss : 0.436193 model2 loss : 0.015160
[01:09:09.174] iteration 26469 : model1 loss : 0.440749 model2 loss : 0.017069
[01:09:09.347] iteration 26470 : model1 loss : 0.442829 model2 loss : 0.017002
[01:09:09.530] iteration 26471 : model1 loss : 0.436782 model2 loss : 0.016494
[01:09:09.710] iteration 26472 : model1 loss : 0.440739 model2 loss : 0.015689
[01:09:09.884] iteration 26473 : model1 loss : 0.446663 model2 loss : 0.017884
[01:09:10.056] iteration 26474 : model1 loss : 0.444346 model2 loss : 0.018368
[01:09:10.225] iteration 26475 : model1 loss : 0.440391 model2 loss : 0.016573
[01:09:10.395] iteration 26476 : model1 loss : 0.439225 model2 loss : 0.018205
[01:09:10.564] iteration 26477 : model1 loss : 0.440833 model2 loss : 0.018094
[01:09:10.739] iteration 26478 : model1 loss : 0.439175 model2 loss : 0.016094
[01:09:10.906] iteration 26479 : model1 loss : 0.439240 model2 loss : 0.017607
[01:09:11.091] iteration 26480 : model1 loss : 0.442392 model2 loss : 0.016621
[01:09:11.277] iteration 26481 : model1 loss : 0.439066 model2 loss : 0.016987
[01:09:13.358] iteration 26482 : model1 loss : 0.441128 model2 loss : 0.017119
[01:09:13.538] iteration 26483 : model1 loss : 0.441504 model2 loss : 0.016152
[01:09:13.731] iteration 26484 : model1 loss : 0.441108 model2 loss : 0.017201
[01:09:13.958] iteration 26485 : model1 loss : 0.439776 model2 loss : 0.015707
[01:09:14.130] iteration 26486 : model1 loss : 0.441932 model2 loss : 0.016537
[01:09:14.303] iteration 26487 : model1 loss : 0.442894 model2 loss : 0.019734
[01:09:14.481] iteration 26488 : model1 loss : 0.448216 model2 loss : 0.019109
[01:09:14.650] iteration 26489 : model1 loss : 0.440418 model2 loss : 0.018481
[01:09:14.820] iteration 26490 : model1 loss : 0.435780 model2 loss : 0.016758
[01:09:14.998] iteration 26491 : model1 loss : 0.441700 model2 loss : 0.016494
[01:09:15.170] iteration 26492 : model1 loss : 0.439804 model2 loss : 0.016455
[01:09:15.341] iteration 26493 : model1 loss : 0.438472 model2 loss : 0.018095
[01:09:15.509] iteration 26494 : model1 loss : 0.435575 model2 loss : 0.015904
[01:09:15.678] iteration 26495 : model1 loss : 0.438019 model2 loss : 0.015754
[01:09:15.846] iteration 26496 : model1 loss : 0.442422 model2 loss : 0.018860
[01:09:16.036] iteration 26497 : model1 loss : 0.439900 model2 loss : 0.016272
[01:09:16.216] iteration 26498 : model1 loss : 0.439861 model2 loss : 0.016161
[01:09:16.406] iteration 26499 : model1 loss : 0.436787 model2 loss : 0.015384
[01:09:16.593] iteration 26500 : model1 loss : 0.439484 model2 loss : 0.016572
[01:09:16.780] iteration 26501 : model1 loss : 0.442140 model2 loss : 0.016967
[01:09:16.968] iteration 26502 : model1 loss : 0.439276 model2 loss : 0.017847
[01:09:19.082] iteration 26503 : model1 loss : 0.439720 model2 loss : 0.015928
[01:09:19.251] iteration 26504 : model1 loss : 0.439326 model2 loss : 0.015332
[01:09:19.421] iteration 26505 : model1 loss : 0.442143 model2 loss : 0.018950
[01:09:19.600] iteration 26506 : model1 loss : 0.438086 model2 loss : 0.014781
[01:09:19.775] iteration 26507 : model1 loss : 0.438947 model2 loss : 0.015983
[01:09:19.944] iteration 26508 : model1 loss : 0.437937 model2 loss : 0.017012
[01:09:20.116] iteration 26509 : model1 loss : 0.438140 model2 loss : 0.015906
[01:09:20.283] iteration 26510 : model1 loss : 0.440254 model2 loss : 0.016182
[01:09:20.457] iteration 26511 : model1 loss : 0.437855 model2 loss : 0.018849
[01:09:20.625] iteration 26512 : model1 loss : 0.442196 model2 loss : 0.017091
[01:09:20.793] iteration 26513 : model1 loss : 0.437968 model2 loss : 0.016242
[01:09:20.968] iteration 26514 : model1 loss : 0.441485 model2 loss : 0.015624
[01:09:21.142] iteration 26515 : model1 loss : 0.440028 model2 loss : 0.016867
[01:09:21.311] iteration 26516 : model1 loss : 0.441879 model2 loss : 0.019245
[01:09:21.487] iteration 26517 : model1 loss : 0.442199 model2 loss : 0.017116
[01:09:21.655] iteration 26518 : model1 loss : 0.438123 model2 loss : 0.016449
[01:09:21.834] iteration 26519 : model1 loss : 0.442194 model2 loss : 0.018484
[01:09:22.003] iteration 26520 : model1 loss : 0.437163 model2 loss : 0.017079
[01:09:22.177] iteration 26521 : model1 loss : 0.438896 model2 loss : 0.017892
[01:09:22.345] iteration 26522 : model1 loss : 0.441623 model2 loss : 0.015434
[01:09:22.520] iteration 26523 : model1 loss : 0.444062 model2 loss : 0.018889
[01:09:24.548] iteration 26524 : model1 loss : 0.439616 model2 loss : 0.016408
[01:09:24.724] iteration 26525 : model1 loss : 0.437780 model2 loss : 0.015853
[01:09:24.907] iteration 26526 : model1 loss : 0.440838 model2 loss : 0.019801
[01:09:25.078] iteration 26527 : model1 loss : 0.439529 model2 loss : 0.016046
[01:09:25.299] iteration 26528 : model1 loss : 0.440454 model2 loss : 0.015090
[01:09:25.494] iteration 26529 : model1 loss : 0.444762 model2 loss : 0.016428
[01:09:25.664] iteration 26530 : model1 loss : 0.441797 model2 loss : 0.018693
[01:09:25.832] iteration 26531 : model1 loss : 0.436344 model2 loss : 0.014861
[01:09:26.004] iteration 26532 : model1 loss : 0.440872 model2 loss : 0.014819
[01:09:26.171] iteration 26533 : model1 loss : 0.436847 model2 loss : 0.016776
[01:09:26.356] iteration 26534 : model1 loss : 0.441913 model2 loss : 0.016727
[01:09:26.524] iteration 26535 : model1 loss : 0.442022 model2 loss : 0.018221
[01:09:26.694] iteration 26536 : model1 loss : 0.436178 model2 loss : 0.018532
[01:09:26.865] iteration 26537 : model1 loss : 0.439993 model2 loss : 0.018484
[01:09:27.036] iteration 26538 : model1 loss : 0.442134 model2 loss : 0.016271
[01:09:27.203] iteration 26539 : model1 loss : 0.439322 model2 loss : 0.016855
[01:09:27.378] iteration 26540 : model1 loss : 0.439325 model2 loss : 0.016495
[01:09:27.556] iteration 26541 : model1 loss : 0.447277 model2 loss : 0.018723
[01:09:27.778] iteration 26542 : model1 loss : 0.438867 model2 loss : 0.016516
[01:09:27.977] iteration 26543 : model1 loss : 0.437964 model2 loss : 0.016198
[01:09:28.156] iteration 26544 : model1 loss : 0.438946 model2 loss : 0.015886
[01:09:30.498] iteration 26545 : model1 loss : 0.435364 model2 loss : 0.016594
[01:09:30.684] iteration 26546 : model1 loss : 0.441076 model2 loss : 0.016189
[01:09:30.865] iteration 26547 : model1 loss : 0.438772 model2 loss : 0.017137
[01:09:31.046] iteration 26548 : model1 loss : 0.436460 model2 loss : 0.017340
[01:09:31.215] iteration 26549 : model1 loss : 0.438007 model2 loss : 0.017830
[01:09:31.382] iteration 26550 : model1 loss : 0.440008 model2 loss : 0.018905
[01:09:31.552] iteration 26551 : model1 loss : 0.444460 model2 loss : 0.016185
[01:09:31.728] iteration 26552 : model1 loss : 0.438607 model2 loss : 0.015915
[01:09:31.919] iteration 26553 : model1 loss : 0.441635 model2 loss : 0.015832
[01:09:32.099] iteration 26554 : model1 loss : 0.435427 model2 loss : 0.017007
[01:09:32.314] iteration 26555 : model1 loss : 0.440480 model2 loss : 0.016697
[01:09:32.485] iteration 26556 : model1 loss : 0.440993 model2 loss : 0.015422
[01:09:32.653] iteration 26557 : model1 loss : 0.439318 model2 loss : 0.018412
[01:09:32.822] iteration 26558 : model1 loss : 0.442661 model2 loss : 0.018087
[01:09:32.992] iteration 26559 : model1 loss : 0.446718 model2 loss : 0.020091
[01:09:33.174] iteration 26560 : model1 loss : 0.438107 model2 loss : 0.018408
[01:09:33.386] iteration 26561 : model1 loss : 0.444932 model2 loss : 0.018394
[01:09:33.598] iteration 26562 : model1 loss : 0.446326 model2 loss : 0.016356
[01:09:33.773] iteration 26563 : model1 loss : 0.438014 model2 loss : 0.016471
[01:09:33.943] iteration 26564 : model1 loss : 0.438650 model2 loss : 0.015754
[01:09:34.123] iteration 26565 : model1 loss : 0.439994 model2 loss : 0.015193
[01:09:36.532] iteration 26566 : model1 loss : 0.440632 model2 loss : 0.017378
[01:09:36.743] iteration 26567 : model1 loss : 0.437905 model2 loss : 0.016263
[01:09:36.921] iteration 26568 : model1 loss : 0.444262 model2 loss : 0.014936
[01:09:37.147] iteration 26569 : model1 loss : 0.439691 model2 loss : 0.015762
[01:09:37.400] iteration 26570 : model1 loss : 0.443588 model2 loss : 0.017984
[01:09:37.586] iteration 26571 : model1 loss : 0.439213 model2 loss : 0.016474
[01:09:37.768] iteration 26572 : model1 loss : 0.441858 model2 loss : 0.017372
[01:09:37.955] iteration 26573 : model1 loss : 0.439028 model2 loss : 0.015933
[01:09:38.138] iteration 26574 : model1 loss : 0.436902 model2 loss : 0.019019
[01:09:38.332] iteration 26575 : model1 loss : 0.440213 model2 loss : 0.017276
[01:09:38.527] iteration 26576 : model1 loss : 0.437362 model2 loss : 0.015595
[01:09:38.698] iteration 26577 : model1 loss : 0.441196 model2 loss : 0.018531
[01:09:38.870] iteration 26578 : model1 loss : 0.435462 model2 loss : 0.016273
[01:09:39.045] iteration 26579 : model1 loss : 0.436796 model2 loss : 0.016778
[01:09:39.214] iteration 26580 : model1 loss : 0.439806 model2 loss : 0.014526
[01:09:39.383] iteration 26581 : model1 loss : 0.436092 model2 loss : 0.015128
[01:09:39.556] iteration 26582 : model1 loss : 0.440991 model2 loss : 0.016858
[01:09:39.726] iteration 26583 : model1 loss : 0.439047 model2 loss : 0.017504
[01:09:39.901] iteration 26584 : model1 loss : 0.442609 model2 loss : 0.015616
[01:09:40.068] iteration 26585 : model1 loss : 0.443107 model2 loss : 0.014527
[01:09:40.239] iteration 26586 : model1 loss : 0.443757 model2 loss : 0.018494
[01:09:42.216] iteration 26587 : model1 loss : 0.438624 model2 loss : 0.015378
[01:09:42.386] iteration 26588 : model1 loss : 0.440093 model2 loss : 0.017600
[01:09:42.562] iteration 26589 : model1 loss : 0.439810 model2 loss : 0.017025
[01:09:42.732] iteration 26590 : model1 loss : 0.442365 model2 loss : 0.019169
[01:09:42.904] iteration 26591 : model1 loss : 0.446502 model2 loss : 0.018944
[01:09:43.079] iteration 26592 : model1 loss : 0.444547 model2 loss : 0.016047
[01:09:43.248] iteration 26593 : model1 loss : 0.439687 model2 loss : 0.019885
[01:09:43.415] iteration 26594 : model1 loss : 0.441160 model2 loss : 0.018775
[01:09:43.603] iteration 26595 : model1 loss : 0.440570 model2 loss : 0.016835
[01:09:43.790] iteration 26596 : model1 loss : 0.438022 model2 loss : 0.014560
[01:09:43.968] iteration 26597 : model1 loss : 0.438278 model2 loss : 0.016318
[01:09:44.150] iteration 26598 : model1 loss : 0.439645 model2 loss : 0.015967
[01:09:44.333] iteration 26599 : model1 loss : 0.441369 model2 loss : 0.017337
[01:09:44.509] iteration 26600 : model1 loss : 0.442698 model2 loss : 0.014024
[01:09:44.679] iteration 26601 : model1 loss : 0.437491 model2 loss : 0.015915
[01:09:44.854] iteration 26602 : model1 loss : 0.439894 model2 loss : 0.016113
[01:09:45.036] iteration 26603 : model1 loss : 0.440962 model2 loss : 0.015212
[01:09:45.213] iteration 26604 : model1 loss : 0.440230 model2 loss : 0.017089
[01:09:45.400] iteration 26605 : model1 loss : 0.438665 model2 loss : 0.015400
[01:09:45.585] iteration 26606 : model1 loss : 0.436150 model2 loss : 0.017383
[01:09:45.753] iteration 26607 : model1 loss : 0.436848 model2 loss : 0.016522
[01:09:47.742] iteration 26608 : model1 loss : 0.439090 model2 loss : 0.015794
[01:09:47.911] iteration 26609 : model1 loss : 0.443181 model2 loss : 0.016824
[01:09:48.083] iteration 26610 : model1 loss : 0.437844 model2 loss : 0.017059
[01:09:48.250] iteration 26611 : model1 loss : 0.443869 model2 loss : 0.017840
[01:09:48.416] iteration 26612 : model1 loss : 0.442994 model2 loss : 0.016997
[01:09:48.588] iteration 26613 : model1 loss : 0.440297 model2 loss : 0.015996
[01:09:48.763] iteration 26614 : model1 loss : 0.440116 model2 loss : 0.015047
[01:09:48.956] iteration 26615 : model1 loss : 0.437873 model2 loss : 0.016830
[01:09:49.160] iteration 26616 : model1 loss : 0.443057 model2 loss : 0.017004
[01:09:49.347] iteration 26617 : model1 loss : 0.441977 model2 loss : 0.018160
[01:09:49.534] iteration 26618 : model1 loss : 0.436785 model2 loss : 0.015274
[01:09:49.728] iteration 26619 : model1 loss : 0.443857 model2 loss : 0.017754
[01:09:49.906] iteration 26620 : model1 loss : 0.438862 model2 loss : 0.015355
[01:09:50.081] iteration 26621 : model1 loss : 0.434715 model2 loss : 0.015198
[01:09:50.252] iteration 26622 : model1 loss : 0.443783 model2 loss : 0.018875
[01:09:50.420] iteration 26623 : model1 loss : 0.443524 model2 loss : 0.016475
[01:09:50.589] iteration 26624 : model1 loss : 0.437471 model2 loss : 0.017035
[01:09:50.758] iteration 26625 : model1 loss : 0.438653 model2 loss : 0.015351
[01:09:50.960] iteration 26626 : model1 loss : 0.440528 model2 loss : 0.018678
[01:09:51.138] iteration 26627 : model1 loss : 0.437007 model2 loss : 0.017024
[01:09:51.310] iteration 26628 : model1 loss : 0.436780 model2 loss : 0.015665
[01:09:53.318] iteration 26629 : model1 loss : 0.444552 model2 loss : 0.016867
[01:09:53.501] iteration 26630 : model1 loss : 0.439558 model2 loss : 0.015849
[01:09:53.672] iteration 26631 : model1 loss : 0.440590 model2 loss : 0.016873
[01:09:53.852] iteration 26632 : model1 loss : 0.445260 model2 loss : 0.017300
[01:09:54.026] iteration 26633 : model1 loss : 0.438609 model2 loss : 0.017378
[01:09:54.200] iteration 26634 : model1 loss : 0.439337 model2 loss : 0.015561
[01:09:54.373] iteration 26635 : model1 loss : 0.438779 model2 loss : 0.017691
[01:09:54.553] iteration 26636 : model1 loss : 0.439439 model2 loss : 0.016691
[01:09:54.729] iteration 26637 : model1 loss : 0.437762 model2 loss : 0.014080
[01:09:54.906] iteration 26638 : model1 loss : 0.435323 model2 loss : 0.016781
[01:09:55.085] iteration 26639 : model1 loss : 0.440068 model2 loss : 0.017057
[01:09:55.257] iteration 26640 : model1 loss : 0.444254 model2 loss : 0.016645
[01:09:55.441] iteration 26641 : model1 loss : 0.439467 model2 loss : 0.016610
[01:09:55.617] iteration 26642 : model1 loss : 0.440668 model2 loss : 0.017220
[01:09:55.788] iteration 26643 : model1 loss : 0.440242 model2 loss : 0.016870
[01:09:55.958] iteration 26644 : model1 loss : 0.443265 model2 loss : 0.018055
[01:09:56.142] iteration 26645 : model1 loss : 0.440766 model2 loss : 0.015378
[01:09:56.322] iteration 26646 : model1 loss : 0.439827 model2 loss : 0.016056
[01:09:56.497] iteration 26647 : model1 loss : 0.439079 model2 loss : 0.017632
[01:09:56.670] iteration 26648 : model1 loss : 0.436976 model2 loss : 0.017345
[01:09:56.841] iteration 26649 : model1 loss : 0.437092 model2 loss : 0.018140
[01:09:58.908] iteration 26650 : model1 loss : 0.434756 model2 loss : 0.015658
[01:09:59.079] iteration 26651 : model1 loss : 0.436854 model2 loss : 0.016429
[01:09:59.247] iteration 26652 : model1 loss : 0.441928 model2 loss : 0.016792
[01:09:59.424] iteration 26653 : model1 loss : 0.441742 model2 loss : 0.017005
[01:09:59.601] iteration 26654 : model1 loss : 0.442280 model2 loss : 0.018281
[01:09:59.770] iteration 26655 : model1 loss : 0.444196 model2 loss : 0.018613
[01:09:59.941] iteration 26656 : model1 loss : 0.442236 model2 loss : 0.014876
[01:10:00.113] iteration 26657 : model1 loss : 0.436698 model2 loss : 0.015198
[01:10:00.281] iteration 26658 : model1 loss : 0.439248 model2 loss : 0.016002
[01:10:00.448] iteration 26659 : model1 loss : 0.441055 model2 loss : 0.017242
[01:10:00.617] iteration 26660 : model1 loss : 0.435153 model2 loss : 0.017292
[01:10:00.791] iteration 26661 : model1 loss : 0.438487 model2 loss : 0.019459
[01:10:00.961] iteration 26662 : model1 loss : 0.436374 model2 loss : 0.015228
[01:10:01.133] iteration 26663 : model1 loss : 0.438615 model2 loss : 0.017507
[01:10:01.307] iteration 26664 : model1 loss : 0.442205 model2 loss : 0.017988
[01:10:01.475] iteration 26665 : model1 loss : 0.438463 model2 loss : 0.016301
[01:10:01.656] iteration 26666 : model1 loss : 0.442154 model2 loss : 0.018000
[01:10:01.850] iteration 26667 : model1 loss : 0.440692 model2 loss : 0.017372
[01:10:02.029] iteration 26668 : model1 loss : 0.443409 model2 loss : 0.017775
[01:10:02.252] iteration 26669 : model1 loss : 0.442104 model2 loss : 0.015941
[01:10:02.496] iteration 26670 : model1 loss : 0.442237 model2 loss : 0.018479
[01:10:04.890] iteration 26671 : model1 loss : 0.443393 model2 loss : 0.016781
[01:10:05.063] iteration 26672 : model1 loss : 0.440935 model2 loss : 0.017078
[01:10:05.242] iteration 26673 : model1 loss : 0.444715 model2 loss : 0.020419
[01:10:05.423] iteration 26674 : model1 loss : 0.440446 model2 loss : 0.016950
[01:10:05.628] iteration 26675 : model1 loss : 0.443755 model2 loss : 0.019508
[01:10:05.814] iteration 26676 : model1 loss : 0.439375 model2 loss : 0.016880
[01:10:05.989] iteration 26677 : model1 loss : 0.440219 model2 loss : 0.017287
[01:10:06.190] iteration 26678 : model1 loss : 0.439699 model2 loss : 0.015832
[01:10:06.371] iteration 26679 : model1 loss : 0.437754 model2 loss : 0.016358
[01:10:06.546] iteration 26680 : model1 loss : 0.436242 model2 loss : 0.016764
[01:10:06.751] iteration 26681 : model1 loss : 0.437500 model2 loss : 0.017261
[01:10:06.936] iteration 26682 : model1 loss : 0.444477 model2 loss : 0.018068
[01:10:07.129] iteration 26683 : model1 loss : 0.434378 model2 loss : 0.015115
[01:10:07.316] iteration 26684 : model1 loss : 0.439274 model2 loss : 0.017598
[01:10:07.512] iteration 26685 : model1 loss : 0.440558 model2 loss : 0.015967
[01:10:07.695] iteration 26686 : model1 loss : 0.439721 model2 loss : 0.015559
[01:10:07.875] iteration 26687 : model1 loss : 0.440993 model2 loss : 0.016654
[01:10:08.067] iteration 26688 : model1 loss : 0.435659 model2 loss : 0.014801
[01:10:08.252] iteration 26689 : model1 loss : 0.436898 model2 loss : 0.018243
[01:10:08.423] iteration 26690 : model1 loss : 0.441861 model2 loss : 0.017639
[01:10:08.595] iteration 26691 : model1 loss : 0.441446 model2 loss : 0.016847
[01:10:10.630] iteration 26692 : model1 loss : 0.441176 model2 loss : 0.017830
[01:10:10.820] iteration 26693 : model1 loss : 0.439860 model2 loss : 0.016561
[01:10:11.016] iteration 26694 : model1 loss : 0.437073 model2 loss : 0.016724
[01:10:11.187] iteration 26695 : model1 loss : 0.437720 model2 loss : 0.014651
[01:10:11.358] iteration 26696 : model1 loss : 0.438921 model2 loss : 0.015658
[01:10:11.528] iteration 26697 : model1 loss : 0.442015 model2 loss : 0.017601
[01:10:11.702] iteration 26698 : model1 loss : 0.440517 model2 loss : 0.018976
[01:10:11.900] iteration 26699 : model1 loss : 0.440414 model2 loss : 0.017881
[01:10:12.074] iteration 26700 : model1 loss : 0.442909 model2 loss : 0.015937
[01:10:12.243] iteration 26701 : model1 loss : 0.441012 model2 loss : 0.018186
[01:10:12.414] iteration 26702 : model1 loss : 0.438020 model2 loss : 0.015957
[01:10:12.588] iteration 26703 : model1 loss : 0.436463 model2 loss : 0.015658
[01:10:12.765] iteration 26704 : model1 loss : 0.441813 model2 loss : 0.016657
[01:10:12.957] iteration 26705 : model1 loss : 0.442053 model2 loss : 0.019179
[01:10:13.131] iteration 26706 : model1 loss : 0.440879 model2 loss : 0.017911
[01:10:13.306] iteration 26707 : model1 loss : 0.438074 model2 loss : 0.017485
[01:10:13.476] iteration 26708 : model1 loss : 0.438567 model2 loss : 0.016684
[01:10:13.647] iteration 26709 : model1 loss : 0.436662 model2 loss : 0.015615
[01:10:13.818] iteration 26710 : model1 loss : 0.443115 model2 loss : 0.018528
[01:10:13.987] iteration 26711 : model1 loss : 0.445813 model2 loss : 0.019300
[01:10:14.156] iteration 26712 : model1 loss : 0.442491 model2 loss : 0.018581
[01:10:16.204] iteration 26713 : model1 loss : 0.439677 model2 loss : 0.016724
[01:10:16.409] iteration 26714 : model1 loss : 0.442072 model2 loss : 0.019008
[01:10:16.598] iteration 26715 : model1 loss : 0.435219 model2 loss : 0.015841
[01:10:16.802] iteration 26716 : model1 loss : 0.441248 model2 loss : 0.016830
[01:10:16.998] iteration 26717 : model1 loss : 0.442463 model2 loss : 0.016716
[01:10:17.196] iteration 26718 : model1 loss : 0.441937 model2 loss : 0.017496
[01:10:17.374] iteration 26719 : model1 loss : 0.437347 model2 loss : 0.016240
[01:10:17.550] iteration 26720 : model1 loss : 0.438805 model2 loss : 0.017118
[01:10:17.733] iteration 26721 : model1 loss : 0.448685 model2 loss : 0.023204
[01:10:17.906] iteration 26722 : model1 loss : 0.445131 model2 loss : 0.019141
[01:10:18.081] iteration 26723 : model1 loss : 0.436951 model2 loss : 0.018136
[01:10:18.251] iteration 26724 : model1 loss : 0.440249 model2 loss : 0.014734
[01:10:18.421] iteration 26725 : model1 loss : 0.442056 model2 loss : 0.018507
[01:10:18.591] iteration 26726 : model1 loss : 0.437620 model2 loss : 0.014981
[01:10:18.759] iteration 26727 : model1 loss : 0.440896 model2 loss : 0.016864
[01:10:18.942] iteration 26728 : model1 loss : 0.439634 model2 loss : 0.016396
[01:10:19.111] iteration 26729 : model1 loss : 0.439316 model2 loss : 0.018016
[01:10:19.283] iteration 26730 : model1 loss : 0.439556 model2 loss : 0.015723
[01:10:19.451] iteration 26731 : model1 loss : 0.435894 model2 loss : 0.017141
[01:10:19.621] iteration 26732 : model1 loss : 0.436080 model2 loss : 0.016971
[01:10:19.791] iteration 26733 : model1 loss : 0.440414 model2 loss : 0.017849
[01:10:21.826] iteration 26734 : model1 loss : 0.441200 model2 loss : 0.017282
[01:10:22.002] iteration 26735 : model1 loss : 0.444417 model2 loss : 0.018298
[01:10:22.178] iteration 26736 : model1 loss : 0.441442 model2 loss : 0.016022
[01:10:22.346] iteration 26737 : model1 loss : 0.439768 model2 loss : 0.017796
[01:10:22.518] iteration 26738 : model1 loss : 0.438027 model2 loss : 0.016526
[01:10:22.686] iteration 26739 : model1 loss : 0.442918 model2 loss : 0.018514
[01:10:22.856] iteration 26740 : model1 loss : 0.441286 model2 loss : 0.015648
[01:10:23.028] iteration 26741 : model1 loss : 0.437970 model2 loss : 0.014855
[01:10:23.197] iteration 26742 : model1 loss : 0.437478 model2 loss : 0.015938
[01:10:23.365] iteration 26743 : model1 loss : 0.437732 model2 loss : 0.016265
[01:10:23.537] iteration 26744 : model1 loss : 0.435456 model2 loss : 0.017061
[01:10:23.711] iteration 26745 : model1 loss : 0.441706 model2 loss : 0.015817
[01:10:23.881] iteration 26746 : model1 loss : 0.440602 model2 loss : 0.016679
[01:10:24.054] iteration 26747 : model1 loss : 0.440057 model2 loss : 0.017172
[01:10:24.228] iteration 26748 : model1 loss : 0.441393 model2 loss : 0.016283
[01:10:24.397] iteration 26749 : model1 loss : 0.440459 model2 loss : 0.015419
[01:10:24.566] iteration 26750 : model1 loss : 0.435611 model2 loss : 0.016592
[01:10:24.737] iteration 26751 : model1 loss : 0.443899 model2 loss : 0.018372
[01:10:24.909] iteration 26752 : model1 loss : 0.436094 model2 loss : 0.014157
[01:10:25.080] iteration 26753 : model1 loss : 0.437906 model2 loss : 0.017764
[01:10:25.249] iteration 26754 : model1 loss : 0.441493 model2 loss : 0.017481
[01:10:27.250] iteration 26755 : model1 loss : 0.441999 model2 loss : 0.015311
[01:10:27.446] iteration 26756 : model1 loss : 0.441600 model2 loss : 0.017355
[01:10:27.626] iteration 26757 : model1 loss : 0.442240 model2 loss : 0.018358
[01:10:27.826] iteration 26758 : model1 loss : 0.440617 model2 loss : 0.013856
[01:10:28.031] iteration 26759 : model1 loss : 0.438037 model2 loss : 0.017861
[01:10:28.222] iteration 26760 : model1 loss : 0.437201 model2 loss : 0.015170
[01:10:28.425] iteration 26761 : model1 loss : 0.436959 model2 loss : 0.014217
[01:10:28.597] iteration 26762 : model1 loss : 0.441100 model2 loss : 0.015474
[01:10:28.782] iteration 26763 : model1 loss : 0.440682 model2 loss : 0.016736
[01:10:28.964] iteration 26764 : model1 loss : 0.439003 model2 loss : 0.017349
[01:10:29.135] iteration 26765 : model1 loss : 0.443421 model2 loss : 0.019306
[01:10:29.304] iteration 26766 : model1 loss : 0.439271 model2 loss : 0.016083
[01:10:29.474] iteration 26767 : model1 loss : 0.436985 model2 loss : 0.017222
[01:10:29.643] iteration 26768 : model1 loss : 0.438992 model2 loss : 0.017628
[01:10:29.814] iteration 26769 : model1 loss : 0.444209 model2 loss : 0.018899
[01:10:29.982] iteration 26770 : model1 loss : 0.439753 model2 loss : 0.015732
[01:10:30.152] iteration 26771 : model1 loss : 0.442782 model2 loss : 0.017415
[01:10:30.323] iteration 26772 : model1 loss : 0.441022 model2 loss : 0.017352
[01:10:30.493] iteration 26773 : model1 loss : 0.438171 model2 loss : 0.015867
[01:10:30.662] iteration 26774 : model1 loss : 0.435836 model2 loss : 0.016807
[01:10:30.831] iteration 26775 : model1 loss : 0.443871 model2 loss : 0.017354
[01:10:32.872] iteration 26776 : model1 loss : 0.439644 model2 loss : 0.015468
[01:10:33.050] iteration 26777 : model1 loss : 0.440889 model2 loss : 0.017975
[01:10:33.223] iteration 26778 : model1 loss : 0.438783 model2 loss : 0.015375
[01:10:33.398] iteration 26779 : model1 loss : 0.437340 model2 loss : 0.016100
[01:10:33.590] iteration 26780 : model1 loss : 0.443943 model2 loss : 0.018932
[01:10:33.770] iteration 26781 : model1 loss : 0.437890 model2 loss : 0.015227
[01:10:33.942] iteration 26782 : model1 loss : 0.437740 model2 loss : 0.015824
[01:10:34.119] iteration 26783 : model1 loss : 0.440393 model2 loss : 0.016102
[01:10:34.296] iteration 26784 : model1 loss : 0.439542 model2 loss : 0.017495
[01:10:34.470] iteration 26785 : model1 loss : 0.440164 model2 loss : 0.017060
[01:10:34.647] iteration 26786 : model1 loss : 0.437297 model2 loss : 0.014840
[01:10:34.837] iteration 26787 : model1 loss : 0.437524 model2 loss : 0.015515
[01:10:35.027] iteration 26788 : model1 loss : 0.441615 model2 loss : 0.017831
[01:10:35.196] iteration 26789 : model1 loss : 0.440432 model2 loss : 0.017166
[01:10:35.370] iteration 26790 : model1 loss : 0.444414 model2 loss : 0.016947
[01:10:35.538] iteration 26791 : model1 loss : 0.441228 model2 loss : 0.017252
[01:10:35.711] iteration 26792 : model1 loss : 0.441247 model2 loss : 0.015276
[01:10:35.910] iteration 26793 : model1 loss : 0.436826 model2 loss : 0.018100
[01:10:36.101] iteration 26794 : model1 loss : 0.438745 model2 loss : 0.017278
[01:10:36.286] iteration 26795 : model1 loss : 0.440677 model2 loss : 0.016483
[01:10:36.452] iteration 26796 : model1 loss : 0.440069 model2 loss : 0.017646
[01:10:38.568] iteration 26797 : model1 loss : 0.439297 model2 loss : 0.017628
[01:10:38.771] iteration 26798 : model1 loss : 0.440810 model2 loss : 0.016814
[01:10:38.946] iteration 26799 : model1 loss : 0.439217 model2 loss : 0.015352
[01:10:39.115] iteration 26800 : model1 loss : 0.438012 model2 loss : 0.014747
[01:10:39.290] iteration 26801 : model1 loss : 0.437624 model2 loss : 0.016081
[01:10:39.468] iteration 26802 : model1 loss : 0.439560 model2 loss : 0.016568
[01:10:39.650] iteration 26803 : model1 loss : 0.438844 model2 loss : 0.016166
[01:10:39.822] iteration 26804 : model1 loss : 0.441462 model2 loss : 0.016840
[01:10:40.008] iteration 26805 : model1 loss : 0.444769 model2 loss : 0.017297
[01:10:40.243] iteration 26806 : model1 loss : 0.439570 model2 loss : 0.017234
[01:10:40.473] iteration 26807 : model1 loss : 0.438883 model2 loss : 0.018013
[01:10:40.683] iteration 26808 : model1 loss : 0.444978 model2 loss : 0.017020
[01:10:40.851] iteration 26809 : model1 loss : 0.438650 model2 loss : 0.016600
[01:10:41.021] iteration 26810 : model1 loss : 0.442300 model2 loss : 0.014692
[01:10:41.196] iteration 26811 : model1 loss : 0.435554 model2 loss : 0.014617
[01:10:41.365] iteration 26812 : model1 loss : 0.439508 model2 loss : 0.015913
[01:10:41.562] iteration 26813 : model1 loss : 0.439403 model2 loss : 0.015327
[01:10:41.733] iteration 26814 : model1 loss : 0.439480 model2 loss : 0.017146
[01:10:41.901] iteration 26815 : model1 loss : 0.442614 model2 loss : 0.017533
[01:10:42.071] iteration 26816 : model1 loss : 0.440067 model2 loss : 0.016771
[01:10:42.254] iteration 26817 : model1 loss : 0.442456 model2 loss : 0.015869
[01:10:44.339] iteration 26818 : model1 loss : 0.438644 model2 loss : 0.016211
[01:10:44.510] iteration 26819 : model1 loss : 0.441194 model2 loss : 0.018816
[01:10:44.681] iteration 26820 : model1 loss : 0.441287 model2 loss : 0.016041
[01:10:44.850] iteration 26821 : model1 loss : 0.442823 model2 loss : 0.015028
[01:10:45.022] iteration 26822 : model1 loss : 0.440009 model2 loss : 0.015172
[01:10:45.190] iteration 26823 : model1 loss : 0.438620 model2 loss : 0.017845
[01:10:45.358] iteration 26824 : model1 loss : 0.443928 model2 loss : 0.017653
[01:10:45.529] iteration 26825 : model1 loss : 0.443375 model2 loss : 0.019000
[01:10:45.698] iteration 26826 : model1 loss : 0.439507 model2 loss : 0.015570
[01:10:45.868] iteration 26827 : model1 loss : 0.439851 model2 loss : 0.015638
[01:10:46.038] iteration 26828 : model1 loss : 0.443427 model2 loss : 0.015651
[01:10:46.209] iteration 26829 : model1 loss : 0.443987 model2 loss : 0.019344
[01:10:46.381] iteration 26830 : model1 loss : 0.438855 model2 loss : 0.015709
[01:10:46.548] iteration 26831 : model1 loss : 0.437918 model2 loss : 0.015910
[01:10:46.716] iteration 26832 : model1 loss : 0.437102 model2 loss : 0.018114
[01:10:46.886] iteration 26833 : model1 loss : 0.440401 model2 loss : 0.016875
[01:10:47.057] iteration 26834 : model1 loss : 0.437042 model2 loss : 0.014566
[01:10:47.227] iteration 26835 : model1 loss : 0.434671 model2 loss : 0.016312
[01:10:47.397] iteration 26836 : model1 loss : 0.436817 model2 loss : 0.016769
[01:10:47.563] iteration 26837 : model1 loss : 0.443661 model2 loss : 0.015464
[01:10:47.732] iteration 26838 : model1 loss : 0.437445 model2 loss : 0.017860
[01:10:49.727] iteration 26839 : model1 loss : 0.438863 model2 loss : 0.015428
[01:10:49.896] iteration 26840 : model1 loss : 0.439075 model2 loss : 0.016953
[01:10:50.068] iteration 26841 : model1 loss : 0.438605 model2 loss : 0.014709
[01:10:50.238] iteration 26842 : model1 loss : 0.434626 model2 loss : 0.017400
[01:10:50.407] iteration 26843 : model1 loss : 0.439200 model2 loss : 0.015152
[01:10:50.578] iteration 26844 : model1 loss : 0.438663 model2 loss : 0.016314
[01:10:50.747] iteration 26845 : model1 loss : 0.443078 model2 loss : 0.017272
[01:10:50.917] iteration 26846 : model1 loss : 0.440999 model2 loss : 0.017332
[01:10:51.087] iteration 26847 : model1 loss : 0.441532 model2 loss : 0.016847
[01:10:51.257] iteration 26848 : model1 loss : 0.440583 model2 loss : 0.014743
[01:10:51.426] iteration 26849 : model1 loss : 0.438933 model2 loss : 0.015528
[01:10:51.595] iteration 26850 : model1 loss : 0.439918 model2 loss : 0.015895
[01:10:51.765] iteration 26851 : model1 loss : 0.437348 model2 loss : 0.014937
[01:10:51.933] iteration 26852 : model1 loss : 0.441231 model2 loss : 0.014247
[01:10:52.105] iteration 26853 : model1 loss : 0.441028 model2 loss : 0.013622
[01:10:52.273] iteration 26854 : model1 loss : 0.440884 model2 loss : 0.017761
[01:10:52.442] iteration 26855 : model1 loss : 0.442966 model2 loss : 0.018054
[01:10:52.612] iteration 26856 : model1 loss : 0.436001 model2 loss : 0.016412
[01:10:52.780] iteration 26857 : model1 loss : 0.441892 model2 loss : 0.019448
[01:10:52.949] iteration 26858 : model1 loss : 0.438812 model2 loss : 0.016321
[01:10:53.120] iteration 26859 : model1 loss : 0.440573 model2 loss : 0.015353
[01:10:55.077] iteration 26860 : model1 loss : 0.448182 model2 loss : 0.017106
[01:10:55.248] iteration 26861 : model1 loss : 0.438954 model2 loss : 0.018671
[01:10:55.417] iteration 26862 : model1 loss : 0.439460 model2 loss : 0.016718
[01:10:55.585] iteration 26863 : model1 loss : 0.437622 model2 loss : 0.018182
[01:10:55.755] iteration 26864 : model1 loss : 0.438612 model2 loss : 0.014378
[01:10:55.926] iteration 26865 : model1 loss : 0.441058 model2 loss : 0.017228
[01:10:56.097] iteration 26866 : model1 loss : 0.446084 model2 loss : 0.020762
[01:10:56.265] iteration 26867 : model1 loss : 0.438027 model2 loss : 0.016346
[01:10:56.434] iteration 26868 : model1 loss : 0.443264 model2 loss : 0.017260
[01:10:56.603] iteration 26869 : model1 loss : 0.439647 model2 loss : 0.016641
[01:10:56.774] iteration 26870 : model1 loss : 0.441980 model2 loss : 0.017566
[01:10:56.944] iteration 26871 : model1 loss : 0.440080 model2 loss : 0.017535
[01:10:57.116] iteration 26872 : model1 loss : 0.445141 model2 loss : 0.017892
[01:10:57.284] iteration 26873 : model1 loss : 0.442121 model2 loss : 0.017849
[01:10:57.455] iteration 26874 : model1 loss : 0.439077 model2 loss : 0.015979
[01:10:57.648] iteration 26875 : model1 loss : 0.439477 model2 loss : 0.016672
[01:10:57.818] iteration 26876 : model1 loss : 0.433632 model2 loss : 0.015118
[01:10:57.986] iteration 26877 : model1 loss : 0.438418 model2 loss : 0.017789
[01:10:58.159] iteration 26878 : model1 loss : 0.438944 model2 loss : 0.017376
[01:10:58.327] iteration 26879 : model1 loss : 0.440180 model2 loss : 0.016919
[01:10:58.495] iteration 26880 : model1 loss : 0.438058 model2 loss : 0.015105
[01:11:00.463] iteration 26881 : model1 loss : 0.440431 model2 loss : 0.016427
[01:11:00.632] iteration 26882 : model1 loss : 0.444001 model2 loss : 0.018007
[01:11:00.808] iteration 26883 : model1 loss : 0.440067 model2 loss : 0.016339
[01:11:00.977] iteration 26884 : model1 loss : 0.442362 model2 loss : 0.016896
[01:11:01.150] iteration 26885 : model1 loss : 0.433173 model2 loss : 0.018825
[01:11:01.318] iteration 26886 : model1 loss : 0.438420 model2 loss : 0.015732
[01:11:01.488] iteration 26887 : model1 loss : 0.437997 model2 loss : 0.016223
[01:11:01.656] iteration 26888 : model1 loss : 0.440256 model2 loss : 0.016794
[01:11:01.831] iteration 26889 : model1 loss : 0.438918 model2 loss : 0.016134
[01:11:02.001] iteration 26890 : model1 loss : 0.444832 model2 loss : 0.020740
[01:11:02.171] iteration 26891 : model1 loss : 0.446516 model2 loss : 0.015388
[01:11:02.340] iteration 26892 : model1 loss : 0.435963 model2 loss : 0.017281
[01:11:02.510] iteration 26893 : model1 loss : 0.444913 model2 loss : 0.016116
[01:11:02.679] iteration 26894 : model1 loss : 0.438016 model2 loss : 0.015970
[01:11:02.850] iteration 26895 : model1 loss : 0.436720 model2 loss : 0.015679
[01:11:03.020] iteration 26896 : model1 loss : 0.439208 model2 loss : 0.017111
[01:11:03.189] iteration 26897 : model1 loss : 0.444449 model2 loss : 0.019870
[01:11:03.359] iteration 26898 : model1 loss : 0.438445 model2 loss : 0.014304
[01:11:03.529] iteration 26899 : model1 loss : 0.439586 model2 loss : 0.018592
[01:11:03.696] iteration 26900 : model1 loss : 0.437116 model2 loss : 0.017081
[01:11:03.864] iteration 26901 : model1 loss : 0.440829 model2 loss : 0.017859
[01:11:05.851] iteration 26902 : model1 loss : 0.442948 model2 loss : 0.016680
[01:11:06.022] iteration 26903 : model1 loss : 0.439822 model2 loss : 0.016307
[01:11:06.192] iteration 26904 : model1 loss : 0.441879 model2 loss : 0.016363
[01:11:06.361] iteration 26905 : model1 loss : 0.437838 model2 loss : 0.017274
[01:11:06.529] iteration 26906 : model1 loss : 0.441334 model2 loss : 0.016423
[01:11:06.698] iteration 26907 : model1 loss : 0.437721 model2 loss : 0.015809
[01:11:06.868] iteration 26908 : model1 loss : 0.439456 model2 loss : 0.019329
[01:11:07.039] iteration 26909 : model1 loss : 0.437274 model2 loss : 0.015887
[01:11:07.210] iteration 26910 : model1 loss : 0.442788 model2 loss : 0.015902
[01:11:07.378] iteration 26911 : model1 loss : 0.440836 model2 loss : 0.015092
[01:11:07.548] iteration 26912 : model1 loss : 0.438920 model2 loss : 0.018513
[01:11:07.719] iteration 26913 : model1 loss : 0.445062 model2 loss : 0.018604
[01:11:07.888] iteration 26914 : model1 loss : 0.439488 model2 loss : 0.017053
[01:11:08.059] iteration 26915 : model1 loss : 0.440930 model2 loss : 0.017968
[01:11:08.227] iteration 26916 : model1 loss : 0.442720 model2 loss : 0.017305
[01:11:08.395] iteration 26917 : model1 loss : 0.442717 model2 loss : 0.017802
[01:11:08.563] iteration 26918 : model1 loss : 0.441742 model2 loss : 0.016678
[01:11:08.734] iteration 26919 : model1 loss : 0.433650 model2 loss : 0.016617
[01:11:08.903] iteration 26920 : model1 loss : 0.439301 model2 loss : 0.014616
[01:11:09.073] iteration 26921 : model1 loss : 0.439499 model2 loss : 0.018040
[01:11:09.243] iteration 26922 : model1 loss : 0.439883 model2 loss : 0.017695
[01:11:11.253] iteration 26923 : model1 loss : 0.437237 model2 loss : 0.016754
[01:11:11.429] iteration 26924 : model1 loss : 0.434970 model2 loss : 0.014596
[01:11:11.638] iteration 26925 : model1 loss : 0.441885 model2 loss : 0.016351
[01:11:11.807] iteration 26926 : model1 loss : 0.438550 model2 loss : 0.016720
[01:11:11.986] iteration 26927 : model1 loss : 0.440986 model2 loss : 0.015534
[01:11:12.173] iteration 26928 : model1 loss : 0.435888 model2 loss : 0.016557
[01:11:12.358] iteration 26929 : model1 loss : 0.444249 model2 loss : 0.018283
[01:11:12.561] iteration 26930 : model1 loss : 0.439102 model2 loss : 0.017007
[01:11:12.790] iteration 26931 : model1 loss : 0.437930 model2 loss : 0.016175
[01:11:13.022] iteration 26932 : model1 loss : 0.440684 model2 loss : 0.017943
[01:11:13.251] iteration 26933 : model1 loss : 0.443327 model2 loss : 0.016979
[01:11:13.488] iteration 26934 : model1 loss : 0.443578 model2 loss : 0.015111
[01:11:13.728] iteration 26935 : model1 loss : 0.444350 model2 loss : 0.017400
[01:11:13.964] iteration 26936 : model1 loss : 0.440691 model2 loss : 0.016700
[01:11:14.197] iteration 26937 : model1 loss : 0.442052 model2 loss : 0.018240
[01:11:14.423] iteration 26938 : model1 loss : 0.439226 model2 loss : 0.017025
[01:11:14.648] iteration 26939 : model1 loss : 0.436436 model2 loss : 0.016692
[01:11:14.874] iteration 26940 : model1 loss : 0.439406 model2 loss : 0.016473
[01:11:15.097] iteration 26941 : model1 loss : 0.444447 model2 loss : 0.019503
[01:11:15.318] iteration 26942 : model1 loss : 0.441106 model2 loss : 0.015568
[01:11:15.538] iteration 26943 : model1 loss : 0.436912 model2 loss : 0.016645
[01:11:17.720] iteration 26944 : model1 loss : 0.434840 model2 loss : 0.017193
[01:11:17.900] iteration 26945 : model1 loss : 0.439055 model2 loss : 0.014888
[01:11:18.077] iteration 26946 : model1 loss : 0.441682 model2 loss : 0.016831
[01:11:18.290] iteration 26947 : model1 loss : 0.439390 model2 loss : 0.016742
[01:11:18.462] iteration 26948 : model1 loss : 0.438021 model2 loss : 0.016468
[01:11:18.635] iteration 26949 : model1 loss : 0.438024 model2 loss : 0.015940
[01:11:18.811] iteration 26950 : model1 loss : 0.437581 model2 loss : 0.016206
[01:11:18.990] iteration 26951 : model1 loss : 0.441946 model2 loss : 0.017330
[01:11:19.166] iteration 26952 : model1 loss : 0.439887 model2 loss : 0.015596
[01:11:19.337] iteration 26953 : model1 loss : 0.441310 model2 loss : 0.018122
[01:11:19.510] iteration 26954 : model1 loss : 0.440583 model2 loss : 0.016815
[01:11:19.733] iteration 26955 : model1 loss : 0.436984 model2 loss : 0.017220
[01:11:19.944] iteration 26956 : model1 loss : 0.440314 model2 loss : 0.016038
[01:11:20.122] iteration 26957 : model1 loss : 0.442833 model2 loss : 0.017020
[01:11:20.293] iteration 26958 : model1 loss : 0.440042 model2 loss : 0.016036
[01:11:20.461] iteration 26959 : model1 loss : 0.439454 model2 loss : 0.019576
[01:11:20.638] iteration 26960 : model1 loss : 0.438353 model2 loss : 0.015641
[01:11:20.812] iteration 26961 : model1 loss : 0.442568 model2 loss : 0.015882
[01:11:20.984] iteration 26962 : model1 loss : 0.442954 model2 loss : 0.015650
[01:11:21.155] iteration 26963 : model1 loss : 0.441609 model2 loss : 0.016630
[01:11:21.325] iteration 26964 : model1 loss : 0.443519 model2 loss : 0.016776
[01:11:23.395] iteration 26965 : model1 loss : 0.443151 model2 loss : 0.015547
[01:11:23.568] iteration 26966 : model1 loss : 0.436167 model2 loss : 0.016497
[01:11:23.744] iteration 26967 : model1 loss : 0.438550 model2 loss : 0.018558
[01:11:23.924] iteration 26968 : model1 loss : 0.436645 model2 loss : 0.015266
[01:11:24.094] iteration 26969 : model1 loss : 0.442300 model2 loss : 0.017687
[01:11:24.271] iteration 26970 : model1 loss : 0.441352 model2 loss : 0.018382
[01:11:24.443] iteration 26971 : model1 loss : 0.438546 model2 loss : 0.017662
[01:11:24.617] iteration 26972 : model1 loss : 0.439649 model2 loss : 0.015227
[01:11:24.787] iteration 26973 : model1 loss : 0.442941 model2 loss : 0.016067
[01:11:24.974] iteration 26974 : model1 loss : 0.441771 model2 loss : 0.015744
[01:11:25.210] iteration 26975 : model1 loss : 0.437327 model2 loss : 0.016883
[01:11:25.405] iteration 26976 : model1 loss : 0.440804 model2 loss : 0.015726
[01:11:25.577] iteration 26977 : model1 loss : 0.440185 model2 loss : 0.015456
[01:11:25.747] iteration 26978 : model1 loss : 0.439393 model2 loss : 0.017999
[01:11:25.923] iteration 26979 : model1 loss : 0.441968 model2 loss : 0.015816
[01:11:26.096] iteration 26980 : model1 loss : 0.445274 model2 loss : 0.015812
[01:11:26.272] iteration 26981 : model1 loss : 0.434985 model2 loss : 0.017555
[01:11:26.465] iteration 26982 : model1 loss : 0.438389 model2 loss : 0.015932
[01:11:26.648] iteration 26983 : model1 loss : 0.440710 model2 loss : 0.016611
[01:11:26.817] iteration 26984 : model1 loss : 0.436135 model2 loss : 0.014218
[01:11:26.990] iteration 26985 : model1 loss : 0.443424 model2 loss : 0.016520
[01:11:29.127] iteration 26986 : model1 loss : 0.437821 model2 loss : 0.016943
[01:11:29.367] iteration 26987 : model1 loss : 0.441023 model2 loss : 0.014433
[01:11:29.596] iteration 26988 : model1 loss : 0.439242 model2 loss : 0.017637
[01:11:29.779] iteration 26989 : model1 loss : 0.439060 model2 loss : 0.016561
[01:11:29.950] iteration 26990 : model1 loss : 0.441881 model2 loss : 0.015727
[01:11:30.125] iteration 26991 : model1 loss : 0.439864 model2 loss : 0.017059
[01:11:30.296] iteration 26992 : model1 loss : 0.440802 model2 loss : 0.016516
[01:11:30.466] iteration 26993 : model1 loss : 0.445209 model2 loss : 0.018732
[01:11:30.635] iteration 26994 : model1 loss : 0.437033 model2 loss : 0.015101
[01:11:30.804] iteration 26995 : model1 loss : 0.443041 model2 loss : 0.016507
[01:11:30.973] iteration 26996 : model1 loss : 0.436426 model2 loss : 0.017116
[01:11:31.143] iteration 26997 : model1 loss : 0.439408 model2 loss : 0.015653
[01:11:31.315] iteration 26998 : model1 loss : 0.437634 model2 loss : 0.015519
[01:11:31.486] iteration 26999 : model1 loss : 0.439938 model2 loss : 0.015961
[01:11:31.658] iteration 27000 : model1 loss : 0.436472 model2 loss : 0.015974
[01:11:41.361] iteration 27000 : model1_mean_dice : 0.883720 model1_mean_hd95 : 3.555138
[01:11:50.321] iteration 27000 : model2_mean_dice : 0.882068 model2_mean_hd95 : 3.988818
[01:11:50.341] save model1 to ../model/ACDC/EVILv1_kl0.5_tau0.25_14_1337/unet\model1_iter_27000.pth
[01:11:50.361] save model2 to ../model/ACDC/EVILv1_kl0.5_tau0.25_14_1337/unet\model2_iter_27000.pth
[01:11:50.539] iteration 27001 : model1 loss : 0.440121 model2 loss : 0.016250
[01:11:50.713] iteration 27002 : model1 loss : 0.441074 model2 loss : 0.016334
[01:11:50.884] iteration 27003 : model1 loss : 0.440174 model2 loss : 0.015305
[01:11:51.052] iteration 27004 : model1 loss : 0.437567 model2 loss : 0.016180
[01:11:51.219] iteration 27005 : model1 loss : 0.441006 model2 loss : 0.018578
[01:11:51.386] iteration 27006 : model1 loss : 0.445215 model2 loss : 0.014806
[01:11:53.452] iteration 27007 : model1 loss : 0.436743 model2 loss : 0.015756
[01:11:53.626] iteration 27008 : model1 loss : 0.438226 model2 loss : 0.016801
[01:11:53.800] iteration 27009 : model1 loss : 0.439926 model2 loss : 0.015196
[01:11:53.969] iteration 27010 : model1 loss : 0.440515 model2 loss : 0.016009
[01:11:54.141] iteration 27011 : model1 loss : 0.440713 model2 loss : 0.018203
[01:11:54.312] iteration 27012 : model1 loss : 0.442953 model2 loss : 0.016813
[01:11:54.484] iteration 27013 : model1 loss : 0.442583 model2 loss : 0.017094
[01:11:54.653] iteration 27014 : model1 loss : 0.436653 model2 loss : 0.015233
[01:11:54.823] iteration 27015 : model1 loss : 0.441428 model2 loss : 0.018044
[01:11:54.990] iteration 27016 : model1 loss : 0.438728 model2 loss : 0.016295
[01:11:55.164] iteration 27017 : model1 loss : 0.439979 model2 loss : 0.016038
[01:11:55.337] iteration 27018 : model1 loss : 0.443709 model2 loss : 0.015857
[01:11:55.536] iteration 27019 : model1 loss : 0.438546 model2 loss : 0.014465
[01:11:55.710] iteration 27020 : model1 loss : 0.440182 model2 loss : 0.017583
[01:11:55.879] iteration 27021 : model1 loss : 0.441428 model2 loss : 0.017895
[01:11:56.046] iteration 27022 : model1 loss : 0.438648 model2 loss : 0.015948
[01:11:56.219] iteration 27023 : model1 loss : 0.435145 model2 loss : 0.015195
[01:11:56.403] iteration 27024 : model1 loss : 0.439238 model2 loss : 0.016759
[01:11:56.579] iteration 27025 : model1 loss : 0.441368 model2 loss : 0.017649
[01:11:56.743] iteration 27026 : model1 loss : 0.440340 model2 loss : 0.018699
[01:11:56.911] iteration 27027 : model1 loss : 0.444354 model2 loss : 0.020098
[01:11:59.246] iteration 27028 : model1 loss : 0.442466 model2 loss : 0.018247
[01:11:59.469] iteration 27029 : model1 loss : 0.438714 model2 loss : 0.016151
[01:11:59.690] iteration 27030 : model1 loss : 0.439750 model2 loss : 0.016945
[01:11:59.907] iteration 27031 : model1 loss : 0.441173 model2 loss : 0.015957
[01:12:00.129] iteration 27032 : model1 loss : 0.437470 model2 loss : 0.017360
[01:12:00.307] iteration 27033 : model1 loss : 0.439044 model2 loss : 0.015425
[01:12:00.491] iteration 27034 : model1 loss : 0.442062 model2 loss : 0.017659
[01:12:00.667] iteration 27035 : model1 loss : 0.436329 model2 loss : 0.015820
[01:12:00.846] iteration 27036 : model1 loss : 0.440728 model2 loss : 0.016205
[01:12:01.012] iteration 27037 : model1 loss : 0.439638 model2 loss : 0.016834
[01:12:01.180] iteration 27038 : model1 loss : 0.443896 model2 loss : 0.019263
[01:12:01.348] iteration 27039 : model1 loss : 0.444310 model2 loss : 0.016373
[01:12:01.544] iteration 27040 : model1 loss : 0.437379 model2 loss : 0.016309
[01:12:01.726] iteration 27041 : model1 loss : 0.437201 model2 loss : 0.016417
[01:12:01.895] iteration 27042 : model1 loss : 0.436969 model2 loss : 0.015961
[01:12:02.067] iteration 27043 : model1 loss : 0.439067 model2 loss : 0.015701
[01:12:02.243] iteration 27044 : model1 loss : 0.437642 model2 loss : 0.017088
[01:12:02.418] iteration 27045 : model1 loss : 0.444505 model2 loss : 0.014139
[01:12:02.593] iteration 27046 : model1 loss : 0.442134 model2 loss : 0.018438
[01:12:02.761] iteration 27047 : model1 loss : 0.439456 model2 loss : 0.016019
[01:12:02.932] iteration 27048 : model1 loss : 0.441950 model2 loss : 0.018333
[01:12:05.121] iteration 27049 : model1 loss : 0.441700 model2 loss : 0.016438
[01:12:05.290] iteration 27050 : model1 loss : 0.443205 model2 loss : 0.017529
[01:12:05.460] iteration 27051 : model1 loss : 0.441863 model2 loss : 0.017865
[01:12:05.643] iteration 27052 : model1 loss : 0.437998 model2 loss : 0.016127
[01:12:05.835] iteration 27053 : model1 loss : 0.436472 model2 loss : 0.014621
[01:12:06.021] iteration 27054 : model1 loss : 0.442232 model2 loss : 0.019014
[01:12:06.205] iteration 27055 : model1 loss : 0.441169 model2 loss : 0.017313
[01:12:06.390] iteration 27056 : model1 loss : 0.439375 model2 loss : 0.015604
[01:12:06.574] iteration 27057 : model1 loss : 0.438218 model2 loss : 0.017368
[01:12:06.758] iteration 27058 : model1 loss : 0.441355 model2 loss : 0.014751
[01:12:06.944] iteration 27059 : model1 loss : 0.439921 model2 loss : 0.016713
[01:12:07.124] iteration 27060 : model1 loss : 0.439102 model2 loss : 0.015454
[01:12:07.293] iteration 27061 : model1 loss : 0.438241 model2 loss : 0.017045
[01:12:07.462] iteration 27062 : model1 loss : 0.443881 model2 loss : 0.017129
[01:12:07.630] iteration 27063 : model1 loss : 0.438907 model2 loss : 0.015676
[01:12:07.798] iteration 27064 : model1 loss : 0.434502 model2 loss : 0.015803
[01:12:07.969] iteration 27065 : model1 loss : 0.441648 model2 loss : 0.016666
[01:12:08.140] iteration 27066 : model1 loss : 0.440059 model2 loss : 0.017811
[01:12:08.312] iteration 27067 : model1 loss : 0.445689 model2 loss : 0.019538
[01:12:08.477] iteration 27068 : model1 loss : 0.438487 model2 loss : 0.015148
[01:12:08.645] iteration 27069 : model1 loss : 0.436441 model2 loss : 0.014283
[01:12:10.675] iteration 27070 : model1 loss : 0.438189 model2 loss : 0.016044
[01:12:10.850] iteration 27071 : model1 loss : 0.443711 model2 loss : 0.017435
[01:12:11.025] iteration 27072 : model1 loss : 0.439028 model2 loss : 0.015173
[01:12:11.197] iteration 27073 : model1 loss : 0.440658 model2 loss : 0.015272
[01:12:11.366] iteration 27074 : model1 loss : 0.433336 model2 loss : 0.014362
[01:12:11.536] iteration 27075 : model1 loss : 0.439736 model2 loss : 0.015563
[01:12:11.708] iteration 27076 : model1 loss : 0.438783 model2 loss : 0.015667
[01:12:11.882] iteration 27077 : model1 loss : 0.443215 model2 loss : 0.015622
[01:12:12.057] iteration 27078 : model1 loss : 0.442685 model2 loss : 0.015821
[01:12:12.225] iteration 27079 : model1 loss : 0.443148 model2 loss : 0.016899
[01:12:12.392] iteration 27080 : model1 loss : 0.439351 model2 loss : 0.016416
[01:12:12.559] iteration 27081 : model1 loss : 0.439037 model2 loss : 0.016007
[01:12:12.727] iteration 27082 : model1 loss : 0.441922 model2 loss : 0.016294
[01:12:12.897] iteration 27083 : model1 loss : 0.439195 model2 loss : 0.015543
[01:12:13.067] iteration 27084 : model1 loss : 0.438948 model2 loss : 0.016802
[01:12:13.236] iteration 27085 : model1 loss : 0.443042 model2 loss : 0.019453
[01:12:13.405] iteration 27086 : model1 loss : 0.435670 model2 loss : 0.016620
[01:12:13.574] iteration 27087 : model1 loss : 0.439742 model2 loss : 0.015961
[01:12:13.742] iteration 27088 : model1 loss : 0.440330 model2 loss : 0.017208
[01:12:13.908] iteration 27089 : model1 loss : 0.442942 model2 loss : 0.018763
[01:12:14.078] iteration 27090 : model1 loss : 0.438959 model2 loss : 0.017010
[01:12:16.065] iteration 27091 : model1 loss : 0.442035 model2 loss : 0.016787
[01:12:16.237] iteration 27092 : model1 loss : 0.440669 model2 loss : 0.015740
[01:12:16.405] iteration 27093 : model1 loss : 0.441013 model2 loss : 0.015751
[01:12:16.574] iteration 27094 : model1 loss : 0.442777 model2 loss : 0.017531
[01:12:16.744] iteration 27095 : model1 loss : 0.439173 model2 loss : 0.014502
[01:12:16.912] iteration 27096 : model1 loss : 0.438673 model2 loss : 0.017621
[01:12:17.083] iteration 27097 : model1 loss : 0.439212 model2 loss : 0.015569
[01:12:17.252] iteration 27098 : model1 loss : 0.439859 model2 loss : 0.015770
[01:12:17.422] iteration 27099 : model1 loss : 0.437747 model2 loss : 0.015740
[01:12:17.588] iteration 27100 : model1 loss : 0.438564 model2 loss : 0.016319
[01:12:17.759] iteration 27101 : model1 loss : 0.439643 model2 loss : 0.016732
[01:12:17.927] iteration 27102 : model1 loss : 0.436737 model2 loss : 0.016091
[01:12:18.101] iteration 27103 : model1 loss : 0.439626 model2 loss : 0.017405
[01:12:18.270] iteration 27104 : model1 loss : 0.441794 model2 loss : 0.017804
[01:12:18.439] iteration 27105 : model1 loss : 0.441948 model2 loss : 0.017339
[01:12:18.607] iteration 27106 : model1 loss : 0.439856 model2 loss : 0.015752
[01:12:18.779] iteration 27107 : model1 loss : 0.440765 model2 loss : 0.017846
[01:12:18.949] iteration 27108 : model1 loss : 0.444063 model2 loss : 0.017577
[01:12:19.128] iteration 27109 : model1 loss : 0.440370 model2 loss : 0.013604
[01:12:19.296] iteration 27110 : model1 loss : 0.437787 model2 loss : 0.015501
[01:12:19.465] iteration 27111 : model1 loss : 0.435975 model2 loss : 0.015943
[01:12:21.472] iteration 27112 : model1 loss : 0.440237 model2 loss : 0.019509
[01:12:21.641] iteration 27113 : model1 loss : 0.435621 model2 loss : 0.015987
[01:12:21.811] iteration 27114 : model1 loss : 0.440304 model2 loss : 0.016072
[01:12:21.980] iteration 27115 : model1 loss : 0.439469 model2 loss : 0.015469
[01:12:22.150] iteration 27116 : model1 loss : 0.441904 model2 loss : 0.016085
[01:12:22.322] iteration 27117 : model1 loss : 0.435348 model2 loss : 0.015729
[01:12:22.494] iteration 27118 : model1 loss : 0.441827 model2 loss : 0.014324
[01:12:22.662] iteration 27119 : model1 loss : 0.442757 model2 loss : 0.016356
[01:12:22.831] iteration 27120 : model1 loss : 0.436153 model2 loss : 0.016099
[01:12:22.999] iteration 27121 : model1 loss : 0.442624 model2 loss : 0.017243
[01:12:23.169] iteration 27122 : model1 loss : 0.438848 model2 loss : 0.015979
[01:12:23.337] iteration 27123 : model1 loss : 0.440088 model2 loss : 0.017554
[01:12:23.508] iteration 27124 : model1 loss : 0.440184 model2 loss : 0.016657
[01:12:23.675] iteration 27125 : model1 loss : 0.438273 model2 loss : 0.017538
[01:12:23.844] iteration 27126 : model1 loss : 0.441613 model2 loss : 0.016497
[01:12:24.013] iteration 27127 : model1 loss : 0.445307 model2 loss : 0.017973
[01:12:24.181] iteration 27128 : model1 loss : 0.442248 model2 loss : 0.016693
[01:12:24.349] iteration 27129 : model1 loss : 0.439045 model2 loss : 0.014513
[01:12:24.518] iteration 27130 : model1 loss : 0.442009 model2 loss : 0.017103
[01:12:24.685] iteration 27131 : model1 loss : 0.441545 model2 loss : 0.016716
[01:12:24.855] iteration 27132 : model1 loss : 0.436895 model2 loss : 0.015839
[01:12:26.801] iteration 27133 : model1 loss : 0.436565 model2 loss : 0.016228
[01:12:26.967] iteration 27134 : model1 loss : 0.440654 model2 loss : 0.017985
[01:12:27.140] iteration 27135 : model1 loss : 0.441026 model2 loss : 0.015675
[01:12:27.311] iteration 27136 : model1 loss : 0.438700 model2 loss : 0.015281
[01:12:27.484] iteration 27137 : model1 loss : 0.440598 model2 loss : 0.015945
[01:12:27.652] iteration 27138 : model1 loss : 0.439247 model2 loss : 0.016837
[01:12:27.819] iteration 27139 : model1 loss : 0.439989 model2 loss : 0.014882
[01:12:27.987] iteration 27140 : model1 loss : 0.443858 model2 loss : 0.019611
[01:12:28.158] iteration 27141 : model1 loss : 0.440008 model2 loss : 0.018049
[01:12:28.329] iteration 27142 : model1 loss : 0.440159 model2 loss : 0.016732
[01:12:28.498] iteration 27143 : model1 loss : 0.437882 model2 loss : 0.016258
[01:12:28.664] iteration 27144 : model1 loss : 0.447775 model2 loss : 0.019091
[01:12:28.834] iteration 27145 : model1 loss : 0.437216 model2 loss : 0.015032
[01:12:29.002] iteration 27146 : model1 loss : 0.439098 model2 loss : 0.017794
[01:12:29.172] iteration 27147 : model1 loss : 0.441679 model2 loss : 0.017233
[01:12:29.341] iteration 27148 : model1 loss : 0.441318 model2 loss : 0.018333
[01:12:29.512] iteration 27149 : model1 loss : 0.439068 model2 loss : 0.015932
[01:12:29.684] iteration 27150 : model1 loss : 0.437782 model2 loss : 0.015870
[01:12:29.852] iteration 27151 : model1 loss : 0.441239 model2 loss : 0.017301
[01:12:30.019] iteration 27152 : model1 loss : 0.440729 model2 loss : 0.015552
[01:12:30.192] iteration 27153 : model1 loss : 0.437719 model2 loss : 0.016915
[01:12:32.197] iteration 27154 : model1 loss : 0.437481 model2 loss : 0.019121
[01:12:32.366] iteration 27155 : model1 loss : 0.442203 model2 loss : 0.016453
[01:12:32.538] iteration 27156 : model1 loss : 0.442952 model2 loss : 0.020061
[01:12:32.706] iteration 27157 : model1 loss : 0.437088 model2 loss : 0.014965
[01:12:32.879] iteration 27158 : model1 loss : 0.440048 model2 loss : 0.015291
[01:12:33.046] iteration 27159 : model1 loss : 0.437198 model2 loss : 0.015623
[01:12:33.216] iteration 27160 : model1 loss : 0.443381 model2 loss : 0.015895
[01:12:33.384] iteration 27161 : model1 loss : 0.439945 model2 loss : 0.016070
[01:12:33.552] iteration 27162 : model1 loss : 0.442081 model2 loss : 0.018210
[01:12:33.720] iteration 27163 : model1 loss : 0.438957 model2 loss : 0.017402
[01:12:33.890] iteration 27164 : model1 loss : 0.438685 model2 loss : 0.015879
[01:12:34.060] iteration 27165 : model1 loss : 0.441795 model2 loss : 0.015978
[01:12:34.229] iteration 27166 : model1 loss : 0.437808 model2 loss : 0.016312
[01:12:34.397] iteration 27167 : model1 loss : 0.437785 model2 loss : 0.016332
[01:12:34.566] iteration 27168 : model1 loss : 0.445440 model2 loss : 0.015543
[01:12:34.735] iteration 27169 : model1 loss : 0.437268 model2 loss : 0.016343
[01:12:34.904] iteration 27170 : model1 loss : 0.447631 model2 loss : 0.021701
[01:12:35.074] iteration 27171 : model1 loss : 0.442931 model2 loss : 0.017267
[01:12:35.244] iteration 27172 : model1 loss : 0.432933 model2 loss : 0.015369
[01:12:35.411] iteration 27173 : model1 loss : 0.440639 model2 loss : 0.016422
[01:12:35.579] iteration 27174 : model1 loss : 0.438927 model2 loss : 0.016672
[01:12:37.609] iteration 27175 : model1 loss : 0.442722 model2 loss : 0.016212
[01:12:37.777] iteration 27176 : model1 loss : 0.439712 model2 loss : 0.016664
[01:12:37.968] iteration 27177 : model1 loss : 0.439150 model2 loss : 0.014218
[01:12:38.160] iteration 27178 : model1 loss : 0.440409 model2 loss : 0.017296
[01:12:38.337] iteration 27179 : model1 loss : 0.438554 model2 loss : 0.015554
[01:12:38.521] iteration 27180 : model1 loss : 0.441369 model2 loss : 0.016948
[01:12:38.701] iteration 27181 : model1 loss : 0.441703 model2 loss : 0.017785
[01:12:38.906] iteration 27182 : model1 loss : 0.439707 model2 loss : 0.017318
[01:12:39.091] iteration 27183 : model1 loss : 0.438847 model2 loss : 0.020013
[01:12:39.263] iteration 27184 : model1 loss : 0.444767 model2 loss : 0.019167
[01:12:39.430] iteration 27185 : model1 loss : 0.441897 model2 loss : 0.016381
[01:12:39.601] iteration 27186 : model1 loss : 0.443146 model2 loss : 0.018640
[01:12:39.769] iteration 27187 : model1 loss : 0.442643 model2 loss : 0.017274
[01:12:39.967] iteration 27188 : model1 loss : 0.437636 model2 loss : 0.015925
[01:12:40.174] iteration 27189 : model1 loss : 0.435602 model2 loss : 0.015284
[01:12:40.379] iteration 27190 : model1 loss : 0.438014 model2 loss : 0.018902
[01:12:40.583] iteration 27191 : model1 loss : 0.443853 model2 loss : 0.017351
[01:12:40.788] iteration 27192 : model1 loss : 0.439887 model2 loss : 0.016142
[01:12:40.971] iteration 27193 : model1 loss : 0.439891 model2 loss : 0.016551
[01:12:41.170] iteration 27194 : model1 loss : 0.442703 model2 loss : 0.016507
[01:12:41.370] iteration 27195 : model1 loss : 0.431981 model2 loss : 0.015819
[01:12:43.433] iteration 27196 : model1 loss : 0.437702 model2 loss : 0.014701
[01:12:43.614] iteration 27197 : model1 loss : 0.439509 model2 loss : 0.017173
[01:12:43.813] iteration 27198 : model1 loss : 0.436520 model2 loss : 0.016762
[01:12:43.990] iteration 27199 : model1 loss : 0.442654 model2 loss : 0.016856
[01:12:44.159] iteration 27200 : model1 loss : 0.440705 model2 loss : 0.016430
[01:12:44.329] iteration 27201 : model1 loss : 0.437436 model2 loss : 0.017756
[01:12:44.498] iteration 27202 : model1 loss : 0.442847 model2 loss : 0.017842
[01:12:44.666] iteration 27203 : model1 loss : 0.442653 model2 loss : 0.019269
[01:12:44.836] iteration 27204 : model1 loss : 0.437798 model2 loss : 0.017285
[01:12:45.009] iteration 27205 : model1 loss : 0.439087 model2 loss : 0.016579
[01:12:45.179] iteration 27206 : model1 loss : 0.440068 model2 loss : 0.015583
[01:12:45.348] iteration 27207 : model1 loss : 0.441157 model2 loss : 0.016252
[01:12:45.517] iteration 27208 : model1 loss : 0.436543 model2 loss : 0.017147
[01:12:45.709] iteration 27209 : model1 loss : 0.440523 model2 loss : 0.016124
[01:12:45.914] iteration 27210 : model1 loss : 0.443232 model2 loss : 0.016471
[01:12:46.117] iteration 27211 : model1 loss : 0.437963 model2 loss : 0.014794
[01:12:46.321] iteration 27212 : model1 loss : 0.442489 model2 loss : 0.016922
[01:12:46.523] iteration 27213 : model1 loss : 0.443727 model2 loss : 0.016835
[01:12:46.712] iteration 27214 : model1 loss : 0.440616 model2 loss : 0.016915
[01:12:46.878] iteration 27215 : model1 loss : 0.441288 model2 loss : 0.017258
[01:12:47.046] iteration 27216 : model1 loss : 0.435069 model2 loss : 0.013848
[01:12:49.045] iteration 27217 : model1 loss : 0.442836 model2 loss : 0.017078
[01:12:49.228] iteration 27218 : model1 loss : 0.435728 model2 loss : 0.017131
[01:12:49.431] iteration 27219 : model1 loss : 0.441141 model2 loss : 0.016747
[01:12:49.612] iteration 27220 : model1 loss : 0.438619 model2 loss : 0.016576
[01:12:49.820] iteration 27221 : model1 loss : 0.444435 model2 loss : 0.018534
[01:12:50.026] iteration 27222 : model1 loss : 0.441838 model2 loss : 0.017160
[01:12:50.231] iteration 27223 : model1 loss : 0.438985 model2 loss : 0.015995
[01:12:50.436] iteration 27224 : model1 loss : 0.436765 model2 loss : 0.016487
[01:12:50.632] iteration 27225 : model1 loss : 0.444958 model2 loss : 0.018812
[01:12:50.803] iteration 27226 : model1 loss : 0.443413 model2 loss : 0.018129
[01:12:50.973] iteration 27227 : model1 loss : 0.439502 model2 loss : 0.015734
[01:12:51.143] iteration 27228 : model1 loss : 0.437601 model2 loss : 0.015959
[01:12:51.314] iteration 27229 : model1 loss : 0.441971 model2 loss : 0.016523
[01:12:51.483] iteration 27230 : model1 loss : 0.441856 model2 loss : 0.016528
[01:12:51.667] iteration 27231 : model1 loss : 0.440437 model2 loss : 0.016412
[01:12:51.873] iteration 27232 : model1 loss : 0.435809 model2 loss : 0.017020
[01:12:52.079] iteration 27233 : model1 loss : 0.437344 model2 loss : 0.015274
[01:12:52.287] iteration 27234 : model1 loss : 0.443078 model2 loss : 0.016621
[01:12:52.490] iteration 27235 : model1 loss : 0.441204 model2 loss : 0.018060
[01:12:52.656] iteration 27236 : model1 loss : 0.437245 model2 loss : 0.016315
[01:12:52.842] iteration 27237 : model1 loss : 0.438127 model2 loss : 0.016241
[01:12:54.972] iteration 27238 : model1 loss : 0.440581 model2 loss : 0.015946
[01:12:55.170] iteration 27239 : model1 loss : 0.440132 model2 loss : 0.015665
[01:12:55.342] iteration 27240 : model1 loss : 0.440207 model2 loss : 0.016432
[01:12:55.532] iteration 27241 : model1 loss : 0.439743 model2 loss : 0.015077
[01:12:55.734] iteration 27242 : model1 loss : 0.437093 model2 loss : 0.017220
[01:12:55.936] iteration 27243 : model1 loss : 0.442279 model2 loss : 0.018237
[01:12:56.106] iteration 27244 : model1 loss : 0.439389 model2 loss : 0.016143
[01:12:56.276] iteration 27245 : model1 loss : 0.438273 model2 loss : 0.013811
[01:12:56.447] iteration 27246 : model1 loss : 0.443626 model2 loss : 0.017623
[01:12:56.619] iteration 27247 : model1 loss : 0.441043 model2 loss : 0.016931
[01:12:56.789] iteration 27248 : model1 loss : 0.435512 model2 loss : 0.017567
[01:12:56.960] iteration 27249 : model1 loss : 0.437852 model2 loss : 0.017080
[01:12:57.139] iteration 27250 : model1 loss : 0.446288 model2 loss : 0.017170
[01:12:57.313] iteration 27251 : model1 loss : 0.437276 model2 loss : 0.016477
[01:12:57.485] iteration 27252 : model1 loss : 0.438270 model2 loss : 0.017087
[01:12:57.655] iteration 27253 : model1 loss : 0.443337 model2 loss : 0.017776
[01:12:57.823] iteration 27254 : model1 loss : 0.439085 model2 loss : 0.016247
[01:12:57.993] iteration 27255 : model1 loss : 0.437490 model2 loss : 0.016097
[01:12:58.162] iteration 27256 : model1 loss : 0.442838 model2 loss : 0.016531
[01:12:58.335] iteration 27257 : model1 loss : 0.442733 model2 loss : 0.017190
[01:12:58.504] iteration 27258 : model1 loss : 0.439009 model2 loss : 0.016110
[01:13:00.536] iteration 27259 : model1 loss : 0.440393 model2 loss : 0.017409
[01:13:00.705] iteration 27260 : model1 loss : 0.437262 model2 loss : 0.017453
[01:13:00.880] iteration 27261 : model1 loss : 0.440119 model2 loss : 0.014818
[01:13:01.049] iteration 27262 : model1 loss : 0.440718 model2 loss : 0.016178
[01:13:01.217] iteration 27263 : model1 loss : 0.439358 model2 loss : 0.016723
[01:13:01.384] iteration 27264 : model1 loss : 0.443348 model2 loss : 0.018729
[01:13:01.553] iteration 27265 : model1 loss : 0.437741 model2 loss : 0.015834
[01:13:01.721] iteration 27266 : model1 loss : 0.441471 model2 loss : 0.016568
[01:13:01.890] iteration 27267 : model1 loss : 0.441400 model2 loss : 0.016917
[01:13:02.060] iteration 27268 : model1 loss : 0.439152 model2 loss : 0.015961
[01:13:02.229] iteration 27269 : model1 loss : 0.438358 model2 loss : 0.015991
[01:13:02.397] iteration 27270 : model1 loss : 0.438690 model2 loss : 0.016578
[01:13:02.565] iteration 27271 : model1 loss : 0.436692 model2 loss : 0.015335
[01:13:02.734] iteration 27272 : model1 loss : 0.438302 model2 loss : 0.015591
[01:13:02.904] iteration 27273 : model1 loss : 0.444875 model2 loss : 0.016876
[01:13:03.075] iteration 27274 : model1 loss : 0.442802 model2 loss : 0.016988
[01:13:03.251] iteration 27275 : model1 loss : 0.440292 model2 loss : 0.015306
[01:13:03.420] iteration 27276 : model1 loss : 0.437599 model2 loss : 0.016296
[01:13:03.589] iteration 27277 : model1 loss : 0.441547 model2 loss : 0.018092
[01:13:03.755] iteration 27278 : model1 loss : 0.439233 model2 loss : 0.015571
[01:13:03.923] iteration 27279 : model1 loss : 0.440013 model2 loss : 0.014466
[01:13:05.926] iteration 27280 : model1 loss : 0.437055 model2 loss : 0.016778
[01:13:06.093] iteration 27281 : model1 loss : 0.439168 model2 loss : 0.016848
[01:13:06.266] iteration 27282 : model1 loss : 0.439086 model2 loss : 0.014877
[01:13:06.434] iteration 27283 : model1 loss : 0.438124 model2 loss : 0.017790
[01:13:06.605] iteration 27284 : model1 loss : 0.441112 model2 loss : 0.017399
[01:13:06.775] iteration 27285 : model1 loss : 0.438509 model2 loss : 0.015951
[01:13:06.945] iteration 27286 : model1 loss : 0.445956 model2 loss : 0.019153
[01:13:07.116] iteration 27287 : model1 loss : 0.443475 model2 loss : 0.015715
[01:13:07.285] iteration 27288 : model1 loss : 0.436290 model2 loss : 0.015565
[01:13:07.457] iteration 27289 : model1 loss : 0.436965 model2 loss : 0.017717
[01:13:07.629] iteration 27290 : model1 loss : 0.440569 model2 loss : 0.016965
[01:13:07.800] iteration 27291 : model1 loss : 0.445288 model2 loss : 0.020486
[01:13:07.970] iteration 27292 : model1 loss : 0.437630 model2 loss : 0.016669
[01:13:08.141] iteration 27293 : model1 loss : 0.439636 model2 loss : 0.016843
[01:13:08.315] iteration 27294 : model1 loss : 0.443686 model2 loss : 0.015786
[01:13:08.484] iteration 27295 : model1 loss : 0.439616 model2 loss : 0.016391
[01:13:08.655] iteration 27296 : model1 loss : 0.438629 model2 loss : 0.017320
[01:13:08.826] iteration 27297 : model1 loss : 0.440129 model2 loss : 0.017173
[01:13:08.995] iteration 27298 : model1 loss : 0.437514 model2 loss : 0.014314
[01:13:09.163] iteration 27299 : model1 loss : 0.445376 model2 loss : 0.017433
[01:13:09.333] iteration 27300 : model1 loss : 0.438517 model2 loss : 0.016011
[01:13:11.318] iteration 27301 : model1 loss : 0.439304 model2 loss : 0.014762
[01:13:11.488] iteration 27302 : model1 loss : 0.440263 model2 loss : 0.017161
[01:13:11.657] iteration 27303 : model1 loss : 0.440055 model2 loss : 0.018032
[01:13:11.828] iteration 27304 : model1 loss : 0.441047 model2 loss : 0.017774
[01:13:12.000] iteration 27305 : model1 loss : 0.447506 model2 loss : 0.019062
[01:13:12.169] iteration 27306 : model1 loss : 0.439203 model2 loss : 0.017947
[01:13:12.339] iteration 27307 : model1 loss : 0.442490 model2 loss : 0.015684
[01:13:12.508] iteration 27308 : model1 loss : 0.443126 model2 loss : 0.018112
[01:13:12.677] iteration 27309 : model1 loss : 0.439395 model2 loss : 0.016407
[01:13:12.847] iteration 27310 : model1 loss : 0.436800 model2 loss : 0.017720
[01:13:13.018] iteration 27311 : model1 loss : 0.438727 model2 loss : 0.016886
[01:13:13.186] iteration 27312 : model1 loss : 0.438517 model2 loss : 0.015927
[01:13:13.354] iteration 27313 : model1 loss : 0.438811 model2 loss : 0.015304
[01:13:13.523] iteration 27314 : model1 loss : 0.436859 model2 loss : 0.016557
[01:13:13.692] iteration 27315 : model1 loss : 0.443553 model2 loss : 0.017765
[01:13:13.861] iteration 27316 : model1 loss : 0.443859 model2 loss : 0.016024
[01:13:14.031] iteration 27317 : model1 loss : 0.440140 model2 loss : 0.016994
[01:13:14.200] iteration 27318 : model1 loss : 0.441975 model2 loss : 0.016690
[01:13:14.371] iteration 27319 : model1 loss : 0.440497 model2 loss : 0.016788
[01:13:14.539] iteration 27320 : model1 loss : 0.436326 model2 loss : 0.015586
[01:13:14.708] iteration 27321 : model1 loss : 0.437552 model2 loss : 0.015691
[01:13:16.677] iteration 27322 : model1 loss : 0.444920 model2 loss : 0.018134
[01:13:16.845] iteration 27323 : model1 loss : 0.437359 model2 loss : 0.014772
[01:13:17.018] iteration 27324 : model1 loss : 0.439777 model2 loss : 0.016552
[01:13:17.188] iteration 27325 : model1 loss : 0.435854 model2 loss : 0.015310
[01:13:17.357] iteration 27326 : model1 loss : 0.436855 model2 loss : 0.016421
[01:13:17.526] iteration 27327 : model1 loss : 0.434309 model2 loss : 0.016636
[01:13:17.698] iteration 27328 : model1 loss : 0.440668 model2 loss : 0.016167
[01:13:17.867] iteration 27329 : model1 loss : 0.442769 model2 loss : 0.019320
[01:13:18.038] iteration 27330 : model1 loss : 0.445804 model2 loss : 0.019010
[01:13:18.209] iteration 27331 : model1 loss : 0.443576 model2 loss : 0.016481
[01:13:18.378] iteration 27332 : model1 loss : 0.441044 model2 loss : 0.018599
[01:13:18.547] iteration 27333 : model1 loss : 0.437928 model2 loss : 0.014501
[01:13:18.718] iteration 27334 : model1 loss : 0.440912 model2 loss : 0.018186
[01:13:18.888] iteration 27335 : model1 loss : 0.440644 model2 loss : 0.017543
[01:13:19.059] iteration 27336 : model1 loss : 0.446054 model2 loss : 0.019308
[01:13:19.226] iteration 27337 : model1 loss : 0.443756 model2 loss : 0.021523
[01:13:19.395] iteration 27338 : model1 loss : 0.439462 model2 loss : 0.016261
[01:13:19.563] iteration 27339 : model1 loss : 0.437649 model2 loss : 0.015370
[01:13:19.734] iteration 27340 : model1 loss : 0.438254 model2 loss : 0.017051
[01:13:19.903] iteration 27341 : model1 loss : 0.437300 model2 loss : 0.016889
[01:13:20.072] iteration 27342 : model1 loss : 0.439655 model2 loss : 0.018236
[01:13:22.035] iteration 27343 : model1 loss : 0.440297 model2 loss : 0.017668
[01:13:22.204] iteration 27344 : model1 loss : 0.443001 model2 loss : 0.016838
[01:13:22.375] iteration 27345 : model1 loss : 0.440262 model2 loss : 0.016973
[01:13:22.544] iteration 27346 : model1 loss : 0.442044 model2 loss : 0.016558
[01:13:22.713] iteration 27347 : model1 loss : 0.444740 model2 loss : 0.020187
[01:13:22.883] iteration 27348 : model1 loss : 0.436759 model2 loss : 0.016086
[01:13:23.054] iteration 27349 : model1 loss : 0.439531 model2 loss : 0.016449
[01:13:23.223] iteration 27350 : model1 loss : 0.440261 model2 loss : 0.017021
[01:13:23.393] iteration 27351 : model1 loss : 0.438203 model2 loss : 0.017616
[01:13:23.560] iteration 27352 : model1 loss : 0.436266 model2 loss : 0.015454
[01:13:23.729] iteration 27353 : model1 loss : 0.439045 model2 loss : 0.017106
[01:13:23.897] iteration 27354 : model1 loss : 0.439376 model2 loss : 0.016937
[01:13:24.069] iteration 27355 : model1 loss : 0.440271 model2 loss : 0.017545
[01:13:24.237] iteration 27356 : model1 loss : 0.443051 model2 loss : 0.016656
[01:13:24.405] iteration 27357 : model1 loss : 0.438327 model2 loss : 0.015072
[01:13:24.573] iteration 27358 : model1 loss : 0.439621 model2 loss : 0.016376
[01:13:24.743] iteration 27359 : model1 loss : 0.442626 model2 loss : 0.015019
[01:13:24.914] iteration 27360 : model1 loss : 0.441438 model2 loss : 0.015401
[01:13:25.087] iteration 27361 : model1 loss : 0.443871 model2 loss : 0.017040
[01:13:25.257] iteration 27362 : model1 loss : 0.436506 model2 loss : 0.014194
[01:13:25.424] iteration 27363 : model1 loss : 0.436790 model2 loss : 0.017632
[01:13:27.400] iteration 27364 : model1 loss : 0.444377 model2 loss : 0.019637
[01:13:27.569] iteration 27365 : model1 loss : 0.438706 model2 loss : 0.014619
[01:13:27.738] iteration 27366 : model1 loss : 0.443305 model2 loss : 0.019050
[01:13:27.908] iteration 27367 : model1 loss : 0.441333 model2 loss : 0.018107
[01:13:28.079] iteration 27368 : model1 loss : 0.441561 model2 loss : 0.015858
[01:13:28.250] iteration 27369 : model1 loss : 0.437011 model2 loss : 0.015045
[01:13:28.420] iteration 27370 : model1 loss : 0.435721 model2 loss : 0.016122
[01:13:28.588] iteration 27371 : model1 loss : 0.441690 model2 loss : 0.017699
[01:13:28.759] iteration 27372 : model1 loss : 0.438586 model2 loss : 0.016451
[01:13:28.927] iteration 27373 : model1 loss : 0.438020 model2 loss : 0.015986
[01:13:29.097] iteration 27374 : model1 loss : 0.440280 model2 loss : 0.015777
[01:13:29.265] iteration 27375 : model1 loss : 0.435824 model2 loss : 0.017278
[01:13:29.434] iteration 27376 : model1 loss : 0.439423 model2 loss : 0.016860
[01:13:29.601] iteration 27377 : model1 loss : 0.446067 model2 loss : 0.017086
[01:13:29.771] iteration 27378 : model1 loss : 0.436902 model2 loss : 0.016529
[01:13:29.941] iteration 27379 : model1 loss : 0.434981 model2 loss : 0.014738
[01:13:30.114] iteration 27380 : model1 loss : 0.436852 model2 loss : 0.015109
[01:13:30.282] iteration 27381 : model1 loss : 0.442387 model2 loss : 0.016561
[01:13:30.449] iteration 27382 : model1 loss : 0.441777 model2 loss : 0.016630
[01:13:30.616] iteration 27383 : model1 loss : 0.444247 model2 loss : 0.017722
[01:13:30.783] iteration 27384 : model1 loss : 0.443960 model2 loss : 0.018843
[01:13:32.772] iteration 27385 : model1 loss : 0.443386 model2 loss : 0.017196
[01:13:32.953] iteration 27386 : model1 loss : 0.438224 model2 loss : 0.017446
[01:13:33.125] iteration 27387 : model1 loss : 0.441183 model2 loss : 0.016062
[01:13:33.295] iteration 27388 : model1 loss : 0.440765 model2 loss : 0.015938
[01:13:33.463] iteration 27389 : model1 loss : 0.445306 model2 loss : 0.017423
[01:13:33.630] iteration 27390 : model1 loss : 0.442419 model2 loss : 0.015990
[01:13:33.800] iteration 27391 : model1 loss : 0.437822 model2 loss : 0.017731
[01:13:33.969] iteration 27392 : model1 loss : 0.444098 model2 loss : 0.015999
[01:13:34.141] iteration 27393 : model1 loss : 0.436691 model2 loss : 0.014342
[01:13:34.313] iteration 27394 : model1 loss : 0.440056 model2 loss : 0.018105
[01:13:34.484] iteration 27395 : model1 loss : 0.442727 model2 loss : 0.016659
[01:13:34.651] iteration 27396 : model1 loss : 0.438813 model2 loss : 0.015524
[01:13:34.821] iteration 27397 : model1 loss : 0.432534 model2 loss : 0.016316
[01:13:34.989] iteration 27398 : model1 loss : 0.440036 model2 loss : 0.016085
[01:13:35.158] iteration 27399 : model1 loss : 0.441084 model2 loss : 0.017860
[01:13:35.328] iteration 27400 : model1 loss : 0.441672 model2 loss : 0.016807
[01:13:35.498] iteration 27401 : model1 loss : 0.441579 model2 loss : 0.017440
[01:13:35.666] iteration 27402 : model1 loss : 0.441241 model2 loss : 0.016442
[01:13:35.836] iteration 27403 : model1 loss : 0.438659 model2 loss : 0.017522
[01:13:36.004] iteration 27404 : model1 loss : 0.439719 model2 loss : 0.017464
[01:13:36.172] iteration 27405 : model1 loss : 0.443150 model2 loss : 0.019036
[01:13:38.164] iteration 27406 : model1 loss : 0.441620 model2 loss : 0.017876
[01:13:38.335] iteration 27407 : model1 loss : 0.442757 model2 loss : 0.015570
[01:13:38.507] iteration 27408 : model1 loss : 0.434366 model2 loss : 0.014946
[01:13:38.677] iteration 27409 : model1 loss : 0.433815 model2 loss : 0.015009
[01:13:38.848] iteration 27410 : model1 loss : 0.444619 model2 loss : 0.017264
[01:13:39.017] iteration 27411 : model1 loss : 0.441209 model2 loss : 0.015424
[01:13:39.188] iteration 27412 : model1 loss : 0.438998 model2 loss : 0.017033
[01:13:39.358] iteration 27413 : model1 loss : 0.433478 model2 loss : 0.017160
[01:13:39.526] iteration 27414 : model1 loss : 0.439965 model2 loss : 0.016136
[01:13:39.693] iteration 27415 : model1 loss : 0.445650 model2 loss : 0.020372
[01:13:39.864] iteration 27416 : model1 loss : 0.437391 model2 loss : 0.015347
[01:13:40.039] iteration 27417 : model1 loss : 0.439084 model2 loss : 0.016106
[01:13:40.210] iteration 27418 : model1 loss : 0.440011 model2 loss : 0.017883
[01:13:40.379] iteration 27419 : model1 loss : 0.440092 model2 loss : 0.016536
[01:13:40.548] iteration 27420 : model1 loss : 0.439366 model2 loss : 0.016300
[01:13:40.717] iteration 27421 : model1 loss : 0.440931 model2 loss : 0.017535
[01:13:40.888] iteration 27422 : model1 loss : 0.444239 model2 loss : 0.018586
[01:13:41.075] iteration 27423 : model1 loss : 0.442622 model2 loss : 0.017922
[01:13:41.251] iteration 27424 : model1 loss : 0.442695 model2 loss : 0.016724
[01:13:41.418] iteration 27425 : model1 loss : 0.439941 model2 loss : 0.016262
[01:13:41.617] iteration 27426 : model1 loss : 0.441906 model2 loss : 0.018462
[01:13:43.680] iteration 27427 : model1 loss : 0.438081 model2 loss : 0.015557
[01:13:43.852] iteration 27428 : model1 loss : 0.442749 model2 loss : 0.017841
[01:13:44.021] iteration 27429 : model1 loss : 0.439806 model2 loss : 0.016373
[01:13:44.191] iteration 27430 : model1 loss : 0.441829 model2 loss : 0.016735
[01:13:44.360] iteration 27431 : model1 loss : 0.435838 model2 loss : 0.017893
[01:13:44.528] iteration 27432 : model1 loss : 0.440712 model2 loss : 0.014979
[01:13:44.699] iteration 27433 : model1 loss : 0.440684 model2 loss : 0.015458
[01:13:44.869] iteration 27434 : model1 loss : 0.436502 model2 loss : 0.016612
[01:13:45.040] iteration 27435 : model1 loss : 0.440768 model2 loss : 0.015983
[01:13:45.209] iteration 27436 : model1 loss : 0.440076 model2 loss : 0.016293
[01:13:45.378] iteration 27437 : model1 loss : 0.440360 model2 loss : 0.016760
[01:13:45.546] iteration 27438 : model1 loss : 0.438639 model2 loss : 0.015912
[01:13:45.750] iteration 27439 : model1 loss : 0.443078 model2 loss : 0.019020
[01:13:45.954] iteration 27440 : model1 loss : 0.437762 model2 loss : 0.016724
[01:13:46.165] iteration 27441 : model1 loss : 0.441493 model2 loss : 0.015484
[01:13:46.371] iteration 27442 : model1 loss : 0.439962 model2 loss : 0.016998
[01:13:46.572] iteration 27443 : model1 loss : 0.441365 model2 loss : 0.017720
[01:13:46.780] iteration 27444 : model1 loss : 0.441916 model2 loss : 0.016730
[01:13:46.988] iteration 27445 : model1 loss : 0.441943 model2 loss : 0.017725
[01:13:47.164] iteration 27446 : model1 loss : 0.441240 model2 loss : 0.015461
[01:13:47.337] iteration 27447 : model1 loss : 0.437270 model2 loss : 0.015615
[01:13:50.204] iteration 27448 : model1 loss : 0.441698 model2 loss : 0.017099
[01:13:50.377] iteration 27449 : model1 loss : 0.439278 model2 loss : 0.014734
[01:13:50.550] iteration 27450 : model1 loss : 0.441988 model2 loss : 0.015731
[01:13:50.722] iteration 27451 : model1 loss : 0.438843 model2 loss : 0.017138
[01:13:50.895] iteration 27452 : model1 loss : 0.440604 model2 loss : 0.018477
[01:13:51.068] iteration 27453 : model1 loss : 0.436169 model2 loss : 0.014989
[01:13:51.238] iteration 27454 : model1 loss : 0.438075 model2 loss : 0.015748
[01:13:51.407] iteration 27455 : model1 loss : 0.442727 model2 loss : 0.017283
[01:13:51.582] iteration 27456 : model1 loss : 0.444857 model2 loss : 0.017150
[01:13:51.749] iteration 27457 : model1 loss : 0.441752 model2 loss : 0.015674
[01:13:51.919] iteration 27458 : model1 loss : 0.436658 model2 loss : 0.017625
[01:13:52.091] iteration 27459 : model1 loss : 0.439681 model2 loss : 0.015988
[01:13:52.262] iteration 27460 : model1 loss : 0.439445 model2 loss : 0.014746
[01:13:52.431] iteration 27461 : model1 loss : 0.438510 model2 loss : 0.015209
[01:13:52.604] iteration 27462 : model1 loss : 0.443105 model2 loss : 0.016876
[01:13:52.782] iteration 27463 : model1 loss : 0.439287 model2 loss : 0.015955
[01:13:52.950] iteration 27464 : model1 loss : 0.442114 model2 loss : 0.020178
[01:13:53.126] iteration 27465 : model1 loss : 0.440951 model2 loss : 0.015891
[01:13:53.296] iteration 27466 : model1 loss : 0.438536 model2 loss : 0.014668
[01:13:53.464] iteration 27467 : model1 loss : 0.442024 model2 loss : 0.018991
[01:13:53.635] iteration 27468 : model1 loss : 0.437348 model2 loss : 0.016204
[01:13:55.671] iteration 27469 : model1 loss : 0.442003 model2 loss : 0.014885
[01:13:55.841] iteration 27470 : model1 loss : 0.439483 model2 loss : 0.017731
[01:13:56.018] iteration 27471 : model1 loss : 0.439168 model2 loss : 0.017397
[01:13:56.189] iteration 27472 : model1 loss : 0.438198 model2 loss : 0.016762
[01:13:56.361] iteration 27473 : model1 loss : 0.435297 model2 loss : 0.015453
[01:13:56.549] iteration 27474 : model1 loss : 0.441735 model2 loss : 0.015665
[01:13:56.725] iteration 27475 : model1 loss : 0.439764 model2 loss : 0.016712
[01:13:56.896] iteration 27476 : model1 loss : 0.441644 model2 loss : 0.018869
[01:13:57.074] iteration 27477 : model1 loss : 0.442618 model2 loss : 0.014823
[01:13:57.243] iteration 27478 : model1 loss : 0.436988 model2 loss : 0.015235
[01:13:57.417] iteration 27479 : model1 loss : 0.443973 model2 loss : 0.016209
[01:13:57.591] iteration 27480 : model1 loss : 0.444144 model2 loss : 0.016063
[01:13:57.776] iteration 27481 : model1 loss : 0.439549 model2 loss : 0.017852
[01:13:57.947] iteration 27482 : model1 loss : 0.443717 model2 loss : 0.018724
[01:13:58.129] iteration 27483 : model1 loss : 0.439024 model2 loss : 0.016927
[01:13:58.299] iteration 27484 : model1 loss : 0.440122 model2 loss : 0.016557
[01:13:58.470] iteration 27485 : model1 loss : 0.438500 model2 loss : 0.016342
[01:13:58.641] iteration 27486 : model1 loss : 0.438888 model2 loss : 0.016847
[01:13:58.816] iteration 27487 : model1 loss : 0.439138 model2 loss : 0.015685
[01:13:58.982] iteration 27488 : model1 loss : 0.440483 model2 loss : 0.016914
[01:13:59.159] iteration 27489 : model1 loss : 0.440527 model2 loss : 0.017383
[01:14:01.183] iteration 27490 : model1 loss : 0.441221 model2 loss : 0.016314
[01:14:01.357] iteration 27491 : model1 loss : 0.437658 model2 loss : 0.015373
[01:14:01.531] iteration 27492 : model1 loss : 0.441121 model2 loss : 0.015914
[01:14:01.704] iteration 27493 : model1 loss : 0.442149 model2 loss : 0.017337
[01:14:01.877] iteration 27494 : model1 loss : 0.440170 model2 loss : 0.017984
[01:14:02.047] iteration 27495 : model1 loss : 0.438969 model2 loss : 0.018318
[01:14:02.222] iteration 27496 : model1 loss : 0.439223 model2 loss : 0.014712
[01:14:02.391] iteration 27497 : model1 loss : 0.435578 model2 loss : 0.016516
[01:14:02.565] iteration 27498 : model1 loss : 0.439787 model2 loss : 0.017735
[01:14:02.735] iteration 27499 : model1 loss : 0.440843 model2 loss : 0.016284
[01:14:02.907] iteration 27500 : model1 loss : 0.441712 model2 loss : 0.016721
[01:14:03.082] iteration 27501 : model1 loss : 0.437109 model2 loss : 0.016069
[01:14:03.258] iteration 27502 : model1 loss : 0.439169 model2 loss : 0.014738
[01:14:03.425] iteration 27503 : model1 loss : 0.440729 model2 loss : 0.014866
[01:14:03.598] iteration 27504 : model1 loss : 0.445162 model2 loss : 0.018726
[01:14:03.767] iteration 27505 : model1 loss : 0.443556 model2 loss : 0.017555
[01:14:03.942] iteration 27506 : model1 loss : 0.440930 model2 loss : 0.015801
[01:14:04.134] iteration 27507 : model1 loss : 0.441167 model2 loss : 0.016285
[01:14:04.313] iteration 27508 : model1 loss : 0.439001 model2 loss : 0.016216
[01:14:04.481] iteration 27509 : model1 loss : 0.441924 model2 loss : 0.017799
[01:14:04.655] iteration 27510 : model1 loss : 0.439099 model2 loss : 0.016713
[01:14:06.710] iteration 27511 : model1 loss : 0.439620 model2 loss : 0.017046
[01:14:06.907] iteration 27512 : model1 loss : 0.443184 model2 loss : 0.017097
[01:14:07.099] iteration 27513 : model1 loss : 0.438064 model2 loss : 0.018832
[01:14:07.274] iteration 27514 : model1 loss : 0.442445 model2 loss : 0.016002
[01:14:07.449] iteration 27515 : model1 loss : 0.433531 model2 loss : 0.015337
[01:14:07.626] iteration 27516 : model1 loss : 0.438569 model2 loss : 0.016038
[01:14:07.804] iteration 27517 : model1 loss : 0.442004 model2 loss : 0.015834
[01:14:07.983] iteration 27518 : model1 loss : 0.437797 model2 loss : 0.014746
[01:14:08.171] iteration 27519 : model1 loss : 0.435540 model2 loss : 0.015354
[01:14:08.348] iteration 27520 : model1 loss : 0.440069 model2 loss : 0.014933
[01:14:08.526] iteration 27521 : model1 loss : 0.442460 model2 loss : 0.018548
[01:14:08.712] iteration 27522 : model1 loss : 0.440531 model2 loss : 0.019040
[01:14:08.891] iteration 27523 : model1 loss : 0.436355 model2 loss : 0.015706
[01:14:09.064] iteration 27524 : model1 loss : 0.446167 model2 loss : 0.019200
[01:14:09.240] iteration 27525 : model1 loss : 0.442072 model2 loss : 0.016596
[01:14:09.408] iteration 27526 : model1 loss : 0.440959 model2 loss : 0.014901
[01:14:09.584] iteration 27527 : model1 loss : 0.442977 model2 loss : 0.016591
[01:14:09.752] iteration 27528 : model1 loss : 0.439272 model2 loss : 0.018588
[01:14:09.929] iteration 27529 : model1 loss : 0.443482 model2 loss : 0.016587
[01:14:10.103] iteration 27530 : model1 loss : 0.438656 model2 loss : 0.016550
[01:14:10.277] iteration 27531 : model1 loss : 0.440625 model2 loss : 0.015698
[01:14:12.268] iteration 27532 : model1 loss : 0.440378 model2 loss : 0.015591
[01:14:12.452] iteration 27533 : model1 loss : 0.440892 model2 loss : 0.016392
[01:14:12.653] iteration 27534 : model1 loss : 0.437313 model2 loss : 0.016224
[01:14:12.837] iteration 27535 : model1 loss : 0.437665 model2 loss : 0.015479
[01:14:13.015] iteration 27536 : model1 loss : 0.438911 model2 loss : 0.018675
[01:14:13.199] iteration 27537 : model1 loss : 0.445950 model2 loss : 0.017491
[01:14:13.390] iteration 27538 : model1 loss : 0.438803 model2 loss : 0.016031
[01:14:13.582] iteration 27539 : model1 loss : 0.435201 model2 loss : 0.016796
[01:14:13.774] iteration 27540 : model1 loss : 0.445925 model2 loss : 0.016018
[01:14:13.946] iteration 27541 : model1 loss : 0.434851 model2 loss : 0.015971
[01:14:14.120] iteration 27542 : model1 loss : 0.442977 model2 loss : 0.016570
[01:14:14.293] iteration 27543 : model1 loss : 0.441180 model2 loss : 0.018051
[01:14:14.463] iteration 27544 : model1 loss : 0.439716 model2 loss : 0.016013
[01:14:14.637] iteration 27545 : model1 loss : 0.440126 model2 loss : 0.017206
[01:14:14.815] iteration 27546 : model1 loss : 0.437630 model2 loss : 0.017344
[01:14:14.991] iteration 27547 : model1 loss : 0.442754 model2 loss : 0.016778
[01:14:15.162] iteration 27548 : model1 loss : 0.441073 model2 loss : 0.016324
[01:14:15.335] iteration 27549 : model1 loss : 0.439738 model2 loss : 0.016065
[01:14:15.506] iteration 27550 : model1 loss : 0.440965 model2 loss : 0.016234
[01:14:15.673] iteration 27551 : model1 loss : 0.440310 model2 loss : 0.016437
[01:14:15.845] iteration 27552 : model1 loss : 0.438720 model2 loss : 0.017735
[01:14:17.882] iteration 27553 : model1 loss : 0.440858 model2 loss : 0.016984
[01:14:18.051] iteration 27554 : model1 loss : 0.441122 model2 loss : 0.019222
[01:14:18.226] iteration 27555 : model1 loss : 0.441652 model2 loss : 0.016655
[01:14:18.394] iteration 27556 : model1 loss : 0.443235 model2 loss : 0.019545
[01:14:18.568] iteration 27557 : model1 loss : 0.439515 model2 loss : 0.016280
[01:14:18.736] iteration 27558 : model1 loss : 0.438948 model2 loss : 0.017205
[01:14:18.910] iteration 27559 : model1 loss : 0.444272 model2 loss : 0.017607
[01:14:19.079] iteration 27560 : model1 loss : 0.440843 model2 loss : 0.016721
[01:14:19.250] iteration 27561 : model1 loss : 0.440845 model2 loss : 0.015269
[01:14:19.418] iteration 27562 : model1 loss : 0.440297 model2 loss : 0.017270
[01:14:19.591] iteration 27563 : model1 loss : 0.439175 model2 loss : 0.015972
[01:14:19.761] iteration 27564 : model1 loss : 0.441274 model2 loss : 0.016420
[01:14:19.937] iteration 27565 : model1 loss : 0.441225 model2 loss : 0.018366
[01:14:20.107] iteration 27566 : model1 loss : 0.438765 model2 loss : 0.016903
[01:14:20.279] iteration 27567 : model1 loss : 0.437397 model2 loss : 0.016853
[01:14:20.447] iteration 27568 : model1 loss : 0.442439 model2 loss : 0.016303
[01:14:20.618] iteration 27569 : model1 loss : 0.436332 model2 loss : 0.016188
[01:14:20.786] iteration 27570 : model1 loss : 0.446487 model2 loss : 0.021066
[01:14:20.965] iteration 27571 : model1 loss : 0.436182 model2 loss : 0.015657
[01:14:21.134] iteration 27572 : model1 loss : 0.436039 model2 loss : 0.015789
[01:14:21.306] iteration 27573 : model1 loss : 0.439591 model2 loss : 0.015709
[01:14:23.338] iteration 27574 : model1 loss : 0.435807 model2 loss : 0.016209
[01:14:23.509] iteration 27575 : model1 loss : 0.440764 model2 loss : 0.015140
[01:14:23.683] iteration 27576 : model1 loss : 0.436880 model2 loss : 0.014333
[01:14:23.850] iteration 27577 : model1 loss : 0.443169 model2 loss : 0.018291
[01:14:24.021] iteration 27578 : model1 loss : 0.440032 model2 loss : 0.017147
[01:14:24.190] iteration 27579 : model1 loss : 0.437774 model2 loss : 0.014404
[01:14:24.360] iteration 27580 : model1 loss : 0.441838 model2 loss : 0.015835
[01:14:24.540] iteration 27581 : model1 loss : 0.441542 model2 loss : 0.016526
[01:14:24.712] iteration 27582 : model1 loss : 0.435733 model2 loss : 0.016699
[01:14:24.882] iteration 27583 : model1 loss : 0.438887 model2 loss : 0.014684
[01:14:25.055] iteration 27584 : model1 loss : 0.439245 model2 loss : 0.016028
[01:14:25.224] iteration 27585 : model1 loss : 0.439999 model2 loss : 0.017525
[01:14:25.396] iteration 27586 : model1 loss : 0.440818 model2 loss : 0.016462
[01:14:25.563] iteration 27587 : model1 loss : 0.439983 model2 loss : 0.016511
[01:14:25.738] iteration 27588 : model1 loss : 0.443195 model2 loss : 0.015424
[01:14:25.908] iteration 27589 : model1 loss : 0.439157 model2 loss : 0.018441
[01:14:26.081] iteration 27590 : model1 loss : 0.437583 model2 loss : 0.017095
[01:14:26.248] iteration 27591 : model1 loss : 0.439084 model2 loss : 0.016296
[01:14:26.423] iteration 27592 : model1 loss : 0.442147 model2 loss : 0.017204
[01:14:26.595] iteration 27593 : model1 loss : 0.445391 model2 loss : 0.016955
[01:14:26.769] iteration 27594 : model1 loss : 0.441700 model2 loss : 0.017972
[01:14:28.865] iteration 27595 : model1 loss : 0.439514 model2 loss : 0.014599
[01:14:29.038] iteration 27596 : model1 loss : 0.437568 model2 loss : 0.015989
[01:14:29.236] iteration 27597 : model1 loss : 0.443194 model2 loss : 0.019125
[01:14:29.439] iteration 27598 : model1 loss : 0.437950 model2 loss : 0.016729
[01:14:29.626] iteration 27599 : model1 loss : 0.439906 model2 loss : 0.017364
[01:14:29.796] iteration 27600 : model1 loss : 0.441468 model2 loss : 0.016497
[01:14:29.967] iteration 27601 : model1 loss : 0.441317 model2 loss : 0.016492
[01:14:30.138] iteration 27602 : model1 loss : 0.437766 model2 loss : 0.016638
[01:14:30.312] iteration 27603 : model1 loss : 0.440100 model2 loss : 0.017912
[01:14:30.481] iteration 27604 : model1 loss : 0.439422 model2 loss : 0.016587
[01:14:30.658] iteration 27605 : model1 loss : 0.435746 model2 loss : 0.016570
[01:14:30.832] iteration 27606 : model1 loss : 0.432053 model2 loss : 0.015297
[01:14:31.009] iteration 27607 : model1 loss : 0.444589 model2 loss : 0.017376
[01:14:31.176] iteration 27608 : model1 loss : 0.444307 model2 loss : 0.016489
[01:14:31.348] iteration 27609 : model1 loss : 0.444187 model2 loss : 0.017500
[01:14:31.516] iteration 27610 : model1 loss : 0.446297 model2 loss : 0.020129
[01:14:31.691] iteration 27611 : model1 loss : 0.442065 model2 loss : 0.019053
[01:14:31.862] iteration 27612 : model1 loss : 0.438632 model2 loss : 0.016889
[01:14:32.036] iteration 27613 : model1 loss : 0.436680 model2 loss : 0.016313
[01:14:32.203] iteration 27614 : model1 loss : 0.437425 model2 loss : 0.016895
[01:14:32.374] iteration 27615 : model1 loss : 0.445159 model2 loss : 0.017776
[01:14:34.389] iteration 27616 : model1 loss : 0.443058 model2 loss : 0.015871
[01:14:34.575] iteration 27617 : model1 loss : 0.440866 model2 loss : 0.016479
[01:14:34.752] iteration 27618 : model1 loss : 0.438869 model2 loss : 0.015700
[01:14:34.922] iteration 27619 : model1 loss : 0.438803 model2 loss : 0.014426
[01:14:35.099] iteration 27620 : model1 loss : 0.443955 model2 loss : 0.017780
[01:14:35.274] iteration 27621 : model1 loss : 0.441692 model2 loss : 0.016298
[01:14:35.452] iteration 27622 : model1 loss : 0.444057 model2 loss : 0.019290
[01:14:35.665] iteration 27623 : model1 loss : 0.439823 model2 loss : 0.016901
[01:14:35.855] iteration 27624 : model1 loss : 0.439586 model2 loss : 0.016010
[01:14:36.047] iteration 27625 : model1 loss : 0.439986 model2 loss : 0.016602
[01:14:36.246] iteration 27626 : model1 loss : 0.438879 model2 loss : 0.015623
[01:14:36.439] iteration 27627 : model1 loss : 0.441645 model2 loss : 0.014913
[01:14:36.620] iteration 27628 : model1 loss : 0.439772 model2 loss : 0.016779
[01:14:36.796] iteration 27629 : model1 loss : 0.439776 model2 loss : 0.017912
[01:14:36.981] iteration 27630 : model1 loss : 0.438747 model2 loss : 0.015529
[01:14:37.298] iteration 27631 : model1 loss : 0.444605 model2 loss : 0.015424
[01:14:37.471] iteration 27632 : model1 loss : 0.439969 model2 loss : 0.016097
[01:14:37.647] iteration 27633 : model1 loss : 0.436647 model2 loss : 0.016075
[01:14:37.818] iteration 27634 : model1 loss : 0.439012 model2 loss : 0.016300
[01:14:37.988] iteration 27635 : model1 loss : 0.432865 model2 loss : 0.016982
[01:14:38.174] iteration 27636 : model1 loss : 0.435102 model2 loss : 0.015513
[01:14:40.261] iteration 27637 : model1 loss : 0.445632 model2 loss : 0.017997
[01:14:40.461] iteration 27638 : model1 loss : 0.437802 model2 loss : 0.016986
[01:14:40.802] iteration 27639 : model1 loss : 0.438718 model2 loss : 0.014785
[01:14:40.982] iteration 27640 : model1 loss : 0.438914 model2 loss : 0.015738
[01:14:41.157] iteration 27641 : model1 loss : 0.438464 model2 loss : 0.017387
[01:14:41.331] iteration 27642 : model1 loss : 0.436009 model2 loss : 0.016968
[01:14:41.504] iteration 27643 : model1 loss : 0.444891 model2 loss : 0.017107
[01:14:41.675] iteration 27644 : model1 loss : 0.437076 model2 loss : 0.017074
[01:14:41.849] iteration 27645 : model1 loss : 0.438387 model2 loss : 0.015503
[01:14:42.019] iteration 27646 : model1 loss : 0.441152 model2 loss : 0.016407
[01:14:42.191] iteration 27647 : model1 loss : 0.442716 model2 loss : 0.017171
[01:14:42.362] iteration 27648 : model1 loss : 0.444409 model2 loss : 0.017685
[01:14:42.535] iteration 27649 : model1 loss : 0.442609 model2 loss : 0.017817
[01:14:42.705] iteration 27650 : model1 loss : 0.442261 model2 loss : 0.017526
[01:14:42.884] iteration 27651 : model1 loss : 0.437099 model2 loss : 0.015163
[01:14:43.053] iteration 27652 : model1 loss : 0.440332 model2 loss : 0.016362
[01:14:43.227] iteration 27653 : model1 loss : 0.444577 model2 loss : 0.015757
[01:14:43.398] iteration 27654 : model1 loss : 0.441186 model2 loss : 0.015642
[01:14:43.568] iteration 27655 : model1 loss : 0.438563 model2 loss : 0.017802
[01:14:43.742] iteration 27656 : model1 loss : 0.438263 model2 loss : 0.015946
[01:14:43.925] iteration 27657 : model1 loss : 0.437095 model2 loss : 0.015341
[01:14:45.974] iteration 27658 : model1 loss : 0.439016 model2 loss : 0.015712
[01:14:46.143] iteration 27659 : model1 loss : 0.446185 model2 loss : 0.018303
[01:14:46.323] iteration 27660 : model1 loss : 0.439961 model2 loss : 0.018723
[01:14:46.493] iteration 27661 : model1 loss : 0.440021 model2 loss : 0.017285
[01:14:46.666] iteration 27662 : model1 loss : 0.438009 model2 loss : 0.014837
[01:14:46.839] iteration 27663 : model1 loss : 0.438492 model2 loss : 0.017018
[01:14:47.011] iteration 27664 : model1 loss : 0.441785 model2 loss : 0.016250
[01:14:47.180] iteration 27665 : model1 loss : 0.440412 model2 loss : 0.016771
[01:14:47.357] iteration 27666 : model1 loss : 0.441360 model2 loss : 0.017545
[01:14:47.526] iteration 27667 : model1 loss : 0.441091 model2 loss : 0.016698
[01:14:47.698] iteration 27668 : model1 loss : 0.437366 model2 loss : 0.018865
[01:14:47.871] iteration 27669 : model1 loss : 0.437622 model2 loss : 0.017735
[01:14:48.047] iteration 27670 : model1 loss : 0.441305 model2 loss : 0.017734
[01:14:48.228] iteration 27671 : model1 loss : 0.440052 model2 loss : 0.016267
[01:14:48.412] iteration 27672 : model1 loss : 0.437586 model2 loss : 0.015665
[01:14:48.589] iteration 27673 : model1 loss : 0.440489 model2 loss : 0.015694
[01:14:48.775] iteration 27674 : model1 loss : 0.439700 model2 loss : 0.017518
[01:14:48.946] iteration 27675 : model1 loss : 0.440077 model2 loss : 0.016118
[01:14:49.131] iteration 27676 : model1 loss : 0.440120 model2 loss : 0.015718
[01:14:49.332] iteration 27677 : model1 loss : 0.445599 model2 loss : 0.019846
[01:14:49.525] iteration 27678 : model1 loss : 0.440878 model2 loss : 0.015712
[01:14:51.729] iteration 27679 : model1 loss : 0.440737 model2 loss : 0.015920
[01:14:51.901] iteration 27680 : model1 loss : 0.440462 model2 loss : 0.015068
[01:14:52.074] iteration 27681 : model1 loss : 0.438214 model2 loss : 0.015431
[01:14:52.242] iteration 27682 : model1 loss : 0.439464 model2 loss : 0.017298
[01:14:52.418] iteration 27683 : model1 loss : 0.439635 model2 loss : 0.019759
[01:14:52.597] iteration 27684 : model1 loss : 0.440784 model2 loss : 0.015591
[01:14:52.783] iteration 27685 : model1 loss : 0.442310 model2 loss : 0.017825
[01:14:52.955] iteration 27686 : model1 loss : 0.433582 model2 loss : 0.015118
[01:14:53.129] iteration 27687 : model1 loss : 0.439305 model2 loss : 0.016665
[01:14:53.311] iteration 27688 : model1 loss : 0.440450 model2 loss : 0.015493
[01:14:53.493] iteration 27689 : model1 loss : 0.440604 model2 loss : 0.016477
[01:14:53.675] iteration 27690 : model1 loss : 0.442543 model2 loss : 0.019119
[01:14:53.856] iteration 27691 : model1 loss : 0.445329 model2 loss : 0.016989
[01:14:54.033] iteration 27692 : model1 loss : 0.444252 model2 loss : 0.015942
[01:14:54.204] iteration 27693 : model1 loss : 0.441070 model2 loss : 0.017272
[01:14:54.375] iteration 27694 : model1 loss : 0.441180 model2 loss : 0.017840
[01:14:54.550] iteration 27695 : model1 loss : 0.436583 model2 loss : 0.016194
[01:14:54.728] iteration 27696 : model1 loss : 0.440115 model2 loss : 0.015851
[01:14:54.911] iteration 27697 : model1 loss : 0.440469 model2 loss : 0.018004
[01:14:55.087] iteration 27698 : model1 loss : 0.437278 model2 loss : 0.015993
[01:14:55.266] iteration 27699 : model1 loss : 0.438838 model2 loss : 0.014642
[01:14:57.259] iteration 27700 : model1 loss : 0.440959 model2 loss : 0.017018
[01:14:57.442] iteration 27701 : model1 loss : 0.440070 model2 loss : 0.016349
[01:14:57.640] iteration 27702 : model1 loss : 0.443144 model2 loss : 0.016678
[01:14:57.822] iteration 27703 : model1 loss : 0.443460 model2 loss : 0.015026
[01:14:57.997] iteration 27704 : model1 loss : 0.442426 model2 loss : 0.015532
[01:14:58.169] iteration 27705 : model1 loss : 0.438591 model2 loss : 0.015994
[01:14:58.343] iteration 27706 : model1 loss : 0.436582 model2 loss : 0.016027
[01:14:58.517] iteration 27707 : model1 loss : 0.441480 model2 loss : 0.015991
[01:14:58.691] iteration 27708 : model1 loss : 0.439562 model2 loss : 0.015710
[01:14:58.863] iteration 27709 : model1 loss : 0.441895 model2 loss : 0.015224
[01:14:59.047] iteration 27710 : model1 loss : 0.439023 model2 loss : 0.017206
[01:14:59.226] iteration 27711 : model1 loss : 0.439047 model2 loss : 0.014613
[01:14:59.409] iteration 27712 : model1 loss : 0.440596 model2 loss : 0.016617
[01:14:59.590] iteration 27713 : model1 loss : 0.436288 model2 loss : 0.014481
[01:14:59.765] iteration 27714 : model1 loss : 0.438925 model2 loss : 0.017197
[01:14:59.939] iteration 27715 : model1 loss : 0.445052 model2 loss : 0.016763
[01:15:00.126] iteration 27716 : model1 loss : 0.442182 model2 loss : 0.017088
[01:15:00.327] iteration 27717 : model1 loss : 0.435161 model2 loss : 0.016768
[01:15:00.612] iteration 27718 : model1 loss : 0.443399 model2 loss : 0.016748
[01:15:00.804] iteration 27719 : model1 loss : 0.440230 model2 loss : 0.015782
[01:15:00.987] iteration 27720 : model1 loss : 0.437387 model2 loss : 0.016867
[01:15:03.125] iteration 27721 : model1 loss : 0.439044 model2 loss : 0.016616
[01:15:03.305] iteration 27722 : model1 loss : 0.445167 model2 loss : 0.018810
[01:15:03.477] iteration 27723 : model1 loss : 0.442318 model2 loss : 0.017574
[01:15:03.650] iteration 27724 : model1 loss : 0.437165 model2 loss : 0.015575
[01:15:03.825] iteration 27725 : model1 loss : 0.435796 model2 loss : 0.017742
[01:15:04.004] iteration 27726 : model1 loss : 0.441288 model2 loss : 0.018256
[01:15:04.188] iteration 27727 : model1 loss : 0.437346 model2 loss : 0.016184
[01:15:04.367] iteration 27728 : model1 loss : 0.440212 model2 loss : 0.016015
[01:15:04.579] iteration 27729 : model1 loss : 0.443811 model2 loss : 0.019192
[01:15:04.764] iteration 27730 : model1 loss : 0.437151 model2 loss : 0.017394
[01:15:04.954] iteration 27731 : model1 loss : 0.440750 model2 loss : 0.016683
[01:15:05.233] iteration 27732 : model1 loss : 0.437188 model2 loss : 0.016514
[01:15:05.402] iteration 27733 : model1 loss : 0.437577 model2 loss : 0.015886
[01:15:05.584] iteration 27734 : model1 loss : 0.440709 model2 loss : 0.015813
[01:15:05.769] iteration 27735 : model1 loss : 0.442475 model2 loss : 0.016050
[01:15:05.951] iteration 27736 : model1 loss : 0.438406 model2 loss : 0.015888
[01:15:06.168] iteration 27737 : model1 loss : 0.442100 model2 loss : 0.016688
[01:15:06.354] iteration 27738 : model1 loss : 0.438545 model2 loss : 0.015230
[01:15:06.535] iteration 27739 : model1 loss : 0.440909 model2 loss : 0.017003
[01:15:06.729] iteration 27740 : model1 loss : 0.443721 model2 loss : 0.017047
[01:15:06.913] iteration 27741 : model1 loss : 0.440429 model2 loss : 0.016602
[01:15:09.198] iteration 27742 : model1 loss : 0.441238 model2 loss : 0.016445
[01:15:09.370] iteration 27743 : model1 loss : 0.437084 model2 loss : 0.014806
[01:15:09.544] iteration 27744 : model1 loss : 0.439243 model2 loss : 0.018773
[01:15:09.718] iteration 27745 : model1 loss : 0.441737 model2 loss : 0.014134
[01:15:09.893] iteration 27746 : model1 loss : 0.441524 model2 loss : 0.015795
[01:15:10.072] iteration 27747 : model1 loss : 0.439008 model2 loss : 0.015081
[01:15:10.253] iteration 27748 : model1 loss : 0.442576 model2 loss : 0.018821
[01:15:10.456] iteration 27749 : model1 loss : 0.441217 model2 loss : 0.016830
[01:15:10.638] iteration 27750 : model1 loss : 0.442107 model2 loss : 0.017422
[01:15:10.811] iteration 27751 : model1 loss : 0.438104 model2 loss : 0.016358
[01:15:10.984] iteration 27752 : model1 loss : 0.441074 model2 loss : 0.016646
[01:15:11.181] iteration 27753 : model1 loss : 0.441613 model2 loss : 0.016309
[01:15:11.352] iteration 27754 : model1 loss : 0.440659 model2 loss : 0.016479
[01:15:11.524] iteration 27755 : model1 loss : 0.437709 model2 loss : 0.016761
[01:15:11.693] iteration 27756 : model1 loss : 0.439397 model2 loss : 0.016961
[01:15:11.865] iteration 27757 : model1 loss : 0.437551 model2 loss : 0.016936
[01:15:12.089] iteration 27758 : model1 loss : 0.444192 model2 loss : 0.019169
[01:15:12.267] iteration 27759 : model1 loss : 0.436302 model2 loss : 0.015874
[01:15:12.449] iteration 27760 : model1 loss : 0.441566 model2 loss : 0.015332
[01:15:12.628] iteration 27761 : model1 loss : 0.440478 model2 loss : 0.016785
[01:15:12.806] iteration 27762 : model1 loss : 0.439778 model2 loss : 0.015126
[01:15:14.819] iteration 27763 : model1 loss : 0.435035 model2 loss : 0.014827
[01:15:14.990] iteration 27764 : model1 loss : 0.439055 model2 loss : 0.015469
[01:15:15.163] iteration 27765 : model1 loss : 0.437201 model2 loss : 0.017873
[01:15:15.336] iteration 27766 : model1 loss : 0.439406 model2 loss : 0.016914
[01:15:15.505] iteration 27767 : model1 loss : 0.436646 model2 loss : 0.014072
[01:15:15.677] iteration 27768 : model1 loss : 0.440520 model2 loss : 0.015822
[01:15:15.851] iteration 27769 : model1 loss : 0.442852 model2 loss : 0.016505
[01:15:16.021] iteration 27770 : model1 loss : 0.440618 model2 loss : 0.015805
[01:15:16.195] iteration 27771 : model1 loss : 0.440087 model2 loss : 0.017745
[01:15:16.366] iteration 27772 : model1 loss : 0.442630 model2 loss : 0.018152
[01:15:16.541] iteration 27773 : model1 loss : 0.441311 model2 loss : 0.016800
[01:15:16.714] iteration 27774 : model1 loss : 0.439470 model2 loss : 0.017420
[01:15:16.888] iteration 27775 : model1 loss : 0.441726 model2 loss : 0.016234
[01:15:17.058] iteration 27776 : model1 loss : 0.439923 model2 loss : 0.015342
[01:15:17.231] iteration 27777 : model1 loss : 0.438851 model2 loss : 0.016759
[01:15:17.401] iteration 27778 : model1 loss : 0.438113 model2 loss : 0.015749
[01:15:17.575] iteration 27779 : model1 loss : 0.442681 model2 loss : 0.015704
[01:15:17.747] iteration 27780 : model1 loss : 0.441138 model2 loss : 0.016603
[01:15:17.921] iteration 27781 : model1 loss : 0.441592 model2 loss : 0.017624
[01:15:18.089] iteration 27782 : model1 loss : 0.443594 model2 loss : 0.018495
[01:15:18.261] iteration 27783 : model1 loss : 0.440184 model2 loss : 0.015883
[01:15:20.275] iteration 27784 : model1 loss : 0.437946 model2 loss : 0.015731
[01:15:20.446] iteration 27785 : model1 loss : 0.437842 model2 loss : 0.017695
[01:15:20.622] iteration 27786 : model1 loss : 0.441566 model2 loss : 0.015214
[01:15:20.795] iteration 27787 : model1 loss : 0.443181 model2 loss : 0.017687
[01:15:20.965] iteration 27788 : model1 loss : 0.441131 model2 loss : 0.019775
[01:15:21.135] iteration 27789 : model1 loss : 0.440249 model2 loss : 0.016156
[01:15:21.319] iteration 27790 : model1 loss : 0.445288 model2 loss : 0.016541
[01:15:21.497] iteration 27791 : model1 loss : 0.439494 model2 loss : 0.016953
[01:15:21.671] iteration 27792 : model1 loss : 0.439059 model2 loss : 0.015659
[01:15:21.844] iteration 27793 : model1 loss : 0.441932 model2 loss : 0.018098
[01:15:22.031] iteration 27794 : model1 loss : 0.439642 model2 loss : 0.017156
[01:15:22.209] iteration 27795 : model1 loss : 0.439854 model2 loss : 0.015976
[01:15:22.382] iteration 27796 : model1 loss : 0.439756 model2 loss : 0.016513
[01:15:22.552] iteration 27797 : model1 loss : 0.438055 model2 loss : 0.018495
[01:15:22.721] iteration 27798 : model1 loss : 0.438678 model2 loss : 0.016513
[01:15:22.890] iteration 27799 : model1 loss : 0.438316 model2 loss : 0.015960
[01:15:23.061] iteration 27800 : model1 loss : 0.444555 model2 loss : 0.018019
[01:15:23.230] iteration 27801 : model1 loss : 0.441395 model2 loss : 0.016774
[01:15:23.401] iteration 27802 : model1 loss : 0.434308 model2 loss : 0.015637
[01:15:23.569] iteration 27803 : model1 loss : 0.441352 model2 loss : 0.016542
[01:15:23.741] iteration 27804 : model1 loss : 0.441091 model2 loss : 0.015796
[01:15:25.765] iteration 27805 : model1 loss : 0.438593 model2 loss : 0.015255
[01:15:25.940] iteration 27806 : model1 loss : 0.441420 model2 loss : 0.015390
[01:15:26.116] iteration 27807 : model1 loss : 0.439254 model2 loss : 0.015888
[01:15:26.294] iteration 27808 : model1 loss : 0.440377 model2 loss : 0.016666
[01:15:26.481] iteration 27809 : model1 loss : 0.440787 model2 loss : 0.018292
[01:15:26.650] iteration 27810 : model1 loss : 0.444968 model2 loss : 0.016729
[01:15:26.823] iteration 27811 : model1 loss : 0.440370 model2 loss : 0.015676
[01:15:26.991] iteration 27812 : model1 loss : 0.442194 model2 loss : 0.017482
[01:15:27.161] iteration 27813 : model1 loss : 0.441240 model2 loss : 0.018537
[01:15:27.337] iteration 27814 : model1 loss : 0.435985 model2 loss : 0.016173
[01:15:27.518] iteration 27815 : model1 loss : 0.440016 model2 loss : 0.016319
[01:15:27.703] iteration 27816 : model1 loss : 0.443853 model2 loss : 0.016250
[01:15:27.880] iteration 27817 : model1 loss : 0.436320 model2 loss : 0.017364
[01:15:28.053] iteration 27818 : model1 loss : 0.440269 model2 loss : 0.015520
[01:15:28.230] iteration 27819 : model1 loss : 0.439754 model2 loss : 0.016106
[01:15:28.400] iteration 27820 : model1 loss : 0.436622 model2 loss : 0.015276
[01:15:28.582] iteration 27821 : model1 loss : 0.437919 model2 loss : 0.014401
[01:15:28.758] iteration 27822 : model1 loss : 0.445410 model2 loss : 0.019492
[01:15:28.932] iteration 27823 : model1 loss : 0.440174 model2 loss : 0.016971
[01:15:29.110] iteration 27824 : model1 loss : 0.440254 model2 loss : 0.014303
[01:15:29.286] iteration 27825 : model1 loss : 0.436467 model2 loss : 0.014975
[01:15:31.301] iteration 27826 : model1 loss : 0.442228 model2 loss : 0.019442
[01:15:31.483] iteration 27827 : model1 loss : 0.434860 model2 loss : 0.014463
[01:15:31.657] iteration 27828 : model1 loss : 0.440618 model2 loss : 0.016674
[01:15:31.829] iteration 27829 : model1 loss : 0.441596 model2 loss : 0.016789
[01:15:32.000] iteration 27830 : model1 loss : 0.444057 model2 loss : 0.016765
[01:15:32.172] iteration 27831 : model1 loss : 0.442051 model2 loss : 0.017758
[01:15:32.359] iteration 27832 : model1 loss : 0.443908 model2 loss : 0.016252
[01:15:32.559] iteration 27833 : model1 loss : 0.443636 model2 loss : 0.019273
[01:15:32.798] iteration 27834 : model1 loss : 0.441618 model2 loss : 0.016095
[01:15:32.980] iteration 27835 : model1 loss : 0.440474 model2 loss : 0.016900
[01:15:33.160] iteration 27836 : model1 loss : 0.436535 model2 loss : 0.016097
[01:15:33.334] iteration 27837 : model1 loss : 0.440785 model2 loss : 0.015329
[01:15:33.506] iteration 27838 : model1 loss : 0.435036 model2 loss : 0.016258
[01:15:33.677] iteration 27839 : model1 loss : 0.436699 model2 loss : 0.015507
[01:15:33.850] iteration 27840 : model1 loss : 0.440401 model2 loss : 0.017643
[01:15:34.035] iteration 27841 : model1 loss : 0.433890 model2 loss : 0.017295
[01:15:34.212] iteration 27842 : model1 loss : 0.440442 model2 loss : 0.016535
[01:15:34.387] iteration 27843 : model1 loss : 0.440677 model2 loss : 0.016050
[01:15:34.561] iteration 27844 : model1 loss : 0.441481 model2 loss : 0.015432
[01:15:34.743] iteration 27845 : model1 loss : 0.442532 model2 loss : 0.016775
[01:15:34.923] iteration 27846 : model1 loss : 0.441633 model2 loss : 0.016223
[01:15:37.440] iteration 27847 : model1 loss : 0.438026 model2 loss : 0.015993
[01:15:37.609] iteration 27848 : model1 loss : 0.440286 model2 loss : 0.015655
[01:15:37.792] iteration 27849 : model1 loss : 0.440022 model2 loss : 0.017434
[01:15:37.972] iteration 27850 : model1 loss : 0.437551 model2 loss : 0.016732
[01:15:38.148] iteration 27851 : model1 loss : 0.442736 model2 loss : 0.018365
[01:15:38.321] iteration 27852 : model1 loss : 0.441516 model2 loss : 0.019063
[01:15:38.503] iteration 27853 : model1 loss : 0.440788 model2 loss : 0.016025
[01:15:38.682] iteration 27854 : model1 loss : 0.441559 model2 loss : 0.018103
[01:15:38.861] iteration 27855 : model1 loss : 0.441544 model2 loss : 0.016443
[01:15:39.036] iteration 27856 : model1 loss : 0.438109 model2 loss : 0.016521
[01:15:39.217] iteration 27857 : model1 loss : 0.438712 model2 loss : 0.015200
[01:15:39.395] iteration 27858 : model1 loss : 0.438755 model2 loss : 0.016827
[01:15:39.568] iteration 27859 : model1 loss : 0.441630 model2 loss : 0.016182
[01:15:39.747] iteration 27860 : model1 loss : 0.441602 model2 loss : 0.016663
[01:15:39.926] iteration 27861 : model1 loss : 0.441864 model2 loss : 0.015953
[01:15:40.102] iteration 27862 : model1 loss : 0.441932 model2 loss : 0.015570
[01:15:40.275] iteration 27863 : model1 loss : 0.438009 model2 loss : 0.016331
[01:15:40.449] iteration 27864 : model1 loss : 0.442769 model2 loss : 0.017571
[01:15:40.626] iteration 27865 : model1 loss : 0.439070 model2 loss : 0.015111
[01:15:40.794] iteration 27866 : model1 loss : 0.434517 model2 loss : 0.014923
[01:15:40.965] iteration 27867 : model1 loss : 0.442160 model2 loss : 0.015429
[01:15:42.994] iteration 27868 : model1 loss : 0.439183 model2 loss : 0.015099
[01:15:43.165] iteration 27869 : model1 loss : 0.441174 model2 loss : 0.016211
[01:15:43.347] iteration 27870 : model1 loss : 0.436820 model2 loss : 0.016229
[01:15:43.552] iteration 27871 : model1 loss : 0.439209 model2 loss : 0.016629
[01:15:43.743] iteration 27872 : model1 loss : 0.438629 model2 loss : 0.016705
[01:15:43.958] iteration 27873 : model1 loss : 0.442186 model2 loss : 0.016227
[01:15:44.132] iteration 27874 : model1 loss : 0.442336 model2 loss : 0.017380
[01:15:44.317] iteration 27875 : model1 loss : 0.438157 model2 loss : 0.016434
[01:15:44.496] iteration 27876 : model1 loss : 0.441059 model2 loss : 0.016690
[01:15:44.673] iteration 27877 : model1 loss : 0.442367 model2 loss : 0.016331
[01:15:44.849] iteration 27878 : model1 loss : 0.440592 model2 loss : 0.016191
[01:15:45.033] iteration 27879 : model1 loss : 0.442980 model2 loss : 0.015161
[01:15:45.210] iteration 27880 : model1 loss : 0.439253 model2 loss : 0.015099
[01:15:45.394] iteration 27881 : model1 loss : 0.438799 model2 loss : 0.015863
[01:15:45.577] iteration 27882 : model1 loss : 0.443957 model2 loss : 0.019748
[01:15:45.760] iteration 27883 : model1 loss : 0.438355 model2 loss : 0.017537
[01:15:45.929] iteration 27884 : model1 loss : 0.440182 model2 loss : 0.016340
[01:15:46.109] iteration 27885 : model1 loss : 0.438752 model2 loss : 0.015636
[01:15:46.292] iteration 27886 : model1 loss : 0.440003 model2 loss : 0.017261
[01:15:46.474] iteration 27887 : model1 loss : 0.438620 model2 loss : 0.016708
[01:15:46.651] iteration 27888 : model1 loss : 0.444234 model2 loss : 0.015783
[01:15:48.690] iteration 27889 : model1 loss : 0.438785 model2 loss : 0.017950
[01:15:48.862] iteration 27890 : model1 loss : 0.438889 model2 loss : 0.015955
[01:15:49.038] iteration 27891 : model1 loss : 0.441482 model2 loss : 0.017388
[01:15:49.206] iteration 27892 : model1 loss : 0.443099 model2 loss : 0.017576
[01:15:49.378] iteration 27893 : model1 loss : 0.440316 model2 loss : 0.016349
[01:15:49.558] iteration 27894 : model1 loss : 0.441436 model2 loss : 0.014969
[01:15:49.743] iteration 27895 : model1 loss : 0.440285 model2 loss : 0.017142
[01:15:49.919] iteration 27896 : model1 loss : 0.438849 model2 loss : 0.015540
[01:15:50.103] iteration 27897 : model1 loss : 0.440430 model2 loss : 0.015786
[01:15:50.274] iteration 27898 : model1 loss : 0.442827 model2 loss : 0.015594
[01:15:50.451] iteration 27899 : model1 loss : 0.439781 model2 loss : 0.017638
[01:15:50.629] iteration 27900 : model1 loss : 0.441162 model2 loss : 0.017520
[01:15:50.809] iteration 27901 : model1 loss : 0.442144 model2 loss : 0.016128
[01:15:50.988] iteration 27902 : model1 loss : 0.440727 model2 loss : 0.015706
[01:15:51.170] iteration 27903 : model1 loss : 0.442678 model2 loss : 0.016831
[01:15:51.354] iteration 27904 : model1 loss : 0.438043 model2 loss : 0.017322
[01:15:51.529] iteration 27905 : model1 loss : 0.440366 model2 loss : 0.014683
[01:15:51.706] iteration 27906 : model1 loss : 0.439474 model2 loss : 0.017078
[01:15:51.885] iteration 27907 : model1 loss : 0.435079 model2 loss : 0.016028
[01:15:52.057] iteration 27908 : model1 loss : 0.439724 model2 loss : 0.015877
[01:15:52.230] iteration 27909 : model1 loss : 0.441656 model2 loss : 0.015370
[01:15:54.262] iteration 27910 : model1 loss : 0.441184 model2 loss : 0.017003
[01:15:54.439] iteration 27911 : model1 loss : 0.437577 model2 loss : 0.015369
[01:15:54.614] iteration 27912 : model1 loss : 0.440434 model2 loss : 0.015166
[01:15:54.785] iteration 27913 : model1 loss : 0.445398 model2 loss : 0.016197
[01:15:54.962] iteration 27914 : model1 loss : 0.443269 model2 loss : 0.017224
[01:15:55.133] iteration 27915 : model1 loss : 0.440087 model2 loss : 0.015381
[01:15:55.312] iteration 27916 : model1 loss : 0.439253 model2 loss : 0.015866
[01:15:55.484] iteration 27917 : model1 loss : 0.439456 model2 loss : 0.017667
[01:15:55.660] iteration 27918 : model1 loss : 0.433665 model2 loss : 0.015066
[01:15:55.834] iteration 27919 : model1 loss : 0.443184 model2 loss : 0.014676
[01:15:56.012] iteration 27920 : model1 loss : 0.440273 model2 loss : 0.017279
[01:15:56.180] iteration 27921 : model1 loss : 0.438057 model2 loss : 0.015820
[01:15:56.362] iteration 27922 : model1 loss : 0.437101 model2 loss : 0.015327
[01:15:56.539] iteration 27923 : model1 loss : 0.442868 model2 loss : 0.019005
[01:15:56.725] iteration 27924 : model1 loss : 0.438409 model2 loss : 0.015921
[01:15:56.907] iteration 27925 : model1 loss : 0.442637 model2 loss : 0.016793
[01:15:57.086] iteration 27926 : model1 loss : 0.440733 model2 loss : 0.019812
[01:15:57.253] iteration 27927 : model1 loss : 0.435733 model2 loss : 0.017539
[01:15:57.426] iteration 27928 : model1 loss : 0.443519 model2 loss : 0.016296
[01:15:57.593] iteration 27929 : model1 loss : 0.441358 model2 loss : 0.014881
[01:15:57.769] iteration 27930 : model1 loss : 0.441505 model2 loss : 0.017197
[01:15:59.767] iteration 27931 : model1 loss : 0.435920 model2 loss : 0.015077
[01:15:59.945] iteration 27932 : model1 loss : 0.443242 model2 loss : 0.016571
[01:16:00.125] iteration 27933 : model1 loss : 0.442911 model2 loss : 0.017608
[01:16:00.296] iteration 27934 : model1 loss : 0.441879 model2 loss : 0.016494
[01:16:00.474] iteration 27935 : model1 loss : 0.437715 model2 loss : 0.016834
[01:16:00.647] iteration 27936 : model1 loss : 0.445086 model2 loss : 0.017891
[01:16:00.822] iteration 27937 : model1 loss : 0.437688 model2 loss : 0.015213
[01:16:01.028] iteration 27938 : model1 loss : 0.439739 model2 loss : 0.016729
[01:16:01.202] iteration 27939 : model1 loss : 0.444922 model2 loss : 0.016893
[01:16:01.381] iteration 27940 : model1 loss : 0.439087 model2 loss : 0.014376
[01:16:01.552] iteration 27941 : model1 loss : 0.440462 model2 loss : 0.016469
[01:16:01.725] iteration 27942 : model1 loss : 0.436310 model2 loss : 0.016046
[01:16:01.896] iteration 27943 : model1 loss : 0.437883 model2 loss : 0.017122
[01:16:02.067] iteration 27944 : model1 loss : 0.440072 model2 loss : 0.015485
[01:16:02.237] iteration 27945 : model1 loss : 0.442367 model2 loss : 0.015460
[01:16:02.410] iteration 27946 : model1 loss : 0.445393 model2 loss : 0.018145
[01:16:02.581] iteration 27947 : model1 loss : 0.438755 model2 loss : 0.015909
[01:16:02.776] iteration 27948 : model1 loss : 0.436759 model2 loss : 0.017488
[01:16:02.957] iteration 27949 : model1 loss : 0.437471 model2 loss : 0.016116
[01:16:03.139] iteration 27950 : model1 loss : 0.441045 model2 loss : 0.017202
[01:16:03.312] iteration 27951 : model1 loss : 0.439397 model2 loss : 0.016394
[01:16:05.879] iteration 27952 : model1 loss : 0.437019 model2 loss : 0.014158
[01:16:06.058] iteration 27953 : model1 loss : 0.440343 model2 loss : 0.019119
[01:16:06.238] iteration 27954 : model1 loss : 0.435770 model2 loss : 0.017052
[01:16:06.415] iteration 27955 : model1 loss : 0.443108 model2 loss : 0.014972
[01:16:06.600] iteration 27956 : model1 loss : 0.435207 model2 loss : 0.014583
[01:16:06.778] iteration 27957 : model1 loss : 0.440278 model2 loss : 0.016998
[01:16:06.962] iteration 27958 : model1 loss : 0.443257 model2 loss : 0.018385
[01:16:07.142] iteration 27959 : model1 loss : 0.442447 model2 loss : 0.015322
[01:16:07.322] iteration 27960 : model1 loss : 0.441766 model2 loss : 0.016168
[01:16:07.496] iteration 27961 : model1 loss : 0.442984 model2 loss : 0.017482
[01:16:07.670] iteration 27962 : model1 loss : 0.443752 model2 loss : 0.017929
[01:16:07.843] iteration 27963 : model1 loss : 0.442613 model2 loss : 0.018082
[01:16:08.016] iteration 27964 : model1 loss : 0.437570 model2 loss : 0.016607
[01:16:08.185] iteration 27965 : model1 loss : 0.441518 model2 loss : 0.015639
[01:16:08.363] iteration 27966 : model1 loss : 0.438377 model2 loss : 0.015491
[01:16:08.535] iteration 27967 : model1 loss : 0.438680 model2 loss : 0.015389
[01:16:08.710] iteration 27968 : model1 loss : 0.438970 model2 loss : 0.016466
[01:16:08.881] iteration 27969 : model1 loss : 0.440926 model2 loss : 0.016269
[01:16:09.057] iteration 27970 : model1 loss : 0.439388 model2 loss : 0.016857
[01:16:09.226] iteration 27971 : model1 loss : 0.440375 model2 loss : 0.016338
[01:16:09.399] iteration 27972 : model1 loss : 0.440408 model2 loss : 0.015953
[01:16:11.398] iteration 27973 : model1 loss : 0.439412 model2 loss : 0.017014
[01:16:11.592] iteration 27974 : model1 loss : 0.441145 model2 loss : 0.019341
[01:16:11.786] iteration 27975 : model1 loss : 0.439277 model2 loss : 0.015368
[01:16:11.969] iteration 27976 : model1 loss : 0.445391 model2 loss : 0.017674
[01:16:12.162] iteration 27977 : model1 loss : 0.438761 model2 loss : 0.016218
[01:16:12.349] iteration 27978 : model1 loss : 0.441829 model2 loss : 0.018974
[01:16:12.527] iteration 27979 : model1 loss : 0.434000 model2 loss : 0.015747
[01:16:12.708] iteration 27980 : model1 loss : 0.438105 model2 loss : 0.015369
[01:16:12.909] iteration 27981 : model1 loss : 0.437901 model2 loss : 0.015185
[01:16:13.085] iteration 27982 : model1 loss : 0.439112 model2 loss : 0.015424
[01:16:13.295] iteration 27983 : model1 loss : 0.436896 model2 loss : 0.016495
[01:16:13.503] iteration 27984 : model1 loss : 0.436594 model2 loss : 0.016259
[01:16:13.716] iteration 27985 : model1 loss : 0.441920 model2 loss : 0.017896
[01:16:13.941] iteration 27986 : model1 loss : 0.444898 model2 loss : 0.016219
[01:16:14.117] iteration 27987 : model1 loss : 0.447858 model2 loss : 0.017966
[01:16:14.293] iteration 27988 : model1 loss : 0.443514 model2 loss : 0.017513
[01:16:14.467] iteration 27989 : model1 loss : 0.438823 model2 loss : 0.017220
[01:16:14.648] iteration 27990 : model1 loss : 0.443028 model2 loss : 0.017091
[01:16:14.819] iteration 27991 : model1 loss : 0.437955 model2 loss : 0.016099
[01:16:15.002] iteration 27992 : model1 loss : 0.437949 model2 loss : 0.016705
[01:16:15.186] iteration 27993 : model1 loss : 0.442484 model2 loss : 0.013979
[01:16:17.253] iteration 27994 : model1 loss : 0.435830 model2 loss : 0.015047
[01:16:17.437] iteration 27995 : model1 loss : 0.438116 model2 loss : 0.016142
[01:16:17.616] iteration 27996 : model1 loss : 0.434362 model2 loss : 0.015264
[01:16:17.788] iteration 27997 : model1 loss : 0.439760 model2 loss : 0.016153
[01:16:17.983] iteration 27998 : model1 loss : 0.439221 model2 loss : 0.018147
[01:16:18.166] iteration 27999 : model1 loss : 0.441283 model2 loss : 0.016921
[01:16:18.357] iteration 28000 : model1 loss : 0.444055 model2 loss : 0.018995
[01:16:27.483] iteration 28000 : model1_mean_dice : 0.882812 model1_mean_hd95 : 5.090013
[01:16:36.650] iteration 28000 : model2_mean_dice : 0.881498 model2_mean_hd95 : 4.003063
[01:16:36.841] iteration 28001 : model1 loss : 0.441939 model2 loss : 0.016564
[01:16:37.016] iteration 28002 : model1 loss : 0.440623 model2 loss : 0.016453
[01:16:37.184] iteration 28003 : model1 loss : 0.440940 model2 loss : 0.017527
[01:16:37.358] iteration 28004 : model1 loss : 0.441043 model2 loss : 0.015920
[01:16:37.525] iteration 28005 : model1 loss : 0.445735 model2 loss : 0.019353
[01:16:37.696] iteration 28006 : model1 loss : 0.441084 model2 loss : 0.018842
[01:16:37.879] iteration 28007 : model1 loss : 0.437847 model2 loss : 0.015742
[01:16:38.054] iteration 28008 : model1 loss : 0.446219 model2 loss : 0.019863
[01:16:38.223] iteration 28009 : model1 loss : 0.444554 model2 loss : 0.019527
[01:16:38.393] iteration 28010 : model1 loss : 0.442106 model2 loss : 0.014740
[01:16:38.561] iteration 28011 : model1 loss : 0.439969 model2 loss : 0.014531
[01:16:38.738] iteration 28012 : model1 loss : 0.436773 model2 loss : 0.015228
[01:16:38.905] iteration 28013 : model1 loss : 0.438858 model2 loss : 0.017059
[01:16:39.078] iteration 28014 : model1 loss : 0.435645 model2 loss : 0.015083
[01:16:41.086] iteration 28015 : model1 loss : 0.440488 model2 loss : 0.017002
[01:16:41.259] iteration 28016 : model1 loss : 0.442847 model2 loss : 0.016354
[01:16:41.434] iteration 28017 : model1 loss : 0.438740 model2 loss : 0.016312
[01:16:41.603] iteration 28018 : model1 loss : 0.438670 model2 loss : 0.015334
[01:16:41.774] iteration 28019 : model1 loss : 0.437552 model2 loss : 0.016003
[01:16:41.948] iteration 28020 : model1 loss : 0.439163 model2 loss : 0.017055
[01:16:42.130] iteration 28021 : model1 loss : 0.443086 model2 loss : 0.017252
[01:16:42.309] iteration 28022 : model1 loss : 0.441845 model2 loss : 0.018824
[01:16:42.497] iteration 28023 : model1 loss : 0.438936 model2 loss : 0.015575
[01:16:42.676] iteration 28024 : model1 loss : 0.439676 model2 loss : 0.017537
[01:16:42.857] iteration 28025 : model1 loss : 0.438593 model2 loss : 0.014790
[01:16:43.035] iteration 28026 : model1 loss : 0.437582 model2 loss : 0.017013
[01:16:43.216] iteration 28027 : model1 loss : 0.443676 model2 loss : 0.018010
[01:16:43.394] iteration 28028 : model1 loss : 0.445444 model2 loss : 0.017575
[01:16:43.577] iteration 28029 : model1 loss : 0.440241 model2 loss : 0.016739
[01:16:43.755] iteration 28030 : model1 loss : 0.443936 model2 loss : 0.017791
[01:16:43.937] iteration 28031 : model1 loss : 0.436432 model2 loss : 0.015143
[01:16:44.115] iteration 28032 : model1 loss : 0.445896 model2 loss : 0.017691
[01:16:44.302] iteration 28033 : model1 loss : 0.441602 model2 loss : 0.017023
[01:16:44.478] iteration 28034 : model1 loss : 0.438242 model2 loss : 0.016409
[01:16:44.658] iteration 28035 : model1 loss : 0.434463 model2 loss : 0.015055
[01:16:46.690] iteration 28036 : model1 loss : 0.441038 model2 loss : 0.015510
[01:16:46.876] iteration 28037 : model1 loss : 0.439241 model2 loss : 0.016436
[01:16:47.057] iteration 28038 : model1 loss : 0.437706 model2 loss : 0.017111
[01:16:47.232] iteration 28039 : model1 loss : 0.440116 model2 loss : 0.017583
[01:16:47.415] iteration 28040 : model1 loss : 0.438409 model2 loss : 0.016978
[01:16:47.591] iteration 28041 : model1 loss : 0.438457 model2 loss : 0.017152
[01:16:47.774] iteration 28042 : model1 loss : 0.443900 model2 loss : 0.017129
[01:16:47.956] iteration 28043 : model1 loss : 0.443813 model2 loss : 0.018628
[01:16:48.137] iteration 28044 : model1 loss : 0.441754 model2 loss : 0.017096
[01:16:48.317] iteration 28045 : model1 loss : 0.442610 model2 loss : 0.016437
[01:16:48.495] iteration 28046 : model1 loss : 0.437371 model2 loss : 0.015041
[01:16:48.675] iteration 28047 : model1 loss : 0.443645 model2 loss : 0.016079
[01:16:48.855] iteration 28048 : model1 loss : 0.441777 model2 loss : 0.017103
[01:16:49.032] iteration 28049 : model1 loss : 0.438622 model2 loss : 0.017176
[01:16:49.214] iteration 28050 : model1 loss : 0.436149 model2 loss : 0.016202
[01:16:49.394] iteration 28051 : model1 loss : 0.442488 model2 loss : 0.016283
[01:16:49.576] iteration 28052 : model1 loss : 0.435278 model2 loss : 0.014538
[01:16:49.751] iteration 28053 : model1 loss : 0.438389 model2 loss : 0.015352
[01:16:49.930] iteration 28054 : model1 loss : 0.446346 model2 loss : 0.018554
[01:16:50.103] iteration 28055 : model1 loss : 0.440136 model2 loss : 0.015800
[01:16:50.286] iteration 28056 : model1 loss : 0.440410 model2 loss : 0.016170
[01:16:52.306] iteration 28057 : model1 loss : 0.438142 model2 loss : 0.016241
[01:16:52.493] iteration 28058 : model1 loss : 0.441672 model2 loss : 0.015560
[01:16:52.673] iteration 28059 : model1 loss : 0.439031 model2 loss : 0.017048
[01:16:52.852] iteration 28060 : model1 loss : 0.439595 model2 loss : 0.015502
[01:16:53.031] iteration 28061 : model1 loss : 0.436678 model2 loss : 0.014712
[01:16:53.208] iteration 28062 : model1 loss : 0.439961 model2 loss : 0.015630
[01:16:53.390] iteration 28063 : model1 loss : 0.439717 model2 loss : 0.016989
[01:16:53.566] iteration 28064 : model1 loss : 0.435880 model2 loss : 0.015363
[01:16:53.744] iteration 28065 : model1 loss : 0.440213 model2 loss : 0.013929
[01:16:53.924] iteration 28066 : model1 loss : 0.441616 model2 loss : 0.014449
[01:16:54.106] iteration 28067 : model1 loss : 0.441356 model2 loss : 0.018752
[01:16:54.287] iteration 28068 : model1 loss : 0.441956 model2 loss : 0.017225
[01:16:54.466] iteration 28069 : model1 loss : 0.444840 model2 loss : 0.020933
[01:16:54.643] iteration 28070 : model1 loss : 0.441137 model2 loss : 0.018175
[01:16:54.823] iteration 28071 : model1 loss : 0.438233 model2 loss : 0.016697
[01:16:55.002] iteration 28072 : model1 loss : 0.440042 model2 loss : 0.017461
[01:16:55.186] iteration 28073 : model1 loss : 0.441847 model2 loss : 0.016410
[01:16:55.362] iteration 28074 : model1 loss : 0.444786 model2 loss : 0.017770
[01:16:55.544] iteration 28075 : model1 loss : 0.436633 model2 loss : 0.016108
[01:16:55.716] iteration 28076 : model1 loss : 0.439493 model2 loss : 0.017139
[01:16:55.893] iteration 28077 : model1 loss : 0.442140 model2 loss : 0.018007
[01:16:57.954] iteration 28078 : model1 loss : 0.440113 model2 loss : 0.015764
[01:16:58.132] iteration 28079 : model1 loss : 0.438667 model2 loss : 0.015917
[01:16:58.320] iteration 28080 : model1 loss : 0.438549 model2 loss : 0.015633
[01:16:58.496] iteration 28081 : model1 loss : 0.440146 model2 loss : 0.016590
[01:16:58.680] iteration 28082 : model1 loss : 0.442491 model2 loss : 0.016466
[01:16:58.859] iteration 28083 : model1 loss : 0.440800 model2 loss : 0.017352
[01:16:59.041] iteration 28084 : model1 loss : 0.440894 model2 loss : 0.015144
[01:16:59.221] iteration 28085 : model1 loss : 0.440842 model2 loss : 0.015295
[01:16:59.403] iteration 28086 : model1 loss : 0.438499 model2 loss : 0.015170
[01:16:59.583] iteration 28087 : model1 loss : 0.439779 model2 loss : 0.017782
[01:16:59.762] iteration 28088 : model1 loss : 0.437234 model2 loss : 0.016403
[01:16:59.938] iteration 28089 : model1 loss : 0.439458 model2 loss : 0.016513
[01:17:00.125] iteration 28090 : model1 loss : 0.438982 model2 loss : 0.016822
[01:17:00.405] iteration 28091 : model1 loss : 0.437956 model2 loss : 0.016212
[01:17:00.587] iteration 28092 : model1 loss : 0.442949 model2 loss : 0.017489
[01:17:00.763] iteration 28093 : model1 loss : 0.441249 model2 loss : 0.016531
[01:17:00.947] iteration 28094 : model1 loss : 0.444432 model2 loss : 0.016617
[01:17:01.129] iteration 28095 : model1 loss : 0.441990 model2 loss : 0.017662
[01:17:01.315] iteration 28096 : model1 loss : 0.439091 model2 loss : 0.018032
[01:17:01.496] iteration 28097 : model1 loss : 0.445021 model2 loss : 0.017946
[01:17:01.673] iteration 28098 : model1 loss : 0.438136 model2 loss : 0.016187
[01:17:03.748] iteration 28099 : model1 loss : 0.443835 model2 loss : 0.016816
[01:17:03.925] iteration 28100 : model1 loss : 0.438646 model2 loss : 0.015712
[01:17:04.104] iteration 28101 : model1 loss : 0.444766 model2 loss : 0.017772
[01:17:04.283] iteration 28102 : model1 loss : 0.437545 model2 loss : 0.016511
[01:17:04.464] iteration 28103 : model1 loss : 0.442380 model2 loss : 0.018208
[01:17:04.646] iteration 28104 : model1 loss : 0.437291 model2 loss : 0.016391
[01:17:04.825] iteration 28105 : model1 loss : 0.435041 model2 loss : 0.014270
[01:17:05.001] iteration 28106 : model1 loss : 0.441026 model2 loss : 0.015700
[01:17:05.185] iteration 28107 : model1 loss : 0.439210 model2 loss : 0.016111
[01:17:05.361] iteration 28108 : model1 loss : 0.439924 model2 loss : 0.014428
[01:17:05.543] iteration 28109 : model1 loss : 0.440001 model2 loss : 0.016756
[01:17:05.738] iteration 28110 : model1 loss : 0.442348 model2 loss : 0.016087
[01:17:05.919] iteration 28111 : model1 loss : 0.440208 model2 loss : 0.018166
[01:17:06.100] iteration 28112 : model1 loss : 0.439535 model2 loss : 0.017333
[01:17:06.284] iteration 28113 : model1 loss : 0.440196 model2 loss : 0.016086
[01:17:06.463] iteration 28114 : model1 loss : 0.437264 model2 loss : 0.014812
[01:17:06.648] iteration 28115 : model1 loss : 0.445825 model2 loss : 0.017827
[01:17:06.829] iteration 28116 : model1 loss : 0.442518 model2 loss : 0.015669
[01:17:07.012] iteration 28117 : model1 loss : 0.437553 model2 loss : 0.016363
[01:17:07.179] iteration 28118 : model1 loss : 0.439246 model2 loss : 0.016209
[01:17:07.349] iteration 28119 : model1 loss : 0.437729 model2 loss : 0.016873
[01:17:09.402] iteration 28120 : model1 loss : 0.437030 model2 loss : 0.015752
[01:17:09.575] iteration 28121 : model1 loss : 0.437045 model2 loss : 0.016227
[01:17:09.748] iteration 28122 : model1 loss : 0.439274 model2 loss : 0.016553
[01:17:09.921] iteration 28123 : model1 loss : 0.442827 model2 loss : 0.016749
[01:17:10.091] iteration 28124 : model1 loss : 0.438900 model2 loss : 0.015090
[01:17:10.257] iteration 28125 : model1 loss : 0.440071 model2 loss : 0.015893
[01:17:10.428] iteration 28126 : model1 loss : 0.436591 model2 loss : 0.016920
[01:17:10.596] iteration 28127 : model1 loss : 0.438447 model2 loss : 0.017460
[01:17:10.767] iteration 28128 : model1 loss : 0.440564 model2 loss : 0.016033
[01:17:10.935] iteration 28129 : model1 loss : 0.438981 model2 loss : 0.015600
[01:17:11.110] iteration 28130 : model1 loss : 0.438655 model2 loss : 0.016340
[01:17:11.277] iteration 28131 : model1 loss : 0.440319 model2 loss : 0.015277
[01:17:11.449] iteration 28132 : model1 loss : 0.443613 model2 loss : 0.018336
[01:17:11.616] iteration 28133 : model1 loss : 0.444705 model2 loss : 0.017745
[01:17:11.796] iteration 28134 : model1 loss : 0.435668 model2 loss : 0.016709
[01:17:11.961] iteration 28135 : model1 loss : 0.440431 model2 loss : 0.013869
[01:17:12.137] iteration 28136 : model1 loss : 0.446095 model2 loss : 0.018830
[01:17:12.307] iteration 28137 : model1 loss : 0.440077 model2 loss : 0.015714
[01:17:12.482] iteration 28138 : model1 loss : 0.444949 model2 loss : 0.014432
[01:17:12.647] iteration 28139 : model1 loss : 0.439288 model2 loss : 0.017805
[01:17:12.816] iteration 28140 : model1 loss : 0.439390 model2 loss : 0.014975
[01:17:14.784] iteration 28141 : model1 loss : 0.440869 model2 loss : 0.015497
[01:17:14.957] iteration 28142 : model1 loss : 0.443955 model2 loss : 0.016762
[01:17:15.136] iteration 28143 : model1 loss : 0.442554 model2 loss : 0.016444
[01:17:15.308] iteration 28144 : model1 loss : 0.444676 model2 loss : 0.016210
[01:17:15.478] iteration 28145 : model1 loss : 0.439805 model2 loss : 0.017376
[01:17:15.645] iteration 28146 : model1 loss : 0.440673 model2 loss : 0.015726
[01:17:15.819] iteration 28147 : model1 loss : 0.436621 model2 loss : 0.014947
[01:17:15.986] iteration 28148 : model1 loss : 0.442316 model2 loss : 0.016291
[01:17:16.158] iteration 28149 : model1 loss : 0.436626 model2 loss : 0.016148
[01:17:16.327] iteration 28150 : model1 loss : 0.440887 model2 loss : 0.016775
[01:17:16.498] iteration 28151 : model1 loss : 0.438303 model2 loss : 0.015204
[01:17:16.666] iteration 28152 : model1 loss : 0.437187 model2 loss : 0.016423
[01:17:16.839] iteration 28153 : model1 loss : 0.440574 model2 loss : 0.017743
[01:17:17.006] iteration 28154 : model1 loss : 0.437877 model2 loss : 0.014209
[01:17:17.177] iteration 28155 : model1 loss : 0.441290 model2 loss : 0.015386
[01:17:17.346] iteration 28156 : model1 loss : 0.440469 model2 loss : 0.017709
[01:17:17.518] iteration 28157 : model1 loss : 0.433855 model2 loss : 0.015071
[01:17:17.685] iteration 28158 : model1 loss : 0.440418 model2 loss : 0.014953
[01:17:17.856] iteration 28159 : model1 loss : 0.440799 model2 loss : 0.017445
[01:17:18.023] iteration 28160 : model1 loss : 0.441165 model2 loss : 0.015415
[01:17:18.195] iteration 28161 : model1 loss : 0.443947 model2 loss : 0.014387
[01:17:20.178] iteration 28162 : model1 loss : 0.440438 model2 loss : 0.016344
[01:17:20.350] iteration 28163 : model1 loss : 0.436567 model2 loss : 0.016419
[01:17:20.525] iteration 28164 : model1 loss : 0.434212 model2 loss : 0.015337
[01:17:20.692] iteration 28165 : model1 loss : 0.436178 model2 loss : 0.016853
[01:17:20.863] iteration 28166 : model1 loss : 0.440079 model2 loss : 0.017775
[01:17:21.030] iteration 28167 : model1 loss : 0.440013 model2 loss : 0.016286
[01:17:21.203] iteration 28168 : model1 loss : 0.433933 model2 loss : 0.014382
[01:17:21.369] iteration 28169 : model1 loss : 0.444859 model2 loss : 0.019465
[01:17:21.544] iteration 28170 : model1 loss : 0.443189 model2 loss : 0.018543
[01:17:21.712] iteration 28171 : model1 loss : 0.440795 model2 loss : 0.015523
[01:17:21.882] iteration 28172 : model1 loss : 0.436286 model2 loss : 0.014438
[01:17:22.050] iteration 28173 : model1 loss : 0.445201 model2 loss : 0.020394
[01:17:22.221] iteration 28174 : model1 loss : 0.441919 model2 loss : 0.015310
[01:17:22.388] iteration 28175 : model1 loss : 0.437344 model2 loss : 0.014077
[01:17:22.561] iteration 28176 : model1 loss : 0.446113 model2 loss : 0.017938
[01:17:22.729] iteration 28177 : model1 loss : 0.442547 model2 loss : 0.015406
[01:17:22.901] iteration 28178 : model1 loss : 0.443084 model2 loss : 0.017354
[01:17:23.070] iteration 28179 : model1 loss : 0.438715 model2 loss : 0.016980
[01:17:23.242] iteration 28180 : model1 loss : 0.440510 model2 loss : 0.015897
[01:17:23.408] iteration 28181 : model1 loss : 0.442239 model2 loss : 0.016172
[01:17:23.577] iteration 28182 : model1 loss : 0.439612 model2 loss : 0.015011
[01:17:25.528] iteration 28183 : model1 loss : 0.441185 model2 loss : 0.017891
[01:17:25.703] iteration 28184 : model1 loss : 0.445187 model2 loss : 0.015839
[01:17:25.876] iteration 28185 : model1 loss : 0.439367 model2 loss : 0.016796
[01:17:26.043] iteration 28186 : model1 loss : 0.442033 model2 loss : 0.015248
[01:17:26.214] iteration 28187 : model1 loss : 0.439285 model2 loss : 0.014945
[01:17:26.380] iteration 28188 : model1 loss : 0.439258 model2 loss : 0.015944
[01:17:26.553] iteration 28189 : model1 loss : 0.435142 model2 loss : 0.014713
[01:17:26.721] iteration 28190 : model1 loss : 0.442326 model2 loss : 0.016680
[01:17:26.895] iteration 28191 : model1 loss : 0.441532 model2 loss : 0.017715
[01:17:27.062] iteration 28192 : model1 loss : 0.445499 model2 loss : 0.017785
[01:17:27.233] iteration 28193 : model1 loss : 0.441544 model2 loss : 0.017923
[01:17:27.403] iteration 28194 : model1 loss : 0.442091 model2 loss : 0.018029
[01:17:27.574] iteration 28195 : model1 loss : 0.439038 model2 loss : 0.014715
[01:17:27.742] iteration 28196 : model1 loss : 0.444028 model2 loss : 0.016956
[01:17:27.914] iteration 28197 : model1 loss : 0.442473 model2 loss : 0.017513
[01:17:28.082] iteration 28198 : model1 loss : 0.440499 model2 loss : 0.017676
[01:17:28.254] iteration 28199 : model1 loss : 0.437557 model2 loss : 0.015888
[01:17:28.420] iteration 28200 : model1 loss : 0.435613 model2 loss : 0.014490
[01:17:28.592] iteration 28201 : model1 loss : 0.437272 model2 loss : 0.017838
[01:17:28.759] iteration 28202 : model1 loss : 0.440396 model2 loss : 0.016132
[01:17:28.930] iteration 28203 : model1 loss : 0.438095 model2 loss : 0.016772
[01:17:30.914] iteration 28204 : model1 loss : 0.439813 model2 loss : 0.017427
[01:17:31.087] iteration 28205 : model1 loss : 0.442669 model2 loss : 0.017183
[01:17:31.262] iteration 28206 : model1 loss : 0.436099 model2 loss : 0.015240
[01:17:31.428] iteration 28207 : model1 loss : 0.438300 model2 loss : 0.015968
[01:17:31.604] iteration 28208 : model1 loss : 0.437483 model2 loss : 0.016695
[01:17:31.771] iteration 28209 : model1 loss : 0.436501 model2 loss : 0.014758
[01:17:31.943] iteration 28210 : model1 loss : 0.438355 model2 loss : 0.015555
[01:17:32.110] iteration 28211 : model1 loss : 0.442430 model2 loss : 0.017404
[01:17:32.282] iteration 28212 : model1 loss : 0.441532 model2 loss : 0.017307
[01:17:32.452] iteration 28213 : model1 loss : 0.441940 model2 loss : 0.016217
[01:17:32.624] iteration 28214 : model1 loss : 0.439747 model2 loss : 0.016818
[01:17:32.791] iteration 28215 : model1 loss : 0.444315 model2 loss : 0.016687
[01:17:32.963] iteration 28216 : model1 loss : 0.437484 model2 loss : 0.016128
[01:17:33.135] iteration 28217 : model1 loss : 0.439408 model2 loss : 0.015186
[01:17:33.308] iteration 28218 : model1 loss : 0.439993 model2 loss : 0.018311
[01:17:33.475] iteration 28219 : model1 loss : 0.442473 model2 loss : 0.017034
[01:17:33.645] iteration 28220 : model1 loss : 0.437129 model2 loss : 0.016042
[01:17:33.810] iteration 28221 : model1 loss : 0.437002 model2 loss : 0.016403
[01:17:33.984] iteration 28222 : model1 loss : 0.448047 model2 loss : 0.017881
[01:17:34.153] iteration 28223 : model1 loss : 0.442662 model2 loss : 0.018040
[01:17:34.326] iteration 28224 : model1 loss : 0.444447 model2 loss : 0.017470
[01:17:36.269] iteration 28225 : model1 loss : 0.441009 model2 loss : 0.015808
[01:17:36.446] iteration 28226 : model1 loss : 0.442522 model2 loss : 0.018014
[01:17:36.619] iteration 28227 : model1 loss : 0.437538 model2 loss : 0.015070
[01:17:36.786] iteration 28228 : model1 loss : 0.437638 model2 loss : 0.014692
[01:17:36.959] iteration 28229 : model1 loss : 0.441923 model2 loss : 0.016975
[01:17:37.130] iteration 28230 : model1 loss : 0.442411 model2 loss : 0.017544
[01:17:37.305] iteration 28231 : model1 loss : 0.433448 model2 loss : 0.015697
[01:17:37.476] iteration 28232 : model1 loss : 0.443551 model2 loss : 0.017485
[01:17:37.650] iteration 28233 : model1 loss : 0.442278 model2 loss : 0.017308
[01:17:37.817] iteration 28234 : model1 loss : 0.444344 model2 loss : 0.017020
[01:17:37.991] iteration 28235 : model1 loss : 0.439477 model2 loss : 0.015557
[01:17:38.162] iteration 28236 : model1 loss : 0.433820 model2 loss : 0.016867
[01:17:38.337] iteration 28237 : model1 loss : 0.443617 model2 loss : 0.017520
[01:17:38.504] iteration 28238 : model1 loss : 0.438163 model2 loss : 0.015513
[01:17:38.674] iteration 28239 : model1 loss : 0.443280 model2 loss : 0.015398
[01:17:38.842] iteration 28240 : model1 loss : 0.439343 model2 loss : 0.016411
[01:17:39.014] iteration 28241 : model1 loss : 0.436292 model2 loss : 0.016483
[01:17:39.183] iteration 28242 : model1 loss : 0.444069 model2 loss : 0.016841
[01:17:39.357] iteration 28243 : model1 loss : 0.441660 model2 loss : 0.016070
[01:17:39.524] iteration 28244 : model1 loss : 0.433202 model2 loss : 0.015701
[01:17:39.694] iteration 28245 : model1 loss : 0.445914 model2 loss : 0.018043
[01:17:41.665] iteration 28246 : model1 loss : 0.436242 model2 loss : 0.015577
[01:17:41.840] iteration 28247 : model1 loss : 0.444064 model2 loss : 0.017095
[01:17:42.015] iteration 28248 : model1 loss : 0.438652 model2 loss : 0.016917
[01:17:42.182] iteration 28249 : model1 loss : 0.438436 model2 loss : 0.016146
[01:17:42.355] iteration 28250 : model1 loss : 0.442064 model2 loss : 0.015624
[01:17:42.522] iteration 28251 : model1 loss : 0.440415 model2 loss : 0.014948
[01:17:42.697] iteration 28252 : model1 loss : 0.438487 model2 loss : 0.014401
[01:17:42.865] iteration 28253 : model1 loss : 0.435134 model2 loss : 0.015541
[01:17:43.037] iteration 28254 : model1 loss : 0.443307 model2 loss : 0.019509
[01:17:43.205] iteration 28255 : model1 loss : 0.443431 model2 loss : 0.015777
[01:17:43.377] iteration 28256 : model1 loss : 0.445974 model2 loss : 0.017605
[01:17:43.544] iteration 28257 : model1 loss : 0.438333 model2 loss : 0.016732
[01:17:43.714] iteration 28258 : model1 loss : 0.437421 model2 loss : 0.016657
[01:17:43.881] iteration 28259 : model1 loss : 0.444975 model2 loss : 0.019714
[01:17:44.054] iteration 28260 : model1 loss : 0.439332 model2 loss : 0.014123
[01:17:44.222] iteration 28261 : model1 loss : 0.439543 model2 loss : 0.016311
[01:17:44.395] iteration 28262 : model1 loss : 0.438745 model2 loss : 0.016463
[01:17:44.562] iteration 28263 : model1 loss : 0.437161 model2 loss : 0.016058
[01:17:44.737] iteration 28264 : model1 loss : 0.445968 model2 loss : 0.020494
[01:17:44.903] iteration 28265 : model1 loss : 0.438686 model2 loss : 0.016542
[01:17:45.074] iteration 28266 : model1 loss : 0.439511 model2 loss : 0.015786
[01:17:47.063] iteration 28267 : model1 loss : 0.441277 model2 loss : 0.015718
[01:17:47.236] iteration 28268 : model1 loss : 0.442411 model2 loss : 0.017233
[01:17:47.413] iteration 28269 : model1 loss : 0.434993 model2 loss : 0.016851
[01:17:47.580] iteration 28270 : model1 loss : 0.439139 model2 loss : 0.016046
[01:17:47.753] iteration 28271 : model1 loss : 0.436762 model2 loss : 0.016475
[01:17:47.921] iteration 28272 : model1 loss : 0.442065 model2 loss : 0.016321
[01:17:48.097] iteration 28273 : model1 loss : 0.435838 model2 loss : 0.016564
[01:17:48.264] iteration 28274 : model1 loss : 0.442102 model2 loss : 0.016631
[01:17:48.436] iteration 28275 : model1 loss : 0.441592 model2 loss : 0.020028
[01:17:48.605] iteration 28276 : model1 loss : 0.442789 model2 loss : 0.016671
[01:17:48.776] iteration 28277 : model1 loss : 0.436340 model2 loss : 0.016434
[01:17:48.944] iteration 28278 : model1 loss : 0.440345 model2 loss : 0.016895
[01:17:49.121] iteration 28279 : model1 loss : 0.442953 model2 loss : 0.016721
[01:17:49.289] iteration 28280 : model1 loss : 0.444514 model2 loss : 0.014682
[01:17:49.462] iteration 28281 : model1 loss : 0.437193 model2 loss : 0.016263
[01:17:49.630] iteration 28282 : model1 loss : 0.443142 model2 loss : 0.014449
[01:17:49.802] iteration 28283 : model1 loss : 0.439851 model2 loss : 0.016188
[01:17:49.970] iteration 28284 : model1 loss : 0.436822 model2 loss : 0.017216
[01:17:50.145] iteration 28285 : model1 loss : 0.441325 model2 loss : 0.015652
[01:17:50.317] iteration 28286 : model1 loss : 0.443210 model2 loss : 0.016752
[01:17:50.488] iteration 28287 : model1 loss : 0.441363 model2 loss : 0.016883
[01:17:52.476] iteration 28288 : model1 loss : 0.440202 model2 loss : 0.017373
[01:17:52.646] iteration 28289 : model1 loss : 0.443549 model2 loss : 0.017460
[01:17:52.821] iteration 28290 : model1 loss : 0.436636 model2 loss : 0.015937
[01:17:52.986] iteration 28291 : model1 loss : 0.441371 model2 loss : 0.016958
[01:17:53.160] iteration 28292 : model1 loss : 0.442611 model2 loss : 0.015066
[01:17:53.336] iteration 28293 : model1 loss : 0.436579 model2 loss : 0.015532
[01:17:53.508] iteration 28294 : model1 loss : 0.441429 model2 loss : 0.017758
[01:17:53.678] iteration 28295 : model1 loss : 0.435702 model2 loss : 0.015810
[01:17:53.851] iteration 28296 : model1 loss : 0.440529 model2 loss : 0.015292
[01:17:54.037] iteration 28297 : model1 loss : 0.442077 model2 loss : 0.016479
[01:17:54.228] iteration 28298 : model1 loss : 0.440789 model2 loss : 0.015738
[01:17:54.415] iteration 28299 : model1 loss : 0.438080 model2 loss : 0.016516
[01:17:54.590] iteration 28300 : model1 loss : 0.442445 model2 loss : 0.018240
[01:17:54.760] iteration 28301 : model1 loss : 0.442325 model2 loss : 0.017118
[01:17:54.934] iteration 28302 : model1 loss : 0.443141 model2 loss : 0.015856
[01:17:55.104] iteration 28303 : model1 loss : 0.434977 model2 loss : 0.016245
[01:17:55.279] iteration 28304 : model1 loss : 0.439242 model2 loss : 0.017634
[01:17:55.455] iteration 28305 : model1 loss : 0.443527 model2 loss : 0.017278
[01:17:55.639] iteration 28306 : model1 loss : 0.441089 model2 loss : 0.015438
[01:17:55.815] iteration 28307 : model1 loss : 0.436000 model2 loss : 0.014531
[01:17:55.996] iteration 28308 : model1 loss : 0.441715 model2 loss : 0.016377
[01:17:58.056] iteration 28309 : model1 loss : 0.444083 model2 loss : 0.020869
[01:17:58.238] iteration 28310 : model1 loss : 0.441121 model2 loss : 0.016493
[01:17:58.409] iteration 28311 : model1 loss : 0.442399 model2 loss : 0.016315
[01:17:58.577] iteration 28312 : model1 loss : 0.436676 model2 loss : 0.014962
[01:17:58.749] iteration 28313 : model1 loss : 0.445062 model2 loss : 0.018748
[01:17:58.917] iteration 28314 : model1 loss : 0.440811 model2 loss : 0.017059
[01:17:59.089] iteration 28315 : model1 loss : 0.441142 model2 loss : 0.015551
[01:17:59.254] iteration 28316 : model1 loss : 0.438932 model2 loss : 0.015600
[01:17:59.427] iteration 28317 : model1 loss : 0.442668 model2 loss : 0.015764
[01:17:59.625] iteration 28318 : model1 loss : 0.440011 model2 loss : 0.017676
[01:17:59.844] iteration 28319 : model1 loss : 0.438552 model2 loss : 0.016589
[01:18:00.031] iteration 28320 : model1 loss : 0.440776 model2 loss : 0.017372
[01:18:00.224] iteration 28321 : model1 loss : 0.439856 model2 loss : 0.017064
[01:18:00.416] iteration 28322 : model1 loss : 0.437583 model2 loss : 0.016789
[01:18:00.602] iteration 28323 : model1 loss : 0.439343 model2 loss : 0.017918
[01:18:00.786] iteration 28324 : model1 loss : 0.442312 model2 loss : 0.018282
[01:18:00.976] iteration 28325 : model1 loss : 0.438252 model2 loss : 0.016606
[01:18:01.157] iteration 28326 : model1 loss : 0.443397 model2 loss : 0.015853
[01:18:01.345] iteration 28327 : model1 loss : 0.438972 model2 loss : 0.015297
[01:18:01.524] iteration 28328 : model1 loss : 0.438473 model2 loss : 0.015745
[01:18:01.705] iteration 28329 : model1 loss : 0.434718 model2 loss : 0.015516
[01:18:03.821] iteration 28330 : model1 loss : 0.442037 model2 loss : 0.017027
[01:18:04.001] iteration 28331 : model1 loss : 0.439497 model2 loss : 0.014915
[01:18:04.186] iteration 28332 : model1 loss : 0.435292 model2 loss : 0.015858
[01:18:04.363] iteration 28333 : model1 loss : 0.442149 model2 loss : 0.016156
[01:18:04.544] iteration 28334 : model1 loss : 0.441937 model2 loss : 0.014707
[01:18:04.726] iteration 28335 : model1 loss : 0.440066 model2 loss : 0.017443
[01:18:04.913] iteration 28336 : model1 loss : 0.438272 model2 loss : 0.016130
[01:18:05.094] iteration 28337 : model1 loss : 0.437865 model2 loss : 0.015789
[01:18:05.279] iteration 28338 : model1 loss : 0.438430 model2 loss : 0.019404
[01:18:05.457] iteration 28339 : model1 loss : 0.445599 model2 loss : 0.017768
[01:18:05.636] iteration 28340 : model1 loss : 0.441356 model2 loss : 0.017520
[01:18:05.818] iteration 28341 : model1 loss : 0.438082 model2 loss : 0.016582
[01:18:06.000] iteration 28342 : model1 loss : 0.445454 model2 loss : 0.019202
[01:18:06.182] iteration 28343 : model1 loss : 0.440421 model2 loss : 0.016921
[01:18:06.371] iteration 28344 : model1 loss : 0.440019 model2 loss : 0.017346
[01:18:06.554] iteration 28345 : model1 loss : 0.441628 model2 loss : 0.017918
[01:18:06.736] iteration 28346 : model1 loss : 0.439723 model2 loss : 0.016950
[01:18:06.923] iteration 28347 : model1 loss : 0.440104 model2 loss : 0.015427
[01:18:08.475] iteration 28348 : model1 loss : 0.442502 model2 loss : 0.016262
[01:18:08.659] iteration 28349 : model1 loss : 0.440762 model2 loss : 0.014466
[01:18:08.840] iteration 28350 : model1 loss : 0.438762 model2 loss : 0.017374
[01:18:10.971] iteration 28351 : model1 loss : 0.444100 model2 loss : 0.016659
[01:18:11.159] iteration 28352 : model1 loss : 0.446754 model2 loss : 0.019846
[01:18:11.350] iteration 28353 : model1 loss : 0.439506 model2 loss : 0.017171
[01:18:11.530] iteration 28354 : model1 loss : 0.440064 model2 loss : 0.016658
[01:18:11.716] iteration 28355 : model1 loss : 0.443677 model2 loss : 0.015663
[01:18:11.896] iteration 28356 : model1 loss : 0.440610 model2 loss : 0.016798
[01:18:12.086] iteration 28357 : model1 loss : 0.441307 model2 loss : 0.017209
[01:18:12.281] iteration 28358 : model1 loss : 0.442855 model2 loss : 0.017569
[01:18:12.469] iteration 28359 : model1 loss : 0.440482 model2 loss : 0.016217
[01:18:12.650] iteration 28360 : model1 loss : 0.438765 model2 loss : 0.015068
[01:18:12.833] iteration 28361 : model1 loss : 0.437822 model2 loss : 0.015547
[01:18:13.015] iteration 28362 : model1 loss : 0.443787 model2 loss : 0.014855
[01:18:13.199] iteration 28363 : model1 loss : 0.438257 model2 loss : 0.016210
[01:18:13.380] iteration 28364 : model1 loss : 0.437412 model2 loss : 0.014453
[01:18:13.570] iteration 28365 : model1 loss : 0.440175 model2 loss : 0.017418
[01:18:13.752] iteration 28366 : model1 loss : 0.440021 model2 loss : 0.017714
[01:18:13.935] iteration 28367 : model1 loss : 0.438990 model2 loss : 0.016430
[01:18:14.121] iteration 28368 : model1 loss : 0.436955 model2 loss : 0.015146
[01:18:14.308] iteration 28369 : model1 loss : 0.440569 model2 loss : 0.015408
[01:18:14.485] iteration 28370 : model1 loss : 0.439389 model2 loss : 0.015539
[01:18:14.664] iteration 28371 : model1 loss : 0.435223 model2 loss : 0.015701
[01:18:16.755] iteration 28372 : model1 loss : 0.446595 model2 loss : 0.016819
[01:18:16.935] iteration 28373 : model1 loss : 0.437279 model2 loss : 0.016062
[01:18:17.122] iteration 28374 : model1 loss : 0.440427 model2 loss : 0.014941
[01:18:17.303] iteration 28375 : model1 loss : 0.439724 model2 loss : 0.016362
[01:18:17.493] iteration 28376 : model1 loss : 0.435908 model2 loss : 0.014993
[01:18:17.670] iteration 28377 : model1 loss : 0.439867 model2 loss : 0.015954
[01:18:17.852] iteration 28378 : model1 loss : 0.437924 model2 loss : 0.015644
[01:18:18.036] iteration 28379 : model1 loss : 0.442764 model2 loss : 0.017496
[01:18:18.220] iteration 28380 : model1 loss : 0.442661 model2 loss : 0.015549
[01:18:18.399] iteration 28381 : model1 loss : 0.436991 model2 loss : 0.017220
[01:18:18.587] iteration 28382 : model1 loss : 0.443185 model2 loss : 0.016615
[01:18:18.766] iteration 28383 : model1 loss : 0.441660 model2 loss : 0.018015
[01:18:18.949] iteration 28384 : model1 loss : 0.441013 model2 loss : 0.017966
[01:18:19.133] iteration 28385 : model1 loss : 0.440265 model2 loss : 0.015537
[01:18:19.324] iteration 28386 : model1 loss : 0.437026 model2 loss : 0.015713
[01:18:19.505] iteration 28387 : model1 loss : 0.438932 model2 loss : 0.015472
[01:18:19.693] iteration 28388 : model1 loss : 0.438712 model2 loss : 0.016907
[01:18:19.873] iteration 28389 : model1 loss : 0.437857 model2 loss : 0.014744
[01:18:20.057] iteration 28390 : model1 loss : 0.443095 model2 loss : 0.017124
[01:18:20.236] iteration 28391 : model1 loss : 0.441638 model2 loss : 0.015227
[01:18:20.421] iteration 28392 : model1 loss : 0.439465 model2 loss : 0.015309
[01:18:22.511] iteration 28393 : model1 loss : 0.441697 model2 loss : 0.016604
[01:18:22.690] iteration 28394 : model1 loss : 0.440844 model2 loss : 0.018139
[01:18:22.870] iteration 28395 : model1 loss : 0.446572 model2 loss : 0.017367
[01:18:23.052] iteration 28396 : model1 loss : 0.441624 model2 loss : 0.015048
[01:18:23.234] iteration 28397 : model1 loss : 0.440950 model2 loss : 0.017618
[01:18:23.418] iteration 28398 : model1 loss : 0.440765 model2 loss : 0.015936
[01:18:23.597] iteration 28399 : model1 loss : 0.435220 model2 loss : 0.017048
[01:18:23.780] iteration 28400 : model1 loss : 0.443338 model2 loss : 0.017222
[01:18:23.961] iteration 28401 : model1 loss : 0.441258 model2 loss : 0.016599
[01:18:24.146] iteration 28402 : model1 loss : 0.436009 model2 loss : 0.017100
[01:18:24.333] iteration 28403 : model1 loss : 0.439168 model2 loss : 0.016954
[01:18:24.510] iteration 28404 : model1 loss : 0.438216 model2 loss : 0.017390
[01:18:24.698] iteration 28405 : model1 loss : 0.440343 model2 loss : 0.016124
[01:18:24.878] iteration 28406 : model1 loss : 0.445324 model2 loss : 0.016916
[01:18:25.058] iteration 28407 : model1 loss : 0.443389 model2 loss : 0.016583
[01:18:25.238] iteration 28408 : model1 loss : 0.441940 model2 loss : 0.016446
[01:18:25.422] iteration 28409 : model1 loss : 0.435086 model2 loss : 0.016692
[01:18:25.599] iteration 28410 : model1 loss : 0.439263 model2 loss : 0.015901
[01:18:25.788] iteration 28411 : model1 loss : 0.439493 model2 loss : 0.015995
[01:18:25.966] iteration 28412 : model1 loss : 0.442972 model2 loss : 0.020573
[01:18:26.149] iteration 28413 : model1 loss : 0.440069 model2 loss : 0.017413
[01:18:28.267] iteration 28414 : model1 loss : 0.445035 model2 loss : 0.018536
[01:18:28.453] iteration 28415 : model1 loss : 0.443563 model2 loss : 0.018283
[01:18:28.634] iteration 28416 : model1 loss : 0.442035 model2 loss : 0.016233
[01:18:28.816] iteration 28417 : model1 loss : 0.437352 model2 loss : 0.015894
[01:18:28.999] iteration 28418 : model1 loss : 0.443278 model2 loss : 0.017997
[01:18:29.180] iteration 28419 : model1 loss : 0.443018 model2 loss : 0.017600
[01:18:29.361] iteration 28420 : model1 loss : 0.440763 model2 loss : 0.017085
[01:18:29.542] iteration 28421 : model1 loss : 0.434348 model2 loss : 0.016468
[01:18:29.724] iteration 28422 : model1 loss : 0.433212 model2 loss : 0.014740
[01:18:29.907] iteration 28423 : model1 loss : 0.440257 model2 loss : 0.014738
[01:18:30.091] iteration 28424 : model1 loss : 0.439877 model2 loss : 0.015025
[01:18:30.271] iteration 28425 : model1 loss : 0.442800 model2 loss : 0.016557
[01:18:30.453] iteration 28426 : model1 loss : 0.439159 model2 loss : 0.015145
[01:18:30.639] iteration 28427 : model1 loss : 0.437229 model2 loss : 0.015612
[01:18:30.824] iteration 28428 : model1 loss : 0.434056 model2 loss : 0.015652
[01:18:31.008] iteration 28429 : model1 loss : 0.445085 model2 loss : 0.017248
[01:18:31.192] iteration 28430 : model1 loss : 0.439753 model2 loss : 0.016803
[01:18:31.376] iteration 28431 : model1 loss : 0.445394 model2 loss : 0.015350
[01:18:31.561] iteration 28432 : model1 loss : 0.439422 model2 loss : 0.015333
[01:18:31.740] iteration 28433 : model1 loss : 0.445319 model2 loss : 0.017958
[01:18:31.921] iteration 28434 : model1 loss : 0.439875 model2 loss : 0.016103
[01:18:34.044] iteration 28435 : model1 loss : 0.444623 model2 loss : 0.018719
[01:18:34.229] iteration 28436 : model1 loss : 0.442499 model2 loss : 0.016265
[01:18:34.413] iteration 28437 : model1 loss : 0.436798 model2 loss : 0.015826
[01:18:34.593] iteration 28438 : model1 loss : 0.440117 model2 loss : 0.019082
[01:18:34.779] iteration 28439 : model1 loss : 0.434626 model2 loss : 0.014190
[01:18:34.960] iteration 28440 : model1 loss : 0.442693 model2 loss : 0.016749
[01:18:35.150] iteration 28441 : model1 loss : 0.439235 model2 loss : 0.015710
[01:18:35.336] iteration 28442 : model1 loss : 0.439612 model2 loss : 0.016786
[01:18:35.517] iteration 28443 : model1 loss : 0.438944 model2 loss : 0.015055
[01:18:35.698] iteration 28444 : model1 loss : 0.448666 model2 loss : 0.019270
[01:18:35.883] iteration 28445 : model1 loss : 0.438545 model2 loss : 0.015517
[01:18:36.065] iteration 28446 : model1 loss : 0.439303 model2 loss : 0.015371
[01:18:36.253] iteration 28447 : model1 loss : 0.443320 model2 loss : 0.016332
[01:18:36.430] iteration 28448 : model1 loss : 0.439209 model2 loss : 0.018570
[01:18:36.617] iteration 28449 : model1 loss : 0.439439 model2 loss : 0.015210
[01:18:36.801] iteration 28450 : model1 loss : 0.436479 model2 loss : 0.015453
[01:18:36.989] iteration 28451 : model1 loss : 0.435778 model2 loss : 0.016908
[01:18:37.169] iteration 28452 : model1 loss : 0.438006 model2 loss : 0.014603
[01:18:37.354] iteration 28453 : model1 loss : 0.444789 model2 loss : 0.016982
[01:18:37.531] iteration 28454 : model1 loss : 0.441461 model2 loss : 0.016732
[01:18:37.711] iteration 28455 : model1 loss : 0.442738 model2 loss : 0.018711
[01:18:39.826] iteration 28456 : model1 loss : 0.439937 model2 loss : 0.017954
[01:18:40.012] iteration 28457 : model1 loss : 0.437638 model2 loss : 0.015763
[01:18:40.192] iteration 28458 : model1 loss : 0.439220 model2 loss : 0.014710
[01:18:40.373] iteration 28459 : model1 loss : 0.439429 model2 loss : 0.016546
[01:18:40.556] iteration 28460 : model1 loss : 0.443118 model2 loss : 0.017041
[01:18:40.735] iteration 28461 : model1 loss : 0.439499 model2 loss : 0.016334
[01:18:40.920] iteration 28462 : model1 loss : 0.441684 model2 loss : 0.017917
[01:18:41.105] iteration 28463 : model1 loss : 0.441164 model2 loss : 0.016138
[01:18:41.290] iteration 28464 : model1 loss : 0.436607 model2 loss : 0.016310
[01:18:41.467] iteration 28465 : model1 loss : 0.436047 model2 loss : 0.015487
[01:18:41.651] iteration 28466 : model1 loss : 0.442852 model2 loss : 0.016115
[01:18:41.830] iteration 28467 : model1 loss : 0.443371 model2 loss : 0.017123
[01:18:42.016] iteration 28468 : model1 loss : 0.438024 model2 loss : 0.016189
[01:18:42.197] iteration 28469 : model1 loss : 0.441019 model2 loss : 0.016226
[01:18:42.383] iteration 28470 : model1 loss : 0.439399 model2 loss : 0.016562
[01:18:42.559] iteration 28471 : model1 loss : 0.442187 model2 loss : 0.017002
[01:18:42.746] iteration 28472 : model1 loss : 0.438385 model2 loss : 0.015591
[01:18:42.926] iteration 28473 : model1 loss : 0.438302 model2 loss : 0.014733
[01:18:43.111] iteration 28474 : model1 loss : 0.440440 model2 loss : 0.016971
[01:18:43.292] iteration 28475 : model1 loss : 0.441600 model2 loss : 0.014981
[01:18:43.474] iteration 28476 : model1 loss : 0.440231 model2 loss : 0.013668
[01:18:45.575] iteration 28477 : model1 loss : 0.435659 model2 loss : 0.016539
[01:18:45.758] iteration 28478 : model1 loss : 0.438638 model2 loss : 0.017739
[01:18:45.945] iteration 28479 : model1 loss : 0.443139 model2 loss : 0.016317
[01:18:46.125] iteration 28480 : model1 loss : 0.435812 model2 loss : 0.016292
[01:18:46.307] iteration 28481 : model1 loss : 0.442352 model2 loss : 0.014659
[01:18:46.492] iteration 28482 : model1 loss : 0.436995 model2 loss : 0.013760
[01:18:46.678] iteration 28483 : model1 loss : 0.444412 model2 loss : 0.019036
[01:18:46.859] iteration 28484 : model1 loss : 0.443219 model2 loss : 0.016408
[01:18:47.048] iteration 28485 : model1 loss : 0.445455 model2 loss : 0.016378
[01:18:47.226] iteration 28486 : model1 loss : 0.445629 model2 loss : 0.017641
[01:18:47.409] iteration 28487 : model1 loss : 0.437469 model2 loss : 0.017641
[01:18:47.590] iteration 28488 : model1 loss : 0.441435 model2 loss : 0.014974
[01:18:47.778] iteration 28489 : model1 loss : 0.439422 model2 loss : 0.016438
[01:18:47.958] iteration 28490 : model1 loss : 0.442325 model2 loss : 0.017055
[01:18:48.149] iteration 28491 : model1 loss : 0.437488 model2 loss : 0.016206
[01:18:48.332] iteration 28492 : model1 loss : 0.435153 model2 loss : 0.014940
[01:18:48.517] iteration 28493 : model1 loss : 0.440651 model2 loss : 0.017832
[01:18:48.699] iteration 28494 : model1 loss : 0.440813 model2 loss : 0.017073
[01:18:48.885] iteration 28495 : model1 loss : 0.440293 model2 loss : 0.017441
[01:18:49.066] iteration 28496 : model1 loss : 0.439583 model2 loss : 0.015723
[01:18:49.251] iteration 28497 : model1 loss : 0.438806 model2 loss : 0.016331
[01:18:51.349] iteration 28498 : model1 loss : 0.442999 model2 loss : 0.018157
[01:18:51.536] iteration 28499 : model1 loss : 0.436254 model2 loss : 0.015035
[01:18:51.724] iteration 28500 : model1 loss : 0.440178 model2 loss : 0.015091
[01:18:51.905] iteration 28501 : model1 loss : 0.442678 model2 loss : 0.017834
[01:18:52.087] iteration 28502 : model1 loss : 0.440167 model2 loss : 0.016974
[01:18:52.288] iteration 28503 : model1 loss : 0.442044 model2 loss : 0.018080
[01:18:52.474] iteration 28504 : model1 loss : 0.439898 model2 loss : 0.016173
[01:18:52.656] iteration 28505 : model1 loss : 0.439651 model2 loss : 0.015006
[01:18:52.839] iteration 28506 : model1 loss : 0.441357 model2 loss : 0.017768
[01:18:53.021] iteration 28507 : model1 loss : 0.440280 model2 loss : 0.016721
[01:18:53.210] iteration 28508 : model1 loss : 0.438791 model2 loss : 0.014945
[01:18:53.392] iteration 28509 : model1 loss : 0.441740 model2 loss : 0.016926
[01:18:53.575] iteration 28510 : model1 loss : 0.441615 model2 loss : 0.018096
[01:18:53.761] iteration 28511 : model1 loss : 0.437424 model2 loss : 0.014335
[01:18:53.949] iteration 28512 : model1 loss : 0.441127 model2 loss : 0.017385
[01:18:54.128] iteration 28513 : model1 loss : 0.440559 model2 loss : 0.016230
[01:18:54.318] iteration 28514 : model1 loss : 0.441972 model2 loss : 0.016737
[01:18:54.498] iteration 28515 : model1 loss : 0.436911 model2 loss : 0.015449
[01:18:54.686] iteration 28516 : model1 loss : 0.442267 model2 loss : 0.014931
[01:18:54.865] iteration 28517 : model1 loss : 0.438022 model2 loss : 0.016365
[01:18:55.046] iteration 28518 : model1 loss : 0.440082 model2 loss : 0.015923
[01:18:57.155] iteration 28519 : model1 loss : 0.442850 model2 loss : 0.017360
[01:18:57.340] iteration 28520 : model1 loss : 0.440835 model2 loss : 0.015650
[01:18:57.526] iteration 28521 : model1 loss : 0.438883 model2 loss : 0.014847
[01:18:57.710] iteration 28522 : model1 loss : 0.441912 model2 loss : 0.016186
[01:18:57.889] iteration 28523 : model1 loss : 0.438444 model2 loss : 0.015774
[01:18:58.074] iteration 28524 : model1 loss : 0.440369 model2 loss : 0.017845
[01:18:58.258] iteration 28525 : model1 loss : 0.435961 model2 loss : 0.015236
[01:18:58.438] iteration 28526 : model1 loss : 0.439509 model2 loss : 0.014724
[01:18:58.626] iteration 28527 : model1 loss : 0.443482 model2 loss : 0.016308
[01:18:58.804] iteration 28528 : model1 loss : 0.439258 model2 loss : 0.017888
[01:18:58.986] iteration 28529 : model1 loss : 0.442076 model2 loss : 0.017403
[01:18:59.184] iteration 28530 : model1 loss : 0.439825 model2 loss : 0.015586
[01:18:59.370] iteration 28531 : model1 loss : 0.438569 model2 loss : 0.015161
[01:18:59.554] iteration 28532 : model1 loss : 0.439322 model2 loss : 0.015599
[01:18:59.737] iteration 28533 : model1 loss : 0.438637 model2 loss : 0.017971
[01:18:59.917] iteration 28534 : model1 loss : 0.444665 model2 loss : 0.015619
[01:19:00.102] iteration 28535 : model1 loss : 0.436976 model2 loss : 0.014694
[01:19:00.280] iteration 28536 : model1 loss : 0.437343 model2 loss : 0.015581
[01:19:00.460] iteration 28537 : model1 loss : 0.441309 model2 loss : 0.017626
[01:19:00.639] iteration 28538 : model1 loss : 0.443079 model2 loss : 0.017313
[01:19:00.826] iteration 28539 : model1 loss : 0.438598 model2 loss : 0.015536
[01:19:02.968] iteration 28540 : model1 loss : 0.438560 model2 loss : 0.016882
[01:19:03.154] iteration 28541 : model1 loss : 0.438072 model2 loss : 0.015157
[01:19:03.338] iteration 28542 : model1 loss : 0.438202 model2 loss : 0.015482
[01:19:03.519] iteration 28543 : model1 loss : 0.443574 model2 loss : 0.016379
[01:19:03.703] iteration 28544 : model1 loss : 0.443965 model2 loss : 0.016003
[01:19:03.886] iteration 28545 : model1 loss : 0.439359 model2 loss : 0.016059
[01:19:04.073] iteration 28546 : model1 loss : 0.435757 model2 loss : 0.016612
[01:19:04.255] iteration 28547 : model1 loss : 0.447295 model2 loss : 0.018040
[01:19:04.438] iteration 28548 : model1 loss : 0.444818 model2 loss : 0.016584
[01:19:04.619] iteration 28549 : model1 loss : 0.438065 model2 loss : 0.016203
[01:19:04.804] iteration 28550 : model1 loss : 0.441799 model2 loss : 0.015511
[01:19:04.988] iteration 28551 : model1 loss : 0.444043 model2 loss : 0.016653
[01:19:05.171] iteration 28552 : model1 loss : 0.434264 model2 loss : 0.014611
[01:19:05.360] iteration 28553 : model1 loss : 0.439868 model2 loss : 0.015582
[01:19:05.542] iteration 28554 : model1 loss : 0.442066 model2 loss : 0.017047
[01:19:05.728] iteration 28555 : model1 loss : 0.438250 model2 loss : 0.015173
[01:19:05.918] iteration 28556 : model1 loss : 0.440436 model2 loss : 0.017726
[01:19:06.098] iteration 28557 : model1 loss : 0.438128 model2 loss : 0.015442
[01:19:06.284] iteration 28558 : model1 loss : 0.438203 model2 loss : 0.014613
[01:19:06.459] iteration 28559 : model1 loss : 0.440905 model2 loss : 0.016433
[01:19:06.639] iteration 28560 : model1 loss : 0.442759 model2 loss : 0.015072
[01:19:08.739] iteration 28561 : model1 loss : 0.445280 model2 loss : 0.015568
[01:19:08.924] iteration 28562 : model1 loss : 0.438309 model2 loss : 0.016844
[01:19:09.109] iteration 28563 : model1 loss : 0.439460 model2 loss : 0.016811
[01:19:09.287] iteration 28564 : model1 loss : 0.439413 model2 loss : 0.016297
[01:19:09.473] iteration 28565 : model1 loss : 0.438945 model2 loss : 0.014262
[01:19:09.653] iteration 28566 : model1 loss : 0.442747 model2 loss : 0.018255
[01:19:09.839] iteration 28567 : model1 loss : 0.440463 model2 loss : 0.015032
[01:19:10.023] iteration 28568 : model1 loss : 0.437709 model2 loss : 0.015854
[01:19:10.205] iteration 28569 : model1 loss : 0.441867 model2 loss : 0.017883
[01:19:10.382] iteration 28570 : model1 loss : 0.439204 model2 loss : 0.016579
[01:19:10.567] iteration 28571 : model1 loss : 0.441041 model2 loss : 0.017033
[01:19:10.748] iteration 28572 : model1 loss : 0.444912 model2 loss : 0.014711
[01:19:10.930] iteration 28573 : model1 loss : 0.441917 model2 loss : 0.018178
[01:19:11.120] iteration 28574 : model1 loss : 0.438451 model2 loss : 0.015797
[01:19:11.302] iteration 28575 : model1 loss : 0.441430 model2 loss : 0.016702
[01:19:11.481] iteration 28576 : model1 loss : 0.441234 model2 loss : 0.014355
[01:19:11.667] iteration 28577 : model1 loss : 0.441215 model2 loss : 0.015400
[01:19:11.850] iteration 28578 : model1 loss : 0.441587 model2 loss : 0.017546
[01:19:12.033] iteration 28579 : model1 loss : 0.435815 model2 loss : 0.015580
[01:19:12.212] iteration 28580 : model1 loss : 0.435447 model2 loss : 0.014856
[01:19:12.391] iteration 28581 : model1 loss : 0.436554 model2 loss : 0.016998
[01:19:14.432] iteration 28582 : model1 loss : 0.441865 model2 loss : 0.016541
[01:19:14.615] iteration 28583 : model1 loss : 0.437140 model2 loss : 0.015320
[01:19:14.796] iteration 28584 : model1 loss : 0.439102 model2 loss : 0.013559
[01:19:14.979] iteration 28585 : model1 loss : 0.443110 model2 loss : 0.014916
[01:19:15.161] iteration 28586 : model1 loss : 0.440391 model2 loss : 0.015520
[01:19:15.341] iteration 28587 : model1 loss : 0.439314 model2 loss : 0.017691
[01:19:15.527] iteration 28588 : model1 loss : 0.438439 model2 loss : 0.016935
[01:19:15.705] iteration 28589 : model1 loss : 0.442428 model2 loss : 0.014963
[01:19:15.887] iteration 28590 : model1 loss : 0.438419 model2 loss : 0.015331
[01:19:16.068] iteration 28591 : model1 loss : 0.446545 model2 loss : 0.016206
[01:19:16.251] iteration 28592 : model1 loss : 0.438573 model2 loss : 0.015476
[01:19:16.430] iteration 28593 : model1 loss : 0.443554 model2 loss : 0.018541
[01:19:16.616] iteration 28594 : model1 loss : 0.441499 model2 loss : 0.016527
[01:19:16.795] iteration 28595 : model1 loss : 0.436277 model2 loss : 0.016370
[01:19:16.977] iteration 28596 : model1 loss : 0.443148 model2 loss : 0.017235
[01:19:17.158] iteration 28597 : model1 loss : 0.438296 model2 loss : 0.014259
[01:19:17.344] iteration 28598 : model1 loss : 0.439811 model2 loss : 0.016601
[01:19:17.525] iteration 28599 : model1 loss : 0.436985 model2 loss : 0.014848
[01:19:17.710] iteration 28600 : model1 loss : 0.437511 model2 loss : 0.014119
[01:19:17.888] iteration 28601 : model1 loss : 0.438222 model2 loss : 0.017191
[01:19:18.070] iteration 28602 : model1 loss : 0.440134 model2 loss : 0.016959
[01:19:20.108] iteration 28603 : model1 loss : 0.439154 model2 loss : 0.014800
[01:19:20.286] iteration 28604 : model1 loss : 0.440319 model2 loss : 0.016017
[01:19:20.470] iteration 28605 : model1 loss : 0.434303 model2 loss : 0.014729
[01:19:20.652] iteration 28606 : model1 loss : 0.439646 model2 loss : 0.015576
[01:19:20.834] iteration 28607 : model1 loss : 0.439775 model2 loss : 0.013455
[01:19:21.016] iteration 28608 : model1 loss : 0.438671 model2 loss : 0.016107
[01:19:21.196] iteration 28609 : model1 loss : 0.441735 model2 loss : 0.016281
[01:19:21.375] iteration 28610 : model1 loss : 0.445290 model2 loss : 0.018088
[01:19:21.559] iteration 28611 : model1 loss : 0.441045 model2 loss : 0.014271
[01:19:21.743] iteration 28612 : model1 loss : 0.438287 model2 loss : 0.014828
[01:19:21.923] iteration 28613 : model1 loss : 0.444082 model2 loss : 0.018110
[01:19:22.105] iteration 28614 : model1 loss : 0.436161 model2 loss : 0.015808
[01:19:22.287] iteration 28615 : model1 loss : 0.439525 model2 loss : 0.017644
[01:19:22.466] iteration 28616 : model1 loss : 0.443195 model2 loss : 0.019386
[01:19:22.651] iteration 28617 : model1 loss : 0.441210 model2 loss : 0.017385
[01:19:22.833] iteration 28618 : model1 loss : 0.436045 model2 loss : 0.014498
[01:19:23.016] iteration 28619 : model1 loss : 0.440889 model2 loss : 0.015871
[01:19:23.196] iteration 28620 : model1 loss : 0.442157 model2 loss : 0.016858
[01:19:23.381] iteration 28621 : model1 loss : 0.438017 model2 loss : 0.014733
[01:19:23.558] iteration 28622 : model1 loss : 0.439515 model2 loss : 0.017686
[01:19:23.740] iteration 28623 : model1 loss : 0.442006 model2 loss : 0.016611
[01:19:25.759] iteration 28624 : model1 loss : 0.440215 model2 loss : 0.015307
[01:19:25.938] iteration 28625 : model1 loss : 0.439168 model2 loss : 0.017391
[01:19:26.123] iteration 28626 : model1 loss : 0.441362 model2 loss : 0.018483
[01:19:26.304] iteration 28627 : model1 loss : 0.441345 model2 loss : 0.015260
[01:19:26.486] iteration 28628 : model1 loss : 0.441817 model2 loss : 0.015899
[01:19:26.669] iteration 28629 : model1 loss : 0.441929 model2 loss : 0.017486
[01:19:26.851] iteration 28630 : model1 loss : 0.436328 model2 loss : 0.017442
[01:19:27.031] iteration 28631 : model1 loss : 0.442441 model2 loss : 0.016369
[01:19:27.213] iteration 28632 : model1 loss : 0.442457 model2 loss : 0.014896
[01:19:27.400] iteration 28633 : model1 loss : 0.441021 model2 loss : 0.015754
[01:19:27.586] iteration 28634 : model1 loss : 0.436203 model2 loss : 0.017066
[01:19:27.764] iteration 28635 : model1 loss : 0.436765 model2 loss : 0.013436
[01:19:27.946] iteration 28636 : model1 loss : 0.437550 model2 loss : 0.015162
[01:19:28.130] iteration 28637 : model1 loss : 0.442501 model2 loss : 0.017486
[01:19:28.319] iteration 28638 : model1 loss : 0.441013 model2 loss : 0.018003
[01:19:28.496] iteration 28639 : model1 loss : 0.442829 model2 loss : 0.015448
[01:19:28.683] iteration 28640 : model1 loss : 0.437516 model2 loss : 0.015686
[01:19:28.862] iteration 28641 : model1 loss : 0.442162 model2 loss : 0.015910
[01:19:29.046] iteration 28642 : model1 loss : 0.439991 model2 loss : 0.015407
[01:19:29.221] iteration 28643 : model1 loss : 0.438013 model2 loss : 0.015160
[01:19:29.414] iteration 28644 : model1 loss : 0.439934 model2 loss : 0.016840
[01:19:31.427] iteration 28645 : model1 loss : 0.442260 model2 loss : 0.015339
[01:19:31.609] iteration 28646 : model1 loss : 0.438847 model2 loss : 0.016543
[01:19:31.794] iteration 28647 : model1 loss : 0.443557 model2 loss : 0.017936
[01:19:31.978] iteration 28648 : model1 loss : 0.438102 model2 loss : 0.016546
[01:19:32.156] iteration 28649 : model1 loss : 0.439889 model2 loss : 0.014971
[01:19:32.336] iteration 28650 : model1 loss : 0.436483 model2 loss : 0.016648
[01:19:32.520] iteration 28651 : model1 loss : 0.435459 model2 loss : 0.014690
[01:19:32.704] iteration 28652 : model1 loss : 0.438415 model2 loss : 0.015618
[01:19:32.893] iteration 28653 : model1 loss : 0.442361 model2 loss : 0.016864
[01:19:33.076] iteration 28654 : model1 loss : 0.438867 model2 loss : 0.016266
[01:19:33.258] iteration 28655 : model1 loss : 0.442620 model2 loss : 0.015444
[01:19:33.433] iteration 28656 : model1 loss : 0.441959 model2 loss : 0.015860
[01:19:33.612] iteration 28657 : model1 loss : 0.443107 model2 loss : 0.015044
[01:19:33.793] iteration 28658 : model1 loss : 0.442072 model2 loss : 0.017155
[01:19:33.977] iteration 28659 : model1 loss : 0.437954 model2 loss : 0.015137
[01:19:34.157] iteration 28660 : model1 loss : 0.442409 model2 loss : 0.015238
[01:19:34.342] iteration 28661 : model1 loss : 0.440526 model2 loss : 0.016612
[01:19:34.523] iteration 28662 : model1 loss : 0.439578 model2 loss : 0.015039
[01:19:34.706] iteration 28663 : model1 loss : 0.442483 model2 loss : 0.019862
[01:19:34.889] iteration 28664 : model1 loss : 0.437446 model2 loss : 0.015982
[01:19:35.071] iteration 28665 : model1 loss : 0.439368 model2 loss : 0.018204
[01:19:37.100] iteration 28666 : model1 loss : 0.441265 model2 loss : 0.016151
[01:19:37.286] iteration 28667 : model1 loss : 0.439303 model2 loss : 0.016202
[01:19:37.471] iteration 28668 : model1 loss : 0.439679 model2 loss : 0.016529
[01:19:37.653] iteration 28669 : model1 loss : 0.439646 model2 loss : 0.015858
[01:19:37.833] iteration 28670 : model1 loss : 0.440088 model2 loss : 0.018826
[01:19:38.012] iteration 28671 : model1 loss : 0.438547 model2 loss : 0.015018
[01:19:38.196] iteration 28672 : model1 loss : 0.443041 model2 loss : 0.018415
[01:19:38.377] iteration 28673 : model1 loss : 0.437150 model2 loss : 0.015083
[01:19:38.559] iteration 28674 : model1 loss : 0.439655 model2 loss : 0.015910
[01:19:38.742] iteration 28675 : model1 loss : 0.444102 model2 loss : 0.015348
[01:19:38.926] iteration 28676 : model1 loss : 0.443660 model2 loss : 0.016666
[01:19:39.117] iteration 28677 : model1 loss : 0.439394 model2 loss : 0.016454
[01:19:39.304] iteration 28678 : model1 loss : 0.440752 model2 loss : 0.016781
[01:19:39.483] iteration 28679 : model1 loss : 0.440958 model2 loss : 0.017391
[01:19:39.670] iteration 28680 : model1 loss : 0.440905 model2 loss : 0.013410
[01:19:39.842] iteration 28681 : model1 loss : 0.435585 model2 loss : 0.015889
[01:19:40.015] iteration 28682 : model1 loss : 0.437713 model2 loss : 0.014423
[01:19:40.181] iteration 28683 : model1 loss : 0.438654 model2 loss : 0.016409
[01:19:40.354] iteration 28684 : model1 loss : 0.442117 model2 loss : 0.017625
[01:19:40.520] iteration 28685 : model1 loss : 0.438143 model2 loss : 0.014850
[01:19:40.690] iteration 28686 : model1 loss : 0.439174 model2 loss : 0.017804
[01:19:42.668] iteration 28687 : model1 loss : 0.441929 model2 loss : 0.018277
[01:19:42.837] iteration 28688 : model1 loss : 0.438939 model2 loss : 0.015799
[01:19:43.022] iteration 28689 : model1 loss : 0.439460 model2 loss : 0.015747
[01:19:43.188] iteration 28690 : model1 loss : 0.446689 model2 loss : 0.017704
[01:19:43.364] iteration 28691 : model1 loss : 0.447017 model2 loss : 0.017257
[01:19:43.532] iteration 28692 : model1 loss : 0.441018 model2 loss : 0.018606
[01:19:43.709] iteration 28693 : model1 loss : 0.440880 model2 loss : 0.016965
[01:19:43.877] iteration 28694 : model1 loss : 0.437934 model2 loss : 0.013893
[01:19:44.051] iteration 28695 : model1 loss : 0.442901 model2 loss : 0.017675
[01:19:44.218] iteration 28696 : model1 loss : 0.438259 model2 loss : 0.015354
[01:19:44.391] iteration 28697 : model1 loss : 0.438370 model2 loss : 0.015157
[01:19:44.559] iteration 28698 : model1 loss : 0.440399 model2 loss : 0.016215
[01:19:44.739] iteration 28699 : model1 loss : 0.438477 model2 loss : 0.015653
[01:19:44.909] iteration 28700 : model1 loss : 0.436433 model2 loss : 0.016877
[01:19:45.082] iteration 28701 : model1 loss : 0.441560 model2 loss : 0.015089
[01:19:45.250] iteration 28702 : model1 loss : 0.440643 model2 loss : 0.016415
[01:19:45.422] iteration 28703 : model1 loss : 0.437942 model2 loss : 0.016249
[01:19:45.589] iteration 28704 : model1 loss : 0.436517 model2 loss : 0.016442
[01:19:45.763] iteration 28705 : model1 loss : 0.438019 model2 loss : 0.015242
[01:19:45.931] iteration 28706 : model1 loss : 0.443138 model2 loss : 0.016622
[01:19:46.103] iteration 28707 : model1 loss : 0.438593 model2 loss : 0.015293
[01:19:48.518] iteration 28708 : model1 loss : 0.436945 model2 loss : 0.017254
[01:19:48.695] iteration 28709 : model1 loss : 0.442838 model2 loss : 0.017587
[01:19:48.875] iteration 28710 : model1 loss : 0.437335 model2 loss : 0.014476
[01:19:49.045] iteration 28711 : model1 loss : 0.444523 model2 loss : 0.017815
[01:19:49.217] iteration 28712 : model1 loss : 0.439037 model2 loss : 0.015705
[01:19:49.387] iteration 28713 : model1 loss : 0.438724 model2 loss : 0.015555
[01:19:49.560] iteration 28714 : model1 loss : 0.441261 model2 loss : 0.015240
[01:19:49.733] iteration 28715 : model1 loss : 0.437015 model2 loss : 0.016035
[01:19:49.915] iteration 28716 : model1 loss : 0.443033 model2 loss : 0.016320
[01:19:50.084] iteration 28717 : model1 loss : 0.436107 model2 loss : 0.016332
[01:19:50.255] iteration 28718 : model1 loss : 0.438833 model2 loss : 0.016091
[01:19:50.422] iteration 28719 : model1 loss : 0.439813 model2 loss : 0.015165
[01:19:50.607] iteration 28720 : model1 loss : 0.439682 model2 loss : 0.015790
[01:19:50.797] iteration 28721 : model1 loss : 0.441399 model2 loss : 0.017483
[01:19:50.972] iteration 28722 : model1 loss : 0.443064 model2 loss : 0.017072
[01:19:51.147] iteration 28723 : model1 loss : 0.443143 model2 loss : 0.016746
[01:19:51.369] iteration 28724 : model1 loss : 0.439779 model2 loss : 0.016420
[01:19:51.554] iteration 28725 : model1 loss : 0.438927 model2 loss : 0.017802
[01:19:51.736] iteration 28726 : model1 loss : 0.443685 model2 loss : 0.016845
[01:19:51.927] iteration 28727 : model1 loss : 0.438959 model2 loss : 0.016510
[01:19:52.146] iteration 28728 : model1 loss : 0.443005 model2 loss : 0.015538
[01:19:54.179] iteration 28729 : model1 loss : 0.438142 model2 loss : 0.014601
[01:19:54.351] iteration 28730 : model1 loss : 0.441456 model2 loss : 0.017079
[01:19:54.524] iteration 28731 : model1 loss : 0.443193 model2 loss : 0.017462
[01:19:54.700] iteration 28732 : model1 loss : 0.441270 model2 loss : 0.015400
[01:19:54.884] iteration 28733 : model1 loss : 0.437109 model2 loss : 0.017671
[01:19:55.061] iteration 28734 : model1 loss : 0.439099 model2 loss : 0.016756
[01:19:55.247] iteration 28735 : model1 loss : 0.440734 model2 loss : 0.017565
[01:19:55.421] iteration 28736 : model1 loss : 0.437887 model2 loss : 0.014779
[01:19:55.593] iteration 28737 : model1 loss : 0.439575 model2 loss : 0.015234
[01:19:55.767] iteration 28738 : model1 loss : 0.444318 model2 loss : 0.018203
[01:19:55.940] iteration 28739 : model1 loss : 0.436730 model2 loss : 0.015200
[01:19:56.112] iteration 28740 : model1 loss : 0.438342 model2 loss : 0.015283
[01:19:56.283] iteration 28741 : model1 loss : 0.440602 model2 loss : 0.016213
[01:19:56.456] iteration 28742 : model1 loss : 0.437847 model2 loss : 0.015466
[01:19:56.638] iteration 28743 : model1 loss : 0.437894 model2 loss : 0.015499
[01:19:56.810] iteration 28744 : model1 loss : 0.440826 model2 loss : 0.014739
[01:19:56.983] iteration 28745 : model1 loss : 0.440835 model2 loss : 0.016024
[01:19:57.158] iteration 28746 : model1 loss : 0.438196 model2 loss : 0.015526
[01:19:57.333] iteration 28747 : model1 loss : 0.441654 model2 loss : 0.014788
[01:19:57.501] iteration 28748 : model1 loss : 0.442823 model2 loss : 0.017386
[01:19:57.675] iteration 28749 : model1 loss : 0.445686 model2 loss : 0.018293
[01:19:59.674] iteration 28750 : model1 loss : 0.442829 model2 loss : 0.016095
[01:19:59.848] iteration 28751 : model1 loss : 0.440354 model2 loss : 0.016339
[01:20:00.025] iteration 28752 : model1 loss : 0.440268 model2 loss : 0.015151
[01:20:00.204] iteration 28753 : model1 loss : 0.441981 model2 loss : 0.017243
[01:20:00.377] iteration 28754 : model1 loss : 0.439398 model2 loss : 0.014395
[01:20:00.547] iteration 28755 : model1 loss : 0.436634 model2 loss : 0.015474
[01:20:00.720] iteration 28756 : model1 loss : 0.437232 model2 loss : 0.014847
[01:20:00.895] iteration 28757 : model1 loss : 0.437123 model2 loss : 0.015123
[01:20:01.069] iteration 28758 : model1 loss : 0.444557 model2 loss : 0.015955
[01:20:01.253] iteration 28759 : model1 loss : 0.438286 model2 loss : 0.014940
[01:20:01.428] iteration 28760 : model1 loss : 0.437554 model2 loss : 0.013939
[01:20:01.615] iteration 28761 : model1 loss : 0.436175 model2 loss : 0.016495
[01:20:01.791] iteration 28762 : model1 loss : 0.442244 model2 loss : 0.017148
[01:20:01.967] iteration 28763 : model1 loss : 0.443109 model2 loss : 0.017540
[01:20:02.145] iteration 28764 : model1 loss : 0.443519 model2 loss : 0.016633
[01:20:02.319] iteration 28765 : model1 loss : 0.439985 model2 loss : 0.015614
[01:20:02.498] iteration 28766 : model1 loss : 0.440606 model2 loss : 0.015991
[01:20:02.669] iteration 28767 : model1 loss : 0.437981 model2 loss : 0.015470
[01:20:02.844] iteration 28768 : model1 loss : 0.436930 model2 loss : 0.015242
[01:20:03.011] iteration 28769 : model1 loss : 0.441708 model2 loss : 0.017038
[01:20:03.182] iteration 28770 : model1 loss : 0.440339 model2 loss : 0.016049
[01:20:05.304] iteration 28771 : model1 loss : 0.443127 model2 loss : 0.017986
[01:20:05.479] iteration 28772 : model1 loss : 0.442355 model2 loss : 0.016057
[01:20:05.655] iteration 28773 : model1 loss : 0.440674 model2 loss : 0.017618
[01:20:05.830] iteration 28774 : model1 loss : 0.445279 model2 loss : 0.017369
[01:20:06.012] iteration 28775 : model1 loss : 0.440347 model2 loss : 0.015959
[01:20:06.184] iteration 28776 : model1 loss : 0.440767 model2 loss : 0.014373
[01:20:06.369] iteration 28777 : model1 loss : 0.440538 model2 loss : 0.013841
[01:20:06.544] iteration 28778 : model1 loss : 0.437006 model2 loss : 0.016268
[01:20:06.747] iteration 28779 : model1 loss : 0.442574 model2 loss : 0.016695
[01:20:06.921] iteration 28780 : model1 loss : 0.442675 model2 loss : 0.017503
[01:20:07.109] iteration 28781 : model1 loss : 0.440822 model2 loss : 0.014944
[01:20:07.285] iteration 28782 : model1 loss : 0.439362 model2 loss : 0.014912
[01:20:07.496] iteration 28783 : model1 loss : 0.438279 model2 loss : 0.014533
[01:20:07.673] iteration 28784 : model1 loss : 0.440248 model2 loss : 0.015913
[01:20:07.850] iteration 28785 : model1 loss : 0.436142 model2 loss : 0.017148
[01:20:08.021] iteration 28786 : model1 loss : 0.442717 model2 loss : 0.017966
[01:20:08.202] iteration 28787 : model1 loss : 0.439222 model2 loss : 0.015109
[01:20:08.375] iteration 28788 : model1 loss : 0.438371 model2 loss : 0.016292
[01:20:08.555] iteration 28789 : model1 loss : 0.433645 model2 loss : 0.015502
[01:20:08.724] iteration 28790 : model1 loss : 0.439751 model2 loss : 0.015210
[01:20:08.899] iteration 28791 : model1 loss : 0.439878 model2 loss : 0.016238
[01:20:10.923] iteration 28792 : model1 loss : 0.440223 model2 loss : 0.016461
[01:20:11.095] iteration 28793 : model1 loss : 0.435043 model2 loss : 0.015674
[01:20:11.269] iteration 28794 : model1 loss : 0.439986 model2 loss : 0.014618
[01:20:11.441] iteration 28795 : model1 loss : 0.440394 model2 loss : 0.016231
[01:20:11.613] iteration 28796 : model1 loss : 0.443105 model2 loss : 0.018416
[01:20:11.793] iteration 28797 : model1 loss : 0.443504 model2 loss : 0.016909
[01:20:11.979] iteration 28798 : model1 loss : 0.441630 model2 loss : 0.015530
[01:20:12.152] iteration 28799 : model1 loss : 0.436110 model2 loss : 0.014789
[01:20:12.338] iteration 28800 : model1 loss : 0.443105 model2 loss : 0.014777
[01:20:12.514] iteration 28801 : model1 loss : 0.438710 model2 loss : 0.016795
[01:20:12.687] iteration 28802 : model1 loss : 0.440242 model2 loss : 0.016975
[01:20:12.857] iteration 28803 : model1 loss : 0.437995 model2 loss : 0.017778
[01:20:13.034] iteration 28804 : model1 loss : 0.441533 model2 loss : 0.016529
[01:20:13.207] iteration 28805 : model1 loss : 0.441883 model2 loss : 0.014778
[01:20:13.385] iteration 28806 : model1 loss : 0.442421 model2 loss : 0.017840
[01:20:13.554] iteration 28807 : model1 loss : 0.438785 model2 loss : 0.017655
[01:20:13.724] iteration 28808 : model1 loss : 0.445509 model2 loss : 0.016722
[01:20:13.897] iteration 28809 : model1 loss : 0.440815 model2 loss : 0.018208
[01:20:14.075] iteration 28810 : model1 loss : 0.439019 model2 loss : 0.017781
[01:20:14.252] iteration 28811 : model1 loss : 0.438433 model2 loss : 0.017256
[01:20:14.427] iteration 28812 : model1 loss : 0.436916 model2 loss : 0.016115
[01:20:16.455] iteration 28813 : model1 loss : 0.440949 model2 loss : 0.016361
[01:20:16.629] iteration 28814 : model1 loss : 0.437770 model2 loss : 0.015003
[01:20:16.811] iteration 28815 : model1 loss : 0.443976 model2 loss : 0.017925
[01:20:16.992] iteration 28816 : model1 loss : 0.440668 model2 loss : 0.014199
[01:20:17.186] iteration 28817 : model1 loss : 0.439302 model2 loss : 0.016181
[01:20:17.447] iteration 28818 : model1 loss : 0.444875 model2 loss : 0.016566
[01:20:17.628] iteration 28819 : model1 loss : 0.438433 model2 loss : 0.015432
[01:20:17.845] iteration 28820 : model1 loss : 0.440524 model2 loss : 0.015795
[01:20:18.070] iteration 28821 : model1 loss : 0.438293 model2 loss : 0.016962
[01:20:18.251] iteration 28822 : model1 loss : 0.439232 model2 loss : 0.015503
[01:20:18.429] iteration 28823 : model1 loss : 0.438261 model2 loss : 0.015548
[01:20:18.608] iteration 28824 : model1 loss : 0.441521 model2 loss : 0.014184
[01:20:18.782] iteration 28825 : model1 loss : 0.439367 model2 loss : 0.015680
[01:20:18.956] iteration 28826 : model1 loss : 0.444550 model2 loss : 0.015265
[01:20:19.144] iteration 28827 : model1 loss : 0.437652 model2 loss : 0.015320
[01:20:19.335] iteration 28828 : model1 loss : 0.441763 model2 loss : 0.015914
[01:20:19.506] iteration 28829 : model1 loss : 0.440413 model2 loss : 0.017262
[01:20:19.676] iteration 28830 : model1 loss : 0.436273 model2 loss : 0.016702
[01:20:19.848] iteration 28831 : model1 loss : 0.440596 model2 loss : 0.015625
[01:20:20.014] iteration 28832 : model1 loss : 0.443914 model2 loss : 0.017605
[01:20:20.185] iteration 28833 : model1 loss : 0.436778 model2 loss : 0.015855
[01:20:22.236] iteration 28834 : model1 loss : 0.440677 model2 loss : 0.016170
[01:20:22.439] iteration 28835 : model1 loss : 0.435979 model2 loss : 0.014965
[01:20:22.620] iteration 28836 : model1 loss : 0.436150 model2 loss : 0.014811
[01:20:22.797] iteration 28837 : model1 loss : 0.444597 model2 loss : 0.017356
[01:20:22.971] iteration 28838 : model1 loss : 0.439680 model2 loss : 0.016499
[01:20:23.150] iteration 28839 : model1 loss : 0.439872 model2 loss : 0.015836
[01:20:23.335] iteration 28840 : model1 loss : 0.439855 model2 loss : 0.014809
[01:20:23.509] iteration 28841 : model1 loss : 0.439750 model2 loss : 0.015867
[01:20:23.684] iteration 28842 : model1 loss : 0.443800 model2 loss : 0.017287
[01:20:23.854] iteration 28843 : model1 loss : 0.446915 model2 loss : 0.017920
[01:20:24.026] iteration 28844 : model1 loss : 0.437668 model2 loss : 0.015970
[01:20:24.197] iteration 28845 : model1 loss : 0.437110 model2 loss : 0.014269
[01:20:24.374] iteration 28846 : model1 loss : 0.439420 model2 loss : 0.016187
[01:20:24.552] iteration 28847 : model1 loss : 0.438343 model2 loss : 0.014904
[01:20:24.726] iteration 28848 : model1 loss : 0.442499 model2 loss : 0.016373
[01:20:24.906] iteration 28849 : model1 loss : 0.443946 model2 loss : 0.015901
[01:20:25.085] iteration 28850 : model1 loss : 0.437862 model2 loss : 0.014348
[01:20:25.262] iteration 28851 : model1 loss : 0.438441 model2 loss : 0.016116
[01:20:25.437] iteration 28852 : model1 loss : 0.443626 model2 loss : 0.018603
[01:20:25.604] iteration 28853 : model1 loss : 0.439730 model2 loss : 0.016704
[01:20:25.779] iteration 28854 : model1 loss : 0.436745 model2 loss : 0.014869
[01:20:27.773] iteration 28855 : model1 loss : 0.442708 model2 loss : 0.017989
[01:20:27.951] iteration 28856 : model1 loss : 0.440786 model2 loss : 0.016401
[01:20:28.128] iteration 28857 : model1 loss : 0.437406 model2 loss : 0.015849
[01:20:28.306] iteration 28858 : model1 loss : 0.441799 model2 loss : 0.019456
[01:20:28.487] iteration 28859 : model1 loss : 0.438104 model2 loss : 0.017744
[01:20:28.677] iteration 28860 : model1 loss : 0.439176 model2 loss : 0.016354
[01:20:28.871] iteration 28861 : model1 loss : 0.439256 model2 loss : 0.016869
[01:20:29.060] iteration 28862 : model1 loss : 0.443478 model2 loss : 0.016637
[01:20:29.239] iteration 28863 : model1 loss : 0.444292 model2 loss : 0.016004
[01:20:29.459] iteration 28864 : model1 loss : 0.437638 model2 loss : 0.016565
[01:20:29.626] iteration 28865 : model1 loss : 0.437828 model2 loss : 0.016451
[01:20:29.810] iteration 28866 : model1 loss : 0.433791 model2 loss : 0.015765
[01:20:29.987] iteration 28867 : model1 loss : 0.440849 model2 loss : 0.016386
[01:20:30.158] iteration 28868 : model1 loss : 0.442149 model2 loss : 0.014993
[01:20:30.330] iteration 28869 : model1 loss : 0.441515 model2 loss : 0.016199
[01:20:30.505] iteration 28870 : model1 loss : 0.444312 model2 loss : 0.016850
[01:20:30.683] iteration 28871 : model1 loss : 0.441048 model2 loss : 0.014226
[01:20:30.886] iteration 28872 : model1 loss : 0.435751 model2 loss : 0.014072
[01:20:31.076] iteration 28873 : model1 loss : 0.439971 model2 loss : 0.016239
[01:20:31.260] iteration 28874 : model1 loss : 0.444345 model2 loss : 0.016194
[01:20:31.454] iteration 28875 : model1 loss : 0.439183 model2 loss : 0.015238
[01:20:33.688] iteration 28876 : model1 loss : 0.440500 model2 loss : 0.015982
[01:20:33.862] iteration 28877 : model1 loss : 0.438701 model2 loss : 0.016423
[01:20:34.050] iteration 28878 : model1 loss : 0.439499 model2 loss : 0.014944
[01:20:34.245] iteration 28879 : model1 loss : 0.441077 model2 loss : 0.016817
[01:20:34.448] iteration 28880 : model1 loss : 0.438832 model2 loss : 0.017343
[01:20:34.631] iteration 28881 : model1 loss : 0.440757 model2 loss : 0.014763
[01:20:34.825] iteration 28882 : model1 loss : 0.435639 model2 loss : 0.016386
[01:20:35.002] iteration 28883 : model1 loss : 0.433154 model2 loss : 0.015008
[01:20:35.177] iteration 28884 : model1 loss : 0.440385 model2 loss : 0.016777
[01:20:35.372] iteration 28885 : model1 loss : 0.440459 model2 loss : 0.016001
[01:20:35.569] iteration 28886 : model1 loss : 0.440213 model2 loss : 0.014781
[01:20:35.755] iteration 28887 : model1 loss : 0.441397 model2 loss : 0.017148
[01:20:35.948] iteration 28888 : model1 loss : 0.439747 model2 loss : 0.017056
[01:20:36.175] iteration 28889 : model1 loss : 0.441370 model2 loss : 0.016171
[01:20:36.395] iteration 28890 : model1 loss : 0.445529 model2 loss : 0.021118
[01:20:36.585] iteration 28891 : model1 loss : 0.442687 model2 loss : 0.016208
[01:20:36.773] iteration 28892 : model1 loss : 0.440493 model2 loss : 0.015886
[01:20:36.941] iteration 28893 : model1 loss : 0.443502 model2 loss : 0.018061
[01:20:37.130] iteration 28894 : model1 loss : 0.443198 model2 loss : 0.015988
[01:20:37.332] iteration 28895 : model1 loss : 0.440635 model2 loss : 0.017345
[01:20:37.529] iteration 28896 : model1 loss : 0.438024 model2 loss : 0.016100
[01:20:39.929] iteration 28897 : model1 loss : 0.442573 model2 loss : 0.014969
[01:20:40.148] iteration 28898 : model1 loss : 0.444396 model2 loss : 0.021886
[01:20:40.376] iteration 28899 : model1 loss : 0.437876 model2 loss : 0.015373
[01:20:40.599] iteration 28900 : model1 loss : 0.438925 model2 loss : 0.017001
[01:20:40.821] iteration 28901 : model1 loss : 0.442155 model2 loss : 0.017226
[01:20:41.043] iteration 28902 : model1 loss : 0.441515 model2 loss : 0.017682
[01:20:41.268] iteration 28903 : model1 loss : 0.436796 model2 loss : 0.015354
[01:20:41.488] iteration 28904 : model1 loss : 0.440147 model2 loss : 0.016298
[01:20:41.710] iteration 28905 : model1 loss : 0.441937 model2 loss : 0.016803
[01:20:41.933] iteration 28906 : model1 loss : 0.440907 model2 loss : 0.016118
[01:20:42.159] iteration 28907 : model1 loss : 0.431725 model2 loss : 0.014956
[01:20:42.390] iteration 28908 : model1 loss : 0.436243 model2 loss : 0.014627
[01:20:42.610] iteration 28909 : model1 loss : 0.439766 model2 loss : 0.016592
[01:20:42.831] iteration 28910 : model1 loss : 0.445534 model2 loss : 0.017354
[01:20:43.057] iteration 28911 : model1 loss : 0.438444 model2 loss : 0.014708
[01:20:43.279] iteration 28912 : model1 loss : 0.441989 model2 loss : 0.017761
[01:20:43.500] iteration 28913 : model1 loss : 0.439622 model2 loss : 0.014763
[01:20:43.722] iteration 28914 : model1 loss : 0.442948 model2 loss : 0.016445
[01:20:43.945] iteration 28915 : model1 loss : 0.439084 model2 loss : 0.015158
[01:20:44.169] iteration 28916 : model1 loss : 0.441507 model2 loss : 0.017326
[01:20:44.392] iteration 28917 : model1 loss : 0.440514 model2 loss : 0.016883
[01:20:46.668] iteration 28918 : model1 loss : 0.444497 model2 loss : 0.017980
[01:20:46.891] iteration 28919 : model1 loss : 0.438419 model2 loss : 0.017903
[01:20:47.114] iteration 28920 : model1 loss : 0.437059 model2 loss : 0.014513
[01:20:47.340] iteration 28921 : model1 loss : 0.440006 model2 loss : 0.016455
[01:20:47.564] iteration 28922 : model1 loss : 0.441886 model2 loss : 0.016365
[01:20:47.790] iteration 28923 : model1 loss : 0.443885 model2 loss : 0.016936
[01:20:48.011] iteration 28924 : model1 loss : 0.442777 model2 loss : 0.017129
[01:20:48.230] iteration 28925 : model1 loss : 0.443945 model2 loss : 0.015786
[01:20:48.454] iteration 28926 : model1 loss : 0.439592 model2 loss : 0.015708
[01:20:48.676] iteration 28927 : model1 loss : 0.442633 model2 loss : 0.016193
[01:20:48.898] iteration 28928 : model1 loss : 0.439301 model2 loss : 0.014689
[01:20:49.119] iteration 28929 : model1 loss : 0.438701 model2 loss : 0.015535
[01:20:49.349] iteration 28930 : model1 loss : 0.444396 model2 loss : 0.016260
[01:20:49.571] iteration 28931 : model1 loss : 0.438507 model2 loss : 0.015987
[01:20:49.792] iteration 28932 : model1 loss : 0.437246 model2 loss : 0.015101
[01:20:50.017] iteration 28933 : model1 loss : 0.440586 model2 loss : 0.015737
[01:20:50.246] iteration 28934 : model1 loss : 0.441268 model2 loss : 0.016087
[01:20:50.473] iteration 28935 : model1 loss : 0.439336 model2 loss : 0.014830
[01:20:50.702] iteration 28936 : model1 loss : 0.434792 model2 loss : 0.014776
[01:20:50.920] iteration 28937 : model1 loss : 0.436365 model2 loss : 0.017535
[01:20:51.138] iteration 28938 : model1 loss : 0.439783 model2 loss : 0.016188
[01:20:53.750] iteration 28939 : model1 loss : 0.442662 model2 loss : 0.018261
[01:20:53.989] iteration 28940 : model1 loss : 0.438319 model2 loss : 0.015450
[01:20:54.228] iteration 28941 : model1 loss : 0.441248 model2 loss : 0.017808
[01:20:54.464] iteration 28942 : model1 loss : 0.441509 model2 loss : 0.016619
[01:20:54.696] iteration 28943 : model1 loss : 0.440539 model2 loss : 0.014477
[01:20:54.925] iteration 28944 : model1 loss : 0.440206 model2 loss : 0.016449
[01:20:55.160] iteration 28945 : model1 loss : 0.437669 model2 loss : 0.014342
[01:20:55.397] iteration 28946 : model1 loss : 0.443004 model2 loss : 0.014385
[01:20:55.629] iteration 28947 : model1 loss : 0.441069 model2 loss : 0.019700
[01:20:55.861] iteration 28948 : model1 loss : 0.436765 model2 loss : 0.014131
[01:20:56.094] iteration 28949 : model1 loss : 0.440036 model2 loss : 0.014898
[01:20:56.325] iteration 28950 : model1 loss : 0.444139 model2 loss : 0.016461
[01:20:56.561] iteration 28951 : model1 loss : 0.438912 model2 loss : 0.016694
[01:20:56.792] iteration 28952 : model1 loss : 0.440944 model2 loss : 0.017809
[01:20:57.023] iteration 28953 : model1 loss : 0.444221 model2 loss : 0.016839
[01:20:57.255] iteration 28954 : model1 loss : 0.443001 model2 loss : 0.018519
[01:20:57.487] iteration 28955 : model1 loss : 0.444909 model2 loss : 0.016233
[01:20:57.718] iteration 28956 : model1 loss : 0.437649 model2 loss : 0.017059
[01:20:57.954] iteration 28957 : model1 loss : 0.436807 model2 loss : 0.016530
[01:20:58.188] iteration 28958 : model1 loss : 0.435973 model2 loss : 0.017259
[01:20:58.419] iteration 28959 : model1 loss : 0.439107 model2 loss : 0.015934
[01:21:00.745] iteration 28960 : model1 loss : 0.440493 model2 loss : 0.017131
[01:21:00.981] iteration 28961 : model1 loss : 0.440174 model2 loss : 0.016557
[01:21:01.212] iteration 28962 : model1 loss : 0.437532 model2 loss : 0.014668
[01:21:01.447] iteration 28963 : model1 loss : 0.441577 model2 loss : 0.015402
[01:21:01.682] iteration 28964 : model1 loss : 0.444638 model2 loss : 0.016403
[01:21:01.914] iteration 28965 : model1 loss : 0.443812 model2 loss : 0.015731
[01:21:02.147] iteration 28966 : model1 loss : 0.441547 model2 loss : 0.018126
[01:21:02.374] iteration 28967 : model1 loss : 0.440399 model2 loss : 0.017504
[01:21:02.607] iteration 28968 : model1 loss : 0.437132 model2 loss : 0.016173
[01:21:02.843] iteration 28969 : model1 loss : 0.435309 model2 loss : 0.015545
[01:21:03.075] iteration 28970 : model1 loss : 0.435164 model2 loss : 0.017426
[01:21:03.308] iteration 28971 : model1 loss : 0.442782 model2 loss : 0.017428
[01:21:03.546] iteration 28972 : model1 loss : 0.441313 model2 loss : 0.019126
[01:21:03.779] iteration 28973 : model1 loss : 0.444887 model2 loss : 0.016050
[01:21:04.009] iteration 28974 : model1 loss : 0.438041 model2 loss : 0.016193
[01:21:04.243] iteration 28975 : model1 loss : 0.439620 model2 loss : 0.015015
[01:21:04.477] iteration 28976 : model1 loss : 0.442120 model2 loss : 0.015141
[01:21:04.715] iteration 28977 : model1 loss : 0.444469 model2 loss : 0.017108
[01:21:04.948] iteration 28978 : model1 loss : 0.440553 model2 loss : 0.015387
[01:21:05.183] iteration 28979 : model1 loss : 0.437233 model2 loss : 0.015498
[01:21:05.417] iteration 28980 : model1 loss : 0.436819 model2 loss : 0.014637
[01:21:07.789] iteration 28981 : model1 loss : 0.436631 model2 loss : 0.016420
[01:21:08.026] iteration 28982 : model1 loss : 0.436507 model2 loss : 0.016136
[01:21:08.262] iteration 28983 : model1 loss : 0.441240 model2 loss : 0.014482
[01:21:08.492] iteration 28984 : model1 loss : 0.439170 model2 loss : 0.015687
[01:21:08.722] iteration 28985 : model1 loss : 0.441211 model2 loss : 0.015187
[01:21:08.957] iteration 28986 : model1 loss : 0.436953 model2 loss : 0.015070
[01:21:09.196] iteration 28987 : model1 loss : 0.440714 model2 loss : 0.018544
[01:21:09.429] iteration 28988 : model1 loss : 0.439769 model2 loss : 0.016287
[01:21:09.659] iteration 28989 : model1 loss : 0.442526 model2 loss : 0.016914
[01:21:09.895] iteration 28990 : model1 loss : 0.442271 model2 loss : 0.014930
[01:21:10.133] iteration 28991 : model1 loss : 0.442302 model2 loss : 0.015747
[01:21:10.368] iteration 28992 : model1 loss : 0.439646 model2 loss : 0.016962
[01:21:10.604] iteration 28993 : model1 loss : 0.442408 model2 loss : 0.017227
[01:21:10.837] iteration 28994 : model1 loss : 0.443040 model2 loss : 0.016231
[01:21:11.067] iteration 28995 : model1 loss : 0.440741 model2 loss : 0.017100
[01:21:11.297] iteration 28996 : model1 loss : 0.443749 model2 loss : 0.016946
[01:21:11.528] iteration 28997 : model1 loss : 0.434825 model2 loss : 0.014212
[01:21:11.764] iteration 28998 : model1 loss : 0.441934 model2 loss : 0.016474
[01:21:11.995] iteration 28999 : model1 loss : 0.438482 model2 loss : 0.016606
[01:21:12.224] iteration 29000 : model1 loss : 0.439377 model2 loss : 0.015854
[01:21:20.906] iteration 29000 : model1_mean_dice : 0.885171 model1_mean_hd95 : 3.463512
[01:21:30.608] iteration 29000 : model2_mean_dice : 0.882123 model2_mean_hd95 : 3.844542
[01:21:30.797] iteration 29001 : model1 loss : 0.437938 model2 loss : 0.014521
[01:21:32.855] iteration 29002 : model1 loss : 0.439637 model2 loss : 0.015717
[01:21:33.030] iteration 29003 : model1 loss : 0.441234 model2 loss : 0.016366
[01:21:33.205] iteration 29004 : model1 loss : 0.442699 model2 loss : 0.015264
[01:21:33.380] iteration 29005 : model1 loss : 0.442186 model2 loss : 0.016162
[01:21:33.554] iteration 29006 : model1 loss : 0.440795 model2 loss : 0.014256
[01:21:33.720] iteration 29007 : model1 loss : 0.444291 model2 loss : 0.013570
[01:21:33.890] iteration 29008 : model1 loss : 0.442870 model2 loss : 0.019052
[01:21:34.061] iteration 29009 : model1 loss : 0.435358 model2 loss : 0.016587
[01:21:34.232] iteration 29010 : model1 loss : 0.439202 model2 loss : 0.015991
[01:21:34.410] iteration 29011 : model1 loss : 0.442176 model2 loss : 0.017979
[01:21:34.585] iteration 29012 : model1 loss : 0.441514 model2 loss : 0.016193
[01:21:34.753] iteration 29013 : model1 loss : 0.437446 model2 loss : 0.014548
[01:21:34.927] iteration 29014 : model1 loss : 0.440631 model2 loss : 0.015809
[01:21:35.100] iteration 29015 : model1 loss : 0.439425 model2 loss : 0.017001
[01:21:35.276] iteration 29016 : model1 loss : 0.442230 model2 loss : 0.017591
[01:21:35.448] iteration 29017 : model1 loss : 0.438724 model2 loss : 0.017856
[01:21:35.627] iteration 29018 : model1 loss : 0.438774 model2 loss : 0.016791
[01:21:35.810] iteration 29019 : model1 loss : 0.437944 model2 loss : 0.015759
[01:21:35.990] iteration 29020 : model1 loss : 0.438244 model2 loss : 0.016392
[01:21:36.158] iteration 29021 : model1 loss : 0.440832 model2 loss : 0.015626
[01:21:36.336] iteration 29022 : model1 loss : 0.439860 model2 loss : 0.016541
[01:21:38.371] iteration 29023 : model1 loss : 0.441850 model2 loss : 0.015294
[01:21:38.550] iteration 29024 : model1 loss : 0.437646 model2 loss : 0.015438
[01:21:38.726] iteration 29025 : model1 loss : 0.437133 model2 loss : 0.014500
[01:21:38.897] iteration 29026 : model1 loss : 0.439297 model2 loss : 0.016461
[01:21:39.073] iteration 29027 : model1 loss : 0.443972 model2 loss : 0.016087
[01:21:39.240] iteration 29028 : model1 loss : 0.444567 model2 loss : 0.014608
[01:21:39.422] iteration 29029 : model1 loss : 0.440300 model2 loss : 0.016598
[01:21:39.598] iteration 29030 : model1 loss : 0.443002 model2 loss : 0.016238
[01:21:39.775] iteration 29031 : model1 loss : 0.444650 model2 loss : 0.016561
[01:21:39.957] iteration 29032 : model1 loss : 0.443829 model2 loss : 0.017241
[01:21:40.139] iteration 29033 : model1 loss : 0.441576 model2 loss : 0.016264
[01:21:40.321] iteration 29034 : model1 loss : 0.435586 model2 loss : 0.014606
[01:21:40.491] iteration 29035 : model1 loss : 0.435472 model2 loss : 0.016504
[01:21:40.669] iteration 29036 : model1 loss : 0.443177 model2 loss : 0.016185
[01:21:40.848] iteration 29037 : model1 loss : 0.439556 model2 loss : 0.015149
[01:21:41.026] iteration 29038 : model1 loss : 0.440153 model2 loss : 0.015728
[01:21:41.205] iteration 29039 : model1 loss : 0.439907 model2 loss : 0.017416
[01:21:41.376] iteration 29040 : model1 loss : 0.438582 model2 loss : 0.017305
[01:21:41.554] iteration 29041 : model1 loss : 0.436062 model2 loss : 0.015900
[01:21:41.724] iteration 29042 : model1 loss : 0.444628 model2 loss : 0.018018
[01:21:41.891] iteration 29043 : model1 loss : 0.433863 model2 loss : 0.015362
[01:21:43.995] iteration 29044 : model1 loss : 0.439990 model2 loss : 0.014353
[01:21:44.196] iteration 29045 : model1 loss : 0.439002 model2 loss : 0.016542
[01:21:44.379] iteration 29046 : model1 loss : 0.436470 model2 loss : 0.016024
[01:21:44.551] iteration 29047 : model1 loss : 0.444510 model2 loss : 0.016900
[01:21:44.756] iteration 29048 : model1 loss : 0.437088 model2 loss : 0.015233
[01:21:45.111] iteration 29049 : model1 loss : 0.442726 model2 loss : 0.016778
[01:21:45.299] iteration 29050 : model1 loss : 0.437225 model2 loss : 0.016221
[01:21:45.478] iteration 29051 : model1 loss : 0.445745 model2 loss : 0.017694
[01:21:45.720] iteration 29052 : model1 loss : 0.436178 model2 loss : 0.015446
[01:21:45.890] iteration 29053 : model1 loss : 0.434850 model2 loss : 0.014414
[01:21:46.063] iteration 29054 : model1 loss : 0.442975 model2 loss : 0.015693
[01:21:46.233] iteration 29055 : model1 loss : 0.444895 model2 loss : 0.019555
[01:21:46.403] iteration 29056 : model1 loss : 0.436723 model2 loss : 0.015334
[01:21:46.574] iteration 29057 : model1 loss : 0.439925 model2 loss : 0.015524
[01:21:46.747] iteration 29058 : model1 loss : 0.445059 model2 loss : 0.016453
[01:21:46.914] iteration 29059 : model1 loss : 0.444461 model2 loss : 0.016707
[01:21:47.095] iteration 29060 : model1 loss : 0.435999 model2 loss : 0.015834
[01:21:47.270] iteration 29061 : model1 loss : 0.442280 model2 loss : 0.015473
[01:21:47.467] iteration 29062 : model1 loss : 0.443044 model2 loss : 0.015708
[01:21:47.651] iteration 29063 : model1 loss : 0.436058 model2 loss : 0.016603
[01:21:47.837] iteration 29064 : model1 loss : 0.439250 model2 loss : 0.016412
[01:21:49.874] iteration 29065 : model1 loss : 0.439827 model2 loss : 0.015684
[01:21:50.101] iteration 29066 : model1 loss : 0.438764 model2 loss : 0.015710
[01:21:50.314] iteration 29067 : model1 loss : 0.441591 model2 loss : 0.015865
[01:21:50.490] iteration 29068 : model1 loss : 0.442329 model2 loss : 0.015960
[01:21:50.668] iteration 29069 : model1 loss : 0.439538 model2 loss : 0.014961
[01:21:50.835] iteration 29070 : model1 loss : 0.440218 model2 loss : 0.015499
[01:21:51.009] iteration 29071 : model1 loss : 0.440530 model2 loss : 0.015811
[01:21:51.180] iteration 29072 : model1 loss : 0.441071 model2 loss : 0.017251
[01:21:51.352] iteration 29073 : model1 loss : 0.442266 model2 loss : 0.016035
[01:21:51.524] iteration 29074 : model1 loss : 0.441181 model2 loss : 0.017209
[01:21:51.698] iteration 29075 : model1 loss : 0.440750 model2 loss : 0.014896
[01:21:51.864] iteration 29076 : model1 loss : 0.437283 model2 loss : 0.016012
[01:21:52.039] iteration 29077 : model1 loss : 0.440254 model2 loss : 0.016336
[01:21:52.218] iteration 29078 : model1 loss : 0.439760 model2 loss : 0.015901
[01:21:52.396] iteration 29079 : model1 loss : 0.441103 model2 loss : 0.017254
[01:21:52.574] iteration 29080 : model1 loss : 0.437908 model2 loss : 0.014017
[01:21:52.752] iteration 29081 : model1 loss : 0.441676 model2 loss : 0.015330
[01:21:52.921] iteration 29082 : model1 loss : 0.438963 model2 loss : 0.015687
[01:21:53.093] iteration 29083 : model1 loss : 0.442057 model2 loss : 0.017589
[01:21:53.263] iteration 29084 : model1 loss : 0.438273 model2 loss : 0.016102
[01:21:53.441] iteration 29085 : model1 loss : 0.441764 model2 loss : 0.016317
[01:21:55.802] iteration 29086 : model1 loss : 0.444053 model2 loss : 0.016902
[01:21:55.976] iteration 29087 : model1 loss : 0.438280 model2 loss : 0.013972
[01:21:56.215] iteration 29088 : model1 loss : 0.443598 model2 loss : 0.017577
[01:21:56.384] iteration 29089 : model1 loss : 0.440597 model2 loss : 0.016578
[01:21:56.555] iteration 29090 : model1 loss : 0.443114 model2 loss : 0.016136
[01:21:56.726] iteration 29091 : model1 loss : 0.439943 model2 loss : 0.016099
[01:21:56.897] iteration 29092 : model1 loss : 0.441528 model2 loss : 0.014847
[01:21:57.070] iteration 29093 : model1 loss : 0.442000 model2 loss : 0.015850
[01:21:57.239] iteration 29094 : model1 loss : 0.440726 model2 loss : 0.016013
[01:21:57.407] iteration 29095 : model1 loss : 0.441870 model2 loss : 0.017841
[01:21:57.580] iteration 29096 : model1 loss : 0.437886 model2 loss : 0.016160
[01:21:57.748] iteration 29097 : model1 loss : 0.438436 model2 loss : 0.015160
[01:21:57.965] iteration 29098 : model1 loss : 0.436030 model2 loss : 0.015471
[01:21:58.183] iteration 29099 : model1 loss : 0.442246 model2 loss : 0.016079
[01:21:58.352] iteration 29100 : model1 loss : 0.441053 model2 loss : 0.016089
[01:21:58.523] iteration 29101 : model1 loss : 0.442759 model2 loss : 0.016497
[01:21:58.691] iteration 29102 : model1 loss : 0.438492 model2 loss : 0.014335
[01:21:58.877] iteration 29103 : model1 loss : 0.435871 model2 loss : 0.015678
[01:21:59.054] iteration 29104 : model1 loss : 0.438184 model2 loss : 0.014044
[01:21:59.234] iteration 29105 : model1 loss : 0.438703 model2 loss : 0.016721
[01:21:59.410] iteration 29106 : model1 loss : 0.440197 model2 loss : 0.014725
[01:22:01.480] iteration 29107 : model1 loss : 0.438501 model2 loss : 0.016658
[01:22:01.666] iteration 29108 : model1 loss : 0.440858 model2 loss : 0.016871
[01:22:01.835] iteration 29109 : model1 loss : 0.441132 model2 loss : 0.014837
[01:22:02.009] iteration 29110 : model1 loss : 0.441761 model2 loss : 0.016198
[01:22:02.179] iteration 29111 : model1 loss : 0.438210 model2 loss : 0.016010
[01:22:02.347] iteration 29112 : model1 loss : 0.436949 model2 loss : 0.014995
[01:22:02.520] iteration 29113 : model1 loss : 0.441631 model2 loss : 0.016949
[01:22:02.700] iteration 29114 : model1 loss : 0.442468 model2 loss : 0.016887
[01:22:02.884] iteration 29115 : model1 loss : 0.441279 model2 loss : 0.017990
[01:22:03.061] iteration 29116 : model1 loss : 0.440730 model2 loss : 0.015280
[01:22:03.239] iteration 29117 : model1 loss : 0.440714 model2 loss : 0.015769
[01:22:03.407] iteration 29118 : model1 loss : 0.438156 model2 loss : 0.016661
[01:22:03.586] iteration 29119 : model1 loss : 0.438228 model2 loss : 0.015793
[01:22:03.754] iteration 29120 : model1 loss : 0.439091 model2 loss : 0.015877
[01:22:03.926] iteration 29121 : model1 loss : 0.444634 model2 loss : 0.017972
[01:22:04.105] iteration 29122 : model1 loss : 0.435190 model2 loss : 0.014249
[01:22:04.291] iteration 29123 : model1 loss : 0.437703 model2 loss : 0.015938
[01:22:04.470] iteration 29124 : model1 loss : 0.440687 model2 loss : 0.016941
[01:22:04.652] iteration 29125 : model1 loss : 0.444033 model2 loss : 0.018789
[01:22:04.821] iteration 29126 : model1 loss : 0.440724 model2 loss : 0.015765
[01:22:04.997] iteration 29127 : model1 loss : 0.441875 model2 loss : 0.016579
[01:22:07.002] iteration 29128 : model1 loss : 0.438094 model2 loss : 0.015949
[01:22:07.174] iteration 29129 : model1 loss : 0.444567 model2 loss : 0.015963
[01:22:07.349] iteration 29130 : model1 loss : 0.439530 model2 loss : 0.015906
[01:22:07.520] iteration 29131 : model1 loss : 0.440813 model2 loss : 0.016575
[01:22:07.690] iteration 29132 : model1 loss : 0.437545 model2 loss : 0.014899
[01:22:07.859] iteration 29133 : model1 loss : 0.438342 model2 loss : 0.018115
[01:22:08.033] iteration 29134 : model1 loss : 0.441984 model2 loss : 0.015165
[01:22:08.202] iteration 29135 : model1 loss : 0.438182 model2 loss : 0.014273
[01:22:08.373] iteration 29136 : model1 loss : 0.441272 model2 loss : 0.014186
[01:22:08.544] iteration 29137 : model1 loss : 0.435671 model2 loss : 0.016291
[01:22:08.716] iteration 29138 : model1 loss : 0.441562 model2 loss : 0.015491
[01:22:08.888] iteration 29139 : model1 loss : 0.441239 model2 loss : 0.016176
[01:22:09.067] iteration 29140 : model1 loss : 0.437409 model2 loss : 0.017923
[01:22:09.243] iteration 29141 : model1 loss : 0.440573 model2 loss : 0.015102
[01:22:09.412] iteration 29142 : model1 loss : 0.439038 model2 loss : 0.016269
[01:22:09.586] iteration 29143 : model1 loss : 0.443264 model2 loss : 0.017310
[01:22:09.759] iteration 29144 : model1 loss : 0.441949 model2 loss : 0.015826
[01:22:09.933] iteration 29145 : model1 loss : 0.443317 model2 loss : 0.015847
[01:22:10.109] iteration 29146 : model1 loss : 0.440321 model2 loss : 0.016020
[01:22:10.277] iteration 29147 : model1 loss : 0.437979 model2 loss : 0.014428
[01:22:10.461] iteration 29148 : model1 loss : 0.440950 model2 loss : 0.015843
[01:22:12.675] iteration 29149 : model1 loss : 0.446032 model2 loss : 0.018174
[01:22:12.925] iteration 29150 : model1 loss : 0.442946 model2 loss : 0.018728
[01:22:13.098] iteration 29151 : model1 loss : 0.444206 model2 loss : 0.017185
[01:22:13.309] iteration 29152 : model1 loss : 0.439519 model2 loss : 0.015613
[01:22:13.481] iteration 29153 : model1 loss : 0.436222 model2 loss : 0.015695
[01:22:13.657] iteration 29154 : model1 loss : 0.438688 model2 loss : 0.016855
[01:22:13.830] iteration 29155 : model1 loss : 0.441902 model2 loss : 0.016169
[01:22:14.004] iteration 29156 : model1 loss : 0.440840 model2 loss : 0.018330
[01:22:14.175] iteration 29157 : model1 loss : 0.442765 model2 loss : 0.017302
[01:22:14.346] iteration 29158 : model1 loss : 0.436914 model2 loss : 0.014682
[01:22:14.512] iteration 29159 : model1 loss : 0.436290 model2 loss : 0.016234
[01:22:14.683] iteration 29160 : model1 loss : 0.439011 model2 loss : 0.016590
[01:22:14.852] iteration 29161 : model1 loss : 0.441697 model2 loss : 0.014853
[01:22:15.023] iteration 29162 : model1 loss : 0.441237 model2 loss : 0.015443
[01:22:15.195] iteration 29163 : model1 loss : 0.438956 model2 loss : 0.015125
[01:22:15.369] iteration 29164 : model1 loss : 0.438331 model2 loss : 0.016255
[01:22:15.537] iteration 29165 : model1 loss : 0.440484 model2 loss : 0.016989
[01:22:15.712] iteration 29166 : model1 loss : 0.444335 model2 loss : 0.016096
[01:22:15.882] iteration 29167 : model1 loss : 0.439007 model2 loss : 0.016448
[01:22:16.082] iteration 29168 : model1 loss : 0.440283 model2 loss : 0.016371
[01:22:16.301] iteration 29169 : model1 loss : 0.439663 model2 loss : 0.017412
[01:22:18.782] iteration 29170 : model1 loss : 0.442579 model2 loss : 0.015319
[01:22:18.951] iteration 29171 : model1 loss : 0.445164 model2 loss : 0.016160
[01:22:19.130] iteration 29172 : model1 loss : 0.443472 model2 loss : 0.017008
[01:22:19.311] iteration 29173 : model1 loss : 0.439473 model2 loss : 0.015580
[01:22:19.494] iteration 29174 : model1 loss : 0.438133 model2 loss : 0.017306
[01:22:19.672] iteration 29175 : model1 loss : 0.436809 model2 loss : 0.015289
[01:22:19.846] iteration 29176 : model1 loss : 0.440428 model2 loss : 0.015021
[01:22:20.022] iteration 29177 : model1 loss : 0.440779 model2 loss : 0.015155
[01:22:20.194] iteration 29178 : model1 loss : 0.438053 model2 loss : 0.015742
[01:22:20.363] iteration 29179 : model1 loss : 0.438722 model2 loss : 0.017360
[01:22:20.532] iteration 29180 : model1 loss : 0.438010 model2 loss : 0.014391
[01:22:20.700] iteration 29181 : model1 loss : 0.439547 model2 loss : 0.015215
[01:22:20.870] iteration 29182 : model1 loss : 0.440055 model2 loss : 0.015833
[01:22:21.047] iteration 29183 : model1 loss : 0.441088 model2 loss : 0.016086
[01:22:21.228] iteration 29184 : model1 loss : 0.444281 model2 loss : 0.017398
[01:22:21.407] iteration 29185 : model1 loss : 0.441404 model2 loss : 0.016836
[01:22:21.586] iteration 29186 : model1 loss : 0.444043 model2 loss : 0.016282
[01:22:21.768] iteration 29187 : model1 loss : 0.436966 model2 loss : 0.017482
[01:22:21.943] iteration 29188 : model1 loss : 0.440904 model2 loss : 0.017504
[01:22:22.111] iteration 29189 : model1 loss : 0.439498 model2 loss : 0.017789
[01:22:22.284] iteration 29190 : model1 loss : 0.437994 model2 loss : 0.017193
[01:22:24.310] iteration 29191 : model1 loss : 0.436066 model2 loss : 0.016332
[01:22:24.481] iteration 29192 : model1 loss : 0.440668 model2 loss : 0.015612
[01:22:24.659] iteration 29193 : model1 loss : 0.443291 model2 loss : 0.016515
[01:22:24.842] iteration 29194 : model1 loss : 0.446591 model2 loss : 0.019957
[01:22:25.022] iteration 29195 : model1 loss : 0.440849 model2 loss : 0.016823
[01:22:25.199] iteration 29196 : model1 loss : 0.436768 model2 loss : 0.015500
[01:22:25.379] iteration 29197 : model1 loss : 0.437224 model2 loss : 0.015122
[01:22:25.554] iteration 29198 : model1 loss : 0.438404 model2 loss : 0.014978
[01:22:25.724] iteration 29199 : model1 loss : 0.441804 model2 loss : 0.017593
[01:22:25.897] iteration 29200 : model1 loss : 0.441940 model2 loss : 0.015077
[01:22:26.086] iteration 29201 : model1 loss : 0.438929 model2 loss : 0.017598
[01:22:26.266] iteration 29202 : model1 loss : 0.439221 model2 loss : 0.015701
[01:22:26.440] iteration 29203 : model1 loss : 0.442077 model2 loss : 0.016223
[01:22:26.618] iteration 29204 : model1 loss : 0.440928 model2 loss : 0.014998
[01:22:26.795] iteration 29205 : model1 loss : 0.442008 model2 loss : 0.014886
[01:22:26.966] iteration 29206 : model1 loss : 0.435754 model2 loss : 0.017275
[01:22:27.144] iteration 29207 : model1 loss : 0.443077 model2 loss : 0.015044
[01:22:27.325] iteration 29208 : model1 loss : 0.443010 model2 loss : 0.017947
[01:22:27.509] iteration 29209 : model1 loss : 0.440015 model2 loss : 0.015349
[01:22:27.679] iteration 29210 : model1 loss : 0.439752 model2 loss : 0.014812
[01:22:27.852] iteration 29211 : model1 loss : 0.441166 model2 loss : 0.015724
[01:22:30.249] iteration 29212 : model1 loss : 0.440891 model2 loss : 0.016555
[01:22:30.424] iteration 29213 : model1 loss : 0.442057 model2 loss : 0.015918
[01:22:30.601] iteration 29214 : model1 loss : 0.442047 model2 loss : 0.015651
[01:22:30.769] iteration 29215 : model1 loss : 0.439370 model2 loss : 0.016141
[01:22:30.946] iteration 29216 : model1 loss : 0.443451 model2 loss : 0.016114
[01:22:31.122] iteration 29217 : model1 loss : 0.438044 model2 loss : 0.017083
[01:22:31.297] iteration 29218 : model1 loss : 0.440432 model2 loss : 0.014653
[01:22:31.466] iteration 29219 : model1 loss : 0.444281 model2 loss : 0.014945
[01:22:31.651] iteration 29220 : model1 loss : 0.440373 model2 loss : 0.017736
[01:22:31.833] iteration 29221 : model1 loss : 0.437193 model2 loss : 0.017043
[01:22:32.015] iteration 29222 : model1 loss : 0.439071 model2 loss : 0.017105
[01:22:32.190] iteration 29223 : model1 loss : 0.440990 model2 loss : 0.017218
[01:22:32.381] iteration 29224 : model1 loss : 0.438795 model2 loss : 0.016391
[01:22:32.556] iteration 29225 : model1 loss : 0.436731 model2 loss : 0.015332
[01:22:32.733] iteration 29226 : model1 loss : 0.439375 model2 loss : 0.015497
[01:22:32.903] iteration 29227 : model1 loss : 0.437337 model2 loss : 0.016481
[01:22:33.074] iteration 29228 : model1 loss : 0.441041 model2 loss : 0.016917
[01:22:33.244] iteration 29229 : model1 loss : 0.438772 model2 loss : 0.015236
[01:22:33.418] iteration 29230 : model1 loss : 0.443682 model2 loss : 0.017582
[01:22:33.587] iteration 29231 : model1 loss : 0.443261 model2 loss : 0.017074
[01:22:33.759] iteration 29232 : model1 loss : 0.438011 model2 loss : 0.014615
[01:22:35.804] iteration 29233 : model1 loss : 0.439173 model2 loss : 0.014492
[01:22:35.983] iteration 29234 : model1 loss : 0.444187 model2 loss : 0.015193
[01:22:36.160] iteration 29235 : model1 loss : 0.438914 model2 loss : 0.015665
[01:22:36.341] iteration 29236 : model1 loss : 0.440555 model2 loss : 0.015871
[01:22:36.520] iteration 29237 : model1 loss : 0.436675 model2 loss : 0.016354
[01:22:36.694] iteration 29238 : model1 loss : 0.441998 model2 loss : 0.016719
[01:22:36.874] iteration 29239 : model1 loss : 0.445919 model2 loss : 0.015646
[01:22:37.043] iteration 29240 : model1 loss : 0.438496 model2 loss : 0.014355
[01:22:37.213] iteration 29241 : model1 loss : 0.437181 model2 loss : 0.013612
[01:22:37.385] iteration 29242 : model1 loss : 0.443341 model2 loss : 0.016869
[01:22:37.557] iteration 29243 : model1 loss : 0.439984 model2 loss : 0.018399
[01:22:37.732] iteration 29244 : model1 loss : 0.443763 model2 loss : 0.018106
[01:22:37.912] iteration 29245 : model1 loss : 0.438331 model2 loss : 0.016891
[01:22:38.093] iteration 29246 : model1 loss : 0.438074 model2 loss : 0.015652
[01:22:38.271] iteration 29247 : model1 loss : 0.441424 model2 loss : 0.016833
[01:22:38.443] iteration 29248 : model1 loss : 0.437564 model2 loss : 0.016604
[01:22:38.616] iteration 29249 : model1 loss : 0.437590 model2 loss : 0.015225
[01:22:38.782] iteration 29250 : model1 loss : 0.438945 model2 loss : 0.016947
[01:22:38.962] iteration 29251 : model1 loss : 0.441161 model2 loss : 0.015695
[01:22:39.140] iteration 29252 : model1 loss : 0.446304 model2 loss : 0.015635
[01:22:39.332] iteration 29253 : model1 loss : 0.439236 model2 loss : 0.015544
[01:22:41.486] iteration 29254 : model1 loss : 0.439772 model2 loss : 0.018015
[01:22:41.666] iteration 29255 : model1 loss : 0.437352 model2 loss : 0.016613
[01:22:41.839] iteration 29256 : model1 loss : 0.440240 model2 loss : 0.015073
[01:22:42.016] iteration 29257 : model1 loss : 0.438984 model2 loss : 0.016512
[01:22:42.194] iteration 29258 : model1 loss : 0.439000 model2 loss : 0.015793
[01:22:42.376] iteration 29259 : model1 loss : 0.443889 model2 loss : 0.016579
[01:22:42.555] iteration 29260 : model1 loss : 0.446843 model2 loss : 0.018722
[01:22:42.730] iteration 29261 : model1 loss : 0.437744 model2 loss : 0.015415
[01:22:42.901] iteration 29262 : model1 loss : 0.439270 model2 loss : 0.015563
[01:22:43.069] iteration 29263 : model1 loss : 0.436184 model2 loss : 0.014860
[01:22:43.252] iteration 29264 : model1 loss : 0.441557 model2 loss : 0.016340
[01:22:43.431] iteration 29265 : model1 loss : 0.438456 model2 loss : 0.017246
[01:22:43.612] iteration 29266 : model1 loss : 0.444921 model2 loss : 0.016746
[01:22:43.788] iteration 29267 : model1 loss : 0.437444 model2 loss : 0.015761
[01:22:43.970] iteration 29268 : model1 loss : 0.443539 model2 loss : 0.018915
[01:22:44.149] iteration 29269 : model1 loss : 0.440651 model2 loss : 0.015903
[01:22:44.330] iteration 29270 : model1 loss : 0.442074 model2 loss : 0.017727
[01:22:44.498] iteration 29271 : model1 loss : 0.443637 model2 loss : 0.016331
[01:22:44.670] iteration 29272 : model1 loss : 0.439588 model2 loss : 0.013886
[01:22:44.840] iteration 29273 : model1 loss : 0.437798 model2 loss : 0.015238
[01:22:45.022] iteration 29274 : model1 loss : 0.441596 model2 loss : 0.017603
[01:22:47.120] iteration 29275 : model1 loss : 0.439426 model2 loss : 0.014047
[01:22:47.303] iteration 29276 : model1 loss : 0.441467 model2 loss : 0.018001
[01:22:47.487] iteration 29277 : model1 loss : 0.441244 model2 loss : 0.017002
[01:22:47.662] iteration 29278 : model1 loss : 0.440142 model2 loss : 0.015460
[01:22:47.836] iteration 29279 : model1 loss : 0.438753 model2 loss : 0.015322
[01:22:48.020] iteration 29280 : model1 loss : 0.441909 model2 loss : 0.017379
[01:22:48.192] iteration 29281 : model1 loss : 0.438987 model2 loss : 0.015482
[01:22:48.367] iteration 29282 : model1 loss : 0.445629 model2 loss : 0.018742
[01:22:48.537] iteration 29283 : model1 loss : 0.436220 model2 loss : 0.013968
[01:22:48.709] iteration 29284 : model1 loss : 0.443003 model2 loss : 0.015739
[01:22:48.899] iteration 29285 : model1 loss : 0.438811 model2 loss : 0.015301
[01:22:49.084] iteration 29286 : model1 loss : 0.440260 model2 loss : 0.018039
[01:22:49.261] iteration 29287 : model1 loss : 0.438870 model2 loss : 0.016993
[01:22:49.433] iteration 29288 : model1 loss : 0.439417 model2 loss : 0.016397
[01:22:49.607] iteration 29289 : model1 loss : 0.442550 model2 loss : 0.015909
[01:22:49.779] iteration 29290 : model1 loss : 0.439200 model2 loss : 0.017246
[01:22:49.948] iteration 29291 : model1 loss : 0.441235 model2 loss : 0.016909
[01:22:50.119] iteration 29292 : model1 loss : 0.444680 model2 loss : 0.017439
[01:22:50.293] iteration 29293 : model1 loss : 0.437450 model2 loss : 0.015377
[01:22:50.459] iteration 29294 : model1 loss : 0.437760 model2 loss : 0.016383
[01:22:50.638] iteration 29295 : model1 loss : 0.439665 model2 loss : 0.016215
[01:22:52.749] iteration 29296 : model1 loss : 0.444414 model2 loss : 0.017489
[01:22:52.925] iteration 29297 : model1 loss : 0.440978 model2 loss : 0.016504
[01:22:53.128] iteration 29298 : model1 loss : 0.443770 model2 loss : 0.017191
[01:22:53.302] iteration 29299 : model1 loss : 0.440059 model2 loss : 0.018156
[01:22:53.477] iteration 29300 : model1 loss : 0.438420 model2 loss : 0.015044
[01:22:53.645] iteration 29301 : model1 loss : 0.442560 model2 loss : 0.015601
[01:22:53.821] iteration 29302 : model1 loss : 0.437767 model2 loss : 0.015826
[01:22:54.010] iteration 29303 : model1 loss : 0.437189 model2 loss : 0.015593
[01:22:54.191] iteration 29304 : model1 loss : 0.437661 model2 loss : 0.015089
[01:22:54.369] iteration 29305 : model1 loss : 0.443882 model2 loss : 0.014587
[01:22:54.550] iteration 29306 : model1 loss : 0.436709 model2 loss : 0.014666
[01:22:54.722] iteration 29307 : model1 loss : 0.434869 model2 loss : 0.015933
[01:22:54.902] iteration 29308 : model1 loss : 0.439304 model2 loss : 0.016541
[01:22:55.071] iteration 29309 : model1 loss : 0.442240 model2 loss : 0.015970
[01:22:55.246] iteration 29310 : model1 loss : 0.436798 model2 loss : 0.014341
[01:22:55.419] iteration 29311 : model1 loss : 0.438979 model2 loss : 0.017562
[01:22:55.596] iteration 29312 : model1 loss : 0.444136 model2 loss : 0.019139
[01:22:55.764] iteration 29313 : model1 loss : 0.446776 model2 loss : 0.017178
[01:22:55.942] iteration 29314 : model1 loss : 0.441112 model2 loss : 0.017483
[01:22:56.115] iteration 29315 : model1 loss : 0.439414 model2 loss : 0.016716
[01:22:56.293] iteration 29316 : model1 loss : 0.444560 model2 loss : 0.017563
[01:22:58.467] iteration 29317 : model1 loss : 0.442415 model2 loss : 0.016531
[01:22:58.637] iteration 29318 : model1 loss : 0.443081 model2 loss : 0.015246
[01:22:58.812] iteration 29319 : model1 loss : 0.437998 model2 loss : 0.016811
[01:22:58.979] iteration 29320 : model1 loss : 0.435275 model2 loss : 0.016061
[01:22:59.150] iteration 29321 : model1 loss : 0.439328 model2 loss : 0.016659
[01:22:59.323] iteration 29322 : model1 loss : 0.442993 model2 loss : 0.018095
[01:22:59.494] iteration 29323 : model1 loss : 0.440329 model2 loss : 0.015557
[01:22:59.684] iteration 29324 : model1 loss : 0.434594 model2 loss : 0.016591
[01:22:59.860] iteration 29325 : model1 loss : 0.444677 model2 loss : 0.017208
[01:23:00.040] iteration 29326 : model1 loss : 0.443404 model2 loss : 0.018155
[01:23:00.220] iteration 29327 : model1 loss : 0.442201 model2 loss : 0.014669
[01:23:00.425] iteration 29328 : model1 loss : 0.439581 model2 loss : 0.015373
[01:23:00.597] iteration 29329 : model1 loss : 0.441017 model2 loss : 0.013640
[01:23:00.769] iteration 29330 : model1 loss : 0.441191 model2 loss : 0.014185
[01:23:00.951] iteration 29331 : model1 loss : 0.438689 model2 loss : 0.014639
[01:23:01.122] iteration 29332 : model1 loss : 0.439778 model2 loss : 0.014978
[01:23:01.306] iteration 29333 : model1 loss : 0.439573 model2 loss : 0.016314
[01:23:01.486] iteration 29334 : model1 loss : 0.443104 model2 loss : 0.014775
[01:23:01.670] iteration 29335 : model1 loss : 0.439982 model2 loss : 0.015434
[01:23:01.864] iteration 29336 : model1 loss : 0.436841 model2 loss : 0.017262
[01:23:02.060] iteration 29337 : model1 loss : 0.439502 model2 loss : 0.015741
[01:23:04.289] iteration 29338 : model1 loss : 0.439610 model2 loss : 0.014892
[01:23:04.463] iteration 29339 : model1 loss : 0.437407 model2 loss : 0.019001
[01:23:04.638] iteration 29340 : model1 loss : 0.439421 model2 loss : 0.015532
[01:23:04.808] iteration 29341 : model1 loss : 0.439007 model2 loss : 0.015467
[01:23:04.990] iteration 29342 : model1 loss : 0.443151 model2 loss : 0.016698
[01:23:05.172] iteration 29343 : model1 loss : 0.437848 model2 loss : 0.015892
[01:23:05.349] iteration 29344 : model1 loss : 0.437845 model2 loss : 0.016242
[01:23:05.518] iteration 29345 : model1 loss : 0.443132 model2 loss : 0.016900
[01:23:05.687] iteration 29346 : model1 loss : 0.441713 model2 loss : 0.017904
[01:23:05.858] iteration 29347 : model1 loss : 0.434902 model2 loss : 0.015852
[01:23:06.031] iteration 29348 : model1 loss : 0.439656 model2 loss : 0.014321
[01:23:06.198] iteration 29349 : model1 loss : 0.443701 model2 loss : 0.017505
[01:23:06.371] iteration 29350 : model1 loss : 0.443977 model2 loss : 0.017062
[01:23:06.542] iteration 29351 : model1 loss : 0.441427 model2 loss : 0.016476
[01:23:06.713] iteration 29352 : model1 loss : 0.442071 model2 loss : 0.015252
[01:23:06.882] iteration 29353 : model1 loss : 0.439800 model2 loss : 0.017431
[01:23:07.058] iteration 29354 : model1 loss : 0.437376 model2 loss : 0.016146
[01:23:07.225] iteration 29355 : model1 loss : 0.436889 model2 loss : 0.015815
[01:23:07.394] iteration 29356 : model1 loss : 0.445755 model2 loss : 0.016815
[01:23:07.564] iteration 29357 : model1 loss : 0.441632 model2 loss : 0.015343
[01:23:07.731] iteration 29358 : model1 loss : 0.439074 model2 loss : 0.014946
[01:23:09.716] iteration 29359 : model1 loss : 0.447120 model2 loss : 0.018627
[01:23:09.886] iteration 29360 : model1 loss : 0.442229 model2 loss : 0.015464
[01:23:10.063] iteration 29361 : model1 loss : 0.438852 model2 loss : 0.014415
[01:23:10.234] iteration 29362 : model1 loss : 0.437799 model2 loss : 0.015127
[01:23:10.405] iteration 29363 : model1 loss : 0.437803 model2 loss : 0.016436
[01:23:10.572] iteration 29364 : model1 loss : 0.441006 model2 loss : 0.016660
[01:23:10.743] iteration 29365 : model1 loss : 0.439998 model2 loss : 0.016108
[01:23:10.914] iteration 29366 : model1 loss : 0.437183 model2 loss : 0.015244
[01:23:11.085] iteration 29367 : model1 loss : 0.437005 model2 loss : 0.016119
[01:23:11.253] iteration 29368 : model1 loss : 0.442385 model2 loss : 0.016939
[01:23:11.429] iteration 29369 : model1 loss : 0.439542 model2 loss : 0.017933
[01:23:11.597] iteration 29370 : model1 loss : 0.436143 model2 loss : 0.017509
[01:23:11.772] iteration 29371 : model1 loss : 0.437911 model2 loss : 0.016195
[01:23:11.942] iteration 29372 : model1 loss : 0.442131 model2 loss : 0.014736
[01:23:12.116] iteration 29373 : model1 loss : 0.441450 model2 loss : 0.016189
[01:23:12.284] iteration 29374 : model1 loss : 0.443105 model2 loss : 0.016634
[01:23:12.461] iteration 29375 : model1 loss : 0.440349 model2 loss : 0.017908
[01:23:12.628] iteration 29376 : model1 loss : 0.439109 model2 loss : 0.015610
[01:23:12.797] iteration 29377 : model1 loss : 0.440258 model2 loss : 0.015241
[01:23:12.967] iteration 29378 : model1 loss : 0.441622 model2 loss : 0.017253
[01:23:13.142] iteration 29379 : model1 loss : 0.440440 model2 loss : 0.015950
[01:23:15.128] iteration 29380 : model1 loss : 0.440966 model2 loss : 0.015950
[01:23:15.302] iteration 29381 : model1 loss : 0.445094 model2 loss : 0.017099
[01:23:15.474] iteration 29382 : model1 loss : 0.438307 model2 loss : 0.015621
[01:23:15.642] iteration 29383 : model1 loss : 0.438948 model2 loss : 0.016417
[01:23:15.814] iteration 29384 : model1 loss : 0.441700 model2 loss : 0.015202
[01:23:15.983] iteration 29385 : model1 loss : 0.442740 model2 loss : 0.016832
[01:23:16.156] iteration 29386 : model1 loss : 0.439842 model2 loss : 0.014850
[01:23:16.332] iteration 29387 : model1 loss : 0.443103 model2 loss : 0.015961
[01:23:16.503] iteration 29388 : model1 loss : 0.441160 model2 loss : 0.017091
[01:23:16.671] iteration 29389 : model1 loss : 0.437677 model2 loss : 0.015124
[01:23:16.844] iteration 29390 : model1 loss : 0.440618 model2 loss : 0.016504
[01:23:17.012] iteration 29391 : model1 loss : 0.437831 model2 loss : 0.015101
[01:23:17.183] iteration 29392 : model1 loss : 0.439567 model2 loss : 0.013997
[01:23:17.357] iteration 29393 : model1 loss : 0.436085 model2 loss : 0.016117
[01:23:17.530] iteration 29394 : model1 loss : 0.445957 model2 loss : 0.017391
[01:23:17.697] iteration 29395 : model1 loss : 0.441031 model2 loss : 0.017061
[01:23:17.876] iteration 29396 : model1 loss : 0.439931 model2 loss : 0.016965
[01:23:18.052] iteration 29397 : model1 loss : 0.439525 model2 loss : 0.017039
[01:23:18.234] iteration 29398 : model1 loss : 0.435012 model2 loss : 0.014217
[01:23:18.421] iteration 29399 : model1 loss : 0.437711 model2 loss : 0.015492
[01:23:18.612] iteration 29400 : model1 loss : 0.442376 model2 loss : 0.016658
[01:23:20.920] iteration 29401 : model1 loss : 0.439851 model2 loss : 0.016195
[01:23:21.164] iteration 29402 : model1 loss : 0.438709 model2 loss : 0.013647
[01:23:21.404] iteration 29403 : model1 loss : 0.439169 model2 loss : 0.017944
[01:23:21.636] iteration 29404 : model1 loss : 0.441815 model2 loss : 0.016023
[01:23:21.877] iteration 29405 : model1 loss : 0.439503 model2 loss : 0.015241
[01:23:22.114] iteration 29406 : model1 loss : 0.441704 model2 loss : 0.016238
[01:23:22.352] iteration 29407 : model1 loss : 0.437758 model2 loss : 0.016107
[01:23:22.587] iteration 29408 : model1 loss : 0.438483 model2 loss : 0.017567
[01:23:22.820] iteration 29409 : model1 loss : 0.436750 model2 loss : 0.015241
[01:23:23.054] iteration 29410 : model1 loss : 0.441754 model2 loss : 0.017631
[01:23:23.288] iteration 29411 : model1 loss : 0.445957 model2 loss : 0.016705
[01:23:23.523] iteration 29412 : model1 loss : 0.441141 model2 loss : 0.016056
[01:23:23.758] iteration 29413 : model1 loss : 0.436693 model2 loss : 0.016625
[01:23:23.992] iteration 29414 : model1 loss : 0.442162 model2 loss : 0.015823
[01:23:24.224] iteration 29415 : model1 loss : 0.441445 model2 loss : 0.016791
[01:23:24.459] iteration 29416 : model1 loss : 0.441239 model2 loss : 0.016781
[01:23:24.694] iteration 29417 : model1 loss : 0.439965 model2 loss : 0.016684
[01:23:24.926] iteration 29418 : model1 loss : 0.441578 model2 loss : 0.015256
[01:23:25.159] iteration 29419 : model1 loss : 0.437964 model2 loss : 0.018566
[01:23:25.394] iteration 29420 : model1 loss : 0.438372 model2 loss : 0.013922
[01:23:25.626] iteration 29421 : model1 loss : 0.437454 model2 loss : 0.014326
[01:23:27.952] iteration 29422 : model1 loss : 0.439501 model2 loss : 0.015922
[01:23:28.185] iteration 29423 : model1 loss : 0.439425 model2 loss : 0.016431
[01:23:28.424] iteration 29424 : model1 loss : 0.436814 model2 loss : 0.014950
[01:23:28.655] iteration 29425 : model1 loss : 0.445574 model2 loss : 0.017450
[01:23:28.892] iteration 29426 : model1 loss : 0.441034 model2 loss : 0.015351
[01:23:29.127] iteration 29427 : model1 loss : 0.437562 model2 loss : 0.016451
[01:23:29.363] iteration 29428 : model1 loss : 0.437559 model2 loss : 0.015653
[01:23:29.597] iteration 29429 : model1 loss : 0.435844 model2 loss : 0.016495
[01:23:29.829] iteration 29430 : model1 loss : 0.438353 model2 loss : 0.014588
[01:23:30.065] iteration 29431 : model1 loss : 0.441226 model2 loss : 0.015820
[01:23:30.299] iteration 29432 : model1 loss : 0.443379 model2 loss : 0.015931
[01:23:30.530] iteration 29433 : model1 loss : 0.437144 model2 loss : 0.014766
[01:23:30.764] iteration 29434 : model1 loss : 0.439075 model2 loss : 0.015099
[01:23:30.996] iteration 29435 : model1 loss : 0.442903 model2 loss : 0.016573
[01:23:31.231] iteration 29436 : model1 loss : 0.445438 model2 loss : 0.017113
[01:23:31.461] iteration 29437 : model1 loss : 0.441486 model2 loss : 0.015878
[01:23:31.697] iteration 29438 : model1 loss : 0.439646 model2 loss : 0.016336
[01:23:31.930] iteration 29439 : model1 loss : 0.440020 model2 loss : 0.015990
[01:23:32.163] iteration 29440 : model1 loss : 0.438492 model2 loss : 0.016153
[01:23:32.397] iteration 29441 : model1 loss : 0.441238 model2 loss : 0.017519
[01:23:32.627] iteration 29442 : model1 loss : 0.441367 model2 loss : 0.016116
[01:23:34.921] iteration 29443 : model1 loss : 0.442774 model2 loss : 0.016162
[01:23:35.153] iteration 29444 : model1 loss : 0.438543 model2 loss : 0.014495
[01:23:35.392] iteration 29445 : model1 loss : 0.438266 model2 loss : 0.016551
[01:23:35.627] iteration 29446 : model1 loss : 0.436531 model2 loss : 0.014722
[01:23:35.860] iteration 29447 : model1 loss : 0.444211 model2 loss : 0.016957
[01:23:36.094] iteration 29448 : model1 loss : 0.440760 model2 loss : 0.014645
[01:23:36.324] iteration 29449 : model1 loss : 0.442354 model2 loss : 0.017079
[01:23:36.558] iteration 29450 : model1 loss : 0.437942 model2 loss : 0.014718
[01:23:36.794] iteration 29451 : model1 loss : 0.437866 model2 loss : 0.017473
[01:23:37.028] iteration 29452 : model1 loss : 0.440904 model2 loss : 0.015859
[01:23:37.261] iteration 29453 : model1 loss : 0.439240 model2 loss : 0.016690
[01:23:37.497] iteration 29454 : model1 loss : 0.441152 model2 loss : 0.014760
[01:23:37.729] iteration 29455 : model1 loss : 0.437622 model2 loss : 0.014534
[01:23:37.960] iteration 29456 : model1 loss : 0.442062 model2 loss : 0.017302
[01:23:38.197] iteration 29457 : model1 loss : 0.438239 model2 loss : 0.016011
[01:23:38.427] iteration 29458 : model1 loss : 0.439192 model2 loss : 0.017004
[01:23:38.656] iteration 29459 : model1 loss : 0.440406 model2 loss : 0.016754
[01:23:38.887] iteration 29460 : model1 loss : 0.439094 model2 loss : 0.015703
[01:23:39.120] iteration 29461 : model1 loss : 0.441408 model2 loss : 0.014174
[01:23:39.356] iteration 29462 : model1 loss : 0.442591 model2 loss : 0.017035
[01:23:39.585] iteration 29463 : model1 loss : 0.443143 model2 loss : 0.017082
[01:23:41.882] iteration 29464 : model1 loss : 0.440184 model2 loss : 0.017631
[01:23:42.118] iteration 29465 : model1 loss : 0.439694 model2 loss : 0.015551
[01:23:42.360] iteration 29466 : model1 loss : 0.436257 model2 loss : 0.016144
[01:23:42.594] iteration 29467 : model1 loss : 0.442881 model2 loss : 0.016229
[01:23:42.828] iteration 29468 : model1 loss : 0.437954 model2 loss : 0.014640
[01:23:43.059] iteration 29469 : model1 loss : 0.440193 model2 loss : 0.015649
[01:23:43.293] iteration 29470 : model1 loss : 0.445631 model2 loss : 0.017946
[01:23:43.532] iteration 29471 : model1 loss : 0.443448 model2 loss : 0.018026
[01:23:43.773] iteration 29472 : model1 loss : 0.440661 model2 loss : 0.016279
[01:23:44.002] iteration 29473 : model1 loss : 0.441904 model2 loss : 0.014142
[01:23:44.232] iteration 29474 : model1 loss : 0.441457 model2 loss : 0.016998
[01:23:44.466] iteration 29475 : model1 loss : 0.444256 model2 loss : 0.017023
[01:23:44.698] iteration 29476 : model1 loss : 0.442419 model2 loss : 0.015405
[01:23:44.926] iteration 29477 : model1 loss : 0.441587 model2 loss : 0.015934
[01:23:45.161] iteration 29478 : model1 loss : 0.438588 model2 loss : 0.015523
[01:23:45.398] iteration 29479 : model1 loss : 0.438549 model2 loss : 0.015293
[01:23:45.633] iteration 29480 : model1 loss : 0.443717 model2 loss : 0.017618
[01:23:45.866] iteration 29481 : model1 loss : 0.436220 model2 loss : 0.015711
[01:23:46.099] iteration 29482 : model1 loss : 0.437922 model2 loss : 0.016708
[01:23:46.338] iteration 29483 : model1 loss : 0.438821 model2 loss : 0.016672
[01:23:46.570] iteration 29484 : model1 loss : 0.435324 model2 loss : 0.015818
[01:23:48.904] iteration 29485 : model1 loss : 0.437022 model2 loss : 0.017536
[01:23:49.140] iteration 29486 : model1 loss : 0.441038 model2 loss : 0.014861
[01:23:49.378] iteration 29487 : model1 loss : 0.439269 model2 loss : 0.015843
[01:23:49.610] iteration 29488 : model1 loss : 0.440212 model2 loss : 0.015006
[01:23:49.844] iteration 29489 : model1 loss : 0.442093 model2 loss : 0.014995
[01:23:50.076] iteration 29490 : model1 loss : 0.441613 model2 loss : 0.016167
[01:23:50.303] iteration 29491 : model1 loss : 0.446111 model2 loss : 0.018584
[01:23:50.530] iteration 29492 : model1 loss : 0.437459 model2 loss : 0.014125
[01:23:50.767] iteration 29493 : model1 loss : 0.440308 model2 loss : 0.016079
[01:23:51.002] iteration 29494 : model1 loss : 0.435309 model2 loss : 0.015509
[01:23:51.235] iteration 29495 : model1 loss : 0.442057 model2 loss : 0.015125
[01:23:51.467] iteration 29496 : model1 loss : 0.438892 model2 loss : 0.017209
[01:23:51.702] iteration 29497 : model1 loss : 0.439489 model2 loss : 0.015148
[01:23:51.933] iteration 29498 : model1 loss : 0.434436 model2 loss : 0.015914
[01:23:52.168] iteration 29499 : model1 loss : 0.441472 model2 loss : 0.015693
[01:23:52.399] iteration 29500 : model1 loss : 0.440078 model2 loss : 0.015444
[01:23:52.633] iteration 29501 : model1 loss : 0.442059 model2 loss : 0.016343
[01:23:52.868] iteration 29502 : model1 loss : 0.442094 model2 loss : 0.015457
[01:23:53.102] iteration 29503 : model1 loss : 0.444059 model2 loss : 0.016882
[01:23:53.336] iteration 29504 : model1 loss : 0.442037 model2 loss : 0.015754
[01:23:53.567] iteration 29505 : model1 loss : 0.437518 model2 loss : 0.014945
[01:23:55.857] iteration 29506 : model1 loss : 0.439632 model2 loss : 0.016120
[01:23:56.090] iteration 29507 : model1 loss : 0.438203 model2 loss : 0.015545
[01:23:56.322] iteration 29508 : model1 loss : 0.438154 model2 loss : 0.015461
[01:23:56.560] iteration 29509 : model1 loss : 0.443836 model2 loss : 0.015927
[01:23:56.787] iteration 29510 : model1 loss : 0.440184 model2 loss : 0.013639
[01:23:57.019] iteration 29511 : model1 loss : 0.442418 model2 loss : 0.016382
[01:23:57.252] iteration 29512 : model1 loss : 0.441369 model2 loss : 0.018306
[01:23:57.490] iteration 29513 : model1 loss : 0.436162 model2 loss : 0.014818
[01:23:57.726] iteration 29514 : model1 loss : 0.441003 model2 loss : 0.016106
[01:23:57.960] iteration 29515 : model1 loss : 0.443291 model2 loss : 0.017208
[01:23:58.197] iteration 29516 : model1 loss : 0.439472 model2 loss : 0.017381
[01:23:58.431] iteration 29517 : model1 loss : 0.442036 model2 loss : 0.018149
[01:23:58.667] iteration 29518 : model1 loss : 0.438059 model2 loss : 0.016458
[01:23:58.898] iteration 29519 : model1 loss : 0.438573 model2 loss : 0.013240
[01:23:59.132] iteration 29520 : model1 loss : 0.444000 model2 loss : 0.016351
[01:23:59.370] iteration 29521 : model1 loss : 0.438245 model2 loss : 0.015647
[01:23:59.603] iteration 29522 : model1 loss : 0.442193 model2 loss : 0.015942
[01:23:59.835] iteration 29523 : model1 loss : 0.439690 model2 loss : 0.016503
[01:24:00.065] iteration 29524 : model1 loss : 0.440884 model2 loss : 0.016672
[01:24:00.296] iteration 29525 : model1 loss : 0.438888 model2 loss : 0.014931
[01:24:00.529] iteration 29526 : model1 loss : 0.438571 model2 loss : 0.015661
[01:24:02.849] iteration 29527 : model1 loss : 0.439266 model2 loss : 0.016567
[01:24:03.084] iteration 29528 : model1 loss : 0.436849 model2 loss : 0.015702
[01:24:03.319] iteration 29529 : model1 loss : 0.441970 model2 loss : 0.016411
[01:24:03.551] iteration 29530 : model1 loss : 0.440251 model2 loss : 0.015106
[01:24:03.780] iteration 29531 : model1 loss : 0.448407 model2 loss : 0.018266
[01:24:04.018] iteration 29532 : model1 loss : 0.440043 model2 loss : 0.017434
[01:24:04.253] iteration 29533 : model1 loss : 0.440737 model2 loss : 0.017726
[01:24:04.486] iteration 29534 : model1 loss : 0.442951 model2 loss : 0.016727
[01:24:04.720] iteration 29535 : model1 loss : 0.440415 model2 loss : 0.016452
[01:24:04.951] iteration 29536 : model1 loss : 0.437531 model2 loss : 0.014881
[01:24:05.190] iteration 29537 : model1 loss : 0.443027 model2 loss : 0.017905
[01:24:05.420] iteration 29538 : model1 loss : 0.437928 model2 loss : 0.016634
[01:24:05.655] iteration 29539 : model1 loss : 0.440061 model2 loss : 0.016623
[01:24:05.889] iteration 29540 : model1 loss : 0.440719 model2 loss : 0.015997
[01:24:06.121] iteration 29541 : model1 loss : 0.442122 model2 loss : 0.016107
[01:24:06.358] iteration 29542 : model1 loss : 0.437270 model2 loss : 0.013750
[01:24:06.593] iteration 29543 : model1 loss : 0.439462 model2 loss : 0.016728
[01:24:06.823] iteration 29544 : model1 loss : 0.439540 model2 loss : 0.015963
[01:24:07.056] iteration 29545 : model1 loss : 0.432445 model2 loss : 0.014300
[01:24:07.288] iteration 29546 : model1 loss : 0.441283 model2 loss : 0.016026
[01:24:07.528] iteration 29547 : model1 loss : 0.446229 model2 loss : 0.019296
[01:24:09.831] iteration 29548 : model1 loss : 0.436938 model2 loss : 0.015634
[01:24:10.062] iteration 29549 : model1 loss : 0.439699 model2 loss : 0.016135
[01:24:10.293] iteration 29550 : model1 loss : 0.441950 model2 loss : 0.016440
[01:24:10.526] iteration 29551 : model1 loss : 0.437092 model2 loss : 0.015470
[01:24:10.759] iteration 29552 : model1 loss : 0.438112 model2 loss : 0.013840
[01:24:10.991] iteration 29553 : model1 loss : 0.441173 model2 loss : 0.016917
[01:24:11.225] iteration 29554 : model1 loss : 0.441397 model2 loss : 0.015799
[01:24:11.462] iteration 29555 : model1 loss : 0.444244 model2 loss : 0.018384
[01:24:11.696] iteration 29556 : model1 loss : 0.440129 model2 loss : 0.018275
[01:24:11.931] iteration 29557 : model1 loss : 0.439826 model2 loss : 0.014974
[01:24:12.167] iteration 29558 : model1 loss : 0.438439 model2 loss : 0.014675
[01:24:12.403] iteration 29559 : model1 loss : 0.438084 model2 loss : 0.016023
[01:24:12.634] iteration 29560 : model1 loss : 0.444045 model2 loss : 0.015483
[01:24:12.866] iteration 29561 : model1 loss : 0.440876 model2 loss : 0.018544
[01:24:13.100] iteration 29562 : model1 loss : 0.436450 model2 loss : 0.015471
[01:24:13.332] iteration 29563 : model1 loss : 0.439493 model2 loss : 0.015117
[01:24:13.565] iteration 29564 : model1 loss : 0.438256 model2 loss : 0.016330
[01:24:13.800] iteration 29565 : model1 loss : 0.439705 model2 loss : 0.014640
[01:24:14.032] iteration 29566 : model1 loss : 0.439531 model2 loss : 0.014421
[01:24:14.265] iteration 29567 : model1 loss : 0.441041 model2 loss : 0.016266
[01:24:14.496] iteration 29568 : model1 loss : 0.444841 model2 loss : 0.018500
[01:24:16.803] iteration 29569 : model1 loss : 0.439385 model2 loss : 0.015552
[01:24:17.036] iteration 29570 : model1 loss : 0.440251 model2 loss : 0.016473
[01:24:17.271] iteration 29571 : model1 loss : 0.442989 model2 loss : 0.016885
[01:24:17.508] iteration 29572 : model1 loss : 0.439777 model2 loss : 0.016372
[01:24:17.741] iteration 29573 : model1 loss : 0.440166 model2 loss : 0.015299
[01:24:17.971] iteration 29574 : model1 loss : 0.437444 model2 loss : 0.015397
[01:24:18.211] iteration 29575 : model1 loss : 0.441961 model2 loss : 0.014286
[01:24:18.442] iteration 29576 : model1 loss : 0.441427 model2 loss : 0.016275
[01:24:18.683] iteration 29577 : model1 loss : 0.439921 model2 loss : 0.016102
[01:24:18.917] iteration 29578 : model1 loss : 0.442628 model2 loss : 0.016508
[01:24:19.150] iteration 29579 : model1 loss : 0.440576 model2 loss : 0.016019
[01:24:19.386] iteration 29580 : model1 loss : 0.438037 model2 loss : 0.015620
[01:24:19.619] iteration 29581 : model1 loss : 0.438943 model2 loss : 0.015527
[01:24:19.852] iteration 29582 : model1 loss : 0.439395 model2 loss : 0.016961
[01:24:20.083] iteration 29583 : model1 loss : 0.436066 model2 loss : 0.014485
[01:24:20.316] iteration 29584 : model1 loss : 0.443350 model2 loss : 0.016684
[01:24:20.551] iteration 29585 : model1 loss : 0.440958 model2 loss : 0.016661
[01:24:20.785] iteration 29586 : model1 loss : 0.439758 model2 loss : 0.015394
[01:24:21.019] iteration 29587 : model1 loss : 0.436283 model2 loss : 0.015004
[01:24:21.254] iteration 29588 : model1 loss : 0.441661 model2 loss : 0.019569
[01:24:21.487] iteration 29589 : model1 loss : 0.442520 model2 loss : 0.015651
[01:24:23.783] iteration 29590 : model1 loss : 0.437520 model2 loss : 0.014872
[01:24:24.017] iteration 29591 : model1 loss : 0.438683 model2 loss : 0.016833
[01:24:24.247] iteration 29592 : model1 loss : 0.442212 model2 loss : 0.016047
[01:24:24.483] iteration 29593 : model1 loss : 0.441430 model2 loss : 0.017904
[01:24:24.716] iteration 29594 : model1 loss : 0.442010 model2 loss : 0.016334
[01:24:24.950] iteration 29595 : model1 loss : 0.439458 model2 loss : 0.014854
[01:24:25.182] iteration 29596 : model1 loss : 0.438854 model2 loss : 0.015474
[01:24:25.421] iteration 29597 : model1 loss : 0.448048 model2 loss : 0.020584
[01:24:25.658] iteration 29598 : model1 loss : 0.444530 model2 loss : 0.017131
[01:24:25.885] iteration 29599 : model1 loss : 0.433056 model2 loss : 0.016926
[01:24:26.117] iteration 29600 : model1 loss : 0.435200 model2 loss : 0.015805
[01:24:26.359] iteration 29601 : model1 loss : 0.440561 model2 loss : 0.016259
[01:24:26.585] iteration 29602 : model1 loss : 0.436553 model2 loss : 0.015617
[01:24:26.817] iteration 29603 : model1 loss : 0.439376 model2 loss : 0.015376
[01:24:27.052] iteration 29604 : model1 loss : 0.440447 model2 loss : 0.017971
[01:24:27.289] iteration 29605 : model1 loss : 0.444044 model2 loss : 0.017386
[01:24:27.526] iteration 29606 : model1 loss : 0.438424 model2 loss : 0.015728
[01:24:27.759] iteration 29607 : model1 loss : 0.440956 model2 loss : 0.015166
[01:24:27.996] iteration 29608 : model1 loss : 0.444125 model2 loss : 0.017406
[01:24:28.231] iteration 29609 : model1 loss : 0.437306 model2 loss : 0.014424
[01:24:28.461] iteration 29610 : model1 loss : 0.443324 model2 loss : 0.016002
[01:24:30.753] iteration 29611 : model1 loss : 0.440566 model2 loss : 0.017791
[01:24:30.984] iteration 29612 : model1 loss : 0.439565 model2 loss : 0.014841
[01:24:31.219] iteration 29613 : model1 loss : 0.440847 model2 loss : 0.014520
[01:24:31.454] iteration 29614 : model1 loss : 0.439132 model2 loss : 0.014456
[01:24:31.683] iteration 29615 : model1 loss : 0.439537 model2 loss : 0.016469
[01:24:31.916] iteration 29616 : model1 loss : 0.446594 model2 loss : 0.018629
[01:24:32.149] iteration 29617 : model1 loss : 0.438972 model2 loss : 0.016288
[01:24:32.386] iteration 29618 : model1 loss : 0.439856 model2 loss : 0.015185
[01:24:32.617] iteration 29619 : model1 loss : 0.437266 model2 loss : 0.015727
[01:24:32.850] iteration 29620 : model1 loss : 0.436557 model2 loss : 0.015142
[01:24:33.086] iteration 29621 : model1 loss : 0.436421 model2 loss : 0.014978
[01:24:33.319] iteration 29622 : model1 loss : 0.443969 model2 loss : 0.015328
[01:24:33.549] iteration 29623 : model1 loss : 0.440866 model2 loss : 0.017791
[01:24:33.780] iteration 29624 : model1 loss : 0.440867 model2 loss : 0.017921
[01:24:34.013] iteration 29625 : model1 loss : 0.440711 model2 loss : 0.016174
[01:24:34.253] iteration 29626 : model1 loss : 0.437731 model2 loss : 0.014957
[01:24:34.488] iteration 29627 : model1 loss : 0.442174 model2 loss : 0.019569
[01:24:34.724] iteration 29628 : model1 loss : 0.442044 model2 loss : 0.014269
[01:24:34.955] iteration 29629 : model1 loss : 0.441275 model2 loss : 0.017375
[01:24:35.192] iteration 29630 : model1 loss : 0.436859 model2 loss : 0.016266
[01:24:35.419] iteration 29631 : model1 loss : 0.443728 model2 loss : 0.015807
[01:24:37.735] iteration 29632 : model1 loss : 0.445225 model2 loss : 0.018834
[01:24:37.967] iteration 29633 : model1 loss : 0.437158 model2 loss : 0.015725
[01:24:38.207] iteration 29634 : model1 loss : 0.444966 model2 loss : 0.016310
[01:24:38.437] iteration 29635 : model1 loss : 0.439307 model2 loss : 0.015013
[01:24:38.669] iteration 29636 : model1 loss : 0.438743 model2 loss : 0.016158
[01:24:38.906] iteration 29637 : model1 loss : 0.439074 model2 loss : 0.016114
[01:24:39.141] iteration 29638 : model1 loss : 0.439499 model2 loss : 0.016087
[01:24:39.381] iteration 29639 : model1 loss : 0.438379 model2 loss : 0.016694
[01:24:39.617] iteration 29640 : model1 loss : 0.440306 model2 loss : 0.014840
[01:24:39.849] iteration 29641 : model1 loss : 0.441990 model2 loss : 0.014163
[01:24:40.079] iteration 29642 : model1 loss : 0.441832 model2 loss : 0.016082
[01:24:40.314] iteration 29643 : model1 loss : 0.441426 model2 loss : 0.015535
[01:24:40.550] iteration 29644 : model1 loss : 0.438672 model2 loss : 0.015593
[01:24:40.781] iteration 29645 : model1 loss : 0.438025 model2 loss : 0.018191
[01:24:41.010] iteration 29646 : model1 loss : 0.440464 model2 loss : 0.017770
[01:24:41.248] iteration 29647 : model1 loss : 0.441040 model2 loss : 0.016433
[01:24:41.487] iteration 29648 : model1 loss : 0.435752 model2 loss : 0.016186
[01:24:41.717] iteration 29649 : model1 loss : 0.440605 model2 loss : 0.015224
[01:24:41.955] iteration 29650 : model1 loss : 0.441790 model2 loss : 0.015865
[01:24:42.191] iteration 29651 : model1 loss : 0.438255 model2 loss : 0.014350
[01:24:42.420] iteration 29652 : model1 loss : 0.441545 model2 loss : 0.015878
[01:24:44.701] iteration 29653 : model1 loss : 0.441664 model2 loss : 0.014684
[01:24:44.931] iteration 29654 : model1 loss : 0.446476 model2 loss : 0.019042
[01:24:45.168] iteration 29655 : model1 loss : 0.436383 model2 loss : 0.015274
[01:24:45.404] iteration 29656 : model1 loss : 0.441140 model2 loss : 0.014165
[01:24:45.639] iteration 29657 : model1 loss : 0.439138 model2 loss : 0.015685
[01:24:45.872] iteration 29658 : model1 loss : 0.439957 model2 loss : 0.016658
[01:24:46.107] iteration 29659 : model1 loss : 0.439588 model2 loss : 0.014705
[01:24:46.343] iteration 29660 : model1 loss : 0.440922 model2 loss : 0.016303
[01:24:46.574] iteration 29661 : model1 loss : 0.442010 model2 loss : 0.016841
[01:24:46.808] iteration 29662 : model1 loss : 0.439036 model2 loss : 0.017256
[01:24:47.040] iteration 29663 : model1 loss : 0.436812 model2 loss : 0.015994
[01:24:47.282] iteration 29664 : model1 loss : 0.436449 model2 loss : 0.014293
[01:24:47.516] iteration 29665 : model1 loss : 0.436542 model2 loss : 0.014480
[01:24:47.749] iteration 29666 : model1 loss : 0.440932 model2 loss : 0.013924
[01:24:47.986] iteration 29667 : model1 loss : 0.440497 model2 loss : 0.016725
[01:24:48.218] iteration 29668 : model1 loss : 0.440225 model2 loss : 0.016789
[01:24:48.447] iteration 29669 : model1 loss : 0.439737 model2 loss : 0.014154
[01:24:48.682] iteration 29670 : model1 loss : 0.442399 model2 loss : 0.014840
[01:24:48.918] iteration 29671 : model1 loss : 0.440462 model2 loss : 0.016872
[01:24:49.150] iteration 29672 : model1 loss : 0.440181 model2 loss : 0.016004
[01:24:49.379] iteration 29673 : model1 loss : 0.440555 model2 loss : 0.016636
[01:24:51.687] iteration 29674 : model1 loss : 0.441443 model2 loss : 0.016913
[01:24:51.920] iteration 29675 : model1 loss : 0.442899 model2 loss : 0.016206
[01:24:52.152] iteration 29676 : model1 loss : 0.438845 model2 loss : 0.015736
[01:24:52.390] iteration 29677 : model1 loss : 0.439024 model2 loss : 0.015103
[01:24:52.621] iteration 29678 : model1 loss : 0.437321 model2 loss : 0.016254
[01:24:52.851] iteration 29679 : model1 loss : 0.438830 model2 loss : 0.017362
[01:24:53.086] iteration 29680 : model1 loss : 0.439783 model2 loss : 0.015785
[01:24:53.315] iteration 29681 : model1 loss : 0.439225 model2 loss : 0.013631
[01:24:53.546] iteration 29682 : model1 loss : 0.440703 model2 loss : 0.014481
[01:24:53.781] iteration 29683 : model1 loss : 0.434852 model2 loss : 0.015488
[01:24:54.015] iteration 29684 : model1 loss : 0.435728 model2 loss : 0.016074
[01:24:54.250] iteration 29685 : model1 loss : 0.439400 model2 loss : 0.017828
[01:24:54.488] iteration 29686 : model1 loss : 0.438437 model2 loss : 0.015397
[01:24:54.719] iteration 29687 : model1 loss : 0.444675 model2 loss : 0.017378
[01:24:54.955] iteration 29688 : model1 loss : 0.441582 model2 loss : 0.013529
[01:24:55.188] iteration 29689 : model1 loss : 0.442844 model2 loss : 0.015758
[01:24:55.421] iteration 29690 : model1 loss : 0.442070 model2 loss : 0.016937
[01:24:55.653] iteration 29691 : model1 loss : 0.440063 model2 loss : 0.015520
[01:24:55.885] iteration 29692 : model1 loss : 0.444928 model2 loss : 0.017774
[01:24:56.121] iteration 29693 : model1 loss : 0.443157 model2 loss : 0.015577
[01:24:56.355] iteration 29694 : model1 loss : 0.436433 model2 loss : 0.016892
[01:24:58.671] iteration 29695 : model1 loss : 0.436005 model2 loss : 0.013844
[01:24:58.909] iteration 29696 : model1 loss : 0.437492 model2 loss : 0.015274
[01:24:59.143] iteration 29697 : model1 loss : 0.441975 model2 loss : 0.013996
[01:24:59.386] iteration 29698 : model1 loss : 0.443540 model2 loss : 0.016254
[01:24:59.614] iteration 29699 : model1 loss : 0.439818 model2 loss : 0.015876
[01:24:59.843] iteration 29700 : model1 loss : 0.441785 model2 loss : 0.016306
[01:25:00.076] iteration 29701 : model1 loss : 0.438602 model2 loss : 0.015705
[01:25:00.307] iteration 29702 : model1 loss : 0.438602 model2 loss : 0.016025
[01:25:00.543] iteration 29703 : model1 loss : 0.441732 model2 loss : 0.015331
[01:25:00.777] iteration 29704 : model1 loss : 0.441513 model2 loss : 0.013896
[01:25:01.008] iteration 29705 : model1 loss : 0.439259 model2 loss : 0.016622
[01:25:01.241] iteration 29706 : model1 loss : 0.436457 model2 loss : 0.015950
[01:25:01.472] iteration 29707 : model1 loss : 0.440848 model2 loss : 0.015933
[01:25:01.698] iteration 29708 : model1 loss : 0.439188 model2 loss : 0.015773
[01:25:01.929] iteration 29709 : model1 loss : 0.441622 model2 loss : 0.017966
[01:25:02.164] iteration 29710 : model1 loss : 0.438984 model2 loss : 0.017047
[01:25:02.393] iteration 29711 : model1 loss : 0.441337 model2 loss : 0.017555
[01:25:02.623] iteration 29712 : model1 loss : 0.444619 model2 loss : 0.016574
[01:25:02.855] iteration 29713 : model1 loss : 0.441450 model2 loss : 0.015060
[01:25:03.087] iteration 29714 : model1 loss : 0.440726 model2 loss : 0.015926
[01:25:03.322] iteration 29715 : model1 loss : 0.437602 model2 loss : 0.016270
[01:25:05.622] iteration 29716 : model1 loss : 0.443218 model2 loss : 0.015821
[01:25:05.853] iteration 29717 : model1 loss : 0.436646 model2 loss : 0.013932
[01:25:06.085] iteration 29718 : model1 loss : 0.434110 model2 loss : 0.016276
[01:25:06.318] iteration 29719 : model1 loss : 0.440350 model2 loss : 0.017250
[01:25:06.549] iteration 29720 : model1 loss : 0.436738 model2 loss : 0.014888
[01:25:06.780] iteration 29721 : model1 loss : 0.436137 model2 loss : 0.014306
[01:25:07.012] iteration 29722 : model1 loss : 0.443093 model2 loss : 0.015329
[01:25:07.241] iteration 29723 : model1 loss : 0.438773 model2 loss : 0.014328
[01:25:07.474] iteration 29724 : model1 loss : 0.439880 model2 loss : 0.015569
[01:25:07.706] iteration 29725 : model1 loss : 0.439195 model2 loss : 0.014930
[01:25:07.938] iteration 29726 : model1 loss : 0.442425 model2 loss : 0.014660
[01:25:08.175] iteration 29727 : model1 loss : 0.440037 model2 loss : 0.015697
[01:25:08.411] iteration 29728 : model1 loss : 0.438908 model2 loss : 0.014809
[01:25:08.642] iteration 29729 : model1 loss : 0.441422 model2 loss : 0.016500
[01:25:08.878] iteration 29730 : model1 loss : 0.442743 model2 loss : 0.014683
[01:25:09.112] iteration 29731 : model1 loss : 0.438893 model2 loss : 0.016767
[01:25:09.343] iteration 29732 : model1 loss : 0.442521 model2 loss : 0.016299
[01:25:09.575] iteration 29733 : model1 loss : 0.440609 model2 loss : 0.015709
[01:25:09.808] iteration 29734 : model1 loss : 0.445279 model2 loss : 0.016041
[01:25:10.045] iteration 29735 : model1 loss : 0.438658 model2 loss : 0.015292
[01:25:10.279] iteration 29736 : model1 loss : 0.441480 model2 loss : 0.014878
[01:25:12.624] iteration 29737 : model1 loss : 0.439418 model2 loss : 0.016848
[01:25:12.859] iteration 29738 : model1 loss : 0.446369 model2 loss : 0.018660
[01:25:13.092] iteration 29739 : model1 loss : 0.440886 model2 loss : 0.017198
[01:25:13.327] iteration 29740 : model1 loss : 0.441293 model2 loss : 0.016690
[01:25:13.556] iteration 29741 : model1 loss : 0.437661 model2 loss : 0.014194
[01:25:13.788] iteration 29742 : model1 loss : 0.443709 model2 loss : 0.017325
[01:25:14.024] iteration 29743 : model1 loss : 0.437341 model2 loss : 0.017149
[01:25:14.256] iteration 29744 : model1 loss : 0.440712 model2 loss : 0.016355
[01:25:14.493] iteration 29745 : model1 loss : 0.438022 model2 loss : 0.017434
[01:25:14.734] iteration 29746 : model1 loss : 0.440600 model2 loss : 0.015607
[01:25:14.968] iteration 29747 : model1 loss : 0.438461 model2 loss : 0.015916
[01:25:15.205] iteration 29748 : model1 loss : 0.437312 model2 loss : 0.014104
[01:25:15.440] iteration 29749 : model1 loss : 0.437168 model2 loss : 0.016611
[01:25:15.671] iteration 29750 : model1 loss : 0.440424 model2 loss : 0.015970
[01:25:15.907] iteration 29751 : model1 loss : 0.436107 model2 loss : 0.013103
[01:25:16.142] iteration 29752 : model1 loss : 0.441141 model2 loss : 0.016781
[01:25:16.379] iteration 29753 : model1 loss : 0.440566 model2 loss : 0.018057
[01:25:16.609] iteration 29754 : model1 loss : 0.440614 model2 loss : 0.016773
[01:25:16.842] iteration 29755 : model1 loss : 0.442112 model2 loss : 0.014659
[01:25:17.078] iteration 29756 : model1 loss : 0.442086 model2 loss : 0.016594
[01:25:17.306] iteration 29757 : model1 loss : 0.443925 model2 loss : 0.017431
[01:25:19.631] iteration 29758 : model1 loss : 0.442369 model2 loss : 0.015799
[01:25:19.859] iteration 29759 : model1 loss : 0.438459 model2 loss : 0.016181
[01:25:20.093] iteration 29760 : model1 loss : 0.441368 model2 loss : 0.016957
[01:25:20.324] iteration 29761 : model1 loss : 0.439309 model2 loss : 0.016312
[01:25:20.552] iteration 29762 : model1 loss : 0.440640 model2 loss : 0.015836
[01:25:20.782] iteration 29763 : model1 loss : 0.441718 model2 loss : 0.014732
[01:25:21.019] iteration 29764 : model1 loss : 0.443781 model2 loss : 0.018024
[01:25:21.253] iteration 29765 : model1 loss : 0.436998 model2 loss : 0.016305
[01:25:21.489] iteration 29766 : model1 loss : 0.443161 model2 loss : 0.014354
[01:25:21.725] iteration 29767 : model1 loss : 0.437030 model2 loss : 0.014756
[01:25:21.961] iteration 29768 : model1 loss : 0.439338 model2 loss : 0.015149
[01:25:22.198] iteration 29769 : model1 loss : 0.436130 model2 loss : 0.014736
[01:25:22.431] iteration 29770 : model1 loss : 0.441799 model2 loss : 0.016061
[01:25:22.664] iteration 29771 : model1 loss : 0.440197 model2 loss : 0.015678
[01:25:22.897] iteration 29772 : model1 loss : 0.436145 model2 loss : 0.014798
[01:25:23.128] iteration 29773 : model1 loss : 0.440624 model2 loss : 0.014391
[01:25:23.366] iteration 29774 : model1 loss : 0.437888 model2 loss : 0.014761
[01:25:23.598] iteration 29775 : model1 loss : 0.438216 model2 loss : 0.015535
[01:25:23.831] iteration 29776 : model1 loss : 0.443034 model2 loss : 0.016946
[01:25:24.066] iteration 29777 : model1 loss : 0.444541 model2 loss : 0.015255
[01:25:24.294] iteration 29778 : model1 loss : 0.439946 model2 loss : 0.017801
[01:25:26.629] iteration 29779 : model1 loss : 0.438975 model2 loss : 0.015192
[01:25:26.863] iteration 29780 : model1 loss : 0.441835 model2 loss : 0.014545
[01:25:27.097] iteration 29781 : model1 loss : 0.434772 model2 loss : 0.016583
[01:25:27.325] iteration 29782 : model1 loss : 0.440841 model2 loss : 0.015036
[01:25:27.559] iteration 29783 : model1 loss : 0.447274 model2 loss : 0.017964
[01:25:27.794] iteration 29784 : model1 loss : 0.437514 model2 loss : 0.015056
[01:25:28.024] iteration 29785 : model1 loss : 0.438876 model2 loss : 0.015712
[01:25:28.263] iteration 29786 : model1 loss : 0.442287 model2 loss : 0.017458
[01:25:28.501] iteration 29787 : model1 loss : 0.444975 model2 loss : 0.016926
[01:25:28.732] iteration 29788 : model1 loss : 0.434167 model2 loss : 0.015631
[01:25:28.962] iteration 29789 : model1 loss : 0.445368 model2 loss : 0.018011
[01:25:29.199] iteration 29790 : model1 loss : 0.436450 model2 loss : 0.014160
[01:25:29.426] iteration 29791 : model1 loss : 0.436441 model2 loss : 0.015426
[01:25:29.658] iteration 29792 : model1 loss : 0.439229 model2 loss : 0.016254
[01:25:29.891] iteration 29793 : model1 loss : 0.437723 model2 loss : 0.015662
[01:25:30.132] iteration 29794 : model1 loss : 0.441746 model2 loss : 0.015587
[01:25:30.371] iteration 29795 : model1 loss : 0.444949 model2 loss : 0.015753
[01:25:30.601] iteration 29796 : model1 loss : 0.443666 model2 loss : 0.018073
[01:25:30.832] iteration 29797 : model1 loss : 0.442636 model2 loss : 0.017654
[01:25:31.065] iteration 29798 : model1 loss : 0.434544 model2 loss : 0.014279
[01:25:31.294] iteration 29799 : model1 loss : 0.441066 model2 loss : 0.013850
[01:25:33.664] iteration 29800 : model1 loss : 0.438098 model2 loss : 0.015230
[01:25:33.897] iteration 29801 : model1 loss : 0.441641 model2 loss : 0.016242
[01:25:34.131] iteration 29802 : model1 loss : 0.440784 model2 loss : 0.015382
[01:25:34.366] iteration 29803 : model1 loss : 0.439810 model2 loss : 0.015648
[01:25:34.596] iteration 29804 : model1 loss : 0.441929 model2 loss : 0.015626
[01:25:34.828] iteration 29805 : model1 loss : 0.440242 model2 loss : 0.014443
[01:25:35.064] iteration 29806 : model1 loss : 0.438044 model2 loss : 0.015369
[01:25:35.299] iteration 29807 : model1 loss : 0.433615 model2 loss : 0.015257
[01:25:35.531] iteration 29808 : model1 loss : 0.442197 model2 loss : 0.014883
[01:25:35.762] iteration 29809 : model1 loss : 0.444626 model2 loss : 0.017517
[01:25:35.998] iteration 29810 : model1 loss : 0.440002 model2 loss : 0.015162
[01:25:36.232] iteration 29811 : model1 loss : 0.438249 model2 loss : 0.018497
[01:25:36.467] iteration 29812 : model1 loss : 0.445390 model2 loss : 0.015807
[01:25:36.699] iteration 29813 : model1 loss : 0.440496 model2 loss : 0.017416
[01:25:36.930] iteration 29814 : model1 loss : 0.442881 model2 loss : 0.017143
[01:25:37.163] iteration 29815 : model1 loss : 0.438972 model2 loss : 0.014184
[01:25:37.395] iteration 29816 : model1 loss : 0.438102 model2 loss : 0.013892
[01:25:37.631] iteration 29817 : model1 loss : 0.439430 model2 loss : 0.016574
[01:25:37.870] iteration 29818 : model1 loss : 0.437370 model2 loss : 0.015743
[01:25:38.102] iteration 29819 : model1 loss : 0.444929 model2 loss : 0.018060
[01:25:38.331] iteration 29820 : model1 loss : 0.438209 model2 loss : 0.016752
[01:25:40.668] iteration 29821 : model1 loss : 0.440452 model2 loss : 0.016237
[01:25:40.900] iteration 29822 : model1 loss : 0.438820 model2 loss : 0.016083
[01:25:41.140] iteration 29823 : model1 loss : 0.440314 model2 loss : 0.015697
[01:25:41.377] iteration 29824 : model1 loss : 0.442908 model2 loss : 0.017783
[01:25:41.608] iteration 29825 : model1 loss : 0.442894 model2 loss : 0.015383
[01:25:41.841] iteration 29826 : model1 loss : 0.439845 model2 loss : 0.015904
[01:25:42.075] iteration 29827 : model1 loss : 0.437013 model2 loss : 0.014764
[01:25:42.306] iteration 29828 : model1 loss : 0.439253 model2 loss : 0.014985
[01:25:42.545] iteration 29829 : model1 loss : 0.443911 model2 loss : 0.015997
[01:25:42.776] iteration 29830 : model1 loss : 0.441104 model2 loss : 0.015507
[01:25:43.008] iteration 29831 : model1 loss : 0.436367 model2 loss : 0.013430
[01:25:43.246] iteration 29832 : model1 loss : 0.443784 model2 loss : 0.015469
[01:25:43.484] iteration 29833 : model1 loss : 0.436294 model2 loss : 0.016633
[01:25:43.714] iteration 29834 : model1 loss : 0.443018 model2 loss : 0.017117
[01:25:43.952] iteration 29835 : model1 loss : 0.435613 model2 loss : 0.015231
[01:25:44.189] iteration 29836 : model1 loss : 0.440717 model2 loss : 0.015124
[01:25:44.424] iteration 29837 : model1 loss : 0.438435 model2 loss : 0.016412
[01:25:44.661] iteration 29838 : model1 loss : 0.438939 model2 loss : 0.015272
[01:25:44.893] iteration 29839 : model1 loss : 0.439088 model2 loss : 0.017464
[01:25:45.123] iteration 29840 : model1 loss : 0.443273 model2 loss : 0.016452
[01:25:45.359] iteration 29841 : model1 loss : 0.441774 model2 loss : 0.015082
[01:25:47.748] iteration 29842 : model1 loss : 0.437455 model2 loss : 0.015724
[01:25:47.980] iteration 29843 : model1 loss : 0.435953 model2 loss : 0.015180
[01:25:48.213] iteration 29844 : model1 loss : 0.440162 model2 loss : 0.015900
[01:25:48.442] iteration 29845 : model1 loss : 0.435917 model2 loss : 0.014636
[01:25:48.676] iteration 29846 : model1 loss : 0.442732 model2 loss : 0.014682
[01:25:48.908] iteration 29847 : model1 loss : 0.440814 model2 loss : 0.017223
[01:25:49.143] iteration 29848 : model1 loss : 0.441323 model2 loss : 0.016589
[01:25:49.374] iteration 29849 : model1 loss : 0.438024 model2 loss : 0.015936
[01:25:49.613] iteration 29850 : model1 loss : 0.441730 model2 loss : 0.015914
[01:25:49.843] iteration 29851 : model1 loss : 0.443289 model2 loss : 0.015170
[01:25:50.081] iteration 29852 : model1 loss : 0.440608 model2 loss : 0.015516
[01:25:50.311] iteration 29853 : model1 loss : 0.444440 model2 loss : 0.016524
[01:25:50.545] iteration 29854 : model1 loss : 0.438051 model2 loss : 0.015068
[01:25:50.780] iteration 29855 : model1 loss : 0.442909 model2 loss : 0.016056
[01:25:51.018] iteration 29856 : model1 loss : 0.437036 model2 loss : 0.014059
[01:25:51.250] iteration 29857 : model1 loss : 0.436723 model2 loss : 0.013837
[01:25:51.486] iteration 29858 : model1 loss : 0.434504 model2 loss : 0.016589
[01:25:51.719] iteration 29859 : model1 loss : 0.445934 model2 loss : 0.016388
[01:25:51.953] iteration 29860 : model1 loss : 0.441389 model2 loss : 0.015272
[01:25:52.192] iteration 29861 : model1 loss : 0.441945 model2 loss : 0.016777
[01:25:52.420] iteration 29862 : model1 loss : 0.442620 model2 loss : 0.014524
[01:25:54.741] iteration 29863 : model1 loss : 0.439736 model2 loss : 0.014051
[01:25:54.971] iteration 29864 : model1 loss : 0.437395 model2 loss : 0.015736
[01:25:55.203] iteration 29865 : model1 loss : 0.442449 model2 loss : 0.016119
[01:25:55.434] iteration 29866 : model1 loss : 0.441133 model2 loss : 0.015532
[01:25:55.670] iteration 29867 : model1 loss : 0.443573 model2 loss : 0.015314
[01:25:55.903] iteration 29868 : model1 loss : 0.444339 model2 loss : 0.015783
[01:25:56.136] iteration 29869 : model1 loss : 0.440116 model2 loss : 0.016073
[01:25:56.373] iteration 29870 : model1 loss : 0.441183 model2 loss : 0.015480
[01:25:56.606] iteration 29871 : model1 loss : 0.436033 model2 loss : 0.015266
[01:25:56.839] iteration 29872 : model1 loss : 0.436270 model2 loss : 0.016028
[01:25:57.071] iteration 29873 : model1 loss : 0.443550 model2 loss : 0.018436
[01:25:57.302] iteration 29874 : model1 loss : 0.433958 model2 loss : 0.016113
[01:25:57.540] iteration 29875 : model1 loss : 0.439107 model2 loss : 0.015610
[01:25:57.775] iteration 29876 : model1 loss : 0.444541 model2 loss : 0.016164
[01:25:58.004] iteration 29877 : model1 loss : 0.442359 model2 loss : 0.017099
[01:25:58.237] iteration 29878 : model1 loss : 0.439755 model2 loss : 0.016676
[01:25:58.476] iteration 29879 : model1 loss : 0.437806 model2 loss : 0.015120
[01:25:58.713] iteration 29880 : model1 loss : 0.439741 model2 loss : 0.016426
[01:25:58.944] iteration 29881 : model1 loss : 0.441739 model2 loss : 0.015772
[01:25:59.183] iteration 29882 : model1 loss : 0.437484 model2 loss : 0.015660
[01:25:59.420] iteration 29883 : model1 loss : 0.438706 model2 loss : 0.016432
[01:26:01.786] iteration 29884 : model1 loss : 0.437831 model2 loss : 0.014600
[01:26:02.018] iteration 29885 : model1 loss : 0.440982 model2 loss : 0.017460
[01:26:02.253] iteration 29886 : model1 loss : 0.440576 model2 loss : 0.016227
[01:26:02.490] iteration 29887 : model1 loss : 0.445443 model2 loss : 0.017709
[01:26:02.721] iteration 29888 : model1 loss : 0.438936 model2 loss : 0.015642
[01:26:02.956] iteration 29889 : model1 loss : 0.435976 model2 loss : 0.016535
[01:26:03.191] iteration 29890 : model1 loss : 0.440667 model2 loss : 0.015269
[01:26:03.427] iteration 29891 : model1 loss : 0.439326 model2 loss : 0.017916
[01:26:03.662] iteration 29892 : model1 loss : 0.442315 model2 loss : 0.016415
[01:26:03.894] iteration 29893 : model1 loss : 0.437651 model2 loss : 0.015705
[01:26:04.129] iteration 29894 : model1 loss : 0.446389 model2 loss : 0.018026
[01:26:04.363] iteration 29895 : model1 loss : 0.438663 model2 loss : 0.015048
[01:26:04.595] iteration 29896 : model1 loss : 0.433079 model2 loss : 0.014749
[01:26:04.830] iteration 29897 : model1 loss : 0.439148 model2 loss : 0.016149
[01:26:05.064] iteration 29898 : model1 loss : 0.442037 model2 loss : 0.015713
[01:26:05.296] iteration 29899 : model1 loss : 0.442603 model2 loss : 0.016400
[01:26:05.535] iteration 29900 : model1 loss : 0.439700 model2 loss : 0.014303
[01:26:05.767] iteration 29901 : model1 loss : 0.439096 model2 loss : 0.015587
[01:26:06.001] iteration 29902 : model1 loss : 0.444919 model2 loss : 0.017212
[01:26:06.232] iteration 29903 : model1 loss : 0.441181 model2 loss : 0.016685
[01:26:06.463] iteration 29904 : model1 loss : 0.439310 model2 loss : 0.015754
[01:26:08.526] iteration 29905 : model1 loss : 0.444206 model2 loss : 0.017390
[01:26:08.697] iteration 29906 : model1 loss : 0.441096 model2 loss : 0.014947
[01:26:08.869] iteration 29907 : model1 loss : 0.443809 model2 loss : 0.018634
[01:26:09.041] iteration 29908 : model1 loss : 0.440712 model2 loss : 0.015671
[01:26:09.213] iteration 29909 : model1 loss : 0.440148 model2 loss : 0.016721
[01:26:09.381] iteration 29910 : model1 loss : 0.438481 model2 loss : 0.014758
[01:26:09.551] iteration 29911 : model1 loss : 0.438375 model2 loss : 0.015027
[01:26:09.721] iteration 29912 : model1 loss : 0.438450 model2 loss : 0.016769
[01:26:09.893] iteration 29913 : model1 loss : 0.440433 model2 loss : 0.015948
[01:26:10.063] iteration 29914 : model1 loss : 0.441190 model2 loss : 0.017536
[01:26:10.235] iteration 29915 : model1 loss : 0.436513 model2 loss : 0.014644
[01:26:10.404] iteration 29916 : model1 loss : 0.441878 model2 loss : 0.016506
[01:26:10.573] iteration 29917 : model1 loss : 0.437300 model2 loss : 0.014557
[01:26:10.740] iteration 29918 : model1 loss : 0.435983 model2 loss : 0.014771
[01:26:10.910] iteration 29919 : model1 loss : 0.442597 model2 loss : 0.015584
[01:26:11.080] iteration 29920 : model1 loss : 0.443945 model2 loss : 0.016747
[01:26:11.249] iteration 29921 : model1 loss : 0.436484 model2 loss : 0.014861
[01:26:11.418] iteration 29922 : model1 loss : 0.439631 model2 loss : 0.015346
[01:26:11.588] iteration 29923 : model1 loss : 0.441768 model2 loss : 0.016905
[01:26:11.755] iteration 29924 : model1 loss : 0.442390 model2 loss : 0.015962
[01:26:11.925] iteration 29925 : model1 loss : 0.438672 model2 loss : 0.016027
[01:26:13.954] iteration 29926 : model1 loss : 0.441175 model2 loss : 0.016483
[01:26:14.127] iteration 29927 : model1 loss : 0.440754 model2 loss : 0.015999
[01:26:14.303] iteration 29928 : model1 loss : 0.441100 model2 loss : 0.017213
[01:26:14.471] iteration 29929 : model1 loss : 0.439139 model2 loss : 0.014375
[01:26:14.641] iteration 29930 : model1 loss : 0.438777 model2 loss : 0.015944
[01:26:14.815] iteration 29931 : model1 loss : 0.435548 model2 loss : 0.015064
[01:26:14.993] iteration 29932 : model1 loss : 0.438995 model2 loss : 0.015859
[01:26:15.165] iteration 29933 : model1 loss : 0.441299 model2 loss : 0.015829
[01:26:15.339] iteration 29934 : model1 loss : 0.443458 model2 loss : 0.015814
[01:26:15.507] iteration 29935 : model1 loss : 0.440928 model2 loss : 0.015119
[01:26:15.678] iteration 29936 : model1 loss : 0.438045 model2 loss : 0.013305
[01:26:15.847] iteration 29937 : model1 loss : 0.439486 model2 loss : 0.015527
[01:26:16.019] iteration 29938 : model1 loss : 0.441328 model2 loss : 0.015385
[01:26:16.190] iteration 29939 : model1 loss : 0.438954 model2 loss : 0.015519
[01:26:16.368] iteration 29940 : model1 loss : 0.441738 model2 loss : 0.016071
[01:26:16.536] iteration 29941 : model1 loss : 0.439350 model2 loss : 0.016142
[01:26:16.709] iteration 29942 : model1 loss : 0.441265 model2 loss : 0.016433
[01:26:16.879] iteration 29943 : model1 loss : 0.444124 model2 loss : 0.017906
[01:26:17.049] iteration 29944 : model1 loss : 0.439325 model2 loss : 0.015693
[01:26:17.217] iteration 29945 : model1 loss : 0.444026 model2 loss : 0.015602
[01:26:17.386] iteration 29946 : model1 loss : 0.437697 model2 loss : 0.014552
[01:26:19.347] iteration 29947 : model1 loss : 0.437638 model2 loss : 0.016139
[01:26:19.515] iteration 29948 : model1 loss : 0.439653 model2 loss : 0.015147
[01:26:19.688] iteration 29949 : model1 loss : 0.440659 model2 loss : 0.016983
[01:26:19.856] iteration 29950 : model1 loss : 0.445526 model2 loss : 0.017928
[01:26:20.028] iteration 29951 : model1 loss : 0.440268 model2 loss : 0.014880
[01:26:20.197] iteration 29952 : model1 loss : 0.437213 model2 loss : 0.017219
[01:26:20.370] iteration 29953 : model1 loss : 0.435799 model2 loss : 0.015637
[01:26:20.539] iteration 29954 : model1 loss : 0.438681 model2 loss : 0.015146
[01:26:20.710] iteration 29955 : model1 loss : 0.438082 model2 loss : 0.015369
[01:26:20.880] iteration 29956 : model1 loss : 0.443102 model2 loss : 0.017743
[01:26:21.053] iteration 29957 : model1 loss : 0.435892 model2 loss : 0.014812
[01:26:21.219] iteration 29958 : model1 loss : 0.440011 model2 loss : 0.013802
[01:26:21.391] iteration 29959 : model1 loss : 0.438261 model2 loss : 0.016130
[01:26:21.560] iteration 29960 : model1 loss : 0.438132 model2 loss : 0.014872
[01:26:21.730] iteration 29961 : model1 loss : 0.440553 model2 loss : 0.016662
[01:26:21.900] iteration 29962 : model1 loss : 0.439622 model2 loss : 0.016463
[01:26:22.072] iteration 29963 : model1 loss : 0.444941 model2 loss : 0.016813
[01:26:22.240] iteration 29964 : model1 loss : 0.445042 model2 loss : 0.016134
[01:26:22.411] iteration 29965 : model1 loss : 0.442227 model2 loss : 0.015662
[01:26:22.578] iteration 29966 : model1 loss : 0.440270 model2 loss : 0.016874
[01:26:22.747] iteration 29967 : model1 loss : 0.445147 model2 loss : 0.018791
[01:26:24.705] iteration 29968 : model1 loss : 0.441269 model2 loss : 0.015830
[01:26:24.872] iteration 29969 : model1 loss : 0.442696 model2 loss : 0.014363
[01:26:25.045] iteration 29970 : model1 loss : 0.439553 model2 loss : 0.017984
[01:26:25.212] iteration 29971 : model1 loss : 0.436570 model2 loss : 0.015487
[01:26:25.382] iteration 29972 : model1 loss : 0.443198 model2 loss : 0.018014
[01:26:25.551] iteration 29973 : model1 loss : 0.445469 model2 loss : 0.017004
[01:26:25.723] iteration 29974 : model1 loss : 0.440301 model2 loss : 0.014961
[01:26:25.893] iteration 29975 : model1 loss : 0.442344 model2 loss : 0.017980
[01:26:26.065] iteration 29976 : model1 loss : 0.445990 model2 loss : 0.019481
[01:26:26.235] iteration 29977 : model1 loss : 0.437337 model2 loss : 0.015874
[01:26:26.405] iteration 29978 : model1 loss : 0.437228 model2 loss : 0.013881
[01:26:26.575] iteration 29979 : model1 loss : 0.438551 model2 loss : 0.013387
[01:26:26.747] iteration 29980 : model1 loss : 0.439784 model2 loss : 0.016136
[01:26:26.917] iteration 29981 : model1 loss : 0.440593 model2 loss : 0.015463
[01:26:27.094] iteration 29982 : model1 loss : 0.439650 model2 loss : 0.015638
[01:26:27.262] iteration 29983 : model1 loss : 0.437901 model2 loss : 0.017227
[01:26:27.438] iteration 29984 : model1 loss : 0.439127 model2 loss : 0.015776
[01:26:27.607] iteration 29985 : model1 loss : 0.437779 model2 loss : 0.013533
[01:26:27.777] iteration 29986 : model1 loss : 0.438637 model2 loss : 0.016566
[01:26:27.945] iteration 29987 : model1 loss : 0.439177 model2 loss : 0.014610
[01:26:28.116] iteration 29988 : model1 loss : 0.441589 model2 loss : 0.015913
[01:26:30.100] iteration 29989 : model1 loss : 0.438179 model2 loss : 0.013435
[01:26:30.270] iteration 29990 : model1 loss : 0.442063 model2 loss : 0.016267
[01:26:30.441] iteration 29991 : model1 loss : 0.443594 model2 loss : 0.018973
[01:26:30.610] iteration 29992 : model1 loss : 0.439171 model2 loss : 0.016506
[01:26:30.781] iteration 29993 : model1 loss : 0.442439 model2 loss : 0.014869
[01:26:30.951] iteration 29994 : model1 loss : 0.444174 model2 loss : 0.015765
[01:26:31.124] iteration 29995 : model1 loss : 0.441408 model2 loss : 0.017362
[01:26:31.295] iteration 29996 : model1 loss : 0.438408 model2 loss : 0.016446
[01:26:31.465] iteration 29997 : model1 loss : 0.436363 model2 loss : 0.015605
[01:26:31.634] iteration 29998 : model1 loss : 0.440673 model2 loss : 0.015894
[01:26:31.806] iteration 29999 : model1 loss : 0.442331 model2 loss : 0.016528
[01:26:31.975] iteration 30000 : model1 loss : 0.441601 model2 loss : 0.014333
[01:26:41.537] iteration 30000 : model1_mean_dice : 0.885955 model1_mean_hd95 : 4.869895
[01:26:51.043] iteration 30000 : model2_mean_dice : 0.883621 model2_mean_hd95 : 3.973788
[01:26:51.064] save model1 to ../model/ACDC/EVILv1_kl0.5_tau0.25_14_1337/unet\model1_iter_30000.pth
[01:26:51.085] save model2 to ../model/ACDC/EVILv1_kl0.5_tau0.25_14_1337/unet\model2_iter_30000.pth
